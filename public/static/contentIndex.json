{"2--source-materials/mateNum--Lez16_trascrizione":{"slug":"2--source-materials/mateNum--Lez16_trascrizione","filePath":"2- source materials/mateNum- Lez16_trascrizione.md","title":"mateNum- Lez16_trascrizione","links":["3--tag/trascrizione","3--tag/matematica-numerica"],"tags":[],"content":"2025-04-25 10:38\n_Tags:trascrizione. matematica numerica\nmateNum- Lez16_trascrizione\nSecondo me verrà una disgrazia sta registrazione. Allora, cerchiamo di capire, anzi rifaccio un attimo il punto della situazione. L’ultima volta abbiamo incominciato a gestire i sistemi indeterminati distinguendo tra sistemi sovradeterminati, ovvero quelli che hanno eh m mag n. Ok? Quindi sono i sistemi per i quali abbiamo modificato la definizione di soluzione in senso classico, distinguendo il caso in cui la matrice A sia a rango pieno e in quel caso lì si poteva arrivare alle equazioni normali, se vi ricordate, per le quali o uno procedeva con i solver per le matrici simmetriche definite positive oce del fatto che questo avrebbe portato inevitabilmente degli errori numerici si procedeva via fattorizzazione QR reclutato. Ok? Poi invece avevamo chiuso gestendo i sistemi sovradeterminati non a rango massimo. E a questo punto avevamo detto che la soluzione nel senso dei minimi quadrati, cioè quella che minimizza la norma del del residuo, non era più sufficiente per definire in modo unico quella soluzione, quindi si andava alla ricerca di una soluzione che minimizzasse eh la la norma del residuo, ma a norma minima. Ok? E quindi gli avevamo introdotto tutta la parte della ST, mi sembra che fossimo fermi di Ok? Quindi ci mancano i sistemi sottodeterminati per i quali in realtà diremo molto di meno, quindi sarà una cosa sicuramente più veloce. E però prima di far questo vorrei legare i due concetti, cioè i due momenti, se avete fatto caso, in cui abbiamo parlato di equazioni normali. Quindi abbiamo citato una volta le equazioni normali parlando di quando abbiamo costruito la retta di regressione e la sua generalizzazione. Ok? Quindi il sistema che era fatto che aveva come entrate eh la somma in composition la somma di tutti uno, la somma di tutti gli isconi, la somma di tutti gli isconi al quadrato, eccetera. Ok? E poi parlato di pozioni normali la scorsa volta gestendo i sistemi sovradeterminati nella fattispecie il caso del rango pieno. Ok? Quindi ed erano apparentemente due cose diverse. Allora, adesso quello che vogliamo fare è capire che in realtà stiamo parlando della stessa cosa, ok? Quindi unire un po’ eh i punichini in modo corretto. Allora, se vi ricordate, quando abbiamo definito il nostro polinomio eh nel senso dei minimi quadrati, eh l’abbiamo in indicato, mi pare con FT e l’abbiamo caratterizzato con la proprietà di andare a minimizzare, vi ricordate, la somma degli scarti quadratici, ok? Quindi andavamo a fare la differenza tra y i f², ok? E questo c rimbombavo anche il gesso, giusto? È bellissimo. Ok, cioè non so cos’altro fare. C’ho l’alternativa chiamare il tecnico. Vediamo fin quando non impazziamo con questo rimbombo. Allora, questa possiamo andare a riespanderla. Eh, se vi ricordate questo FT discon i era un polinomio di grado T con M. Quindi ricostruisco un attimo le cose che c’eravamo detti e avevamo detto che questo polinomio era caratterizzato da certi specifici coefficienti che avevamo battezzato B con0, B con 1, B con M. Ok? E questi coefficienti, adesso non ricordo se mi chiamato con A quelli del fetilde e con B quelli del polinomio generico, lo recupero o viceversa. Anche ve lo ricordate per caso? Al contrario. Perfetto. Quindi questo era il generico polinomio p m, ok? Appartenente alla famiglia dei pic con m. Lui invece era quello identificato dai coefficienti a 0 + a 1 * x + a m * x^ m, quindi dai coefficienti a con 0 con 1 con m. Ok? Quindi queste dovrebbero essere notazioni eh corrette rispetto alla scorsa volta e quindi alla luce di questo Questa quantità qua possiamo giustamente andare a scriverla. Questo è generico polinomio di grado m, quindi 0 +1 * x i + dm * x i^ il tutto elevato al quadrato. Ok? E quindi, se vi ricordate avevamo tradotto la disuguaglianza che identifica f Ok? Che praticamente prevede questo uguale tramitarsi in un numero uguale. Ok? Quindi questa, se vi ditemi se vi torna è la disuguaglianza da cui eravamo partiti per definire il nostro polinomio minimi quadrati, ok? Dove questo è il generico polinomio di grado m valutato in x y. Quindi a destra avete lo scatto quadratico tra i dati che vogliamo approssimare e il generico polinomio. valutato in corrispondenza dei dati. A sinistra c’è il nostro polinomio minimi quadrati e quindi ho lo scarto quadratico tra y con i e il valore assunto da questo oggetto in corrispondenza di questi nodi. Ok? Mi sembra che questo fosse il frame da cui eravamo partiti. Ok? Quindi questa disuguaglianza eravamo andati a eh tramutarla in un problema di minimizzazione introducendo la famosa funzione f, ok? Per la quale poi eravamo andati a calcolare le derivate parziali rispetto ai alle nostre variabili che sono B0 - BM, imponendo che queste derivate parziali quando valutate nei cofficienti di fetille fossero uguale a zero. Ok? Questa era la strada che avevamo fatto in piccolo poi generalizzandola. Ok? Allora, fondamentalmente questa strada possiamo andare a riscriverla. Possiamo andare a riscriverla nel seguente modo. Io ho il mio vettore A e il vettore A è il vettore che raccoglie i cofficienti a 0 a 1 a m. E questo vettore a quello che realizza il minimo al variare di B in RM, ok? Dove B è il vettore invece che raccoglie i coefficienti del generico polinomio PM. Ok? Quindi possiamo, se ci affidiamo a quella disuguaglianza là sopra, dire che il vettore a quello che realizza il minimo di che cosa? Della somma di i che va da 0 ad n, esattamente di quello che abbiamo a destra, quindi di y - b0 + b1 * x i + bm * x i^ m². Ok? Quindi esattamente un modo equivalente di andare a riscrivere la relazione che avevamo scritto scomodando la funzione f. Ok? Quindi la somma degli scatti quadratici nel momento in cui i coefficienti variano in R viene ottenuta quando scelgo il vettore generico che sta in R con M coincidente col vettore a. Ok? Esattamente la stessa cosa. E si può vedere che dire questo è equivalente a cercare l’oggetto che minimizza sempre al variare del nostro vettore B in R + 1 la seguente quantità. Allora, scrivo A, dobbiamo dare un nome a questi oggetto, a questa matrice a * B - y a quadrato dove B l’abbiamo definito y Quindi con la seconda uguaglianza dobbiamo eh convincere. Ok? Y è il vettore che raccoglie i dati Y0, Y1, YM, ok? Em pa A invece è la matrice che definiamo nel nel seguente modo 1 x0 x0^ X0^ m. Adesso verifichiamo tutto qua. Quanto? E in fondo abbiamo 1 x n x n qu x n^ m. Ok? Allora, quindi fino a qui è tutta roba vecchia. Ditemi se vi torna. Ok? Questa è la vecchia f, giusto? Quindi, anziché dire che f di a0 1 m uguale di f b0 b1 bm * ogni b0 b1 bm. in RM l’ho tradotta dicendo che A realizza il minimo di questa cosa. Ok? Questo invece è un passaggio nuovo. Quindi quello di cui dobbiamo accertarci è che questa sommatoria corrisponde a questo oggetto, ok? Dove Y, dove v l’abbiamo definito y è il vettore che raccoglie i dati coinvolti nella somma degli scarsi quadratici, quindi il vettore y0, y1, YM e A e quella matrice lì. Ok? Allora, perché è vera sta cosa? andiamo a eh capire dove tra l’altro questa matrice l’abbiamo già vista chi è. È la matrice di alzo un attimo di Vermond. Ok? Quindi una matrice che sappiamo non essere delle più amichevoli. Allora, cerchiamo di capire se vale o meno quell’uguaglianza che ho scritto lì, ok? Perché sarà proprio quella che ci porterà a trovare il link con i sistemi sopradeterminati. Allora, innanzitutto questa somma di oggetti al quadrato ci torna è una domanda che sia possa essere intesa come la definizione di una norma euclide al quadrato, giusto? La norma al quadrato è una somma delle componenti di un vettore al quadrato, corretto? Quindi ritorno qua perché mi serve a attivare dei puntatori. Possiamo dire che questa somma per i che va da 0 a n al quadrato di oggetti al quadrato, possa essere intesa effettivamente come l’implementazione di una norma idea di un vettore il cui vettore ha questo come argomento, giusto?\nEh am sì, certo. Grazie. Sì, anche qua questo è giusto. Ok, grazie. Eh, va bene. Quindi questa è la norma euclidea al quadrato di un vettore che ha questo come generica componente, ok? E questa generica componente è del tipo y i, ok? Meno questo oggetto, quindi è una differenza di vettori, quindi che uno dei due vettori sia y direi che deriva dal fatto che qui abbiamo un y con i, ok? E l’altro vettore chi sarà? Boh, da quello che mi si racconta qua, dovrebbe essere il prodotto di quella matrice di Vanermond per il mio vettore B delle eh incognite. Ok? Infatti, se voi provate a fare la prima riga di A per il vettore delle B, che cosa ottenete? B0 * 1 + B1 * X0 + b2 * x0^ che sarebbe qua + b * x0^ m. Ok? Quindi questo oggetto qua per i = 0 ci dà proprio la differenza tra la prima componente del vettore y è la prima componente del vettore prodotto fra la matrice A e il vettore B. È giusto? Provo avere sta cosa. Allora, quindi noi abbiamo da un lato il vettore y0 y1 y con m e poi abbiamo qua il prodotto della mia matrice di Vandermond X0 X0 X0^ M. Simil cosa fino all’ultimo dato che è x n x n² x n^ m e questo va moltiplicare il mio vettore0 b1 bm. Ok? Io sto dicendo che la quantità al quadrato, questa è una differenza di vettori, quindi il primo vettore sarà uguale proprio a y0 - b0 - b0 eh - b0 - b1 * x0 - b2 * x0^ - bm * x0^ m. Ok? Fino all’ultimo e l’ultimo sarà y con n - esattamente la stessa cosa, quindi v0 - b1 * x n - b2 * x n - bm * x n^ m, giusto? Quindi ognuna di queste righe è laima componente del vettore y, il segno è rilevante - a* b. È corretto? Allora, provo a ripeterlo fino a qui. Ditemi se ci siete almeno su questa uguaglianza. Questa roba è materia vecchia, però se non vi torna la riguardiamo un attimo insieme. Vi torna. Ok? Adesso, visto che io vorrei legare i due momenti in cui visto le equazioni normali, cerco di ricondurre questa cosa che abbiamo già portato a casa con una parte nuova, ok? E alla fine la prima cosa che dico è che questa somma di scarti quadratici si può in realtà leggere come una norma euclide. al quadrato. Ok? Ci ricordiamo che se io ho un generico vettore W di componenti W1, anzi parliamo pure W0 WM, ok? Quindi un oggetto che sta in R di M + 1, ci ricordiamo tutti che la norma e l’idea di doppio al quadrato non è nient’altro che la somma qu che va da 0 a m di un w^, è corretto? Ok. Quindi questa somma di una parentesi di un oggetto con componente i al quadrato può essere vista come la componente i esima di un vettore di RM1, giusto? Quindi quello è il punto di partenza, capire, interpretare questa somma di quadrati. Ok? E quindi adesso quello che voglio vedere è che la componentesima del mio vettore, effettivamente se interpreto questa come la componentesima di un vettore, voglio capire chi è questo vettore. È una differenza di vettore. Il primo vettore è facile da capire chi è, è Y. Ok? Il secondo vettore ha esattamente la struttura tipica di un prodotto riga per colonna. E allora se io vado a definire A come la matrice di Vanderlond, effettivamente se voi andate a espandere questo prodotto, scusate questo prodotto meno questa somma, trovate questi oggetti, il vettore caratterizzato da queste componenti e l’esima componente di questo vettore è esattamente questo. Ok? Quindi Quindi possiamo dire che il la parte vecchia effettivamente può essere riletta con una minimizzazione di che cos’è questo? Il solito residuo al quadrato, giusto? La norma al quadrato del residuo. Bene, ma allora abbiamo imparato a calcolare la soluzione della minimizzazione di un problema che ci porta a cercare il vettore tale per cui viene minimizzata la norma al quadrato di un residuo, giusto? È esattamente la nuova definizione che abbiamo dato di di soluzione quando abbiamo i sistemi sovradeterminati a rango massimo, corretto? È la prima definizione nuova che mi è andato l’altra volta e per quello avevamo detto che cosa? Quindi questo problema qui avevamo scoperto che aveva una soluzione che avevamo battezzato eh forse con X star. Ok? Questa soluzione è esattamente il nostro vettore A e questo vettore A, quindi a suo tempo abbiamo trovato il sistema a trasposto per Ax² è uguale ad A trasposto per B. Questo per quello che ci siamo detti genericamente la scorsa volta dove Xstar era la soluzione del sistema sovradeterminato a rango pieno. Ok? Anche questo è un sistema sopradeterminato, giusto? La dimensione è quella di un sistema sovradeterminato e quindi che il nostro vettore A è soluzione della matrice A trasposto per A ed è uguale ad A trasposto per B. Ok? Quindi quante righe qua ho? O n + 1 righe, ok? O m + 1 colonne. E in generale, nel caso di un’approssimazione di minimi quadrati n è molto più grande di m, quindi vuol dire che più righe che colonne, quindi questo è esattamente un sistema sovradeterminato, è corretto? Ok? Dopodiché questo è quello che abbiamo imparato come soluzione del nostro sistema sopradeterminato quest’a non è la stessa di qua sopra, era la soluzione e la a del sistema visto la scorsa volta, ok? È semplicemente per ritrovare la struttura che avevamo imparato precedentemente. Quindi tra un secondo sparirà per un confusione che è applicata al nostro caso specifico e identica dove la matrice A in realtà è undermond, dove il vettore X star è il nostro vettore delle incognite, quello che realizza il minimo della norma del residuo, quindi l’abbiamo battezzato A e anziché B, giustamente qua, scusatemi, abbiamo Y. Ok? Quindi questa è la soluzione che ci viene data nel momento in cui io vado a rileggere il mio problema della ricerca dei polinomie minimi quadrati come la risoluzione nel senso di eh minimi quadrati di un sistema sovradeterminato. Ok? E quindi adesso per chiudere il cerchio cosa dobbiamo dimostrare? Che questa cosa qui coincide col nostro sistema di equazioni normali che abbiamo derivato quando abbiamo fatto la retta di regressione. Ok? Questo ci permetterebbe di chiudere effettivamente il cerchio. Corretto? Allora, chi è al trasposto per A? Questo è a trasposto è la matrice, quindi con tutti 1 sulla prima riga con x 0, x 1, x n. Sulla seconda riga, sull’ultima riga abbiamo x 0^ m, x1^ m, x * n^ m. Ok? E quindi quando vado a fare il prodotto di questi due oggetti, quindi questo è il nostro a trasporto per a che abbiamo riscritto, cosa succede? Che quando faccio, per esempio, la prima riga per la prima colonna trovo una somma di tutti uno. Ok? Quindi troviamo la famosa sommatoria di 1 * i che conta da 0 a n. Quando faccio la prima riga per la seconda colonna ho proprio la somma di tutti gli isconi, ok? Quindi trovo la somma degli sconogi per i che va da 0 ad n. Quando faccio la prima riga per l’ultima colonna cosa avrò? Avrò la somma delle potenze ennesime di tutti gli sconi, quindi la somma i che va da 0 ad n dei miei x con i^ m. E ad esempio prendiamo in posizione 1 per vedere se ci ritrovi Seconda riga per prima colonna ritrovo la somma di tutti i discori e così via. E quando farò l’ultima riga per l’ultima colonna effettivamente ho la somma del disconi elevato 2m. Ok? Quindi questa matrice ha trasposto per A, per fortuna, quella che ci viene eh diciamo identificata come la matrice del sistema delle equazioni normali via minimizzazione della norma del residuo è esattamente la matrice a cui siamo arrivati quando abbiamo fatto la retta di regressione e poi l’abbiamo generalizzata. Ok? Quindi esattamente la nostra matrice prima di che che avevamo prima di iniziare a parlare di sistemi sovradeterminati. Siamo d’accordo? E analogamente quando faccio trasposto per Y, eh, quindi uso questa matrice qua. Rimettiamoci qua. Se faccio a trasposto per Y, quindi ho tutti 1, ho x0 X con 1 x m o x0^ x con n, scusate, x0^ m x 1^ m x n^ m. Questo va a moltiplicare il mio y0 y1 y m. Ok? E quando faccio a trasposto per y, allora cosa ottengo? Prima riga per la il vettore degli y o la somma degli y con i. Seconda riga, per il vettore delle y ho i prodotti del tipo xi y con i. Se avessi esplicitato la terza riga, avrei la somma dei disco i al quadrato * y i fino all posizione in cui la somma degli con i^ m * y e anche questo è esattamente il termine noto che avevamo quando abbiamo ricavato per la prima volta le equazioni naturali, giusto? Ritorna. Quindi per fortuna questi due sistemi visti in due momenti diversi seguendo due strade completamente opposte effettivamente vengono a coincidere. Ok? Quindi la nostra il nostro polinomio minimi quadrati potete vedere o costruito normalmente attraverso appunto la minimizzazione del funzionale F con le derivate eccetera, oppure potete ricondurre la nostra minimizzazione della somma degli scarti quadratici come la minimizzazione del la norme qued quadrato di un residuo, quindi procedere secondo la strada soluzione mini quadrati di un sistema sureterminato e alla fine giustamente si arriva la stessa cosa. Ok? Ci siete? Non è banale, però se vi mettete di concamera e fate questi passaggi, alla fine si tratta proprio di vedere che si arriva alla stessa matrice prima e dopo il trattamento sovradeterminati. Ok? Va bene. Allora, se ci siete su questo, sperando che a caso sia ancora tutto stabile, eh passerà ai sistemi sottodeterminati su cui diciamo molto meno, quindi sarà più rapido. Ok. Cancello. Allora, quindi parliamo di sistemi sottodeterminati. Quindi questa volta abbiamo meno equazioni che incognite, quindi ci mancano delle informazioni, ok? Quindi ho sempre il mio sistema ax = y, dove a sempre la matrice rettangolare m * n, ma questa volta m è min in senso stretto di n. Ok? Quindi vuol dire che la mia matrice, anziché essere alta e magra è larga. Ok? Quindi questa è, per esempio, la nostra matrice A. A questo punto il vettore X continua a stare in R, quindi il vettore X invece ha una dimensionalità maggiore. Questo X che ha n colonne e il vettore y continua a stare in rensionalità più piccola. Ok? Quindi m Allora, eh esattamente come avevamo incominciato a fare per i sistemi sovradeterminati ad assumere che il rango della matrice A sia massimo e quindi supponiamo che il rango di A sia pari ad M. Ok? Allora, qual è il problema di avere una configurazione in cui ho più incognite che equazioni? Beh, sicuramente avevamo fatto l’esempio della retta a cui chiedo di passare per un punto, quindi non ho un numero sufficiente di condizioni per definirle in modo univoco, ok? In una retta, una retta, scusatemi. per un punto passano infinite rette. E allora in quel caso lì, per identificare nel fascio di rette che passano per un punto la retta che ci interessa, quello che avevamo detto che bisognava fare era andare a aggiungere una condizione. Ok? Quindi anche qui la soluzione di un sistema sottodeterminato verrà cercata come la soluzione classica, quindi che soddisfa x = y, ma con una condizione addizionale. Quindi si può dimostrare che aggiungere una condizione effettivamente sufficiente per dare l’unicità di x. E analogamente a quanto abbiamo visto, per i sistemi sopradeterminati a rango non massimo verrà cercata la soluzione nuovamente con norma eutidea minima. Ok? Quindi è una delle opzioni che andiamo a sfruttare, quindi diciamo che X Star è soluzione del nostro sistema sotto determinato a x = a y. Se quindi eh x asterisco utilizziamo la notazione dell’argamin che abbiamo appena utilizzato, quindi realizza la il minimo della eh Rn. Ok? Quindi realizza il minimo della funzione norma di x varia di x in r con l ed è tale che a* x star st è uguale all y. Ok? Quindi dire questo vuol dire cercare una soluzione in senso classico a cui andiamo ad aggiungere questo vincolo ulteriore per garantire l’unicità. Ok? Quindi, se volete, rispetto a prima, quando parlavamo di minimizzare la norma della soluzione, quella soluzione di cui ce cercavamo il minimo della norma minimizzava il residuo. Questa invece risolve il sistema in senso classico, ok? Quindi c’è una discretanza rispetto a cosa avevamo prima, ok? Quando siamo andati ad aggiungere il vincolo di avere un oggetto a norma minima. D’accordo? Allora, quello che si può dimostrare è che la nostra x è così definibile, coincide con la trasposta di A che moltiplica l’inversa di a * a trasposto per Y. Ok? Quindi adesso noi andremo a verificare che questa scelta soddisfa entrambe queste condizioni qua. Quindi e soluzione classica del mio sistema ax = y in più a prima. Ok, andiamo a verificarlo. Quindi verifichiamo due cose. La prima cosa che andiamo a verificare è che X star, così definit Quindi ci domandiamo se a* x asterisco effettivamente è uguale a y. Ok? Per far questo andiamo a sfruttare l’espressione di x asterisco. Quindi abbiamo a per a trasposto per A * A trasposto all -1 * y. Quindi ci domandiamo se si avverà questa uguaglianza, ma Questo è il nostro AX trascosto. Beh, vediamo immediatamente che è vera, perché questa è una matrice che comunque battezziamo, la battezziamo B o B per la verso inversa, quindi l’identità e quindi questo è chiaramente Y. Ok? Quindi la prima cosa che verifico è data questa definizione per X star che effettivamente è soluzione in senso classico, cioè a di x star st fa y. Ok? E adesso invece dobbiamo andare a verificare l’altra cosa, cioè che effettivamente realizza il minimo della norma di x. Quindi quello che dobbiamo andare a verificare è che la norma eidea di x asterisco così definita minimizza, prendiamola pure al quadrato, è minore o uguale della norma eupleidea di x qu. Questo per ogni x che sta in rale da essere soluzione classico del mio sistema, cioè tale che a* x risulti essere essere uguale a y. Quindi, se volete, uno che abbiamo verificato è questa parte, due che stiamo per verificare è questa parte qui. Ok? Quindi abbiamo verificato uno che x stare è soluzione in senso classico. Per verificare che x stare realizza il minimo della norma e più di x, andiamo a vedere che la norma equide di x al quadrato, se pure al quadrato è minore o uguale della norma equa al quadrato di un qualunque altro vettore x R con n che è soluzione in senso classico del nostro sistema. Ok? E per far questo abbiamo bisogno di un risultato per eliminare, quindi vi metto qua, ovvero il risultato preliminare dice la seguente cosa che x - asterisco - x asterisco trasposto per x asterisco fondamentalmente fa Adesso vediamo perché allora eh incomincio a espandere questo x asterisco con la sua definizione che abbiamo sopra. Quindi abbiamo a trasposto che moltiplica a * a trasposto -1 * y posso scriverlo mettendo insieme questi due oggetti. Ok? Vi ricordo che la trasposta di un prodotto o il trasposto di un prodotto è il prodotto dei trasposti in senso opposto. Ok? Quindi questi due oggetti qua io come posso andare a scriverli? Posso scriverli come a che moltiplica x - x asterisco il tutto trasposto. Giusto? Quindi questo incomincio a scriverlo come a x - x² trascosto e poi mi rimane a per a trascosto -1 * y, ma questa quantità qui che quindi è uguale ad a * x - a * x² è uguale Da quanto? Quant’è a * x?\nQuant’è a* x?\nY. Quindi questo è\n0 e quindi vuol dire che tutto questo oggetto è zero. Ok? Perché xara abbiamo dimostrato che soddisfa la soluzione del mio problema in senso classico x. Stiamo supponendo che lo facci Ok, quindi questa quantità è nulla. Ok? E allora questo preliminare ci serve per andare a dimostrare questo. Come facciamo? Allora, parto dalla norma di x quadrato che vado a scrivere tramite un’uguaglianza aggiungendo e togliendo la stessa quantità e questa quantità ovviamente è x a stisco. Ok? Dopodiché questo posso andare a scriverlo. Potete vederlo in vari modi, o usando Pitagoras, se li leggete come vettori, oppure eh interpretando, per esempio, questo come un vettore A, questo come un vettore B. E allora questa è Ea + B trasposto per a + b definizione di norme equide a quadrato. Ok? E questo prodotto scalare vi dà a trasporto per A, che è la norma di questo oggetto al quadrato, più pi trasposto per B, che è la norma di questo oggetto al quadrato e poi ci sono i due doppi prodotti A trasposto per B o B trasposto per A che è uguale quindi a due volte un oggetto di di tipo questo trasposto per questo. Ok? Quindi questa cosa qua Possiamo vederla come la norma di x qu la norma di x - x star qu più due volte x - x asterisco trasposto per x asterisco. Ok? Quindi vedete cosa vi torna più comodo. O li leggete come vettore, applicate banalmente Pitagoro, o espandete la definizione di norma, una somma di due oggetti. Quindi avete a + b trasposto per A + B. A trasposto per A dà eh A e questo oggetto. Poi avete A trasposto per B che è uno di questi due signori, B trasposto per A che è l’altro di questi due signori, B trasposto per B che è questa norma qui. Ok? Dopodiché questo oggetto qui per per il nostro preliminare è uguale a 0 Ok? Quindi cosa abbiamo? Abbiamo che la norma di x^ coincide con la norma di x asterisco al quadrato più la norma di x - x asterisco quadrato. Allora, questa è sempre una quantità maggiore o uguale di 0 e quindi cosa possiamo dire? Che la nostra norma di x quadrato è sempre maggiore o uguale della norma di x asterisco al quadrato. Ok. E quindi abbiamo dimostrato anche il punto due. Ok. Bene. Dopodiché, esattamente come succedeva nel caso dei sistemi sovradeterminati, questo computo qua si può dimostrare che numericamente è instabile. Ok? E quindi faremo la strada alternativa di andare a calcolare X asterisco usando la fattorizzazione QR. Ok? Quindi teniamo la formula esplicita, qua sotto è la dimostrazione e adesso vediamo quello che invece è l’approccio grafico per andare a calcolare X star tramite fattorizzazione QR. Quindi nella pratica il nostro X star si calcola usando la fattorizzazione QR. In realtà si usa la fattorizzazione ridotta QR. Attenzione della matrice a trasposto e questo ci riporta Il terra è conosciuto è perché la matrice A è, diciamo, rettangolare nel senso della lunghezza. Facendo la matrice, la fattorizzazione, scusatemi, QR, QR ridotta della matrice trasposta e ritorniamo a parlare della fattorizzazione QR che è una matrice tipica di un sistema sopradeterminato, quindi ritorniamo a qualcosa che già abbiamo gestito, ok? E quindi noi supponiamo di avere a nostra disposizione questa fattorizzazione, quindi supponiamo di poter scrivere a trascosto come utilde rtille. Ok? E allora niente, andiamo a espandere chix asterisco e vediamo come si può utilizzare questa fattorizzazione. Ok? Allora, a trasporto viene rimpiazzata dalla sua fattorizzazione ridotta, quindi è utile per rtind. Poi eh a vuol dire che andiamo a fare il trasposto di questi oggetti qua. Quindi abbiamo utilde ril trasposto. Quindi vi rimetto l’etichetta qua sotto. Questo è trasposto. Questo di conseguenza è a. Poi ha trasposto e di nuovo e questo è il nostro ha trascosto tutto. Questo è all -1 e poi abbiamo Y. Ok? Conviene ovviamente andare a espandere questo trasposto per vedere se possiamo in qualche modo sfruttare l’ortogonalità di cutile. Quindi questo oggetto al momento è utilde per rt tilde che moltiplica r tilde trasposto per tilde trasposto per tilde per rchilde. ^ -1 * y. Ma intanto questo oggetto qui ci dà l’identità. Inizio a togliere due protagonisti. Quindi abbiamo utilde per r tilde che moltiplica rt tilde trascosto per rt tilde^ -1 * y. Ok? Quindi ho semplicemente espanso questo operatore di trasposizione e sfruttato l’ortogonalità della matrice Qilde. E a questo punto vado ancora a sfruttare questo inverso, ricordandoci che così come il trasposto di un prodotto è il prodotto dei trasposti in ordine al costo, anche l’inverso di un prodotto è l’inverso è il prodotto degli inversi in ordine inverso. Ok? Quindi questo oggetto qui a che è uguale? È uguale a utilde per r tilde che rimangono tali e quali. Poi abbiamo r tilde^ -1 così che questo ci dà l’identità. Abbiamo rt^ - t abbiamo y, ok? Così cheé alla fine il nostro la nostra soluzione x asterisco del sistema sottodeterminato, si può nella pratica andare a calcolare come prodotto qutilde per r til all - t per y Ok? E questo è il modo con cui viene calcolata la soluzione. Siè perso mettere l’annotazione\ndeve fare il l’inverso del trasposto.\nCioè vuol dire rt^ -1.\nVuol dire rt^ -1. Certo.\nBeh, se vi tu poi lo tenete spacchettato, insomma.\nOk.\nFaccio l’inverso del trascosto. Se potete battezzare il trasposto in un qualche modo e poi ci applicate inverso. Ok. Fine dei sistemi indeterminati. Alleluia. Mi sento di dire l’unica cosa che l’anno scorso avevo fatto e poi in realtà mi ero persa in cioè c’eravamo persi in mille tecnicismi per cui quest’anno ho deciso di lasciarvelo eventualmente da guardare sul libro e capire come volendo uno, non avendo matrava costruisce la fattorizzazione QR di una matrice. Ok? È giusto per dire veramente il minimo essenziale, poi ripeto Sto conto ci sono i conti fatti tutti per bene, tutti espansi, quindi direi che non stiamo a perdere mezz’ora per guardare dei tecnicismi, però abbiamo già detto che la fattorizzazione QR si ottiene e di conseguenza per quella ridotta si ottiene applicando l’algoritmo di autonormalizzazione di grmit alle colonne di A. Ok? Quindi fondamentalmente battezzando sono dei vettori contiene con i coefficienti di prima. Battezzando con A1 eh questa è una M * N, quindi A n colonne a n le colonne della matrice a attraverso gramit si ottiene una base porta normale di vettori e2 e nmostrato sul libro la matrice Q non sarà nient’altro che la matrice che raccoglie proprio questi vettori ortonormali e 1 e nelle sue colonne. Ok? mentre la matrice R eh andrà a raccogliere, insomma, le entrate saranno del tipo m prodotto E1 contro A1, E1 contro A2, quindi sarà la proiezione E1 contro A con N e così via, che è la matrice pseudo triangolare superiore che raccoglie questi queste proiezioni. Ok? Comunque ripeto, sul libro avete proprio tutti gli operatori definiti per bene di proiezione, lezzazioni. Per chi è interessato è un buon esercizio per ripassare il gradmit. Ok, non stiamo a farlo. Eh bene, direi che questo chiude per quel che dovrebbe riguardarci definitivamente i sistemi, quindi non diciamo sembravano già chiusi i fatti gli iterativi, poi sono ritornati sono rientrati dalla finestra posta approssimazione di date e funzioni. Direi che li utilizzeremo soltanto più i quando serviranno, ma non parleremo, se non mi sbaglio, più di metodi per risolvere i sistemi, ok? E quindi quello che facciamo adesso è completamente andare a cambiare argomento, cioè imparare ad approssimare degli oggetti completamente diversi, quindi parleremo di approssimazione di derivate, super corto e approssimazione di integrali. Entrambi gli argomenti sono legati all’interpolazione, quindi se volete sono in continuità anche loro col concetto di interpolazione. Ecco. Quindi portano le derivate che queste sicuramente ci stanno nel tempo che abbiamo e poi se tempo iniziamo gli integrali. Allora, in realtà abbiamo già parlato di in modo molto blando di approssimazione di derivate. Se vi ricordate quando l’altra volta abbiamo citato le spline, ok? Queste funzioni interpolanti super regolari dicendo che un po’ con un abuso di forzando un po’ la mano uno può utilizzare la derivata della spl per approssimare la derivata della funzione. Vi ricordate questo discorso? Ok? E quindi in quel contesto lì parlavamo di approssimazione di derivata come approssimazione di una funzione che rappresenta la derivata. Ok? Quindi approssimo f’, quindi dato una funzione f1 via b, avevamo, diciamo, pensato a come approssimare f’ come funzione. Ok? In realtà adesso cambiamo un attimino lo scenario e ci occupiamo di imare non f’ come funzione, ma f’ come valore assunto dalla derivata prima in un certo punto x asterisco che appartiene al dominio di definizione. Ok? Quindi faremo ci occuperemo di schemi per approssimare questi che sono banalmente dei numeri reali, ok? Quindi sono schemi per approssimare il valore puntuale della derivata prima in un punto del dominio. Ok? Quindi, ricapitolando, abbiamo la nostra funzione f definita sono un intervallo b della retta reale a valori reali che ha una certa regolarità e una funzione C1 e siamo alla ricerca di un’approssimazione per la derivata prima in un qualche punto di AB. Ok, va bene. Poi magari commenteremo avendo questi, come faccio a costruirmi l’approssimazione di F prima. Ma prima di inoltrarci nel mondo delle approssimazioni, volevo sondare un attimo m quanto avete chiaro il concetto di derivata, cioè perché il concetto di derivata potrebbe essere utile fisicamente. Quindi le mettiamoci usciamo dalla veste del matematico e mettiamoci il cappellino da ingegnere perché\nquello è un un punto di vista geometrico. Adesso con il passare dei mesi, degli anni acquisirete sempre più un senso pragmatico delle cose. Quindi il concetto di derivata è associato in indipendentemente dalla simulazione numerica al concetto di velocità più in generale\ncambiamento\nvariazione. Ok? E in tante applicazioni è molto più importante monitorare la variazione della quantità che sto modellando piuttosto che la quantità che sto modellando. Faccio un esempio. Se penso a una membrana che si deforma, ok? Dietro alla deformazione di una membrana c’è un’equazione che lungi da questo corso, comunque si chiama equazione dell’elasticità. Ok? Questo suona credibile. l’equazione dell’elasticità ha come incognita lo spostamento, ok? Quindi lei è la nostra funzione f. Quantità legate allo spostamento in realtà alle derivate dello spostamento sono per esempio le deformazioni, gli sforzi, ok? Per le applicazioni da un punto di vista per esempio dell’ingegneria civile, della statica, dell’analisi delle strutture, sicuramente gli sforzi piuttosto che gli stress sono molto più importanti da monitorare piuttosto che alla variazione rispetto alla posizione di equilibrio. Ok? Da un punto di vista fluidodinamico, se io, per esempio, attivo il modello per monitorare eh facciamo un esempio più semplice, la diffusione del solito inquinante nel fiume della doccia di inchiostro nella bacinella, quindi se la mia funzione f misura la concentrazione dell’inchiostro dell’inquinante nel fiume piuttosto che nella bacinella, quella è F. Se passo alla derivata sto pensando al flusso di questo inquinante o di questo inchiostro attraverso una qualche per esempio porzione del dominio e quindi ad esempio i fini ambientali è molto più interessante sapere che ne so, il flusso di schifenza, cioè di inquinante che va a deteriorare una certa zona che devo salvaguardare piuttosto che sapere esattamente che concentrazione c’è. Ok? Quindi tutto questo per dire che a volte, anzi molto spesso nelle applicazioni può essere più interessante capire quanto vale la derivata piuttosto che la funzione stessa. Da qui la necessità di andare ad approssimarla e a volte è proprio per esempio l’esempio del fiume parla chiaro, anziché monitorare la var il flusso della mia Il mio inquinante su tutto il percorso del fiume può essere più interessante monitorarlo in certi punti dove magari ho le soldine che misurano, dove magari ci sono che ne so gli animali da proteggere, eccetera eccetera. Ok? Quindi questo per giustificare perché c’è interesse per le derivate. Dopodiché, come sempre, andiamo a partiamo da quello che l’analisi ci offre per il calcolo della derivata, come viene calcolata dall’analisi la derivata di una funzione in un punto\ncome famoso limite di un rapporto incrementale, ok? Quindi, per esempio, f’ non è l’unico modo per cui posso andare a scrivere f’ di xa, ma posso andare a scriverlo come il limite per h che tende a 0 dal famoso rapporto incrementale una possibilità e scriverlo come fx + h - fx / h. Ok? Questo è il famoso rapporto incrementale che cita il vostro collega e quindi io faccio tendere h0 e questo mi trova il valore di f’ x. Vi ricordo che se questa è la nostra f e questa è la nostra x asterisco, f’ in x star è il coefficiente angolare della retta tangente ad f nel punto di coordinate x star f x, giusto? Quindi è un numero, ok? E quindi Se guardo quella definizione lì, io cosa sto facendo? Sto chiedendo informazioni al punto x st + h che sta dopo x asteristo, ok? E prendere il rapporto incrementale vuol dire fondamentalmente rimpiazzare la tangente con questa retta. Ok? Quindi io dovrei surrogare la pendenza della tangente con la pendenza di questa retta. Quindi in questo caso non va proprio con bene bene perché addirittura ho un coefficiente positivo contro il coefficiente negativo, ma c’è un limite. E quindi il limite cosa fa? Fa scorrere questo punto lungo la curva. Ok? E se voi fate scorrere questa questa retta mano avvicinando questo punto qua, vedete che la vostra retta secante effettivamente per h che va a 0 tende a sovrapporsi alla tangente. Ok? Quindi questa è l’interpretazione grafica della derivata. D’accordo? Bene. Ora con riferimento a questa definizione analitica che è sicuramente esatta, c’è qualcosa che ci turba, cioè che al nostro calcolatore non va tanto bene o siamo tranquilli e usiamo questa. Esattamente c’è il limite che non va bene. Tutto ciò che risuona con l’infinito abbiamo capito che non è il concetto digeribile da un calcolatore e il limite ovviamente è un asintotico e quindi non va bene. Ok? Allora, nell’andare a proporre un possibile schema per approssimare f’ in X star, cosa è stato fatto? Beh, semplicemente si è deciso di rimuovere questo limite, ok? E quindi di andare ad approssimare le prime di X asterisco con un oggetto che usando le notazioni della letteratura viene indicato con delta + fx asterisco. Delta + f è un unico simbolo. Ok, adesso vediamo questo più cosa vuol dire. E questo delta + fx asterisco semplicemente coincide col rapporto incrementale scomodato nella definizione esatta, quindi è fx asterisco + h - f(x) asterisco diviso H. Ok.\nMa H chi è?\nEh,\nh chi è?\nH è questa distanza qua,\nè decisa in maniera arbitraria.\nAllora, in questo caso qui va a zero. Per quello che abbiamo visto l’andamento della retta, questo h dovrà essere ovviamente piccolo, ok? Perché altrimenti effettivamente questo è un caso disgraziato in cui ho una segante che è una pendenza contro una tangente che ne un’altra. Ok? Quindi h, diciamo la solita frase che poi nella pratica non serve a niente, deva essere preso opportunamente piccolo. Ok? Poi uno se la gioca ogni volta a seconda dell’approssimazione, cerca di sopravvivere prendendo un’aria abbia senso. Allora, questo oggetto è una prima modalità per approssimare f’ di X star e si chiama schema alle differenze finite in avanti. Perché mai si chiamerà differenza finita in avanti? La qualcosa giustifica questo più perché per approssimare il valore di f il segnato io sto ricercando informazioni in un punto che sta davanti a x star, ok? Cioè x star + h. Ok? Chiaramente ci sarà anche quella all’indietro, sarà la seconda proposta di approssimazione che vi farò, ok? Andiamo, messo lì il, diciamo, la proposta di approssimazione, come sempre, cercare di capire se è approssimata, quanto è approssimata questa questo oggetto, questa prima questo primo surrogato di fara. E per far questo, quindi, quello che vogliamo andare a calcolare, per intenderci, è il solito errore tra f’ di x st e il nostro delta + fx st. Ok? E come sempre, cioè come sempre, e per far questo utilizziamo uno strumento classico dell’analisi che è l’espressione di Taylor. Ok? Quindi usiamo Taylor, lo tronchiamo a second Questo quindi ci porta a chiedere che la nostra funzione f sia una funzione C2 di AB. Ok? Allora, scriviamo valutandolo in x st + h, centrandolo in x asterisco e eh trandolo al secondo ordine. Ok? Quindi abbiamo che f + a è ugx + h vol star + h2 su 2 per la derivata seconda di f calcolato in un qualche punto alfa dove alfa se ne sta tra x e x + h. Ok? Quindi cosa basta fare per andare a stimare questa quantità? Ve riconosco dei tratti dei pezzi costituenti delta + f. Ok? Quindi inizio a dividere tutto per h. Ok? Quindi questo si divide per h, questo si divide per h, questo sparisce, questo diventa un h. E a questo punto cosa è sufficiente fare? Beh, è sufficiente muovere questo oggetto a destra. e muovere questo oggetto a sinistra.\nOk? Quindi abbiamo che cosa? Abbiamo che f’ di x star a f’ di x andiamo a sottrarre f star + h / h. Poi ci rimane un + fx sta/ h. E questo è uguale a - h/2^ derivata seconda di f. Ok, ci siete? Quindi sto calcolando l’errore. Ho deciso di appoggiarmi a Taylor che centro in x asterisco, valido in x asterisco + h tronco al secondo ordine. Quindi poi ho diviso tutto per h e sto spostando un po’ di oggetti a destra e a sinistra perché a questo punto questo termine qui se mettete se raccogliete un meno 1 su h che è esattamente la vostra differenza finita in avanti, giusto? Se raccogliete un 1 su h vuol dire che faccio una frazione unica e qua c’era un più, quindi vuol dire che metto un meno. Ok? Sguardi super persi. Dove siete persi? Peppa rossa qua davanti. Mattia\nè approssimato\nda delta + fx che è uguale a quell’oggetto.\nUn delta p+ o delta+?\nEh no, è un delta p+ta destra.\nOk,\nl’ho detto. Eh, questo oggetto qua è il suo delta più, vero o falso? Ok.\nNo, no, no, no. È una notazione infelice, ma è molto classica. È come si chiamasse G, ok? Delta + F. Qua ci sono altre domande? Ci siete? Non è successo nulla di drammatico, semplicemente abbiamo fatto Taylor, abbiam diviso, abbiam raccolto, messo in forno a 180° e viene fuori sta cosa qua. Ci siete? Devo ripetere? No, va bene. Bene. Quindi questo oggetto qui, se la lavagna collabora, è delta + f un unico simbolo di x asterisco, ok? E quindi abbiamo che il nostro errore è uguale a - h/2 per la derivata seconda di f calcolato in questo punto è alfa. Ok? Quindi faccio due azioni, una di natura pratica. Questo altro è il solito punto che non si sa bene chi sia. Quindi poi come sempre a cosa servirà questa formula? Per andare a calcolare il massimo dell’errore, ok? Dove h/2 perderà il segno, quindi rimarrà un h/2 e prenderò il massimo della derivata seconda. Quindi da un punto di vista pratico, poi questo oggetto di destra diventa utile rendendo questo punto identificabile. Visto che non so chi è, faccio che prendere il massimo di questi oggetti e già successa questa cosa quando parlavamo di interpolazione, forse. Ok? La seconda osservazione che faccio è che per fortuna questo errore vedo che per h che va a 0, cioè man mano che il mio punto x star + h si avvicina a x star, dove va? A zero. Quindi stiamo dicendo e l’abbiamo visto graficamente che effettivamente la mia secante per alta che va a zero va a sovrapporsi con la tangente, ok? E ci va con una certa velocità. Questa velocità è come sempre data dalla potenza di la potenza di se h che va 0, qualcuno va a zero, quindi con che con una velocità che è data dalla potenza di ho sentito forse neiandri h ok che potenza ha ho. Quindi si dice che questo è uno schema che converge a zero linearmente per h che va a 0. Quindi stiamo dicendo, vabbè, è uno schema che quantomeno tende, preso un arco opportunamente piccolo, facendolo tendere a zero, va al valore esatto F’ di SAR. Certo, non è dei più rapidi, però intanto per arco che opportunamente piccolo ho un’accuratezza desiderata, mettiamola così. Ok? Bene, questo è il primo schema. Dopodiché, chiaramente uno può dirmi “Vabbè, ma perché prendi il punto in avanti e non prendi il punto indietro?” Giusto, effettivamente potevo andare a definirvi la derivata esatta di f’ in x star anziché in limite attraverso il limite che c’è sopra come limite per h che va a 0 di fx asterisco - f asterisco - h / hita cosa elevato alla potenza di h.\nOk? Eh, quindi la cosa ho detto due cose, una è della diciamo modalità pragmatica. Cosa me ne faccio di questo oggetto? Questo è a costo. Ok? E l’altro è che questo è l’errore di approssimazione della derivata, quindi stiamo dicendo che questa quantità se ne va 0 per h che va 0, ok? E lo fa come sempre con una certa velocità. Questa velocità è dettata da questo h che va 0, da questo h che va a 0 e qui abbiamo una potenza 1, quindi diciamo che è uno schema curato al primo ordine per altro che va a zero dove al primo ordine che convergi linearmente a te. Ok, prego. Altre domande su questa parte qui? Non siate timidi, eh, tanto io non mi ricordo che vi fa le domande, quindi qualunque cosa diciate non verrà usata contro di voi. Ritorna. Per me questa è una parte super facile, quindi di solito la faccio abbastanza velocemente, però come ho colto prima a voi sembrano uguali i sistemi, i metodi itativi con l’approssimazione di dati e funzioni, per cui vuol dire che io non ho assolutamente il poso di questa classe la cosa. Quindi se Ti devi libermi di chiedermi qualunque cosa a sto punto. Bene, se siete lì, se ci siete fino al lì sotto, abbiamo detto che alternativamente potevamo definire la derivata in questo modo, giusto? Quindi, fondamentalmente vuol dire che saremmo andati a prendere un punto x - h più piccolo di x asterisco, saremmo andati a considerare la secante che passa per questi due punti, ok? Quantomeno abbiamo il coefficiente angolare positivo come per la tangente e nuovamente per h che va a 0 punto si avvicina a questo e quindi la mia approssimazione diventa coincidente con la tangente. Ok? Quindi è un’altra opzione, giusto? Perché considerare x st + h da buon una buona persona che va controtendenza uno può prendere x- H. E allora a questo punto questa è di nuovo la definizione esatta che ci risulta in digest esattamente come quella prima per la presenza del limite. Quindi definisco un secondo possibile schema per approssimare f’ di xar. Come mai si chiamerà secondo voi? Delta - f di xar e sarà uno schema di differenze finite al indietro se premere in avanti. Ok? Quindi da questo segue il secondo schema di approssimazione. che mi porta a definire un oggetto che in modo compatto chiamiamo delta - f x asterisco e questo coincide col rapporto incrementale che abbiamo scritto qua sopra e quindi fx st - fx -/ h schema alle differenze finite all’indietro domanda. Vi aspettate che sia meglio di questo schema, cioè che lo schema le differenze finite all’indietro sia meglio dello schema le differenze finite in avanti o no?\nNon ho capito. Sappiamo che sappiamo che\nEsatto. Cioè, ma anche graficamente non vi ma che in certi casi in particolari può darsi che ci sia differenza, ok? Quindi bene o male sembra brutto tanto uguale e infatti lo facciamo con un passaggio, si può verificare di nuovo con di nuovo supponendo regolarità C2 che è esattamente uno schema del primo ordine anche questo. Ok? Fino a quel punto uno vale l’altro. Quindi calcoliamo f’ x star - delta - f. Questa volta pur centrando lo sviluppo di telo sempre in x asterisco e ancora al secondo ordine, andiamo a valutarlo in x - h. Quindi l’unica cosa a cui stare attenti sono i segni che si alternano, ok? Quindi abbiamo fx - h vol’ x² + h2 per la derivata seconda di falcolato in un certo beta dove questa volta beta vive tra x² - h. Ok? Quindi rispetto a prima c’è un meno che balla e la valutazione dove viene fatta la valutazione. E allora procedo esattamente come prima, divido per h, ok? E questa volta conviene portare chi questi due oggetti a sinistra e il resto lascio tutto dov’è. Ok? Quindi abbiamo f’ di x asterisco, poi abbiamo lui - fx asterisco/ fx asterisco - h / h e questo è uguale a h/2 per la derivata. seconda di essere qualitate in beta. Ok? Bene. Nuovamente accorpiamo questi due oggetti, quindi facendo una frazione unica, 1/ h sparisce e qua rimane un e questo oggetto qui è esattamente il nostro delta - fx st. Ok? Quindi l’errore è esattamente identico tranne che per un cambio di segno e quindi anche questo è uno schema. Qua c’è un uno del primoordine per h che va a 0. Ok? Quindi, visto che noi non ci accontentiamo mai e sono d’accordo su questo approccio alla vita, eh Vi domando, abbiamo due schemi che sono, insomma, due schemi del primo ordine, quindi due cose vagamente poco utili sul tavolo. Ok? C’è un modo per avere uno schema del secondo ordine, cioè vale il solito detto che noi non abbiamo tempo da aspettare, ok? Quindi se avesse uno schema del secondo ordine questo convergerebbe molto più velocemente. Secondo voi, guardando là, qui la parte geometrica sempre un po’ aiuta quando siamo in difficoltà? La media,\npiù che la media uso il non è una media esattamente, ma quale retta considero? Viene viene in mente un’altra retta per inciso. Esercizio tanto utile. Questa retta qua chi è? Usando il gergo che avevo imparato in due argomenti precedenti, è la retta che\ninterpola F in queste due coppie di dati, giusto? Quindi vi inviterei a fare il seguente esercizio che non fa male. Prendete le due coppie di punti X star f x star, poi dopo ritorna alla domanda x star + h fx star + h. Ok? Avete due copie, due dati, due copri di dati. Costruite la retta che interpola queste due copie di dati che, guarda caso è proprio questa retta qua. Quindi costruite P 1 F che interpola questi due dati e poi fatene la derivata e scoprirete che quello che ottenete è esattamente il vostro delta + fx stara. Ok? Quindi, fatelo esplicitamente, vuol dire che dovete costruire i polinomi caratteristici di la granja. Quando fate riferimento a questo nodo, eh dovete costruire il polinomio associato a lui e quindi insomma dovete tenere propriamente in considerazione verrà moltiplicato per questo valore più questo valore per il polinomio caratteristico associato a x star st h fate proprio i conti a manina due punti okruite questo, lo derivate e troverete esattamente la stessa cosa. È la traduzione grafica di quello che abbiamo fatto. Abbiamo preso la retta che passa per queste due coppie di punti reinterpola, ok? E la sua pendenza che è la derivata del nostro delta + f. Analogamente non sto a dirlo se prendessi x - h f x² - h f x² - h x² f x ok stessa cosa, è un esercizio interessante che vi fa capire immediatamente se avete capito l’interpolazione di la grange, per quello dico è interessante. Quindi siamo alla ricerca di qualcosa di più furbo, cioè qualcosa che converga prima. Quindi guardando la retta, anziché guardando, scusatemi il grafico, anziché farla media, che non è che mi faccio tanto felice come risposta, che retta vi verrebbe da prendere in considerazione? Eh, la digazione,\nno, molto più facile. Guardate sti punti, li avete accoppiati in un certo modo. Avete preso sempre due coppie di punti consecutivi successivi, va bene? Uguale. Quindi perché non andare a prendere baretta\nverso la casa. Stai che passa in basso\nmi debide le coordinate perché forse è giusto.\nSì, il primo quello xerisco - h la altro x + h poi la retta che fa lì\nm gli parafruso perché non è del tutto giusta. Prendo la retta che interpola le coppie x star - h f x - h x + h f star + h. Ok? Volevo dire più o meno questo. No, ma non importa, faccio finta di Sì, certo, ovvio. Ok. Bene. Quindi prendo questa retta qua. Ok. Giusto. Ah. Ah. Ok. Ok.\nOk. Pazienza. prendo questa retta e come vedete questa retta è già molto più simile alla mia tangente, giusto? Quindi quella associata delta più andava esattamente da un’altra parte, quella associata a delta meno ha ancora una pendenza molto diversa. La tangente che è questa e questa che passa per queste due coppie di punti effettivamente è meglio, sembra meglio, ma adesso verifichiamo che è meglio di suo. Quindi andiamo a definire il terzo e ultimo schema per approssimare la nostra derivata prima così che 5 minuti visto il disagio tecnico che abbiamo avuto inizialmente. Quindi vuol dire questa volta che se vogliamo sempre fa riferimento all’analisi andremo a considerare il limite per h che tende a 0 di fx + h - fx - h. Questa volta diviso\n2\n2h Ok? Quindi il rapporto incrementale, ricordatevi che deve sempre far parlare quantità in ordinate e quantità in ascissa corrispondenti, quindi la copertura in x è di 2h. H. Buttiamo via al limite e così diamo luogo al terzo schema per approssimare la vostra f’ di Xstar, che questa volta indichiamo senza meno e senza più perché sto centrando l’informazione, quindi lo indichiamo soltanto con delta fx star e questo è uguale a f di x² + h - f x - h / 2 e questo si chiama differenza finita centrata. E adesso l’ultima cosa che facciamo è vedere effettivamente uno schema di ordine 2 rispetto ad h. Quindi andiamo a calcolare questa cosa qua. Quindi la differenza tra f’ di x car delta f di x star. Come sempre non c’è nulla di gratuito, ok? E quindi portare a casa uno schema che converge più velocemente, quindi il cui errore converge più velocemente a zero, ci porterà ad aumentare ai noi le richieste di regolarità su F, che quindi non basterà più che sia C2, ma dovremmo chiedere C3. Questo è il pegno che dobbiamo pagare. E allora per trovare l’espressione dell’errore, quindi questa quantità qua, procediamo in parallelo andando a espandere i Taylor, scusate, andando a espandere attraverso Taylor F, la centriamo sempre in x asterisco, la tronchiamo al terzo ordine e una volta la valutiamo in x segnato + h, l’altra volta la valutiamo in x segnato - h. Ok? Quindi abbiamo f x + h che è uguale a f x st + h vol f’ x st + h2 su 2 per la derivata seconda di f calcolata ancora in x aster e poi abbiamo h su 6 per la derivata terza di f calcolato in un qualche punto sigma che se ne sta tra il segnato x star scusate e xar. Ok? Faccio lo stesso esercizio valutando in x st - h, quindi abbiamo fx star - h vol + h2 * f - h3 su per la derivata terza di f calcolata in un qualche punto gamma che se ne sta tra x asterisco - h e x asterisco Ok, quindi l’espansione di failor, diciamo, all’ordine successivo. Ok, procediamo facendo che cosa? Dobbiamo valutare la differenza tra f’ e quel nuovo oggetto lì. Quindi, come combiniamo questi due sviluppi? Andiamo a o rismiamo e sottraiamolo. Dobbiamo trasparire una deriva, la derivata la prima lo dobbiamo tenere perché dobbiamo valutare sta cosa, no? Quindi chi è che ci dà noi la derivata seconda, giusto? Che ci serve la derivata seconda? A niente, quindi le sottraiamo ovviamente. Ok? Quindi sottraiamo le due equazioni. Quindi abbiamo f x² + h - fx - H. Ok? Tutti tutte le gli oggetti, diciamo, tutte le derivate di ordine fare vanno via, quindi la derivata zeresima che è la valutazione di f. Ok? Quindi andando a sottrarre questi due oggetti rimane un h - h che ci dà due volte h * f’ x². Questi e questi si semplificano e qua rimane un + h su che moltiplica la derivata terza di falcolata in sigma più la derivata terza di falcolata in gamma. Ok? Ritorna. Quindi ho sottratto membro a membro. Ok? Adesso, anziché dividere tutto per h come facevamo prima, divido per 2 sono sempre alla ricerca del denominatore di delta f. Quindi questo è diviso 2H, questo è diviso 2H, questo sparisce, questo diventa un quadrato e qua rimane un 2. Ok? E a questo punto cosa faccio? Sposto questi due oggetti a destra e questo oggetto a sinistra. Quindi riscrivo i vari pezzi. Ho f’ di x asterisco - fx asterisco + h / 2h + f asterisco - h / 2 e questo è uguale a - H2 / 12 per la derivata terza di f calcolata in sigma più la derivata terza calcolata in gamma. Quindi ho, diciamo, aumentato espanso un ordine più ad un ordine più alto le due espansioni di tela che avevamo usato prima, le ho combinate con una sottrazione per eliminare le cose che non compaiono in quello che devo valutare. Ho diviso anziché per h* 2h perché è il nuovo denominatore che abbiamo e sposto le cose in modo da avere f’ x - delta f. Ok? Quindi siamo qua. Come sempre metto questi due oggetti in un’unica frazione, quindi più divento un men e i 2h dei 2h me ne rimane 1. E questo è esattamente il mio delta fx star sale Ok? E quindi abbiamo un errore che grazie a Dio se ne va a zero per h che va a 0, ma questa volta lo fa con un esponente che da 1 diventa 2. Ok? Quindi la differenza finita centrata è uno schema di ordine 2 per approssimare la derivata prima, giusto? Quindi mi risulta, ditemi se risulta anche a voi che in questo momento voi avete tre schemi per approssimare la derivata prima. Avete delta + fx, delta - f e delta f. Ok? Giusto? Avete uno schema differenze finite in avanti, uno l’indietro e uno centrato. Quindi ammesso di avere tutta la regolarità che vi serve, quale scegliete? Questo.\nQuello centrato, giusto? Perché è un ordine peggiore. Cosa potrebbe evitarmi e qua chiudo di usare di fare questa scelta? Due cose fondamentalmente la regolarità, quindi occhio che queste due vanno bene se C2. Questa vi chiede un C3 e magari la regolarità C3 non ce l’ho. E l’altra cosa un pochino più difficile come\nNo, è una cosa più anche questa più da da praticoni, cioè supponete di avere di voler calcolare la derivata di f una collezione di punti. Ok? Quindi all’interno va bene tutto, ma se io devo calcolare la derivata prima in a cosa uso? Ho libertà di scelta. No,\nposso usare soltanto il delta più, giusto? Perché indietro non ho nessun altro e quindi qua non posso calcolare né delta meno né delta più, scusate, né delta e viceversa Quando sono qua in B devo necessariamente calcolare, utilizzare del - ok? Quindi ripeto, al momento e sono anche le uniche che vediamo, avete queste tre formule per approssimare la derivata prima di una funzione in un punto. Due schemi sono del primo ordine a fronte di una regolarità c2, uno schema di ordine 2 a fronte di una regolarità C3. Quindi l’idea è uso la se l’ultimo schema se posso, dove se posso vuol dire se ho tutta la regolarità che mi serve e più subentra anche, diciamo, una richiesta di o le informazioni che mi servono per costruire lo schema. Quindi, vuol dire che se io, per esempio, sono in un estremo di un intervallo e quindi la mia funzione prima non è definita e dopo non è definita, agli estremi ho un vincolo del preciso sullo schema che posso andare a utilizzare. Ok? In avanti sono in A, arrivo subito all’indietro ci sono in B. Vi dica tutto regolarità per scrivare l’errore, però\nSì, non per scriverla. Per scriverla serve soltanto che sia C1, direi, cioè che esista la deriv quello che stiamo approssimando nel punto\nSì, però poi alla fine si si fa, diciamo, caso anche alla regolarità. Comunque sì, poi insomma la disperazione guardo che sia almeno C1"},"2--source-materials/meccanica-Lez6_trascrizione":{"slug":"2--source-materials/meccanica-Lez6_trascrizione","filePath":"2- source materials/meccanica-Lez6_trascrizione.md","title":"meccanica-Lez6_trascrizione","links":["3--tag/trascrizione","3--tag/meccanica-razionale"],"tags":[],"content":"_Tags:trascrizione. meccanica razionale\nmeccanica- Lez6_trascrizione\nAllora, ieri abbiamo introdotto parecchi concetti sui vincoli, in pratica abbiamo detto, abbiamo ripetuto facendo degli esempi anche più generali, si ferma lì, che brutta roba, anche dei… ma non è utile così però… no, fermo, così che forse si convince… va bene, ok, che fa? torna giù… ah che disarro… va bene, non si vedrà tutta la lavagna quando lo attiro su, pericolosissimo. Vi stavo dicendo, abbiamo introdotto varie classi di vincoli, abbiamo visto che esistono oltre vincoli di posizioni, vincoli di mobilità e la sottoclasse dei vincoli che non possono essere ridotti a vincoli di posizione che sono i vincoli di pura mobilità. Poi abbiamo visto che possiamo dividere i vincoli in fissi e mobili secondo che nella loro espressione ci sia una dipendente esplicita dal tempo oppure no. Vi diremo fissi quando non c’è la dipendente esplicita e mobili altrimenti. Penso poi ci verrà bene di capirlo più avanti quando effettivamente questa distinzione avrà una specifica applicazione. Adesso andiamo a vedere per poter fare… difficilissimo. Controllo videocamera, non succede niente. Controllo videocamera, non succede assolutamente niente. Non mi fa fare niente, spiace. Perlomeno così. Allora vediamo un po’. Cosa c’è qui? Ah vista, ok. Controllo videocamera. Allora me la dà lì però non me la farà fare. È andata a posto? Non so come mai ma se è a toccare prima o poi qualcosa succede. Allora finalmente riusciamo a cominciare a vincoli per il nostro corpo rigido piano. Andiamo direttamente a vedere esempi di questo tipo. Saranno quelli che incontrerete negli esercizi. Il primo vincolo che introduciamo è la cerniera fissa. La cerniera fissa che Mestre ha. Un punto, chiamiamolo A, di BT viene bloccato e BT può solo ruotare attorno ad A. Il simbolo è questa pallina con questi raggetti che escono fuori. D’accordo? Sacciamo il disegno. Naturalmente avendo un corpo rigido piano avremo gli assi XY, che sono gli assi fissi. Prendiamo qui il nostro corpo rigido piano BP di foggia varia. Andiamo a mettere la nostra cerniera fissa in A. Prendiamo gli assi solidali. Questa è la direzione E1 e poi qua avremo la direzione E2. Se volete questi sono Y’ assi solidali. Ok, allora cosa succede? Che A è fisso, quindi X di A, Y di A non sono gradi di libertà. Questa è l’origine, no? Sappiamo che ci sono i gradi di libertà traslationali, li abbiamo eliminati fissando A. Rimane un Gdl theta, che è questo qui. Ok? La cerniera fissa quindi, che messiere fa? Toglie due gradi di libertà. Abbiamo eliminato sostanzialmente i gradi di libertà traslazionali. Forse in fondo avete problemi da vedere, quindi ti rompo sulla lavagna. Ditemi se vedete bene. Ok, quindi la situazione è questa. Con la cerniera fissa togliamo due gradi di libertà, non c’è altro da aggiungere e rimane solo la possibilità di ruotare attorno ad A. Poi un altro personaggio interessante, il carrello. Allora il carrello noi lo indicheremo con queste due stanghette e questo semicerchietto, o potrei anche metterci un circoleto qui, è la stessa cosa, per dire che poi rimane, rimangono dei gradi di libertà. Adesso ve li spiego. Oppure su qualche testo un po’ più vecchio trovate proprio il carrellino, con le due rotelline e quel pernetto sopra. Ok? Allora cosa fa? Costringe un punto A appartenente al corpo rigido piano a far cosa? A scorrere lungo, più in generale lungo una curva piano, nella maggioranza dei casi una retta. Ok? Allora questo toglie, come vedremo, un grado di libertà. Ne rimangono due. Allora, il caso più generale è quello in cui abbiamo proprio questa situazione, cioè il caso che si incontra più spesso è questo qui, asse X, asse Y. Poi qui c’è il vostro corpo rigido piano e qua nel punto A fissiamo il carrellino. Allora cosa fa il carrellino? Costringe A a rimanere tangente alla retta, più in generale sarà una curva. Potrebbe essere anche un carrello su una circunferenza, perché no. Allora però qui capiamo subito che quello che succede è che se qui mettiamo gli assi X’, Y’, con i loro versori E1, E2 solidali, adesso A lo passicciato orrendamente, poi gli loro assi con i loro versori solidali E1, E2, vedete? Non abbiamo buttato via tutti i due gradi di libertà traslazionali, però uno sì, cioè qui XA è fissato, d’accordo? Quindi rimangono YA di T e theta di T, dove theta di T possiamo prendere questo angolo, theta. D’accordo? Quindi è una situazione in cui è meno forte della cerniera perché toglie meno gradi di libertà. No, allora, ho scritto una stupidata. Toglie YA, ha ragione lei. Allora toglie YDA, ovviamente X è libera, perché questo punto può traslare lungo X. Se ne vanno Y, se ne va Y e basta, quindi rimangono questi due, XA di T e theta di T. Y, il simbolo di carrello, ci dice che non vi potete muovere ortogonalmente a questa direzione. La direzione è data dalle due sanghettine. Ok? Quindi rimangono questi due YA è fissato. Per fortuna, se ne ho accorto, perché sennò non funzionava. D’accordo? E chiaro a tutti come definizione? YA è fissato perché rimane Y uguale a 0, perché questo punto si può muovere solo lungo l’asse X. Va bene? No, perché c’è un motivo molto semplice che è quello che negli esercizi trovate X e Y. Ma poi, sulle notazioni non sarò sempre conforme a quella che vi ho dato all’inizio, perché in realtà va bene. Abbiamo la libertà anche di cambiare i simboli pur che sia chiaro quello che succede. Allora, terzo esempio, il pattino. Allora, il punto è che se ha la circunferenza e il pattino fatto così, e poi qui c’è il corpo rigido, comunque deve stare tangente alla circunferenza, d’accordo? E comunque le rimangono due gradi liberda. Perché c’è il vincolo dato dalla circunferenza, è più complicato da descrivere. Il pattino, il pattino come simbolo è molto simile, ma attenzione, non c’è più il pallino e questo vuol dire che quella direzione solidale che vedete qui non può essere piegata, cioè non c’è la libertà di ruotare, detto in altri termini. Allora, costringe un punto, chiamiamolo sempre a DbP, a muoversi, diciamo per semplicità lungo una retta e non consente rotazioni attorno ad A. Quindi in questa situazione qui, qui vi metto la direzione solidale, qua metto la sagoma del corpo rigido, questo per esempio potrebbe essere x primo, questo y primo, questo x, questo y, vedete che qui l’angolo theta non ve lo segno perché non è libero, rimane xA dt. Adesso facciamo vedere anche quelli che sono lontani. Lettate 1 su x primo e 2 su y primo, sono direzioni solidali, avete buttato via un grado di libertà traslazionale, quello rotazionale non c’è perché il pattino non lo consente. Allora viene utile già a questo livello ricordare, poi lo vedremo in dettaglio più avanti, che poi a questi vincoli corrisponderanno delle reazioni vincolari, d’accordo? E nel caso del pattino, quello che io chiamo il maledetto pattino perché mette spesso in difficoltà, ha messo spesso in difficoltà gli studenti degli anni precedenti, anche di altri corsi, perché maledetto? Perché c’è la tendenza a dimenticare che questo avrà un momento di reazione vincolare perché impedisce le rotazioni, ma quando arriveremo al punto giusto ve lo racconterò in dettaglio. Oh, adesso viene il più cattivo di tutti, l’incastro. Va beh, lo dice la parola stessa, quanti gravi libertà rimarranno al corpo rigido a nessuno perché è un incastro. Il simbolo potete trovare sia questo che più frequente, questa è una direzione solidale, oppure potete, quindi va beh il simbolo in realtà, adesso ve lo restauro, è questo qua, oppure in qualche caso si trova anche questo qua, però più frequente il primo, con l’ombreggiatura e poi con una direzione solidale al corpo rigido che si confica dentro. Dica. Ma perché? Dunque, nell’altro corso lo chiamano anche manicotto, adesso pattino, no, non è adeguato pensare alla amicna nel viaggio perché lei la caviglia la può muovere, quindi non, a parte che non è corpo rigido, però voglio dire. L’origine non me lo so. Che oggetto geometrico rappresenta? No, che oggetto geometrico rappresenta, vorrei dire, potrà vedere fisicamente proprio una situazione così, due barrette che costringono il suo corpo rigido muoversi di qua e però non c’è nessuno lo snodo che consente alla rotazione, lo costruisce proprio così. Ok? L’incastro cosa fa? Fissa a appartenente a BP e non consente rotazioni. Allora, lo potete vedere come un rafforzamento della cerniera fissa ma anche come un rafforzamento del pattino, nel senso che la cerniera fissa consente le rotazioni, questo non le consente però è fissa il punto. Il pattino non consente le rotazioni ma non fissa il punto quindi può essere visto come rafforzamento dell’una e dell’altra. Non rimangono gradi di libertà. Prendete proprio una asta, la piantate nel pavimento, la piantate nel muro e non si muoverà più, c’è poco da fare. Ok? Questi sono, poi vedremo un esempio dopo. Qui toglie, ah non l’ho scritto, questo vuol dire toglie tre gradi di libertà perché sono tre gradi di libertà, il corpo rigido piano glieli, glieli soprae tutti, è molto forte. Non ce ne può essere uno più forte del pattino, dell’incastro naturalmente, in quel senso lì. Poi un altro vincolo molto frequente è quella che viene chiamata cerniera mobile. Si indica con un pallino. Cosa fa la cerniera mobile? Eh, questo è proprio un vincolo, qui vincoli che vi ho detto sono vincoli tra il, beh, possono essere visti anche come vincoli tra il corpo rigido e appunto un vincolo esterno allo stesso che può non essere considerato un corpo rigido a sua volta, cioè non essere un corpo rigido di un sistema di corpi rigidi. Questo è un vincolo tra due corpi rigidi, ok? Allora, vincola due punti a primo appartenente a BP1, primo corpo rigido, chiamiamoli BP1, BP2, ok? A primo e poi a secondo appartenente a BP2 a coincidere, ok? Li porta a coincidere lasciando in un punto a, lascia libertà di rotazione attorno ad A che si può muovere. Il punto A si può muovere, non viene fissato. Adesso, detta così, è molto inastratto, facciamo vedere cosa succede. Di solito questo è un gioco che si fa con le aste, comunque sia, prendiamo il sistema, beh, facciamolo proprio così come l’ho fatto qua. Qui c’è A primo, vedete gli assi solidali, poi qui c’è A secondo e qua disegniamo gli altri assi solidali, ok? Ai due corpi rigidi, questo per BP1, questo per BP2 e poi prendiamo questo oggetto e lo trasformiamo, grazie alla cerniera mobile, in quest’altro oggetto qua. Qui vedete, ah va bene, adesso se disegno gli assi solidali facciamo anche che ci mettiamo una sagoma, adesso la lasciamo al bordo se no non viene bene. Quando li leghiamo assieme cosa verrà? Adesso verrà uno così e l’altro, adesso non riuscirò mai a ripar la stessa figura, però questo è BP1, questo è BP2, ok? E qui c’è la nostra cerniera in A. Li abbiamo uniti in quel punto comune che ha dato dalla fusione di A primo e A secondo a cui attacchiamo la cerniera mobile. Adesso sembra complicato, se fossero due aste, prendiamo questa asta e quest’altra asta e le mettiamo assieme con la cerniera. Quanti gradi di libertà rimangono? Quanti ne togliamo? Ve lo dire, dire\n\nquanti ne togliamo è più facile ancora, di dire quanti ne rimangono, poi lo diciamo. Vedete che qui avete tre gradi di libertà e qui ne avete altri tre. Mettiamo assieme le due origini, a questo punto i gradi traslazionali di una delle due origini vengono lavati via, perché le facciamo coincidere e quindi vi rimangono soltanto i gradi di libertà traslazionali di A e la possibilità di rotare attorno ad A per tutte e due, quindi altri due, toglie due GDL, la ragione che toglie i due gradi di libertà traslazionali di una delle due origini. Ok, rimangono 6 meno 2 uguale 4 gradi di libertà. 2 traslazionali di A e 2 di rotazione attorno ad A. Per capirci, qui c’è il punto A che ha i due gradi di libertà nel piano, lo potete muovere, è una cerniera mobile, quindi lo potete muovere nel piano. E poi cosa succede? Avete anche questi due, che sono, questo lo chiamiamo lo theta e questo lo chiamiamo phi. D’accordo? Guardate, non fa più impressione a vederlo che non ha a giocarci negli esercizi. Comunque qui sono due corpi rigidi messi assieme attraverso questo vincolo che si chiama cerniera mobile. Ok? Quando la mettiamo perdiamo due traslazionali ma le rotazioni, come vedete da quelle due aste, le libertà di rotazione attorno ad A rimangono. Va bene? Poi, cosa viene? No, adesso per il momento abbiamo visto vincoli che sono manifestamente vincoli di posizione. Adesso viene il bello, il puro rotolamento. Essendo a priori un vincolo di velocità non c’è un simbolo. Si dice che nel punto di contatto tra un disco e una guida che può essere fissa o mobile parte di un sistema, può essere un altro corpo rigido, sarà quello che sarà. Si dice che i due punti di contatto tra il disco e la guida avranno la stessa velocità e questo vuol dire che il disco non striscia sulla guida. Allora, è un vincolo di contatto tra due di P o un corpo rigido e una guida. Ok? Il contatto è in un punto. A e vale vA per il corpo rigido BP1 uguale vA del corpo rigido BP2 oppure o anche vA di BP uguale a vA della guida. Facciamo vedere agli spettatori distanti. Adesso andiamo un po’ meno in ordine. Questo è un argomento importante perché di puri rotolamenti ne incontreremo parecchi. D’accordo? Beh, anche gli altri sono molto importanti. A pare come vincolo di mobilità. Su stringer vedete i punti di contatto dei due corpi. In realtà sono due punti di contatto. Il corpo rigido 1 che sta a contatto col corpo rigido 2 a muoversi con la stessa velocità del punto di contatto del corpo rigido 2 col corpo rigido 1. Va bene, abbiate pazienza. Adesso vedremo l’esempio notato. Allora, è un vincolo di mobilità. A pare così. In realtà vedremo che per quello che interessa a noi, cioè il disco che si muove, che rotola senza strisciare dentro al piano FIGRECO, questo si ridurrà a vincolo di posizione. Adesso lo vediamo. Comunque, per come è scritto, è un vincolo di mobilità. È un vincolo sulle velocità. Giusto? Quindi è un vincolo di mobilità. Esempio notevole. Disco che rotola senza strisciare su una guida, guida, che brutto, fissa. La prendiamo fissa tanto per fissare le idee, prendiamo una guida fissa. Una guida che non si muove a sua volta. Allora, qual è la situazione? La situazione è questa qua. Asse Y, asse X, disco, punto A di contatto, che qui è unico. Poi ci piace anche di indicare il centro del disco C. Ci viene comodo anche di indicare il raggio R del disco, R grande, d’accordo? E questa è la guida fissa. E diciamo che in A c’è pure rotolamento. Imponiamo questo vincolo. Attenzione, si dice pure rotolamento o anche rotolamento senza strisciamento, d’accordo? Sono sinonimi. Potete trovarli detti in un modo o nell’altro, gli eserciziari sappiate che sono la stessa cosa. Ok, allora, andiamo a vedere cosa succede. Per la condizione di puro rotolamento vale, secondo la definizione che vi ho dato, che vA del disco è uguale a vA della guida, ma siccome la guida è fissa, questo è uguale a 0. Non si muove, quindi non si muove neanche il punto A della guida. Per avere puro rotolamento del disco, quindi se voi prendete una moneta di 50 centesimi, di un euro, la fate rotolare sul piano della lavagna mantenendola sempre nello stesso piano. Ci ritroviamo in questa situazione qua, e quello che succede è che se c’è puro rotolamento, se non fate strisciare il bordo della moneta sul tavolo, il punto della moneta che va a contatto con il tavolo, istante per istante, ha velocità nulla. Se no, non è puro rotolamento. Ammetterete che il tavolo è una guida fissa, questo è facile. D’accordo? Ci siamo per tutti? Perché la guida è fissa, la guida è ferma. Il punto A della guida non si muove. No, se la guida è fissa, lo sa che la guida non si muove e quindi viene così la condizione di vincolo. Io potevo scrivere anche direttamente, sapendo che la guida è fissa, che la velocità via del disco è uguale a zero perché la guida è ferma. Allora, qui stiamo parlando dell’istante in cui un punto, ci arriviamo tra poco, vi farò capire la natura, la triplice natura di quello che chiamiamo A. Quindi se appazienzi un attimo vedrà che il suo dubbio si dovrebbe risolvere, però bisogna fare molta attenzione. Non ve lo spacchetto subito, quindi non le rispondo subito perché l’argomento è subito immediatamente successivo. Quindi cosa scopriamo? Che via del disco uguale a zero, questo vuol dire che A è il centro di istantanea rotazione del disco. Perché a quel punto il disco è fermo e l’atto di moto è traslatorio, ma non è il caso in generale, oppure il punto di contatto è l’unico punto a velocità nulla e in quanto punto di velocità nulla è il centro di istantanea rotazione. L’abbiamo visto ieri. Vedo facce tal triste e lo sconsolato, se avete domande fatemele. Allora, questa parte, la meccanica analitica è così. A è il centro di istantanea rotazione. Allora, possiamo osservare che mettiamo… L’origine in C viene bene in questo modo. E poi ci prendiamo… Io questa volta prendo questo angolo theta qua. Ok? Allora osserviamo che la quota, meglio l’ordinata del punto C non cambia. Se c’è pur rotolamento vuol dire che c’è contatto, vuol dire che l’ordinata del centro del disco… Vabbè, scusate, adesso C era il C e oggi C era A. Adesso usiamo per il centro del disco. Ok? Quindi rimarreribbero due gradi di libertà che sono x dc e theta. D’accordo? Ne rimarrebbero due. Ma di questi in realtà sono in relazione tra loro. Questo è quello che vogliamo far vedere. Dei due gradi di libertà che rimangono, che sono xc, la scissa del centro del disco e l’angolo di rotazione theta è solo uno indipendente. Ok? Infatti abbiamo vc, la possiamo scrivere come la derivata rispetto al tempo di xci più ycj, dove i e j sono i versori degli assi fissi. Quindi qui quando derivate, vi rimane soltanto x.c per i, perché? Perché yxc è r costante, quando lo derivate trovate 0. E poi per lato di moto rotatorio potete scrivere che vc è uguale a omega vettor cimena, perché questo è vero, perché A è il centro di istantanea rotazione. Quindi possiamo sempre scrivere la legge di istruzione delle velocità. Scriveremo vc uguale vA più questo p, ma vA uguale a 0. VA del disco abbiamo detto che è uguale a 0. Questi sono tutti i punti del disco. Che cos’è omega? Per quanto abbiamo detto questo è meno theta punto k che esce dal piano della lavagna, vettor cimena che è rj, uguale k vettor j e meno i, c’è il meno che ci rimane r theta punto i. Cosa scopriamo quindi? Scopriamo questo fatto interessante che x.c è uguale a r theta punto. Perché le due, ovviamente quando scrivete vc, la velocità del punto c, usando le coordinate xc e yc o usando l’atto di moto alla fine vi deve venire sempre lo stesso oggetto. Quindi queste due quantità devono essere uguali, ne segue integrando rispetto al tempo, che vi rimane x dc uguale r theta più costante. Allora vedete c’è una relazione finita tra le due coordinate. Tra theta e xc solo una è indipendente. La conclusione qual è? La conclusione è che potete usare indifferentemente per l’unico grau di libertà che rimane, theta o xc a seconda della vostra preferenza. La rendifinizione non l’ho mai cancellata, in questo giro, va bene, meglio così. Allora quindi rimane un grau di libertà xc di t oppure theta dp a vostra scelta. Quindi in sostanza cosa scopriamo? Scopriamo due cose. Toglie due gradi di libertà, perché siamo partiti da tre, poi tra appoggio e puro rotolamento, ne abbiamo quindi contatto con la guida e appunto rotolamento senza strisciamento, abbiamo scoperto che ne rimane uno solo di grado di libertà e seconda cosa nel caso il vincolo di mobilità si riduce a vincolo di posizione. L’abbiamo visto qui quando abbiamo scritto che xc uguale r theta più qualcosa, quello è il vincolo. In questo caso di disco che rotola nel piano della lavagna o comunque nel piano pi greco, quindi senza far mai cambiare orientazione a questo piano. In questo caso specifico, quello che vi ho detto, il disco che si muove nel piano rotolando come nel disegno che c’era prima. Quindi è olonomo come vincolo in questo caso. Allora se la guida è mobile cosa succede? Facciamo un’nota bene che è indispensabile per non indurre impeffazioni strane. Se la guida è mobile, diciamo toglie due gradi di libertà, come per la guida fissa, ma a non è cheer del disco. Quando abbiamo parlato di cheer, abbiamo fatto tutti i ragionamenti di cinematica considerando un singolo corpo rigido. Non vi potete permettere di cercare il centro di istantanea rotazione di più corpi rigidi, cioè assegnare lo stesso centro di istantanea rotazione ad un insieme di corpi rigidi che si muovono uno rispetto all’altro. Centro di istantanea rotazione è relativo a uno specifico corpo rigido di cui state studiando la cinematica. Questo è un’osservazione anche di troppo nel vostro caso, però diciamolo. Non è il cheer del disco perché? Allora facciamo questo esempio. Adesso sappiamo cosa è il carrello. Ci metto un’asta sopra con due carrelli in, chiamiamo questi punti, via, qua avete il vostro disco, questo è il centro C e qui trovate A. Il punto di contatto poi diventerà H. Adesso lo trasformeremo in H perché è più comodo. Allora vedete questa asta che cosa può fare nella vita? Può solo traslare lungo la direzione X. Se questa è in movimento, se questa asta si muove, può traslare solo lungo la direzione X il suo atto di moto traslatorio. Il punto cos’è che la velocità, via, guida diverso da zero e via disco uguale, via guida diverso da zero perché in generale quella guida si può muovere. Allora vedete non potete beatamente dire che questo è il cheer del disco perché non ha velocità nulla. Questo ve lo dico subito perché la tentazione è forte. Adesso veniamo alla risposta al vostro collega. Di e\n\nD, sì ho introdotto altre lettere perché le volevo chiamare A e B poi. Vabbè, poi veniva male a mantenere A come punto di contraria. Allora, natura, molteplice di A. Vabbè, poi useremo sempre H in linea di massima per il punto di contatto, però non c’è problema. Adesso abbiamo cambiato la notazione e viene così. Natura molteplice, che significa? Natura, se volete, stitofrenica del punto. In questo senso qui, così ve lo ricordate. Allora, prendiamo il nostro disco. Qui c’è A primo del disco, poi prendiamo la nostra guida. L’antemiamo pure che sia guida fissa. Qui c’è A secondo, poi qui ci mettiamo in mezzo e due A geom, che vuol dire A visto come punto geometrico. Allora, la cosa sembra complicata ma non lo è. I personaggi sono tre. Quando scriviamo A ci sono in realtà tre personaggi. Il primo personaggio, a primo, punto del disco a contatto con la guida. Poi c’è A secondo, che è il punto della guida a contatto col disco. Adesso arriva il punto geometrico in cui questi vanno a coincidere, che è A geometrico. Questo è il punto geometrico. Allora, questi qui sono punti materiali, perché uno appartiene alla guida, un altro appartiene al disco. Quello è il punto geometrico in cui istante per istante, a primo e a secondo, vanno a coincidere. D’accordo. E l’osservazione importante da fare è che per guida fissa v secondo di A, scusate, v di A secondo uguale a zero, perché la guida è fissa, il puro rotolamento ci dice che via primo è uguale via secondo uguale a zero e per quanto riguarda invece il punto geometrico in cui istante per, quindi questi due punti, a primo e a secondo, hanno velocità nulla e sono punti materiali. Uno della guida e un altro del disco. A primo del disco e a secondo della guida. Ci siamo? Il punto geometrico in istanti in cui questi vengono a coincidere, se lo consideriamo istanti diversi si muove ed è l’osservazione che faceva il vostro collega. Il punto geometrico in cui istante per istante questi coincidono si muove ed ha una velocità. Ha una velocità. Qual è questa velocità? È la velocità del centro del disco. Perché è vero? Facciamo il disegno. Questa è la foto del vostro disco al tempo T1. Questa è la foto del vostro disco al tempo T2 maggiore di T1, quindi il disco ha roto traslato in questo modo e vedete che il punto di contatto sta sempre sotto C, quindi si deve muovere come il punto geometrico in cui avviene il contatto sta sempre sotto C e quindi si deve muovere con la stessa velocità. Diciamola anche con un altro esempio. Adesso vediamo se ho la moneta giusta, non ce l’ho, però forse sì. Va bene non ce l’ho da 50 centesimi, usiamo quella da 2 euro che è più grossa si vede meglio. Allora quella 50 centesimi è più bella perché la zigrinatura, le scanalature. Segnatevi una di quelle scanalature. Se la moneta rotola, adesso da lontano non si lo facciamo rotolare sulla mano, pensate che sia un piano, facciamola rotolare. C’è il punto di contatto in un certo istante ed è in una certa posizione. In quel punto di contatto sia la velocità della mia mano che fa da guida e la velocità della moneta hanno valore nullo perché c’è il rotolamento senza strisciamento. Quando questa procede in avanti ci sarà un altro punto della moneta che va a contatto con la guida e quella avrà sempre velocità nulla istantaneamente. Mentre va a contatto con la guida fissa il punto avrà sempre velocità nulla, se no c’è strisciamento. Se andiamo a vedere, invece facciamo intanto, guardiamo come si muove il punto in cui coincidono il punto del disco e il punto della guida, cioè se andiamo a vedere la geometrica, questo a cambiare del tempo è cambiato con che velocità? Con la velocità del centro del disco. Non è difficile, bisogna fare un po’ un’ilente locale, pensarci, ma come concetto non è difficile perché stiamo semplicemente considerando punti diversi, cioè i punti materiali, ripeto, hanno velocità nulla istantaneamente quando vanno a contatto. E così. Se consideriamo il punto geometrico in cui questi vanno a contatto in istanti diversi, vedete in un certo momento qui, in un istante successivo si è spostato e si sposta con la velocità del centro del disco. Vedo delle perplessità, se avete perplessità, però pensateci, sono punti di natura diverse, cioè chiamiamo con lo stesso simbolo A oggetti che hanno in realtà una natura diversa, un conto è dire dei punti materiali che vanno a contatto e quelli in quell’istante in cui vanno a contatto non ci sono santi, se la guida è fissa hanno velocità nulla, se no non è puro rotolamento. Il punto in cui si incontrano i due punti materiali è un punto geometrico che nel tempo si sposta con quella velocità lì, dove l’ho scritta, ecco quella allora, cambia allora, noi chiamiamo sempre a il punto di contatto, il punto materiale di contatto man mano che questi ruo… allora, sì è chiaro dai, nel senso quando prende la moneta segna una di quelle ziglinature, quando arriva a contatto sa che ha velocità nulla se non sta strisciando, dopodiché quel punto lì che era a contatto si solleva e da una velocità diversa da zero, il nuovo punto di contatto lo chiamiamo sempre a, lo chiamiamo sempre a, il nuovo punto di contatto e perché qui tenete conto stiamo facendo in realtà stiamo assultando l’atto di moto, quindi sono istantanei che noi facciamo ad un istante fissato, ok? Poi se va a vedere il moto più che stare a vedere l’atto di moto, a ragionare quell’oggetto si sposta, diciamo dove vanno a coincidere volte in volte i punti di contatto, il punto geometrico si sposta da una velocità pari a, ok? Ho l’ultima nuotazione che vi voglio fare e che in generale, adesso in questo caso specifico abbiamo detto che il vincolo di puro rotolamento è olonomo, in generale non lo è e quindi è un esempio di vincolo olonomo. Il puro rotolamento è un vincolo di pura mobilità, quindi anolonomo. Esempio, palla, dovrei dire sfera ma tanto per essere concreti, che rotola senza strisciare sul pavimento, per dirla in modo più aulico, la sfera che rotola senza strisciare su un piano fisso, tanto per fare un esempio concreto. In quel caso lì vi dà un vincolo di velocità che non è integrabile, proprio in ripendi difficile, molto difficile da trattare ed è vincolo anolonomo. Sorpresona anche se consideriamo per esempio un disco dice vabbè è la ruota della bicicletta. Se la ruota della bicicletta sta sempre nel piano e rotola senza strisciare il vincolo anolonomo, ma non appena la manteniamo magari sempre per tendicolare il piano, però la facciamo girare e quindi cambiamo il piano in cui già c’è, diventa subito vincolo anolonomo. Il che ci fa comodo nella vita reale, nel senso che poi anche con l’automobile, pur rotolamento delle ruote ma non è un vincolo anolonomo, è un vincolo di pura mobilità e ci viene bene perché questo non limita le configurazioni in cui possiamo mettere l’automobile, d’accordo? Quindi le configurazioni a cui possiamo accedere facendo manovra, quindi ci viene comodo, però il problema è che dal punto di vista della meccanica analitica i vincoli anolonomi sono un disastro per trattarli. Sono le equazioni di Hafele, sono cose molto complicate. Bene, allora, questo è il vincolo numero 6. Gli esempi li facciamo martedì, ma ci sono lauree la settimana prossima, giovedì, allora salteremo giovedì evidentemente, però vabbè controllo sul calendario, quindi martedì c’è lezione e mercoledì ci sono le proteste. Come è che funziona? L’avete capito? No, vabbè dai, guardo sul calendario, se ci sono lauree lo sapete e quindi martedì casomai non ci vediamo, ma non mi risulta. No, perché martedì è il 2, quindi dovrebbe essere più avanti il 4 se non mi sbaglio. Vincolo numero 7, contatto con strisciamento. Io finisco il catalogo e poi vi faccio gli esempi. Contatto con strisciamento è ancora un vincolo tra due corpi rigidi. Allora, un punto, diciamo, Q appartenente a un primo corpo rigido BT1 è a contatto con la superficie sigma di normale esterna N sigma, che può dipendere appunto, non è che possano essere cose troppo tranquille, però per noi saranno tranquille, di un secondo corpo rigido BP2, quindi sigma di normale N sigma è la normale, diciamolo così, siccome poi è un corpo rigido piano sarà la normale a un punto del perimetro del corpo rigido, del secondo corpo rigido. La condizione, vedete, è meno forte del puro rotolamento. Nel puro rotolamento pretendiamo che l’intero vettore velocità venga impegnato ad essere lo stesso nel punto di contatto tra i due corpi rigidi. Qui chiediamo di meno, cioè chiediamo che siano uguali VQ di BP1 calare N sigma nel punto Q uguale a VQ del secondo corpo rigido calare N sigma di Q. Cioè, stiamo dicendo che solo le proiezioni lungo la normale alla superficie devono essere uguali. Adesso, detta così, sembra una roba lunare, però se facciamo l’esempio, l’esempio più stupido è questo, poi faremo un esercizio direttamente su questo. Avete un sistema di due corpi rigidi fatti in questo modo. Allora, abbassiamo, sia l’asse X, l’asse Y, possiamo metterlo direttamente qua. Allora avete l’asta OQ che va a contatto con questo lato che sarà la nostra superficie sigma della lamina. La normale esterna è questa qui ed è veramente la stessa. Allora, facciamola un po’ meglio. Allora, la normale esterna in Q è questo oggetto, non riesco a farvela abbastanza grande, N sigma, d’accordo, è sempre lo stesso per tutti i punti di questo lato perché la normale non cambia mai. D’accordo, stiamo scattando un’istantanea. Questo è il punto Q. Allora, cosa stiamo dicendo? Questa asta ha un atto di moto rotatorio, perché avete solo questo angolo theta, ha un atto di moto rotatorio e ha un moto rotatorio perché c’è una cermiera fissa, può solo ruotare attorno a questo. Qui avete il vincolo di contatto senza strisciamento, eh, scusate, contrisciamento, contatto con strisciamento, ok. Allora, cosa stiamo chiedendo? Stiamo chiedendo che le due componenti delle velocità in questa direzione qua siano uguali, che è naturale se vogliamo ottenere a contatto i due corpi. Cioè, questa può scendere là e la lamina si può allontanare oppure viceversa. Ma quello che succede è che chiediamo che le componenti parallele a questa normale delle due velocità, quella dell’asta e quella della lamina, siano le stesse nel punto Q, perché il modo per mantenere il contatto. Ok? E questo, va beh, qui se volete N sigma è uguale a meno i, versore dell’ase X e questo è il corpo rigido 1, BP1, e questo è BP2. La lamina è BP2. Ok, stiamo dicendo che aggiustiamo le componenti normali alla superficie in modo tale che il contatto si possa mantenere. Se si muovessero con velocità diverse il contatto si perderebbe, giusto? Quindi diciamola così, è una condizione più naturale di quella che non possa sembrare giustamente a prima vista. È più naturale quel che sembra. Ok, allora esempio ve lo faccio lunedì. Faremo un esercizio su questo contatto e poi un esercizio che praticamente prenderà tutti, tranne l’incastro, tutti gli altri vincoli che abbiamo visto. Bene?"},"2--source-materials/meccanica-lez04_trascrizione":{"slug":"2--source-materials/meccanica-lez04_trascrizione","filePath":"2- source materials/meccanica-lez04_trascrizione.md","title":"meccanica-lez04_trascrizione","links":[],"tags":[],"content":"Allora, la volta scorsa abbiamo incominciato a fare il catalogo diare sotto vedremo solo certe categorie, certi tipi moti che saranno interessanti per noi. D’accordo? E oggi dopo aver visto in modo trascore il moto rotasorio che poi del moto piano continuiamo con il nostro catalogo e facciamo l’inferiore moto sotto caso del moto traio che è il moto enicoidale. Allora, il moto di un corpo di B è se esiste una direzioneorità di invarian Solito discorso, c’è un’orientazione invariante, cioè che non c’è un’asse a direzione un’asse solidale corpo rigido che non cambia orientazione rispetto agli assi fissi, tale che la Due punti hanno velocità parallela a tale direzione. Ok? Quindi abbiamo Rariante con i p parallelo ad r per ogni f appartenente a d’accordo? Allora, questo è chiaramente è un sotto caso del moto rotto col traslatorio. Perché? Perché c’è una direzione invariante che sarà poi parallela ad omega come abbiamo imparato la volta scorsa, quindi giedì scorso. Ok? Il sotto caso del mono rotolatorio. E cosa succede in questo caso? Beh, avete solo 2° di libertà da spendere complessivamente. Questi x grandi questo y E questo grande qui poi mettete z piccolo y piccolo x piccol eh, quindi k parallelo a R e K parallelo a K grand, d’accordo? E cosa vi rimangono come gradi di libertà? Che rimangono l’angolo di rotazione e poi di A. Ok. Questo asse, questa è la direzione invariante e questo trasla verso l’asse. Evidentemente tutti i punti di quell’asse hanno velocità parallele all’asse dopo vi faccio un esempio complessivo di questi di queste tipologie di mosi. Eh direi che non ci sono particolari misteri da velare. Passiamo all’altro moto. D. Allora, in questo caso è ancora più semplice, ci rimarrà, come sapieremo subito, un grado di libertà. Il moto di P è tale esiste una direzione R invariante. Abbiamo capito come dire invariante rispetto agli assi fissi tale che no i quei punti che i quei punti hanno velocità Ah, t appartenente a R vuol dire che la velocità di t è uguale a 0. R si dice asse di rotazione. Ok. Allora, c’è un solo grado di libertà. A questo punto, vedete, questo è un sotto caso del rotaslatorio ed è un sotto caso anche dell’elipidale. Prendete il moto elidale, mettete al zero la velocità dei punti dell’asse e ottenete il moto rotatorio. Professore, scritto direzione variante per\nSì. Allora Sì, è che avevo scritto, allora qui avevo scelto K parallelo a R e poi abbiamo detto anche K parallelo a K magico. K piccolo è il grassore dell’asse Z solidare del corpo e K grande inversore dell’asse fisso. Ma sopra il terra che sembro c’è sopra terra non c’è nessun simbolo sopra tetra. Ho fatto semplicemente vedere la il buon angolo di rotazione che va dalla direzione invariante a quella solitaria. A\na rappresenta l’origine dell’assi. Va bene. Allora Allora, ritorniamo al rotatore sottoc traslatorio e il Ok? Eh, qui prendiamo direttamente l’asse di rotazione, facciamo l’esempio di un cilindro che ruota attorno su asse. D’accordo? Questo lo prendiamo, prendiamolo pure come asse Z, quindi e altri possiamo anche non disegnarli. Quello che succede è che l’unico grado di libertà, prendiamolo anche orario, è questo angolo qui in sezione vuol dire che questa è la l’intersezione, se lo guardiamo perpendicolarmente. Facciamo con l’asse Z entrante. Eh, ma fa niente, poteva anche essere uscente. Qui prendiamo una direzione invariante, poi c’è una direzione solidale e qua c’è l’angolo T, l’unico grado di qua che è rimasto il cilindro a parte are su se stesso. Vedete, ha i punti dell’asse che sono fissi perché hanno velocità, appunto, è l’asse di rotazione. Stesso assoluto. Avete un oggetto che ruota solo addosso dell’asse, non può fare altre. Questa è una sezione perpendicolare all’asse. Abbiamo scelto l’asse Z entrante. Possiamo scegliere un scente, anzi lo scegliamo uscente Ok, va bene. Questo diciamo che ci muove a questo punto la possibilità questo è l’esempio per il modulo Adesso mettiamo consideramo un modellino assolutamente, diciamo, non fisico, però a proposito di fisici, sono arrivati i fisici del di meccanica analitica o no? Ci sono in aula? No, a indagare questa cosa. Allora, eh dicevamo Vi faccio un modellino proprio ridotto all’osso di elicottero. Lo disegnerò in maniera pessima, quindi voi prendete messi potenti che avete. Io lo faccio a mano libera anche elicottero sceno. Allora, questo oggetto è la carling poi qui ci mettiamo il rotore principale e qui in coda mettiamo Allora, questo è il rotore e questo si chiama rotore anticoppia. Potete decorare, fate fate quello che volete. A me passano sti questi tre. Sono tre corpi La perlinga, il rotore e quello anticipia. Oh, a cosa serve il dottore Anticoppia? Beh, quando l’elicottero decolla e si stacca la terra non c’è più la resistenza. dovuta agli del terreno e quello che succede che se c’è non c’è il motore anticoppia devi cirere in un verso e la carlinga nel verso opposto. Non è bello, non è molto più locabile un sistema del genere. Avete visto nei film, forse in qualche arma letale, però è troppo antico per voi come film colpire il rotore posteriore, vedere le rocchette comincia a fare questo moto nella carlinga in rotazione opposta a quella della del rotore principale. Quindi il rotore anticoppia serve per stabilizzare il volo della cavolinica. D’accordo? Allora, pensiamo a un che collo alla fase di colollo. in verticale cinga eh che non cambia orientazione. Ok, decollate, tenete in accetto la linga corpo del dell’elicottero. Allora, qui abbiamo tre diversi perché perché per per come abbiamo posto le cose la carlinga sta traslatando, no, i suoi assi, gli assi solidali con la carlinga non cambiano orientazione rispetto agli assi fissi, fissi a terra, per dire, no? Se decollate, se vi muovete in questa direzione qui con la carlinga che va solo verso l’alto, tutti i punti della carlinga hanno la stessa velocità, la carringa non ruota e moto osservate il rotore invece Il secondo corpo rigido, naturalmente le palle possono basculare, le vere el io sto facendo una roba iper semplificato. Il rotore cosa fa? Moto e liquidale. I punti di quest’asse hanno tutti velocità sicuramente verticale parallela all’asso. Venoreia fa rotaslazione. Moto moto trastatore, nel senso che la direzione invariante per questo per il rotore anticoppia è il suo asse che lì non vedete, però diciamo entra nella lavagna, l’asse per rotore anticoppia. Quella è una è la direzione privilegiata che fa moto rotatorio. Quindi questo è l’esempetto che mette assieme tre tipologie di moti che abbiamo appena visto il moto è liquidale anche il moto della vite che si attiva, d’accordo? L’asse della vite è la direzione invariante se vuole. Va bene. Allora, prima di passare ad un nuovo argomento, ahorà l’altro moto che vi devo fare dimenticato che è il moto polare. Qui finalmente usciamo dalla dal per esempio dalle categorie dei moti può essere misura tutti i rotras perché se volete anche il mototras è un sotto caso del rototras, no? Il moto trulatorio potete vederlo come sotto caso del moto prototatorio mettendo media, quindi avendo tutte lezione piuttosto che una sola. In quel caso dovete estenderla leggermente la definizione di moto rotassatoria e dire che esiste almeno una direzione nella definizione l’hai estendete un pochino anche il caluratore in sottopasso. Comunque usciamo da quel da da quel mondo. Che cosa chiediamo? Chiediamo in questo caso che allora il mondo il B è tale se esiste un Q di X. Allora, qua tipicamente si fa il disegno di una trotola. Qui c’è il punto P fisso VP uguale a 0 e P appartiene al vostro corpo rigido. Allora, eh cosa succede? Se prendete P come origine degli assi solidari, vedete subito che ne rimangono solo tre. di t di t gli angoli dia. Questo è il moto qua. Va bene, ci fermiamo qui con il catalogo dei moti. Ecco, già il corpo di sapete che ha 6 gr di libertà. In in pratica qui stiamo dicendo fissiamo i gradi di libertà traslazionali perché fissiamo l’origine P e di conseguenza ci rimangono solo quelli frazionali. D’accordo? Allora, c’è un ultimo teoremino di cinematica che mi interessa di fare per qua ci sarà che è un un teorema importante ehm della cinematica del corpo rigido che picchio che un sistema di gr punti materiali è rigido se e solo se ehm dala - a uguale di a^ per ogni a e b appartenente al sistema. Ok? E per ogni questo è Allora, cosa vi sta dicendo questo teorema? Discuamo un attimo il suo significato prima di vedere la dimostrazione. Vi sta dicendo che per avere un sistema rigido, sicuramente sarà in moto perché ci sono delle velocità e parlo. Cosa dovete avere? Dovete avere che le proiezioni delle velocità lungo una congiungente di due punti, comunque presi se corpo liquido, devono essere uguali non soltanto in modulo, ma anche inverso, d’accordo? Cioè, per esempio, questo che vi dice, allora devo stare attento a prendere la stessa proiezione con lo stesso. Questo è rigido, questo è. Questo è A. Questo è B. E questo è di questo è rigido. Se invece lo prendiamo così, questo no, non hanno la stessa proiezione e neanche questo, diciamo, è sem è sempre tentato di dire “Beh, ma ma questo qui è rigido perché ho le stesse velocità Ah, questo ruota attorno a questo punto qui. No, non è rigido perché le proiezioni in modulo sono le stesse, ma i versi sono diversi. Questa è fatta così e quest’altra è fatta così con verso non va bene, no? E anche questo lo riprendiamo al momento del di un teorino molto utile della Sempre la cinematica del corpo rigido a questo in generale. Eh, se fate le proiezioni lungo la congiungenza, attenzione, le proiezioni devono essere uguali. Non so lo dice questa eguaglianza. Le proiezioni lungo la congiungente devono essere uguali sia in modulo che inverso. Allora, vediamo la dimostrazione. A S Allora, la derivata rispetto al centro di b² è uguale a 0 perché perché b- al quadrato è il modulo quadro di b a e questo è costante. se è ripido. Ok? Allora, quando facciamo, vi ricordo b - a al qu significa b - a scal b - a. Questa derivata che cosa è uguale? È uguale a 2 volte b - a scalar la derivata rispetto al tempo di b - a e questo uguale, quindi due volte b - a scalar di b - e qui abbiamo dimostrato quindi che se il corpo è rigido vale esattamente questa relazione qui la possiamo anche scrivere vedete come VB - va da scalar b - a = 0 Ok. Se qualcuno non quadra qu tutti viceversa. valga questa relazione R per ogni a b ogni t. Allora, la scriviamo esattamente r equivale eh b - a sturfa scalare di- a uguale a 0. Questo è uguale a 1/2 derivata rispetto a temp di b- a al quadrato. segue S è rigido o in moto Ok? E questo chiude la dimostrazione è veramente banale come questo posso dire e però questo è Il un teorema importante da ricordare, soprattutto quando dobbiamo fare figure che rappresentino moti plausibili di corpo rigido. E questo è plausibile. Se avessi messo questa da questa parte comunque andava bene. Mh. E invece queste due No, perché violano le PS di questo parente. Va bene? Quadratino e teorema è chiuso. Ehm adesso dobbiamo parlare di un altro argomento importante nella scematica del corpo rigide. che è il cosiddetto atto di motto. Da ora in poi ADN. Allora, l’asto di moto che caratteristiche ha? Beh, innanzitutto definiamolo. si dice atto di moto eh diciamolo bene insieme delle velocità dei punti. I di B adante fissato. Questo te ve lo sottolineo perché si a dimenticare. Stiamo dicendo, scattiamo una fotografia del del nostro corpo rigido, lo usciato, chiamiamolo Po, direttamente. che portiamo meglio. Si tratta di uno stato stato. Allora, scattiamo una fotografia del nostro corso X. Andiamo a vedere come sono fatte le velocità e punti del corpo quindi se volete è questo insieme qui è il VP, ok? Al tempo t con0 e VT del tempo t contero con eh pi apparten al corpo di per ogni che va da 1 a corpo rigido visto come sotto caso del del di un sistema di n grande punti materiali come la definizione che abbiamo dato il primo giorno. Non so se da là in fondo si legge ho scritto VP con i d0 con T con i appartenente a B per ogni I che è attivata 1 a NR. Ripendiamo che il nostro corpo rigido P è appunto un sofissi un scusate un sistema di n punti materiali n grande punti materiali col vincolo di diciamo vi dovrebbe quadrare e andate a vedere la definizione che abbiamo dato a primaizione. Ora, quindi ora dice vabbè, ma l’atto di moto se volete lo possiamo dire l’atto di moto è il campo e velocità e Q Ok. Ci dice come sono fatte le velocità quell’istante. Allora, non Allora, la definizione di atto di noto si deve quando riportano testi sacri della meccanica italiana si deve almarci e quindi rimane atto di moto. Non lo trovate se prendete un libro di lingua inglese, per esempio, non trovate di sicuro atto di moto come definizione. Potremmo anche dire è lo stato cinetico del corpo rigido al tempo t. Stato cinetico significa a al tempo t0 le velocità. Ora chiaramente diciamo Matto di moto storicamente si chiama così per le che dalla ragione che vi ho appena detto, cioè l’ha inventato immagine, non è proprio il nome migliore perché lo studente molto distratto, non è il caso nostro, può facilmente confondere moto e dato di non sono la stessa cosa manco per niente, nel senso che qui vedete avete molta meno informazione. Sapete il campo di velocità a un istante fisso. Questo vuol dire sapere il moto? No, anche per niente, però informazione interessante lo stesso. Lo vedrete soprattutto facendo gli esercizi o ehm diciamola così là posso farvi questa diciamo paragone con quello che succede per il punto mater Diciamo che l’asco di moto di toto di T con la velocità istantanea di T di T0. un punto materiale sta al moto dello, cioè al moto del punto matico. Questo mi dice che c’è un abisso di informazione tra il moto. Se sapete il moto sapete tutto se sapete Avete l’atto di moto, sapete qualcosa che non è tutto. Sicuramente non è tutto. Così come se avete un punto materiale, se conoscete la velocità istantanea ad un istante t0 non potete dire di sapere. Chiaro? No. Ok. Questo tanto per togliere Voi siete scappati studenti di ingegneria matematica, non ci sarebbe bisogno di dirlo, ma diciamolo comunque. Pericolo di confusione. C ora eh si potrebbe anche fare un altro discorso, però diciamo no. Evitiamo per il momento evitiamo per introdurre la lesione della granigiana uleriana del mo dei consumi è prematuro rispetto alla parte di meccanica di consumi che vedremo in coda al corso. Quindi, per il momento ci accontentiamo di questo, poi faremo dei commenti che mai a dedico. Quella definizione che vi ho dato assolutamente rigorosa e di contestare. Ora andiamo a vedere. Dice, ma uno qua se ne fa qualcosa grazie alla conoscenza dell’atto di moto se riuscite a ricostruire come f l’atto di moto di un corpo rigido su un intervallo temporale potete grazie a condizioni iniziali ricostruire il moto del vostro. Comunque qui possiamo fare un catalogo completo degli atti di moto perché gli atti di moto sono fondamentalmente quattro e vedremo che in realtà ci possiamo ridurre tranquillamente. A3. Nel caso del corpo liquido piano ci ridurremo due possibili a Allora, cominciamo dall’atto di moto traslator. Allora, diciamo che ehm In tal caso avete che Bt è uguale BQ per ogni PQ appartenente al corpo ok? Non lo metto a T0 fissato perché questo è implicito nel defino rinoto che in un istante fissato l’atto di nuoto potrebbe cambiare da una frase un’altra del moto questo è Allora, questo significa che in quell’istante in cui vedamo questo atto di moto translatorio omega ug Allora, questo significa che tutti i punti di B hanno eh hanno la stessa velocità. Questo è possibile se solo se omega è uguale a perché vale la legge ispuzione della velocità. Allora di t =q se metter omega 0 non avete l’atto di nuovo tratto la d’accordo? Cosa? Ma se avesse un corpo di un moto trasatorio è tanto di nuovo perché dietro è uguale a 0 in ogni istante. D’accordo? Allora, adesso facciamo diamo un’altra izione quadro. Allora, atto di moto roto traslatorio. Allora, l’atto di moto rotto tratuatorio viene caratterizzato sostanzial ente dal fatto che, come sappiamo, vale la legge di distribuzione delle velocità e quindi dovrà valere per ogni zero fissato esattamente quella legge di sostituzione velocità. Chiedi diamo una definizione che nella sostanza ci fa capire esattamente quella cosa lì. Allora, l’atto di mossa di B è il caso se 1 direzione privilegiata la chiamiamo RP d’accordo? Per indicare che è una direzione più scale che ogni direzione R parallela ad R è luogo di punti Q ug velocità Sì. Allora, vale la legge di distribuzione della velocità sappiamo che d è uguale a d + omega vettor n q. Questa dovrà per forza essere anche ad un istante vale per ogni tale anche t0. Quindi questa non la possiamo certamente scavallare anche per caricare è una informazione fondamentale che dobbiamo avere a disposizione. Allora, Omega è parallela ad RP o dovrei scrivere meglio RP parallelo ad Omega, ok? E dà quindi la direzione privilegiata Ok? Allora, se prendete P Q appartenente a R con R parallela alla direzione privilegiata, cosa vi succede? Che scrivete VP =q + omega vettor in Q, ma Prima in Q appartiene a R che quindi prima in Q è parallelo a omega e quindi questo pezzo è per definizione di questo asso di moto. D’accordo? Oh, poi quando che quando scriviamo uguale b + omega vettor t, allora diciamo che l’atto di mo è riferito al punto Q e ci bastano ci basta conoscere RQ ed omega per dare dioto di ogni punto per un latimo moto di P che ogni volta sottintesa. D’accordo? Possiamo anche dire qualcosa in più che vi fa capire l’importante questo di moto. che è il più generale possibile, dico subito più generale della legge di distribuzione delle velocità. Non vi potete aspettare di avere niente. C’è un teorema che dice che un sistema S di N punti materiali, ma potrebbe anche essere un continuo aereo dico questa cosa potrebbe anche essere un porchinio, quindi aver infinito per la potenza del porchio è in moto se è solo l’atto di moto di S è è prototizio e nonista. Beh, qui non abbiamo niente da dimostrare perché la legge di distribuzione delle velocità l’abbiamo già dimostrata e quindi non abbiamo dimostrare Ok, allora abbiamo fatto l’atto di moto traslatorio. Vi direi che il più generale possibile degli atti not in realtà il più generale sarà in sotto caso, quindi non lo scrivo, non lo dico. Oh, diciamola così quando siccome è equiv alla legge diuzione delle velocità lo potete sempre scrivere, d’accordo? Sì, non c’è. Adesso ADM e poi avviene pro è tale se esiste una direzione RNA asse di mozi altro meccanico italiano eh con RM parallela alla direzione più. Ok? tale che i punti di questo asse sono paralleli alla direzione più del P. A ho detto una cosa orribile. I punti di questo asse di mozzi hanno velocità parallela alla direzione d parallela R. P per ogni P appartenente all’asse di Adesso ci avviciniamo. Vabbè, in realtà poi siccome negli esercizi vedere che sono corte rigidi di piani cosa succederà? Succederà che l’atto di moto ricord Non c’è l’atto di moto rotraso. Potete sempre scrivere di Q = VQ + Omega del Tor in Q per ovvi motivi perché a questo punto sono ovvi cioè la rete distione delle velocità che è semplice, ma l’atto di moto sarà o traslatorio, come vedremo fra poco, cioè tra poco non non rica troppo fuoco e eh oppure rotatorio che è quello che vi vado a scrivere l’emmoto rotatorio è un sotto caso del traslatorio in cui del rotto traslatorio in cui la direzione esiste una direzione parallela enunciate un po’ come questa. Che cosa? Allora, no?\nEh, sì, sì, va bene. Triviamolo di là, dai. Parliamo dell’atto di moto rotatorio. A questo punto l’atto di moto rotatorio. Cosa apriamo? La DM roto traslatorio. Si dice rotatorio da si riduce al rotatorio. Se esiste Reto asse di istantanea frazione tale che con ri parallelo una direzione privilegiata i cui punti hanno velocità nulla di P ugale 0 per ogni P appartenente a R. Allora, uno dice, “Ma cai appena raccontato il moto rotatore questo somiglia tantissimo il moto rotatorio. Attenzione che qui l’asse di moto rotatorio, l’asse non è un asse di rotazioni, quello è lì per tutta l’eternità, è un asse istantaneo, cioè in un istante può essere quello, in un altro istante ci può essere e ci sarà se lato di moto il rotatore istanti. un altro asso di istantanea equazione, istantanea e non necessariamente non necessariamente faccio osservare anche quest’altra cosa, avere atto di moto rotatorio significa che poi il moto è rotatorio. Non è vero, manco per niente perché il moto può essere rottiamo nello spazio per esempio con la Nel moto polare della protola con il punto fisso c’è un asse di istantanea rotazione, ma è istantanea rotazione, non è quell’asse lì fisso una volta. Va bene? Ho eh Quindi osservate che quando scrivete l’atto di moto, se prendete come riferimento il un punto dell’asse di istantanea rotazione, potete semplificare l’espressione. Qu ho scelto di chiamarlo fila è il punto del dell’asse finger di f più omega vettor 1 - p. Ok appartiene a ri asse istantanea rotazione. Allora questo va a zero. Vedete che si semplifica la scrittura delle velocità per l’altro punto. Ok? Allora, in questo caso andiamo subito a vedere il caso del cosmo rigido piano. Allora, qui compare un personaggio che sarà molto importante negli esercizi Sì, che è il centro stanziale. Allora, cosa succede nel caso del corpo diopano? Omega è perpendicolare al piano. Ok? Le velocità sono tutte nel piano. Ok. Che cosa succede? Bene, che vabbè, naturalmente il corpo rigido del piano, però se c’è un punto di velocità nulla, c’è un asso di istantanea rotazione automaticamente, questo lo vedremo fra poco passo l’informazione subito il se il corpo non è fermo. Trovate un punto E a velocità nulla, allora potete dire che lo zero che nato in modo è sicuramente di tipo rotatorio, il contenuto di un teorema che vediamo fra poco. Cosa succede? Che l’asse istantanea rotazione intersezione del piano mi dà questo. Questa R è perpendicolare qui. perché R che fa le? Allora, esiste punto di intersezione, questo è c che chiameremo centro di istantanea rotazione, cioè nel il corpo istantaneamente cerca di ruotare E questa stranazione è detto anche Cir Dorinanzi. Questo è un personaggio molto importante. Potete riferire se avete l’atto moto ropatorio, lato in moto 17% e quindi avere questa semplice. D’accordo. avere quella semplificazione. Vabbè, naturalmente diciamo c’è anche un’altra cosa subito. Se scoperite che avere un corpo rigido piano, l’atto di moto non è trasmatorio perché trovate due punti con velocità diverse, incluetevi immediatamente che omega deve essere diverso da Z0, allora l’atto di moto non può che essere rotatorio, specialmente è solo rotatorio. O è rotatorio o èatorio. più rendi. Questo lo vedo fra poco eh potete riferirvi al C quando costruite l’imoto, ma non siete impiccati a nel senso specifico che saltare unazione utile alle volte può essere difficile individuar. Allora scrivete atto di noto ripetito del punto di cui conoscete veloci. Questo è il messaggio che volevo darvi subito piuttosto che lasciarvi Oh, adesso ci serve una nozione, anche questa è importante perché entra nozione. Allora, eh variante scalare. cinematic. Evo scalare i per defin uguale a ptal omega, d’accordo? Dove appartiene al vostro corpo e omega è la velocità angolare. Possiamo dire per ogni f appartenza a potem questo oggetto è un’invariante nel senso che non dipende dalla certa di T. non dipende dalla scelta. Ok? Se prendiamo di uguale dq + omega vettor in q Cosa succede? Succede che trovate di T scala omega PQ + Omega vettor Qala omega. Quindi questo uguale di Q scala omega più che cosa? Omega vettor in Qalà omega e questo è zero perché questo vettore la definizione di prodotto vettoriale perpendicolare a Omega. Questa cosa l’abbiamo già vista quando abbiamo dimostrato la legge di distribuzione veloce. Quindi quello che succede è che comunque scegliate il punto del corpo rigido che fisca la omega è uguale fus omega è uguale a Tisca omega dove un ulteriore del corpo origine è un invariante l’invariante strane Questo invariante scalare è utile per formulare il cosiddetto teorema di Mozzi. Teorema di Mozzi che vi dice che in sostanza il generale atto di moto che potete avere per un corpo liquido è iliquidale con asse che coinci con asse di moto cosiddetto che coincide appunto con l’asse di Mozzi. Allora, per dimostrare quel teorema abbiamo bisogno, ci sono diverse dimostrazioni questo teorema e preferisco quella algebrica più in un certo senso più veloce. Eh, trovate anche delle dimostrazioni costruttive in letteratura. Io vi ho messo a disposizione, non so se siano in chiaro, vi ho messo a disposizione delle note su internet, sui in cui il teorema di Monti è dimostrato sviluppo in lago sia attraverso la strada costruttiva che attraverso la strada che usa un lemma che adesso andiamo a dimostrare. Sceglietevi la dimostrazione che preferite o seguite quella che ho fatto che farò con la macchina. Siete liberi di scegliere quella che vi lascia più tranquilli. D’accordo. Però alla fine le conclusioni ovviamente sono le stesse e sono del tutto allora abbiamo bisogno di questo lemma di calcolo vettoriale. L’EM è una composizione matematica ausiliaria per mostrare se non ve l’hanno se non per me capitato di sentire. Ma sì, dai, figuriamoci se non avete sentito la parola. Allora, siano a di vettori fissanti non nuli sia Ho l’origine Ok, l’equazione vettoriale. Ah, t- vettor a uguale a b. Avrei potuto scriverla come x volete x vettor a ug b. Però seguirò dove x risponde questo dove q- e Cere x. D’accordo? Avete queste equazioni, vorrete vedere se esistono e come sono fatte le soluzioni di quelle equazioni lì. X vett a = b è più familiare. Penso che sia più comoda per capire certi aspetti questa Quindi seguo questa Allora, contenuto positivo dell’emm è il seguente. L’equazione, chiamiamola e ammette soluzione Se è solo se a A B è uguale a 0. Questa è una cosa molto semplice da vedere. Poi se a scar b la soluzione della forma in realtà da un’equazione vettoriale vi aspettate un vettore su in realtà qui avete i vettori la soluzione alla forma di lambda - o uguale lambda a più a vettor b a² = a = norma di a al quadrato modulo di a chiam forma possibile due scritte, quindi d’accordo con lambda appartenen Rbitrale. D’accordo? Poi vi faccio periamolo punti di lambda al variare di lambda descrivono una retta parallela al vettore A. E se adesso facciamo la dimostrazione. La rimostrazione Come la impostiamo? La impostiamo semplicemente dicendo, guardando, la prima cosa che dobbiamo andare a vedere è cosa succede se A scor b è diverso da 0. Perché diciamo che non esiste soluzione. Se A^ B diverso da 0 soluzione. D’accordo? Sì, se esistesse il vettore segnato - tale che segnato - o vettor A ug. D’accordo? Se facciamo Il prodotto scalare com’è? Il prodotto sarà con A si avrebbe una contraddizione. Si avrebbe Vediamola subito, così convincete subito. Il segnato - vettor A scala a uguale a a scala T. Vabbè, lo devo mettere di là, ma tanto è la stessa cosa. Ah, questo oggetto è zero. che A scala B per ipotesi diversa da impossibile assurdo. Questo è zero perché perché questo prodotto vettoriale è ortogonale ad A, quindi quando faccio la proiezione su A non ce sta fa zero. Ci siamo? Allora, vedete, non esiste la soluzione se a B è diverso da Z0. Non ci sono non Non ci possiamo far niente. Adesso andiamo a vedere la seconda parte. Andiamo a vedere. Allora, sia a scar di ug1 2 risolvono nel senso che abbiamo T1 - vettor A = T2 - vettor A ug, no? Allora, adesso cerchiamo di vedere se ci sono soluzioni, comeè fatto il modo di fun che sono soluzione di questa equazione. Allora, cosa facciamo? Sottraiamo membro a membro e troviamo T1 nel T2 vettora uguale a 0. Sottraiamo membramento, no? Prodotto vettoriale lo lasciamo a destra. P1 - O - P2 - O fa P1 - P2, giusto? Allora, qui mi d fa 0 E quindi uno P2 vettor A. Sì, questa vettorinatura ci sta. Non è aperta. Fermatemi se non capite. Sprendo membro a membro otteniamo quello. Quindi vuol dire che T1 - P2 è parallelo a dunque i pi soluzione sono su una parallello. Adesso per costruire la soluzione facciamo i seguenti passaggi. Allora sia0 tale che0 - o è perpendicolare ad. Lo possiamo trovare questo punto, no? Andiamo dal punto o origine degli assi alla retta a e andiamo a prendere il punto di distanza minima da cuore fondamentalmente. Stiamo facendo questo minto. D’accordo? E lo troviamo da sicuro. Allora, consideriamo a vettor 0 - o vettorale uguale. Allora, ehm, scriviamolo adesso. Costruiamo una prima soluzione. Questo è quello che stiamo facendo attraverso questi passaggi algebrici, cioè stiamo andando a costruire una prima soluzione dell’equazione. Intanto osserviamo che cos’è. Questo è un trito prodotto vettoriale. Questo è uguale ad A² che moltiplica il vettore di 0 - O- a scal 0 - O. Pera a Sì, era il primo per il terzo. primo scalare il terzo per il secondo meno il primo scalare il secondo devi Ora questo pezzo è uguale, ok? Sia, attenzione, P0 - son, cioè 0 - A ug, così verifichiamo che 0, d’accordo? Allora, osservate vale a questo punto a a qua il 0 - o uguale ad a vett perché qui abbiamo moltiplicato, eh, e se questa è soluzione, questo deve essere anche uguale da vettor B. Questo è questo qua. Allora, scopriamo che effettivamente Vedete, possiamo ricavare 0- da quelle espressione, no? C’è qualche passaggio algebrico mentre soluzione delle equazioni richiedono qualche trick algebrico. L’abbiamo messo in opera in quella lavagna lì. Allora,0 - o uguale da vettor di 4. È vero che soluzione? Sì, se proprio veniamo a fare di San Tommasi lo verifi vale che a vettor b div quad è uguale eh vettor a è uguale lo rovesciamo a vettor rovesciamo anche dentro di vettor A tutto diviso a quadro e qui avete a qu - a scala b per a diviso questo fa zero per ipotesi perché a b fa 0 e vedete che eh che fa quindi una soluzione Se andiamo a considerare che consideriamo lambda - lambda a + a vettor b diviso a 4 con lambda alternali. Possiamo anche fissarlo se volete. Proviamo altre soluzioni. All ok. Per motivi direi, perché se facciamo pi lambda - vettor a questo si riduce ad a vettor B diviso quadro vettore a e questo quadro paralmente l’abbiamo appena visto perché perché il primo è fare il primo termine è parallelo a data vettoriale. Allora, facciamo il disegno quello così magari che lo schema vi rimane un po’ più più chiaro di quanto non possa risultare in questo momento. Diciamo qui c’è il punto ho assunto come origine, qui c’è la retta, qui c’è a, d’accordo? E qui c’è 0 perpendicolare perché 0- è per perpendicolare ad a. Ok? Allora, i pi lambda come sono fatti? Per lambda uguale a 0 li troviamo 0 e qui poi invece troveremo lambda - a lambda distante. Allora, vedete che tutti le punte di questi vett Allora, nessuno di questi vettori teplicamente è parallelo da non è di no. Questa è una cosa che può andare in più. Nessuno di questi vettori è parallelo ad un pezzo non par neanche per Ok. E perché dico la Quindi sommate per ogni lambda finito giustamente avete questi vettori che non sono parallele, ma questi vettori le punte i punti lambda che esprimono questa retta che è parallela. che è unica. Non possiamo pretendere avere un’altra che soddisf l’equazione che sia parallela ad A. Perché se facciamo esempio T0- A sappiamo che è parallelo. Se prendessimo un p asterisco che è fuori da questa retta qui dovremmo poi avere che t asterisco -0 data l’equazione e dato il nostro ragionamento sul parallelismo dei segmenti ottenuti sottraendo le varie soluzioni troveremo a risco nel P0 parallelo ad A, che non sarebbe possibile che rispostesse su un’altra retta parallele. Però questo direi che vi dà ragionamento che abbiamo Oh, tempo finito. Allora, questo lemma ci serve per dimostrare nei morti che facciamo domani. Se avete domande, se c’è qualcosa che non vi convince, dite, perché se vi piacete non è bello. Va bene, nessunoa, nessuno dice niente. Interrompiamo la registrazione."},"3--tag/Metodi-Analitici-per-le-Equazioni-alle-Derivate-Parziali":{"slug":"3--tag/Metodi-Analitici-per-le-Equazioni-alle-Derivate-Parziali","filePath":"3- tag/Metodi Analitici per le Equazioni alle Derivate Parziali.md","title":"Metodi Analitici per le Equazioni alle Derivate Parziali","links":[],"tags":[],"content":""},"3--tag/POLI.RADIO":{"slug":"3--tag/POLI.RADIO","filePath":"3- tag/POLI.RADIO.md","title":"POLI.RADIO","links":[],"tags":[],"content":""},"3--tag/analisi-3":{"slug":"3--tag/analisi-3","filePath":"3- tag/analisi 3.md","title":"analisi 3","links":[],"tags":[],"content":""},"3--tag/automatica":{"slug":"3--tag/automatica","filePath":"3- tag/automatica.md","title":"automatica","links":[],"tags":[],"content":""},"3--tag/chimica":{"slug":"3--tag/chimica","filePath":"3- tag/chimica.md","title":"chimica","links":[],"tags":[],"content":""},"3--tag/fisica-1":{"slug":"3--tag/fisica-1","filePath":"3- tag/fisica 1.md","title":"fisica 1","links":[],"tags":[],"content":""},"3--tag/los-sonideros":{"slug":"3--tag/los-sonideros","filePath":"3- tag/los sonideros.md","title":"los sonideros","links":[],"tags":[],"content":""},"3--tag/matematica-numerica":{"slug":"3--tag/matematica-numerica","filePath":"3- tag/matematica numerica.md","title":"matematica numerica","links":[],"tags":[],"content":""},"3--tag/materiale-di-studio":{"slug":"3--tag/materiale-di-studio","filePath":"3- tag/materiale di studio.md","title":"materiale di studio","links":[],"tags":[],"content":""},"3--tag/meccanica-razionale":{"slug":"3--tag/meccanica-razionale","filePath":"3- tag/meccanica razionale.md","title":"meccanica razionale","links":["6--full-note/meccanica-lez04","6--full-note/meccanica-lez05"],"tags":[],"content":"meccanica-lez04\nmeccanica-lez05"},"3--tag/pensieri":{"slug":"3--tag/pensieri","filePath":"3- tag/pensieri.md","title":"pensieri","links":[],"tags":[],"content":""},"3--tag/personale":{"slug":"3--tag/personale","filePath":"3- tag/personale.md","title":"personale","links":[],"tags":[],"content":""},"3--tag/probabilità":{"slug":"3--tag/probabilità","filePath":"3- tag/probabilità.md","title":"probabilità","links":[],"tags":[],"content":""},"3--tag/sbobine":{"slug":"3--tag/sbobine","filePath":"3- tag/sbobine.md","title":"sbobine","links":[],"tags":[],"content":""},"3--tag/settimana-2":{"slug":"3--tag/settimana-2","filePath":"3- tag/settimana 2.md","title":"settimana 2","links":["6--full-note/Matenum--lez03","6--full-note/Matenum--lez04","6--full-note/mateNum--Lez05","6--full-note/matenum-lab01","6--full-note/Prob--Ese01","6--full-note/prob-lez05","6--full-note/prob-lez06","6--full-note/prob-lez07","6--full-note/fisica1--Lez04","6--full-note/fisica1--Ese01","6--full-note/chimica-Lez01","6--full-note/chimica-Lez02","6--full-note/meccanica-lez01","6--full-note/meccanica-lez02","6--full-note/meccanica-lez03","6--full-note/meccanica-lez04","6--full-note/Analisi3--Lez08","/","6--full-note/Edp--lez05"],"tags":[],"content":"\nMatematica numerica\n\n.Matenum- lez03\n.Matenum- lez04*\nmateNum- Lez05\nmatenum-lab01.\n\n\nProbabilità\n\n.Prob- Ese01\nprob-lez05\nprob-lez06\n. prob-lez07\n\n\nFisica 1\n\nfisica1- Lez04\n.fisica1- Ese01*\n.\n.\n\n\n\n\n\nChimica\n\n.chimica-Lez01\n.chimica-Lez02\n.\n\n\nMeccanica Razionale\n\n.  meccanica-lez01\n.meccanica-lez02\n.meccanica-lez03\n. meccanica-lez04\n\n\nAnalisi III\n1.Analisi3- Lez08*\n\n\n\n\n\n\n\nAutomatica\n\n.\n.\n.\n\n\n\n\n\nEDP\n\n\n.Edp- lez05\n.\n.\n.\n"},"3--tag/trascrizione":{"slug":"3--tag/trascrizione","filePath":"3- tag/trascrizione.md","title":"trascrizione","links":[],"tags":[],"content":""},"3--tag/tutorial":{"slug":"3--tag/tutorial","filePath":"3- tag/tutorial.md","title":"tutorial","links":[],"tags":[],"content":""},"5-template/Full-Note":{"slug":"5-template/Full-Note","filePath":"5-template/Full Note.md","title":"Full Note","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"{{date}} {{time}}\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\n{{Title}}\nReferences"},"5-template/settimane":{"slug":"5-template/settimane","filePath":"5-template/settimane.md","title":"settimane","links":["tags/settimana_in_corso","3--tag/sbobine","/"],"tags":["settimana_in_corso"],"content":"{{date}} {{time}}\n_Status: settimana_in_corso\n_Tags: sbobine*\n{{Title}}\n\nMatematica numerica\n\n*\n*\n*\n*\n\n\nProbabilità\n\n*\n*\n*\n*\n\n\nFisica 1\n\n*\n*\n*\n*\n\n\n\n\n\nChimica\n\n*\n*\n*\n\n\nMeccanica Razionale\n\n*\n*\n*\n*\n\n\nAnalisi III\n\n*\n*\n\n\n\n\n\nAutomatica\n\n*\n*\n*\n\n\n\n\nReferences"},"6--full-note/Analisi3---programma":{"slug":"6--full-note/Analisi3---programma","filePath":"6- full note/Analisi3 - programma.md","title":"Analisi3 - programma","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/analisi-3","3--tag/materiale-di-studio","tags/"],"tags":["flashcard_zero","riscritto_zero","revisione_zero",""],"content":"2025-04-26 18:26\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:  analisi 3  materiale di studio\nAnalisi3 - programma\n Settimana 1.\nLezioni. Funzioni di variabile complessa. Derivabilità e differenziabilità. Equazioni di Cauchy-Riemann.  Equivalenza tra la derivabilità in senso complesso e la differenziabilità+Cauchy-Riemann (dim). Definizione di funzione olomorfa in un aperto. Curve nel piano complesso. Integrale di una funzione lungo una curva. Forme differenziali associate a una funzione olomorfa. Primitiva di una funzione. Relazione la differenziabilità o l’esistenza di una primitiva di una funzione di variabile complessa e le forme differenziali (reali) associate. Teorema dell’integrale nullo di Cauchy (dimostrazione nel caso C1). Esponenziale, seno e coseno di variabile complessa. Logaritmo, cenni alle funzioni polidrome.\nSettimana 2.\nLezione. Serie di potenze in C. Regione di convergenza puntuale e totale (dim). Derivabilità delle serie di potenze. Estensione analitica di funzioni di variabili reali.\nEsercitazioni. Ripasso sugli integrali impropri e sulle serie di potenze in C, prodotto alla Cauchy. Condizioni di Cauchy-Riemann.\nSettimana 3.\nLezioni. Formula di Cauchy (dim). Teorema di Weierstrass (dim). Formula delle derivate. Punti singolari. Serie di Laurent. Singolarità eliminabile, polo, singolarità essenziale.\nSettimana 4.\nLezione. Calcolo di residui. Punti di singolarità e residui all’infinito. Teorema dei residui. Introduzione ai lemmi di Jordan.\nEsercitazioni. Punti di singolarità, serie di Laurent e gli integrali di Fresnel.\nSettimana 5.\nLezione. Lemma di Jordan (dim). Spazi vettoriali normati  e con prodotto scalare. Spazi di Banach.\nEsercitazioni. Calcolo di residui. Calcolo integrale con la teoria dei residui.\nSettimana 6.\nLezione. Esempi 1 2di spazi di Banach e di spazi vettoriali normati non completi. Prodotto scalare, spazi di Hilbert. Spazio l2.\nEsercitazioni. Calcolo integrale con la teoria dei residui.\nSettimana 7.\nLezione. Disuguaglianza di Cauchy-Schwartz, uguaglianza del parallelogramma. Lo spazio l2. Basi Hilbertiane. Serie di Fourier generalizzate. Serie di seni e coseni. Identità di Parseval (dim). Ogni spazio di Hilbert separabile è isomorfo a l2 (dim).\nEsercitazioni. Serie di Fourier.\nSettimana 8.\nLezione. Cenni all’integrale di Lebesgue. Insiemi di misura nulla. Teorema di Fubini e della convergenza dominata. Spazi Lp. Disuguaglianza di Young (dim) e di Hölder (dim). C0(0,1) esempio di spazio prehilbertiano. Continuità del prodotto scalare.\nEsercitazione. Serie di Fourier.\nSettimana 9.\nLezione. Funzionali lineari continui su uno spazio vettoriale normato. Equivalenza di linearità e continuità (dim), norma dell’operatore. Esempi di funzionali lineari continui su C0 [a; b] (funzionale integrale, funzionale di valutazione in un punto). Spazio duale. Supporto di una funzione, funzioni Cinfinito a supporto compatto. Convergenza delle funzioni test. Distribuzioni, esempi: L1loc, delta di Dirac. Derivata di una distribuzione, la delta come derivata del gradino di Heaviside. Distribuzioni temperate.\nEsercitazione. Serie di Fourier.\nSettimana 10.\nLezione. Inclusione continua D in S, e S’ in D’. Supporto di una distribuzione. Spazio C00. Convergenza in L1 delle funzioni traslate (dim). Trasformata di Fourier. Teorema di Riemann-Lebesgue (dim).\nEsercitazione. Spazi Lp.\nSettimana 11.\nLezione. Derivata di una trasformata di Fourier (dim). Trasformata di Fourier di una derivata (dim). Antitrasformata. Trasformata di Fourier in L^2 (teorema di Plancherel, con dim). Trasformata di Fourier in S.\nEsercitazione. Distribuzioni.\nSettimana 12.\nLezione. Trasformata di Fourier in S’. Convoluzione in L1. Trasformata di Fourier di una convoluzione (dim). Teorema di Young Lp-Lq-Lr.\nEsercitazioni. Calcolo di trasformata e antitrasformata di Fourier in L1.\nSettimana 13.\nEsercitazioni. Calcolo di trasformata e antitrasformata di Fourier in L2 e S’.\nReferences"},"6--full-note/Analisi3--Lez07":{"slug":"6--full-note/Analisi3--Lez07","filePath":"6- full note/Analisi3- Lez07.md","title":"Analisi3- Lez07","links":["tags/flashcard_finite","tags/revisione_finita","tags/riscritto_finito","tags/domande","6--full-note/Analisi3--Lez07","3--tag/sbobine","paste/Lezione_AM_10_31.pdf"],"tags":["flashcard_finite","revisione_finita","riscritto_finito","domande"],"content":"2025-02-19 21:30\n_Status: flashcard_finite  revisione_finita   riscritto_finito domande\n_Tags: Analisi3- Lez07 sbobine\nlez07- Analisi3\nSpazi Vettoriali e Norme\n\nIl punto di partenza è la definizione di norma su uno spazio vettoriale.\nSia V uno spazio vettoriale su ℝ. Una norma su V è una funzione || ⋅ ||: V → ℝ che soddisfa le seguenti proprietà:\n\nNon negatività: ||x|| ≥ 0 per ogni x ∈ V\nDefinitezza: ||x|| = 0 se e solo se x = 0ᵥ (dove 0ᵥ è il vettore nullo di V).\nOmogeneità: ||tx|| = |t| ||x|| per ogni x ∈ V e t ∈ ℝ.\nDisuguaglianza triangolare: ||x + y|| ≤ ||x|| + ||y|| per ogni x, y ∈ V.\n\nSe uno spazio vettoriale V è dotato di una norma, la coppia (V, || ⋅ ||) è detta spazio normato. La norma generalizza l’idea di lunghezza di un vettore.\nSpazi Metrici\n\nLa norma induce naturalmente una distanza (o metrica) su V, definita come:\nd_{||.||}(x, y) = ||x - y||per ogni x, y ∈ V\nQuesta distanza soddisfa le proprietà fondamentali di una metrica:\n\nd(x, y) ≥ 0 per ogni x, y ∈ V, e d(x, y) = 0 se e solo se x = y\nd(x, y) = d(y, x) per ogni x, y ∈ V (simmetria)\nd(x, z) ≤ d(x, y) + d(y, z) per ogni x, y, z ∈ V (disuguaglianza triangolare)\n\nLa coppia (V, d), dove d è la distanza indotta dalla norma, è uno spazio metrico.\nConvergenza di Successioni\nIn uno spazio normato (e quindi anche metrico), si può definire la convergenza di una successione. Sia (V, || ⋅ ||) uno spazio normato e sia (xₙ) una successione in V.\n\n\nLa successione (xₙ) converge a x₀ ∈ V se per ogni ε &gt; 0 esiste un N ∈ ℕ tale che per ogni n &gt; N, ||xₙ - x₀|| &lt; ε. In altre parole:\nlim (n→∞) ||xₙ - x₀|| = 0\n\n\nLa successione (xₙ) è di Cauchy se per ogni ε &gt; 0 esiste un N ∈ ℕ tale che per ogni n, m &gt; N, ||xₙ - xₘ|| &lt; ε. In altre parole, i termini della successione diventano arbitrariamente vicini tra loro al crescere di n e m.\n\n\nOgni successione convergente è di Cauchy, ma il viceversa non è sempre vero.\nSpazi di Banach\n\nLa completezza è cruciale. Uno spazio normato (V, || ⋅ ||) è uno spazio di Banach se ogni successione di Cauchy in V converge a un limite che appartiene ancora a V. In termini di spazi metrici, uno spazio di Banach è uno spazio metrico completo rispetto alla metrica indotta dalla norma.\nEsempi\n\n\n\nℝⁿ con la norma euclidea è uno spazio di Banach. La norma euclidea è definita come:\n||x|| = √(x₁² + … + xₙ²) dove x = (x₁, …, xₙ)\n\n\nC⁰([a, b]), lo spazio delle funzioni continue sull’intervallo chiuso e limitato [a, b], con la norma del sup è uno spazio di Banach. La norma del sup è definita come:\n||f|| = max (x ∈ [a, b]) |f(x)|\nLa convergenza in questa norma è equivalente alla convergenza uniforme. cos&#039;è la convergenza uniforme???\n\n\nLo spazio CB, delle funzioni continue e limitate su tutto ℝ, con la norma del sup è uno spazio di Banach.\n\n\nControesempi\n\nÈ importante notare che non tutti gli spazi normati sono di Banach. Il professore ha fornito alcuni esempi di spazi che “hanno buchi”, cioè contengono successioni di Cauchy che non convergono a un elemento dello spazio.\n\n\nC⁰([a, b]) con la norma L¹ non è uno spazio di Banach. La norma L¹ è definita come:\n||f|| = ∫ₐᵇ |f(x)| dx\nIn questo caso, si possono trovare successioni di funzioni continue la cui distanza, misurata con l’integrale del valore assoluto della differenza, tende a zero, ma che convergono a una funzione discontinua (che quindi non appartiene allo spazio C⁰([a, b])).\nUn esempio specifico fornito dal professore:\nSi consideri l’intervallo \\ e la successione di funzioni fₙ definite come:\nfₙ(x) = 0 se 0 ≤ x ≤ 1/2\nfₙ(x) = 2ⁿ(x - 1/2) se 1/2 &lt; x ≤ 1/2 + 1/2ⁿ\nfₙ(x) = 1 se 1/2 + 1/2ⁿ &lt; x ≤ 1\nQueste funzioni sono continue sull’intervallo . Tuttavia, questa successione è di Cauchy rispetto alla norma L¹, ma converge a una funzione discontinua. La funzione limite sarebbe:\nf(x) = 0 se 0 ≤ x ≤ 1/2\nf(x) = 1 se 1/2 &lt; x ≤ 1\nQuesta funzione limite non è continua in x = 1/2, quindi non appartiene a C⁰(). Questo dimostra che C⁰() con la norma L¹ non è completo.\n\n\nLo spazio C₀ delle funzioni continue a supporto compatto non è uno spazio di Banach. In questo spazio, si considera la norma del sup, ma le successioni di Cauchy possono convergere a funzioni che non hanno supporto compatto.\nUn esempio è dato dalla successione:\nfₙ(x) = e^(-x²) se |x| &lt; n\nfₙ(x) = e^(-n²) (n + 1 - |x|) se n ≤ |x| ≤ n + 1\nfₙ(x) = 0 se |x| &gt; n + 1\nQueste funzioni sono continue e hanno supporto compatto. Tuttavia, la successione converge (rispetto alla norma del sup) alla funzione:\nf(x) = e^(-x²)\nche è continua e limitata su tutto ℝ, ma non ha supporto compatto. Questo mostra che C₀ non è uno spazio di Banach.\n\n\nFunzioni continue tra spazi normati\nSiano V1 e V2 due spazi normati. Una funzione L: V1 → V2 è continua in x₀ ∈ V1 se per ogni ε &gt; 0 esiste δ &gt; 0 tale che:\n||L(x) - L(x₀)||&lt; ε per ogni x ∈ V1 tale che ||x - x₀|| &lt; δ\nEquivalentemente, L è continua in x₀ se e solo se per ogni successione xₙ in V1 convergente a x₀, la successione L(xₙ) converge a L(x₀) in V2.\nContinuità di applicazioni lineari\nSiano V1 e V2 spazi normati e sia L: V1 → V2 una applicazione lineare. Sono equivalenti le seguenti affermazioni:\n\nL è continua in ogni punto di V1.\nL è continua in 0 (il vettore nullo di V1).\nEsiste una costante M &gt; 0 tale che ||L(x)|| ≤ M ||x|| per ogni x ∈ V1.\n\nReferences: Lezione_AM_10_31.pdf"},"6--full-note/Analisi3--Lez08":{"slug":"6--full-note/Analisi3--Lez08","filePath":"6- full note/Analisi3- Lez08.md","title":"Analisi3- Lez08","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/analisi-3"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-02 19:20\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:   sbobine   analisi 3\nAnalisi3- Lez08\nProdotto Scalare su uno Spazio Vettoriale V\n\nSia V uno spazio vettoriale reale (\\mathbb{R}-spazio vettoriale). Un prodotto scalare su V è una funzione che prende due elementi di V e restituisce un numero reale, soddisfacendo le seguenti proprietà:\n\nProprietà del Prodotto Scalare\n\nBilinearità: Il prodotto scalare è lineare in entrambe le variabili.\n\nRispetto alla somma: \\langle x + y, z \\rangle = \\langle x, z \\rangle + \\langle y, z \\rangle per ogni x, y, z \\in V\nRispetto al prodotto per scalare: \\langle Tx, y \\rangle = T \\langle x, y \\rangle per ogni x, y \\in V e T \\in \\mathbb{R} Nota che Tx è il prodotto dello scalare T per il vettore x, mentre \\langle x, y \\rangle è il prodotto di due numeri reali.\n\n\nSimmetria: \\langle x, y \\rangle = \\langle y, x \\rangle per ogni x, y \\in V\n\nQuesta proprietà è simile alla proprietà commutativa.\n\n\nDefinita Positività: \\langle x, x \\rangle \\geq 0 per ogni x \\in V e \\langle x, x \\rangle = 0 se e solo se x = 0, dove 0 è il vettore nullo di V\n\nQuesta proprietà caratterizza veramente il prodotto scalare: il prodotto scalare di un vettore con se stesso è sempre maggiore o uguale a zero, e si annulla solo nell’origine.\n\n\n\nSpazio Preilbertiano\nLa coppia (V, \\langle \\cdot, \\cdot \\rangle), dove V è uno spazio vettoriale e \\langle \\cdot, \\cdot \\rangle è un prodotto scalare su V, è chiamato spazio preHilbertiano.\n\nQuesto è analogo a come uno spazio normato è definito con una norma. Gli spazi di Banach sono un caso particolare di spazi normati. Allo stesso modo, gli spazi di Hilbert sono un caso particolare di spazi preHilbertiani.\n\nEsempio Prototipo: \\mathbb{R}^n\nL’esempio da tenere a mente è \\mathbb{R}^n (con n = 2, 3, ...) con il suo prodotto scalare standard:\n\\langle x, y \\rangle = x_1y_1 + x_2y_2 + ... + x_ny_n\nNorma Indotta da un Prodotto Scalare\nIn uno spazio preilbertiano V, è possibile definire una norma a partire dal prodotto scalare:\n|x| = ||x||_{\\langle \\ , \\ \\rangle}= \\sqrt{\\langle x, x \\rangle} per ogni x \\in V\n\nQuesta norma è ben definita grazie alla proprietà di definita positività del prodotto scalare.\n\nProprietà Fondamentali\n\nDisuguaglianza di Cauchy-Schwarz: Per ogni x, y \\in V, |\\langle x, y \\rangle| \\leq |x| |y|\nV è uno Spazio Normato: La funzione |x| definita sopra è una norma su V. Quindi, (V, |\\cdot|) è uno spazio normato.\nIdentità del Parallelogramma: Per ogni x, y \\in V, |x + y|^2 + |x - y|^2 = 2(|x|^2 + |y|^2)\n\nQuesta identità è facilmente verificabile usando la definizione di norma e le proprietà del prodotto scalare.\n\n\n\nConseguenze\n\nGli spazi preilbertiani sono casi particolari di spazi normati. Quindi, concetti come successioni convergenti, successioni di Cauchy e distanza sono applicabili.\n\nConseguenze “Geometriche”\nSia V uno spazio preilbertiano.\n\n\nApplicazione Lineare Limitata: Dalla disuguaglianza di Cauchy-Schwarz, per ogni y \\in V fissato, l’applicazione lineare L_y: V \\rightarrow \\mathbb{R} definita da L_y(x) = \\langle x, y \\rangle è limitata e continua.\n\n\nLa norma di L_y è |y|= M.\n\n\n\n\nAngolo tra Due Vettori: Dalla disuguaglianza di Cauchy-Schwarz, Se x, y \\in V sono non nulli, allora -1 \\leq \\frac{\\langle x, y \\rangle}{|x| |y|} \\leq 1\n\n\n\nEsiste un unico \\theta \\in [0, \\pi] tale che \\cos(\\theta) = \\frac{\\langle x, y \\rangle}{|x| |y|}.\n\n\n\\theta rappresenta l’angolo convesso tra i vettori x e y.\n\n\nL’esistenza di un angolo tra due vettori dipende dal prodotto scalare, non solo dalla norma.\n\n\n\n\nOrtogonalità: Due vettori x, y \\in V sono ortogonali se \\langle x, y \\rangle = 0.\n\nSe x e y sono non nulli, l’angolo tra loro è \\pi/2.\n\n\n\nTeorema di Pitagora\n\nSe x, y \\in V sono ortogonali, allora\n|x + y|^2 = |x|^2 + |y|^2\n\nQuesto è il teorema di Pitagora in uno spazio di Hilbert.\nGeneralizzazione: Se x_1, ..., x_n \\in V sono tali che \\langle x_i, x_j \\rangle = 0 per ogni i \\neq j, allora \\left|\\sum_{m=1}^{n} x_m\\right|^2 = \\sum_{m=1}^{n} |x_m|^2\n\nIn generale, in uno spazio normato, si ha solo la disuguaglianza triangolare.\n\n\n\nSpazio di Hilbert\n\nUno spazio di Hilbert è uno spazio preilbertiano (V, \\langle \\cdot, \\cdot \\rangle) tale che lo spazio normato (V, |\\cdot|), dove |x| = \\sqrt{\\langle x, x \\rangle}, è uno spazio di Banach.\n\nIn altre parole, ogni successione di Cauchy in V converge a un limite in V.\nUno spazio di Hilbert è un particolare spazio di Banach in cui la norma deriva da un prodotto scalare.\n\nEsempi di Spazi di Hilbert\n1. \\mathbb{R}^n come Spazio di Hilbert\n\n\nConsideriamo \\mathbb{R}^n con n \\geq 1.\n\n\nDefiniamo il prodotto scalare tra due vettori x, y \\in \\mathbb{R}^n come:\n\\qquad \\langle x, y \\rangle = x_1y_1 + x_2y_2 + \\dots + x_ny_n = \\sum_{i=1}^{n} x_i y_i\n\n\nLa norma indotta da questo prodotto scalare è la norma euclidea:\n\\qquad ||x|| = \\sqrt{\\langle x, x \\rangle} = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2} = \\sqrt{\\sum_{i=1}^{n} x_i^2}\n\n\nPoiché \\mathbb{R}^n con la norma euclidea è uno spazio di Banach, allora \\mathbb{R}^n con il prodotto scalare standard è uno spazio di Hilbert.\n\n\n2. Spazio delle Funzioni Continue su un Intervallo\n\n\nConsideriamo lo spazio C^0([a, b]) delle funzioni continue sull’intervallo [a, b].\n\n\nDefiniamo un prodotto scalare tra due funzioni f, g \\in C^0([a, b]) tali da ottenere un numero:\n\\qquad \\langle f, g \\rangle = \\int_a^b f(x)g(x) , dx\n\n\nLa norma associata a questo prodotto scalare è:\n\\qquad ||f|| = \\sqrt{\\langle f, f \\rangle} = \\sqrt{\\int_a^b f(x)^2 , dx}\n\n\nImportante: Questo spazio, con questa norma, non è uno spazio di Hilbert, perché non è completo. La norma integrale che abbiamo visto essere una norma rispetto a cui questo spazio non è completo, quindi non è uno spazio di Banach.\n\n_La norma di f non è proprio l’integrale tra a e b di |f|, ma è una cosa che relativamente ci assomiglia. È l’integrale tra A e B di, f^2 1/2.\n_Non abbiamo veramente dimostrato l’altra volta, però insomma capite che l’altra volta avevamo l’integrale del modulo di f, qui abbiamo l’integrale di f^2 1/2, non è strutturalmente molto diversa dalla norma integrale che abbiamo visto l’altra volta.\n\n\n\nSpazi Normati e Spazi Prehilbertiani\n\n\nNon tutti gli spazi normati sono spazi prehilbertiani.\n\n\nEsiste una caratterizzazione precisa: uno spazio normato V con una norma ||\\cdot|| è uno spazio prehilbertiano (cioè, la sua norma deriva da un prodotto scalare) se e solo se la norma soddisfa l’identità del parallelogramma:\n\\qquad ||x + y||^2 + ||x - y||^2 = 2(||x||^2 + ||y||^2) per ogni x, y \\in V\n\n\nSe la norma di uno spazio normato non soddisfa l’identità del parallelogramma, allora non esiste un prodotto scalare che induca quella norma.\n\n\nAd esempio, la norma del “massimo” (sup) non soddisfa l’identità del parallelogramma e quindi non proviene da un prodotto scalare.\n\n\nTeorema della Proiezione\nQuesto teorema è fondamentale nel contesto degli spazi di Hilbert.\nIpotesi\n\nSia V uno spazio di Hilbert.\nSia E \\subseteq V un sottospazio di dimensione finita n \\geq 1.\nSia \\mathcal{E}=\\set{e_1, e_2, \\dots, e_n} una base ortonormale di E.\n\n\\qquad \\langle e_i, e_j \\rangle = \\begin{cases} 1, &amp; \\text{se } i = j \\quad (\\text{ossia } |e_i|=0),\\\\ 0, &amp; \\text{se } i \\neq j \\end{cases}\n\n\n\nDefinizione\n\n\nDato x \\in V, definiamo la proiezione di x su E come:\n\\qquad P_E(x) = \\sum_{m=1}^n \\langle x, e_m \\rangle e_m \\ \\in {E}\nDove \\langle x, e_m \\rangle := \\hat x_m è il prodotto scalare tra x e e_m.\n\n\n\nTesi\n\n\n||x - P_E(x)|| \\leq ||x - y|| per ogni y \\in E.\n\nP_E(x) è l’elemento di E che minimizza la distanza da x.\nQuesta è la distanza rispetto alla norma indotta dal prodotto scalare di x da y.\nLa distanza di x_0 è minore o uguale della distanza di x da y per ogni altro y in E.\n\n\n\nIl vettore x - P_E(x) è ortogonale a ogni elemento di E, cioè \\langle x - P_E(x), y \\rangle = 0 per ogni y \\in E.\n\n\n\\sum_{m=1}^n |\\langle x, e_m \\rangle|^2 \\leq ||x||^2.\n\n\nP_E(x) è l’unico elemento di E che soddisfa le proprietà 1 e 2.\n\n\nP_E(x) è detta la proiezione ortogonale di x su E.\nIllustrazione\n\nImmagina V come uno spazio vettoriale e E come un sottospazio di dimensione finita (ad esempio, una retta) contenuto in V. Dato un punto x in V, il teorema della proiezione afferma che esiste un unico punto in E (la proiezione ortogonale P_E(x)) che è il più vicino a x . Inoltre, la differenza tra x e la sua proiezione è perpendicolare a E .\nChiarimento sulla natura vettoriale della proiezione\nPer visualizzare P_E(x) come vettore, è necessario fissare un’origine all’interno del sottospazio E. Poiché E è uno spazio vettoriale, contiene un elemento zero. Il vettore P_E(x) può quindi essere inteso come il vettore che parte dall’origine di E e arriva al punto P_E(x) stesso.\nSistemi Ortonormali e Sistemi Ortonormali Completi\nSistema Ortonormale\n\n\nSia V uno spazio di Hilbert.\n\n\nUna successione di elementi {e_n}_{n \\geq 1} in V è detta sistema ortonormale se:\n\\qquad \\langle e_i, e_j \\rangle = \\begin{cases} 1, &amp; \\text{se } i = j \\\\ 0, &amp; \\text{se } i \\neq j \\end{cases}\nIn altre parole, i vettori sono a due a due ortogonali e hanno norma 1.\n\n\nSistema Ortonormale Completo (SONC)\n\nUn sistema ortonormale \\set{e_n}_{n \\geq 1} è detto completo se l’unico vettore x \\in V ortogonale a tutti gli elementi del sistema è il vettore nullo.\n\nIn formule: se \\langle x, e_n \\rangle = 0 per ogni n, allora x = 0.\n\n\n\nDisuguaglianza di Bessel\nSia V uno spazio di Hilbert e {e_n}_{n \\geq 1} un sistema ortonormale in V. Allora, per ogni x \\in V:\n\\qquad \\sum_{m=1}^n |\\langle x, e_m \\rangle|^2 \\leq ||x||^2\n\nQuesta disuguaglianza vale per ogni n e quindi si può estendere al limite per n \\to \\infty.\nPoiché la serie è a termini non negativi, converge.\nUna condizione necessaria (ma non sufficiente) per la convergenza di una serie è che il termine ennesimo tenda a zero: \\lim_{n \\to \\infty} \\langle x, e_n \\rangle = 0.\n\nTeorema di Fourier\nQuesto teorema mostra come un sistema ortonormale completo (SONC) può essere utilizzato per rappresentare qualsiasi vettore in uno spazio di Hilbert.\nIpotesi\n\nSia V uno spazio di Hilbert.\nSia {e_n}_{n \\geq 1} un sistema ortonormale completo (SONC) in V.\nPer ogni x \\in V, definiamo i coefficienti di Fourier come x_n = \\langle x, e_n \\rangle per ogni n \\geq 1.\n\nTesi\n\n\nOgni vettore x \\in V può essere scritto come una serie convergente:\n\\qquad x = \\sum_{n=1}^\\infty x_n e_n = \\sum_{n=1}^\\infty \\langle x, e_n \\rangle e_n\nCioè, il limite per n che va a più infinito della norma di x - la successione delle somme parziali è zero.\n\n\nUguaglianza di Parseval:\n\\qquad ||x||^2 = \\sum_{n=1}^\\infty |x_n|^2 = \\sum_{n=1}^\\infty |\\langle x, e_n \\rangle|^2\n\n\nSe y \\in V e y_n = \\langle y, e_n \\rangle, allora:\n\\qquad \\langle x, y \\rangle = \\sum_{n=1}^\\infty x_n \\overline{y_n} = \\sum_{n=1}^\\infty \\langle x, e_n \\rangle \\overline{\\langle y, e_n \\rangle}\ndove \\overline{y_n} indica il complesso coniugato di y_n (se stiamo lavorando con spazi di Hilbert complessi). Questo significa che il prodotto scalare assume un aspetto simile a quello di \\mathbb{R}^n.\n\n\nIn sostanza, un sistema ortonormale completo gioca il ruolo di una base, anche in spazi di dimensione infinita. Ogni vettore può essere espresso come combinazione lineare (in forma di serie) degli elementi del sistema.\n\nGeneralizzazione a Spazi di Dimensione Infinita\nIl professore accenna alla possibilità di estendere questi concetti a spazi di dimensione infinita, introducendo il concetto di sistema ortonormale completo.\nSistemi Ortonormali e Completi\nDefinizione\nUn sistema ortonormale \\mathcal{E} in uno spazio di Hilbert V è una successione di vettori \\mathcal{E}=\\set{e_n}_{n \\geq 1} \\subseteq V tale che:\n\\qquad \\langle e_i, e_j \\rangle = \\begin{cases} 1, &amp; \\text{se } i = j \\\\ 0, &amp; \\text{se } i \\neq j \\end{cases}\nUn sistema ortonormale è completo (sonc) \\mathcal{E}  è un sistema ortonormale di V\ne se l’unico vettore x in V che è ortogonale a tutti gli elementi del sistema è il vettore nullo:\n\\qquad \\langle x, e_n \\rangle = 0 \\quad \\forall n \\implies x = 0_V\nDisuguaglianza di Bessel\nDato un sistema ortonormale {e_n}_{n \\geq 1} in uno spazio di Hilbert V, per ogni x in V vale la disuguaglianza di Bessel:\n\\qquad \\sum_{n=1}^{\\infty} |\\langle x, e_n \\rangle|^2 \\leq |x|^2\nQuesta disuguaglianza implica che la serie converge.\nTeorema di Fourier\nSia {e_n}_{n \\geq 1} un sistema ortonormale completo in uno spazio di Hilbert V. Allora, per ogni x in V:\n\nEspansione in Serie: x = \\sum_{n=1}^{\\infty} \\langle x, e_n \\rangle e_n\nUguaglianza di Parseval: |x|^2 = \\sum_{n=1}^{\\infty} |\\langle x, e_n \\rangle|^2\nProdotto Scalare: Per ogni y \\in V, \\langle x, y \\rangle = \\sum_{n=1}^{\\infty} \\langle x, e_n \\rangle \\langle y, e_n \\rangle\n\nIl professore sottolinea che questo teorema sarà dimostrato nella prossima lezione e verrà applicato alle serie di Fourier.\n\nSpazi di Hilbert e Sistemi Ortonormali\nOsservazione Preliminare\nAnche se la definizione di sistema ortonormale potrebbe essere data in uno spazio prehilbertiano, tradizionalmente si preferisce darla in uno spazio di Hilbert. Questo perché, sebbene la definizione utilizzi solo il prodotto scalare, le osservazioni successive richiedono la completezza dello spazio normato.\nDefinizione di Sistema Ortonormale\nConsideriamo uno spazio di Hilbert V e una successione di elementi e_n in V, con n \\geq 1. Questa successione è un sistema ortonormale se soddisfa le seguenti condizioni:\n\nOrtogonalità: (e_i, e_j) = 0 per i \\neq j.\nNormalizzazione: |e_i| = 1 per ogni i. Questo significa che il prodotto scalare (e_i, e_i) = 1.\n\nTeorema della Proiezione e Spazi di Dimensione Finita\n\nPer utilizzare il teorema della proiezione, è necessario avere uno spazio di dimensione finita. Definiamo quindi uno spazio E_n come lo span dei primi n elementi del sistema ortonormale:\nE_n = \\text{span}(e_1, e_2, ..., e_n)\nQuesto spazio E_n è di dimensione finita perché è generato da n vettori.\nDisuguaglianza di Bessel\nPer ogni x \\in V, vale la seguente disuguaglianza:\n\\sum_{m=1}^{n} |\\langle x, e_m \\rangle|^2 \\leq |x|^2\nDove \\langle x, e_m \\rangle= \\hat x rappresenta il prodotto scalare tra x e e_m. Nel contesto del teorema della proiezione, \\langle x, e_m \\rangle è chiamato x \\text{ cappuccio } m.\nPoiché questa disuguaglianza vale per ogni n, possiamo estendere la somma all’infinito:\n\\sum_{n=1}^{\\infty} |\\langle x, e_m \\rangle|^2 \\leq |x|^2\nQuesta è la disuguaglianza di Bessel. La serie è a termini non negativi (quadrati), quindi converge o diverge positivamente. Questo implica che la serie converge.\nConseguenza della Convergenza\nSe una serie converge, il limite del termine ennesimo deve tendere a zero. Quindi:\n\\lim_{n \\to \\infty} \\langle x, e_m \\rangle = 0\nDefinizione di Sistema Ortonormale Completo (SONC)\nUn sistema ortonormale E = {e_n}_{n \\geq 1} è completo in V se:\n\nE è un sistema ortonormale in V.\nSe \\langle x, e_m \\rangle = 0 per ogni n, allora x = 0. In altre parole, l’unico vettore ortogonale a tutti gli elementi del sistema è il vettore nullo.\n\nTeorema di Fourier\nSia V uno spazio di Hilbert e E = {e_n}_{n \\geq 1} un sistema ortonormale completo (SONC) in V. Per ogni x \\in V, definiamo i coefficienti di Fourier come:\n\\hat x_n = \\langle x, e_m \\rangle per ogni m \\geq 1\nAllora valgono le seguenti affermazioni:\n\n\nEspansione di Fourier: x = \\sum_{n=1}^{\\infty} (\\hat x_n) e_n = \\sum_{n=1}^{\\infty} (x, e_n) e_n\nQuesta uguaglianza è intesa nel senso della convergenza in norma, cioè:\n\\lim_{N \\to \\infty} \\left| x - \\sum_{n=1}^{N} (x, e_n) e_n \\right| = 0\n\n\nIdentità di Parseval:\n|x|^2 = \\sum_{n=1}^{\\infty} |\\hat x_m|^2\n\n\nGeneralizzazione del Prodotto Scalare:\nPer ogni x, y \\in V, sia \\hat y_n = \\langle y, e_n \\rangle. Allora:\n\\langle x, y\\rangle = \\sum_{n=1}^{\\infty} (\\hat x_n) {\\hat y_n} = \\sum_{n=1}^{\\infty} (x, e_n) {(y, e_n)}\nQuesta serie converge al prodotto scalare tra x e y.\n\n\nInterpretazione del Teorema di Fourier\nUn sistema ortonormale completo gioca il ruolo di una base. Ogni x può essere scritto come una serie di termini che coinvolgono gli elementi del sistema ortonormale.\nReferences"},"6--full-note/Autm---Lez01":{"slug":"6--full-note/Autm---Lez01","filePath":"6- full note/Autm - Lez01.md","title":"Autm - Lez01","links":["3--tag/automatica","3--tag/sbobine","tags/revisione_finita","tags/flashcard_finite","tags/riscritto_finito"],"tags":["revisione_finita","flashcard_finite","riscritto_finito"],"content":"tags: automatica sbobine\nstato: revisione_finita flashcard_finite  riscritto_finito\nIntroduzione ai Sistemi Dinamici\nI sistemi dinamici sono l’argomento centrale del corso. L’obiettivo è comprenderli gradualmente attraverso esempi e concetti introduttivi.\nDefinizione di Segnale\nPrima di studiare i sistemi dinamici, è essenziale definire il concetto di segnale, dato che un sistema dinamico è un modello matematico che descrive le relazioni tra più segnali.\nCos’è un Segnale?\nUn segnale è definito come “una funzione del tempo”, rappresentata genericamente come ( V(t) ), dove ( t ) è la variabile indipendente che indica il tempo.\nTempo Continuo vs. Tempo Discreto\nÈ fondamentale distinguere tra tempo continuo e tempo discreto:\n\nTempo Continuo: ( t ) appartiene all’insieme dei numeri reali t \\in \\mathbb{R}.\nTempo Discreto: ( t ) appartiene all’insieme dei numeri interi non negativi (solitamente i numeri naturali,  t \\in \\mathbb{N}, ovvero ( 0, 1, 2, … )).\n\nSegnali a Tempo Continuo\n\nUn segnale a tempo continuo è definito su una variabile temporale reale e può essere rappresentato graficamente su un piano cartesiano con il tempo ( t ) sull’asse orizzontale e il segnale ( V(t) ) sull’asse verticale.\nEsempi:\n\nRegistrazione continua della temperatura tramite un sensore.\nMisurazione della velocità di una macchina di Formula 1 durante un giro.\nQualsiasi problema di fisica che coinvolge posizione, velocità e accelerazione di corpi in movimento.\n\nSegnali a Tempo Discreto\n\nUn segnale a tempo discreto è definito solo in istanti discreti ed è rappresentato da una successione di valori.\nEsempi:\n\nNumero di immatricolazioni in ingegneria per ogni anno accademico.\nValore dell’indice FTSE MIB alla chiusura della borsa di Milano alle ore 13.\n\nSegnali Campionati\n\nUn segnale campionato è un segnale a tempo continuo misurato a intervalli discreti.\nEsempio:\n\nTemperatura rilevata da un sensore meteorologico inviata ogni due ore.\n\nImportanza:\n\nI computer elaborano solo segnali a tempo discreto, rendendo necessario il campionamento dei segnali continui per l’elaborazione digitale.\n\nSistemi Dinamici\n\nUn sistema dinamico stabilisce una “relazione causa-effetto tra due segnali”.\n\nSegnale di Ingresso  U(t) : La “causa” che influenza il sistema.\nSegnale di Uscita Y(t) : L‘“effetto”, ovvero la risposta del sistema all’ingresso.\n\nCosa Non è un Sistema Dinamico (o algebrico)?\nAlcune relazioni causa-effetto sono troppo semplici per essere considerate sistemi dinamici.\nEsempi di sistemi non dinamici:\n\n\nResistore: La tensione ( V(t) ) ai capi di un resistore è data dalla legge di Ohm: V(t) = R \\cdot I(t) dove ( R ) è la resistenza e ( I(t) ) è la corrente. Questa relazione è istantanea: conoscendo ( I(t) ), si determina immediatamente ( V(t) ).\nRubinetto: La posizione del rubinetto ( U(t) ) determina istantaneamente la portata d’acqua in uscita ( Y(t) ).\n\nEsempi di Sistemi Dinamici\n\n\nVasca da Bagno: La portata d’acqua entrante ( U(t) ) influisce sul volume d’acqua nella vasca ( Y(t) ), ma la relazione non è istantanea. Il volume dipende dalla storia precedente (quanta acqua è stata fatta entrare, se la vasca era piena o vuota all’inizio).\n\n\nCondensatore: La relazione tra tensione ( V(t) ) e corrente ( I(t) ) in un condensatore è data da: C \\cdot \\frac{dV(t)}{dt} = I(t) dove ( C ) è la capacità del condensatore. Questa è una relazione differenziale, non istantanea.\n\n\nStato del Sistema\n\nPer rappresentare fenomeni più complessi, è necessario introdurre una terza variabile: lo stato del sistema X(t).\n\nEquazione di Stato: Descrive come lo stato evolve nel tempo.\nEquazione di Uscita: Descrive come l’uscita dipende dallo stato.\n\nStruttura Generale\nUn sistema dinamico può essere descritto dalle seguenti equazioni:\n\n\nEquazione di Stato: \\dot{x}(t) = f(x(t), u(t)) dove \\dot{x}(t) è la derivata dello stato rispetto al tempo, x(t) è lo stato del sistema e ( u(t) ) è l’ingresso.\n\n\nEquazione di Uscita: y(t) = g(x(t)) dove ( y(t) ) è l’uscita del sistema.\n\n\nstruttura generale\n\\begin{cases} \\dot{x}(t) = f(x(t), u(t)) \\\\ y(t) = g(x(t)) \\end{cases}Questa struttura è valida per sistemi a tempo continuo, dove esiste la derivata rispetto al tempo.\n\n\nEsempio: Serbatoio d’Acqua\n\nSi consideri un serbatoio con una portata d’acqua entrante ( U(t) ) e un deflusso proporzionale all’altezza ( h(t) ) dell’acqua.\n\nVariabile di Ingresso: Portata d’acqua entrante ( U(t) ) (metri cubi al secondo).\nVariabile di Uscita: Portata d’acqua uscente ( Y(t) ).\nVariabile di Stato: Volume d’acqua nella vasca ( V(t) ).\nDeflusso: Il deflusso supponiamo sia proporzionale all’altezza: Q_{uscita} = K \\cdot h(t) dove ( K ) è una costante.\nRelazione Geometrica: Il volume è dato da: V(t) = S \\cdot h(t) dove ( S ) è l’area della sezione della vasca.\n\nEquazione di Stato:\nLa variazione del volume nel tempo è data dal bilancio delle portate entranti e uscenti: \\dot{x}(t) = U(t) - K \\cdot h(t) Sostituendo h(t) con  X(t) / S (in modo da esplicitare la variabile di stato e l’ingresso): \\dot{x}(t) = U(t) - \\frac{K}{S} \\cdot V(t) Equazione di Uscita:\nL’uscita è il deflusso, quindi (ricordiamo che deve essere in funzione della variabile di stato): Y(t) = K \\cdot h(t) = \\frac{K}{S} \\cdot V(t) Ordine del Sistema:\nIn questo caso, l’ordine del sistema è 1, perché è sufficiente una sola variabile di stato per descriverlo.\nordine del sistema: n=1\nEsempio: Rete Elettrica\n\nConsidera una rete elettrica con un generatore di corrente, un resistore, un condensatore e un induttore.\n\nComponenti:\n\nGeneratore di corrente U(t).\nResistore  R  con V(t) = R \\cdot I(t) .\nCondensatore ( C ) con  C \\cdot \\frac{dV(t)}{dt} = I(t).\nInduttore ( L ) con  L \\cdot \\frac{dI(t)}{dt} = V(t) .\n\n\nLeggi di Kirchhoff: La somma delle correnti entranti in un nodo è uguale alla somma delle correnti uscenti; la somma delle tensioni in una maglia è zero.\n\nVariabili:\n\nIngresso: Corrente del generatore ( U(t) ).\nUscita: Tensione sul resistore ( Y(t) ).\nVariabili di Stato: Corrente nell’induttore  X_1(t) e tensione sul condensatore  X_2(t).\n\n\nEquazioni di Stato:\nSono necessarie due equazioni, una per ogni variabile di stato: \\dot{X_1}(t) = \\frac{1}{L} \\cdot (X_2(t) - R \\cdot X_1(t))\ncon (X_2(t) - R \\cdot X_1(t)) la legge di Kirchhoff alla maglia\n\\dot{X_2}(t) = \\frac{1}{C} \\cdot (U(t) - X_1(t))\nEquazione di Uscita:\nL’uscita è la tensione sul resistore: Y(t) = R \\cdot X_1(t) Ordine del Sistema:\nL’ordine del sistema è 2, perché ci sono due variabili di stato.\nSistemi a Tempo Discreto\nNei sistemi a tempo discreto, non esiste l’operatore differenziale, quindi l’equazione di stato non può essere un’equazione differenziale, ma un’equazione alle differenze.\nStruttura Generale\n\nEquazione di Stato: X(t+1) = f(X(t), U(t)) dove ( X(t+1) ) è il valore dello stato al prossimo istante di tempo, ( X(t) ) è lo stato attuale e ( U(t) ) è l’ingresso.\nEquazione di Uscita: Y(t) = g(X(t)) dove ( Y(t) ) è l’uscita del sistema.\n\nEsempio: Conto Corrente\n\n\nVariabile di Stato: Capitale sul conto ( X(t) ).\nVariabile di Ingresso: Versamento annuale ( U(t) ).\n\nEquazione di Stato:\nIl capitale all’anno successivo è dato dal capitale attuale più gli interessi e il versamento: X(t+1) = X(t) + r \\cdot X(t) + U(t) dove ( r ) è il tasso di interesse.\nEquazione di Uscita:\nL’uscita può essere il capitale sul conto: Y(t) = X(t) Oppure, in alternativa, il flusso di interessi generato ogni anno (dipende dalla scelta del tutto facoltativa): Y(t) = r \\cdot X(t)\nEsempio: Modello Compartimentale di una Scuola Media\nQuesto esempio descrive l’evoluzione degli allievi in una scuola media suddivisi in tre classi (prima, seconda e terza media).\n\nva subito esplicitato qual è la discretizzazione (t=1)\nSistema Compartimentale: Un sistema che descrive un insieme di individui divisi tra categorie (compartimenti) e tra istanti di tempo ci sono dei flussi di individui che passano da un compartimento e l’altro.\nVariabili di Stato: Numero di allievi in prima media X_1(t) , in seconda media  X_2(t)  e in terza media  X_3(t) .\nIngresso: Nuovi iscritti in prima media all’anno t+1 ( U(t) ).\nCoefficienti: Frazione di promossi \\alpha_i, bocciati  \\beta_i  e abbandoni \\gamma_i  per ogni classe i , con \\alpha_i + \\beta_i + \\gamma_i = 1 .\n\nEquazioni di Stato:\n\nDescrivono come cambia il numero di allievi in ogni classe da un anno all’altro: \\begin{cases} X_1(t+1) = \\beta_1 \\cdot X_1(t) + U(t) \\\\  X_2(t+1) = \\alpha_1 \\cdot X_1(t) + \\beta_2 \\cdot X_2(t) \\\\ X_3(t+1) = \\alpha_2 \\cdot X_2(t) + \\beta_3 \\cdot X_3(t)  \\end{cases}\nEquazioni di Uscita:\nL’uscita può rappresentare diverse quantità, a seconda dell’interesse:\n\nTotale degli allievi: Y(t) = X_1(t) + X_2(t) + X_3(t)\nAllievi che terminano il ciclo scolastico con successo: Y(t) = \\alpha_3 \\cdot X_3(t)\nAllievi che abbandonano la scuola: Y(t) = \\gamma_1 \\cdot X_1(t) + \\gamma_2 \\cdot X_2(t) + \\gamma_3 \\cdot X_3(t)\n\nStruttura Generale dei Modelli\nLa struttura generale dei modelli lega ingresso, stato e uscita attraverso due equazioni: l’equazione di stato e l’equazione di uscita . Questa struttura non è la più ampia e generale possibile, ma è quella più tipica quando si descrivono modelli derivanti dalla fisica .\n\n\n\n\n\nVettore di Stato:  X(t)  è un vettore n-dimensionale, dove n è l’ordine del sistema .\n\n\nVettore di Ingresso:  U(t)  è un vettore m-dimensionale, dove m è il numero di ingressi .\n\n\nVettore di Uscita:  Y(t) è un vettore p-dimensionale, dove p è il numero di uscite .\n\n\nNel corso, ci si limiterà quasi sempre ai sistemi SISO (Single Input, Single Output), ovvero con un solo ingresso e una sola uscita, l’opposto sarà il MIMO (multi input, multi Output) . Tuttavia, sarà inevitabile considerare sistemi con variabili di stato in numero maggiore di 1 .\n\n\n"},"6--full-note/Autm---Lez02":{"slug":"6--full-note/Autm---Lez02","filePath":"6- full note/Autm - Lez02.md","title":"Autm - Lez02","links":["tags/flashcard_zero","tags/riscritto_finito","tags/revisione_finita","3--tag/sbobine","3--tag/automatica"],"tags":["flashcard_zero","riscritto_finito","revisione_finita"],"content":"2025-02-26 16:16\n_Status: flashcard_zero  riscritto_finito   revisione_finita\n_Tags:  sbobine   automatica\nAutm - Lez02\nSistemi Dinamici Lineari: Movimento, Traiettoria ed Equilibrio\nStruttura di Base dei Sistemi Dinamici\n\n\n\nI sistemi dinamici considerati sono descritti attraverso un modello matematico strutturato in due equazioni:\n\n\nEquazione di stato: descrive il legame causa-effetto tra variabili d’ingresso u(t) e variabili di stato x(t).\n\n\nEquazione di uscita: descrive il legame causa-effetto tra lo stato x(t) e la variabile di uscita y(t).\n\n\nEquazioni di Stato e di Uscita\nEsiste una differenza sostanziale tra l’equazione di stato e l’equazione di uscita:\n\nEquazione di stato: è un’equazione dinamica (differenziale o alle differenze).\n\nTempo continuo: \\dot{x}(t) = f(x(t), u(t)).\nTempo discreto: x(t+1) = f(x(t), u(t)).\n\n\nEquazione di uscita: è una funzione algebrica.\n\ny(t) = g(x(t), u(t)).\nSe l’equazione di uscita dipende esplicitamente dall’ingresso, il sistema è detto improprio.\n\n\n\n\nGeneralità sui Sistemi Dinamici\nLa trattazione si concentra su una classe specifica di sistemi dinamici, rilevante per le applicazioni in diversi campi (elettromeccanica, termodinamica, chimica, scienze sociali, economia, biologia).\nTempo nei Sistemi Dinamici\n\nTempo continuo: t \\in \\mathbb{R}, t \\geq 0.\nTempo discreto: t = {0, 1, 2, ...}, t \\in \\mathbb{N}.\n\nLo studio di un sistema dinamico inizia convenzionalmente all’istante t=0.\nStruttura di Ingresso, Stato e Uscita\n\n\nIngresso: u(t) \\in \\mathbb{R}^m (in generale un vettore).\nUscita: y(t) \\in \\mathbb{R}^p (in generale un vettore).\nLa maggior parte del corso è dedicata a sistemi SISO (Single Input, Single Output), dove m = p = 1.\nStato: x(t) \\in \\mathbb{R}^n, dove n è l’ordine del sistema, ovvero il numero di variabili di stato.\n\nProblema al Valore Iniziale (o di Cauchy)\nEquazioni Differenziali\nL’equazione differenziale è un’equazione la cui incognita è una funzione x(t). Per risolverla, è necessario specificare l’ingresso u(t) e lo stato iniziale x(0).\nTeoria delle Equazioni Differenziali\nLa teoria del problema al valore iniziale afferma che, se si specificano lo stato iniziale x(0) e l’ingresso u(t) e se f è sufficientemente regolare, allora l’evoluzione x(t) è definita univocamente per t \\geq 0.\nRegolarità di f\nPer garantire l’esistenza e l’unicità della soluzione, f deve essere sufficientemente regolare. Nei sistemi lineari, f è lineare e quindi C^\\infty (derivabile infinite volte), il che soddisfa ampiamente i requisiti di regolarità.\nConseguenza\nSe x(t) è definita univocamente, anche y(t) lo è, dato che y è funzione di x.\nSistemi Dinamici Lineari\nDefinizione\nUn sistema dinamico è lineare se l’equazione di stato e l’equazione di uscita sono lineari, ovvero se sono funzioni lineari dei loro argomenti.\nLinearità dell’Equazione di Stato\nSe lo stato è un vettore, l’equazione di stato è un insieme di n equazioni scalari:\n\n\\dot{x}_i(t) = f_i(x(t), u(t)) per i = 1, ..., n.\n\nLa linearità implica che ogni f_i può essere scritta come combinazione lineare dei suoi argomenti:\n\n\\dot{x}_1(t) = a_{11}x_1(t) + a_{12}x_2(t) + ... + a_{1n}x_n(t) + b_1u(t)\n\\dot{x}_2(t) = a_{21}x_1(t) + \\cdots + a_{2n}x_n(t) + b_2u(t)\n\\dot{x}_n(t) = a_{n1}x_1(t) + \\cdots + a_{nn}x_n(t) + b_nu(t)\n\nLinearità dell’Equazione di Uscita\nAnche l’equazione di uscita deve essere lineare:\n\ny(t) = c_1x_1(t) + ... + c_nx_n(t) + du(t)\n\nRappresentazione Matriciale Compatta\n\nLe equazioni lineari possono essere scritte in forma matriciale:\n\n\\dot{x}(t) = Ax(t) + Bu(t)\ny(t) = Cx(t) + Du(t)\n\nDove:\n\nA è la matrice di stato (n \\times n).\nB è il vettore di ingresso (n \\times 1).\nC è il vettore di uscita (1 \\times n).\nD è uno scalare (1 \\times 1).\n\nLa conoscenza delle matrici A, B, C, D definisce completamente il modello del sistema lineare.\nSistemi Proprio e Improprio\nUn sistema è improprio se nell’equazione di uscita compare esplicitamente l’ingresso. Questo dipende dal coefficiente D:\n\nSe D \\neq 0: sistema improprio.\nSe D = 0: sistema proprio.\n\nEsempio 1: Vasca da Bagno (Tempo Continuo)\n\n\nVariabile di stato: volume d’acqua nella vasca x(t).\nIngresso: portata entrante u(t).\nUscita: deflusso y(t) = Kx(t).\nEquazione di stato: \\dot{x}(t) = u(t) - Kx(t).\nMatrici: A = -K, B = 1, C = K, D = 0.\n\nEsempio 2: Circuito Elettrico (Tempo Continuo)\n\nVariabili di stato: corrente nell’induttore x_1(t) e tensione sul condensatore x_2(t).\nIngresso: corrente del generatore u(t).\nUscita: tensione sul resistore y(t) = Rx_1(t).\nEquazioni di stato:\n\n\\dot{x}_1(t) = \\frac{1}{L}x_2(t) - \\frac{R}{L}x_1(t)\n\\dot{x}_2(t) = \\frac{1}{C}u(t) - \\frac{1}{C}x_1(t)\n\n\nMatrici:\n\nA = \\begin{bmatrix} -\\frac{R}{L} &amp; \\frac{1}{L} \\\\ -\\frac{1}{C} &amp; 0 \\end{bmatrix}\nB = \\begin{bmatrix} 0 \\\\ \\frac{1}{C} \\end{bmatrix}\nC = \\begin{bmatrix} R &amp; 0 \\end{bmatrix}\nD = 0\n\n\n\n\nSistemi a Tempo Discreto\nL’equazione di stato è espressa come:\n\nx(t+1) = Ax(t) + Bu(t)\n{x}_1(t+1) = a_{11}x_1(t) + a_{12}x_2(t) + ... + a_{1n}x_n(t) + b_1u(t)\n\nEsempio 1: Conto Corrente (Tempo Discreto)\n\nVariabile di stato: capitale disponibile x(t).\nIngresso: versamento u(t).\nEquazione di stato: x(t+1) = (1+r)x(t) + u(t).\nUscita: capitale depositato y(t) = x(t).\nMatrici: A = 1+r, B = 1, C = 1, D = 0.\n\nD=0 sistema proprio\n\n\n\nEsempio 2: Modello Demografico (Tempo Discreto)\n\nVariabili di stato: numero di allievi in prima, seconda e terza media (x_1(t), x_2(t), x_3(t)).\nIngresso: nuovi ingressi in prima media u(t).\nEquazioni di stato:\n\nx_1(t+1) = \\beta_1 x_1(t) + u(t)\nx_2(t+1) = \\alpha_1 x_1(t) + \\beta_2 x_2(t)\nx_3(t+1) = \\alpha_2 x_2(t) + \\beta_3 x_3(t)\n\n\nUscita: popolazione complessiva y(t) = x_1(t) + x_2(t) + x_3(t).\nMatrici:\n\nA = \\begin{bmatrix} \\beta_1 &amp; 0 &amp; 0 \\\\ \\alpha_1 &amp; \\beta_2 &amp; 0 \\\\ 0 &amp; \\alpha_2 &amp; \\beta_3 \\end{bmatrix}\nB = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}\nC = \\begin{bmatrix} 1 &amp; 1 &amp; 1 \\end{bmatrix}\nD = 0\n\n\n\nConcetti di Movimento, Traiettoria ed Equilibrio\nOggetto di Studio\nSistemi lineari a tempo continuo e discreto:\n\nTempo continuo: \\dot{x}(t) = Ax(t) + Bu(t)\nTempo discreto: x(t+1) = Ax(t) + Bu(t)\n\nMovimento\nIl movimento di un sistema dinamico è sinonimo di soluzione dell’equazione differenziale o alle differenze. Se si definiscono lo stato iniziale x(0) e l’ingresso u(t), \\ \\ t  \\geq 0, allora la soluzione x(t) è univocamente determinata.\nRappresentazione Geometrica del Movimento\n\n\nConoscere la soluzione significa conoscere come evolvono nel tempo tutte le variabili di stato x_1(t), x_2(t), ..., x_n(t).\nIn un sistema di ordine due, il movimento può essere rappresentato come una curva nello spazio tridimensionale (tempo, x_1, x_2).\n\n\nTraiettoria\nLa traiettoria è la proiezione del movimento nello spazio di stato \\mathbb{R}^n.\nTraiettoria a Tempo Continuo\n\n\nÈ una curva nello spazio di stato.\nÈ orientata nel senso del tempo crescente.\ntraiettoria in \\mathbb{R}^3\n\n\nTraiettoria a Tempo Discreto\n\n\nÈ una successione di punti nello spazio di stato ordinati con l’indice tempo.\nGli stati visitati dal sistema sono solo i punti della successione.\n\nla traiettoria e Biunivocità\nLa discussione sulla biunivocità nel contesto dei sistemi dinamici riguarda la corrispondenza tra i punti della traiettoria e gli istanti di tempo. In particolare, ci si chiede se ogni punto della traiettoria corrisponde a un solo istante di tempo oppure se lo stesso punto può essere visitato in istanti diversi.\nIl professore introduce il problema con un esempio di una traiettoria che si interseca:\n\nSi parte da un punto iniziale all’istante t=0.\nLa traiettoria evolve nel tempo.\nAd un certo punto t_1, la traiettoria passa per un punto nello spazio di stato.\nSuccessivamente, ad un tempo t_2 &gt; t_1, la traiettoria ripassa per lo stesso punto.\n\n\nQuesto viola la biunivocità, perché lo stesso punto corrisponde a due istanti di tempo diversi.\nLa tangente alla traiettoria in un punto x è data da \\dot{x} = f(x, u), o nel caso lineare da \\dot{x} = Ax + Bu.\nL’anomalia si verifica quando la traiettoria passa due volte per lo stesso punto x con tangenti diverse.\n\nSe l’ingresso u è costante nel tempo, allora il vettore tangente deve essere lo stesso ogni volta che la traiettoria passa per quel punto. Quindi, se l’ingresso è costante, non è possibile che la traiettoria si auto-intersechi.\nSe l’ingresso u non è costante, è possibile che la traiettoria si auto-intersechi, perché il vettore tangente può essere diverso in tempi diversi.\n\nIn sintesi, la biunivocità tra punti della traiettoria e istanti di tempo è violata quando il sistema è pilotato da un ingresso non costante.\nIl vettore tangente \\dot{x} è dotato di direzione e modulo. La direzione e il verso del vettore tangente definiscono la tangente geometrica, mentre il modulo determina la velocità con cui il punto percorre la traiettoria.\nTangente alla Traiettoria\nIn un sistema a tempo continuo, il vettore tangente alla traiettoria in un punto x è dato da \\dot{x} = f(x, u) (o \\dot{x} = Ax + Bu nel caso lineare). Il modulo del vettore tangente indica la velocità con cui il punto percorre la traiettoria.\nEquilibrio\nDefinizione\nDato un sistema con ingresso costante u(t) = \\bar{u}, uno stato \\bar{x} è di equilibrio se, partendo da x(0) = \\bar{x}, si ha x(t) = \\bar{x} per ogni t \\geq 0.\n\ntraiettoria:\n\nSignificato Applicativo\nIl regime stazionario (o all’equilibrio) è di grande importanza applicativa, poiché molti sistemi funzionano cercando di mantenere le variabili costanti nel tempo.\nRicerca degli Equilibri (Tempo Continuo)\nData l’equazione di stato \\dot{x}(t) = Ax(t) + B\\bar{u}, per trovare gli stati di equilibrio si impone \\dot{x}(t) = 0.\nAx(t) + B\\bar{u}=0 Ax(t)= - B\\bar{u}\nCaso 1: Matrice A Invertibile\nSe \\det(A) \\neq 0, esiste un unico stato di equilibrio:\n\n\\bar{x} = -A^{-1}B\\bar{u}\ncambiando u, cambia anche x segnato\n\nCaso 2: Matrice A Singolare\nSe \\det(A) = 0, possono esistere:\n\nInfiniti stati di equilibrio.\nNessuno stato di equilibrio.\n\nAutovalori e Singolarità\nIl determinante di A è zero se e solo se esiste almeno un autovalore di A uguale a zero. (matrice semidefinita )\nUscita all’Equilibrio\nSe il sistema è all’equilibrio, anche l’uscita è costante. L’uscita di equilibrio è data da:\n\n\\bar{y} = C\\bar{x} + D\\bar{u}\nNel caso di esistenza e unicità dell’equilibrio: \\bar{y} = (-CA^{-1}B + D)\\bar{u}\n\nGuadagno del Sistema\nIl guadagno del sistema è definito come \\mu = -CA^{-1}B + D, tale che \\bar{y} = \\mu\\bar{u}.\nEsempio: Vasca da Bagno (Guadagno)\nAll’equilibrio, la portata entrante deve essere uguale a quella uscente, quindi il guadagno deve essere 1.\nVerifica\n\n\\dot{x} = \\bar{u} - Kx = 0 \\Rightarrow \\bar{x} = \\frac{\\bar{u}}{K}\ny = Kx \\Rightarrow \\bar{y} = K\\frac{\\bar{u}}{K} = \\bar{u}\nQuindi \\mu = 1\n\nCondizione di equilibrio a tempo discreto\nIn un sistema a tempo discreto, definito come x(t+1) = Ax(t) + Bu(t), la condizione di equilibrio si verifica quando lo stato all’istante t+1 è uguale allo stato all’istante t, cioè x(t+1) = x(t). Questo implica che, una volta raggiunto l’equilibrio, il sistema permane in tale stato a meno di perturbazioni esterne.\nEquazione per la ricerca dell’equilibrio\nSotto l’ipotesi di ingresso costante u(t) = \\bar{u}, la condizione di equilibrio porta all’equazione (I - A)x = B\\bar{u}, dove I è la matrice identità.\nAnalisi della matrice (I - A) e autovalori\nLa risolubilità dell’equazione (I - A)x = B\\bar{u} dipende dalle proprietà della matrice (I - A). In particolare, il determinante di (I - A) gioca un ruolo cruciale.\n\n\nCaso 1: (I - A) è invertibile\nSe il determinante di (I - A) è diverso da zero, la matrice è invertibile e esiste un’unica soluzione per x, data da \\bar{x} = (I - A)^{-1}B\\bar{u}. Questo implica che il sistema ha un solo stato di equilibrio.\n\n\nCaso 2: (I - A) è singolare\nSe il determinante di (I - A) è uguale a zero, la matrice è singolare e possono verificarsi due scenari:\n\nEsistono infinite soluzioni, il che implica infiniti stati di equilibrio.\nNon esistono soluzioni, il che implica l’assenza di stati di equilibrio.\n\n\n\nConnessione con gli autovalori\nPer determinare se la matrice (I - A) è singolare, si può analizzare lo spettro della matrice A, ovvero l’insieme dei suoi autovalori. Il determinante di (I - A) è zero se e solo se almeno un autovalore di A è uguale a 1.\nRicerca degli Equilibri a Tempo Discreto\nPer i sistemi a tempo discreto, la procedura per trovare gli equilibri differisce leggermente rispetto al caso a tempo continuo. Consideriamo un sistema a tempo discreto descritto dalla seguente equazione di stato:\n\\qquad x(t+1) = Ax(t) + Bu(t)\nIpotesi Fondamentale: Si assume che l’ingresso sia costante nel tempo, cioè u(t) = \\bar{u} per ogni t \\geq 0.\nCondizione di Equilibrio\nA differenza del caso continuo, dove si impone l’azzeramento delle derivate, nel caso discreto si impone che lo stato all’istante t+1 sia uguale allo stato all’istante t:\n\\qquad x(t+1) = x(t)\nQuesto significa che, se il sistema è in equilibrio, il valore dello stato non cambia nel tempo. In altre parole, se il sistema si trova in un certo stato x e si applica un ingresso costante \\bar{u}, il sistema rimarrà in quello stato anche all’istante successivo.\nRisoluzione dell’Equazione di Equilibrio\nSostituendo la condizione di equilibrio nell’equazione di stato, otteniamo:\n\\qquad x = Ax + B\\bar{u}\nRisolvendo per x, si ottiene l’equazione che definisce gli stati di equilibrio:\n\\qquad (I - A)x = B\\bar{u}\nDove I è la matrice identità.\nAnalisi delle Soluzioni\nLa natura delle soluzioni di questa equazione dipende dalle proprietà della matrice (I - A). In particolare:\n\n\nCaso 1: Matrice (I - A) Invertibile: Se la matrice (I - A) è invertibile, esiste un’unica soluzione per x, che rappresenta l’unico stato di equilibrio:\n\\qquad \\bar{x} = (I - A)^{-1}B\\bar{u}\n\n\nCaso 2: Matrice (I - A) Singolare: Se la matrice (I - A) è singolare, possono verificarsi due situazioni:\n\nEsistono infinite soluzioni, il che significa che ci sono infiniti stati di equilibrio.\nNon esistono soluzioni, il che significa che non ci sono stati di equilibrio.\n\n\n\nLa determinazione del caso specifico richiede un’analisi più approfondita della matrice e del vettore B\\bar{u}.\nUscita all’Equilibrio\nAnche nel caso a tempo discreto, se il sistema è all’equilibrio, anche l’uscita sarà costante. L’equazione di uscita è data da:\n\\qquad y(t) = Cx(t) + Du(t)\nAll’equilibrio, l’uscita diventa:\n\\qquad \\bar{y} = C\\bar{x} + D\\bar{u}\nSostituendo l’espressione di \\bar{x} (nel caso di esistenza e unicità), si può ottenere una relazione tra l’uscita e l’ingresso all’equilibrio.\n\n\\bar{y} = C(I - A)^{-1}B\\bar{u} + D\\bar{u}\n\nRaccogliendo \\bar{u}:\n\n\\bar{y} = [C(I - A)^{-1}B + D]\\bar{u}\n\nQuesta è la relazione tra l’uscita e l’ingresso all’equilibrio. Il termine [C(I - A)^{-1}B + D] rappresenta il guadagno del sistema \\mu, per cui:\n\n\\bar{y} = \\mu \\bar{u}\n\ndove:\n\n\\mu = C(I - A)^{-1}B + D\n\nIl guadagno \\mu esprime il rapporto tra l’uscita e l’ingresso all’equilibrio e dipende esclusivamente dalle matrici del sistema (A, B, C, D).\n\nReferences"},"6--full-note/Edp---Lez01":{"slug":"6--full-note/Edp---Lez01","filePath":"6- full note/Edp - Lez01.md","title":"Edp - Lez01","links":["tags/revisione_zero","tags/flashcard_zero","tags/riscritto_zero","3--tag/Metodi-Analitici-per-le-Equazioni-alle-Derivate-Parziali","3--tag/sbobine"],"tags":["revisione_zero","flashcard_zero","riscritto_zero"],"content":"2025-02-18 17:41\n_Status: revisione_zero flashcard_zero riscritto_zero\n_Tags: Metodi Analitici per le Equazioni alle Derivate Parziali sbobine\nlez01-edp\nIntroduzione al Corso e Materiali Didattici\nStruttura del Corso Integrato\n\nIl corso è integrato con un modulo di Metodi Numerici tenuto dal professor Zunino, successivo al modulo principale.\nGli esami dei due moduli possono essere sostenuti separatamente o nello stesso appello (giugno, luglio, agosto, settembre, gennaio, febbraio).\nL’esame del modulo principale consiste in una prova scritta con tre domande teoriche e un esercizio, riflettendo l’orientamento teorico del corso.\n\nIntroduzione alle Equazioni alle Derivate Parziali (EDP)\n\n\nIl corso introduce le equazioni alle derivate parziali (EDP), un tema centrale nell’analisi matematica e nelle modellizzazioni differenziali.\n\n\nLe EDP modellizzano sistemi fisici continui, come la vibrazione di una corda o la temperatura di un corpo esteso, dove le funzioni incognite dipendono da più variabili (spazio e tempo).\n\n\nUn’equazione alle derivate parziali può essere scritta in forma generale come:\nF(x, u, ∂u, ∂²u, ..., ∂ᵏu) = 0\n\ndove:\n\nu è la funzione incognita.\nx è la variabile indipendente (può includere spazio e tempo).\n∂ᵏu rappresenta le derivate parziali di u fino all’ordine k.\n\n\n\nL’ordine dell’equazione è determinato dal massimo ordine di derivazione presente nell’equazione.\n\n\nEsempi Storici di EDP\n\n\nEquazione della corda vibrante:\n\n\nDescrive la vibrazione di una corda tesa, fissata agli estremi.\n\n\nForma:\n∂²u/∂t² = c² (∂²u/∂x²)\n\ndove u(x, t) rappresenta la forma della corda al tempo t, e c è una costante con le dimensioni di una velocità.\n\n\nEstesa da Bernulli per rappresentare le onde bidimensionali o tridimensionali:\n∂²u/∂t² = c² Δu\n\ndove Δu è il Laplaciano di u.\n\n\n\n\nEquazione di Laplace:\n\n\nDescrive il potenziale gravitazionale (Laplace) o elettrostatico (Green) in punti dello spazio privi di carica.\n\n\nForma:\nΔu = 0\n\ndove Δu è il Laplaciano di u, dato dalla somma delle derivate seconde pure di u.\n\n\n\n\nEquazione del calore (o di diffusione):\n\n\nDescrive la conduzione del calore in un corpo.\n\n\nForma:\n∂u/∂t = c Δu\n\ndove u(x, t) rappresenta la temperatura al tempo t, e c è il coefficiente di conducibilità termica.\n\n\nIntrodotta da Fourier nella Teoria analitica del calore.\n\n\n\n\nEquazioni di Navier-Stokes:\n\nUtilizzate in fluidodinamica.\n\n\n\nEquazioni di Maxwell:\n\nUtilizzate nell’elettromagnetismo.\nFormalizzate matematicamente da Heaviside.\n\n\n\nEquazione di Schrödinger:\n\nUtilizzata nella meccanica quantistica.\n\n\n\nEquazioni di Cauchy-Riemann:\n\nUtilizzate nello studio delle funzioni olomorfe.\nLa parte reale e la parte immaginaria di una funzione olomorfa soddisfano queste equazioni.\n\n\n\nEquazioni delle superfici minime (Lagrange):\n\nDescrivono la superficie di area minima che si appoggia su un bordo dato.\n\n\n\nEquazione di Black-Scholes:\n\nUtilizzata nella finanza matematica per la teoria dei processi stocastici.\n\n\n\nClassificazione delle EDP\n\n\nOrdine:\n\nPrimo ordine (es. equazioni di Cauchy-Riemann, equazione del trasporto lineare).\nSecondo ordine (es. equazione di Laplace, del calore, delle onde, di Schrödinger).\nOrdine superiore (es. equazione della piastra vibrante, equazione di Korteweg-de Vries).\n\n\n\nScalari vs. Sistemi:\n\nEquazioni scalari: una sola equazione.\nSistemi: più equazioni (es. equazioni di Maxwell, equazioni di Navier-Stokes).\n\n\n\nLineari vs. Non Lineari:\n\nLineari: possono essere scritte nella forma Lu = F, dove L è un operatore lineare.\nNon lineari: non soddisfano la proprietà di linearità (es. equazione delle superfici minime, equazione dei mezzi porosi, equazione di Korteweg-de Vries).\n\n\n\nStazionarie vs. di Evoluzione:\n\nStazionarie: descrivono fenomeni indipendenti dal tempo.\nDi evoluzione: descrivono fenomeni che evolvono nel tempo.\n\n\n\nTipi di Equazioni di Evoluzione:\n\nTipo vibrazione/oscillazione (iperboliche): es. equazione delle onde.\nTipo diffusione (paraboliche): es. equazione del calore.\nEllittiche: equazioni stazionarie.\n\n\n\nProblemi Tipici per le EDP\n\n\nAnalogia con le equazioni differenziali ordinarie (EDO).\n\n\nLa soluzione generale di un’EDP dipende da funzioni arbitrarie, non solo da costanti.\n\n\nCondizioni necessarie per determinare una soluzione unica:\n\nCondizioni iniziali: specificano il valore della funzione e/o delle sue derivate al tempo t = 0.\nCondizioni al contorno: specificano il valore della funzione sul bordo del dominio spaziale.\n\n\n\nTipi di problemi:\n\nProblemi ai valori iniziali.\nProblemi ai valori al contorno (Dirichlet, Neumann, ecc.).\nProblemi misti (valori iniziali e al contorno).\n\n\n\nConcetto di Problema Ben Posto (Hadamard)\nUn problema è ben posto se soddisfa tre condizioni:\n\nEsistenza: Esiste almeno una soluzione per ogni dato assegnato.\nUnicità: La soluzione è unica.\nDipendenza continua dai dati: Una piccola variazione nei dati causa una piccola variazione nella soluzione.\n\nSe una di queste condizioni non è soddisfatta, il problema è detto mal posto.\nComplessità nello Studio delle EDP\n\nLa geometria del dominio influenza la complessità del problema.\nÈ utile partire da modelli semplificati per comprendere le idee fondamentali, per poi gradualmente aggiungere ipotesi più realistiche.\n\nPunti di Vista nello Studio delle EDP\n\n\nRicerca di soluzioni esplicite:\n\nTecniche analitiche: sviluppi in serie di Fourier, trasformata di Fourier e Laplace, funzioni speciali (polinomi di Legendre, Laguerre, Hermite, funzioni di Bessel).\n\n\n\nApproccio teorico:\n\nGiustificazione rigorosa delle tecniche analitiche.\nStudio delle proprietà a priori delle soluzioni.\nUtilizzo di strumenti avanzati: teoria della misura e dell’integrazione di Lebesgue, spazi di Sobolev, teoria delle distribuzioni.\n\n\n\nAnalisi numerica:\n\nMetodi per approssimare numericamente le soluzioni (es. metodo degli elementi finiti).\nFondamentale un quadro teorico che garantisca la convergenza dell’approssimazione.\n\n\n\nScaletta del Modulo\n\n\nTeoria classica delle EDP:\n\nEquazione di Laplace.\nEquazione del calore (o di diffusione).\nEquazione del trasporto lineare.\nEquazione delle onde.\n\n\n\nProprietà generali e classificazione delle equazioni:\n\nClassificazione in equazioni ellittiche, paraboliche e iperboliche.\n\n\n\nTeoria moderna:\n\nFormulazione debole dei problemi ai limiti.\nUtilizzo di elementi di analisi funzionale.\n\n\n\nRichiami di Analisi\n\n\nSpazi vettoriali normati:\n\nSpazio vettoriale X con una norma || ||.\nConvergenza in norma, successioni di Cauchy, completezza.\nSpazio di Banach: spazio vettoriale normato completo.\n\n\n\nSpazi di funzioni continue:\n\n\nC⁰(K): funzioni continue f: K → ℝ, dove K ⊆ ℝⁿ è chiuso e limitato.\n\n\nNorma:\n||f||_{C⁰(K)} = max_{x ∈ K} |f(x)|\n\n\nC⁰(K) con questa norma è uno spazio di Banach.\n\n\nC⁰*(ℝⁿ): funzioni continue su ℝⁿ che tendono a zero all’infinito.\n\n\nC⁰⁰(ℝⁿ): funzioni continue a supporto compatto.\n\n\n\n\nSpazi di funzioni derivabili:\n\n\nC¹(Ω): funzioni con derivate prime continue su un aperto Ω ⊆ ℝⁿ.\n\n\nC¹(Ω̄): funzioni con derivate prime continue fino al bordo di Ω.\n\n\nNorma:\n||f||_{C¹(Ω̄)} = ||f||_{C⁰(Ω̄)} + ∑_{i=1}^{n} ||∂f/∂xᵢ||_{C⁰(Ω̄)}\n\n\nC¹(Ω̄) con questa norma è uno spazio di Banach.\n\n\nDominio: insieme aperto e connesso.\n\n\n\n\nSpazi Lᵖ:\n\n\nLᵖ(Ω): funzioni misurabili f: Ω → ℝ tali che ∫|f(x)|ᵖ dx &lt; ∞, dove Ω ⊆ ℝⁿ è misurabile.\n\n\nNorma:\n||f||_{Lᵖ(Ω)} = (∫_{Ω} |f(x)|ᵖ dx)^{1/p}\n\n\n\nL∞(Ω): funzioni essenzialmente limitate su Ω.\n\n\nNorma:\n||f||_{L∞(Ω)} = ess sup_{x ∈ Ω} |f(x)|\n\n\n\nGli spazi Lᵖ(Ω) sono di Banach per ogni 1 ≤ p ≤ ∞.\n\n\n\n\nSpazi di Hilbert:\n\n\nSpazio vettoriale H con un prodotto scalare &lt; , &gt;.\n\n\nNorma indotta dal prodotto scalare:\n||f|| = √&lt;f, f&gt;\n\n\n\nSpazio prehilbertiano: spazio vettoriale con prodotto scalare.\n\n\nSpazio di Hilbert: spazio prehilbertiano completo rispetto alla norma indotta.\n\n\nDisuguaglianza di Cauchy-Schwarz:\n|&lt;f, g&gt;| ≤ ||f|| ||g||\n\n\n\nOrtogonalità: f è ortogonale a g se &lt;f, g&gt; = 0.\n\n\nEsempi:\n\n\nL²(Ω): spazio delle funzioni a quadrato integrabile su Ω con prodotto scalare:\n&lt;f, g&gt; = ∫_{Ω} f(x)g(x) dx\n\n\n\nℓ²: spazio delle successioni x = (xₙ) tali che ∑xₙ² &lt; ∞ con prodotto scalare:\n&lt;x, y&gt; = ∑xₙyₙ\n\n\n\n\n\n\n\nOperatori lineari continui:\n\n\nT: X → Y operatore lineare tra spazi vettoriali normati X e Y.\n\n\nContinuità: se xₙ → x in X, allora T(xₙ) → T(x) in Y.\n\n\nEquivalenze:\n\nT è continuo.\nT è continuo in zero.\nT è limitato: esiste C &gt; 0 tale che ||T(x)||_{Y} ≤ C ||x||_{X} per ogni x ∈ X.\n\n\n\nNorma dell’operatore:\n||T|| = sup_{x ≠ 0} ||T(x)||_{Y} / ||x||_{X}\n\ne\n||T(x)||_{Y} ≤ ||T|| ||x||_{X}\n\n\n\n\n\nFunzionali lineari continui:\n\nT: X → ℝ operatore lineare continuo.\nSpazio duale X*: spazio di tutti i funzionali lineari continui su X.\nEsempi:\n\nIntegrale: T(f) = ∫f(x) dx.\nValutazione: T(f) = f(a).\nIl duale di Lᵖ(Ω) è L^{q}(Ω), dove 1/p + 1/q = 1.\n\n\n\n\n\nReferences"},"6--full-note/Edp--Lez02":{"slug":"6--full-note/Edp--Lez02","filePath":"6- full note/Edp- Lez02.md","title":"Edp- Lez02","links":["tags/revisione_zero","tags/flashcard_zero","tags/riscritto_zero","3--tag/Metodi-Analitici-per-le-Equazioni-alle-Derivate-Parziali","3--tag/sbobine"],"tags":["revisione_zero","flashcard_zero","riscritto_zero"],"content":"2025-02-18 15:21\n_Status: revisione_zero flashcard_zero riscritto_zero\n_Tags: Metodi Analitici per le Equazioni alle Derivate Parziali sbobine\nlez02- Edp\nFunzionali Lineari Continui\nUn funzionale lineare continuo è una trasformazione lineare che mappa uno spazio vettoriale normato nei numeri reali, mantenendo la proprietà di continuità. In termini più formali, T: X \\rightarrow \\mathbb{R} è un funzionale lineare continuo se:\n\nÈ lineare: T(\\alpha x + \\beta y) = \\alpha T(x) + \\beta T(y) per ogni x, y \\in X e \\alpha, \\beta \\in \\mathbb{R}.\nÈ continuo: Esiste una costante C &gt; 0 tale che |T(x)| \\leq C ||x|| per ogni x \\in X.\n\nLa norma di un funzionale lineare continuo T è definita come:\n||T|| = sup { |T(x)| : ||x|| = 1 }\n\nQuesta norma rappresenta il massimo valore che il funzionale può assumere su vettori di norma unitaria. L’insieme di tutti i funzionali lineari continui su uno spazio vettoriale normato X forma lo spazio duale X^*, che è a sua volta uno spazio vettoriale normato e completo.\nEsempi di Funzionali Lineari Continui\n\n\nIntegrale Definito:\n\nConsideriamo lo spazio delle funzioni continue su un intervallo [a, b], indicato come C[a, b]. Un funzionale lineare continuo può essere definito come:\n\nT(f) = integrale_a^b f(x) dx\n\n\nQuesto funzionale mappa ogni funzione f \\in C[a, b] al valore del suo integrale definito sull’intervallo [a, b].\n\n\n\nValutazione in un Punto:\n\nSempre nello spazio C[a, b], possiamo definire un funzionale che valuta la funzione in un punto specifico x_0 \\in [a, b]:\n\nT(f) = f(x_0)\n\n\nQuesto funzionale restituisce il valore della funzione f nel punto x_0.\n\n\n\nDisuguaglianza di Hölder\nLa disuguaglianza di Hölder è uno strumento fondamentale per costruire funzionali lineari continui sugli spazi L^p(\\Omega).\nEsponenti Coniugati\nDue esponenti p, q \\in [1, \\infty] sono detti coniugati se soddisfano la relazione:\n1/p + 1/q = 1\n\nCasi speciali:\n\nSe p = 1, allora q = \\infty e viceversa.\nSe p = 2, allora q = 2.\n\nEnunciato della Disuguaglianza\nSiano f \\in L^p(\\Omega) e g \\in L^q(\\Omega), con p e q esponenti coniugati. Allora il prodotto f \\cdot g appartiene a L^1(\\Omega) e vale la disuguaglianza:\n||f * g||_{L^1}(\\Omega) \\leq ||f||_{L^p}(\\Omega) * ||g||_{L^q}(\\Omega)\n\nQuesta disuguaglianza è cruciale perché ci permette di controllare l’integrale del prodotto di due funzioni in termini delle loro norme L^p e L^q.\n\n\n\n\n\nCostruzione di Funzionali Lineari Continui su L^p(\\Omega)\nFissiamo g \\in L^q(\\Omega). Definiamo un funzionale T su L^p(\\Omega) come per un p \\in[1,+\\infty] e un q suo esponente coniugato:\nT(f) = integrale_Omega f(x) * g(x) dx\n\nQuesto funzionale è lineare per la linearità dell’integrale. Per la disuguaglianza di Hölder, è anche continuo:\n|T(f)| = |integrale_Omega f(x) * g(x) dx| &lt;= ||f||_Lp(Omega) * ||g||_Lq(Omega)\n\nQuindi, ||T|| \\leq ||g||_{L^q(\\Omega)}. Si può dimostrare che, in realtà, ||T|| = ||g||_{L^q(\\Omega)}.\nTeorema di Rappresentazione di Riesz\nIl teorema di rappresentazione di Riesz fornisce una caratterizzazione completa dei funzionali lineari continui sugli spazi L^p(\\Omega).\nEnunciato del Teorema\nSia 1 \\leq p &lt; \\infty e sia T \\in (L^p(\\Omega))^* (cioè, T è un funzionale lineare continuo su L^p(\\Omega)). Allora esiste un’unica funzione g \\in L^q(\\Omega) tale che:\nT(f) = integrale_Omega f(x) * g(x) dx\n\nper ogni f \\in L^p(\\Omega), dove q è l’esponente coniugato di p. Inoltre, ||T|| = ||g||_{L^q(\\Omega)}.\n\nQuesto teorema è potente perché afferma che ogni funzionale lineare continuo su L^p(\\Omega) può essere rappresentato come l’integrale del prodotto con una funzione g appropriata in L^q(\\Omega).\n\nConseguenza Importante\nIl duale di L^p(\\Omega) è isomorficamente isometrico a L^q(\\Omega), cioè (L^p(\\Omega))^* \\cong L^q(\\Omega). In particolare, (L^2(\\Omega))^* \\cong L^2(\\Omega).\nSpazi di Hilbert\nUno spazio di Hilbert è uno spazio vettoriale reale (o complesso) completo dotato di un prodotto scalare \\langle \\cdot, \\cdot \\rangle che induce una norma ||\\cdot|| tale che ||x|| = \\sqrt{\\langle x, x \\rangle}.\nFunzionali Lineari Continui su Spazi di Hilbert\nAnche negli spazi di Hilbert, i funzionali lineari continui hanno una rappresentazione speciale.\nTeorema di Rappresentazione di Riesz per Spazi di Hilbert\nSia H uno spazio di Hilbert e sia T \\in H^*. Allora esiste un unico vettore g \\in H tale che:\nT(f) = &lt;f, g&gt;\n\nper ogni f \\in H. Inoltre, ||T|| = ||g||_H.\n\nQuesto teorema afferma che ogni funzionale lineare continuo su H può essere rappresentato come il prodotto scalare con un vettore g appropriato in H.\n\nConseguenza\nIl duale di H è isomorficamente isometrico a H, cioè H^* \\cong H.\nTeorema di Pitagora negli Spazi di Hilbert\nSia {u_n}_{n=1}^{\\infty} una successione di vettori ortogonali in uno spazio di Hilbert H, cioè \\langle u_n, u_m \\rangle = 0 per n \\neq m. Se la serie delle norme al quadrato converge, cioè \\sum_{n=1}^{\\infty} ||u_n||^2 &lt; \\infty, allora la serie \\sum_{n=1}^{\\infty} u_n converge in H a un vettore u, e vale:\n||u||^2 = sommatoria ||un||^2\n\n\nQuesto è un’estensione del teorema di Pitagora a spazi di dimensione infinita.\n\nSistemi Ortonormali Completi e Serie di Fourier\nUn sistema ortonormale completo (SONC) in uno spazio di Hilbert H è una successione {e_n}_{n=1}^{\\infty} di vettori in H tali che:\n\nOrtonormalità: \\langle e_n, e_m \\rangle = \\delta_{nm}, dove \\delta_{nm} è il delta di Kronecker (1 se n = m, 0 altrimenti).\nCompletezza: Se \\langle f, e_n \\rangle = 0 per ogni n, allora f = 0.\n\nTrasformata di Fourier Astratta\nPer ogni f \\in H, i coefficienti di Fourier rispetto al SONC {e_n} sono definiti come:\nf_n = &lt;f, en&gt;\n\nL’operatore F: H \\rightarrow l^2(\\mathbb{N}) che associa a ogni f \\in H la successione dei suoi coefficienti di Fourier, cioè F(f) = {f_n}_{n=1}^{\\infty}, è una isometria lineare:\n||f||_H^2 = sommatoria |fn|^2\n\nInoltre, per ogni f, g \\in H:\n&lt;f, g&gt; = sommatoria fn * gn\n\n\nQuesto risultato è fondamentale perché mostra che uno spazio di Hilbert con un SONC è isomorficamente isometrico a l^2(\\mathbb{N}).\n\nEquazioni di Laplace e Poisson\nDefinizioni\n\nEquazione di Laplace: \\Delta u = 0 in \\Omega\nEquazione di Poisson: \\Delta u = f in \\Omega\nFunzione Armonica: Una funzione u tale che \\Delta u = 0 in \\Omega\n\nElettrostatica\nIl teorema di Gauss in elettrostatica afferma che il flusso del campo elettrostatico E attraverso una superficie chiusa S è proporzionale alla carica totale Q contenuta all’interno di S:\nintegrale_S E * dS = 4 * pi * K * Q\n\ndove K è la costante di Coulomb. Utilizzando il teorema della divergenza, si ha:\nintegrale_V div(E) dV = 4 * pi * K * Q\n\ndove V è il volume racchiuso da S. Se la carica è distribuita con densità \\rho, allora Q = \\int_V \\rho dV. Quindi:\nintegrale_V (div(E) - 4 * pi * K * rho) dV = 0\n\nSe E è conservativo, E = -\\nabla U, dove U è il potenziale elettrostatico. Quindi \\text{div}(E) = -\\Delta U, e si ottiene l’equazione di Poisson:\nDelta U = -4 * pi * K * rho\n\nFluidodinamica\nPer un fluido incomprimibile e irrotazionale, il campo di velocità v soddisfa \\text{div}(v) = 0 e \\text{rot}(v) = 0. In tal caso, esiste un potenziale di velocità \\phi tale che v = \\nabla \\phi. Quindi \\text{div}(v) = \\Delta \\phi = 0, e il potenziale di velocità soddisfa l’equazione di Laplace:\nDelta phi = 0\n\nSpero che questa rielaborazione dettagliata ti sia utile!\nReferences"},"6--full-note/Edp--Lez03":{"slug":"6--full-note/Edp--Lez03","filePath":"6- full note/Edp- Lez03.md","title":"Edp- Lez03","links":["tags/flashcard_zero","tags/revisione_zero","tags/riscritto_zero","3--tag/Metodi-Analitici-per-le-Equazioni-alle-Derivate-Parziali","3--tag/sbobine"],"tags":["flashcard_zero","revisione_zero","riscritto_zero"],"content":"2025-02-20 10:18\n_Status:   flashcard_zero  revisione_zero    riscritto_zero\n_Tags: Metodi Analitici per le Equazioni alle Derivate Parziali   sbobine\nlez03- Edp\n\n\n\nMotivazioni per Studiare le Equazioni di Laplace e Poisson\n\nEquazione del potenziale elettrostatico o gravitazionale in presenza di una distribuzione continua di cariche o masse.\nIn fluidodinamica, il potenziale di velocità del moto stazionario irrotazionale di un fluido incomprimibile soddisfa l’equazione di Laplace.\nL’equazione di Poisson può essere vista come il caso stazionario delle equazioni del calore o delle onde.\n\nEquazione del Calore\nL’equazione del calore è espressa come:\n\\qquad \\frac{\\partial U}{\\partial t} = c \\nabla^2 U + F\ndove:\n\nU(x, t) rappresenta la temperatura nel punto x all’istante t.\nc è la costante di conducibilità termica.\nF è il termine di sorgente, che indica dove e quando viene fornito o sottratto calore.\n\nIn condizioni di equilibrio termico (stato stazionario), la temperatura non cambia nel tempo (\\frac{\\partial U}{\\partial t} = 0). Se il termine di sorgente F è indipendente dal tempo o è zero, l’equazione diventa:\n\\qquad -c \\nabla^2 U = F\nche può essere riscritta come l’equazione di Poisson:\n\\qquad \\nabla^2 U = f\ndove f è una funzione che dipende solo da x.\nEquazione delle Onde\nNel caso di una membrana vibrante bidimensionale, l’equazione delle onde è:\n\\qquad \\frac{\\partial^2 U}{\\partial t^2} = c^2 \\nabla^2 U\nIn condizioni di equilibrio elastico, quando la membrana smette di vibrare, \\frac{\\partial^2 U}{\\partial t^2} = 0, e l’equazione diventa l’equazione di Laplace:\n\\qquad \\nabla^2 U = 0\nFunzioni Olomorfe e Funzioni Armoniche\n\n\n\nUna funzione complessa f(z) = u(x, y) + iv(x, y), dove z = x + iy, è derivabile in senso complesso (olomorfa) se le funzioni u e v soddisfano le condizioni di Cauchy-Riemann:\n\\qquad \\frac{\\partial u}{\\partial x} = \\frac{\\partial v}{\\partial y}, \\quad \\frac{\\partial u}{\\partial y} = -\\frac{\\partial v}{\\partial x}\nSe f è olomorfa e u, v sono di classe C^2, allora sia u che v sono funzioni armoniche, cioè soddisfano l’equazione di Laplace:\n\\qquad \\nabla^2 u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0\n\\qquad \\nabla^2 v = \\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2} = 0\nEsempi di funzioni armoniche derivanti da funzioni olomorfe includono le parti reali e immaginarie di z^n e 1/z.\n\nFunzioni Olomorfe e Funzioni Armoniche\nDefinizione di Funzione Olomorfa Una funzione complessa di variabile complessa, f: \\mathbb{C} \\to \\mathbb{C}, è detta olomorfa (o derivabile in senso complesso) in un dominio se ammette derivata in ogni punto del dominio.\nRappresentazione con Parte Reale e Immaginaria Sia f(z) una funzione olomorfa, dove z = x + iy. Possiamo scrivere f(z) come: f(x + iy) = u(x, y) + i v(x, y) dove u(x, y) e v(x, y) sono funzioni a valori reali di due variabili reali.\nCondizioni di Cauchy-Riemann Le funzioni u e v devono soddisfare le equazioni di Cauchy-Riemann: \\frac{\\partial u}{\\partial x} = \\frac{\\partial v}{\\partial y}, \\quad \\frac{\\partial u}{\\partial y} = -\\frac{\\partial v}{\\partial x} Queste equazioni sono una condizione necessaria e sufficiente affinché f sia derivabile in senso complesso, assumendo che u e v siano differenziabili.\nRegolarità delle Funzioni Olomorfe Le funzioni olomorfe hanno proprietà notevoli, tra cui l’essere infinitamente derivabili. In particolare, se f è olomorfa, allora u e v sono di classe C^\\infty nel loro dominio. Per i nostri scopi, è sufficiente considerare che siano di classe C^2.\nDimostrazione che le Parti Reale e Immaginaria sono Armoniche\n\n\nDerivazione delle Equazioni di Cauchy-Riemann\n\nDeriviamo la prima equazione di Cauchy-Riemann rispetto a x: \\frac{\\partial^2 u}{\\partial x^2} = \\frac{\\partial^2 v}{\\partial x \\partial y}\nDeriviamo la seconda equazione di Cauchy-Riemann rispetto a y: \\frac{\\partial^2 u}{\\partial y^2} = -\\frac{\\partial^2 v}{\\partial y \\partial x}\n\n\n\nSomma delle Equazioni Derivate\n\nSommiamo le due equazioni derivate: \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = \\frac{\\partial^2 v}{\\partial x \\partial y} - \\frac{\\partial^2 v}{\\partial y \\partial x}\n\n\n\nApplicazione del Teorema di Schwarz\n\nPoiché v è di classe C^2, possiamo applicare il teorema di Schwarz (o delle derivate miste uguali): \\frac{\\partial^2 v}{\\partial x \\partial y} = \\frac{\\partial^2 v}{\\partial y \\partial x}\nQuindi, \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0\nQuesto significa che u è armonica.\n\n\n\nDimostrazione Analoga per v\n\nDeriviamo la prima equazione di Cauchy-Riemann rispetto a y: \\frac{\\partial^2 u}{\\partial y \\partial x} = \\frac{\\partial^2 v}{\\partial y^2}\nDeriviamo la seconda equazione di Cauchy-Riemann rispetto a x: \\frac{\\partial^2 u}{\\partial x \\partial y} = -\\frac{\\partial^2 v}{\\partial x^2}\n\n\n\nSottrazione delle Equazioni Derivate\n\nSottraiamo la seconda equazione derivata dalla prima: \\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2} = \\frac{\\partial^2 u}{\\partial y \\partial x} - \\frac{\\partial^2 u}{\\partial x \\partial y}\nApplicando il teorema di Schwarz: \\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2} = 0\nQuesto significa che anche v è armonica.\n\n\n\nConclusione Se f(z) = u(x, y) + i v(x, y) è una funzione olomorfa, allora sia la parte reale u(x, y) che la parte immaginaria v(x, y) sono funzioni armoniche, cioè soddisfano l’equazione di Laplace: \\nabla^2 u = 0, \\quad \\nabla^2 v = 0\nEsempi di Funzioni Armoniche\n\nPotenze di z: z^n = (x + iy)^n. Le parti reale e immaginaria di z^n sono armoniche. Ad esempio, per n=3, Re(z^3) = x^3 - 3xy^2 è armonica.\nFunzione reciproca: f(z) = \\frac{1}{z}. In questo caso, u(x, y) = \\frac{x}{x^2 + y^2} e v(x, y) = -\\frac{y}{x^2 + y^2} sono armoniche in \\mathbb{R}^2 \\setminus {(0, 0)}.\nEsponenziale complesso: e^z = e^{x+iy} = e^x \\cos(y) + i e^x \\sin(y). Quindi u(x, y) = e^x \\cos(y) e v(x, y) = e^x \\sin(y) sono armoniche.\n\nQuesta dimostrazione e gli esempi illustrano come la teoria delle funzioni olomorfe sia strettamente collegata alla teoria delle funzioni armoniche in due variabili.\n\nCertamente. Gli esempi forniti nelle fonti riguardano le funzioni z^n, \\frac{1}{z} ed e^z, e le loro parti reali e immaginarie espresse sia in coordinate cartesiane (x, y) che, in alcuni casi, in coordinate polari (\\rho, \\theta).\n\n\nFunzione z^n:\n\nCoordinate Cartesiane:\n\nz^n = (x + iy)^n = u_n(x, y) + i v_n(x, y), dove u_n(x, y) è la parte reale e v_n(x, y) è la parte immaginaria.\nEsempio: per n = 3, z^3 = (x + iy)^3 = x^3 + 3x^2(iy) + 3x(iy)^2 + (iy)^3 = (x^3 - 3xy^2) + i(3x^2y - y^3). Quindi u_3(x, y) = x^3 - 3xy^2 e v_3(x, y) = 3x^2y - y^3.\n\n\nCoordinate Polari:\n\nz = \\rho(\\cos\\theta + i\\sin\\theta), quindi z^n = \\rho^n(\\cos(n\\theta) + i\\sin(n\\theta)).\nu_n(\\rho, \\theta) = \\rho^n \\cos(n\\theta) e v_n(\\rho, \\theta) = \\rho^n \\sin(n\\theta).\nQueste espressioni sono più semplici da calcolare rispetto alla forma cartesiana, specialmente per n elevati.\n\n\n\n\n\nFunzione \\frac{1}{z}:\n\nCoordinate Cartesiane:\n\n\\frac{1}{z} = \\frac{1}{x + iy} = \\frac{x - iy}{(x + iy)(x - iy)} = \\frac{x - iy}{x^2 + y^2} = \\frac{x}{x^2 + y^2} - i\\frac{y}{x^2 + y^2}.\nu(x, y) = \\frac{x}{x^2 + y^2} e v(x, y) = -\\frac{y}{x^2 + y^2}.\n\n\nCoordinate Polari:\n\nz = \\rho(\\cos\\theta + i\\sin\\theta), quindi \\frac{1}{z} = \\frac{1}{\\rho(\\cos\\theta + i\\sin\\theta)} = \\frac{\\cos\\theta - i\\sin\\theta}{\\rho} = \\frac{\\cos\\theta}{\\rho} - i\\frac{\\sin\\theta}{\\rho}.\nu(\\rho, \\theta) = \\frac{\\cos\\theta}{\\rho} e v(\\rho, \\theta) = -\\frac{\\sin\\theta}{\\rho}.\n\n\n\n\n\nFunzione e^z:\n\nCoordinate Cartesiane:\n\ne^z = e^{x + iy} = e^x(\\cos y + i\\sin y) = e^x \\cos y + i e^x \\sin y.\nu(x, y) = e^x \\cos y e v(x, y) = e^x \\sin y.\n\n\nCoordinate Polari:\n\nx = \\rho \\cos \\theta, y = \\rho \\sin \\theta, quindi e^z = e^{\\rho \\cos \\theta + i \\rho \\sin \\theta} = e^{\\rho \\cos \\theta} (\\cos(\\rho \\sin \\theta) + i \\sin(\\rho \\sin \\theta)).\nu(\\rho, \\theta) = e^{\\rho \\cos \\theta} \\cos(\\rho \\sin \\theta) e v(\\rho, \\theta) = e^{\\rho \\cos \\theta} \\sin(\\rho \\sin \\theta).\n\n\n\n\n\nIn sintesi, le coordinate polari possono semplificare l’espressione di alcune funzioni complesse, rendendo più agevole l’analisi delle loro proprietà armoniche.\n\nArmoniche Elementari del Piano\nLe armoniche elementari del piano sono ottenute dalle parti reali e immaginarie di z^n, dove z = x + iy:\n\\qquad z^n = (x + iy)^n = u_n(x, y) + iv_n(x, y)\nu_n(x, y) e v_n(x, y) sono polinomi omogenei di grado n in x e y e sono funzioni armoniche.\nIn coordinate polari (x = \\rho \\cos\\theta, y = \\rho \\sin\\theta), le armoniche elementari diventano:\n\\qquad u_n(\\rho, \\theta) = \\rho^n \\cos(n\\theta)\n\\qquad v_n(\\rho, \\theta) = \\rho^n \\sin(n\\theta)\nProblemi al Contorno per l’Equazione di Poisson\nI problemi al contorno per l’equazione di Poisson consistono nel risolvere l’equazione di Poisson in un dominio \\Omega con condizioni specificate sul bordo \\partial\\Omega. Alcuni tipi comuni di problemi al contorno sono:\n\n\nProblema di Dirichlet: Assegnare il valore della soluzione U sul bordo\n\\qquad \\nabla^2 U = F \\text{ in } \\Omega\n\\qquad U = G \\text{ su } \\partial\\Omega\n\n\nProblema di Neumann: Assegnare la derivata normale di U sul bordo\n\\qquad \\nabla^2 U = F \\text{ in } \\Omega\n\\qquad \\frac{\\partial U}{\\partial n} = G \\text{ su } \\partial\\Omega\n\n\nProblema Misto: Assegnare U su una parte del bordo e \\frac{\\partial U}{\\partial n} sulla restante parte\n\\qquad \\nabla^2 U = F \\text{ in } \\Omega\n\\qquad U = G_1 \\text{ su } \\Sigma_1\n\\qquad \\frac{\\partial U}{\\partial n} = G_2 \\text{ su } \\Sigma_2\ndove \\Sigma_1 \\cup \\Sigma_2 = \\partial\\Omega e \\Sigma_1 \\cap \\Sigma_2 = \\emptyset.\n\n\nProblema di Robin: Assegnare una combinazione lineare di U e della sua derivata normale sul bordo\n\\qquad \\nabla^2 U = F \\text{ in } \\Omega\n\\qquad \\alpha U + \\frac{\\partial U}{\\partial n} = G \\text{ su } \\partial\\Omega\ncon \\alpha &gt; 0.\n\n\nSoluzione Classica\nUna soluzione classica di un problema al contorno per una EDP richiede che le derivate che compaiono nell’equazione esistano e siano continue in tutti i punti del dominio, e che le condizioni al contorno siano soddisfatte senza eccezioni.\n\nPer il problema di Dirichlet, si richiede che U \\in C^2(\\Omega) \\cap C^0(\\overline{\\Omega}).\nPer il problema di Neumann, si richiede che U \\in C^2(\\Omega) \\cap C^1(\\overline{\\Omega}).\n\nTeorema di Unicità\nIl teorema di unicità stabilisce che, sotto certe condizioni, la soluzione di un problema al contorno è unica. Per i problemi di Dirichlet, misto e di Robin, la soluzione, se esiste, è unica. Per il problema di Neumann, la soluzione è unica a meno di una costante additiva.\nLa dimostrazione del teorema di unicità si basa sull’identità di Green e sulla linearità dell’equazione e delle condizioni al contorno. Si supponga che U_1 e U_2 siano due soluzioni dello stesso problema. Allora, la differenza U = U_1 - U_2 soddisfa l’equazione di Laplace con condizioni al contorno omogenee. Applicando la prima identità di Green, si dimostra che l’integrale del quadrato del gradiente di U è zero, il che implica che U è costante. Utilizzando le condizioni al contorno, si conclude che U è identicamente nulla per i problemi di Dirichlet, misto e di Robin, mentre per il problema di Neumann U può essere una costante arbitraria.\n\nSì, la dimostrazione del teorema di unicità è inclusa negli appunti forniti. Di seguito è riportata una sintesi della dimostrazione:\nTeorema di Unicità per Problemi al Contorno per l’Equazione di Laplace\nObiettivo: Dimostrare che la soluzione di un problema di Dirichlet, misto o di Robin per l’equazione di Laplace, se esiste, è unica. Per il problema di Neumann, la soluzione è unica a meno di una costante additiva.\nIpotesi: Sia \\Omega un dominio limitato e lipschitziano.\nDimostrazione:\n\n\nLinearità e Superposizione:\n\nSi assuma che U_1 e U_2 siano due soluzioni del problema.\nSi definisce U = U_1 - U_2. Grazie alla linearità dell’equazione di Laplace e delle condizioni al contorno, U soddisfa lo stesso problema con dati nulli.\n\n\n\nApplicazione della Prima Identità di Green:\n\nSi applica la prima identità di Green alle funzioni U e V = U: \\int_{\\Omega} U \\nabla^2 U , dx + \\int_{\\Omega} |\\nabla U|^2 , dx = \\int_{\\partial\\Omega} U \\frac{\\partial U}{\\partial n} , ds\n\n\n\nSemplificazioni Dovute alle Condizioni al Contorno:\n\nPoiché \\nabla^2 U = 0 in \\Omega, il primo termine dell’integrale scompare.\nL’identità si riduce a: \\int_{\\Omega} |\\nabla U|^2 , dx = \\int_{\\partial\\Omega} U \\frac{\\partial U}{\\partial n} , ds\n\n\n\nAnalisi dei Diversi Problemi al Contorno:\n\nDirichlet: U = 0 su \\partial\\Omega, quindi l’integrale sul bordo è zero.\nNeumann: \\frac{\\partial U}{\\partial n} = 0 su \\partial\\Omega, quindi l’integrale sul bordo è zero.\nMisto: Si divide il bordo in \\Sigma_1 e \\Sigma_2 dove U = 0 su \\Sigma_1 e \\frac{\\partial U}{\\partial n} = 0 su \\Sigma_2, quindi l’integrale sul bordo è zero.\nRobin: \\frac{\\partial U}{\\partial n} = -\\alpha U su \\partial\\Omega, con \\alpha &gt; 0. L’integrale diventa \\int_{\\partial\\Omega} -\\alpha U^2 , ds \\leq 0.\n\n\n\nConclusione:\n\nIn tutti i casi, si ha che \\int_{\\Omega} |\\nabla U|^2 , dx = 0.\nQuesto implica che \\nabla U = 0 in \\Omega.\nQuindi U è costante in \\Omega.\n\n\n\nConsiderazioni Finali sui Diversi Problemi:\n\nDirichlet: Poiché U = 0 sul bordo, U = 0 in tutto \\Omega.\nMisto: Poiché U = 0 su una parte del bordo, U = 0 in tutto \\Omega.\nRobin: Poiché \\alpha &gt; 0 e \\int_{\\partial\\Omega} -\\alpha U^2 , ds = 0, allora U = 0 sul bordo e quindi U = 0 in tutto \\Omega.\nNeumann: U è costante, ma non necessariamente zero. Quindi la soluzione è unica a meno di una costante additiva.\n\n\n\nConclusione: La differenza tra due soluzioni qualsiasi è zero (o una costante nel caso di Neumann), il che dimostra l’unicità della soluzione (a meno di una costante per Neumann).\nQuesto completa la dimostrazione del teorema di unicità basata sull’identità di Green.\n\nCondizione di Compatibilità per il Problema di Neumann\nPer il problema di Neumann, affinché esista una soluzione, il dato di Neumann G deve soddisfare una condizione di compatibilità:\n\\qquad \\int_{\\partial\\Omega} G , ds = 0\nQuesta condizione deriva dall’applicazione del teorema della divergenza e rappresenta un bilancio del flusso di calore sul bordo.\nProblema di Dirichlet sul Cerchio\nSi consideri il problema di Dirichlet per l’equazione di Laplace sul cerchio di raggio R:\n\\qquad \\nabla^2 U = 0 \\text{ per } x^2 + y^2 &lt; R^2\n\\qquad U = G \\text{ per } x^2 + y^2 = R^2\nA causa della simmetria del dominio, è conveniente utilizzare le coordinate polari (\\rho, \\theta). L’equazione di Laplace in coordinate polari diventa:\n\\qquad \\frac{\\partial^2 U}{\\partial \\rho^2} + \\frac{1}{\\rho} \\frac{\\partial U}{\\partial \\rho} + \\frac{1}{\\rho^2} \\frac{\\partial^2 U}{\\partial \\theta^2} = 0\nLa condizione al bordo diventa U(R, \\theta) = g(\\theta), dove g(\\theta) è il dato di Dirichlet in coordinate polari.\nMetodo di Separazione delle Variabili\nSi cerca una soluzione del tipo U(\\rho, \\theta) = R(\\rho) \\Theta(\\theta). Sostituendo nell’equazione di Laplace e separando le variabili, si ottengono due equazioni differenziali ordinarie:\n\\qquad \\rho^2 R&#039;&#039;(\\rho) + \\rho R&#039;(\\rho) = \\lambda R(\\rho)\n\\qquad -\\Theta&#039;&#039;(\\theta) = \\lambda \\Theta(\\theta)\ndove \\lambda è una costante di separazione.\nRisoluzione dell’Equazione per \\Theta(\\theta)\nLa funzione \\Theta(\\theta) deve essere periodica con periodo 2\\pi. Le soluzioni non banali si ottengono solo per \\lambda = n^2, con n = 0, 1, 2, \\dots Le soluzioni sono:\n\\qquad \\Theta_n(\\theta) = A_n \\cos(n\\theta) + B_n \\sin(n\\theta)\nRisoluzione dell’Equazione per R(\\rho)\nL’equazione per R(\\rho) è un’equazione di Eulero:\n\\qquad \\rho^2 R&#039;&#039;(\\rho) + \\rho R&#039;(\\rho) - n^2 R(\\rho) = 0\nSi cerca una soluzione del tipo R(\\rho) = \\rho^\\alpha. Sostituendo nell’equazione, si ottiene:\n\\qquad \\alpha(\\alpha - 1) \\rho^\\alpha + \\alpha \\rho^\\alpha - n^2 \\rho^\\alpha = 0\n\\qquad \\alpha^2 - n^2 = 0\n\\qquad \\alpha = \\pm n\nQuindi, le soluzioni sono R(\\rho) = c_1 \\rho^n + c_2 \\rho^{-n}. Per n = 0, la soluzione è R(\\rho) = c_1 \\ln \\rho + c_2.\nSoluzioni Limitate all’Origine\nPoiché la soluzione deve essere limitata all’origine, si scartano le soluzioni con \\rho^{-n} e \\ln \\rho. Rimangono le soluzioni del tipo:\n\\qquad R_n(\\rho) = \\rho^n\nSoluzione Generale\nCombinando le soluzioni per \\Theta(\\theta) e R(\\rho), si ottiene la famiglia di soluzioni a variabili separate:\n\\qquad U_n(\\rho, \\theta) = \\rho^n (A_n \\cos(n\\theta) + B_n \\sin(n\\theta))\ncon n = 0, 1, 2, \\dots. La soluzione generale è una combinazione lineare di queste soluzioni.\nSoluzioni a Variabili Separate\n\\begin{cases}u_n(\\rho, \\theta) = \\rho^n (a_n \\cos(n\\theta) + b_n \\sin(n\\theta))\\\\ u_o(\\rho, \\theta)=a_o\\end{cases}   per n \\ge 1, e u_0(\\rho, \\theta) = a_0.\nReferences"},"6--full-note/Edp--Lez04":{"slug":"6--full-note/Edp--Lez04","filePath":"6- full note/Edp- Lez04.md","title":"Edp- Lez04","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/Metodi-Analitici-per-le-Equazioni-alle-Derivate-Parziali","3--tag/sbobine"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-02-21 12:51\n_Status: flashcard_zero riscritto_zero revisione_zero\n_Tags: Metodi Analitici per le Equazioni alle Derivate Parziali   sbobine\nlez04- Edp\nRisoluzione del Problema di Dirichlet nel Cerchio\nObiettivo: Trovare una funzione u(\\rho, \\theta) che soddisfi l’equazione di Laplace in coordinate polari all’interno di un cerchio di raggio R e che assuma un valore specificato g(\\theta) sul bordo del cerchio.\n1. Impostazione del Problema\nSi cerca u tale che:\n\n\\Delta u = 0 per \\rho &lt; R\nu(R, \\theta) = g(\\theta)\n\ndove \\Delta è l’operatore di Laplace.\n2. Separazione delle Variabili\nSi cerca soluzioni nella forma u(\\rho, \\theta) = P(\\rho)Q(\\theta). Questo porta a soluzioni speciali che sono prodotti di funzioni radiali e angolari. In coordinate polari, le soluzioni trovate sono del tipo:\n\nu_n(\\rho, \\theta) = a_0 + \\sum_{n=1}^{\\infty} (\\rho^n (a_n \\cos(n\\theta) + b_n \\sin(n\\theta)))\n\nQueste soluzioni sono chiamate armoniche elementari del piano. In coordinate cartesiane, queste funzioni armoniche sono la parte reale e immaginaria di una funzione olomorfa z^n, dove z = x + iy.\n3. Combinazione Lineare Infinita\nIdea chiave: Considerare una combinazione lineare infinita delle soluzioni ottenute.\nu(\\rho, \\theta) = a_0 + \\sum_{n=1}^{\\infty} (\\rho^n (a_n \\cos(n\\theta) + b_n \\sin(n\\theta)))\nMotivazione: Una singola soluzione o una somma finita raramente soddisfa la condizione al bordo a meno che g(\\theta) non sia già un polinomio trigonometrico.\nPreoccupazioni:\n\nLa serie infinita ha senso? Converge?\nLa serie soddisfa ancora l’equazione di Laplace? (Problema di derivazione termine a termine)\n\n4. Determinazione dei Coefficienti\nStrategia: Ignorare temporaneamente le questioni di convergenza e derivabilità per trovare una “candidata formula risolutiva”.\n\nImporre u(R, \\theta) = g(\\theta):\n\nu(R, \\theta) = a_0 + \\sum_{n=1}^{\\infty} (R^n (a_n \\cos(n\\theta) + b_n \\sin(n\\theta))) = g(\\theta)\n\nRiconoscere che la serie a primo membro è una serie trigonometrica che deve rappresentare g(\\theta).\nIdentificare la serie con la serie di Fourier di g(\\theta):\n\ng(\\theta) = \\frac{\\alpha_0}{2} + \\sum_{n=1}^{\\infty} (\\alpha_n \\cos(n\\theta) + \\beta_n \\sin(n\\theta))\ndove\n\\alpha_n = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} g(\\theta) \\cos(n\\theta) d\\theta\n\\beta_n = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} g(\\theta) \\sin(n\\theta) d\\theta\n\nUguagliare i coefficienti:\n\na_0 = \\frac{\\alpha_0}{2}\nR^n a_n = \\alpha_n \\Rightarrow a_n = \\frac{\\alpha_n}{R^n}\nR^n b_n = \\beta_n \\Rightarrow b_n = \\frac{\\beta_n}{R^n}\n5. Candidata Formula Risolutiva\nSostituire i coefficienti trovati nell’espressione di u(\\rho, \\theta):\nu(\\rho, \\theta) = \\frac{\\alpha_0}{2} + \\sum_{n=1}^{\\infty} \\left( \\frac{\\rho}{R} \\right)^n (\\alpha_n \\cos(n\\theta) + \\beta_n \\sin(n\\theta))\ndove \\alpha_n e \\beta_n sono i coefficienti di Fourier di g(\\theta).\n6. Giustificazione Rigorosa\nObiettivo: Dimostrare che la candidata formula risolutiva è effettivamente una soluzione del problema di Dirichlet.\nPunti da Verificare:\n\nConvergenza della serie: Studiare la convergenza della serie di funzioni che definisce u(\\rho, \\theta).\nContinuità: Provare che u è continua nel dominio, possibilmente fino alla chiusura.\nDerivabilità: Verificare che u sia derivabile e che le derivate soddisfino l’equazione di Laplace.\nCondizione al bordo: Dimostrare che u(R, \\theta) = g(\\theta).\n\n7. Convergenza e Continuità\n\nStima dei coefficienti di Fourier: |\\alpha_n| \\leq \\frac{1}{\\pi} \\int_{0}^{2\\pi} |g(\\theta)| d\\theta (e analogamente per \\beta_n). Questo implica che \\alpha_n e \\beta_n sono limitati se g è integrabile.\nConvergenza Totale: Fissare r &lt; R e considerare \\rho \\in [0, r]. Allora \\left| \\left( \\frac{\\rho}{R} \\right)^n (\\alpha_n \\cos(n\\theta) + \\beta_n \\sin(n\\theta)) \\right| \\leq C \\delta^n, dove \\delta = \\frac{r}{R} &lt; 1 e C è una costante. La serie \\sum C \\delta^n converge, quindi la serie che definisce u converge totalmente in ogni cerchio \\rho \\leq r.\nContinuità: La convergenza totale implica la convergenza uniforme, e quindi u è continua in ogni cerchio \\rho \\leq r. Poiché questo vale per ogni r &lt; R, u è continua nel cerchio aperto \\rho &lt; R.\n\n8. Derivabilità e Armonicità\n\nDerivazione Termine a Termine: Le derivate dei singoli termini della serie convergono totalmente in ogni cerchio \\rho \\leq r. Questo permette di derivare la serie termine a termine.\nArmonicità: Poiché ogni termine della serie è una funzione armonica (cioè soddisfa l’equazione di Laplace), anche la somma della serie è armonica. Quindi \\Delta u = 0 per \\rho &lt; R.\n\n9. Assunzione della Condizione al Bordo\nCaso 1: g Regolare\n\nSe g è continua, regolare a tratti e soddisfa la condizione di raccordo g(0) = g(2\\pi), allora la serie di Fourier di g converge totalmente.\nIn questo caso, la serie che definisce u converge uniformemente sul cerchio chiuso \\rho \\leq R, e quindi u è continua fino al bordo e u(R, \\theta) = g(\\theta).\n\nCaso 2: g \\in L^2(0, 2\\pi)\n\nSe g è solo L^2, la serie di Fourier di g converge in L^2.\nIn questo caso, u assume il dato al bordo in senso L^2, cioè \\lim_{\\rho \\to R} \\int_{0}^{2\\pi} |u(\\rho, \\theta) - g(\\theta)|^2 d\\theta = 0.\n\n10. Unicità\nLa soluzione trovata è l’unica soluzione del problema di Dirichlet.\nProblema di Neumann sul Cerchio\nObiettivo: Trovare u(\\rho, \\theta) tale che:\n\n\\Delta u = 0 per \\rho &lt; R\n\\frac{\\partial u}{\\partial \\nu} (R, \\theta) = g(\\theta), dove \\frac{\\partial u}{\\partial \\nu} è la derivata normale sul bordo.\n\n1. Espressione Generale della Soluzione\nSi parte dalla stessa espressione generale per la soluzione dell’equazione di Laplace in coordinate polari:\nu(\\rho, \\theta) = a_0 + \\sum_{n=1}^{\\infty} \\rho^n (a_n \\cos(n\\theta) + b_n \\sin(n\\theta))\n2. Imposizione della Condizione al Bordo\n\nCalcolare la derivata normale (radiale):\n\n\\frac{\\partial u}{\\partial \\rho} = \\sum_{n=1}^{\\infty} n \\rho^{n-1} (a_n \\cos(n\\theta) + b_n \\sin(n\\theta))\n\nImporre la condizione al bordo:\n\n\\frac{\\partial u}{\\partial \\rho}(R, \\theta) = \\sum_{n=1}^{\\infty} n R^{n-1} (a_n \\cos(n\\theta) + b_n \\sin(n\\theta)) = g(\\theta)\n3. Condizione di Compatibilità\n\nScrivere la serie di Fourier di g(\\theta):\n\ng(\\theta) = \\frac{\\alpha_0}{2} + \\sum_{n=1}^{\\infty} (\\alpha_n \\cos(n\\theta) + \\beta_n \\sin(n\\theta))\n\nUguagliare i coefficienti:\n\nn R^{n-1} a_n = \\alpha_n n R^{n-1} b_n = \\beta_n\n\nSi nota che il termine costante nella serie di Fourier di g deve essere zero, cioè \\alpha_0 = 0. Questo porta alla condizione di compatibilità:\n\n\\int_{0}^{2\\pi} g(\\theta) d\\theta = 0\n4. Determinazione dei Coefficienti\nSe la condizione di compatibilità è soddisfatta, si possono trovare i coefficienti:\na_n = \\frac{\\alpha_n}{n R^{n-1}} b_n = \\frac{\\beta_n}{n R^{n-1}}\nIl coefficiente a_0 rimane arbitrario, il che riflette il fatto che la soluzione è definita a meno di una costante additiva.\n5. Soluzione\nLa soluzione del problema di Neumann è quindi:\nu(\\rho, \\theta) = a_0 + \\sum_{n=1}^{\\infty} \\frac{\\rho^n}{n R^{n-1}} (\\alpha_n \\cos(n\\theta) + \\beta_n \\sin(n\\theta))\ndove a_0 è una costante arbitraria.\nEsercizio 1\nTesto del problema:\nRisolvere \\Delta u = 0 per \\rho &lt; 3 con la condizione al bordo u(3, \\theta) = \\theta(2\\pi - \\theta).\nSoluzione:\n\n\nIdentificazione del problema: Si tratta di un problema di Dirichlet con g(\\theta) = \\theta(2\\pi - \\theta) e R = 3.\n\n\nApplicazione della formula risolutiva: La soluzione generale è data da:\nu(\\rho, \\theta) = \\frac{\\alpha_0}{2} + \\sum_{n=1}^{\\infty} \\left(\\frac{\\rho}{3}\\right)^n (\\alpha_n \\cos(n\\theta) + \\beta_n \\sin(n\\theta))\n\n\nCalcolo dei coefficienti di Fourier:\n\n\\alpha_n = \\frac{1}{\\pi} \\int_{0}^{2\\pi} g(\\theta) \\cos(n\\theta) d\\theta\n\\beta_n = \\frac{1}{\\pi} \\int_{0}^{2\\pi} g(\\theta) \\sin(n\\theta) d\\theta\n\n\n\nSimmetria della funzione g(θ): g(\\theta) è pari rispetto a \\pi, quindi i coefficienti \\beta_n sono tutti zero. Questo semplifica notevolmente i calcoli.\n\n\nCalcolo di α₀:\n\\alpha_0 = \\frac{1}{\\pi} \\int_{0}^{2\\pi} \\theta(2\\pi - \\theta) d\\theta = \\frac{2}{\\pi} \\int_{0}^{\\pi} \\theta(2\\pi - \\theta) d\\theta = \\frac{2\\pi^2}{3}\n\n\nCalcolo di αₙ per n &gt; 0:\n\\alpha_n = \\frac{2}{\\pi} \\int_{0}^{\\pi} \\theta(2\\pi - \\theta) \\cos(n\\theta) d\\theta = \\frac{8}{n^2}\n(Questo calcolo richiede integrazione per parti).\n\n\nSoluzione finale:\nu(\\rho, \\theta) = \\frac{\\pi^2}{3} + \\sum_{n=1}^{\\infty} \\left(\\frac{\\rho}{3}\\right)^n \\frac{8}{n^2} \\cos(n\\theta)\n\n\nCommenti:\n\nLa convergenza totale della serie è garantita fino al bordo perché i coefficienti di Fourier decadono come 1/n^2.\nLa soluzione è classica perché g(\\theta) è continua, regolare a tratti e soddisfa le condizioni di raccordo.\n\nEsercizio 2\nTesto del problema:\nRisolvere \\Delta u(x, y) = 0 per x^2 + y^2 &lt; 4 con la condizione al bordo u(x, y) = x^2y per x^2 + y^2 = 4.\nSoluzione:\n\n\nRiscrivere la condizione al bordo in coordinate polari: Poiché siamo sul bordo, usiamo x = 2\\cos(\\theta) e y = 2\\sin(\\theta). Quindi x^2y = (2\\cos(\\theta))^2 (2\\sin(\\theta)) = 8\\cos^2(\\theta)\\sin(\\theta).\n\n\nIdentificazione del problema: Problema di Dirichlet con R = 2 e g(\\theta) = 8\\cos^2(\\theta)\\sin(\\theta).\n\n\nSemplificazione usando identità trigonometriche: L’obiettivo è esprimere g(\\theta) come una somma finita di seni e coseni, ovvero un polinomio trigonometrico.\n8\\cos^2(\\theta)\\sin(\\theta) = 8\\cos(\\theta) (\\cos(\\theta)\\sin(\\theta)) = 8\\cos(\\theta) \\left(\\frac{1}{2}\\sin(2\\theta)\\right) = 4\\cos(\\theta)\\sin(2\\theta)\nUsando la formula di Werner:\n4\\cos(\\theta)\\sin(2\\theta) = 2[\\sin(3\\theta) + \\sin(\\theta)]\n\n\nApplicazione diretta della soluzione: Poiché g(\\theta) è una somma finita, la soluzione è una somma finita:\nu(\\rho, \\theta) = 2\\left(\\frac{\\rho}{2}\\right) \\sin(\\theta) + 2\\left(\\frac{\\rho}{2}\\right)^3 \\sin(3\\theta) = \\rho\\sin(\\theta) + \\frac{\\rho^3}{4}\\sin(3\\theta)\n\n\nRiscrivere in coordinate cartesiane (opzionale):\nu(x, y) = y + \\frac{1}{4}(3x^2y - y^3)\n\n\nCommenti:\n\nQuesto esercizio mostra come, quando il dato al bordo è un polinomio trigonometrico, non è necessario calcolare integrali infiniti.\nL’uso delle identità trigonometriche semplifica notevolmente il problema.\nLa soluzione ottenuta è già nella forma di armoniche elementari, quindi non c’è bisogno di ulteriori passaggi.\nL’esercizio evidenzia l’importanza di riconoscere le strutture speciali nel dato al bordo per semplificare i calcoli.\n\nReferences"},"6--full-note/Edp--lez05":{"slug":"6--full-note/Edp--lez05","filePath":"6- full note/Edp- lez05.md","title":"Edp- lez05","links":["tags/flashcard_zero","tags/revisione_zero","tags/riscritto_zero","3--tag/Metodi-Analitici-per-le-Equazioni-alle-Derivate-Parziali","3--tag/sbobine"],"tags":["flashcard_zero","revisione_zero","riscritto_zero"],"content":"2025-02-24 10:51\n_Status: flashcard_zero revisione_zero  riscritto_zero\n_Tags: Metodi Analitici per le Equazioni alle Derivate Parziali. sbobine\nEdp- lez05\nCommenti sugli esercizi della scorsa lezione e problema di Dirichlet\nIl professore inizia con un commento sugli esercizi della lezione precedente relativi al problema di Dirichlet, in particolare su un esercizio riguardante il tracciamento con un cerchio. Dopo aver ottenuto una soluzione analitica, si suggerisce di visualizzare il grafico tramite computer. Tuttavia, poiché il computer può solo plottare un numero finito di termini della serie, è necessario interpretare correttamente il significato del grafico ottenuto.\nSomme parziali e loro significato\nLa somma parziale della serie fino a n=5 fornisce un’approssimazione della soluzione. Per capire cosa rappresenta questa approssimazione, si considera la formula risolutiva ottenuta. Questa formula esprime la soluzione come una funzione armonica all’interno del cerchio. La somma parziale fino a n=5 rappresenta la soluzione esatta corrispondente a un dato al bordo diverso, ovvero quello il cui sviluppo in serie di Fourier è la somma parziale fino a n=5.\nIn altre parole, il grafico della somma parziale della soluzione fino a n=5 può essere interpretato come la soluzione esatta di un problema con un dato al bordo approssimato, la cui serie di Fourier coincide con la somma parziale considerata.\nTeoremi di convergenza e dipendenza continua\nPer quantificare l’errore commesso approssimando la soluzione con la somma parziale, è necessario combinare due concetti:\n\nConvergenza della serie di Fourier: La somma parziale della serie di Fourier tende alla serie completa se vale un teorema di convergenza per la serie di Fourier.\nDipendenza continua della soluzione dal dato: Un teorema che lega l’errore nell’approssimazione della soluzione all’errore nell’approssimazione del dato al bordo.\n\nIdealmente, si vorrebbe un risultato che mostri come l’errore tra due soluzioni è controllato dallo scarto tra i dati al bordo corrispondenti. Questo permetterebbe di affermare che la soluzione ottenuta con la somma parziale è vicina alla soluzione vera nella misura in cui la somma parziale di Fourier approssima il dato al bordo originale.\nProblema di Neumann sul cerchio\nIl professore riprende il problema di Neumann sul cerchio. Si ricorda che le soluzioni a variabili separate sono le stesse del problema di Dirichlet. Imponendo che una serie di queste soluzioni soddisfi il dato al bordo, si ottiene una candidata formula risolutiva.\nCondizione di compatibilità\nUna condizione necessaria per l’esistenza di soluzioni è che l’integrale del dato sul bordo sia uguale a zero. Questo è noto come condizione di compatibilità. Fisicamente, questa condizione rappresenta un bilancio nullo tra il calore fornito e sottratto dal bordo in un problema di temperatura stazionaria su un disco.\nUnicità a meno di una costante additiva\nAnche nel problema di Neumann, la soluzione è unica a meno di una costante additiva. Questo emerge naturalmente dai calcoli.\nRegolarità della soluzione\nSe il dato al bordo g è L^2(0, 2\\pi), i coefficienti di Fourier sono limitati. La serie che definisce u converge totalmente in ogni cerchio strettamente contenuto in quello dato. Questo implica che u è C^\\infty all’interno del cerchio e armonica. Per avere una soluzione classica del problema di Neumann, si richiede che le derivate esistano continue fino al bordo. Questo richiede ipotesi più forti sul dato al bordo.\nEsempi numerici per il problema di Neumann\nEsempio 1: Dato al bordo discontinuo\nSi considera un problema di Neumann con raggio R=3 e dato al bordo g(\\theta) = 1 per \\theta \\in (0, \\pi) e g(\\theta) = -1 per \\theta \\in (-\\pi, 0). Questo dato al bordo è discontinuo e non soddisfa le ipotesi della teoria generale. Tuttavia, si procede formalmente e si verifica che la condizione di compatibilità è soddisfatta.\nLa soluzione è data da:\nu(\\rho, \\theta) = a_0 + \\sum_{n=1}^{\\infty} \\frac{\\rho^n}{3^{n-1}} (\\alpha_n \\cos(n\\theta) + \\beta_n \\sin(n\\theta))\ndove \\alpha_n e \\beta_n sono i coefficienti di Fourier di g.\nPoiché g è dispari, \\alpha_n = 0 per ogni n. I coefficienti \\beta_n sono dati da:\n\\beta_n = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} g(\\theta) \\sin(n\\theta) d\\theta = \\frac{2}{\\pi} \\int_{0}^{\\pi} \\sin(n\\theta) d\\theta = \\frac{2}{n\\pi} (1 - \\cos(n\\pi))\nQuindi, \\beta_n = 0 se n è pari e \\beta_n = \\frac{4}{n\\pi} se n è dispari.\nLa soluzione diventa:\nu(\\rho, \\theta) = a_0 + \\sum_{k=0}^{\\infty} \\frac{\\rho^{2k+1}}{3^{2k}} \\frac{4}{(2k+1)\\pi} \\sin((2k+1)\\theta)\nIl grafico della soluzione mostra un comportamento tipico in corrispondenza della discontinuità del dato al bordo, con il fenomeno di Gibbs.\nEsempio 2: Dato al bordo trigonometrico\nSi considera un problema di Neumann con dato al bordo g(\\theta) = \\cos(\\theta) \\sin^2(\\theta). In questo caso, il dato al bordo è un polinomio trigonometrico, quindi non è necessario calcolare i coefficienti di Fourier tramite integrazione. Si sfrutta l’identità trigonometrica:\n\\sin^2(\\theta) = \\frac{1 - \\cos(2\\theta)}{2}\nQuindi, g(\\theta) = \\cos(\\theta) \\frac{1 - \\cos(2\\theta)}{2} = \\frac{1}{2} \\cos(\\theta) - \\frac{1}{2} \\cos(\\theta) \\cos(2\\theta)\nUsando la formula di Werner:\n\\cos(\\theta) \\cos(2\\theta) = \\frac{1}{2} (\\cos(3\\theta) + \\cos(\\theta))\nQuindi, g(\\theta) = \\frac{1}{2} \\cos(\\theta) - \\frac{1}{4} \\cos(3\\theta) - \\frac{1}{4} \\cos(\\theta) = \\frac{1}{4} \\cos(\\theta) - \\frac{1}{4} \\cos(3\\theta)\nLa soluzione è data da:\nu(\\rho, \\theta) = a_0 + \\frac{\\rho}{4} \\cos(\\theta) - \\frac{\\rho^3}{36} \\cos(3\\theta)\nFormula integrale di Poisson\nIl professore introduce la formula integrale di Poisson come alternativa alla rappresentazione in serie per risolvere il problema di Dirichlet. Questa formula permette di ottenere risultati più raffinati riguardo alla regolarità della soluzione, in particolare in presenza di discontinuità nel dato al bordo. L’idea è di sostituire i coefficienti di Fourier nella formula in serie con le loro espressioni integrali e manipolare l’espressione per ottenere una formula integrale.\nPassaggi matematici\nSi parte dalla formula in serie:\nu(\\rho, \\theta) = \\frac{\\alpha_0}{2} + \\sum_{n=1}^{\\infty} \\left(\\frac{\\rho}{R}\\right)^n (\\alpha_n \\cos(n\\theta) + \\beta_n \\sin(n\\theta))\nSostituendo le espressioni integrali per i coefficienti di Fourier (cambiando la variabile di integrazione da \\theta a \\phi per evitare confusione):\n\\alpha_n = \\frac{1}{\\pi} \\int_{0}^{2\\pi} g(\\phi) \\cos(n\\phi) d\\phi \\beta_n = \\frac{1}{\\pi} \\int_{0}^{2\\pi} g(\\phi) \\sin(n\\phi) d\\phi\nSi ottiene:\nu(\\rho, \\theta) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} g(\\phi) d\\phi + \\sum_{n=1}^{\\infty} \\left(\\frac{\\rho}{R}\\right)^n \\left( \\frac{1}{\\pi} \\int_{0}^{2\\pi} g(\\phi) \\cos(n\\phi) \\cos(n\\theta) + g(\\phi) \\sin(n\\phi) \\sin(n\\theta) d\\phi \\right)\nu(\\rho, \\theta) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} g(\\phi) d\\phi + \\frac{1}{\\pi} \\int_{0}^{2\\pi} g(\\phi) \\sum_{n=1}^{\\infty} \\left(\\frac{\\rho}{R}\\right)^n \\cos(n(\\theta - \\phi)) d\\phi\nScambiando la serie con l’integrale (sotto opportune ipotesi di convergenza che verranno dimostrate poi), si ottiene:\nu(\\rho, \\theta) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} g(\\phi) \\left[ 1 + 2 \\sum_{n=1}^{\\infty} \\left(\\frac{\\rho}{R}\\right)^n \\cos(n(\\theta - \\phi)) \\right] d\\phi\nLa serie all’interno dell’integrale può essere sommata esplicitamente. Ponendo z = \\frac{\\rho}{R} e^{i(\\theta - \\phi)}, la serie diventa la parte reale di una serie geometrica:\n1 + 2 \\sum_{n=1}^{\\infty} \\left(\\frac{\\rho}{R}\\right)^n \\cos(n(\\theta - \\phi)) = 1 + 2 \\Re \\left( \\sum_{n=1}^{\\infty} z^n \\right) = 1 + 2 \\Re \\left( \\frac{z}{1 - z} \\right)\nDopo alcune manipolazioni algebriche, si ottiene:\n1 + 2 \\Re \\left( \\frac{z}{1 - z} \\right) = \\frac{R^2 - \\rho^2}{R^2 + \\rho^2 - 2R\\rho \\cos(\\theta - \\phi)}\nSostituendo questa espressione nell’integrale, si ottiene la formula integrale di Poisson:\nu(\\rho, \\theta) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} g(\\phi) \\frac{R^2 - \\rho^2}{R^2 + \\rho^2 - 2R\\rho \\cos(\\theta - \\phi)} d\\phi\nLa funzione K(\\rho, \\theta, \\phi) = \\frac{1}{2\\pi} \\frac{R^2 - \\rho^2}{R^2 + \\rho^2 - 2R\\rho \\cos(\\theta - \\phi)} è nota come nucleo di Poisson.\nAnalisi della formula integrale di Poisson e teoremi di convergenza\nIl professore spiega in dettaglio alcuni aspetti cruciali riguardanti la formula integrale di Poisson e la sua convergenza, concentrandosi sulle condizioni che ne garantiscono la validità e l’applicabilità.\nPassaggio dalla serie all’integrale: convergenza uniforme\nIl punto chiave è giustificare il passaggio dalla serie all’integrale nella derivazione della formula di Poisson. Questo scambio è lecito sotto opportune ipotesi di convergenza uniforme della serie.\n\n\nIl professore sottolinea che i passaggi che portano alla formula sono puramente algebrici, eccetto uno: lo scambio tra la serie e l’integrale.\n\n\nQuesto scambio richiede che la serie di integrali converga uniformemente. In termini matematici, si deve verificare se la seguente serie converge uniformemente per \\theta \\in [0, 2\\pi] quando \\rho e \\theta_0 sono fissati:\n\\sum_{n=1}^{\\infty} f(\\phi) \\frac{\\rho^n}{R^n} \\cos(n(\\theta - \\theta_0))\ndove f è la funzione integranda.\n\n\nConvergenza totale implica convergenza uniforme: Per dimostrare la convergenza uniforme, si utilizza il criterio di convergenza totale. Si maggiora il modulo di ogni termine della serie con una costante tale che la serie delle costanti converga. In questo caso, si ha:\n|f(\\phi) \\frac{\\rho^n}{R^n} \\cos(n(\\theta - \\theta_0))| \\leq |f(\\phi)| \\frac{\\rho^n}{R^n}\nSe |f(\\phi)| è limitata da una costante M e \\rho &lt; R, allora la serie converge totalmente e quindi uniformemente.\n\n\nIl ruolo di \\rho &lt; R: La condizione \\rho &lt; R è cruciale per garantire la convergenza della serie geometrica \\sum_{n=1}^{\\infty} (\\frac{\\rho}{R})^n. Questo assicura che il termine \\frac{\\rho^n}{R^n} decresca sufficientemente velocemente da rendere convergente la serie.\n\n\nTeorema chiave: regolarità all’interno del cerchio\nIl professore enuncia un teorema fondamentale:\n\n\nSe f è integrabile e limitata su [0, 2\\pi], allora la funzione u(\\rho, \\theta) assegnata dalla formula integrale di Poisson è C^{\\infty} (infinitamente differenziabile) e armonica all’interno del cerchio. In altre parole:\nu(\\rho, \\theta) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} f(\\phi) \\frac{R^2 - \\rho^2}{R^2 + \\rho^2 - 2R\\rho \\cos(\\theta - \\phi)} d\\phi\nè C^{\\infty} e \\Delta u = 0 per \\rho &lt; R.\n\n\nQuesto teorema è importante perché garantisce che la formula integrale di Poisson fornisce una soluzione regolare all’interno del cerchio, sotto ipotesi relativamente deboli sul dato al bordo f.\n\n\nIl professore precisa che questo risultato non richiede di ripartire da zero per dimostrare la regolarità e l’armonicità della soluzione ottenuta tramite la formula integrale.\n\n\nTeorema di convergenza al bordo: continuità\nIl professore introduce un altro teorema cruciale, che riguarda il comportamento della soluzione quando ci si avvicina al bordo del cerchio:\n\n\nSe f è integrabile e limitata su [0, 2\\pi] e continua in un punto \\theta_0, allora:\n\\lim_{\\rho \\to R} u(\\rho, \\theta_0) = f(\\theta_0)\nIn altre parole, la soluzione u(\\rho, \\theta) converge al valore del dato al bordo f nel punto di continuità \\theta_0.\n\n\nSignificato: Questo teorema afferma che la formula integrale di Poisson assegna una soluzione che, oltre ad essere armonica all’interno, assume il dato al bordo nei punti in cui il dato al bordo è continuo.\n\n\nCaso particolare: dato al bordo continuo su tutto il bordo: Se f è continua su tutto il bordo (cioè f \\in C^0([0, 2\\pi]) e f(0) = f(2\\pi)), allora la formula integrale di Poisson fornisce la soluzione classica del problema di Dirichlet.\n\n\nAnalisi del nucleo di Poisson\nIl professore analizza il nucleo di Poisson per fornire un’interpretazione intuitiva dei teoremi di convergenza.\n\n\nIl nucleo di Poisson è definito come:\nK(\\rho, \\theta, \\phi) = \\frac{1}{2\\pi} \\frac{R^2 - \\rho^2}{R^2 + \\rho^2 - 2R\\rho \\cos(\\theta - \\phi)}\n\n\nProprietà chiave: Il numeratore tende a zero quando \\rho tende a R. Tuttavia, anche il denominatore può tendere a zero, a seconda del valore di \\theta - \\phi.\n\n\nComportamento al bordo:\n\nSe \\theta = \\phi, il denominatore diventa (R - \\rho)^2, e quindi il nucleo di Poisson tende all’infinito quando \\rho \\to R.\nSe \\theta \\neq \\phi, il denominatore rimane strettamente positivo, e quindi il nucleo di Poisson tende a zero quando \\rho \\to R.\n\n\n\nInterpretazione: Questo comportamento suggerisce che il nucleo di Poisson si comporta come una sorta di “delta di Dirac” sulla circonferenza. Quando \\rho si avvicina a R, il nucleo diventa molto concentrato attorno al punto \\theta = \\phi, mentre tende a zero altrove. Questo spiega perché la soluzione tende al valore del dato al bordo nel punto di continuità.\n\n\nRegolarità all’interno e convergenza al bordo\nIl professore riassume i risultati principali:\n\nLa soluzione u(\\rho, \\theta) è regolare all’interno del cerchio (cioè C^{\\infty}) per \\rho &lt; R.\nLa cosa delicata è dimostrare che, quando \\rho tende a R, la soluzione u(\\rho, \\theta) tende al dato al bordo f(\\theta) nei punti di continuità di f.\n\nProblema di Replay nel semipiano\nIl professore introduce il problema di Replay nel semipiano, sottolineando che, insieme al cerchio, rappresenta uno dei domini più semplici per studiare problemi di questo tipo.\n\nMotivazione: L’idea è di analizzare prima questi due esempi concreti (cerchio e semipiano) per comprendere meglio le proprietà delle soluzioni, per poi passare allo studio di proprietà generali del problema di Dirichlet.\nTrasformata di Fourier: Per risolvere il problema di Replay nel semipiano, si farà uso della trasformata di Fourier.\n\nRichiami sulla trasformata di Fourier e teoremi di continuità e derivabilità degli integrali dipendenti da un parametro\nNecessità di strumenti matematici\nPer affrontare il problema di Replay nel semipiano, il professore introduce alcuni strumenti matematici necessari, in particolare teoremi riguardanti la continuità e la derivabilità di integrali dipendenti da un parametro. Questi strumenti sono essenziali per manipolare le formule integrali che si incontrano nella risoluzione di problemi di equazioni alle derivate parziali.\nMotivazione\nL’obiettivo è di giustificare operazioni come portare la derivata sotto il segno di integrale o calcolare limiti sotto il segno di integrale.\nSetting generale\nSi considera una funzione u(x) definita come un integrale:\nu(x) = \\int_{\\Omega} K(x, y) dy\ndove:\n\nx è un parametro scalare.\ny è la variabile di integrazione.\n\\Omega è un sottoinsieme misurabile di \\mathbb{R}.\nK(x, y) è una funzione integranda.\n\nTeorema di continuità\nIl professore enuncia un teorema che fornisce condizioni sufficienti per la continuità di u(x):\n\nIpotesi:\n\nK(x, y) \\in L^1(\\Omega) per ogni x in un intervallo I. In altre parole, per ogni x \\in I, la funzione K(x, y) è integrabile rispetto a y su \\Omega.\nEsiste un x_0 \\in I e un intorno (x_0 - \\delta, x_0 + \\delta) tale che, per quasi ogni y \\in \\Omega, la funzione K(x, y) (vista come funzione di x) è continua in x_0.\nEsiste una funzione g(y) \\in L^1(\\Omega) tale che |K(x, y)| \\leq g(y) per ogni x nell’intorno (x_0 - \\delta, x_0 + \\delta) e per quasi ogni y \\in \\Omega. La funzione g(y) è una dominante integrabile.\n\n\nTesi:\n\nu(x) è continua in x_0.\n\n\n\nIdea della dimostrazione\nLa dimostrazione si basa sul teorema della convergenza dominata di Lebesgue. L’idea è di approssimare x con una successione x_n convergente a x_0, e quindi applicare il teorema della convergenza dominata per scambiare il limite con l’integrale.\nTeorema di derivabilità\nIl professore enuncia un teorema che fornisce condizioni sufficienti per la derivabilità di u(x):\n\nIpotesi:\n\nEsiste un intervallo (x_0 - \\delta, x_0 + \\delta) e una funzione g(y) \\in L^1(\\Omega) tale che K(x, y) \\in L^1(\\Omega) per ogni x in questo intervallo.\nPer quasi ogni y \\in \\Omega e per ogni x nell’intervallo (x_0 - \\delta, x_0 + \\delta), esiste la derivata parziale di K rispetto a x, denotata con \\frac{\\partial K}{\\partial x}(x, y).\nEsiste una funzione g(y) \\in L^1(\\Omega) tale che |\\frac{\\partial K}{\\partial x}(x, y)| \\leq g(y) per ogni x nell’intorno (x_0 - \\delta, x_0 + \\delta) e per quasi ogni y \\in \\Omega. La funzione g(y) è una dominante integrabile.\n\n\nTesi:\n\n\nEsiste la derivata di u(x) in x_0, e si può calcolare scambiando la derivata con l’integrale:\nu&#039;(x_0) = \\int_{\\Omega} \\frac{\\partial K}{\\partial x}(x_0, y) dy\n\n\n\nSignificato: Questo teorema afferma che si può derivare sotto il segno di integrale se la derivata parziale dell’integranda esiste, è integrabile e ammette una dominante integrabile.\n\nOsservazione\nIl professore sottolinea che l’ipotesi cruciale è l’esistenza della dominante integrabile per la derivata parziale. Questa condizione garantisce una sorta di “uniformità” nella derivabilità, permettendo lo scambio tra derivata e integrale.\nApplicazione\nQuesti teoremi sono fondamentali per verificare che le formule risolutive ottenute (ad esempio, tramite la formula integrale di Poisson) soddisfano effettivamente l’equazione alle derivate parziali. In particolare, permettono di giustificare il calcolo delle derivate necessarie per verificare che la soluzione proposta soddisfa l’equazione.\nTrasformata di Fourier: definizione e proprietà\nIl professore introduce la trasformata di Fourier, uno strumento essenziale per risolvere il problema di Replay nel semipiano.\n\n\nDefinizione: Sia f \\in L^1(\\mathbb{R}^n) (cioè, f è una funzione integrabile su \\mathbb{R}^n). La trasformata di Fourier di f, denotata con \\hat{f} o F[f], è definita come:\n\\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} f(x) e^{-2\\pi i x \\cdot \\xi} dx\ndove x \\cdot \\xi indica il prodotto scalare tra x e \\xi.\n\n\nOsservazioni:\n\nLa trasformata di Fourier trasforma una funzione nello spazio delle variabili originali (x) in una funzione nello spazio delle frequenze (\\xi).\nA volte, la trasformata di Fourier è definita senza il fattore 2\\pi nell’esponenziale. In questo caso, la variabile \\xi ha un’interpretazione fisica diversa (non è direttamente la frequenza).\n\n\n\nProprietà fondamentali:\n\n\nBen definita: Se f \\in L^1(\\mathbb{R}^n), allora \\hat{f} è ben definita. Questo segue dal fatto che l’integrale che definisce \\hat{f} converge, poiché |e^{-2\\pi i x \\cdot \\xi}| = 1.\n\n\nLimitata: Se f \\in L^1(\\mathbb{R}^n), allora \\hat{f} è limitata:\n|\\hat{f}(\\xi)| \\leq \\int_{\\mathbb{R}^n} |f(x)| dx = ||f||_{L^1}\n\n\nContinua: Se f \\in L^1(\\mathbb{R}^n), allora \\hat{f} è continua. Questo può essere dimostrato applicando il teorema di continuità degli integrali dipendenti da un parametro.\n\n\n\n\nOperatore lineare continuo: L’operatore che associa a una funzione f la sua trasformata di Fourier \\hat{f} è un operatore lineare continuo da L^1(\\mathbb{R}^n) allo spazio C_0(\\mathbb{R}^n) (funzioni continue che tendono a zero all’infinito). Inoltre, la norma dell’operatore è minore o uguale a 1. In simboli:\nF: L^1(\\mathbb{R}^n) \\to C_0(\\mathbb{R}^n)\n||\\hat{f}||_{C_0(\\mathbb{R}^n)} \\leq ||f||_{L^1(\\mathbb{R}^n)}\n\n\nReferences"},"6--full-note/Fisica1---Ese01":{"slug":"6--full-note/Fisica1---Ese01","filePath":"6- full note/Fisica1 - Ese01.md","title":"Fisica1 - Ese01","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/fisica-1","3--tag/sbobine"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-02-21 16:30\n_Status: flashcard_zero  riscritto_zero   revisione_zero\n_Tags: fisica 1  sbobine\nEse01- Fisica1\nAnalisi Dimensionale e Legge del Pendolo\nEsercizio 1.2: Determinazione della Legge del Pendolo\nObiettivo: Determinare la legge del pendolo attraverso considerazioni dimensionali, sapendo che il periodo T di oscillazione di un pendolo semplice dipende dalla lunghezza L del pendolo e dall’accelerazione di gravità locale g.\nPassaggi:\n\n\nDefinizione delle Dimensioni:\n\nPeriodo di oscillazione (\\tau): [ \\tau ] = T (Tempo).\nLunghezza del pendolo (L): [L] = L (Lunghezza).\nAccelerazione di gravità locale (g): [g] = LT^{-2} (Lunghezza per Tempo alla meno due). Il professore specifica che g vale 9,81 m/s².\n\n\n\nPrincipio di Omogeneità Dimensionale:\n\nIn ogni equazione fisica, entrambi i membri devono avere le stesse dimensioni. Questo principio è fondamentale per verificare la correttezza delle formule e per ricavare unità di misura sconosciute.\nEsempio: 1 \\text{ kg} = 1000 \\text{ g} rispetta il principio perché entrambi i membri rappresentano una massa.\n\n\n\nFormulazione della Relazione:\n\nSi ipotizza che il periodo di oscillazione \\tau dipenda da m (massa), L (lunghezza) e g (accelerazione di gravità) secondo la seguente relazione: \\tau = K \\cdot m^x \\cdot L^y \\cdot g^z dove K è una costante adimensionale. Il valore di K non è determinato dall’analisi dimensionale.\n\n\n\nAnalisi Dimensionale dell’Equazione:\n\nSi sostituiscono le dimensioni delle grandezze nella relazione: T = M^x \\cdot L^y \\cdot (LT^{-2})^z\n\n\n\nRiscrittura dell’Equazione:\n\nSi raggruppano le dimensioni fondamentali: T = M^x \\cdot L^{y+z} \\cdot T^{-2z}\n\n\n\nImposizione delle Condizioni:\n\nSi impone che le dimensioni corrispondano a quelle del periodo, ovvero T: \\begin{cases} x = 0 \\ y + z = 0 \\ -2z = 1 \\end{cases}\n\n\n\nSoluzione del Sistema:\n\nSi risolve il sistema di equazioni per trovare gli esponenti: \\begin{cases} x = 0 \\ z = -\\frac{1}{2} \\ y = \\frac{1}{2} \\end{cases}\n\n\n\nSostituzione degli Esponenti:\n\nSi sostituiscono i valori di x, y e z nella relazione originale: \\tau = K \\cdot m^0 \\cdot L^{\\frac{1}{2}} \\cdot g^{-\\frac{1}{2}}\n\n\n\nLegge del Pendolo:\n\nSi semplifica l’espressione per ottenere la legge del pendolo: \\tau = K \\sqrt{\\frac{L}{g}} Osservazioni:\n\nIl periodo di oscillazione non dipende dalla massa m.\nL’analisi dimensionale non permette di determinare il valore della costante adimensionale K.\n\n\n\n\n\nImportanza della Costante Adimensionale K\nLa costante K è sempre necessaria nell’analisi dimensionale. Anche se a priori non si conosce il suo valore, è importante includerla nella formula. Nella realtà, per il pendolo semplice, K = 2\\pi, ma questo non può essere determinato solo con l’analisi dimensionale.\nCalcolo Vettoriale\nEsercizio 2.10: Angolo tra Vettori e Componente Parallela\nDati:\n\nVettore \\vec{A} = 3\\hat{u}_x - \\hat{u}_y - 2\\hat{u}_z.\nVettore \\vec{B} = -\\hat{u}_x + 2\\hat{u}_y + 7\\hat{u}_z.\n\nObiettivi:\n\nTrovare l’angolo \\theta compreso tra i due vettori \\vec{A} e \\vec{B}.\nTrovare il vettore componente di \\vec{A} parallelo a \\vec{B}, espresso mediante le componenti cartesiane.\n\nPassaggi:\n\n\nCalcolo dei Moduli:\n\nModulo di \\vec{A}: |\\vec{A}| = \\sqrt{3^2 + (-1)^2 + (-2)^2} = \\sqrt{9 + 1 + 4} = \\sqrt{14}\nModulo di \\vec{B}: |\\vec{B}| = \\sqrt{(-1)^2 + 2^2 + 7^2} = \\sqrt{1 + 4 + 49} = \\sqrt{54} = 3\\sqrt{6}\n\n\n\nCalcolo dei Versori:\n\nVersore di \\vec{A}: \\hat{u}_A = \\frac{\\vec{A}}{|\\vec{A}|} = \\frac{1}{\\sqrt{14}}(3\\hat{u}_x - \\hat{u}_y - 2\\hat{u}_z)\nVersore di \\vec{B}: \\hat{u}_B = \\frac{\\vec{B}}{|\\vec{B}|} = \\frac{1}{3\\sqrt{6}}(-\\hat{u}_x + 2\\hat{u}_y + 7\\hat{u}_z)\n\n\n\nCalcolo del Prodotto Scalare dei Versori:\n\nIl prodotto scalare dei versori è uguale al coseno dell’angolo compreso: \\hat{u}_A \\cdot \\hat{u}_B = \\cos{\\theta}\nCalcolo del prodotto scalare: \\hat{u}_A \\cdot \\hat{u}_B = \\frac{1}{\\sqrt{14}} \\cdot \\frac{1}{3\\sqrt{6}} \\cdot (3 \\cdot (-1) + (-1) \\cdot 2 + (-2) \\cdot 7) = \\frac{-3 - 2 - 14}{3\\sqrt{14 \\cdot 6}} = \\frac{-19}{3\\sqrt{84}}\nQuindi: \\cos{\\theta} = \\frac{-19}{3\\sqrt{84}} \\approx -0.69\nL’angolo \\theta è: \\theta = \\arccos{(-0.69)} \\approx 134^\\circ\n\n\n\nCalcolo della Componente di \\vec{A} Parallela a \\vec{B}:\n\nLa componente scalare di \\vec{A} parallela a \\vec{B} è data dalla proiezione di \\vec{A} su \\hat{u}_B: A_B = \\vec{A} \\cdot \\hat{u}_B\nCalcolo della componente: A_B = (3\\hat{u}_x - \\hat{u}_y - 2\\hat{u}_z) \\cdot \\frac{1}{3\\sqrt{6}}(-\\hat{u}_x + 2\\hat{u}_y + 7\\hat{u}_z) = \\frac{1}{3\\sqrt{6}}(3 \\cdot (-1) + (-1) \\cdot 2 + (-2) \\cdot 7) = \\frac{-19}{3\\sqrt{6}}\n\n\n\nCalcolo del Vettore Componente di \\vec{A} Parallelo a \\vec{B}:\n\nPer ottenere il vettore componente \\vec{A}_B, si moltiplica la componente scalare A_B per il versore \\hat{u}_B: \\vec{A}_B = A_B \\cdot \\hat{u}_B = \\frac{-19}{3\\sqrt{6}} \\cdot \\frac{1}{3\\sqrt{6}}(-\\hat{u}_x + 2\\hat{u}_y + 7\\hat{u}_z) = \\frac{-19}{54}(-\\hat{u}_x + 2\\hat{u}_y + 7\\hat{u}_z) \\vec{A}_B = \\frac{19}{54}\\hat{u}_x - \\frac{38}{54}\\hat{u}_y - \\frac{133}{54}\\hat{u}_z\n\n\n\nEsercizio 2.14: Proiezione di un Vettore sulla Bisettrice\nDati:\n\nVettore \\vec{A} = 3\\hat{u}_x + 2\\sqrt{2}\\hat{u}_y + 4\\hat{u}_z.\n\nObiettivo:\n\nProiettare il vettore \\vec{A} sulla retta bisettrice del quadrante XY.\n\nPassaggi:\n\n\nDefinizione del Vettore Bisettrice:\n\nSi considera un vettore \\vec{b}_{xy} parallelo alla bisettrice del quadrante XY: \\vec{b}_{xy} = \\hat{u}_x + \\hat{u}_y\n\n\n\nCalcolo del Versore della Bisettrice:\n\nSi calcola il modulo di \\vec{b}_{xy}: |\\vec{b}_{xy}| = \\sqrt{1^2 + 1^2} = \\sqrt{2}\nSi нормализует \\vec{b}_{xy} per ottenere il versore \\hat{u}_{xy}: \\hat{u}_{xy} = \\frac{\\vec{b}_{xy}}{|\\vec{b}_{xy}|} = \\frac{1}{\\sqrt{2}}(\\hat{u}_x + \\hat{u}_y)\n\n\n\nProiezione del Vettore \\vec{A} sulla Bisettrice:\n\nSi calcola la componente di \\vec{A} lungo la direzione di \\hat{u}_{xy}: A_{xy} = \\vec{A} \\cdot \\hat{u}_{xy} = (3\\hat{u}_x + 2\\sqrt{2}\\hat{u}_y + 4\\hat{u}_z) \\cdot \\frac{1}{\\sqrt{2}}(\\hat{u}_x + \\hat{u}_y) A_{xy} = \\frac{1}{\\sqrt{2}}(3 \\cdot 1 + 2\\sqrt{2} \\cdot 1 + 4 \\cdot 0) = \\frac{3 + 2\\sqrt{2}}{\\sqrt{2}} = \\frac{3}{\\sqrt{2}} + 2 A_{xy} \\approx 4.12\n\n\n\nCalcolo del Vettore Proiettato:\n\nSi moltiplica la componente A_{xy} per il versore \\hat{u}_{xy} per ottenere il vettore proiettato \\vec{A}_{xy}: \\vec{A}_{xy} = A_{xy} \\cdot \\hat{u}_{xy} = \\left(\\frac{3}{\\sqrt{2}} + 2\\right) \\cdot \\frac{1}{\\sqrt{2}}(\\hat{u}_x + \\hat{u}_y) \\vec{A}_{xy} = \\left(\\frac{3}{2} + \\sqrt{2}\\right)\\hat{u}_x + \\left(\\frac{3}{2} + \\sqrt{2}\\right)\\hat{u}_y\n\n\n\nReferences"},"6--full-note/MateNum--Lez01":{"slug":"6--full-note/MateNum--Lez01","filePath":"6- full note/MateNum- Lez01.md","title":"MateNum- Lez01","links":["tags/revisione_finita","tags/flashcard_finite","tags/riscritto_in_corso","3--tag/matematica-numerica","3--tag/sbobine"],"tags":["revisione_finita","flashcard_finite","riscritto_in_corso"],"content":"2025-02-18 10:17\nStatus: revisione_finita flashcard_finite riscritto_in_corso\nTags:matematica numerica sbobine\nlez01-MateNum\nSistemi di Equazioni Lineari e Approssimazione\n\n\nNotazione Compatta: Un sistema di equazioni lineari può essere espresso come Ax = b. Dove:\n\nA è la matrice dei coefficienti (n x n).\nx è il vettore delle incognite.\nb è il termine noto.\n\n\n\n\nNotazione per Componenti: La notazione compatta è equivalente a esprimere il sistema per componenti:\n\na₁₁x₁ + a₁₂x₂ + … + a₁ₙxₙ = b₁\na₂₁x₁ + a₂₂x₂ + … + a₂ₙxₙ = b₂\n…\naₙ₁x₁ + aₙ₂x₂ + … + aₙₙxₙ = bₙ\n\n\n\nEsistenza e Unicità della Soluzione: La condizione necessaria e sufficiente per garantire esistenza e unicità di x è che A sia non singolare (invertibile).\n\n\nRegola di Cramer e Metodo di Laplace\n\n\nRegola di Cramer: La componente i-esima del vettore delle incognite è calcolata come:\n\nxᵢ = det(Aᵢ) / det(A),\ndove Aᵢ è la matrice ottenuta sostituendo la colonna i-esima di A con il vettore b.\ndovremmo calcolare n+1 determinanti\n\n\n\nFormula di Laplace: Usata per il calcolo del determinante:\n\ndet(A) = Σⱼ aᵢⱼ * Δᵢⱼ,\ndove Δᵢⱼ è il complemento algebrico di aᵢⱼ, dato da (-1)ⁱ⁺ʲ * det(Aᵢⱼ), con Aᵢⱼ matrice di dimensione inferiore (n-1) ottenuta eliminando la riga i e la colonna j.\n\n\n\n\nCosto Computazionale: L’uso combinato di Cramer e Laplace porta a un costo computazionale di O(n!), rendendolo inadatto per sistemi di grandi dimensioni.\n\nIl professore sottolinea che questo costo è insostenibile.\n\n\n\nCosto di un algoritmo\n\n\n\n\n\nAlgoritmo di Strassen\n\nL’algoritmo di Strassen ha un costo computazionale di circa O(n^4).\nAnche se migliore di O(n!), è ancora inefficiente per sistemi di dimensioni elevate.\n\nMetodi di Approssimazione: Diretti vs. Iterativi\n\nMetodi Diretti: Forniscono un’approssimazione della soluzione in un numero finito di passi.\nMetodi Iterativi: Generano una successione di approssimazioni che convergono alla soluzione.\n\nL’approssimazione della soluzione si ottiene come il limite di una successione di approssimazioni, partendo da una “black box” che genera approssimazioni successive, con la speranza che convergano alla soluzione esatta.\n\n\n\nFattorizzazione LU ( metodi diretti)\n\n\nDefinizione: La fattorizzazione LU decompone la matrice A nel prodotto di due matrici:\n\nA = L * U,\ndove L è una matrice triangolare inferiore e U è una matrice triangolare superiore.\n\n\n\n\nMatrice Triangolare Inferiore (L):\n\nElementi non nulli nella parte triangolare inferiore e sulla diagonale.\nFormalmente: lᵢⱼ = 0 se i &lt; j.\n\n\n\nMatrice Triangolare Superiore (U):\n\nElementi non nulli nella parte triangolare superiore e sulla diagonale.\nFormalmente: uᵢⱼ = 0 se i &gt; j.\n\n\n\nRisoluzione del Sistema con Fattorizzazione LU\n\nSostituzione: Riscrivere il sistema originale Ax = b come LUx = b.\nVariabile Ausiliaria: Definire Ux = y, trasformando il sistema in Ly = b.\nSistemi Triangolari:\n\nRisolvere Ly = b per trovare y (sistema triangolare inferiore).\nRisolvere Ux = y per trovare x (sistema triangolare superiore).\n\n\n\n\nOrdine di Risoluzione: È necessario risolvere prima Ly = b perché b è noto, mentre y è incognito.\n\nVantaggi della Fattorizzazione LU\n\nEfficienza: Risolvere due sistemi triangolari è più efficiente, soprattutto con matrici sparse.\nMatrici Sparse: Matrici con molti elementi nulli.\n\nUna matrice B (n x n) è sparsa se il numero di elementi diversi da zero è proporzionale a n, non a n².\nLa sparsità rende più efficiente la risoluzione dei sistemi lineari.\n\n\nPattern di Sparsità: La configurazione degli elementi non nulli influenza l’efficienza degli algoritmi.\n\n\nCalcolo del Determinante con LU\n\n\nProprietà: det(A) = det(L) * det(U).\nCalcolo Semplificato: Il determinante di una matrice triangolare è il prodotto degli elementi diagonali.\nEfficienza: Questo metodo è più efficiente rispetto a Laplace.\n\nAlgoritmo delle Sostituzioni in Avanti (Forward Substitution)\n\n\nObiettivo: Risolvere Ly = b, con L triangolare inferiore.\n\n\nProcedimento:\n\n\n\n\n\nInizializzazione: Calcolare y₁ = b₁ / l₁₁.\n\n\nIterazione: Per i = 2, …, n, calcolare:\n\nyᵢ = (bᵢ - Σⱼ lᵢⱼ * yⱼ) / lᵢᵢ, con j che va da 1 a i-1.\n\n\n\n\n\nCosto Computazionale: O(n²).\n\nDivisioni: n divisioni.\nMoltiplicazioni: Σᵢ(i - 1) = n(n - 1) / 2.\nSottrazioni: Σᵢ(i - 1) = n(n - 1) / 2.\nTotale: n + n(n - 1) = n².\n\n\n\nAlgoritmo delle Sostituzioni all’Indietro (Backward Substitution)\n\n\nObiettivo: Risolvere Ux = y, con U triangolare superiore.\n\n\nProcedimento:\n\n\n\n\n\nInizializzazione: Calcolare xₙ = yₙ / uₙₙ.\n\n\nIterazione: Per i = n-1, …, 1, calcolare:\n\nxᵢ = (yᵢ - Σₖ uᵢₖ * xₖ) / uᵢᵢ, con k che va da i+1 a n.\n\n\n\n\n\nCosto Computazionale: O(n²). La struttura è analoga a quella dell’algoritmo in avanti.\n\n\nCalcolo dei Fattori LU e la Scelta di lᵢᵢ = 1\n\nSistema Sottodeterminato: Nel calcolo diretto dei fattori LU, il sistema ha più incognite che equazioni.\nSoluzione: Si impone che gli elementi diagonali di L siano uguali a 1 (lᵢᵢ = 1).\nMotivazione: Questa scelta riduce le incognite, rendendo il sistema determinato e risolvibile.\n\nPassaggi Matematici per il Caso 2x2 (Fattorizzazione LU)\n\n\\begin{bmatrix} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22} \\end{bmatrix} = \\begin{bmatrix} l_{11} &amp; 0 \\\\ l_{21} &amp; l_{22} \\end{bmatrix}\\begin{bmatrix} U_{11} &amp; U_{12} \\\\ 0 &amp; U_{22} \\end{bmatrix} = \\begin{cases} l_{11} U_{11} = a_{11} \\\\ l_{11} l_{12} = a_{12} \\\\ l_{21} U_{11} = a_{21} \\\\ l_{21} U_{12} + l_{22} U_{22} = a_{22} \\end{cases}\n\n4 equazioni e 6 incognite, è un problema, soluzione? rendere la diagonale di L a 1\n\n\n\n\n\n\n\\begin{bmatrix} 1 &amp; 0 \\ l_{21} &amp; 1 \\ \\ \\end{bmatrix} \\\n\\begin{bmatrix} U_{11} &amp; U_{12} \\ 0 &amp; U_{22} \\end{bmatrix}$$\nGeneralizzazione e Costo Computazionale\n\nMatrice nxn: Per una matrice nxn, ci sono n² equazioni.\nNumero di Incognite: Ci sono \\frac{n(n+1)}{2} elementi in L e altrettanti in U, per un totale di n²+n incognite.\nImposizione di lᵢᵢ = 1: Fissare gli elementi diagonali di L a 1 riduce il numero di incognite a n².\n\nReferences"},"6--full-note/Matenum--Lab01":{"slug":"6--full-note/Matenum--Lab01","filePath":"6- full note/Matenum- Lab01.md","title":"Matenum- Lab01","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-15 12:53\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine  matematica numerica\nLaboratorio di Matematica Numerica\nIntroduzione al Corso e Organizzazione\n\nRegistrazione delle Lezioni: Le registrazioni saranno disponibili su Wib (Webex) nel giro di qualche giorno.\nMateriale del Laboratorio: Il testo del laboratorio sarà caricato prima della lezione, mentre le soluzioni saranno disponibili qualche giorno dopo.\nStruttura del Corso: Il corso è diviso in due scaglioni, ma utilizza una singola pagina WVP. Le soluzioni saranno allineate con l’altro scaglione per evitare anticipazioni.\nComunicazione: La stanza di Webex sarà accessibile cercando “Giacomo Speroni”.\n\nIntroduzione a MATLAB\nInterfaccia di MATLAB\n\nCurrent Folder: La cartella di lavoro principale. È consigliabile creare una cartella specifica per il corso (ad esempio, “matematica_numerica_2425”).\nEditor di Testo: Utilizzato per scrivere e modificare script MATLAB. È possibile eseguire il codice premendo il pulsante “Run” o F5.\nCommand Window: Terminale integrato per eseguire comandi riga per riga. Utile per comandi rapidi come help.\nWorkspace: Elenco delle variabili salvate in memoria.\nCommand History: Cronologia dei comandi eseguiti.\n\nVariabili in MATLAB\n\nMATLAB = Matrix Laboratory: MATLAB è progettato per il calcolo con matrici. Tutte le variabili sono matrici, anche gli scalari (che sono matrici 1x1).\nInizializzazione delle Variabili:\n\nNon è necessario dichiarare il tipo di variabile.\nEsempio: a = 1 inizializza una variabile reale.\nLe stringhe vanno inserite tra virgolette.\n\n\n\nVettori e Matrici\n\n\nVettori: Possono essere inizializzati come liste di valori.\n\nEsempio: v = [0, 1, 2, 3, 4, 5] crea un vettore con elementi da 0 a 5.\nInizializzazione con spaziatura: u = 0:1:100 crea un vettore da 0 a 100 con passo 1.\nControllo della lunghezza: linspace(x1, x2, n) crea un vettore con n elementi tra x1 e x2.\n\n\n\nMatrici: Inizializzate con righe separate da punto e virgola o a capo.\n\nEsempio:\nA = [1, 2, 3; 4, 5, 6]\ncrea una matrice 2x3.\n\n\n\nOperazioni con Matrici\n\nMoltiplicazione: Le matrici devono essere compatibili (numero di colonne della prima = numero di righe della seconda).\n\nEsempio: A * B dove A è 2x3 e B è 3x2.\n\n\nErrore di Dimensioni: Se le matrici non sono compatibili, MATLAB restituisce un errore.\nPunto e Virgola: Se omesso, MATLAB stampa il risultato nella Command Window.\n\nOperazioni Elemento per Elemento\n\nOperatore .*: Esegue operazioni elemento per elemento.\n\nEsempio: B .* C moltiplica elemento per elemento.\n\n\nAltre Operazioni: Somma, differenza, elevamento a potenza, ecc.\n\nFunzioni Utili per Matrici\n\nDeterminante: det(A)\nTraccia: trace(A)\nAutovalori: eig(A)\nMassimo e Minimo: max(v), min(v)\nNorma: norm(v)\n\nFormato delle Variabili\n\nPrecisione dei Numeri: MATLAB utilizza numeri in virgola mobile (floating point).\nVisualizzazione delle Variabili:\n\nformat short: Poche cifre decimali.\nformat long: Molte cifre decimali.\nformat short e, format long e: Formato esponenziale.\n\n\n\nMatrici Speciali\n\nMatrice Nulla: zeros(m, n) crea una matrice mxn di zeri.\nMatrice Identità: eye(n) crea una matrice identità nxn.\nMatrice di Uni: ones(m, n) crea una matrice mxn di uni.\nDiagonali:\n\ndiag(A) estrae la diagonale di A.\ndiag(v) crea una matrice diagonale con v sulla diagonale.\n\n\n\nParte Superiore e Inferiore di una Matrice\n\nTriangolare Superiore: triu(A)\nTriangolare Inferiore: tril(A)\n\nPulizia della Workspace\nda inserire sempre all’inizio degli script\n\nComando clear all: Cancella tutte le variabili salvate.\nComando close all: Chiude tutte le finestre grafiche.\nComando  clc\n\nclc\nclear all\nclose all\n-continua\n\nimportanza dei vettori colonna\no comunque fare caso se ti ritrovi con dei vettori riga o colonna nel caso.\nGrafici in MATLAB\nCreazione di un Grafico\n\nDefinizione dell’Intervallo:\na = 0;\nb = pi / 2;\nxx = [a:0.01:b]; %quanto fitta facciamo la funzione? la scelta deve essere ragionevole, la distanza di 0.01 può andare bene\n\nCalcolo delle Ordinate:\nyy = sin(x).^3 + cos(x); %crea un vettore a cui ogni componente applica questa operazione\n\nè diverso elevare  ^3 (che fa il cubo di un vettore) e .^3 (che fa il cubo di ogni singolo termine del vettore)\n\n\nPlot del Grafico:\nplot(xx, yy);\n\n\n-con passo di 0.5\n\n\n\n\nvogliamo definire un nuovo intervallo\n\nun I2=[pi/2,5]\n\nxx2= [pi/2:0.01:5];\nyy2 = sin(xx).^3 + cos(xx2) \n%uguale ma inserisco la nuova ascissa\n \n%inserisco un nuovo plot (tratteggiato di rosso)\nplot(xx2,yy2, &#039;r--&#039;):\n \n\nlo runno\n\nma mi ha cancellato il plot di prima\n\nUtilizzo di hold on\n\nMantenere più Grafici: hold on permette di sovrapporre più grafici nella stessa finestra.\n\n\nFunzioni Anonime\n\nDefinizione di una Funzione Anonima:\n\n y = @(x) sin(x).^3 + cos(x); \n% x può essere qualunque cosa\n\nUtilizzo della Funzione:\n\nplot(xx, yy(xx));\nhold on \nplot(xx2, yy(xx2));\nFunzioni in MATLAB\nDefinizione di una Funzione\n\nSintassi:\nfunction [out1, out2] = namefunction(inpt1, inpt2, inpt3)\n\n\n% Operazioni sulla base degli input\nout1= 0;\nout2 = 0;\nif (inpt3 == 1 ) \n\tout1 = inpt1 + inpt2;\n\tout2 = 0;\nelse \n\tfor i= 0:1:5\n\t\tout1= i+out1;\n\t\tout2= 5:\n\tend\nend\n\n`end\n\n\nSalvataggio: La funzione deve essere salvata con lo stesso nome del file (myfunction.m).\n\n\nesempio:\nfunction [out1, out2] = namefunction(inpt1, inpt2, inpt3)\n \n  \n  \tout1= inp\nend\n\n\nChiamata di una Funzione\n\nEsempio di Chiamata:\n[out1, out2] = myfunction(1, 2, 1);\n\n\nProblemi Numerici in MATLAB\nPrecisione della Macchina\n\nmatlab funziona con floating point\nEpsilon della Macchina: Distanza tra 1 e il numero successivo rappresentabile.\n\neps restituisce questa distanza.\n\n\nEsempio:\n1 + eps(1) % Restituisce un numero diverso da 1\n1 + eps(1) / 2 % Restituisce 1 (non si sposta)\n\n\nLimiti dei Numeri Rappresentabili\n\nRealmin e Realmax:\n\nrealmin: Numero più piccolo rappresentabile.\nrealmax: Numero più grande rappresentabile.\n\n\n\nEsempi di Errori Numerici\n\n\nDifferenza tra Vettori:\na =[0:0.01:1];\nb = linspace(0, 1, 101);\nplot(abs(a - b));\n \n  %se faccio la loro diff in val assoluto\n  plot (abs(a-b))\n\nAnche se a e b sembrano uguali, ci sono piccole differenze dovute alla rappresentazione numerica.\n\n\n\n\nErrore di Cancellazione:\nx = 1e-15; %10^(-15)\nresult = ((x + 1) - 1)/x;\n\nIl risultato non è 1 a causa della cancellazione numerica.\n\n\n\nReferences"},"6--full-note/Matenum--lab02":{"slug":"6--full-note/Matenum--lab02","filePath":"6- full note/Matenum- lab02.md","title":"Matenum- lab02","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-17 16:36\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nMatenum- lab03\nMetodi Iterativi per la Risoluzione di Sistemi Lineari Ax = b\nIntroduzione ai Metodi Iterativi\nInvece di trovare direttamente la soluzione di un sistema lineare Ax = b come con i metodi diretti (ad esempio, il metodo LU), i metodi iterativi generano una sequenza di soluzioni approssimate che, si spera, convergono alla soluzione esatta. Un metodo iterativo generico può essere espresso nella forma:\nx^{(k+1)} = Bx^{(k)} + g\ndove:\n\nx^{(k)} è il vettore soluzione approssimata al passo k.\nx^{(k+1)} è il vettore soluzione approssimata al passo successivo k+1.\nB è la matrice di iterazione del metodo.\ng è un vettore di spostamento.\n\nLe proprietà di convergenza di un metodo iterativo sono determinate principalmente dalla sua matrice di iterazione B.\nConvergenza dei Metodi Iterativi\nCondizione Necessaria e Sufficiente per la Convergenza\nLa convergenza di un metodo iterativo è strettamente legata al raggio spettrale della matrice di iterazione B. Il raggio spettrale, indicato con \\rho(B), è definito come il massimo del modulo degli autovalori di B:\n\\rho(B) = \\max(|\\lambda_i|)\ndove \\lambda_i sono gli autovalori di B.\nUn teorema fondamentale afferma che il metodo iterativo x^{(k+1)} = Bx^{(k)} + g converge per qualsiasi scelta del vettore iniziale x^{(0)} se e solo se il raggio spettrale della matrice di iterazione è minore di 1:\n\\rho(B) &lt; 1\nInoltre, più piccolo è il raggio spettrale, più velocemente il metodo converge. Al contrario, se il raggio spettrale è prossimo a 1, la convergenza sarà lenta.\nCalcolo del Raggio Spettrale in MATLAB\nPer calcolare il raggio spettrale di una matrice B in MATLAB, si può utilizzare il seguente comando:\nmax(abs(eig(B)))\n\nQuesto comando calcola gli autovalori di B (eig(B)), ne prende il valore assoluto (abs(...)), e infine trova il massimo di questi valori assoluti (max(...)), che corrisponde al raggio spettrale.\nMetodo di Jacobi\nDerivazione del Metodo di Jacobi\nIl metodo di Jacobi si basa su una decomposizione (splitting) della matrice A nella somma di tre matrici: una matrice diagonale D, una matrice triangolare inferiore -E (con elementi opposti a quelli della parte strettamente inferiore di A), e una matrice triangolare superiore -F (con elementi opposti a quelli della parte strettamente superiore di A). Quindi, A = D - E - F.\nRiscrivendo il sistema Ax = b come (D - E - F)x = b, possiamo isolare la parte diagonale: Dx = (E + F)x + b. Se la matrice diagonale D è invertibile (ovvero, se tutti gli elementi sulla diagonale principale di A sono non nulli), possiamo ricavare la formula iterativa del metodo di Jacobi:\nx^{(k+1)} = D^{-1}(E + F)x^{(k)} + D^{-1}b\nConfrontando questa espressione con la forma generale x^{(k+1)} = Bx^{(k)} + g, identifichiamo la matrice di iterazione di Jacobi B_J e il vettore di spostamento g_J come:\nB_J = D^{-1}(E + F) = I - D^{-1}A g_J = D^{-1}b\ndove I è la matrice identità.\nAggiornamento delle Componenti nel Metodo di Jacobi\nLa formula per aggiornare la i-esima componente del vettore soluzione x al passo k+1 nel metodo di Jacobi è data da:\nx_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij} x_j^{(k)} \\right)\nQuesta formula indica che per aggiornare la i-esima componente della soluzione, si utilizza il valore corrente di tutte le altre componenti della soluzione al passo precedente k.\nImplementazione in MATLAB (MyJacobi)\nL’implementazione del metodo di Jacobi richiede di iterare fino a raggiungere un criterio di arresto, come ad esempio un residuo normalizzato inferiore a una certa tolleranza. Il residuo al passo k è definito come r^{(k)} = b - Ax^{(k)}, e il residuo normalizzato è |r^{(k)}| / |b|.\nNella funzione MyJacobi, si inizializza una stima dell’errore a un valore elevato per garantire l’ingresso nel ciclo while. Il ciclo continua finché non si raggiunge il numero massimo di iterazioni o l’errore stimato (basato sul residuo normalizzato) non scende al di sotto della tolleranza.\nAll’interno del ciclo, per ogni componente i del vettore soluzione, si calcola il nuovo valore x_i^{(k+1)} utilizzando la formula sopra, sfruttando i valori di x_j^{(k)}. Questo calcolo può essere efficientemente implementato evitando cicli espliciti, ad esempio utilizzando prodotti scalari e opportune indicizzazioni per escludere l’elemento diagonale.\nDopo ogni iterazione, si calcola il residuo normalizzato come stima dell’errore e si aggiorna il vettore della soluzione corrente per la prossima iterazione.\nMetodo di Gauss-Seidel\nDerivazione del Metodo di Gauss-Seidel\nSimilmente al metodo di Jacobi, il metodo di Gauss-Seidel utilizza la decomposizione A = D - E - F. Tuttavia, nell’aggiornamento delle componenti, il metodo di Gauss-Seidel utilizza i valori delle componenti già aggiornate nella stessa iterazione k+1.\nRiscrivendo il sistema Ax = b e isolando i termini che coinvolgono D e -E: (D - E)x = Fx + b. Se la matrice (D - E) è invertibile, la formula iterativa del metodo di Gauss-Seidel è:\nx^{(k+1)} = (D - E)^{-1}Fx^{(k)} + (D - E)^{-1}b\nLa matrice di iterazione di Gauss-Seidel B_{GS} e il vettore di spostamento g_{GS} sono quindi:\nB_{GS} = (D - E)^{-1}F ,  g_{GS} = (D - E)^{-1}b\nAggiornament.  delle Componenti nel Metodo di Gauss-Seidel\nLa formula per aggiornare la i-esima componente del vettore soluzione x al passo k+1 nel metodo di Gauss-Seidel è data da:\nx_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)\nSi osserva che la somma è divisa in due parti: la prima somma include le componenti x_j con indice j &lt; i, che sono già state aggiornate al passo k+1, mentre la seconda somma include le componenti x_j con indice j &gt; i, che mantengono il valore del passo precedente k.\nImplementazione in MATLAB\nIn MATLAB, per calcolare l’effetto della moltiplicazione per l’inversa di (D-E) senza calcolare esplicitamente l’inversa, si utilizza l’operatore backslash (\\):\nB_GS = (D - E) \\ F;\n\ne per applicare (D-E)^{-1} a un vettore come b, si scrive (D - E) \\ b. Questo è computazionalmente più efficiente e numericamente stabile rispetto al calcolo diretto dell’inversa.\nPer l’implementazione del metodo di Gauss-Seidel (o del metodo SOR con \\omega = 1), si procede in modo simile al metodo di Jacobi, ma nell’aggiornamento di ogni componente, si utilizzano i valori già calcolati nella stessa iterazione.\nMetodo SOR (Successive Over-Relaxation)\nIl metodo SOR è una generalizzazione del metodo di Gauss-Seidel che introduce un parametro di rilassamento \\omega. La formula per l’aggiornamento delle componenti nel metodo SOR è:\nx_i^{(k+1)} = (1 - \\omega) x_i^{(k)} + \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)\nQuando \\omega = 1, il metodo SOR si riduce al metodo di Gauss-Seidel. Per valori di \\omega diversi da 1, si può potenzialmente accelerare la convergenza rispetto a Gauss-Seidel. L’implementazione di MySor in MATLAB si basa sulla stessa struttura di MyJacobi, ma incorporando il parametro \\omega e la differente gestione degli indici nelle sommatorie per sfruttare i valori già aggiornati nella corrente iterazione.\nCondizioni Sufficienti di Convergenza\nOltre alla condizione necessaria e sufficiente basata sul raggio spettrale, esistono alcune condizioni sufficienti per la convergenza dei metodi di Jacobi e Gauss-Seidel:\n\nDominanza diagonale stretta per righe: Una matrice A è a dominanza diagonale stretta per righe se per ogni riga i, il valore assoluto dell’elemento diagonale è maggiore della somma dei valori assoluti degli altri elementi sulla stessa riga: |a_{ii}| &gt; \\sum_{j=1, j\\neq i}^{n} |a_{ij}|. Se A è a dominanza diagonale stretta per righe, sia il metodo di Jacobi che il metodo di Gauss-Seidel convergono.\nDominanza diagonale stretta per colonne: Similmente, se |a_{jj}| &gt; \\sum_{i=1, i\\neq j}^{n} |a_{ij}| per ogni colonna j, allora A è a dominanza diagonale stretta per colonne. In questo caso, sia Jacobi che Gauss-Seidel convergono.\nSimmetria e definita positività: Se la matrice A è simmetrica e definita positiva, allora il metodo di Gauss-Seidel converge.\n\nQueste condizioni sono sufficienti, ma non necessarie, il che significa che i metodi possono convergere anche se queste condizioni non sono soddisfatte, a condizione che il raggio spettrale della matrice di iterazione sia minore di 1.\nStima del Numero di Iterazioni\nÈ possibile stimare il numero minimo di iterazioni K necessarie per ridurre l’errore di un certo fattore, utilizzando la norma della matrice di iterazione B. Se si desidera ridurre l’errore iniziale e^{(0)} = x_{exact} - x^{(0)} di un fattore \\epsilon, e si utilizza la norma 2, allora si ha:\n|e^{(K)}|_2 \\le |B|_2^K |e^{(0)}|_2 \\le \\epsilon |e^{(0)}|_2\nDa cui si ricava una stima per il numero di iterazioni K:\nK \\ge \\frac{\\log_{10}(\\epsilon)}{\\log_{10}(|B|_2)}\no\nK \\ge \\frac{\\log_{2}(\\epsilon)}{\\log_{2}(|B|_2)}\nNell’esercizio, con una tolleranza di 10^{-10}, il numero di iterazioni per Jacobi è stato stimato intorno a 26-27, in accordo con i risultati numerici ottenuti.\nConfronto tra Jacobi e Gauss-Seidel\nIn generale, se entrambi i metodi convergono, il metodo di Gauss-Seidel tende a convergere più velocemente del metodo di Jacobi, poiché utilizza le informazioni più recenti disponibili durante l’iterazione. Tuttavia, esiste un teorema specifico per il confronto della velocità di convergenza tra Jacobi e Gauss-Seidel che si applica solo nel caso in cui la matrice A sia tridiagonale e con elementi non nulli sulla diagonale. In questo caso, se entrambi i metodi convergono, il raggio spettrale di Gauss-Seidel è il quadrato del raggio spettrale di Jacobi: \\rho(B_{GS}) = [\\rho(B_J)]^2, il che implica una convergenza più rapida per Gauss-Seidel. Per matrici non tridiagonali, come nell’esempio discusso, questo confronto diretto non è applicabile, e la velocità di convergenza viene confrontata direttamente attraverso i valori dei rispettivi raggi spettrali. Nell’esempio, si è osservato che \\rho(B_{GS}) = 0.08 &lt; \\rho(B_J) = 0.29, confermando una convergenza più veloce per Gauss-Seidel.\nLa consistenza dei metodi di Jacobi e Gauss-Seidel è garantita dalla loro costruzione, il che permette di concentrarsi direttamente sulla verifica della convergenza tramite il raggio spettrale.\nL’errore iniziale e^{(0)} è definito come la differenza tra la soluzione esatta x_{exact} e la soluzione iniziale x^{(0)}. Nel caso in cui la soluzione iniziale sia il vettore nullo (x^{(0)} = 0), allora e^{(0)} = x_{exact}. L’analisi dell’errore durante le iterazioni permette di verificare se la soluzione approssimata converge effettivamente alla soluzione esatta entro la tolleranza specificata.\nReferences"},"6--full-note/Matenum--lez03":{"slug":"6--full-note/Matenum--lez03","filePath":"6- full note/Matenum- lez03.md","title":"Matenum- lez03","links":["tags/flashcard_finite","tags/riscritto_finito","tags/revisione_finita","3--tag/matematica-numerica","3--tag/sbobine","2--source-materials/Appunti-Mate-Num-lez03.pdf"],"tags":["flashcard_finite","riscritto_finito","revisione_finita"],"content":"2025-02-24 15:41\n_Status: flashcard_finite riscritto_finito   revisione_finita\n_Tags: matematica numerica. sbobine\nMatenum- lez03\nCondizioni sufficienti per l’esistenza e l’unicità della fattorizzazione LU\nIl professore introduce le condizioni sufficienti per garantire l’esistenza e l’unicità della fattorizzazione LU di una matrice A. Queste condizioni sono alternative tra loro e si basano su tre famiglie di matrici particolari.\n1. Matrici a dominanza diagonale stretta per righe\nSe A è una matrice a dominanza diagonale stretta per righe, allora la fattorizzazione LU esiste ed è unica. Una matrice A è a dominanza diagonale stretta per righe se l’elemento diagonale in valore assoluto è strettamente maggiore della somma dei valori assoluti degli altri elementi sulla stessa riga.\nMatematicamente, questo significa che per ogni riga i:\n|a_{ii}| &gt; \\sum_{j=1, j\\neq i}^{n} |a_{ij}|\ndove i varia da 1 a n.\nEsempio: Consideriamo la matrice:\nA = \\begin{bmatrix} 4 &amp; 0 &amp; -1 \\\\ 3 &amp; -7 &amp; 2 \\\\ -2 &amp; 1 &amp; 9 \\end{bmatrix}\nVerifichiamo se è a dominanza diagonale stretta per righe:\n\nRiga 1: |4| &gt; |0| + |-1| \\implies 4 &gt; 1 (vero)\nRiga 2: |-7| &gt; |3| + |2| \\implies 7 &gt; 5 (vero)\nRiga 3: |9| &gt; |-2| + |1| \\implies 9 &gt; 3 (vero)\n\nQuindi, la matrice A è a dominanza diagonale stretta per righe.\nAttenzione: È fondamentale considerare i valori assoluti. Se si dimenticano i valori assoluti, si potrebbe erroneamente concludere che una matrice non è a dominanza diagonale stretta per righe.\n2. Matrici a dominanza diagonale stretta per colonne\nSe A è una matrice a dominanza diagonale stretta per colonne, allora la fattorizzazione LU esiste ed è unica. Una matrice A è a dominanza diagonale stretta per colonne se l’elemento diagonale in valore assoluto è strettamente maggiore della somma dei valori assoluti degli altri elementi sulla stessa colonna.\nMatematicamente, questo significa che per ogni colonna j:\n|a_{jj}| &gt; \\sum_{i=1, i\\neq j}^{n} |a_{ij}|\ndove j varia da 1 a n.\nImportante: Una matrice a dominanza diagonale stretta per righe non è necessariamente a dominanza diagonale stretta per colonne, e viceversa.\nEsempio: Riprendendo la matrice A dell’esempio precedente:\nA = \\begin{bmatrix} 4 &amp; 0 &amp; -1 \\\\ 3 &amp; -7 &amp; 2 \\\\ -2 &amp; 1 &amp; 9 \\end{bmatrix}\nVerifichiamo se è a dominanza diagonale stretta per colonne:\n\nColonna 1: |4| &gt; |3| + |-2| \\implies 4 &gt; 5 (falso)\n\nQuindi, la matrice A non è a dominanza diagonale stretta per colonne.\n3. Matrici simmetriche definite positive\nSe A è una matrice simmetrica definita positiva, allora la fattorizzazione LU esiste ed è unica.\n\nSimmetria: una matrice A è simmetrica se A = A^T, ovvero a_{ij} = a_{ji} per ogni i e j. In altre parole, la diagonale è uno specchio. In Matlab, si può verificare la simmetria con il comando A == A&#039; (dove &#039; indica la trasposta).\nDefinita positiva: una matrice A è definita positiva se v^T A v &gt; 0 per ogni vettore v \\in \\mathbb{R}^n diverso dal vettore nullo.\n\nCriterio pratico per verificare se una matrice è definita positiva:\n\nVerificare che la matrice sia simmetrica.\nCalcolare gli autovalori della matrice. Se tutti gli autovalori sono reali e positivi, allora la matrice è definita positiva.\n\nIn Matlab, si può usare il comando eig(A) per calcolare gli autovalori di A.\nFattorizzazione LU per Matrici Non Singolari che Non Soddisfano le Condizioni Precedenti\nSe una matrice A non soddisfa le condizioni sufficienti (dominanza diagonale) o necessarie e sufficienti, è comunque possibile trovare la fattorizzazione LU se A è non singolare. In questo caso, si ricorre al pivoting.\nPivoting: Scambio di Righe\nL’idea base è scambiare le righe della matrice per evitare elementi pivotali nulli o troppo piccoli, che potrebbero compromettere la stabilità numerica dell’algoritmo.\nEsempio:\nConsideriamo la matrice:\nA = \\begin{bmatrix} 1 &amp; 1 &amp; 3 \\\\ 2 &amp; 3 &amp; 6 \\\\ 4 &amp; 5 &amp; 4 \\end{bmatrix}\nDopo alcuni passaggi della fattorizzazione LU senza pivoting, si può arrivare a una matrice con un elemento pivotale nullo. Per ovviare a questo, si scambiano le righe.\nMatrici di Permutazione: Lo scambio di righe si realizza moltiplicando la matrice A per una matrice di permutazione P. Una matrice di permutazione si ottiene permutando le righe della matrice identità.\nEsempio: Per scambiare la riga 2 con la riga 3, la matrice di permutazione è:\nP = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 \\end{bmatrix}\nMoltiplicando P per A, si ottiene una nuova matrice con le righe scambiate: PA.\nAlgoritmo con Pivoting\n\nControllo dell’elemento pivotale: Durante la fattorizzazione LU, se si incontra un elemento pivotale a_{ii} uguale a zero, si scambiano le righe per portare un elemento non nullo in quella posizione.\nScelta della riga da scambiare: Si cerca, tra le righe sottostanti alla riga corrente, quella con l’elemento in valore assoluto più grande nella colonna corrente.\nAggiornamento della matrice di permutazione: Si tiene traccia degli scambi effettuati attraverso una matrice di permutazione P.\nFattorizzazione LU di PA: Alla fine del processo, si ottiene la fattorizzazione LU della matrice PA, dove P è il prodotto di tutte le matrici di permutazione utilizzate.\n\nRisoluzione del Sistema Lineare con Pivoting\nSe l’obiettivo è risolvere il sistema lineare Ax = b, e si è effettuato il pivoting, allora si risolve il sistema equivalente PAx = Pb.\n\nSi calcola Pb, applicando le stesse permutazioni al termine noto b.\nSi risolve il sistema triangolare inferiore Ly = Pb.\nSi risolve il sistema triangolare superiore Ux = y.\n\nPivoting Parziale vs. Pivoting Totale\n\nPivoting Parziale: Si cerca l’elemento massimo in valore assoluto solo nella colonna sotto l’elemento pivotale corrente.\nPivoting Totale: Si cerca l’elemento massimo in valore assoluto in tutta la sottomatrice a destra e in basso rispetto all’elemento pivotale corrente. In questo caso, si scambiano sia righe che colonne, utilizzando due matrici di permutazione, P per le righe e Q per le colonne.\n\nNel pivoting totale, la fattorizzazione diventa PAQ = LU. Per risolvere il sistema lineare Ax = b, si procede come segue:\n\nSi calcola Pb.\nSi risolve Lz = Pb.\nSi risolve Uy = z.\nSi calcola x = Qy.\n\nMotivi per Utilizzare il Pivoting\n\nEvitare divisioni per zero: Se l’elemento pivotale è zero, la fattorizzazione LU si blocca.\nStabilità numerica: Anche se l’elemento pivotale non è zero, ma è molto piccolo, la divisione per questo elemento può amplificare gli errori di arrotondamento, portando a una soluzione inaccurata. Il pivoting aiuta a scegliere elementi pivotali più grandi, riducendo l’amplificazione degli errori.\n\nComando LU in Matlab\nIl comando LU in Matlab implementa sempre il pivoting. La sintassi consigliata è [L, U, P] = lu(A), che restituisce le matrici L, U e P tali che PA = LU.\nPerché Usare [L, U, P] = lu(A) in Matlab invece di [L, U] = lu(A)\nIl professore suggerisce di utilizzare la sintassi completa [L, U, P] = lu(A) invece della sintassi incompleta [L, U] = lu(A) per due motivi principali:\n\nMatlab Implementa Sempre il Pivoting: Il comando lu in Matlab implementa sempre il pivoting. Usando la sintassi [L, U, P] = lu(A), si ottiene esplicitamente la matrice di permutazione P, che permette di tenere traccia degli scambi di righe effettuati durante la fattorizzazione. Questo è utile per capire se il pivoting è stato necessario o meno. Se P è la matrice identità, allora non ci sono stati scambi di righe.\nChiarezza e Controllo: La sintassi completa rende più chiaro il fatto che il pivoting è stato applicato e permette di controllare la matrice di permutazione P. Questo è importante per la stabilità numerica e per la corretta risoluzione del sistema lineare.\n\nUsando la sintassi incompleta [L, U] = lu(A), Matlab esegue comunque il pivoting, ma restituisce matrici L e U tali che A = LU. In realtà, la fattorizzazione calcolata è PA = LU, e la matrice L restituita è in realtà P^{-1}L, dove L è la matrice triangolare inferiore “vera”. Questo può portare a confusione, perché la matrice L ottenuta potrebbe non essere triangolare inferiore.\nImportanza del Pivoting Anche con Elementi Diversi da Zero (ma Piccoli)\nIl pivoting non è necessario solo quando si incontrano elementi pivotali nulli, ma è altamente raccomandato anche quando gli elementi pivotali sono molto piccoli. Questo perché:\n\nStabilità Numerica: La divisione per un elemento pivotale molto piccolo può amplificare gli errori di arrotondamento presenti nei calcoli. Questo può portare a una fattorizzazione LU inaccurata e a una soluzione del sistema lineare molto distante dalla soluzione esatta.\nMoltiplicatori Grandi: Un elemento pivotale piccolo porta a moltiplicatori grandi durante l’eliminazione gaussiana. Questi moltiplicatori, quando applicati ad altre righe, possono amplificare gli errori di arrotondamento, rendendo la soluzione finale inaccurata.\n\nEsempio:\nConsideriamo una matrice A con un elemento pivotale piccolo:\nA = \\begin{bmatrix}1 &amp; 1 + 0.5 \\cdot 10^{-15} &amp; 3 \\\\ 2 &amp; 2 &amp; 20 \\\\ 3 &amp; 6 &amp; 4 \\end{bmatrix}\nAnche se la condizione necessaria e sufficiente per l’esistenza della fattorizzazione LU è soddisfatta, la fattorizzazione LU calcolata senza pivoting può essere molto inaccurata. Questo perché i moltiplicatori risultano essere molto grandi, amplificando gli errori di arrotondamento.\nSoluzione: Pivoting Parziale o Totale\nPer evitare questi problemi, si utilizza il pivoting. L’idea è scambiare le righe (e/o le colonne nel pivoting totale) per portare un elemento pivotale più grande in valore assoluto nella posizione corretta. Questo riduce i moltiplicatori e minimizza l’amplificazione degli errori di arrotondamento, portando a una soluzione più accurata.\nIn sintesi, il pivoting è una tecnica fondamentale per garantire la stabilità numerica della fattorizzazione LU, anche quando gli elementi pivotali non sono esattamente zero. Utilizzare la sintassi [L, U, P] = lu(A) in Matlab permette di tenere traccia degli scambi di righe effettuati e di ottenere una fattorizzazione LU più accurata.\n==Fattorizzazione LU di una matrice tridiagonale\nUna matrice tridiagonale è una matrice in cui gli elementi diversi da zero sono situati solo sulla diagonale principale, sulla prima sovradiagonale e sulla prima sottodiagonale.\nQuando si effettua la fattorizzazione LU di una matrice tridiagonale, le matrici L e U risultano essere bidiagonali.\n\nL è una matrice bidiagonale inferiore con tutti 1 sulla diagonale principale.\nU è una matrice bidiagonale superiore.\n\nEsempio: Consideriamo una matrice tridiagonale 3x3:\nA = \\begin{bmatrix} a_1 &amp; c_1 &amp; 0 \\\\ e_2 &amp; a_2 &amp; c_2 \\\\ 0 &amp; e_3 &amp; a_3 \\end{bmatrix}\nLa sua fattorizzazione LU sarà:\nL = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ \\beta_2 &amp; 1 &amp; 0 \\\\ 0 &amp; \\beta_3 &amp; 1 \\end{bmatrix}\nU = \\begin{bmatrix} \\alpha_1 &amp; \\gamma_1 &amp; 0 \\\\ 0 &amp; \\alpha_2 &amp; \\gamma_2 \\\\ 0 &amp; 0 &amp; \\alpha_3 \\end{bmatrix}\ndove \\gamma_1 = c_1 e \\gamma_2 = c_2.\nPer trovare i valori di \\alpha_i e \\beta_i, si uguagliano gli elementi corrispondenti delle matrici A e LU.\n\n\nCalcolo di \\alpha_1: \\alpha_1 è semplicemente uguale a a_1, dove a_1 è l’elemento diagonale nella prima riga e prima colonna della matrice tridiagonale originale A.\n\n\nCalcolo di \\beta_i per i \\ge 2: \\beta_i è calcolato come:\n\\beta_i = \\frac{e_i}{\\alpha_{i-1}}\ndove e_i è l’elemento sulla sotto-diagonale (i-esima riga, i-1-esima colonna) della matrice originale A e \\alpha_{i-1} è il valore di alfa calcolato al passo precedente. È fondamentale che \\alpha_{i-1} sia diverso da zero per evitare divisioni per zero.\n\n\nCalcolo di \\alpha_i per i \\ge 2: \\alpha_i è calcolato come:\n\\alpha_i = a_i - \\beta_i \\cdot c_{i-1}\ndove:\n\na_i è l’elemento diagonale nella i-esima riga e i-esima colonna della matrice originale A.\n\\beta_i è il valore di beta calcolato al passo corrente.\nc_{i-1} è l’elemento sulla sovra-diagonale (i-1-esima riga, i-esima colonna) della matrice originale A.\n\n\n\nAlgoritmo Generale:\n\nInizia con \\alpha_1 = a_1.\nAlterna il calcolo di \\beta_i e \\alpha_i per ogni i da 2 fino a n.\nPer ogni i, calcola prima \\beta_i usando il valore di \\alpha_{i-1} calcolato precedentemente.\nSuccessivamente, usa il valore di \\beta_i appena calcolato per trovare \\alpha_i.\n\nCosto Computazionale:\nIl costo computazionale di questo algoritmo è 3(n-1), poiché per ogni i (da 2 a n) si eseguono tre operazioni: una divisione per calcolare \\beta_i e una moltiplicazione e una sottrazione per calcolare \\alpha_i. Questo è significativamente più efficiente rispetto alla fattorizzazione LU classica, che ha un costo di O(n^3).\nReferences\nAppunti Mate Num-lez03.pdf"},"6--full-note/Matenum--lez04":{"slug":"6--full-note/Matenum--lez04","filePath":"6- full note/Matenum- lez04.md","title":"Matenum- lez04","links":["tags/flashcard_finite","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","2--source-materials/Appunti-Mate-Num--lez04.pdf"],"tags":["flashcard_finite","riscritto_zero","revisione_zero"],"content":"2025-02-25 12:45\n_Status: flashcard_finite   riscritto_zero  revisione_zero\n_Tags: sbobine  matematica numerica\nMatenum- lez04\n1. Fattorizzazione LU per Matrici Tridiagonali\n1.1. Descrizione del Metodo\nIl metodo della fattorizzazione LU è particolarmente efficace per matrici tridiagonali, ovvero matrici con elementi non nulli solo sulla diagonale principale, sulla prima sopra-diagonale e sulla prima sotto-diagonale.\nLa fattorizzazione LU di una matrice tridiagonale A porta a identificare due fattori:\n\nL (matrice triangolare inferiore) che, in questo caso, è una matrice bidiagonale inferiore con tutti 1 sulla diagonale principale.\nU (matrice triangolare superiore) che, in questo caso, è una matrice bidiagonale superiore.\n\nInoltre, la sopra-diagonale di U coincide esattamente con la sopra-diagonale della matrice A originale.\n1.2. Algoritmo\nL’algoritmo per calcolare la fattorizzazione LU di una matrice tridiagonale ha un costo computazionale di 3n - 1, significativamente inferiore rispetto al costo di \\frac{2}{3} n^3 della fattorizzazione LU standard fornita dalla libreria LAPACK.\n1.3. Risoluzione di Sistemi Lineari con Fattorizzazione LU\nDopo aver ottenuto la fattorizzazione LU, il sistema lineare originale Ax = b viene trasformato in due sistemi più semplici:\n\nLy = b (sistema bidiagonale inferiore)\nUx = y (sistema bidiagonale superiore)\n\nRisolvere questi sistemi bidiagonali è più economico rispetto alla risoluzione di sistemi triangolari standard.\n1.4. Sistema Bidiagonale Inferiore: Ly = b\nConsideriamo un sistema bidiagonale inferiore Ly = b, dove L è una matrice bidiagonale inferiore:\nL = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ \\beta_2 &amp; 1 &amp; 0 \\\\ 0 &amp; \\beta_3 &amp; 1 \\ \\end{bmatrix}, y = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\end{bmatrix}, b = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}\nRisolvendo il sistema Ly = b, si ottiene:\n\ny_1 = b_1\n\\beta_2 y_1 + y_2 = b_2 \\Rightarrow y_2 = b_2 - \\beta_2 y_1\n\\beta_3 y_2 + y_3 = b_3 \\Rightarrow y_3 = b_3 - \\beta_3 y_2\n\nGeneralizzando per una matrice L di ordine n, l’algoritmo è:\n\ny_1 = b_1\ny_i = b_i - \\beta_i y_{i-1}, per i = 2, \\dots, n\n\nQuesto algoritmo ha un costo di 2n - 1.\n1.5. Sistema Bidiagonale Superiore: Ux = y\nConsideriamo un sistema bidiagonale superiore Ux = y, dove U è una matrice bidiagonale superiore:\nU = \\begin{bmatrix} \\alpha_1 &amp; c_1 &amp; 0 \\\\ 0 &amp; \\alpha_2 &amp; c_2 \\\\ 0 &amp; 0 &amp; \\alpha_3 \\ \\end{bmatrix}, x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}, y = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{bmatrix}\nRisolvendo il sistema Ux = y, si ottiene:\n\n\\alpha_3 x_3 = y_3 \\Rightarrow x_3 = \\frac{y_3}{\\alpha_3}\n\\alpha_2 x_2 + c_2 x_3 = y_2 \\Rightarrow x_2 = \\frac{1}{\\alpha_2} (y_2 - c_2 x_3)\n\\alpha_1 x_1 + c_1 x_2 = y_1 \\Rightarrow x_1 = \\frac{1}{\\alpha_1} (y_1 - c_1 x_2)\n\nGeneralizzando per una matrice U di ordine n, l’algoritmo è:\n\nx_n = \\frac{y_n}{\\alpha_n}\nx_i = \\frac{1}{\\alpha_i} (y_i - c_i x_{i+1}), per i = n-1, \\dots, 1\n\nQuesto algoritmo ha un costo di 3n - 2.\n1.6. Algoritmo di Thomas\nL’algoritmo di Thomas combina la fattorizzazione LU di una matrice tridiagonale con la risoluzione dei sistemi bidiagonali inferiore e superiore. Il costo totale dell’algoritmo di Thomas è:\n(3n - 1) + (2n - 1) + (3n - 2) = 8n - 4\nQuesto è un risultato notevole, poiché il costo è lineare rispetto alla dimensione del sistema, rendendo l’algoritmo estremamente efficiente per matrici tridiagonali.\n2. Fattorizzazione di Cholesky per Matrici Simmetriche Definite Positive (SDP)\n2.1. Definizione\nUna matrice A è simmetrica definita positiva (SDP) se è simmetrica (A = A^T) e tutti i suoi autovalori sono positivi. Per tali matrici, la fattorizzazione LU esiste ed è unica.\n2.2. Metodo di Cholesky\nLa fattorizzazione di Cholesky decompone una matrice SDP A nella forma:\nA = R^T R\ndove R è una matrice triangolare superiore. Questo significa che è sufficiente calcolare solo un fattore, poiché il fattore triangolare inferiore è semplicemente la trasposta del fattore triangolare superiore.\n2.3. Costo Computazionale\nIl costo computazionale della fattorizzazione di Cholesky è circa la metà della fattorizzazione LU classica, ovvero \\frac{1}{3}n^3.\n2.4. Osservazioni Importanti\nA differenza della fattorizzazione LU standard, i fattori diagonali nella fattorizzazione di Cholesky non sono necessariamente uguali a uno. Tuttavia, le entrate diagonali di R saranno tutte quantità maggiori o uguali a zero.\n3. Matrici Sparse: Strutturate vs. Non Strutturate\n3.1. Definizioni\n\nMatrice sparsa strutturata: è una matrice in cui gli elementi non nulli si dispongono secondo una struttura ben precisa (ad esempio, matrici diagonali o tridiagonali).\nMatrice sparsa non strutturata: è una matrice con pochi elementi non nulli disposti in modo caotico.\n\n3.2. Fattorizzazione LU e Sparsità\n\nSe A è sparsa e strutturata, i fattori L e U ereditano la struttura.\nSe A è sparsa ma non strutturata, i fattori L e U tendono a riempirsi (fill-in).\n\n3.3. Fill-in\nIl fill-in è il fenomeno per cui, durante la fattorizzazione LU di una matrice sparsa, i fattori L e U diventano più densi della matrice originale. Questo aumenta il costo computazionale e la memoria richiesta.\n3.4. Gestione del Fill-in\nPer ridurre il fill-in, si utilizzano algoritmi di riordinamento che permutano le righe e le colonne della matrice per compattare il pattern di sparsità.\n==4. Condizionamento di una Matrice\n4.1. Definizione\nIl numero di condizionamento di una matrice A, indicato con K(A), misura quanto la soluzione di un sistema lineare Ax = b è sensibile a piccole perturbazioni nei dati. È definito come:\nK(A) = |A| |A^{-1}|\ndove | \\cdot | è una norma matriciale.\n4.2. Interpretazione\n\nSe K(A) è piccolo, la matrice è ben condizionata: piccole perturbazioni nei dati portano a piccole perturbazioni nella soluzione.\nSe K(A) è grande, la matrice è mal condizionata: piccole perturbazioni nei dati possono portare a grandi perturbazioni nella soluzione.\n\n4.3. Effetto del Condizionamento\nAnche se la fattorizzazione LU è accurata, una matrice mal condizionata può portare a soluzioni inaccurate a causa degli errori di arrotondamento e delle perturbazioni nei dati.\n4.4. Stima dell’Errore Relativo\nL’errore relativo nella soluzione di un sistema lineare è legato al numero di condizionamento dalla seguente disuguaglianza:\n\\frac{|\\Delta x|}{|x|} \\leq K(A) \\frac{|\\Delta b|}{|b|}\ndove:\n\n\\Delta x è la perturbazione nella soluzione\nx è la soluzione esatta\n\\Delta b è la perturbazione nel termine noto b\n\n4.5. Calcolo del Condizionamento in Matlab\nMatlab fornisce i seguenti comandi per calcolare il numero di condizionamento:\n\ncond(A): calcola il numero di condizionamento usando la norma spettrale (norma 2).\ncond(A, p): calcola il numero di condizionamento usando la norma p.\ncondest(A): stima il numero di condizionamento per matrici sparse usando la norma 1.\n\n4.6. Numero di Condizionamento Spettrale\nIl numero di condizionamento spettrale, K_2(A), è definito come:\nK_2(A) = \\sqrt{\\frac{\\lambda_{max}(A^T A)}{\\lambda_{min}(A^T A)}}\ndove \\lambda_{max} e \\lambda_{min} sono rispettivamente l’autovalore massimo e minimo di A^T A.\nSe A è simmetrica definita positiva, allora:\nK_2(A) = \\frac{\\lambda_{max}(A)}{\\lambda_{min}(A)}\n5. Norme di Vettori e Matrici\n5.1. Norma di un Vettore\n5.1. Norma Euclidea (Norma 2)\nPer un vettore v \\in \\mathbb{R}^n, la norma euclidea è definita come:\n||v||_2 = \\sqrt{\\sum_{i=1}^{n} v_i^2}\n5.2. Norma p\nLa norma p è una generalizzazione della norma euclidea:\n||v||_p = \\left(\\sum_{i=1}^{n} |v_i|^p\\right)^{\\frac{1}{p}}\n5.3. Norma infinito\nLa norma infinito di un vettore v è definita come il massimo valore assoluto delle sue componenti:\n||v||_{\\infty} = \\max_{1 \\leq i \\leq n} |v_i|\n2. Norme Matriciali\nUna norma matriciale è una funzione che assegna una grandezza a una matrice. Esistono diverse norme matriciali, ognuna con proprietà specifiche.\n2.1. Norma Indotta\nUna norma indotta (o norma di оператор) è definita a partire da una norma vettoriale. La norma indotta p di una matrice A è definita come:\n||A||_p = \\sup_{v \\neq 0} \\frac{||Av||_p}{||v||_p}\ndove il \\sup è preso su tutti i vettori non nulli v \\in \\mathbb{R}^n.\n2.2. Norma 1\nLa norma 1 di una matrice è il massimo della somma dei valori assoluti delle colonne:\n||A||_1 = \\max_{1 \\leq j \\leq n} \\sum_{i=1}^{n} |a_{ij}|\n2.3. Norma infinito\nLa norma infinito di una matrice è il massimo della somma dei valori assoluti delle righe:\n||A||_{\\infty} = \\max_{1 \\leq i \\leq n} \\sum_{j=1}^{n} |a_{ij}|\n2.4. Norma 2 (Norma Spettrale)\nLa norma 2 (o norma spettrale) di una matrice A è definita come la radice quadrata dell’autovalore massimo di A^T A:\n||A||_2 = \\sqrt{\\lambda_{\\max}(A^T A)}\nSe A è simmetrica, allora ||A||_2 = \\max_i |\\lambda_i|, dove \\lambda_i sono gli autovalori di A.\n2.5. Norma di Frobenius\nLa norma di Frobenius di una matrice A è definita come la radice quadrata della somma dei quadrati di tutti i suoi elementi:\n||A||_F = \\sqrt{\\sum_{i=1}^{n} \\sum_{j=1}^{n} |a_{ij}|^2}\n3. Compatibilità tra Norme Vettoriali e Matriciali\nUna proprietà importante è la compatibilità tra norme vettoriali e matriciali. Se || \\cdot || è una norma matriciale indotta dalla norma vettoriale || \\cdot ||, allora:\n||Av|| \\leq ||A|| \\cdot ||v||\nper ogni vettore v.\n4. Esempio di Calcolo\nEsempio: Calcolare la norma 1 della matrice:\nA = \\begin{bmatrix} 1 &amp; -2 \\\\ 3 &amp; 4 \\end{bmatrix}\n\nSomma dei valori assoluti per ogni colonna:\n\nColonna 1: |1| + |3| = 4\nColonna 2: |-2| + |4| = 6\n\n\nPrendere il massimo di queste somme:\n\n||A||_1 = \\max(4, 6) = 6\n\n\n\n5. Numero di Condizionamento e Norme\nIl numero di condizionamento di una matrice A dipende dalla norma scelta per calcolarlo:\nK(A) = ||A|| \\cdot ||A^{-1}||\nAd esempio, K_1(A) = ||A||_1 \\cdot ||A^{-1}||_1 e K_2(A) = ||A||_2 \\cdot ||A^{-1}||_2.\n6. Utilizzo in MATLAB\nIn MATLAB, puoi calcolare diverse norme matriciali:\n\nnorm(A, 1): norma 1\nnorm(A, inf): norma infinito\nnorm(A, 2) o norm(A): norma 2 (spettrale)\nnorm(A, &#039;fro&#039;): norma di Frobenius }\n\n\n5.2. Norme di Matrici\nUna norma matriciale è una funzione che assegna un numero reale non negativo a una matrice, soddisfacendo le seguenti proprietà:\n\n|A| \\geq 0 per ogni matrice A\n|A| = 0 se e solo se A = 0\n|\\alpha A| = |\\alpha| |A| per ogni scalare \\alpha\n|A + B| \\leq |A| + |B| per ogni matrice A e B\n\n5.3. Norma Indotta\nLa norma indotta (o norma operatoriale) di una matrice A è definita come:\n|A|_p = \\sup_{v \\neq 0} \\frac{|Av|_p}{|v|_p}\ndove v è un vettore e | \\cdot |_p è una norma vettoriale.\n5.4. Norme Matriciali Comuni\n\nNorma 1: è il massimo della somma dei valori assoluti delle colonne:\n\n|A|_1 = \\max_{1 \\leq j \\leq n} \\sum_{i=1}^{n} |a_{ij}|\n\nNorma infinito: è il massimo della somma dei valori assoluti delle righe:\n\n|A|_{\\infty} = \\max_{1 \\leq i \\leq n} \\sum_{j=1}^{n} |a_{ij}|\n\nNorma 2 (o norma spettrale): è la radice quadrata dell’autovalore massimo di A^T A:\n\n|A|_2 = \\sqrt{\\lambda_{max}(A^T A)}\n\nNorma di Frobenius: è la radice quadrata della somma dei quadrati di tutti gli elementi:\n\n|A|_F = \\sqrt{\\sum_{i=1}^{n} \\sum_{j=1}^{n} |a_{ij}|^2}\n6. Perturbazioni e Condizionamento\n6.1. Sistemi Perturbati\nIn pratica, quando si risolve un sistema lineare Ax = b con metodi numerici, si risolve un sistema perturbato:\n(A + \\Delta A)(x + \\Delta x) = b + \\Delta b\ndove \\Delta A e \\Delta b rappresentano le perturbazioni nella matrice e nel termine noto, rispettivamente, e \\Delta x è la perturbazione nella soluzione.\n6.2. Fonti delle Perturbazioni\nLe perturbazioni sono causate principalmente da:\n\nAritmetica floating-point\nErrori nell’algoritmo\n\n6.3. Obiettivo\nL’obiettivo è capire come le perturbazioni sui dati ( \\Delta A e \\Delta b ) influenzano la soluzione ( \\Delta x ).\n6.4. Matrice di Hilbert\nLa matrice di Hilbert è un esempio classico di matrice mal condizionata. È definita come:\na_{ij} = \\frac{1}{i + j - 1}\nRisolvere un sistema lineare con una matrice di Hilbert può portare a soluzioni molto inaccurate, anche se si utilizza un metodo di fattorizzazione accurato come LU con pivoting.\n6.5. Conclusioni\n\nLa scelta del metodo numerico dipende dalle proprietà della matrice (tridiagonale, SDP, sparsa, ecc.).\nÈ fondamentale valutare il condizionamento della matrice prima di risolvere il sistema.\nMatrici mal condizionate possono portare a soluzioni inaccurate, anche con metodi accurati.\nAlgoritmi di riordinamento possono ridurre il fill-in nelle matrici sparse non strutturate.\n\n\n1. Introduzione al Problema del Condizionamento\nIl condizionamento di una matrice è un concetto cruciale nell’analisi numerica, specialmente quando si risolvono sistemi lineari. Anche se un metodo di fattorizzazione come LU con pivoting produce una fattorizzazione accurata, la soluzione del sistema lineare può essere inaccurata se la matrice è mal condizionata.\n2. Esempio Illustrativo: La Matrice di Hilbert\nPer illustrare questo problema, il professore introduce un esempio specifico: la matrice di Hilbert (o matrice di invert, come menzionato nella trascrizione). Questa matrice è definita come:\na_{ij} = \\frac{1}{i + j - 1}\n\\begin{pmatrix}\n1 &amp; \\frac{1}{2} &amp; \\frac{1}{3} &amp; \\cdots &amp; \\frac{1}{n} \\\\\n\\frac{1}{2} &amp; \\frac{1}{3} &amp; \\frac{1}{4} &amp; \\cdots &amp; \\frac{1}{n+1} \\\\\n\\frac{1}{3} &amp; \\frac{1}{4} &amp; \\frac{1}{5} &amp; \\cdots &amp; \\frac{1}{n+2} \\\\\n\\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n\\frac{1}{n} &amp; \\frac{1}{n+1} &amp; \\frac{1}{n+2} &amp; \\cdots &amp; \\frac{1}{2n-1}\n\\end{pmatrix}\nLa matrice di Hilbert è simmetrica e definita positiva (SDP), il che significa che la fattorizzazione LU esiste ed è unica. Tuttavia, è anche notoriamente mal condizionata.\n2.1. Setup dell’Esperimento Numerico\nPer dimostrare il problema, si imposta un esperimento numerico in MATLAB:\n\nSi sceglie una dimensione n per la matrice A_n e si crea la matrice di Hilbert di dimensione n.\nSi sceglie un termine noto b_n tale che la soluzione esatta x_n sia un vettore di tutti 1. Questo facilita il confronto tra la soluzione calcolata e quella esatta. Il termine noto è scelto come b_n = A_n \\cdot \\mathbb{1}, dove \\mathbb{1} è il vettore con tutte le componenti uguali a 1.\nSi calcola la fattorizzazione LU di A_n con pivoting e si risolve il sistema lineare A_n x = b_n utilizzando MATLAB.\nSi confronta la soluzione ottenuta con la soluzione esatta e si calcola l’errore relativo.\n\n2.2. ==Monitoraggio dell’Accuratezza\nPer monitorare l’accuratezza della fattorizzazione LU, si calcola la matrice residua R_n come:\nR_n = P_n A_n - L_n U_n\ndove P_n è la matrice di permutazione ottenuta dal pivoting. Si verifica che il massimo delle entrate di R_n sia vicino a zero, il che indica che la fattorizzazione LU è accurata.\nSi calcola l’errore relativo \\epsilon_n come:\n\\epsilon_n = \\frac{||x_n - \\tilde{x}_n||}{||x_n||}\ndove \\tilde{x}_n è la soluzione calcolata da MATLAB e || \\cdot || indica la norma euclidea.\n2.3. Risultati dell’Esperimento\nSi osserva che, anche se la fattorizzazione LU è accurata (cioè, ||R_n||_{\\infty} è piccolo), l’errore relativo \\epsilon_n aumenta rapidamente con n. In particolare, per n \\geq 13, l’errore relativo diventa maggiore di 10, il che significa un errore del 1000%.\nQuesto dimostra che, anche con una fattorizzazione accurata, una matrice mal condizionata può portare a risultati disastrosi.\n3. Analisi del Problema: Sistemi Perturbati\nPer capire perché succede questo, il professore spiega che MATLAB non risolve il sistema originale Ax = b, ma un sistema perturbato:\n(A + \\Delta A)(x + \\Delta x) = b + \\Delta b\ndove \\Delta A e \\Delta b sono perturbazioni nei dati dovute all’aritmetica floating-point e agli errori nell’algoritmo.\n3.1. Fonti delle Perturbazioni\nLe perturbazioni \\Delta A e \\Delta b sono causate principalmente da due fattori:\n\nAritmetica floating-point: I calcoli vengono eseguiti con precisione finita, il che introduce errori di arrotondamento.\nAlgoritmo stesso: La scelta dei moltiplicatori e le operazioni eseguite nell’algoritmo possono amplificare gli errori di arrotondamento.\n\n3.2. Obiettivo: Legare Perturbazioni e Risultati\nL’obiettivo è capire come le perturbazioni nei dati influenzano la soluzione. In un mondo ideale, piccole perturbazioni nei dati dovrebbero portare a piccole perturbazioni nella soluzione. Tuttavia, questo non è sempre il caso, specialmente con matrici mal condizionate.\n4. Il Numero di Condizionamento\nIl numero di condizionamento di una matrice A, indicato con K(A), quantifica la sensibilità della soluzione di un sistema lineare alle perturbazioni nei dati. È definito come:\nK(A) = ||A|| \\cdot ||A^{-1}||\ndove || \\cdot || è una norma matriciale.\n4.1. Interpretazione del Numero di Condizionamento\n\nSe K(A) è piccolo, la matrice è ben condizionata: piccole perturbazioni nei dati portano a piccole perturbazioni nella soluzione.\nSe K(A) è grande, la matrice è mal condizionata: piccole perturbazioni nei dati possono portare a grandi perturbazioni nella soluzione.\n\n4.2. Stima dell’Errore Relativo\nL’errore relativo nella soluzione di un sistema lineare è legato al numero di condizionamento dalla seguente disuguaglianza:\n\\frac{||\\Delta x||}{||x||} \\leq K(A) \\frac{||\\Delta b||}{||b||}\ndove:\n\n\\Delta x è la perturbazione nella soluzione\nx è la soluzione esatta\n\\Delta b è la perturbazione nel termine noto b\n\nQuesta disuguaglianza mostra che l’errore relativo nella soluzione può essere amplificato dal numero di condizionamento.\n4.3. Esempio Numerico\nSupponiamo che la perturbazione relativa nei dati sia 10^{-10}. Se K(A) = 1, allora l’errore relativo nella soluzione sarà al più 10^{-10}. Tuttavia, se K(A) = 10^4, allora l’errore relativo nella soluzione potrebbe essere fino a 10^{-6}, che è molto più grande.\n4.4. Calcolo del Condizionamento in MATLAB\nMATLAB fornisce diversi comandi per calcolare il numero di condizionamento:\n\ncond(A): Calcola il numero di condizionamento usando la norma spettrale (norma 2).\ncond(A, p): Calcola il numero di condizionamento usando la norma p.\ncondest(A): Stima il numero di condizionamento per matrici sparse usando la norma 1.\n\n4.5. Numero di Condizionamento Spettrale\nIl numero di condizionamento spettrale, K_2(A), è definito come:\nK_2(A) = \\sqrt{\\frac{\\lambda_{max}(A^T A)}{\\lambda_{min}(A^T A)}}\ndove \\lambda_{max} e \\lambda_{min} sono rispettivamente l’autovalore massimo e minimo di A^T A.\nSe A è simmetrica definita positiva, allora:\nK_2(A) = \\frac{\\lambda_{max}(A)}{\\lambda_{min}(A)}\n5. Dimostrazione della Disuguaglianza Fondamentale\nIl professore fornisce una dimostrazione della disuguaglianza che lega l’errore relativo nella soluzione all’errore relativo nei dati e al numero di condizionamento.\nSi parte dal sistema esatto:\nAx = b\ne dal sistema perturbato:\nA\\tilde{x} = \\tilde{b} = b + \\Delta b\n==Si sottrae membro a membro e si ottiene:\nA(x - \\tilde{x}) = \\Delta b\nDa cui:\nx - \\tilde{x} = A^{-1} \\Delta b\nPrendendo le norme e usando la compatibilità tra norma matriciale e norma vettoriale:\n||x - \\tilde{x}|| \\leq ||A^{-1}|| \\cdot ||\\Delta b||\nSi riparte dal sistema esatto e si prende la norma:\n||b|| = ||Ax|| \\leq ||A|| \\cdot ||x||\nDa cui:\n\\frac{1}{||x||} \\leq \\frac{||A||}{||b||}\nCombinando le due disuguaglianze, si ottiene:\n\\frac{||x - \\tilde{x}||}{||x||} \\leq ||A|| \\cdot ||A^{-1}|| \\frac{||\\Delta b||}{||b||} = K(A) \\frac{||\\Delta b||}{||b||}\nche è la disuguaglianza desiderata.\n6. Conclusioni\nIn sintesi, il condizionamento di una matrice è un fattore cruciale da considerare quando si risolvono sistemi lineari. Anche se un metodo di fattorizzazione è accurato, una matrice mal condizionata può portare a soluzioni molto inaccurate. Pertanto, è sempre consigliabile calcolare il numero di condizionamento prima di risolvere un sistema lineare e, se la matrice è mal condizionata, considerare metodi alternativi o tecniche di regolarizzazione.\nReferences\nAppunti Mate Num- lez04.pdf"},"6--full-note/Matenum--lez11":{"slug":"6--full-note/Matenum--lez11","filePath":"6- full note/Matenum- lez11.md","title":"Matenum- lez11","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","paste/Appunti-Mate-Num-lez11.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-11 12:15\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine matematica numerica\nMatenum- lez11\nApprossimazione di Funzioni e Dati\nIntroduzione all’Approssimazione\nIl corso inizia con l’introduzione al concetto di approssimazione di funzioni e dati. Si parte dall’ipotesi di avere una funzione f definita su un intervallo [a, b] della retta reale. Nel caso dei dati, si considera una collezione di misurazioni, rappresentate come coppie di istanti temporali (o più in generale, ascisse x_i) e valori misurati y_i.\nMotivazioni per l’Approssimazione\nSi esplorano le ragioni per cui potrebbe essere utile o necessario approssimare funzioni e dati. L’idea fondamentale è di rimpiazzare un oggetto potenzialmente complesso o difficile da manipolare con qualcosa di più gestibile.\nApprossimazione di Funzioni\nUn contesto significativo in cui l’approssimazione di funzioni si rivela utile è nel calcolo di integrali. Se si ha un integrale definito di una funzione f(x) tra a e b, \\int_a^b f(x) dx, e la funzione integranda è particolarmente complessa, potrebbe non essere calcolabile in forma esplicita o potrebbe essere espressa come una serie non facilmente valutabile. In questi casi, si può rimpiazzare f(x) con una sua approssimazione \\tilde{f}(x) che sia più facile da integrare. La scelta di \\tilde{f}(x) deve essere tale che l’integrale \\int_a^b \\tilde{f}(x) dx sia facilmente calcolabile. Una scelta suggerita è quella di approssimare f(x) con un polinomio, poiché i polinomi sono facilmente integrabili. L’integrale di f(x) (\\text{IDF}) viene approssimato dall’integrale di \\tilde{f}(x) (\\text{ID}\\tilde{f}): \\text{IDF} = \\int_a^b f(x) dx \\approx \\int_a^b \\tilde{f}(x) dx = \\text{ID}\\tilde{f}\nUn altro contesto menzionato è la soluzione di equazioni non lineari, dove una funzione complessa potrebbe essere sostituita con un polinomio per semplificare la ricerca delle soluzioni.\nApprossimazione di Dati\nQuando si ha a che fare con una collezione di dati, come misurazioni di temperatura nel tempo, l’approssimazione può servire a trovare una tendenza o una legge sottostante i dati. Se da una serie di misurazioni si riesce a dedurre un andamento, questo può essere utilizzato per stimare il valore della grandezza misurata in istanti o luoghi in cui non sono state effettuate misurazioni.\nLa natura dei dati influenza il tipo di approssimazione più appropriato.\n\nPochi dati ben distribuiti: In questo caso, si può cercare di costruire una curva che replica i valori misurati nei punti in cui sono stati acquisiti.\nMolti dati distribuiti in modo caotico (nuvola di dati): In questa situazione, cercare una curva che passi per tutti i punti risulterebbe in un andamento molto irregolare e poco significativo. È più sensato cercare una curva più semplice, come una retta o una parabola, che colga l’andamento generale dei dati senza necessariamente passare per ogni singolo punto.\n\nTipi di Approssimazione: Interpolazione e Minimi Quadrati\nVengono distinti due tipi principali di approssimazione:\n\nInterpolazione: Questo tipo di approssimazione mira a costruire una curva che passa esattamente per i punti dati. È adatta quando si hanno pochi dati ben distribuiti o quando si vuole replicare esattamente i valori di una funzione in specifici punti. Un esempio menzionato è l’interpolazione lineare a tratti, dove si uniscono punti consecutivi con segmenti di retta.\nApprossimazione ai Minimi Quadrati: Questo metodo è più adatto a dati distribuiti in modo caotico e cerca di trovare una curva che minimizza la somma dei quadrati delle differenze tra i valori misurati e i valori sulla curva approssimante. L’obiettivo non è replicare esattamente i singoli valori, ma catturare l’andamento generale. Questo approccio è strettamente legato all’ambito statistico.\n\nApprossimazione di Funzioni e l’Analisi: La Serie di Taylor\nQuando si considera l’approssimazione di funzioni, lo strumento principale offerto dall’analisi è lo sviluppo di Taylor. La serie di Taylor di una funzione f(x) centrata in un punto x_0 è data da: f(x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(x_0)}{k!} (x - x_0)^k = f(x_0) + f&#039;(x_0)(x-x_0) + \\frac{f&#039;&#039;(x_0)}{2!}(x-x_0)^2 + ...\nLo sviluppo di Taylor fornisce un’approssimazione della funzione in un intorno del punto x_0. Tuttavia, presenta due principali limiti:\n\nLocalità: Lo sviluppo di Taylor è una buona approssimazione solo in un intorno ristretto del punto in cui viene centrato. L’esempio della funzione f(x) = \\frac{1}{x} centrata in x_0 = 1 illustra come l’approssimazione di Taylor possa divergere rapidamente al di fuori di un piccolo intervallo intorno a 1. Sebbene in alcuni casi, come l’esponenziale centrato in zero, l’approssimazione possa essere valida su un intervallo più ampio, la località rimane un problema generale.\nRegolarità: Per poter scrivere l’espansione di Taylor fino a un certo ordine (e quindi ottenere una buona approssimazione troncando la serie), è necessario che la funzione f(x) sia sufficientemente derivabile e che le sue derivate siano continue. In molti fenomeni realistici, la regolarità richiesta per lo sviluppo di Taylor potrebbe non essere soddisfatta.\n\nA causa di questi limiti, si rende necessario esplorare metodi di approssimazione alternativi, come l’interpolazione.\nInterpolazione: Definizione e Obiettivo\nL’interpolazione consiste nel trovare un oggetto (nel nostro caso, una funzione \\tilde{f}(x)) che passa esattamente per un insieme di n+1 coppie di dati (x_i, y_i), dove i va da 0 a n. Le x_i sono chiamate nodi di interpolazione e devono essere distinte tra loro (x_i \\neq x_j per i \\neq j). Le y_i rappresentano i valori da interpolare, che possono essere i valori di una funzione f(x) nei nodi (y_i = f(x_i)) o direttamente dei dati misurati.\nL’obiettivo dell’interpolazione è trovare una funzione \\tilde{f}(x) tale che: \\tilde{f}(x_i) = y_i \\quad \\text{per } i = 0, 1, ..., n Queste condizioni sono chiamate condizioni di interpolazione.\nScelta della Funzione Interpolante\nLa funzione \\tilde{f}(x) può essere scelta tra diverse classi di funzioni:\n\n\nInterpolazione Polinomiale: In questo caso, la funzione interpolante \\tilde{f}(x) è un polinomio. L’insieme dei polinomi di grado al più Q con coefficienti reali è denotato con \\mathbb{P}_Q, e un generico polinomio P_Q(x) \\in \\mathbb{P}_Q ha la forma: P_Q(x) = a_0 + a_1 x + a_2 x^2 + ... + a_Q x^Q, dove a_i \\in \\mathbb{R} per i = 0, ..., Q. Ci focalizzeremo principalmente su questo tipo di interpolazione.\n\n\nInterpolazione Trigonometrica: In questo caso, la funzione interpolante è una combinazione di funzioni trigonometriche, come seni e coseni, o equivalentemente, esponenziali complessi. Questo tipo di interpolazione è strettamente legato alle serie di Fourier e viene spesso utilizzato per approssimare segnali e onde. La forma generale può essere espressa come una somma: \\tilde{f}(x) = \\sum_{k} A_k e^{ikx}, dove A_k \\in \\mathbb{R} sono i coefficienti.\n\n\nInterpolazione Razionale: In questo caso, la funzione interpolante \\tilde{f}(x) è un quoziente di due polinomi: \\tilde{f}(x) = \\frac{P(x)}{S(x)} = \\frac{a_0 + a_1 x + ... + a_k x^k}{b_0 + b_1 x + ... + b_s x^s}, dove a_i, b_i \\in \\mathbb{R}.\n\n\nInterpolazione Polinomiale: Esistenza e Unicità\nSi introduce una proposizione fondamentale riguardante l’interpolazione polinomiale:\nProposizione: Si considerino n+1 coppie di dati (x_i, y_i) per i = 0, ..., n, con i nodi di interpolazione x_i distinti tra loro. Allora, esiste ed è unico un polinomio \\pi_n(x) di grado minore o uguale a n tale che \\pi_n(x_i) = y_i per i = 0, ..., n.\nIl simbolo \\pi_n viene utilizzato per denotare il polinomio interpolante di grado al più n. È importante notare lo stretto legame tra il numero di dati (n+1) e il grado massimo del polinomio interpolante (n). Questo è una caratteristica distintiva dell’interpolazione polinomiale rispetto ad altri metodi di approssimazione come i minimi quadrati, dove il grado del polinomio approssimante può essere scelto indipendentemente dal numero di dati.\nIl polinomio di interpolazione \\pi_n(x) viene definito come un’approssimazione globale, in quanto utilizza tutti i dati contemporaneamente per la sua costruzione.\nDimostrazione dell’Unicità\nPer dimostrare l’unicità del polinomio interpolante, si procede per assurdo. Si suppone che esistano due polinomi, \\pi_n(x) e \\pi_n^*(x), entrambi di grado al più n, tali che interpolino gli stessi n+1 punti (x_i, y_i): \\pi_n(x_i) = y_i \\quad \\text{per } i = 0, ..., n \\pi_n^*(x_i) = y_i \\quad \\text{per } i = 0, ..., n\nSi considera la differenza tra i due polinomi: d(x) = \\pi_n(x) - \\pi_n^*(x)\nPoiché sia \\pi_n(x) che \\pi_n^*(x) hanno grado al più n, anche la loro differenza d(x) avrà grado al più n. Valutando d(x) nei nodi di interpolazione x_i, si ottiene: d(x_i) = \\pi_n(x_i) - \\pi_n^*(x_i) = y_i - y_i = 0 \\quad \\text{per } i = 0, ..., n\nQuesto significa che il polinomio d(x) ha n+1 radici distinte (i nodi di interpolazione x_0, x_1, ..., x_n). Tuttavia, un polinomio non nullo di grado al più n può avere al massimo n radici distinte. Affinché un polinomio di grado al più n abbia n+1 radici distinte, esso deve essere identicamente nullo: d(x) = 0 \\quad \\forall x\nQuesto implica che: \\pi_n(x) - \\pi_n^*(x) = 0 \\implies \\pi_n(x) = \\pi_n^*(x)\nPertanto, il polinomio interpolante di grado al più n che passa per n+1 punti distinti è unico. La dimostrazione dell’esistenza verrà affrontata successivamente attraverso la costruzione esplicita del polinomio interpolante.\n\nPolinomio Interpolatore\nUnicità del Polinomio Interpolatore\nIl professore inizia dimostrando per assurdo l’unicità del polinomio di grado n che interpola n+1 punti. Suppone che esistano due polinomi distinti, \\pi_n(x) e \\pi_n^*(x), entrambi di grado n, che replicano gli stessi valori y_i in corrispondenza dei nodi x_i per i che va da 0 a n. Questo significa che:\n\\pi_n(x_i) = y_i \\pi_n^*(x_i) = y_i\nper i = 0, 1, ..., n.\nSuccessivamente, introduce un polinomio differenza G_n(x) definito come:\nG_n(x) = \\pi_n(x) - \\pi_n^*(x).\nQuesto polinomio G_n(x) è anch’esso di grado al più n, essendo la differenza di due polinomi di grado n. Valutando G_n(x) nei nodi di interpolazione x_i, si ottiene:\nG_n(x_i) = \\pi_n(x_i) - \\pi_n^*(x_i) = y_i - y_i = 0.\nQuesto implica che il polinomio G_n(x) di grado n si annulla in n+1 punti distinti (x_0, x_1, ..., x_n). Un polinomio di grado n può avere al massimo n radici (o zeri), a meno che non sia il polinomio identicamente nullo.\nL’unica possibilità affinché un polinomio di grado n abbia n+1 zeri è che sia il polinomio che associa 0 ad ogni valore di x:\nG_n(x) = 0 per ogni x.\nSostituendo la definizione di G_n(x), si ha:\n\\pi_n(x) - \\pi_n^*(x) = 0 per ogni x.\nDa cui si conclude che:\n\\pi_n(x) = \\pi_n^*(x) per ogni x.\nQuesto contraddice l’ipotesi iniziale che i due polinomi fossero distinti, dimostrando quindi l’unicità del polinomio interpolatore di grado n.\nCostruzione del Polinomio Interpolatore\nDopo aver dimostrato l’unicità, il professore passa alla costruzione del polinomio interpolatore \\pi_n(x). Inizia considerando un caso particolare per poi generalizzare.\nCaso Particolare: Interpolazione con Tre Nodi e Valori Specifici\nSi considerano tre nodi di interpolazione: x_0 = 0, x_1 = 0.5, x_2 = 1, e i corrispondenti valori da interpolare: y_0 = 0, y_1 = 1, y_2 = 0. L’obiettivo è costruire un polinomio di grado 2 (una parabola) che passi per i punti (0, 0), (0.5, 1), e (1, 0).\nInvece di chiamare subito il polinomio \\pi_2(x), il professore lo battezza f_1(x). L’indice ‘1’ nel pedice indica il nodo in corrispondenza del quale il valore interpolato non è zero (in questo caso, y_1 = 1 al nodo x_1 = 0.5).\nSi cerca un polinomio di grado 2 che si annulli in x_0 = 0 e x_2 = 1. Un modo semplice per costruire un tale polinomio è il prodotto di monomi:\n(x - x_0)(x - x_2) = (x - 0)(x - 1) = x(x - 1) = x^2 - x.\nQuesto polinomio si annulla in x = 0 e x = 1, soddisfacendo le condizioni in x_0 e x_2. Tuttavia, valutandolo in x_1 = 0.5, si ottiene:\n(0.5)^2 - 0.5 = 0.25 - 0.5 = -0.25.\nPer fare in modo che il polinomio valga 1 in x_1 = 0.5, è necessario dividere per il valore che il polinomio assume in quel punto:\nf_1(x) = \\frac{(x - x_0)(x - x_2)}{(x_1 - x_0)(x_1 - x_2)} = \\frac{(x - 0)(x - 1)}{(0.5 - 0)(0.5 - 1)} = \\frac{x(x - 1)}{0.5 \\times (-0.5)} = \\frac{x^2 - x}{-0.25} = -4(x^2 - x) = 4x - 4x^2.\nQuindi, il polinomio interpolatore f_1(x) = 4x - 4x^2 è una parabola che passa per i punti (0, 0), (0.5, 1), e (1, 0).\nGeneralizzazione: Costruzione dei Polinomi Caratteristici di Lagrange\nIl professore generalizza ora la costruzione al caso di n+1 nodi di interpolazione generici x_0, x_1, ..., x_n e suppone che l’unico valore da interpolare diverso da zero (e uguale a 1) sia in corrispondenza del k-esimo nodo x_k, cioè y_k = 1 e y_i = 0 per i \\neq k. Si vuole costruire il polinomio f_k(x) di grado n tale che:\nf_k(x_j) = \\delta_{jk} = \\begin{cases} 1 &amp; \\text{se } j = k \\\\ 0 &amp; \\text{se } j \\neq k \\end{cases}\ndove \\delta_{jk} è il delta di Kronecker.\nAnalogamente al caso particolare, f_k(x) deve annullarsi in tutti i nodi x_j con j \\neq k. Questo si ottiene considerando il prodotto di monomi che includono tutti i fattori (x - x_j) eccetto quello con j = k:\n\\prod_{j=0, j \\neq k}^{n} (x - x_j) = (x - x_0)(x - x_1)...(x - x_{k-1})(x - x_{k+1})...(x - x_n).\nQuesto prodotto è un polinomio di grado n. Per fare in modo che f_k(x_k) = 1, si divide questo prodotto per il valore che assume in x = x_k:\nf_k(x) = \\frac{\\prod_{j=0, j \\neq k}^{n} (x - x_j)}{\\prod_{j=0, j \\neq k}^{n} (x_k - x_j)}.\nIl polinomio f_k(x) così definito è chiamato polinomio caratteristico di Lagrange associato al nodo x_k.\nIl denominatore è una costante data da:\n(x_k - x_0)(x_k - x_1)...(x_k - x_{k-1})(x_k - x_{k+1})...(x_k - x_n).\nQuando si valuta f_k(x) in un nodo x_i:\n\nSe i = k, il numeratore contiene tutti i fattori del denominatore (con l’ordine dei termini possibilmente diverso), quindi f_k(x_k) = 1.\nSe i \\neq k, uno dei fattori nel numeratore sarà (x_i - x_i) = 0, rendendo l’intero prodotto nullo, quindi f_k(x_i) = 0.\n\nAnalogie con la Funzione Caratteristica\nIl professore fa un’analogia tra il polinomio caratteristico di Lagrange e la funzione caratteristica (o funzione indicatrice) di un insieme \\Omega in \\mathbb{R}^d, spesso indicata con \\mathbb{1}_{\\Omega}(x) o \\chi_{\\Omega}(x). Questa funzione vale:\n\\chi_{\\Omega}(x) = \\begin{cases} 1 &amp; \\text{se } x \\in \\omega \\\\ 0 &amp; \\text{se } x \\notin \\omega \\end{cases}.\nL’analogia risiede nel fatto che f_k(x) “si accende” (vale 1) solo nel nodo x_k e “si spegne” (vale 0) in tutti gli altri nodi di interpolazione. Questa proprietà permette di localizzare il contributo di ciascun nodo all’interpolazione.\nCaso Generale: Polinomio Interpolatore di Lagrange\nInfine, il professore considera il caso generale in cui si vogliono interpolare i valori y_0, y_1, ..., y_n in corrispondenza dei nodi x_0, x_1, ..., x_n . Il polinomio interpolatore di Lagrange \\pi_n(x) si può esprimere come una combinazione lineare dei polinomi caratteristici di Lagrange :\n\\pi_n(x) = \\sum_{k=0}^{n} y_k f_k(x) = \\sum_{k=0}^{n} y_k \\prod_{j=0, j \\neq k}^{n} \\frac{(x - x_j)}{(x_k - x_j)} .\nDove y_k sono i valori da interpolare nei nodi x_k.\nPer verificare che questo polinomio interpola correttamente i dati, valutiamolo in un nodo x_i:\n\\pi_n(x_i) = \\sum_{k=0}^{n} y_k f_k(x_i)\nSappiamo che f_k(x_i) = \\delta_{ik}, quindi f_k(x_i) è 1 se k = i e 0 se k \\neq i. Pertanto, nella somma, l’unico termine non nullo è quello in cui k = i:\n\\pi_n(x_i) = y_i f_i(x_i) = y_i \\times 1 = y_i.\nQuesto dimostra che il polinomio di Lagrange \\pi_n(x) passa per tutti i punti (x_i, y_i) per i = 0, 1, ..., n. Essendo una combinazione lineare di polinomi di grado n, anche \\pi_n(x) è un polinomio di grado al più n. Per l’unicità dimostrata in precedenza, questo è l’unico polinomio di grado n che interpola i dati.\n\nCostruzione del Polinomio di Interpolazione\nPrimo Metodo: Utilizzo dei Polinomi Caratteristici (Forma di Lagrange)\nL’obiettivo è costruire un polinomio \\pi_2(x) di grado 2 che soddisfi tre condizioni di interpolazione date da tre nodi (x_0, y_0), (x_1, y_1), (x_2, y_2).\nSi decide di esprimere \\pi_2(x) come una combinazione lineare di tre polinomi caratteristici f_0(x), f_1(x), f_2(x) associati rispettivamente ai nodi x_0, x_1, x_2:\n\\pi_2(x) = a f_0(x) + b f_1(x) + c f_2(x)\ndove a, b, c sono i coefficienti da determinare.\nQuesti polinomi caratteristici hanno la seguente proprietà fondamentale:\nf_i(x_j) = \\delta_{ij} = \\begin{cases} 1 &amp; \\text{se } i = j \\\\ 0 &amp; \\text{se } i \\neq j \\end{cases}\nEsplicitamente:\nf_0(x_0) = 1, f_0(x_1) = 0, f_0(x_2) = 0 f_1(x_0) = 0, f_1(x_1) = 1, f_1(x_2) = 0 f_2(x_0) = 0, f_2(x_1) = 0, f_2(x_2) = 1\nOra si impongono le condizioni di interpolazione:\n\n\n\\pi_2(x_0) = y_0: a f_0(x_0) + b f_1(x_0) + c f_2(x_0) = y_0 a \\cdot 1 + b \\cdot 0 + c \\cdot 0 = y_0 \\implies \\mathbf{a = y_0}\n\n\n\\pi_2(x_1) = y_1: a f_0(x_1) + b f_1(x_1) + c f_2(x_1) = y_1 a \\cdot 0 + b \\cdot 1 + c \\cdot 0 = y_1 \\implies \\mathbf{b = y_1}\n\n\n\\pi_2(x_2) = y_2: a f_0(x_2) + b f_1(x_2) + c f_2(x_2) = y_2 a \\cdot 0 + b \\cdot 0 + c \\cdot 1 = y_2 \\implies \\mathbf{c = y_2}\n\n\nSostituendo i valori di a, b, c nell’espressione di \\pi_2(x), si ottiene la forma del polinomio interpolatore di grado 2:\n\\mathbf{\\pi_2(x) = y_0 f_0(x) + y_1 f_1(x) + y_2 f_2(x)}\nGeneralizzando questo risultato per n+1 punti di interpolazione (x_i, y_i) con i = 0, 1, \\dots, n, il polinomio interpolatore \\pi_n(x) di grado n è dato da:\n\\mathbf{\\pi_n(x) = \\sum_{k=0}^{n} y_k f_k(x)}\ndove f_k(x) è il polinomio caratteristico associato al nodo x_k e ha la forma:\n\\mathbf{f_k(x) = \\prod_{j=0, j\\neq k}^{n} \\frac{x - x_j}{x_k - x_j}}\nSostituendo l’espressione di f_k(x) nella formula per \\pi_n(x), si ottiene la forma di Lagrange del polinomio interpolatore:\n\\mathbf{\\pi_n(x) = \\sum_{k=0}^{n} y_k \\prod_{j=0, j\\neq k}^{n} \\frac{x - x_j}{x_k - x_j}}\nSecondo Metodo: Risoluzione di un Sistema Lineare\nUn altro modo per costruire il polinomio interpolatore \\pi_n(x) è di esprimerlo nella sua forma generale come un polinomio di grado n:\n\\mathbf{\\pi_n(x) = a_0 + a_1 x + a_2 x^2 + \\dots + a_n x^n = \\sum_{i=0}^{n} a_i x^i}\ndove a_0, a_1, \\dots, a_n sono i coefficienti incogniti (in numero di n+1) che devono essere determinati.\nUtilizzando le n+1 condizioni di interpolazione \\pi_n(x_i) = y_i per i = 0, 1, \\dots, n, si ottiene un sistema di n+1 equazioni lineari nelle n+1 incognite a_0, a_1, \\dots, a_n:\n\\begin{cases} a_0 + a_1 x_0 + a_2 x_0^2 + \\dots + a_n x_0^n = y_0 \\\\ a_0 + a_1 x_1 + a_2 x_1^2 + \\dots + a_n x_1^n = y_1 \\\\ \\vdots \\ a_0 + a_1 x_n + a_2 x_n^2 + \\dots + a_n x_n^n = y_n \\end{cases}\nQuesto sistema può essere scritto in forma matriciale come:\n\\mathbf{B A = Y}\ndove:\n\n\n\\mathbf{B} è la matrice di Vandermonde di dimensione (n+1) \\times (n+1):\n\\mathbf{B} = \\begin{pmatrix} 1 &amp; x_0 &amp; x_0^2 &amp; \\dots &amp; x_0^n \\\\ 1 &amp; x_1 &amp; x_1^2 &amp; \\dots &amp; x_1^n \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_n &amp; x_n^2 &amp; \\dots &amp; x_n^n \\end{pmatrix}\n\n\n\\mathbf{A} è il vettore delle incognite (i coefficienti del polinomio):\n\\mathbf{A} = \\begin{pmatrix} a_0 \\\\ a_1 \\\\ \\vdots \\\\ a_n \\end{pmatrix}\n\n\n\\mathbf{Y} è il vettore dei valori da interpolare:\n\\mathbf{Y} = \\begin{pmatrix} y_0 \\ y_1 \\ \\vdots \\ y_n \\end{pmatrix}\n\n\nLa matrice di Vandermonde \\mathbf{B} è non singolare (e quindi il sistema ammette un’unica soluzione) se e solo se tutti i nodi x_i sono distinti. Questa è l’ipotesi fondamentale sotto cui si formalizza il problema di interpolazione.\nTuttavia, la matrice di Vandermonde è fortemente mal condizionata, simile alla matrice di Hilbert. Questo significa che la risoluzione diretta di questo sistema può portare a coefficienti numericamente inaffidabili, specialmente per valori di n elevati. Pertanto, questo secondo metodo, pur essendo concettualmente semplice, è spesso evitato nella pratica numerica. I metodi iterativi possono migliorare la situazione, ma rimangono comunque rischiosi. Nonostante ciò, questo approccio è spesso presentato a livelli didattici inferiori come introduzione al problema.\nComandi MATLAB per l’Interpolazione Polinomiale\nMATLAB fornisce due comandi principali per lavorare con l’interpolazione polinomiale:\n\n\nPolifit(x, y, n): Questo comando costruisce il polinomio interpolatore.\n\nInput:\n\nx: un vettore contenente i nodi di interpolazione.\ny: un vettore contenente i valori da interpolare nei rispettivi nodi.\nn: il grado del polinomio interpolatore desiderato. È importante notare che, se si hanno n+1 dati e si desidera interpolarli esattamente, il grado del polinomio sarà n. La funzione Polifit è in realtà progettata anche per il fitting ai minimi quadrati, dove il grado del polinomio può essere inferiore al numero di dati. Nel caso di interpolazione esatta con n+1 dati, specificare il grado n corrisponde a trovare il polinomio che passa esattamente per tutti i punti.\n\n\nOutput:\n\nC: un vettore contenente i coefficienti del polinomio interpolatore di grado n. I coefficienti sono ordinati in modo decrescente rispetto al grado, ovvero C = [c_n, c_{n-1}, \\dots, c_1, c_0], dove il polinomio è p(x) = c_n x^n + c_{n-1} x^{n-1} + \\dots + c_1 x + c_0. È fondamentale ricordare questo ordine per interpretare correttamente i risultati.\n\n\n\n\n\nPolival(C, D): Questo comando valuta un polinomio in uno o più punti.\n\nInput:\n\nC: il vettore dei coefficienti del polinomio (ottenuto da Polifit o definito manualmente).\nD: uno scalare o un vettore contenente i punti in cui si desidera valutare il polinomio.\n\n\nOutput:\n\nQ: uno scalare o un vettore contenente i valori del polinomio valutato nei punti specificati in D. Se D è un numero reale, Q sarà un numero reale, \\pi_n(D) = Q. Se D è un vettore di punti, Q sarà un vettore contenente i valori del polinomio in corrispondenza di ciascun punto in D.\n\n\n\n\n\nL’utilità di Polival si manifesta, ad esempio, quando si vuole valutare l’errore dell’interpolazione. Anche se il polinomio interpolatore coincide con la funzione nei nodi di interpolazione, in altri punti potrebbe esserci una discrepanza. Valutando il polinomio in punti intermedi (non inclusi nel set di nodi) e confrontando il valore ottenuto con il valore effettivo della funzione (se conosciuta), è possibile stimare l’errore commesso dall’approssimazione polinomiale.\nErrore del Polinomio di Interpolazione\nQuando si interpola una funzione f(x) utilizzando un polinomio \\pi_n(x) costruito sui nodi x_0, x_1, \\dots, x_n, è importante analizzare l’errore di interpolazione, definito come la differenza tra la funzione e il polinomio:\n\\mathbf{e_n(f(x)) = f(x) - \\pi_n(f(x))}\nSe la funzione f(x) è sufficientemente regolare, ovvero se f è continua insieme alle sue derivate fino all’ordine n+1 nell’intervallo I = [\\min(x_0, \\dots, x_n), \\max(x_0, \\dots, x_n)], allora per ogni x \\in I, esiste un punto \\alpha(x) \\in I (che dipende da x) tale che l’errore è dato da:\n\\mathbf{e_n(f(x)) = \\frac{1}{(n+1)!} f^{(n+1)}(\\alpha(x)) w_{n+1}(x)}\ndove f^{(n+1)}(\\alpha(x)) è la derivata di ordine n+1 di f valutata nel punto \\alpha(x), e w_{n+1}(x) è il polinomio nodale:\n\\mathbf{w_{n+1}(x) = \\prod_{k=0}^{n} (x - x_k) = (x - x_0)(x - x_1)\\dots(x - x_n)}\nQuesto risultato è notevole perché fornisce un’espressione esatta per l’errore di interpolazione. Tuttavia, il punto \\alpha(x) è generalmente sconosciuto. Questo implica che, per rendere operativa questa formula, spesso si passa a una maggiorazione dell’errore, utilizzando il massimo valore assoluto della derivata (n+1)-esima nell’intervallo I.\nÈ importante notare che, se x coincide con uno dei nodi di interpolazione x_i, allora w_{n+1}(x_i) = 0, e di conseguenza l’errore e_n(f(x_i)) = 0. Questo conferma che il polinomio interpolatore passa esattamente per i punti dati.\nReferences\nAppunti Mate Num-lez11.pdf"},"6--full-note/Prob--Ese01":{"slug":"6--full-note/Prob--Ese01","filePath":"6- full note/Prob- Ese01.md","title":"Prob- Ese01","links":["tags/flashcard_finite","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_finite","riscritto_zero","revisione_zero"],"content":"2025-02-25 12:26\n_Status: flashcard_finite   riscritto_zero  revisione_zero\n_Tags:\nProb- Ese01\nSpazio di Probabilità: Concetti Fondamentali\nIl professore introduce il concetto di spazio di probabilità come base per affrontare esperimenti aleatori. Viene sottolineata l’importanza di non limitarsi ai calcoli di probabilità senza comprendere la struttura sottostante.\nDefinizione\nUno spazio di probabilità è definito come una terna (\\Omega, \\mathcal{F}, P), dove:\n\n\\Omega è lo spazio campionario, ovvero l’insieme di tutti i possibili risultati elementari di un esperimento aleatorio.\n\n\\Omega è un insieme generico, senza una struttura specifica richiesta. Può essere finito, infinito numerabile o non numerabile.\nIl professore fa notare che la scelta di \\Omega non è unica; esistono diversi spazi campionari che possono portare agli stessi risultati. Spesso negli esercizi non si specifica neanche chi è \\Omega.\n\n\n\\mathcal{F} è una \\sigma-algebra su \\Omega, cioè una famiglia di sottoinsiemi di \\Omega che include l’insieme vuoto, è chiusa rispetto alla complementazione e all’unione numerabile.\n\nLa \\sigma-algebra rappresenta gli eventi di cui si può calcolare la probabilità.\nLa stabilità per unioni numerabili è essenziale per la struttura della funzione di probabilità P.\n\n\nP è una funzione di probabilità (o misura di probabilità) che assegna ad ogni evento A \\in \\mathcal{F} un numero reale tra 0 e 1, soddisfacendo gli assiomi di probabilità:\n\nP(A) \\geq 0 per ogni A \\in \\mathcal{F}.\nP(\\Omega) = 1.\nSe {A_i}_{i \\in \\mathbb{N}} è una famiglia numerabile di eventi disgiunti (cioè A_i \\cap A_j = \\emptyset per i \\neq j), allora P(\\bigcup_{i=1}^{\\infty} A_i) = \\sum_{i=1}^{\\infty} P(A_i) (\\sigma-additività).\n\n\n\nEsercizi sullo Spazio Campionario \\Omega\nIl professore propone diversi esercizi per determinare uno spazio campionario adeguato e minimale per vari esperimenti aleatori.\nEsempio 1: Lancio di una Moneta N Volte\n\nDescrizione: Lancio di una moneta N volte.\nEsito di un singolo lancio: Testa (T) o Croce (C).\nSpazio campionario: \\Omega = \\set{T, C}^N, dove l’elevamento a potenza indica il prodotto cartesiano dell’insieme \\set{T, C} con se stesso N volte. Questo significa che ogni elemento di \\Omega è una sequenza di N risultati, ciascuno dei quali è T o C.\nOsservazione: Si può scegliere qualsiasi insieme con due elementi per rappresentare i risultati del singolo lancio, ad esempio {0, 1}. In tal caso, \\Omega = {0, 1}^N.\n\nEsempio 2: Lancio di N Monete Indistinguibili\n\nDescrizione: Lancio di N monete uguali e indistinguibili.\nSpazio campionario: In questo caso, l’ordine non è importante, quindi si può considerare il numero di teste ottenute. Tuttavia, il professore sottolinea che concentrarsi solo sull’esito (numero di teste) è una scelta che dipende dall’interesse specifico.\nConsiderazioni: Questo esperimento è diverso dal lancio di una singola moneta N volte, perché le monete sono lanciate simultaneamente e sono indistinguibili.\n\nEsempio 3: Lancio Continuo di una Moneta\n\nDescrizione: Lancio di una moneta una volta al minuto, senza fermarsi mai.\nSpazio campionario: \\Omega = {T, C}^{\\mathbb{N}}, ovvero l’insieme delle successioni infinite di teste e croci. Questo rappresenta il limite del prodotto cartesiano di {T, C} con se stesso infinite volte.\n\nEsempio 4: Estrazione di una Carta da un Mazzo e Lancio di una Moneta\n\nDescrizione: Si estrae una carta da un mazzo di 10 carte e si lancia una moneta.\nSpazio campionario: \\Omega = C \\times \\set{T, C}, dove C = {1, 2, ..., 10} rappresenta le 10 carte. Ogni elemento di \\Omega è una coppia (carta, esito della moneta).\n\nEsempio 5: Estrazione del Lotto\n\nDescrizione: Estrazione di 5 numeri su 90.\nSpazio campionario (con remissione): \\Omega = {1, 2, ..., 90}^5, dove ogni elemento è una quintupla di numeri tra 1 e 90.\nSpazio campionario (senza remissione): \\Omega = {(x_1, x_2, x_3, x_4, x_5) \\in {1, 2, ..., 90}^5 : x_i \\neq x_j \\text{ per } i \\neq j}. Questo spazio campionario esclude le quintuple con numeri ripetuti.\n\nIl professore corregge l’imprecisione iniziale, specificando che l’estrazione del lotto è senza remissione.\n\n\n\nEsempio 6: Tempo per Risolvere il Cubo di Rubik\n\nDescrizione: Tempo impiegato per risolvere il cubo di Rubik partendo da una configurazione casuale, con un tempo massimo T.\nSpazio campionario: \\Omega = [0, T], assumendo che il tempo sia una variabile continua.\n\nIl valore 0 rappresenta il caso in cui il cubo è già risolto.\n\n\n\nEsercizi sulla \\sigma-algebra \\mathcal{F}\nIl professore spiega come interpretare eventi descritti a parole in termini di operazioni insiemistiche sulla \\sigma-algebra \\mathcal{F}.\nEsempio 1: Almeno uno fra tre eventi A, B, C si verifica\n\nEvento: A \\cup B \\cup C.\n\nEsempio 2: Al più un evento si verifica\n\nEvento: (A^c \\cap B^c \\cap C^c) \\cup (A \\cap B^c \\cap C^c) \\cup (A^c \\cap B \\cap C^c) \\cup (A^c \\cap B^c \\cap C).\n\nQuesto evento è l’unione dell’evento “nessun evento si verifica” e degli eventi “si verifica solo A”, “si verifica solo B”, “si verifica solo C”.\n\n\n\nEsempio 3: Non si verifica nulla\n\nEvento: A^c \\cap B^c \\cap C^c.\n\nEsempio 4: Si verificano tutti e tre\n\nEvento: A \\cap B \\cap C.\n\nEsempio 5: Si verifica esattamente un evento\n\nEvento: (A \\cap B^c \\cap C^c) \\cup (A^c \\cap B \\cap C^c) \\cup (A^c \\cap B^c \\cap C).\n\nIn alternativa, si può esprimere come E_B - E_C, dove E_B è l’evento “al più un evento si verifica” e E_C è l’evento “si verificano tutti e tre”.\n\n\n\nEsempio 6: Si verificano esattamente due eventi\n\nEvento: (A \\cap B \\cap C^c) \\cup (A \\cap B^c \\cap C) \\cup (A^c \\cap B \\cap C).\n\nEventi e Relazioni Logiche\nLa flashcard include esercizi relativi a eventi e relazioni logiche tra eventi in uno spazio di probabilità.\nEsercizio 1: Eventi che si verificano\n\n\nObiettivo: Determinare l’evento risultante quando si hanno determinate relazioni logiche tra eventi A e B.\n\n\nCaso 1: A implica B\n\nSe A implica B, significa che ogni volta che si verifica A, si verifica anche B. In termini insiemistici, questo significa che A è un sottoinsieme di B, ovvero A \\subseteq B.\nEsempio: “Se un numero naturale è multiplo di 4, allora è anche multiplo di 2”. In questo caso, l’insieme dei multipli di 4 è un sottoinsieme dell’insieme dei multipli di 2.\n\n\n\nCaso 2: A e B sono mutuamente esclusivi\n\nSe A e B sono mutuamente esclusivi, significa che non possono verificarsi contemporaneamente. In termini insiemistici, questo significa che la loro intersezione è vuota, ovvero A \\cap B = \\emptyset.\nQuesto implica che tutti gli elementi di B non stanno in A e viceversa tutti gli elementi di A non stanno in B\n\n\n\nCaso 3: Uno fra A e B si verifica sempre\n\nSe uno fra A e B si verifica sempre, significa che preso un qualsiasi esito dell’esperimento, questo deve ricadere o in A o in B. In termini insiemistici, questo significa che l’unione di A e B è l’intero spazio campionario \\Omega, ovvero A \\cup B = \\Omega. Questo vuol dire che \\Omega mette una partizione in A e B\nQuesto include anche i casi in cui uno fra A e B sia effettivamente \\Omega\n\n\n\n\n\nEsercizio 2: Lancio Infinito di una Moneta e \\sigma-algebre\n\n\nDescrizione: Si considera il lancio infinito di una moneta e si analizzano le \\sigma-algebre generate da eventi specifici.\n\n\nSpazio campionario: \\Omega = {0, 1}^{\\mathbb{N}}, dove 0 e 1 rappresentano rispettivamente “croce” e “testa”.\n\n\nEvento E_k: Successo (cioè, esce “testa”) alla k-esima prova.\n\n\\sigma-algebra generata da E_1: È la più piccola \\sigma-algebra che contiene E_1. Deve contenere l’insieme vuoto \\emptyset, \\Omega e il complementare di E_1, ovvero E_1^c.\n\\sigma-algebra generata da E_1 e E_2: Deve contenere \\emptyset, \\Omega, E_1, E_2, i loro complementari, le loro unioni e le unioni miste. L’esercizio chiede di completare questa \\sigma-algebra e determinare quanti elementi ha.\n\n\n\n\\sigma-algebra generata dalla successione E_k: È la più piccola \\sigma-algebra che contiene tutti gli E_k.\n\nIl professore spiega che esiste sempre una \\sigma-algebra non banale che contiene tutti gli E_k.\n\n\n\nEsercizio 3: Eventi con Infiniti Elementi\n\n\nObiettivo: Esprimere eventi complessi in termini di operazioni insiemistiche sugli E_k.\n\nNessun successo: \\bigcap_{k=1}^{\\infty} E_k^c (intersezione di tutti i complementari degli E_k).\nSi verifica soltanto E_3: E_3 \\cap \\bigcap_{k \\neq 3} E_k^c (si verifica E_3 e non si verificano tutti gli altri).\nTutte le prove pari forniscono successo: \\bigcap_{k=1}^{\\infty} E_{2k} (intersezione di tutti gli E_k con k pari).\nSolo successi da un certo k in poi (dove k non è fissato): \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} E_k (unione delle intersezioni degli E_k da un certo punto in poi). Questo si chiama limite inferiore.\n\nil professore arriva a questa formula in due step:  Per dire che io ho solo successi da un certo punto in poi è come dire che ho solo successi dal primo in poi oppure ho solo successi dal secondo in poi oppure ho solo successi dal terzo in poi e così via.\n\n\nInfiniti successi: \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} E_k (intersezione delle unioni degli E_k da un certo punto in poi). Questo si chiama limite superiore.\n\nBisogna ragionare come in analisi 1, infiniti successi vuol dire che non sono finiti i successi. Questo vuol dire, in un certo senso, che l’insieme degli indici delle prove che sono successi non è limitato. Comunque fissate n esiste un successo k più grande di n.\n\n\nUn numero finito di successi: (\\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} E_k)^c = \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} E_k^c (complementare dell’evento “infiniti successi”). Si utilizzano le leggi di De Morgan.\nSi verifica esattamente un successo: \\bigcup_{n=1}^{\\infty} (E_n \\cap \\bigcap_{k \\neq n} E_k^c) (unione degli eventi in cui si verifica solo un E_n).\n\n\n\nEventi e Relazioni Logiche\nLa flashcard include esercizi relativi a eventi e relazioni logiche tra eventi in uno spazio di probabilità.\nEsercizio 1: Eventi che si verificano\n\n\nObiettivo: Determinare l’evento risultante quando si hanno determinate relazioni logiche tra eventi A e B.\n\n\nCaso 1: Almeno uno fra i tre (A, B, C) si verifica\n\nQuesto corrisponde alla disgiunzione inclusiva. L’evento è rappresentato dall’unione dei tre insiemi: A \\cup B \\cup C.\n\n\n\nCaso 2: Si verifica al più un evento\n\nQuesto significa che si verificano zero eventi o esattamente un evento.\nZero eventi: Corrisponde all’intersezione dei complementari: A^c \\cap B^c \\cap C^c.\nEsattamente un evento: (A \\cap B^c \\cap C^c) \\cup (A^c \\cap B \\cap C^c) \\cup (A^c \\cap B^c \\cap C).\nL’evento complessivo è l’unione di questi due casi.\n\n\n\nCaso 3: Non si verifica nulla\n\nCorrisponde all’intersezione dei complementari: A^c \\cap B^c \\cap C^c.\n\n\n\nCaso 4: Si verificano tutti e tre\n\nCorrisponde all’intersezione dei tre insiemi: A \\cap B \\cap C.\n\n\n\nCaso 5: Si verifica esattamente un evento\n\nÈ l’unione degli eventi in cui se ne verifica solo uno: (A \\cap B^c \\cap C^c) \\cup (A^c \\cap B \\cap C^c) \\cup (A^c \\cap B^c \\cap C).\nPuò essere visto anche come l’evento “si verifica al più un evento” meno l’evento “si verificano esattamente due eventi”.\n\n\n\nCaso 6: Si verificano esattamente due\n\n(A \\cap B \\cap C^c) \\cup (A \\cap B^c \\cap C) \\cup (A^c \\cap B \\cap C).\n\n\n\n\n\nEsercizio 2: Relazioni logiche tra eventi\n\n\nCaso 1: A implica B\n\nSe A implica B, significa che ogni volta che si verifica A, si verifica anche B. In termini insiemistici, questo significa che A è un sottoinsieme di B, ovvero A \\subseteq B.\nEsempio: “Se un numero naturale è multiplo di 4, allora è anche multiplo di 2”. In questo caso, l’insieme dei multipli di 4 è un sottoinsieme dell’insieme dei multipli di 2.\n\n\n\nCaso 2: A e B sono mutuamente esclusivi\n\nSe A e B sono mutuamente esclusivi, significa che non possono verificarsi contemporaneamente. In termini insiemistici, questo significa che la loro intersezione è vuota, ovvero A \\cap B = \\emptyset.\nQuesto implica che tutti gli elementi di B non stanno in A e viceversa tutti gli elementi di A non stanno in B\n\n\n\nCaso 3: Uno fra A e B si verifica sempre\n\nSe uno fra A e B si verifica sempre, significa che preso un qualsiasi esito dell’esperimento, questo deve ricadere o in A o in B. In termini insiemistici, questo significa che l’unione di A e B è l’intero spazio campionario \\Omega, ovvero A \\cup B = \\Omega. Questo vuol dire che \\Omega mette una partizione in A e B\nQuesto include anche i casi in cui uno fra A e B sia effettivamente \\Omega\n\n\n\n\n\nEsercizio 2: Lancio Infinito di una Moneta e \\sigma-algebre\n\n\nDescrizione: Si considera il lancio infinito di una moneta e si analizzano le \\sigma-algebre generate da eventi specifici.\n\n\nSpazio campionario: \\Omega = {0, 1}^{\\mathbb{N}}, dove 0 e 1 rappresentano rispettivamente “croce” e “testa”.\n\n\nEvento E_k: Successo (cioè, esce “testa”) alla k-esima prova.\n\n\\sigma-algebra generata da E_1: È la più piccola \\sigma-algebra che contiene E_1. Deve contenere l’insieme vuoto \\emptyset, \\Omega e il complementare di E_1, ovvero E_1^c.\n\\sigma-algebra generata da E_1 e E_2: Deve contenere \\emptyset, \\Omega, E_1, E_2, i loro complementari, le loro unioni e le unioni miste. L’esercizio chiede di completare questa \\sigma-algebra e determinare quanti elementi ha.\n\n\n\n\\sigma-algebra generata dalla successione E_k: È la più piccola \\sigma-algebra che contiene tutti gli E_k.\n\nIl professore spiega che esiste sempre una \\sigma-algebra non banale che contiene tutti gli E_k.\n\n\n\nEsercizio 3: Eventi con Infiniti Elementi\n\n\nObiettivo: Esprimere eventi complessi in termini di operazioni insiemistiche sugli E_k.\n\nNessun successo: \\bigcap_{k=1}^{\\infty} E_k^c (intersezione di tutti i complementari degli E_k).\nSi verifica soltanto E_3: E_3 \\cap \\bigcap_{k \\neq 3} E_k^c (si verifica E_3 e non si verificano tutti gli altri).\nTutte le prove pari forniscono successo: \\bigcap_{k=1}^{\\infty} E_{2k} (intersezione di tutti gli E_k con k pari).\nSolo successi da un certo k in poi (dove k non è fissato): \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} E_k (unione delle intersezioni degli E_k da un certo punto in poi). Questo si chiama limite inferiore.\n\nIl professore arriva a questa formula in due step: Per dire che io ho solo successi da un certo punto in poi è come dire che ho solo successi dal primo in poi oppure ho solo successi dal secondo in poi oppure ho solo successi dal terzo in poi e così via.\n\n\nInfiniti successi: \\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} E_k (intersezione delle unioni degli E_k da un certo punto in poi). Questo si chiama limite superiore.\n\nBisogna ragionare come in analisi 1, infiniti successi vuol dire che non sono finiti i successi. Questo vuol dire, in un certo senso, che l’insieme degli indici delle prove che sono successi non è limitato. Comunque fissate n esiste un successo k più grande di n.\n\n\nUn numero finito di successi: (\\bigcap_{n=1}^{\\infty} \\bigcup_{k=n}^{\\infty} E_k)^c = \\bigcup_{n=1}^{\\infty} \\bigcap_{k=n}^{\\infty} E_k^c (complementare dell’evento “infiniti successi”). Si utilizzano le leggi di De Morgan.\nSi verifica esattamente un successo: \\bigcup_{n=1}^{\\infty} (E_n \\cap \\bigcap_{k \\neq n} E_k^c) (unione degli eventi in cui si verifica solo un E_n).\n\n\n\nEsercizio 4: Pesca di Beneficenza\n\nDescrizione: Anna e Marco partecipano a una pesca di beneficenza con 50 biglietti. Ci sono premi che piacciono solo ad Anna, solo a Marco, o a entrambi.\nSpazio campionario: \\Omega = {1, 2, \\dots, 50}, l’insieme dei biglietti.\n\\sigma-algebra: L’insieme delle parti di \\Omega, indicato come 2^\\Omega.\nProbabilità uniforme: Ogni biglietto ha la stessa probabilità di essere estratto.\n\nLa probabilità di un evento A è data da P(A) = \\frac{|A|}{|\\Omega|}, dove |A| è la cardinalità di A.\n\n\nEventi:\n\nA: Insieme dei premi che piacciono ad Anna.\nM: Insieme dei premi che piacciono a Marco.\nA \\cap M: Insieme dei premi che piacciono a entrambi.\nA \\cup M: Insieme dei premi che piacciono ad almeno uno dei due.\n(A \\cup M)^c: Insieme dei premi che non piacciono a nessuno dei due.\n(A \\cup M) - (A \\cap M): Insieme dei premi che piacciono solo ad Anna o solo a Marco.\n\n\nCalcolo delle probabilità: Si contano gli elementi degli insiemi e si divide per 50.\n\nEsempio: Se |A| = 8 e |M| = 6 e |A \\cap M| = 1, allora P(A) = \\frac{8}{50}, P(M) = \\frac{6}{50} e P(A \\cup M) = \\frac{8 + 6 - 1}{50} = \\frac{13}{50}.\n\n\n\nEsercizio 5: Vero o Falso\n\n\nDescrizione: Dato uno spazio di probabilità e due eventi A e B con P(A) = 0.4 e P(B) = 0.7, determinare se alcune affermazioni sono sempre vere, sempre false o indecidibili.\n\n\nEsempio 1: P(A \\cup B) = 0\n\nAnalisi: Questa affermazione è sempre falsa. Infatti, P(A \\cup B) = P(A) + P(B) - P(A \\cap B). Poiché P(A) e P(B) sono positivi, P(A \\cup B) non può essere zero.\n\n\n\nEsempio 2: P(A \\cup B) = 1.1\n\nQuesta affermazione è sempre falsa perché la probabilità di qualsiasi evento deve essere minore o uguale a 1.\n\n\n\nEsempio 3: P(A \\cap B) = 0.28\n\nQuesta affermazione può essere sia vera che falsa, a seconda dello spazio di probabilità specifico e della relazione tra A e B.\n\n\n\nEsempio 4: P(B \\cap A^c) \\geq 0.3\n\nAnalisi: P(B \\cap A^c) = P(B) - P(A \\cap B). Dobbiamo stabilire se 0.7 - P(A \\cap B) \\geq 0.3, ovvero se P(A \\cap B) \\leq 0.4. Questo è sempre vero perché P(A \\cap B) è minore o uguale al minimo tra P(A) e P(B), e quindi minore o uguale a 0.4.\n\n\n\nEsempio 5: P(A \\cap B^c) \\leq 0.2\n\nAnalisi: P(A \\cap B^c) = P(A) - P(A \\cap B). Dobbiamo stabilire se 0.4 - P(A \\cap B) \\leq 0.2, ovvero se P(A \\cap B) \\geq 0.2.\nLa probabilità dell’unione è P(A \\cup B) = 1.1 - P(A \\cap B). Poiché P(A \\cup B) \\leq 1, allora 1.1 - P(A \\cap B) \\leq 1, quindi P(A \\cap B) \\geq 0.1.\n\n\n\nReferences"},"6--full-note/Prob--Ese02":{"slug":"6--full-note/Prob--Ese02","filePath":"6- full note/Prob- Ese02.md","title":"Prob- Ese02","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità","2--source-materials/appunti-Prob--ese02.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-04 17:07\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine probabilità\nProb- Ese02\nProblemi Paradigma della Combinatoria\nEsercizio 1: Anagrammi e Permutazioni\nDefinizione di Permutazione: Una permutazione è un modo di ordinare una sequenza di elementi. Intuitivamente, si tratta di scambiare l’ordine degli oggetti. Formalmente, è una biiezione da un insieme {1, 2, ..., n} all’insieme stesso, ma per scopi pratici, il concetto intuitivo è sufficiente.\nProblema: Calcolare quanti anagrammi esistono per la parola “enigma”.\n\nLa parola “enigma” ha sei lettere distinte.\nSoluzione: Per il primo slot (la prima lettera dell’anagramma), ci sono sei scelte possibili. Per il secondo slot, rimangono cinque scelte, e così via. Quindi, il numero totale di anagrammi è 6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1 = 6! = 720.\nIn generale, il numero di permutazioni di n oggetti distinti è n!.\n\nCaso con Lettere Ripetute: Cosa cambia se la parola ha lettere ripetute, come “matematica”?\n\nLa parola “matematica” ha 10 lettere, con 3 A, 2 T e 2 M ripetute.\nIntuizione: Scambiare due lettere identiche non cambia la parola, quindi alcune permutazioni sono indistinguibili.\nSoluzione: Fissiamo una permutazione (ad esempio, “matematica”). Contiamo quante permutazioni delle lettere ripetute lasciano la parola invariata. Ci sono 3! modi di permutare le A, 2! modi di permutare le T, e 2! modi di permutare le M. Quindi, ci sono 3! \\times 2! \\times 2! = 6 \\times 2 \\times 2 = 24 permutazioni che lasciano la parola invariata.\nIl numero totale di permutazioni è \\frac{10!}{3! \\times 2! \\times 2!} = \\frac{3628800}{24} = 151200.\n\nRegola Generale: Dato un insieme di n oggetti con k tipi di oggetti ripetuti A_1, A_2, ..., A_k con molteplicità a_1, a_2, ..., a_k, il numero di permutazioni è:\n\\frac{n!}{a_1! \\times a_2! \\times ... \\times a_k!}\nEsercizio 2: Disposizioni Semplici\nDefinizione: Una disposizione di k oggetti scelti da un insieme di n oggetti distinti è una selezione ordinata di k oggetti. L’ordine è importante.\nProblema: Quanti podi (primo, secondo e terzo posto) si possono formare in una competizione con 20 partecipanti?\n\nSoluzione: Ci sono 20 scelte per il primo posto, 19 per il secondo e 18 per il terzo. Quindi, il numero di podi possibili è 20 \\times 19 \\times 18 = 6840.\nQuesto è un esempio di fattoriale decrescente, indicato come \\frac{(20)!}{17!}.\n\nFormula Generale: Il numero di disposizioni di k elementi scelti da n è:\nn \\times (n-1) \\times (n-2) \\times ... \\times (n-k+1) = \\frac{n!}{(n-k)!}\nEsercizio 3: Combinazioni Semplici\nDefinizione: Una combinazione di k elementi scelti da un insieme di n elementi è una selezione di k elementi senza considerare l’ordine.\nProblema: Trovare il numero di sottoinsiemi di k elementi di un insieme con n elementi.\n\nIntuizione: Prima consideriamo le disposizioni, poi eliminiamo l’ordine.\nSoluzione: Partiamo dalle disposizioni di k elementi da n, che sono \\frac{n!}{(n-k)!}. Però, ogni combinazione di k elementi può essere ordinata in k! modi diversi. Quindi, dobbiamo dividere il numero di disposizioni per k! per ottenere il numero di combinazioni.\n\nFormula Generale: Il numero di combinazioni di k elementi scelti da n è:\n\\binom{n}{k} = \\frac{n!}{(n-k)! \\cdot k!}\nQuesto è il coefficiente binomiale.\nCardinalità dell’Insieme delle Parti\nObiettivo: Dimostrare che la cardinalità dell’insieme delle parti di un insieme finito con n elementi è 2^n.\nDefinizioni Preliminari\n\nSia A un insieme tale che la sua cardinalità sia card(A) = n.\nL’insieme delle parti di A, indicato con P(A), è l’insieme di tutti i sottoinsiemi di A.\n\nPassaggi della Dimostrazione\n\n\nEsprimere la cardinalità di P(A)\nLa cardinalità di P(A) può essere espressa come la cardinalità dell’unione di tutti i sottoinsiemi di A aventi cardinalità che va da 0 a n. In termini matematici:\ncard(P(A)) = card(\\bigcup_{k=0}^{n} \\set{B \\subseteq A : \\text{card}(B) = k})\n\n\nDisgiunzione degli insiemi\nOgni sottoinsieme di A ha una e una sola cardinalità. Pertanto, gli insiemi nell’unione sono disgiunti. Questo significa che un insieme B non può appartenere a due insiemi con cardinalità diversa (cioè, per un K1 e K2 diversi, B non può appartenere contemporaneamente a entrambi i sottoinsiemi).\n\n\nCardinalità dell’unione disgiunta\nLa cardinalità dell’unione di insiemi disgiunti è la somma delle cardinalità degli insiemi stessi. Quindi:\ncard(P(A)) = \\sum_{k=0}^{n} \\text{card}(\\set{B \\subseteq A : \\text{card}(B) = k})\nLa cardinalità di ogni insieme di sottoinsiemi di dimensione k è data dal coefficiente binomiale “n su k”, che rappresenta il numero di modi di scegliere k elementi da un insieme di n elementi.\ncard(P(A)) = \\sum_{k=0}^{n} \\binom{n}{k}\n\n\nSomma dei coefficienti binomiali\nSi deve trovare la somma dei coefficienti binomiali. Si utilizza il teorema binomiale per semplificare questa somma. Si considera l’espressione (1 + 1)^n.\n(1 + 1)^n = \\sum_{k=0}^{n} \\binom{n}{k} \\cdot 1^k \\cdot 1^{n-k} = \\sum_{k=0}^{n} \\binom{n}{k}\nPoiché (1 + 1)^n = 2^n, si ha:\n\\sum_{k=0}^{n} \\binom{n}{k} = 2^n\n\n\nConclusione\nSostituendo la somma dei coefficienti binomiali con 2^n, si ottiene la cardinalità dell’insieme delle parti:\ncard(P(A)) = 2^n\n\n\nEsempio e Collegamento al Triangolo di Tartaglia\nLa somma dei coefficienti binomiali corrisponde alla somma degli elementi in ogni riga del triangolo di Tartaglia, e ogni riga ha come somma una potenza di 2.\n\nDefinizione del problema\nSi considera un numero intero n di biglie distinte. L’obiettivo è analizzare l’estrazione di k di queste biglie, considerando tre modalità diverse:\n\nEstrazione senza reimmissione\nEstrazione con reimmissione\nEstrazione simultanea\n\nSvolgimento dell’esercizio\nDefinizioni preliminari\n\nSia B = \\set{b_1, ..., b_n} un insieme che rappresenta le n biglie distinte. Ogni biglia è identificata in modo univoco.\nEstrazione senza reimmissione: ogni biglia estratta viene posta sul tavolo e non viene rimessa nell’urna. Questo implica che nell’urna ci saranno sempre meno biglie rispetto alla partenza.\nEstrazione con reimmissione: ogni biglia estratta viene rimessa nell’urna. In questo modo, è possibile estrarre la stessa biglia più volte.\nEstrazione simultanea: si estraggono k biglie contemporaneamente, senza un ordine specifico. Non c’è una prima o una seconda biglia estratta.\n\nCaso 1: Estrazione senza reimmissione\n\n\nLo spazio degli esiti (\\Omega) è l’insieme delle k-uple di elementi distinti.\n\n\nFormalmente: \\Omega = {(b_1, ..., b_k) \\in B^k \\mid b_i \\neq b_j \\text{ per } i \\neq j}\n\n\nLa cardinalità di \\Omega corrisponde al numero di disposizioni semplici di k elementi su n:\n|\\Omega| = \\frac{n!}{(n-k)!}\n\n\nCaso 2: Estrazione con reimmissione\n\n\n\\Omega è l’insieme delle k-uple, dove ogni elemento della k-upla può essere qualsiasi elemento di B.\n\n\nFormalmente: \\Omega = B \\times B \\times ... \\times B = B^k\n\n\nLa cardinalità di \\Omega è:\n|\\Omega| = |B|^k = n^k\nQuesto corrisponde alle disposizioni con ripetizione.\n\n\nCaso 3: Estrazione simultanea\n\n\nQui si selezionano k elementi su n senza considerare l’ordine.\n\n\n\\Omega può essere identificato come l’insieme dei sottoinsiemi di B con cardinalità k.\n\n\nFormalmente: \\Omega = \\set{b \\subseteq B : |b| = k}\n\n\nLa cardinalità di \\Omega è data dalle combinazioni semplici:\n|\\Omega| = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\n\n\nStars and Bars (Biglie e Scatole)==b hjb\nQuesto problema riguarda la suddivisione di n biglie indistinguibili in k scatole distinte.\n\n\nConfigurazione: Una configurazione rappresenta come le biglie sono distribuite nelle scatole. Dato che le scatole sono distinte, l’ordine è importante.\n\n\nEsempio: Consideriamo il caso con n = 6 biglie e k = 3 scatole. Una configurazione può essere rappresentata inserendo k - 1 = 2 stanghette tra le biglie. Per esempio, la sequenza &quot;\\bullet \\bullet \\bullet | \\bullet | \\bullet \\bullet&quot; rappresenta 3 biglie nella prima scatola, 1 nella seconda e 2 nella terza.\n\n\nBisezione: Esiste una corrispondenza biunivoca tra le configurazioni e questi “disegni” con biglie e stanghette.\n\n\nCalcolo delle configurazioni: Il numero di configurazioni è uguale al numero di anagrammi della stringa formata da n biglie e k - 1 stanghette. Quindi, si ha una stringa di lunghezza n + k - 1. Il numero di modi di disporre queste biglie e stanghette è dato da:\n\\frac{(n + k - 1)!}{n! (k - 1)!} = \\binom{n + k - 1}{k - 1}\n\n\nEsercizio aggiuntivo: Cosa cambia se ogni scatola deve contenere almeno una biglia? In questo caso, k non può essere maggiore di n. Questo problema è legato alle partizioni intere, cioè esprimere un intero n come somma di k addendi strettamente positivi.\n\n\nParadosso dei Compleanni: Spiegazione Dettagliata\nIl problema: In una stanza ci sono n persone. Qual è la probabilità che almeno due di loro festeggino il compleanno nello stesso giorno? Quante persone devono esserci nella stanza affinché questa probabilità sia maggiore del 50%?.\nAssunzioni:\n\nUn anno ha 365 giorni.\nLa probabilità di nascere in un qualsiasi giorno dell’anno è uniforme (equiprobabilità).\nNon ci sono gemelli nella stanza (indipendenza delle date di nascita).\n\n1. Ambientazione Probabilistica\n\nDefinizione dell’insieme delle date: Sia D l’insieme delle date, con |D| = 365. Rappresentiamo i giorni dell’anno con numeri da 1 a 365.\nSpazio campionario \\Omega: Le date di nascita di n persone sono rappresentate da un elemento di D^n, quindi \\Omega = D^n. La cardinalità di \\Omega è |\\Omega| = 365^n.\nSigma algebra: Scegliamo la sigma algebra più semplice, ovvero l’insieme delle parti di \\Omega, denotato come \\mathcal{P}(\\Omega).\nFunzione di probabilità: Assumendo l’equiprobabilità degli elementi di D^n, la probabilità di un qualsiasi evento A è data da: P(A) = \\frac{|A|}{|\\Omega|} = \\frac{|A|}{365^n}\n\n2. Definizione dell’Evento di Interesse\n\nEvento A: Siamo interessati alle n-uple in cui almeno due persone condividono il compleanno. Formalmente: A = \\set{(d_1, d_2, ..., d_n) \\in D^n : \\exists \\ i, j \\in {1, ..., n}, i \\neq j \\text{ tale che } d_i = d_j } Questo significa che A è l’insieme di tutte le possibili combinazioni di date di nascita per n persone, dove almeno due persone hanno lo stesso compleanno.\nEvento Complementare A^c: È più facile calcolare la probabilità dell’evento complementare, cioè l’evento in cui tutte le n persone hanno compleanni diversi. A^c = {(d_1, d_2, ..., d_n) \\in D^n : d_i \\neq d_j \\ \\forall \\ i \\neq j } A^c rappresenta tutte le n-uple in cui non ci sono compleanni in comune.\n\n3. Calcolo della Probabilità di A^c\nLa cardinalità di A^c è data dal numero di disposizioni semplici di n elementi scelti da un insieme di 365 elementi. Questo perché la prima persona può avere qualsiasi dei 365 giorni come compleanno, la seconda persona può avere uno dei rimanenti 364 giorni, e così via. Quindi: |A^c| = 365 \\cdot 364 \\cdot ... \\cdot (365 - n + 1) = \\frac{365!}{(365 - n)!} La probabilità di A^c è quindi: P(A^c) = \\frac{|A^c|}{365^n} = \\frac{365!}{(365 - n)! \\cdot 365^n}\n4. Calcolo della Probabilità di A\nLa probabilità dell’evento A (almeno due persone con lo stesso compleanno) è il complemento a 1 della probabilità di A^c: P(A) = 1 - P(A^c) = 1 - \\frac{365!}{(365 - n)! \\cdot 365^n} che può essere riscritta come P(A) = 1 - \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot \\frac{363}{365} \\cdot ... \\cdot \\frac{365 - n + 1}{365}\n5. Determinazione del Valore di n\nVogliamo trovare il minimo n tale che P(A) \\geq \\frac{1}{2}. Questo equivale a trovare n tale che: 1 - \\frac{365!}{(365 - n)! \\cdot 365^n} \\geq \\frac{1}{2} che può essere riscritto come: \\frac{365}{365} \\cdot \\frac{364}{365} \\cdot ... \\cdot \\frac{365 - n + 1}{365} \\leq \\frac{1}{2} o equivalentemente \\prod_{i=1}^{n-1} \\left( 1 - \\frac{i}{365} \\right) \\leq \\frac{1}{2} Questa equazione non ha una soluzione analitica semplice, ma può essere risolta numericamente.\n6. Soluzione Numerica\nCalcolando i valori di P(A) per diversi n, si trova che:\n\nPer n = 22, P(A) \\approx 0.476\nPer n = 23, P(A) \\approx 0.507\n\nQuindi, il numero minimo di persone necessarie affinché la probabilità che almeno due di loro condividano il compleanno sia maggiore del 50% è 23. Questo risultato è controintuitivo, da cui il nome “paradosso dei compleanni”.\n7. Successione Decrescente (Esercizio di Analisi 1)\nDefiniamo a_n come: a_n = \\prod_{i=1}^{n-1} \\left( 1 - \\frac{i}{365} \\right) a_n è una successione decrescente. Questo significa che man mano che n aumenta, il valore di a_n diminuisce. Quando a_n scende sotto \\frac{1}{2}, continua a diminuire. Questo permette di localizzare la soluzione usando un algoritmo di bisezione.\n\nProblema 8 Probabilità nelle mani di poker all’italiana\nImpostazione del problema probabilistico\nPer risolvere un esercizio di probabilità, è fondamentale definire l’ambientazione probabilistica in modo rigoroso. Questo include la definizione dello spazio campionario, della sigma-algebra e della funzione di probabilità.\nSpazio campionario (\\Omega)\n\n\n\\Omega è l’insieme di tutte le mani possibili nel poker.\n\n\nL’ordine delle carte in una mano non conta. Pertanto, si utilizzano le combinazioni.\n\n\nLa cardinalità di \\Omega è il numero di combinazioni di 5 carte scelte da un mazzo di 52 carte:\n|\\Omega| = \\binom{52}{5}.\n\n\nSigma-algebra (\\Sigma)\n\nSi utilizza la sigma-algebra delle parti discreta uniforme su \\Omega (la più logica da usare in questi casi ).\nQuesto significa che ogni sottoinsieme di \\Omega è misurabile.\n\nFunzione di probabilità (P)\n\n\nLa probabilità di un evento A è data da:\nP(A) = \\frac{|A|}{|\\Omega|}\ndove |A| è la cardinalità dell’insieme A.\n\n\nDefinizione delle carte\nOgni carta è identificata da due parametri:\n\nTipo: Il valore della carta (2-10, Jack, Queen, King, Ace). Ci sono 13 tipi possibili.\nSeme: Il seme della carta (Cuori, Quadri, Fiori, Picche). Ci sono 4 semi possibili.\n\nCalcolo della probabilità di diverse mani\nFull\n\nUn full è una mano composta da tre carte dello stesso tipo (tris) e due carte dello stesso tipo, diverso dal tris.\n\nScelta dei tipi per il tris e la coppia:\n\nCi sono 13 modi per scegliere il tipo per il tris e poi 12 per la coppia, perché deve essere diverso. Quindi 13 \\cdot 12. L’ordine è importante, quindi sono disposizioni semplici.\n\n\nScelta dei semi:\n\nCi sono \\binom{4}{3} modi per scegliere i semi per il tris.\nCi sono \\binom{4}{2} modi per scegliere i semi per la coppia.\n\n\nCalcolo della probabilità:\n\nP(\\text{Full}) = \\frac{13 \\cdot 12 \\cdot \\binom{4}{3} \\cdot \\binom{4}{2}}{\\binom{52}{5}} = \\frac{13 \\cdot 12 \\cdot 4 \\cdot 6}{2598960} = \\frac{3744}{2598960} \\approx 0.00144\nCi sono 3744 full distinti.\nDoppia coppia\n\nUna doppia coppia è una mano con due coppie di carte dello stesso tipo e una quinta carta di tipo diverso.\n\nScelta dei tipi per le coppie e la carta extra:\n\nCi sono \\binom{13}{2} modi per scegliere i tipi per le due coppie. L’ordine non è rilevante, quindi sono combinazioni.\nCi sono 11 modi per scegliere il tipo della quinta carta, perché deve essere diverso dai tipi delle coppie.\n\n\nScelta dei semi:\n\nCi sono \\binom{4}{2} modi per scegliere i semi per ogni coppia.\nCi sono 4 modi per scegliere il seme della quinta carta.\n\n\nCalcolo della probabilità:\n\nP(\\text{Doppia Coppia}) = \\frac{\\binom{13}{2} \\cdot 11 \\cdot \\binom{4}{2} \\cdot \\binom{4}{2} \\cdot 4}{\\binom{52}{5}} = \\frac{78 \\cdot 11 \\cdot 6 \\cdot 6 \\cdot 4}{2598960} = \\frac{123552}{2598960} \\approx 0.0475\nScala Reale Massima\n\nUna scala reale massima (scala reale) è una mano composta da 10, Jack, Queen, King e Asso dello stesso seme.\n\nScelta dei semi:\n\nCi sono 4 modi per scegliere il seme della scala reale.\n\n\nCalcolo della probabilità:\n\nP(\\text{Scala Reale}) = \\frac{4}{\\binom{52}{5}} = \\frac{4}{2598960} \\approx 0.00000154\nColore\n\nUn colore è composto da cinque carte dello stesso seme, ma non in sequenza.\n\n\nScelta del seme:\nCi sono 4 modi per scegliere il seme.\n\n\nScelta dei tipi:\nCi sono \\binom{13}{5} modi per scegliere 5 tipi diversi da quel seme.\n\n\nCalcolo della probabilità:\n\n\nP(\\text{Colore}) = \\frac{\\binom{13}{5} \\cdot 4}{\\binom{52}{5}} = \\frac{1287 \\cdot 4}{2598960} \\approx 0.00197\nReferences\nappunti Prob- ese02.pdf"},"6--full-note/Prob--Ese03":{"slug":"6--full-note/Prob--Ese03","filePath":"6- full note/Prob- Ese03.md","title":"Prob- Ese03","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità","2--source-materials/appunti--prob-ese3.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-11 13:26\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine probabilità\nProb- Ese03\nSpiegazione del Professore sui Problemi delle Urne\nIntroduzione ai Problemi delle Urne: Biglie Distinguibili e Indistinguibili\nEsercizio 1.\nUn’urna contiene 10 biglie, di cui 3 bianche, 5 rosse e 2 gialle. Estraendo 4 biglie dall’urna, quale è la probabilità di aver estratto esattamente 2 biglie bianche, 1 rossa e 1 gialla, al variare delle possibili modalità di estrazione (con o senza reimmissione e simultanea)?\nIl professore introduce la lezione parlando dello studio degli eventi e in particolare del concetto di probabilità condizionata. Tuttavia, decide di dedicare una parte della lezione al calcolo combinatorio attraverso esempi meno banali relativi a problemi con le urne, anticipando gli argomenti che saranno trattati nella prima prova parziale.\nViene ripreso un breve esercizio sulle urne accennato nella lezione precedente, focalizzandosi ora non solo sugli spazi campionari ma anche sul calcolo delle probabilità. Si considera un’urna contenente 10 biglie: tre bianche, cinque rosse e due gialle (inizialmente scritte come blu, ma poi corretto in bianco). L’obiettivo è calcolare la probabilità di estrarre quattro biglie dall’urna, ritrovandosi con due bianche, una rossa e una blu (corretto poi in gialla), al variare delle modalità di estrazione: senza reimmissione, con reimmissione e simultanea.\nIl professore sottolinea che nel caso di biglie indistinguibili, la situazione si complicherebbe. Per semplificare l’analisi iniziale, si assume che tutte le biglie siano distinguibili, anche quelle dello stesso colore (ad esempio, numerando le biglie rosse come R_1, R_2, R_3, R_4, R_5). Questo è un trucco efficace per poter ragionare inizialmente con spazi campionari in cui tutti gli esiti sono equiprobabili.\nEstrazione con Reimmissione\nDefinizione dello Spazio Campionario e Probabilità\nNel caso di estrazione con reimmissione, dopo ogni estrazione, la biglia viene rimessa nell’urna. L’esito di un esperimento aleatorio con quattro estrazioni con reimmissione è una quadrupla ordinata di elementi provenienti dall’insieme delle biglie (considerate distinguibili). Lo spazio campionario è quindi \\Omega = B^4, dove B è l’insieme delle 10 biglie distinguibili, e la sua cardinalità è |\\Omega| = 10^4.\nIl professore spiega che, a differenza di scenari più semplici, qui l’equiprobabilità dell’evento elementare non vale direttamente se consideriamo solo il colore. Ad esempio, è più probabile estrarre quattro biglie rosse che quattro biglie gialle perché ci sono più biglie rosse. Tuttavia, se consideriamo le biglie come distinguibili, ogni sequenza di quattro biglie specifiche ha la stessa probabilità di \\frac{1}{10} \\times \\frac{1}{10} \\times \\frac{1}{10} \\times \\frac{1}{10} = (\\frac{1}{10})^4.\nCalcolo della Probabilità: Due Bianche, Una Rossa e Una Gialla\nPer calcolare la probabilità di ottenere due biglie bianche, una rossa e una gialla, si procede in due passaggi:\n\n\nContare il numero di sequenze favorevoli: Si considerano le sequenze di quattro estrazioni che contengono due bianche (B), una rossa (R) e una gialla (G). Il numero di anagrammi della stringa “BBRG” è dato da: \\frac{4!}{2!1!1!} = \\frac{24}{2} = 12 Queste 12 sequenze rappresentano i diversi ordini in cui possono essere estratte le biglie dei colori desiderati (ad esempio, BBRG, BRBG, BRGB, RBBC, ecc.).\n\n\nContare il numero di modi di scegliere le biglie specifiche:\n\nCi sono 3 biglie bianche, quindi ci sono 3 \\times 3 = 9 modi di estrarre due biglie bianche (con reimmissione).\nCi sono 5 biglie rosse, quindi ci sono 5 modi di estrarre una biglia rossa.\nCi sono 2 biglie gialle, quindi ci sono 2 modi di estrarre una biglia gialla.\n\n\n\nIl numero totale di sequenze favorevoli considerando le biglie distinguibili è quindi 12 \\times 3 \\times 3 \\times 5 \\times 2 = 1080 (il professore nel trascritto indica un “3 quadro”, che si interpreta come 3 \\times 3).\nLa probabilità è data dal rapporto tra il numero di casi favorevoli e il numero di casi possibili: P(2B, 1R, 1G) = \\frac{1080}{10^4} = \\frac{1080}{10000} = \\frac{108}{1000} = \\frac{27}{250}.\nApproccio Alternativo con Probabilità Indipendenti\nIl professore presenta un modo più intuitivo di vedere il risultato, sfruttando l’indipendenza delle estrazioni con reimmissione. La probabilità di una specifica sequenza, ad esempio Bianco-Bianco-Rosso-Giallo, è: P(B_1) \\times P(B_2) \\times P(R_3) \\times P(G_4) = \\frac{3}{10} \\times \\frac{3}{10} \\times \\frac{5}{10} \\times \\frac{2}{10} Siccome ci sono 12 possibili ordini, la probabilità totale è: 12 \\times \\left( \\frac{3}{10} \\times \\frac{3}{10} \\times \\frac{5}{10} \\times \\frac{2}{10} \\right) = 12 \\times \\frac{90}{10000} = \\frac{1080}{10000} = \\frac{27}{250}.\nSi sottolinea che la probabilità di ogni permutazione della sequenza di colori (BBRG) è la stessa a causa dell’indipendenza e del fatto che stiamo moltiplicando le probabilità dei singoli colori ad ogni estrazione.\nEstrazione Senza Reimmissione\nDefinizione dello Spazio Campionario e Probabilità\nNel caso di estrazione senza reimmissione, le biglie estratte non vengono rimesse nell’urna, quindi la composizione dell’urna cambia ad ogni estrazione e le estrazioni non sono indipendenti. Se consideriamo le biglie distinguibili, lo spazio campionario \\Omega è l’insieme delle disposizioni semplici di 4 elementi scelti da un insieme di 10, e la sua cardinalità è: |\\Omega| = 10 \\times 9 \\times 8 \\times 7 = P(10, 4) = \\frac{10!}{(10-4)!} = \\frac{10!}{6!} = 5040. Ogni sequenza ordinata di 4 biglie distinte ha la stessa probabilità di \\frac{1}{10 \\times 9 \\times 8 \\times 7}.\nÈ importante notare che in questo caso non è possibile estrarre più biglie di un certo colore di quante ne siano presenti nell’urna (ad esempio, non si possono estrarre quattro biglie blu se ce ne sono solo due).\nCalcolo della Probabilità: Due Bianche, Una Rossa e Una Gialla\nPer calcolare la probabilità di ottenere due bianche, una rossa e una gialla, si contano le sequenze favorevoli considerando un ordine fissato (ad esempio, BBRG) e poi si moltiplica per il numero di permutazioni:\n\n\nNumero di modi per una sequenza specifica (ad esempio, BBRG):\n\nLa prima biglia bianca può essere scelta in 3 modi.\nLa seconda biglia bianca può essere scelta in 2 modi (rimanendo 2 nell’urna).\nLa biglia rossa può essere scelta in 5 modi.\nLa biglia gialla può essere scelta in 2 modi. Il numero di modi per una sequenza specifica è 3 \\times 2 \\times 5 \\times 2 = 60.\n\n\n\nNumero di ordini possibili: Come nel caso con reimmissione, ci sono 12 ordini possibili per i colori (anagrammi di BBRG).\n\n\nIl numero totale di sequenze favorevoli è 60 \\times 12 = 720.\nLa probabilità è quindi: P(2B, 1R, 1G) = \\frac{720}{5040} = \\frac{1}{7}.\nEstrazione Simultanea\nDefinizione dello Spazio Campionario e Probabilità\nL’estrazione simultanea di quattro biglie può essere pensata come un’estrazione senza reimmissione in cui l’ordine non conta. Lo spazio campionario \\Omega è l’insieme dei sottoinsiemi di 4 biglie scelte dalle 10, e la sua cardinalità è data dalla combinazione: |\\Omega| = \\binom{10}{4} = \\frac{10!}{4!(10-4)!} = \\frac{10 \\times 9 \\times 8 \\times 7}{4 \\times 3 \\times 2 \\times 1} = 10 \\times 3 \\times 7 = 210. Si assume che ogni sottoinsieme di 4 biglie abbia la stessa probabilità di essere estratto.\nCalcolo della Probabilità: Due Bianche, Una Rossa e Una Gialla\nPer ottenere due bianche, una rossa e una gialla simultaneamente, dobbiamo scegliere:\n\n2 biglie bianche dalle 3 disponibili: \\binom{3}{2} = \\frac{3!}{2!1!} = 3 modi.\n1 biglia rossa dalle 5 disponibili: \\binom{5}{1} = \\frac{5!}{1!4!} = 5 modi.\n1 biglia gialla dalle 2 disponibili: \\binom{2}{1} = \\frac{2!}{1!1!} = 2 modi.\n\nIl numero di sottoinsiemi favorevoli è \\binom{3}{2} \\times \\binom{5}{1} \\times \\binom{2}{1} = 3 \\times 5 \\times 2 = 30.\nLa probabilità è quindi: P(2B, 1R, 1G) = \\frac{30}{210} = \\frac{1}{7}.\nIl professore sottolinea che, come previsto intuitivamente, la probabilità ottenuta con l’estrazione simultanea è la stessa di quella ottenuta con l’estrazione senza reimmissione, evidenziando la coerenza del modello.\n\nGeneralizzazione del Problema delle Urne\nCaso con Reimmissione\nIl professore introduce la generalizzazione del problema delle urne considerando un’urna contenente un numero intero N di biglie, suddivise in R biglie rosse e B biglie bianche, dove N = R + B. Si estrae un numero intero n di biglie dall’urna, con reimmissione. Si vuole determinare la probabilità dell’evento E_{k,n}, cioè di estrarre esattamente k biglie rosse su n estrazioni.\nIl professore procede fissando un ordine di estrazione, supponendo di estrarre prima tutte le k biglie rosse e poi le n-k biglie bianche. La probabilità di estrarre una biglia rossa in una singola estrazione è \\frac{R}{N}, e la probabilità di estrarre una biglia bianca è \\frac{B}{N}. Dato che le estrazioni sono con reimmissione, gli eventi sono indipendenti.\nLa probabilità di ottenere la sequenza specifica di k rosse seguite da n-k bianche è: P(\\underbrace{R, R, ..., R}_{k \\text{ volte}}, \\underbrace{B, B, ..., B}_{n-k \\text{ volte}}) = \\left(\\frac{R}{N}\\right)^k \\left(\\frac{B}{N}\\right)^{n-k} Tuttavia, l’ordine in cui vengono estratte le k biglie rosse e le n-k biglie bianche non è specificato. Il numero di sequenze possibili con k biglie rosse e n-k biglie bianche è dato dal coefficiente binomiale \\binom{n}{k} = \\frac{n!}{k!(n-k)!}, che rappresenta il numero di anagrammi di una stringa con k “R” e n-k “B”.\nPertanto, la probabilità di estrarre esattamente k biglie rosse in n estrazioni con reimmissione è data dalla distribuzione binomiale: P(E_{k,n}) = P(K=k) = \\binom{n}{k} \\left(\\frac{R}{N}\\right)^k \\left(\\frac{B}{N}\\right)^{n-k} dove K è la variabile aleatoria che rappresenta il numero di biglie rosse estratte in n prove.\nCaso senza Reimmissione\nNel caso senza reimmissione, l’estrazione di una biglia modifica la composizione dell’urna per le estrazioni successive, rendendo gli eventi dipendenti. Si vuole ancora calcolare la probabilità di estrarre esattamente k biglie rosse in n estrazioni.\nIl professore considera lo spazio campionario \\Omega come l’insieme delle disposizioni di n biglie distinte scelte tra le N biglie distinguibili, la cui cardinalità è P(N, n) = \\frac{N!}{(N-n)!} = N \\times (N-1) \\times ... \\times (N-n+1). Ogni disposizione ha la stessa probabilità di verificarsi, che decresce ad ogni estrazione.\nPer contare il numero di esiti favorevoli (esattamente k rosse e n-k bianche in un ordine specifico), si scelgono k posizioni per le biglie rosse e n-k posizioni per le biglie bianche. Il numero di modi di scegliere k biglie rosse dalle R disponibili in un certo ordine è P(R, k) = \\frac{R!}{(R-k)!}, e il numero di modi di scegliere n-k biglie bianche dalle B disponibili in un certo ordine è P(B, n-k) = \\frac{B!}{(B-(n-k))!} = \\frac{B!}{(B-n+k)!}.\nIl numero totale di sequenze con k rosse e n-k bianche (senza considerare l’ordine dei colori) è \\binom{n}{k}. Quindi, il numero di esiti favorevoli è \\binom{n}{k} \\times P(R, k) \\times P(B, n-k) = \\frac{n!}{k!(n-k)!} \\times \\frac{R!}{(R-k)!} \\times \\frac{B!}{(B-n+k)!}.\nLa probabilità di estrarre esattamente k biglie rosse in n estrazioni senza reimmissione è data dalla distribuzione ipergeometrica: P(E_{k,n}) = \\frac{\\binom{R}{k} \\binom{B}{n-k}}{\\binom{N}{n}} Come sottolineato dal professore e corretto dagli studenti, questa formula può essere derivata considerando lo spazio campionario come l’insieme di tutti i possibili sottoinsiemi di n biglie scelte dalle N, la cui cardinalità è \\binom{N}{n} = \\frac{N!}{n!(N-n)!}. Il numero di modi di scegliere k biglie rosse dalle R è \\binom{R}{k} = \\frac{R!}{k!(R-k)!}, e il numero di modi di scegliere n-k biglie bianche dalle B è \\binom{B}{n-k} = \\frac{B!}{(n-k)!(B-n+k)!}. Il rapporto tra il numero di casi favorevoli e il numero di casi possibili fornisce la probabilità ipergeometrica.\nCaso di Estrazione Simultanea\nIl professore spiega che l’estrazione simultanea di n biglie può essere vista come un’estrazione senza reimmissione in cui l’ordine non conta. Dal punto di vista probabilistico, il risultato è equiprobabile al caso senza reimmissione.\nLo spazio campionario \\Omega è l’insieme dei sottoinsiemi di n biglie scelte dalle N, con cardinalità \\binom{N}{n}. Per ottenere esattamente k biglie rosse e n-k biglie bianche, dobbiamo scegliere k biglie rosse dalle R disponibili in \\binom{R}{k} modi e n-k biglie bianche dalle B disponibili in \\binom{B}{n-k} modi.\nLa probabilità di ottenere esattamente k biglie rosse (e quindi n-k bianche) in un’estrazione simultanea di n biglie è quindi la stessa della distribuzione ipergeometrica: P(E_{k,n}) = \\frac{\\binom{R}{k} \\binom{B}{n-k}}{\\binom{N}{n}}\nEsercizio: Servizio da Caffè di Nonna Papera\nIl problema riguarda un servizio da caffè per sei persone composto da sei piattini e sei tazzine, con due set (tazzina e piattino) di colore arancione, due gialle e due rosse. Ciccio preleva alcuni set abbinati e poi dispone le tazzine a caso sui piattini a caso.\nParte 1: Probabilità di scegliere due set tazzina-piattino dello stesso colore\n==Ciccio sceglie due set tazzina-piattino. Ci si chiede la probabilità che questi due set siano dello stesso colore. Si può pensare a questo come un’estrazione simultanea di due set dagli sei disponibili. Ci sono in totale \\binom{6}{2} = \\frac{6 \\times 5}{2} = 15 possibili coppie di set.==\n==Ci sono tre colori, e per ogni colore ci sono due set abbinati. Il numero di modi di scegliere due set arancioni è \\binom{2}{2} = 1. Lo stesso vale per i set gialli (\\binom{2}{2} = 1) e rossi (\\binom{2}{2} = 1). Quindi ci sono 1 + 1 + 1 = 3 modi di scegliere due set dello stesso colore.==\n==La probabilità di scegliere due set dello stesso colore è quindi: P(\\text{due set dello stesso colore}) = \\frac{\\text{numero di coppie dello stesso colore}}{\\text{numero totale di coppie}} = \\frac{3}{15} = \\frac{1}{5} Il professore arriva allo stesso risultato.==\nParte 2: Probabilità che due set scelti a caso siano ancora abbinati dopo la disposizione casuale delle tazzine\nCiccio estrae due set (che possono essere dello stesso colore o di colori diversi) e poi dispone le sei tazzine a caso sui sei piattini. Si vuole calcolare la probabilità che, scegliendo a caso due set dopo questa operazione, questi siano ancora abbinati.\n==Il professore suggerisce di semplificare il problema considerando i piattini già disposti e permutando solo le tazzine. Il numero totale di possibili disposizioni delle sei tazzine sui sei piattini, considerando le due tazzine di ogni colore indistinguibili, è \\frac{6!}{2!2!2!} = \\frac{720}{8} = 90.==\n==Solo una di queste 90 disposizioni corrisponde al caso in cui tutte le tazzine sono abbinate ai rispettivi piattini per colore. Quindi, la probabilità che i sei set siano abbinati dopo la disposizione casuale è \\frac{1}{90}.==\n==Tuttavia, la domanda si concentra sulla probabilità che due set scelti a caso siano ancora abbinati. Il professore introduce informalmente l’idea di utilizzare il teorema della probabilità totale. Sia A l’evento che i due set scelti a caso dopo la ridistribuzione siano abbinati, e siano U l’evento che i due set estratti inizialmente siano dello stesso colore, e D l’evento che siano di colori diversi. Sappiamo che P(U) = 1/5 e P(D) = 1 - 1/5 = 4/5.==\n==Se i due set estratti inizialmente erano dello stesso colore, dopo la ridistribuzione casuale, la probabilità che quei due specifici set siano ancora abbinati è 1.==\n==Se i due set estratti inizialmente erano di colori diversi, consideriamo una coppia specifica di tazzina e piattino di colori diversi. Dopo la permutazione casuale delle tazzine, la probabilità che questa specifica tazzina finisca sul suo piattino abbinato è 1/6. Pertanto, la probabilità che una specifica coppia di set di colori diversi rimanga abbinata è 1/6.==\n==Tuttavia, il professore semplifica ulteriormente il ragionamento considerando solo la scelta casuale delle tazzine sui piattini fissi. Se scegliamo due set a caso dopo la ridistribuzione casuale, la probabilità che siano abbinati dipende dalla probabilità che le tazzine corrispondenti siano state posizionate sui loro piattini.==\n==Considerando la semplificazione del professore dove solo le tazzine vengono permutate, la probabilità che tutti i set siano abbinati è \\frac{1}{90}. Per la probabilità che due specifici set scelti a caso siano abbinati, il ragionamento diventa più complesso e il professore rimanda a un approccio con la probabilità condizionata per la lezione successiva. Il punto chiave sottolineato è la possibilità di semplificare il problema considerando solo la permutazione delle tazzine sui piattini fissi senza perdita di generalità.==\n\nEsercizio Tratto da un Tema d’Esame (Due Anni Fa)\nDescrizione del Problema\nL’esercizio riguarda un servizio da caffè per sei persone composto da sei piattini e sei tazzine. I sei set abbinati (tazzina e piattino dello stesso colore) sono di tre colori differenti: due arancioni, due gialle e due rosse. Inizialmente, le tazzine sono abbinate ai piattini dello stesso colore. Ciccio preleva alcuni set abbinati dalla credenza e poi dispone le tazzine a caso sui piattini a caso.\nParte 1: Probabilità di Scegliere Due Set Tazzina-Piattino dello Stesso Colore\nSi chiede la probabilità che, scegliendo due set tazzina-piattino, questi siano dello stesso colore. Il professore propone di ragionare in termini di estrazione simultanea di due set dagli sei disponibili.\n\n\nSpazio Campionario: Il numero totale di modi di scegliere 2 set da 6 è dato dalla combinazione di 6 elementi presi 2 alla volta: \\binom{6}{2} = \\frac{6!}{2!(6-2)!} = \\frac{6 \\times 5}{2 \\times 1} = 15 Quindi, ci sono 15 possibili coppie di set.\n\n\nEventi Favorevoli: Ci sono tre colori, e per ogni colore ci sono due set abbinati. Per scegliere due set dello stesso colore, dobbiamo scegliere entrambi i set di quel colore.\n\nNumero di modi di scegliere 2 set arancioni: \\binom{2}{2} = 1\nNumero di modi di scegliere 2 set gialli: \\binom{2}{2} = 1\nNumero di modi di scegliere 2 set rossi: \\binom{2}{2} = 1 Il numero totale di modi di scegliere due set dello stesso colore è 1 + 1 + 1 = 3.\n\n\n\nProbabilità: La probabilità di scegliere due set dello stesso colore è il rapporto tra il numero di casi favorevoli e il numero di casi possibili: P(\\text{due set dello stesso colore}) = \\frac{3}{15} = \\frac{1}{5} Il professore conclude questa parte con il risultato \\frac{3}{15}.\n\n\nParte 2: Probabilità che i Set Scelti Siano Ancora Abbinati Dopo la Disposizione Casuale delle Tazzine\nCiccio prende tutti i sei set dalla credenza (questa parte è una precisazione successiva del professore rispetto a “alcuni set” menzionato inizialmente) e poi dispone le sei tazzine a caso sui sei piattini in modo equiprobabile. Si chiede la probabilità che, scegliendo due set a caso dopo questa operazione, questi siano ancora abbinati.\nIl professore introduce un’idea per semplificare il problema: assumere che i piattini siano già disposti e considerare solo le permutazioni delle tazzine. Questa assunzione non comporta perdita di generalità se si è coerenti nel conteggio delle configurazioni favorevoli.\n\n\nSpazio Campionario Semplificato (Permutazioni delle Tazzine): Considerando i piattini fissi, il numero totale di modi di disporre le sei tazzine sui sei piattini è dato dalle permutazioni di 6 oggetti, tenendo conto che ci sono due tazzine di ogni colore che consideriamo indistinguibili ai fini del calcolo delle configurazioni distinte: \\frac{6!}{2!2!2!} = \\frac{720}{2 \\times 2 \\times 2} = \\frac{720}{8} = 90 Quindi, ci sono 90 possibili configurazioni delle tazzine sui piattini.\n\n\nEvento Favorevole (Tutti i Colori Abbinati): La configurazione in cui tutti i colori sono abbinati è una sola: ogni piattino ha la tazzina del suo stesso colore. Se avessimo considerato le tazzine distinguibili, ci sarebbero state 6! permutazioni totali e 2! \\times 2! \\times 2! modi di abbinare correttamente i colori, portando a una probabilità di \\frac{8}{720} = \\frac{1}{90}, lo stesso risultato.\n\n\nProbabilità che i Sei Set Siano Abbinati: La probabilità che tutti e sei i set siano abbinati dopo la disposizione casuale delle tazzine è: P(\\text{tutti abbinati}) = \\frac{1}{90}\n\n\nProbabilità che Due Set Scelti a Caso Siano Ancora Abbinati: Questa parte è più complessa e il professore introduce informalmente l’idea di usare il teorema della probabilità totale, condizionando sul fatto che i due set estratti inizialmente fossero dello stesso colore o di colori diversi.\n\nSia A l’evento che i due set scelti a caso dopo la ridistribuzione siano abbinati.\nSia U l’evento che i due set estratti inizialmente fossero dello stesso colore, con P(U) = 1/5 (calcolato nella Parte 1).\nSia D l’evento che i due set estratti inizialmente fossero di colori diversi, con P(D) = 1 - P(U) = 1 - 1/5 = 4/5.\n\nIl professore afferma che:\n\n\nSe i due set estratti inizialmente erano dello stesso colore (U), la probabilità che dopo la ridistribuzione casuale quei due specifici set siano ancora abbinati è 1. Questo perché le tazzine sono semplicemente state rimescolate, ma i due set che inizialmente formavano una coppia colorata rimangono individualmente come una tazzina e un piattino di quel colore.\n\n\nSe i due set estratti inizialmente erano di colori diversi (D), la probabilità che una specifica coppia di tazzina e piattino di colori diversi formi un set abbinato dopo la permutazione casuale delle tazzine è intuitivamente \\frac{1}{6}.\n\n\nIl professore imposta la probabilità richiesta usando il teorema della probabilità totale: P(A) = P(A|U)P(U) + P(A|D)P(D) Dove:\n\nP(A|U) = 1 (se i due set iniziali erano dello stesso colore, rimangono abbinati come tali).\nP(U) = 1/5.\nP(D) = 4/5.\nP(A|D) è la probabilità che due set scelti a caso (che inizialmente erano di colori diversi) siano abbinati dopo la permutazione casuale. Il professore indica che questa probabilità è \\frac{1}{5} (implicitamente nel prosieguo del suo ragionamento: P(A) = 1 \\times \\frac{1}{5} + \\frac{1}{5} \\times \\frac{4}{5}). Tuttavia, la giustificazione esatta di questo valore (\\frac{1}{5} per P(A|D)) non viene fornita in dettaglio in questo estratto e il professore rimanda a una spiegazione più formale con la probabilità condizionata nella lezione successiva.\n\nIl professore conclude, fornendo il risultato finale: P(A) = 1 \\times \\frac{1}{5} + \\frac{1}{5} \\times \\frac{4}{5} = \\frac{1}{5} + \\frac{4}{25} = \\frac{5 + 4}{25} = \\frac{9}{25} Questo risultato si basa sull’affermazione (non completamente giustificata in questo estratto) che la probabilità che due set scelti a caso siano abbinati, dato che inizialmente erano di colori diversi, sia \\frac{1}{5}.\nIl professore sottolinea che la furbizia di aver fissato i piattini all’inizio semplifica il problema senza alterare la probabilità finale.\n\n\n\nEsercizio sull’Indipendenza di Eventi\nIl professore ha trattato l’indipendenza di eventi, iniziando dalla definizione per due eventi e poi estendendola a famiglie di eventi, con un focus particolare su un esempio con il lancio di dadi e sulla distinzione tra indipendenza a coppie e indipendenza mutua.\nIndipendenza tra Due Eventi\nRicordiamo che due eventi A e B, definiti su uno spazio di probabilità (\\Omega, \\mathcal{F}, P), sono indipendenti se e solo se la probabilità della loro intersezione è uguale al prodotto delle loro probabilità: P(A \\cap B) = P(A) P(B)\nEsempio con Tre Eventi (Lancio di Due Dadi)\nPer illustrare il concetto di indipendenza per più di due eventi e la differenza tra indipendenza a coppie e indipendenza mutua, il professore ha considerato l’esperimento del lancio di un dado equo per due volte.\nSpazio Campionario: Lo spazio campionario \\Omega è l’insieme di tutte le possibili coppie di risultati dei due lanci: \\Omega = {(i, j) \\mid i, j \\in {1, 2, 3, 4, 5, 6}} La sigma-algebra considerata è \\mathcal{P}(\\Omega), l’insieme di tutti i sottoinsiemi di \\Omega. Poiché il dado è equo, ogni esito elementare (i, j) ha probabilità P({(i, j)}) = \\frac{1}{36}.\nDefinizione degli Eventi: Sono stati definiti i seguenti tre eventi:\n\nA: “Numero dispari sul primo lancio”. Questo evento include gli esiti {(1, j), (3, j), (5, j) \\mid j \\in {1, 2, 3, 4, 5, 6}}.\nB: “Numero dispari sul secondo lancio”. Questo evento include gli esiti {(i, 1), (i, 3), (i, 5) \\mid i \\in {1, 2, 3, 4, 5, 6}}.\nC: “La somma dei risultati è dispari”. Questo evento include le coppie (i, j) dove uno tra i e j è pari e l’altro è dispari.\n\nCalcolo delle Probabilità dei Singoli Eventi:\n\nP(A) = P(\\text{primo lancio è 1, 3 o 5}) = \\frac{3 \\times 6}{36} = \\frac{18}{36} = \\frac{1}{2}.\nP(B) = P(\\text{secondo lancio è 1, 3 o 5}) = \\frac{6 \\times 3}{36} = \\frac{18}{36} = \\frac{1}{2}.\nP(C) = P(\\text{un lancio è pari e l&#039;altro è dispari}) = P(\\text{primo dispari, secondo pari}) + P(\\text{primo pari, secondo dispari}) = \\frac{3 \\times 3}{36} + \\frac{3 \\times 3}{36} = \\frac{9}{36} + \\frac{9}{36} = \\frac{18}{36} = \\frac{1}{2}.\n\nVerifica dell’Indipendenza a Coppie: Ora verifichiamo se ogni coppia di eventi è indipendente.\n\n\nIndipendenza di A e B: A \\cap B è l’evento “numero dispari sul primo lancio E numero dispari sul secondo lancio”. Gli esiti sono {(1, 1), (1, 3), (1, 5), (3, 1), (3, 3), (3, 5), (5, 1), (5, 3), (5, 5)}, quindi |A \\cap B| = 9. P(A \\cap B) = \\frac{9}{36} = \\frac{1}{4}. P(A) P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}. Poiché P(A \\cap B) = P(A) P(B), gli eventi A e B sono indipendenti.\n\n\nIndipendenza di A e C: A \\cap C è l’evento “numero dispari sul primo lancio E la somma è dispari”. Se il primo lancio è dispari, affinché la somma sia dispari, il secondo lancio deve essere pari. Gli esiti sono {(1, 2), (1, 4), (1, 6), (3, 2), (3, 4), (3, 6), (5, 2), (5, 4), (5, 6)}, quindi |A \\cap C| = 9. P(A \\cap C) = \\frac{9}{36} = \\frac{1}{4}. P(A) P(C) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}. Poiché P(A \\cap C) = P(A) P(C), gli eventi A e C sono indipendenti.\nIl professore ha anche introdotto brevemente la probabilità condizionata per spiegare questo punto: P(C|A) = P(\\text{somma dispari} | \\text{primo lancio dispari}) = P(\\text{secondo lancio pari}) = \\frac{1}{2}. Quindi, P(A \\cap C) = P(C|A) P(A) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}.\n\n\nIndipendenza di B e C: B \\cap C è l’evento “numero dispari sul secondo lancio E la somma è dispari”. Se il secondo lancio è dispari, affinché la somma sia dispari, il primo lancio deve essere pari. Gli esiti sono {(2, 1), (4, 1), (6, 1), (2, 3), (4, 3), (6, 3), (2, 5), (4, 5), (6, 5)}, quindi |B \\cap C| = 9. P(B \\cap C) = \\frac{9}{36} = \\frac{1}{4}. P(B) P(C) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}. Poiché P(B \\cap C) = P(B) P(C), gli eventi B e C sono indipendenti.\nSimilmente, usando la probabilità condizionata: P(C|B) = P(\\text{somma dispari} | \\text{secondo lancio dispari}) = P(\\text{primo lancio pari}) = \\frac{1}{2}. Quindi, P(B \\cap C) = P(C|B) P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}.\n\n\nVerifica dell’Indipendenza Mutua (della Famiglia di Eventi {A, B, C}): Perché la famiglia di eventi {A, B, C} sia indipendente, deve valere che P(A \\cap B \\cap C) = P(A) P(B) P(C).\nA \\cap B \\cap C è l’evento “numero dispari sul primo lancio E numero dispari sul secondo lancio E la somma è dispari”. Se il primo lancio è dispari e il secondo lancio è dispari, la loro somma è necessariamente pari. Pertanto, l’evento A \\cap B \\cap C è l’insieme vuoto, e la sua probabilità è: P(A \\cap B \\cap C) = P(\\emptyset) = 0.\nD’altra parte, il prodotto delle probabilità dei singoli eventi è: P(A) P(B) P(C) = \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{8}.\nPoiché P(A \\cap B \\cap C) = 0 \\neq \\frac{1}{8} = P(A) P(B) P(C), la famiglia di eventi {A, B, C} non è una famiglia indipendente, nonostante gli eventi siano indipendenti a coppie.\nDefinizione Generale di Indipendenza per una Famiglia di Eventi\n==Sia (\\Omega, \\mathcal{F}, P) uno spazio di probabilità e {E_i}_{i \\in I} una famiglia di eventi in \\mathcal{F}, indicizzata da un insieme I (finito o infinito). La famiglia {E_i}_{i \\in I} è detta indipendente se per ogni sottoinsieme finito J \\subseteq I, si ha: P\\left(\\bigcap_{i \\in J} E_i\\right) = \\prod_{i \\in J} P(E_i)==\nIndipendenza a Coppie vs. Indipendenza Mutua per Famiglie Finite\n==L’esempio precedente dimostra che per una famiglia di tre eventi, l’indipendenza a coppie non implica l’indipendenza della famiglia. Il professore ha sottolineato che se una famiglia di eventi è indipendente, allora ogni sua sottofamiglia (in particolare ogni coppia di eventi) è indipendente. Tuttavia, la proposizione inversa non è sempre vera, come mostrato dall’esempio dei lanci di dado.==\nIndipendenza per Famiglie Infinite (o Numerabili)\n==Il professore ha poi posto la domanda se, data una famiglia infinita di eventi {E_i}_{i \\in I}, l’indipendenza a coppie implichi l’indipendenza dell’intera famiglia. Ha affermato che questo è falso per una famiglia infinita.==\n==Successivamente, ha considerato il caso di una famiglia numerabile di eventi {E_i}_{i \\in \\mathbb{N}} e ha chiesto se la condizione che ogni sottofamiglia finita sia indipendente implichi che l’intera famiglia sia indipendente, ovvero se valga: P\\left(\\bigcap_{i=1}^{\\infty} E_i\\right) = \\prod_{i=1}^{\\infty} P(E_i)==\n==Il professore ha spiegato che la risposta è affermativa e che questo risultato si basa su una proprietà fondamentale delle misure di probabilità: la continuità lungo successioni monotone di eventi.==\n==Dimostrazione Intuïtiva: Consideriamo le intersezioni parziali: F_n = \\bigcap_{i=1}^{n} E_i Poiché ogni sottofamiglia finita è indipendente, sappiamo che P(F_n) = P\\left(\\bigcap_{i=1}^{n} E_i\\right) = \\prod_{i=1}^{n} P(E_i).==\n==La successione di eventi (F_n)_{n \\in \\mathbb{N}} è una successione decrescente (in quanto F_{n+1} = F_n \\cap E_{n+1} \\subseteq F_n), e la sua intersezione è \\bigcap_{n=1}^{\\infty} F_n = \\bigcap_{i=1}^{\\infty} E_i.==\n==Per la proprietà di continuità delle misure di probabilità per successioni decrescenti di eventi, si ha: P\\left(\\bigcap_{n=1}^{\\infty} F_n\\right) = \\lim_{n \\to \\infty} P(F_n)==\n==Sostituendo le espressioni trovate: P\\left(\\bigcap_{i=1}^{\\infty} E_i\\right) = \\lim_{n \\to \\infty} \\left(\\prod_{i=1}^{n} P(E_i)\\right) = \\prod_{i=1}^{\\infty} P(E_i)==\nQuesto dimostra che se ogni sottofamiglia finita di una famiglia numerabile di eventi è indipendente, allora l&#039;intera famiglia è indipendente. Il professore ha concluso sottolineando l&#039;importanza di questa proprietà per la verifica dell&#039;indipendenza in casi numerabili, in quanto riduce il problema al controllo dell&#039;indipendenza di sottoinsiemi finiti, che è spesso più gestibile.\n==Generalizzazione a un Insieme Numerabile di Indici \\Sigma:==\n==Se l’insieme di indici non è necessariamente {1, 2, ...}, ma un generico insieme numerabile \\Sigma, è possibile stabilire una biiezione con \\mathbb{N}. L’argomentazione basata sulle intersezioni parziali lungo questa biiezione rimane valida, sfruttando sempre la continuità della misura di probabilità. Tuttavia, è cruciale che la proprietà di indipendenza valga per ogni sottoinsieme finito di \\Sigma.==\n\nDiscussione Generale sull’Indipendenza di Famiglie di Eventi\nIl professore ha introdotto una discussione generale sulla nozione di indipendenza estesa a famiglie di eventi, ponendo l’accento sulla relazione tra indipendenza a coppie e indipendenza mutua, specialmente nel contesto di famiglie finite e infinite (o numerabili).\nIndipendenza a Coppie vs. Indipendenza Mutua per Famiglie Finite\nIl professore ha ripreso l’esempio del lancio di due dadi e dei tre eventi A, B, e C. Come precedentemente dimostrato, questi tre eventi sono indipendenti a coppie:\n\nP(A \\cap B) = P(A) P(B) = \\frac{1}{4}\nP(A \\cap C) = P(A) P(C) = \\frac{1}{4}\nP(B \\cap C) = P(B) P(C) = \\frac{1}{4}\n\nTuttavia, la famiglia {A, B, C} non è indipendente poiché P(A \\cap B \\cap C) = 0 \\neq P(A) P(B) P(C) = \\frac{1}{8}. Da questo esempio, il professore ha concluso che per una famiglia finita di tre (o più) eventi, l’indipendenza a coppie non implica necessariamente l’indipendenza mutua (della famiglia).\nIl professore ha poi posto una domanda generale: “È vero che se degli eventi sono indipendenti a coppie, allora la famiglia è indipendente?“. La risposta fornita è che per una famiglia finita, questo è falso, come dimostrato dall’esempio precedente.\nDefinizione Formale di Indipendenza per una Famiglia di Eventi\nIl professore ha quindi fornito la definizione formale di indipendenza per una famiglia di eventi {E_i}_{i \\in I}, dove I è un insieme di indici (finito o numerabile):\nUna famiglia di eventi {E_i}_{i \\in I} è detta indipendente se per ogni sottoinsieme finito J \\subseteq I, si ha: \\qquad P\\left(\\bigcap_{i \\in J} E_i\\right) = \\prod_{i \\in J} P(E_i)\nQuesta definizione richiede che la probabilità dell’intersezione di un numero qualsiasi finito di eventi della famiglia sia uguale al prodotto delle probabilità di questi eventi presi singolarmente.\nIndipendenza per Famiglie Infinite (o Numerabili)\nIl professore ha successivamente considerato il caso in cui la famiglia di eventi è infinita o numerabile. Ha affermato che se una famiglia è indipendente, allora ogni sua sottofamiglia finita è indipendente, il che segue direttamente dalla definizione.\nLa domanda cruciale posta è stata se la condizione di indipendenza per ogni sottofamiglia finita sia sufficiente per garantire l’indipendenza dell’intera famiglia (anche numerabile), nel senso che P\\left(\\bigcap_{i=1}^{\\infty} E_i\\right) = \\prod_{i=1}^{\\infty} P(E_i).\nLa risposta fornita dal professore è che sì, questa proprietà è vera. La giustificazione si basa sulla continuità delle misure di probabilità rispetto a successioni monotone di eventi.\nSpiegazione Dettagliata per una Famiglia Numerabile:\nConsideriamo una famiglia numerabile di eventi {E_i}_{i \\in \\mathbb{N}}. Supponiamo che ogni sottofamiglia finita sia indipendente. Definiamo la successione di eventi (F_n)_{n \\in \\mathbb{N}} come le intersezioni parziali: F_n = \\bigcap_{i=1}^{n} E_i\nPoiché ogni sottofamiglia finita è indipendente, abbiamo: P(F_n) = P\\left(\\bigcap_{i=1}^{n} E_i\\right) = \\prod_{i=1}^{n} P(E_i)\nLa successione (F_n)_{n \\in \\mathbb{N}} è decrescente, cioè F_{n+1} = F_n \\cap E_{n+1} \\subseteq F_n. L’intersezione di tutti gli eventi della famiglia è: \\bigcap_{i=1}^{\\infty} E_i = \\bigcap_{n=1}^{\\infty} F_n\nPer la continuità delle misure di probabilità per successioni decrescenti di eventi, si ha: P\\left(\\bigcap_{n=1}^{\\infty} F_n\\right) = \\lim_{n \\to \\infty} P(F_n)\nSostituendo l’espressione per P(F_n): P\\left(\\bigcap_{i=1}^{\\infty} E_i\\right) = \\lim_{n \\to \\infty} \\left(\\prod_{i=1}^{n} P(E_i)\\right) = \\prod_{i=1}^{\\infty} P(E_i)\nQuesto dimostra che per una famiglia numerabile di eventi, se ogni sottofamiglia finita è indipendente, allora l’intera famiglia è indipendente. Il professore ha sottolineato che questa è una proprietà sorprendente e molto utile per la verifica dell’indipendenza in casi numerabili, in quanto permette di concentrarsi sulle sottofamiglie finite.\nEstensione a un Insieme Numerabile di Indici:\nSe l’insieme di indici è un generico insieme numerabile \\Sigma, si può stabilire una biiezione con \\mathbb{N}. L’argomentazione basata sulla continuità della probabilità applicata alle intersezioni parziali ordinate secondo questa biiezione rimane valida. È fondamentale che l’indipendenza valga per ogni possibile sottoinsieme finito di \\Sigma.\nReferences\nappunti- prob ese3.pdf"},"6--full-note/Prob--Lez01'":{"slug":"6--full-note/Prob--Lez01'","filePath":"6- full note/Prob- Lez01'.md","title":"Prob- Lez01'","links":["tags/revisione_finita","tags/riscritto_finito","tags/flashcard_finite","3--tag/sbobine","3--tag/probabilità"],"tags":["revisione_finita","riscritto_finito","flashcard_finite"],"content":"2025-02-18 13:22\nStatus: revisione_finita   riscritto_finito  flashcard_finite\nTags: sbobine probabilità\nlez01’- Prob\nIntroduzione alla Probabilità e Teoria della Misura\nIl professore introduce il concetto di probabilità, sottolineando come essa si applichi a fenomeni non descrivibili con leggi deterministiche. La probabilità, in sostanza, misura l’incertezza. L’approccio matematico moderno alla probabilità si basa sulla teoria della misura.\nConcetti Chiave: Algebre, Misure, Misure di Probabilità (o probabilità)\nGli argomenti principali della lezione sono algebre, σ-algebre, misure e misure di probabilità. È importante, secondo il professore, fare tabula rasa delle concezioni elementari di probabilità per poter ricostruire i concetti in modo più rigoroso. L’astrazione è necessaria per inglobare sia il discreto che il continuo in un unico linguaggio matematico.\nMisura: Definizione Intuitiva\nIntuitivamente, una misura associa un valore a un insieme. Questo valore può rappresentare un’area, una lunghezza, un peso o un’incertezza.\n\nProprietà Fondamentale\nSe si misurano due insiemi disgiunti A₁ e A₂ separatamente, la somma delle loro misure deve essere uguale alla misura della loro unione:\nμ(A₁ ∪ A₂) = μ(A₁) + μ(A₂) se A₁ ∩ A₂ = ∅\nSpazio Campionario (Ω)\n\n\nΩ (Omega): Spazio Campionario (o Spazio degli Esiti):\n\nL’insieme di tutti i possibili risultati di un esperimento casuale.\nInsieme astratto, senza struttura particolare.\nPuò essere finito, infinito numerabile, o continuo.\nSpesso non è esplicitamente definito, ma esiste implicitamente. \n\n\n\n**ω (omega minuscola):\n\nEsito Elementare**: Un singolo elemento di Ω, un punto, una particolare realizzazione dell’esperimento.( Parametrizzazione del caso).\n\n\n\nEventi A: Sottoinsiemi di Ω  A⊂Ω.\n\nCollezione di esiti elementari che soddisfano una condizione.\n\n\n\nEvento Certo: L’insieme Ω stesso.\n\n\nEsempi di Spazi Campionari:\n\nInsieme finito di punti: Ω = {1, 2, 3, …, 10}\nNumeri naturali non negativi: Ω = {0, 1, 2, …}\nNumeri reali: Ω = ℝ\nSpazio euclideo: Ω = ℝᵈ (vettori con componenti reali)\nSuccessioni: Ω = {x = (x₁, x₂, …): xᵢ ∈ {1, 2, …, m}}\n\nSottoinsiemi e Operazioni Insiemistiche\nI sottoinsiemi di Ω rappresentano eventi. È fondamentale non confondere un punto (ω ∈ Ω) con un sottoinsieme.\nOperazioni Fondamentali:\n\nComplementare: Aᶜ = {ω ∈ Ω: ω ∉ A} (tutti gli elementi di Ω che non appartengono ad A).\n\nÈ essenziale specificare l’insieme universo (Ω) quando si considera il complementare.\n\n\n\nAlgebre di Insiemi\nUna classe (o famiglia) di sottoinsiemi di Ω \\mathcal{A} si dice algebra se soddisfa le seguenti proprietà:\n\nΩ ∈ \\mathcal{A} (l’insieme totale appartiene all’algebra).\nSe A ∈ \\mathcal{A}, allora Aᶜ ∈ \\mathcal{A} (se un insieme appartiene all’algebra, anche il suo complementare appartiene all’algebra).\nSe A₁, A₂ ∈ \\mathcal{A}, allora A₁ ∪ A₂ ∈ \\mathcal{A} (se due insiemi appartengono all’algebra, anche la loro unione appartiene all’algebra).\n\nProprietà Derivata\nSe A è un’algebra e A₁, …, Aₙ ∈ A, allora ∪ᵢ₌₁ⁿ Aᵢ ∈ \\mathcal{A} (l’unione finita di insiemi appartenenti all’algebra appartiene all’algebra). Questo si dimostra per induzione.\nSigma-Algebre (σ-algebre)\nUna σ-algebra è un’algebra che è anche stabile rispetto a unioni numerabili. Formalmente, una classe di insiemi \\mathcal{F} è una σ-algebra se soddisfa: \n\nΩ ∈ \\mathcal{F}\nSe A ∈ \\mathcal{F}, allora Aᶜ ∈ \\mathcal{f}\nSe Aᵢ ∈ \\mathcal{F} per i = 1, 2, …, allora ∪ᵢ₌₁^∞ Aᵢ ∈ \\mathcal{f} (l’unione numerabile di insiemi appartenenti alla σ-algebra appartiene alla σ-algebra).\n\nConseguenze Importanti:\n\nSe \\mathcal{F} è una σ-algebra, allora ∅ ∈ \\mathcal{F} (l’insieme vuoto appartiene alla σ-algebra). ^em0xcw\n\n 1. e 2. implicano che Ω ^c\\in \\mathcal{F} ma con Ω ^c=∅\n\n\nSe \\mathcal{F} è una σ-algebra, allora è anche un’algebra.\nLa stabilità rispetto a unioni numerabili implica la stabilità rispetto a unioni finite, ma non viceversa.\n\n\n\n\n\nOsservazione sulle Notazioni\nIl professore userà la lettera \\mathcal{F} per denotare una σ-algebra. In alcuni testi, si usa la lettera \\mathcal{A} per indicare sia le algebre che le σ-algebre.\nInsieme delle Parti\n\nL’insieme delle parti \\mathcal{P}(Ω) è l’insieme di tutti i sottoinsiemi di Ω. \\mathcal{P}(Ω) è sempre una σ-algebra.\nCaso Finito\nSe Ω è un insieme finito, allora non c’è differenza tra algebra e σ-algebra. In questo caso, l’insieme delle parti \\mathcal{P}(Ω) è finito, e quindi ogni famiglia di sottoinsiemi è finita.\nMisure\nUna misura è una funzione che associa un valore numerico a un insieme, quantificandone la “dimensione” in un certo senso.\nSpazio Misurabile\n\nUna coppia (Ω, \\mathcal{A}) o (Ω, \\mathcal{F}), dove Ω è uno spazio campionario e \\mathcal{A} è un’algebra ( \\mathcal{F} è una σ-algebra) su Ω, è chiamata spazio misurabile.\nMisura Finitamente Additiva\nUna funzione μ: \\mathcal{A} → [0, +∞] è una misura finitamente additiva se soddisfa le seguenti proprietà:\n\nμ(∅) = 0\nPer ogni A₁, A₂ ∈ \\mathcal{A} tali che A₁ ∩ A₂ = ∅, si ha μ(A₁ ∪ A₂) = μ(A₁) + μ(A₂)\n\ndefinire un algebra è servito a questo\n\n\n\n\nNOTA: μ non è una misura di un punto μ_d , ma di una famiglia di sottoinsiemi.\n\nMisura (σ-additiva o completamente additiva)\nUna funzione μ: \\mathcal{F} → [0, +∞] è una misura (σ-additiva) se soddisfa le seguenti proprietà:\n\n\nμ(∅) = 0\n\n\nSe Aᵢ ∈ \\mathcal{F} per i = 1, 2, … e Aᵢ ∩ Aⱼ = ∅ per ogni i ≠ j, allora:\nμ(∪ᵢ₌₁^∞ Aᵢ) = ∑ᵢ₌₁^∞ μ(Aᵢ)\n- μ\\left( \\bigcup_{i \\geq 1} A_i \\right) = \\sum_{i \\geq 1} μ(A_i).\n\nse vale più infinito la somma, la misura sarà infinito\n\n\n\nTerminologia\n\nEventi: I sottoinsiemi di Ω sono spesso chiamati eventi.\nEvento certo: Ω (l’evento che si verifica sempre)\nEvento impossibile: ∅ (l’evento che non si verifica mai)\nEvento contrario: Aᶜ (il complementare di A)\n\nMisure di Probabilità\nUna misura di probabilità è una misura che associa a ogni evento un numero compreso tra 0 e 1, rappresentando la probabilità che l’evento si verifichi.\nProbabilità Finitamente Additiva\nUna funzione \\mathbb{P}: A →[0,1] è una probabilità finitamente additiva se soddisfa:\n\nP(∅) = 0 e P(Ω) = 1\nPer ogni A₁, A₂ ∈ \\mathcal{A} tali che A₁ ∩ A₂ = ∅, si ha P(A₁ ∪ A₂) = P(A₁) + P(A₂)\n\nMisura di Probabilità (σ-additiva)\nUna funzione P: \\mathcal{F} → è una misura di probabilità (σ-additiva) se soddisfa:\n\n\nP(∅) = 0 e P(Ω) = 1\n\n\nSe Aᵢ ∈ \\mathcal{F} per i = 1, 2, … e Aᵢ ∩ Aⱼ = ∅ per ogni i ≠ j, allora:\nP\\left( \\bigcup_{n \\geq 1} A_n \\right) = \\sum_{n \\geq 1} P(A_n).\n\n\nRelazione tra Misure e Misure di Probabilità\nUna misura di probabilità è un caso particolare di misura in cui i valori sono normalizzati tra 0 e 1 e la misura dello spazio totale è 1.\n\ndefinizione probabilità: è una misura sigma additiva tale per cui lo spazio totale vale omega\n\nProprietà Elementari delle Misure (e Misure di Probabilità)\nLe seguenti proprietà valgono sia per le misure che per le misure di probabilità (nell’accezione di σ-additiva):\n\nSe A₁ ∩ A₂ = ∅, allora μ(A₁ ∪ A₂) = μ(A₁) + μ(A₂)\n\nquesta proprietà appartiene alle unioni numerabili (σ- finite) si può dedurre valga anche per le σ-additive\n\n\nSe A ⊆ B, allora μ(A) ≤ μ(B) (monotonia)\n\nSe A ⊆ B significa B implica A\n\n\n\nTerminologia Probabilistica Aggiuntiva\n\nSe A ∩ B = ∅, si dice che A e B sono incompatibili.\n\n\nMisure di Probabilità: Proprietà Fondamentali e Dimostrazioni\nse P è una mdp (misura di probabilità) → P è una misura\nle proprietà sulle misure valgono per P.\nIl professore spiega le proprietà fondamentali delle misure di probabilità, sottolineando che queste proprietà sono valide in generale per le misure su sigma-algebre e sono cruciali per la teoria della probabilità.\n1. Additività Completa e Finitamente Additiva (il cambio da P a un mu è colpa del prof…)\n\n\nDefinizione: Una misura di probabilità (P) su uno spazio campionario (\\Omega) è completamente additiva se, per ogni successione di eventi mutuamente disgiunti A_1, A_2, \\dots, vale:\n\\mu\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} \\mu(A_i)\n\n\nAdditività finita: Se la proprietà vale solo per un numero finito di eventi disgiunti, allora la misura è finitamente additiva.\nP\\left(\\bigcup_{i=1}^{n} A_i\\right) = \\sum_{i=1}^{n} P(A_i) \n\n\nDimostrazione che l’additività completa implica quella finita:\n\n\nSiano A_1 e A_2 eventi disgiunti. Possiamo scrivere la loro unione come un’unione infinita, aggiungendo l’insieme vuoto infinite volte:\nA_1 \\cup A_2 = A_1 \\cup A_2 \\cup \\emptyset \\cup \\emptyset \\cup \\dots\n\n\nPer l’additività completa:\n\\mu(A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2) + \\sum_{i=3}^{\\infty} \\mu(\\emptyset) \n\n\nDato che \\mu(\\emptyset) = 0:\n\\mu(A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2)\n\n\nQuesto dimostra che se una misura è completamente additiva, allora è anche finitamente additiva.\n\n\n\n\n2. Monotonia\n\nDefinizione: Se (A \\subseteq B), allora (P(A) \\leq P(B)).\nDimostrazione:\n\n\nSe A \\subseteq B, possiamo scrivere B come l’unione disgiunta di A e B \\setminus A:\nB = A \\cup (B \\setminus A)\n\n\nA\\cap (B\\setminus A)=\\emptyset\n\n\n\nQuindi, \\mu(B) = \\mu(A) + \\mu(B \\setminus A)\n\n\n\n\nper additività finita.\n\n\n\n\nDato che \\mu(B \\setminus A) \\geq 0 per definizione allora:\n\\mu(B) \\geq \\mu(A)\n\n\n\n\n3. Probabilità del Complementare\n\nDefinizione sia \\mathbb{P}\\in\\cal{F}\n\n: (P(A^c) = 1 - P(A)) \\forall A\\in \\cal{F}\n\ndove (A^c) è il complementare di (A) rispetto a (\\Omega).\n\n\n\n\nDimostrazione:\n\nSappiamo che (A \\cup A^c = \\Omega) e (A \\cap A^c = \\emptyset).\nQuindi, per additività finita\n\n(P(A \\cup A^c) = P(A) + P(A^c) = P(\\Omega) = 1).\n\n\nDa cui: P(A^c) = 1 - P(A)\n\n\n\n4. Probabilità dell’Unione di Due Eventi\n\n\nDefinizione: sia \\mathbb{P}\\in\\cal{F}\n\nPer due eventi (A) e (B), vale: P(A \\cup B) = P(A) + P(B) - P(A \\cap B) \\forall A,B\\in \\cal{F}\n\n\nDimostrazione:\n\n\nSi decompone (A \\cup B) in tre parti disgiunte: (A \\setminus (A \\cap B)), (B \\setminus (A \\cap B)) e (A \\cap B).\n\n\nQuindi per additività finita: P[A \\cup B] = P[A \\setminus (A \\cap B)] + P[B \\setminus (A \\cap B)] + P(A \\cap B)\n\n\nNotiamo che (B\\cap A)\\subseteq A\n\nA = [A \\setminus (A \\cap B)] \\cup (A \\cap B), che sono disgiunti\n\n\n\n\nP(A) = P(A \\setminus (A \\cap B)) + P(A \\cap B)\nP(A \\setminus (A \\cap B)) = P(A) - P(A \\cap B)\n\n\n\nAnalogamente: P(B \\setminus (A \\cap B)) = P(B) - P(A \\cap B)\n\n\nSostituendo: P(A \\cup B) = P(A) - P(A \\cap B) + P(B) - P(A \\cap B) + P(A \\cap B)\n\n\nSemplificando: P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\n\nIl professore sottolinea che sommare (P(A)) e (P(B)) significa contare due volte l’intersezione, quindi la si deve sottrarre.\n\n\n\n\nSigma-algebra Generata da una Famiglia di Insiemi\n\nDefinizione: Data una famiglia di sottoinsiemi (\\mathcal{E}\\subset \\cal{P}(\\Omega)) di (\\Omega),\n\nla sigma-algebra generata da (\\mathcal{E}), indicata con (\\sigma(\\mathcal{E})), è la più piccola sigma-algebra che contiene (\\mathcal{E}).\n\n\nEsempio:\n\nSia (\\Omega = {1, 2, 3}) e (\\mathcal{E} = {{1, 2}, {2, 3}}). (\\mathcal{E}) non è un’algebra perché non contiene (\\Omega) né l’insieme vuoto.\nPer generare la sigma-algebra, dobbiamo aggiungere:\n\n(1, 2) \\cup (2, 3)= \\Omega.\nIl complementare di ({1, 2}), che è ({3}).\nIl complementare di ({2, 3}), che è ({1}).\n{1,3} che è il complementare di {2}\n{2} che è il complementare di {1,3}\nL’insieme vuoto\n\n\nQuindi, (\\sigma(\\mathcal{E}) = {\\emptyset, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, \\Omega}), che è l’insieme delle parti di (\\Omega).\n\n\nEsercizio Proposto\n\nEsercizio: Dato (\\Omega = {1, 2, 3}) e (\\mathcal{E} = {{1, 2}, {3}}), trovare la sigma-algebra generata da (\\mathcal{E}).\nOsservazione: In questo caso, la sigma-algebra generata non sarà l’insieme delle parti, suggerendo che non sempre si è in grado di misurare tutti i sottoinsiemi dello spazio campionario.\nReferences\n\n\n"},"6--full-note/Prob--Lez01":{"slug":"6--full-note/Prob--Lez01","filePath":"6- full note/Prob- Lez01.md","title":"Prob- Lez01","links":["tags/revisione_zero","tags/flashcard_zero","tags/riscritto_zero","3--tag/probabilità","3--tag/sbobine"],"tags":["revisione_zero","flashcard_zero","riscritto_zero"],"content":"2025-02-17 19:48\nStatus: revisione_zero flashcard_zero riscritto_zero\nTags:probabilità sbobine\nlez01-Prob\nIntroduzione alla Teoria della Probabilità: Eventi e Misure\n\n\nObiettivo del corso: Fornire un linguaggio matematico rigoroso per descrivere e analizzare fenomeni non deterministici.\n\nPrerequisiti: Richiesta familiarità con analisi matematica (limiti, integrali) e algebra lineare.\n\n\n\nFormalizzazione matematica dei fenomeni: Strumenti per descrivere e analizzare l’incertezza.\n\n\nEsempio introduttivo: Il lancio di una moneta.\n\nAnche se apparentemente casuale, con la meccanica classica si potrebbe prevedere il risultato conoscendo le condizioni iniziali.\nLa probabilità è usata per modellizzare il risultato, anche se il fenomeno non è intrinsecamente casuale.\n\n\n\nRicostruzione dei concetti di base: Partire da zero per costruire una base solida.\n\n\nFocus su variabili aleatorie e vettori aleatori: Modellizzare fenomeni misurabili e costruire eventi complessi.\n\nLe variabili aleatorie sono funzioni che associano un numero reale ad ogni possibile risultato di un esperimento casuale.\n\n\n\nEventi come sottoinsiemi di uno spazio campionario: Iniziare parlando di eventi senza variabili aleatorie.\n\n\nConcetti Chiave:\n\n\nΩ (Omega): Spazio Campionario (o Spazio degli Esiti):\n\nL’insieme di tutti i possibili risultati di un esperimento casuale.\nInsieme astratto, senza struttura particolare.\nPuò essere finito, infinito numerabile, o continuo.\nSpesso non è esplicitamente definito, ma esiste implicitamente.\n\n\n\nω (omega minuscola): Esito Elementare: Un singolo elemento di Ω, un punto, una particolare realizzazione dell’esperimento.( Parametrizzazione del caso).\n\n\nEventi A: Sottoinsiemi di Ω  A⊂Ω.\n\nCollezione di esiti elementari che soddisfano una condizione.\n\n\n\nEvento Certo: L’insieme Ω stesso.\n\n\nImpostazione Assiomatica della Probabilità:\n\nImpostazione assiomatica di Kolmogorov: Definire la probabilità in termini di assiomi matematici.\nP(A): Misura di Probabilità di un evento A: Funzione che associa un numero reale tra 0 e 1 ad ogni evento A.\n\nAlgebra di Insiemi (o Algebra di Eventi):\n\nNon è necessario considerare tutti i sottoinsiemi di Ω.\n\nP(Ω) INSIEME DELLE PARTI\n\n\nDefinire una famiglia più piccola di sottoinsiemi, chiamata algebra, che soddisfi certe proprietà.\n\nΩ ∈ A (l’evento certo appartiene ad A_).\nSe A ∈ A_, allora Aᶜ ∈ A_ (il complementare di A appartiene ad A).\nSe A₁, A₂, …, Aₙ ∈ A_, allora ⋃ᵢ₌₁ⁿ Aᵢ ∈ A_ (l’unione finita di eventi appartiene ad A).\n\n\n\nMisure di Probabilità Finitamente Additive:\ninformazione a fine costruttivo, poi ci dimenticheremo di sta definizione\n\nFunzione P: A → |0,1| (normalizzo per modellizzare il grado di fiducia che ho per un evento) tale che:\n\n\n0 ≤ P(A) ≤ 1 per ogni A ∈ A.\n\n\nP(Ω) = 1. (“il tutto ha peso 1”)\n\n\nSe A₁, A₂, …, Aₙ ∈ A sono a due a due disgiunti (Aᵢ ∩ Aⱼ = ∅ per i ≠ j), allora:\nP(⋃ᵢ₌₁ⁿ Aᵢ) = ∑ᵢ₌₁ⁿ P(Aᵢ)\n-\n(Additività finita).\n3. \n\nproprietà cercata naturalmente per come misuriamo noi questa cosa\n\n\n\n\nEventi disgiunti: Sono anche detti incompatibili.\n\nMisure di Probabilità e Sigma Algebra (σ-algebra):\n\nIn molti problemi, è necessario considerare unioni infinite numerabili di eventi.\n\nUna famiglia F di sottoinsiemi di Ω è detta σ-algebra soddisfa:\n\nΩ ∈ F.\nSe A ∈ F, allora Aᶜ ∈ F.\nSe {Aᵢ}ᵢ₌₁^∞ è una collezione numerabile di eventi in F, allora ⋃ᵢ₌₁^∞ Aᵢ ∈ F.\n\n\n\n\n\nDifferenza chiave rispetto all’algebra: La σ-algebra è stabile rispetto a unioni numerabili, mentre l’algebra è stabile solo rispetto a unioni finite.\nMisura di probabilità (σ-additiva o completamente additiva): Per poter definire una probabilità su una sigma algebra, serve l’additività completa.\n\nFunzione P: F → |0,1| tale che:\n\n\nP(Ω) = 1.\n\n\nA₁, A₂ ∈ F  , A₁ ∩ A₂ =∅       ⇒ P(A₁ ∪ A₂) = P(A₁) + P(A₂)\n\n\nSiano ( A_1, A_2, \\dots \\in \\mathcal{F} ) una famiglia di insiemi mutuamente disgiunti, cioè: A_i \\cap A_j = \\emptyset \\quad \\text{per } i \\neq j.\nAllora, la probabilità dell’unione numerabile di questi eventi è data da: P\\left( \\bigcup_{n \\geq 1} A_n \\right) = \\sum_{n \\geq 1} P(A_n).\n(Additività completa o σ-additività).\n\n\n\n\n\nUna misura di probabilità completamente additiva è definita su una sigma algebra e soddisfa l’additività completa.\n\nMisura di Probabilità su un’Algebra con Additività Numerabile (Caso intermedio):\ninformazione a fine costruttivo, poi ci dimenticheremo di sta definizione\n\n\nDefinire una misura di probabilità P su un’algebra A che soddisfi una condizione di additività numerabile ristretta:\n\n\nche soddisfi sia 1. che 2. e un 3’. tc\n\n\\{A_1, A_2, \\dots, A_n, \\dots\\} una famiglia di insiemi tali che:  A_i \\cap A_j = \\emptyset \\quad \\text{per } i \\neq j.  Allora si ha:  \\bigcup_{n \\geq 1} A_n \\in \\mathcal{A}\nin un algebra questa proprietà non è automatica ma non è impossibile\n\n\n\nse valgono queste proprietà allora vale additività\n\n\nQuesto approccio intermedio è utile perché costruire direttamente una misura di probabilità su una sigma algebra può essere difficile.\n\n\nConseguenze Elementari\nDate le definizioni, si possono derivare alcune proprietà fondamentali per \\mathbb{P} (finitamente additiva):\n\n\ndefinizioni\n\n\n\n\nProbabilità del complementare: P(Aᶜ) = 1 - P(A).\n\n\nProbabilità dell’evento impossibile (insieme vuoto): P(∅) = 0.\n\n\nMonotonia: Se A ⊆ B, allora P(A) ≤ P(B).\n\nIn termini logici: se A implica B, allora P(A) ≤ P(B).\nutile per esercizi più complessi passare dalla logica\n\n\n\nProbabilità dell’unione (caso generale): P(A ∪ B) = P(A) + P(B) - P(A ∩ B).\n\n\n\n\ndimostrazioni\n\n\nP(A^c) = 1 - P(A)\n\nLo spazio campionario \\Omega è dato dall’unione di un evento A e del suo complementare: \\Omega = A \\cup A^c\nGli insiemi A e A^c sono disgiunti: A \\cap A^c = \\emptyset\nPer la proprietà di additività finita della probabilità: P(\\Omega) = P(A \\cup A^c) = P(A) + P(A^c)\nDato che P(\\Omega) = 1 (primo assioma), otteniamo: 1 = P(A) + P(A^c)\nInfine, isolando P(A^c), si ottiene la formula desiderata: P(A^c) = 1 - P(A)\n\n\n\nP(∅) = 0**:\n\n∅ = Ωᶜ (l’insieme vuoto è il complementare dell’evento certo).\nP(∅) = P(Ωᶜ) = 1 - P(Ω) (per la proprietà del complementare).\nP(∅) = 1 - 1 = 0.\n\n\n\nSe A ⊆ B, allora P(A) ≤ P(B) (Monotonia)**:\n\n\nB = (B \\ A) ∪ A\n(B può essere espresso come l’unione disgiunta di (B - A) e A).\n(B - A) ∩ A = ∅ ((B - A) e A sono disgiunti).\nP(B) = P((B - A) ∪ A) = P(B - A) + P(A) (per l’additività finita).\nP(B) = P(B - A) + P(A) ≥ P(A) (poiché P(B - A) ≥ 0).\nQuindi, P(A) ≤ P(B).\nInoltre, P(B \\ A) = P(B) - P(A) (sotto le ipotesi che A ⊆ B)\n\n\n\nP(A ∪ B) = P(A) + P(B) - P(A ∩ B)**:\n\n\nA ∪ B = (A - B) ∪ (B - A) ∪ (A ∩ B) (unione disgiunta).\nP(A ∪ B) = P(A - B) + P(B - A) + P(A ∩ B) (per l’additività finita).\nA = (A - B) ∪ (A ∩ B) e B = (B - A) ∪ (A ∩ B)\nP(A) = P(A - B) + P(A ∩ B) e P(B) = P(B - A) + P(A ∩ B)\nP(A - B) = P(A) - P(A ∩ B) e P(B - A) = P(B) - P(A ∩ B)\nP(A ∪ B) = P(A) - P(A ∩ B) + P(B) - P(A ∩ B) + P(A ∩ B)\nP(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n\n\n\n\n\nImportante: Il professore sottolinea che i diagrammi di Venn sono utili per l’intuizione, ma le dimostrazioni devono basarsi sulle proprietà degli eventi e non su concetti geometrici.\nPrincipio di Inclusione-Esclusione:\nIl professore menziona il principio di inclusione-esclusione per n eventi, ma non lo esplicita. La formula generale è:\ncita ma non chiede\nP(A₁ ∪ … ∪ Aₙ) = ∑ᵢP(Aᵢ) - ∑ᵢ&lt;ⱼP(Aᵢ ∩ Aⱼ) + ∑ᵢ&lt;ⱼ&lt;ₖP(Aᵢ ∩ Aⱼ ∩ Aₖ) - … + (-1)ⁿ⁻¹P(A₁ ∩ … ∩ Aₙ)\nCostruzione della Sigma Algebra:\nEsempio di Algebra e Misura Finitamente Additiva (ma non σ-additiva)\n\n\nSpazio campionario: Ω = ℕ (interi non negativi).\n\n\nAlgebra: A = {A ⊆ ℕ : A è finito o Aᶜ è finito} (insiemi finiti o cofiniti).\n\n\nMisura di probabilità P:\n\nP(A) = 0 se A è finito.\nP(A) = 1 se A è cofinito.\n\n\n\nVerifica:\n\nA è un’algebra, ma non una σ-algebra.\nP è una misura di probabilità finitamente additiva, ma non σ-additiva.\nSi dimostra che non è σ-additiva prendendo i singoletti di ℕ, che sono finiti, quindi hanno misura 0, ma la loro unione è ℕ, che ha misura 1.\nSiano A e B due insiemi tali che A \\cap B = \\emptyset.\n\n\n\nSe A e B appartengono a una algebra A_ finita,\nA \\cap B = \\emptyset con A,B Finiti allora:\n\nP(A \\cup B) = 0\n0+0 = P(A) + P(B)\nSe invece A è finito B è cofinita e allora: P(A \\cup B) = 1$$$$P(A \\cup B) = 1 = 0 + 1 = P(A) + P(B)\n\n\n\nTeorema di Estensione di Carathéodory\nQuesto teorema permette di estendere una misura di probabilità da un’algebra a una σ-algebra generata da essa.\n\nSia A un’algebra di sottoinsiemi di Ω.\nSia P: A →|0,1| una misura di probabilità σ-additiva (nel senso ristretto descritto sopra).\nAllora, esiste un’unica misura di probabilità σ-additiva P* definita sulla σ-algebra generata da A tale che P*(A) = P(A) per ogni A ∈ A.\nLa dimostrazione di questo teorema è complessa.\nLa σ-algebra generata è la più piccola σ-algebra che contiene A.\n\n\n\n\n\nSpero che questa riscrittura dettagliata sia di tuo gradimento!\nTeorema di Estensione di Carathéodory:\n\nPermette di estendere una misura di probabilità da un’algebra a una σ-algebra generata da essa.\nLa σ-algebra generata da un’algebra A è la più piccola σ-algebra che contiene A.\nSe A è un’algebra di sottoinsiemi di Ω e P: A → \\ è una misura di probabilità σ-additiva (nel senso ristretto descritto sopra), allora esiste un’unica misura di probabilità σ-additiva P* definita sulla σ-algebra generata da A tale che P*(A) = P(A) per ogni A ∈ A.\n\nReferences"},"6--full-note/Prob--Lez02":{"slug":"6--full-note/Prob--Lez02","filePath":"6- full note/Prob- Lez02.md","title":"Prob- Lez02","links":["tags/revisione_in_corso","tags/flashcard_finite","tags/riscritto_zero","3--tag/probabilità","3--tag/sbobine"],"tags":["revisione_in_corso","flashcard_finite","riscritto_zero"],"content":"2025-02-18 08:16\nStatus: revisione_in_corso flashcard_finite riscritto_zero\nTags:probabilità sbobine\nlez02-Prob\nDefinizione di Probabilità: Approccio Alternativo\nIl professore introduce una definizione di probabilità leggermente diversa da quella standard, ma equivalente. Questa definizione alternativa non richiede esplicitamente che la probabilità dell’insieme vuoto sia zero.\nDefinizione\n\nSia (Ω, F) uno spazio misurabile, dove Ω è lo spazio campionario e F è una σ-algebra di eventi. Una funzione P: ℱ →|0,1|  è una misura di probabilità se soddisfa le seguenti condizioni:\n\n\nP(Ω) = 1 (la probabilità dell’evento certo è 1)\n\n\nσ-additività (additività completa): Per ogni successione di eventi Aᵢ ∈ F tali che Aᵢ ∩ Aⱼ = ∅ per i ≠ j (eventi incompatibili), vale:\nP(∪ᵢ Aᵢ) = ∑ᵢ P(Aᵢ)\n\n\n\n\n\nEquivalenza tra le Definizioni\nLa definizione standard di misura di probabilità include anche la condizione che P(∅) = 0. Il professore dimostra che la definizione alternativa è equivalente a quella standard, mostrando che la condizione P(∅) = 0 può essere derivata dalle altre proprietà.\nDimostrazione che P(∅) = 0\n\n\n1→2\n2→1\n\n\nSi esprime l’insieme vuoto come unione numerabile di insiemi vuoti:\n∅ = ∪ᵢ ∅\n\n\nSia p = P(∅). Per la σ-additività, si ha:\np = P(∅) = P(∪ᵢ ∅) = ∑ᵢ P(∅) = ∑ᵢ p\n\n\nQuindi, p = ∑ᵢ p. Questo è possibile solo se p = 0. Se p fosse strettamente positivo, la somma di infiniti valori positivi divergerebbe.\n\n\nPertanto, P(∅) = 0.\n\n\n\n\nCommenti\n\nQuesta dimostrazione mostra che la condizione P(∅) = 0 è ridondante nella definizione alternativa, poiché può essere derivata dalle altre proprietà.\nL’obiettivo del professore è di fornire una caratterizzazione utile per confrontare diverse definizioni di probabilità, ad esempio quella trovata nel libro di Protter.\n\nMisure Finite e σ-Finite\nIl professore introduce le definizioni di misura finita e misura σ-finita.\nMisura Finita\nUna misura μ su una σ-algebra F è detta finita se la misura dell’insieme totale è finita:\nμ(Ω) &lt; ∞\nEsempio: Una misura di probabilità è una misura finita perché P(Ω) = 1.\nMisura σ-Finita\nUna misura μ su una σ-algebra ℱ è detta σ-finita se esiste una famiglia numerabile di insiemi misurabili Bᵢ ∈ F tale che:\n\nGli insiemi Bᵢ sono disgiunti: Bᵢ ∩ Bⱼ = ∅ per i ≠ j\nL’unione degli insiemi Bᵢ è l’intero spazio: ∪ᵢ Bᵢ = Ω\nLa misura di ogni insieme Bᵢ è finita: μ(Bᵢ) &lt; ∞ per ogni i\n\nUna famiglia di insiemi con queste proprietà è chiamata partizione numerabile o partizione misurabile numerabile dello spazio.\n\n\n\nCommenti\n\nLa misura σ-finita è una generalizzazione della misura finita. Permette di lavorare con spazi di misura infinita, purché possano essere suddivisi in una quantità numerabile di sottoinsiemi di misura finita.\nLe misure che verranno utilizzate nel corso avranno spesso questa proprietà. Ad esempio, la misura di Lebesgue su ℝⁿ è σ-finita perché ℝⁿ può essere suddiviso in una quantità numerabile di cubi con lato di lunghezza finita.\n\nrifattorizzo\nEsempi di Misure di Probabilità\nIl professore presenta tre esempi semplici di misure, che servono come base per costruire esempi più complessi.\n1. Delta di Dirac (Massa Puntuale)\nSia Ω uno spazio qualsiasi e ω₀ ∈ Ω un punto fissato. La misura delta di Dirac δω₀ è definita come:\nδω₀(A) = { 1 se ω₀ ∈ A\n{ 0 se ω₀ ∉ A\nδω₀(A) assegna probabilità 1 se l’insieme A contiene il punto ω₀ e probabilità 0 altrimenti.\n\nCommento: La delta di Dirac è una misura di probabilità degenere, perché assegna probabilità 1 a un singolo punto e 0 a tutto il resto. Dal punto di vista probabilistico, rappresenta un evento certo.\n\n2. Misura di Conteggio\nSia Ω un insieme al più numerabile di punti ωᵢ. La misura di conteggio μ è definita come:\nμ(A) = ∑ᵢ δωᵢ(A) = |{ωᵢ ∈ A}|\ndove |{ωᵢ ∈ A}| indica il numero di elementi in A.\n\n\n\nIn altre parole, μ(A) conta il numero di punti ωᵢ che appartengono all’insieme A.\n\n\nEsempio: Sia Ω = ℕ (numeri naturali) e A = {1, 3, 5}. Allora μ(A) = 3.\n\n\nin questo caso μ(Ω) sarebbe infinito → non sarebbe una misura finita\n\n\n3. Misura Discreta Generale\nSia Ω un insieme al più numerabile di punti ωᵢ e siano cᵢ dei numeri reali positivi. La misura discreta μ è definita come:\nμ(A) = ∑{cᵢ : ωᵢ ∈ A}\n\n\n\nIn questo caso, ogni punto ωᵢ ha un peso cᵢ. La misura di un insieme A è la somma dei pesi dei punti che appartengono ad A.\n\nSe ∑ᵢ cᵢ = 1, allora μ è una misura di probabilità.\nSe ∑ᵢ cᵢ &lt; ∞, allora μ è una misura finita.\nSe ∑ᵢ cᵢ = ∞, allora μ non è una misura finita.\n\nCommenti\n\nQuesti esempi mostrano come costruire misure a partire da punti isolati.\nLe misure discrete sono fondamentali in molti contesti probabilistici.\n\nSigma Algebra Generate da Famiglie di Insiemi\nIl professore introduce il concetto di σ-algebra generata da una famiglia di insiemi.\nDefinizione\nData una famiglia di insiemi E, la σ-algebra generata da E, indicata con σ(E), è la più piccola σ-algebra che contiene tutti gli insiemi in E.\nIn altre parole, σ(E) è l’intersezione di tutte le σ-algebre che contengono E.\nσ(E) = ∩{ℱ : ℱ è una σ-algebra e E ⊆ ℱ}\n\n\n\nProprietà\nSe E₁ ⊆ E₂, allora σ(E₁) ⊆ σ(E₂).\nEsempio\nSia Ω = {1, 2, 3} e E = {{1, 2}}. Allora la σ-algebra generata da E è:\nσ(E) = {∅, Ω, {1, 2}, {3}}\nCommenti\n\nLa σ-algebra generata da una famiglia di insiemi è un concetto fondamentale per costruire σ-algebre complesse a partire da insiemi più semplici.\nQuesto concetto è particolarmente importante quando si lavora con spazi non numerabili, come la retta reale.\n\nProbabilità su Spazi Numerabili (o finiti)\nIl professore discute come definire misure di probabilità su spazi numerabili.\nPartizioni Numerabili\nUna partizione numerabile di uno spazio Ω è una famiglia numerabile di insiemi disgiunti H = {Hᵢ} tali che ∪ᵢ Hᵢ = Ω.\nSigma Algebra Generata da una Partizione Numerabile\nLa σ-algebra generata da una partizione numerabile H è l’insieme di tutte le unioni (finite o numerabili) di elementi di H.\n\n\n\nCaratterizzazione delle Misure di Probabilità\nSia F la σ-algebra generata da una partizione numerabile H. Per definire una misura di probabilità P su F, è sufficiente assegnare un peso pᵢ ≥ 0 a ogni elemento Hᵢ della partizione, tale che ∑ᵢ pᵢ = 1.\nLa probabilità di un insieme A ∈ F è data da:\nP(A) = ∑{pᵢ : Hᵢ ⊆ A}\n\n\n\nEsempio\nSia Ω = ℕ e H = {{1}, {2}, {3}, …}. Una misura di probabilità su F = P(ℕ) è completamente determinata dai pesi pᵢ = P({i}), con pᵢ ≥ 0 e ∑ᵢ pᵢ = 1.\n\nProbabilità Uniforme su un Insieme Finito: Se Ω = {ω₁, …, ωₘ}, si pone P(ωᵢ) = 1/m per ogni i.\nDistribuzione Geometrica: Sia Ω = ℕ₀ = {0, 1, 2, …} e sia 0 &lt; θ &lt; 1. Si definisce P(i) = θⁱ (1 - θ) per i ∈ ℕ₀. Questa è la distribuzione geometrica.\n\n\n\nEstensione e Unicità\nIl professore introduce i concetti di estensione* e unicità* delle misure}.\nMotivazione\nSi vuole costruire misure* su spazi non* numerabili*, come la retta* reale*, che soddisfino certe proprietà intuitive. Ad esempio, si vorrebbe una misura μ su ℝ tale che μ([a, b]) = b - a per ogni intervallo* [a, b].\nTeorema di Estensione di Carathéodory\nSia A* un’algebra* su Ω e sia μ una misura* σ-additiva* su A*. Allora esiste un’estensione* μ** di μ a σ(A)* che è una misura σ-additiva*. Se μ è σ-finita*, allora l’estensione è unica*.\n\nformulazione che usiamo noi\n\n\nTeorema di Unicità\nSiano P e Q due misure* di probabilità* su una σ-algebra F. Sia C* una classe* di insiemi* tale che σ(C) = F. Se P(A) = Q(A) per ogni A ∈ C, allora P = Q. In altre parole, se due misure di probabilità coincidono* su una classe* che genera la σ-algebra*, allora coincidono* su tutta* la σ-algebra*.\nP-Classe\nUna classe C di insiemi è detta P-classe se è stabile* per intersezioni* finite*. Ovvero, se A₁, …, Aₙ ∈ C, allora A₁ ∩ … ∩ Aₙ ∈ C.\n\nEsempio di P-Classe: La famiglia di semirette della forma (-∞, x]* con x ∈ ℝ è una P-classe.\n\nReferences"},"6--full-note/Prob--Lez03":{"slug":"6--full-note/Prob--Lez03","filePath":"6- full note/Prob- Lez03.md","title":"Prob- Lez03","links":["tags/revisione_finita","tags/flashcard_finite","tags/riscritto_finito","3--tag/probabilità","3--tag/sbobine"],"tags":["revisione_finita","flashcard_finite","riscritto_finito"],"content":"2025-02-19 10:24\n_Status: revisione_finita  flashcard_finite  riscritto_finito\n_Tags: probabilità sbobine\nlez03- Prob\nMisure di Probabilità su Insiemi Numerabili\nIl professore introduce il concetto di misure di probabilità definite su insiemi numerabili, finiti o, più in generale, su spazi “misurabilmente generali”.\nCaso in cui Ω è un Insieme Finito\n\nProposizione : Se =Ω è un insieme finito* e F è la σ-algebra delle parti di Ω, una misura* di* probabilità* P* su F assegna una probabilità* a ogni sottoinsieme* di Ω* (l’insieme* delle* parti*) .\n\n\n\nSe P è una misura di probabilità su F, e si definisce pᵢ* come la probabilità del singoletto* {ωᵢ},* dove gli ωᵢ sono gli elementi di Ω ordinati* convenzionalmente* (1, 2, 3, …), allora la probabilità di ogni evento* A ⊆ Ω può essere scritta come la somma* delle probabilità* dei singoletti* contenuti* in A*.\n\ncon \\omega \\in \\set{\\omega_1,\\omega_2,\\cdots} numerabile* o finito* e \\mathcal{F}=\\mathcal{P}(\\Omega)\nse \\mathbb{P} è misura* di probabilita* di \\mathcal{F} e p_i:=\\mathbb{\\omega_i}  per i=1,2,3 → \\mathbb{P\\set{A}}=\\sum_{i: \\ \\omega_i \\in A} p_i \\quad \\forall i: \\omega_i \\in A\n\nP(A) = ∑ᵢ pᵢ,  per tutti gli i tali che ωᵢ ∈ A\n\nDove:\n\nP(A) è la probabilità dell’evento A.\npᵢ è la probabilità del singoletto {ωᵢ}.\nLa sommatoria è estesa a tutti gli indici i tali che l’elemento ωᵢ appartiene all’insieme A.\n\n\n\n\nCaratterizzazione completa: Una misura di probabilità sulla σ-algebra* delle parti* è completamente* caratterizzata* dalle probabilità* dei singoletti*. Conoscendo le probabilità di ogni singolo* elemento* di Ω, si può determinare la probabilità* di qualsiasi* evento.\n\n\nCondizione: Data una successione pᵢ ≥ 0 tale che ∑ᵢ pᵢ = 1, si può definire una misura di probabilità P su \\mathcal{F}=\\mathcal{P}(\\Omega) come:\n\nP(A) = \\sum_{i:\\omega_i \\in A} p_i\nÈ fondamentale che questa funzione sia definita su F.\n\n\n\nfatto fino a qua\nTeorema di Unicità per Misure di Probabilità\nIl professore introduce il teorema di unicità per le misure di probabilità.\n\n\nTeorema (caso di misura di probabilità): Se C è una P-classe che genera la σ-algebra F, e P₁ e P₂ sono due misure di probabilità su F, se P₁(A) = P₂(A) per ogni evento A nella P-classe C, allora P₁ = P₂.\n\n\n\nIn termini più formali:\n\nSia C una P-classe tale che σ(C) = F.\nSiano P₁ e P₂ due misure di probabilità su F.\nSe P₁(A) = P₂(A) ∀ A ∈ C, allora P₁ = P₂.\n\n\n\nEstensione a Misure Sigma-Finite: Il teorema si estende a misure sigma-finite con condizioni aggiuntive:\n\nSiano μ₁ e μ₂ due misure sigma-finite su una σ-algebra F.\nSia C una classe tale che la σ-algebra generata da C sia proprio F, cioè σ(C) = F.\nEsista una successione di eventi Eᵢ ∈ C tali che Eᵢ ∩ Eⱼ = ∅ per i ≠ j e ⋃ᵢ Eᵢ = Ω.\nμ₁(Eᵢ) &lt; ∞ per ogni i.\nSe μ₁(A) = μ₂(A) per ogni A ∈ C, allora μ₁ = μ₂.\n\n\n\n\n\nImportante: Per misure che non sono di probabilità, è necessario che le misure siano sigma-finite e che la P-classe contenga una partizione numerabile tale che le misure degli insiemi nella partizione siano finite.\n\n\nEsempio: Famiglia di Intervalli e Misura di Lebesgue\nDiscussione di un esempio riguardante la famiglia di intervalli su \\mathbb{R} e la misura di Lebesgue.\n\nClasse C₀: C₀ è la famiglia di intervalli aperti (a, b). Questa non è una P-classe, perché l’intersezione di due intervalli disgiunti è l’insieme vuoto, che non appartiene a C₀.\n\nClasse C₀ estesa: Aggiungendo l’insieme vuoto a C₀, si ottiene una P-classe.\nMisura di Lebesgue: La misura di Lebesgue non funziona direttamente con C₀, ma con la classe estesa, a causa della condizione di sigma-finità.\n\n\n\n\nContinuità della Misura di Probabilità\n\nMANCA UNA DIMOSTRAZIONE\n\nIl professore introduce il concetto di continuità per le misure di probabilità.\nConvergenza Monotona di Eventi\n\n\nDefinizione: Una successione di eventi Aₙ converge in modo monotono crescente a un evento A se Aₙ ⊆ Aₙ₊₁ per ogni n, e A = ⋃ₙ Aₙ.\nDefinizione: Aₙ converge in modo monotono decrescente a A se Aₙ ⊇ Aₙ₊₁ per ogni n, e A = ⋂ₙ Aₙ.\n\n\n\n\n\nTeorema di Continuità\n\n\nTeorema: Se P è una misura di probabilità su F, allora:\n\n\nPer ogni successione Aₙ di eventi in F che converge in modo monotono crescente ad A, si ha che:\nlim (n→∞) P(Aₙ) = P(A)\n\n\n\nPer ogni successione Aₙ di eventi in F che converge in modo monotono decrescente ad A, si ha che:\nlim (n→∞) P(Aₙ) = P(A)\n\n\n\n\n\n\n\n\n\n\nTeorema di continuità per misure di probabilità\n\n\n\n\nEnunciato: Sia \\mathcal{F} una \\sigma-algebra su \\Omega. Se P è una misura di probabilità su \\mathcal{F}, allora:\n\nP(A_n) \\to P(A) per ogni successione {A_n}_{n \\in \\mathbb{N}} di eventi in \\mathcal{F} che converge ad A monotonicamente (crescente o decrescente).\nSupponiamo che P sia una funzione da \\mathcal{F} a  tale che P(\\Omega) = 1 e P(A_1 \\cup A_2) = P(A_1) + P(A_2) per ogni A_1, A_2 \\in \\mathcal{F} con A_1 \\cap A_2 = \\emptyset. Allora P è \\sigma-additiva se e solo se per ogni successione {B_n}_{n \\in \\mathbb{N}} di eventi in \\mathcal{F} convergente monotonicamente all’insieme vuoto, \\lim_{n \\to \\infty} P(B_n) = 0.\n\n\n\nDimostrazione (parte 1, caso crescente):\n\nSia {A_n}_{n \\in \\mathbb{N}} una successione di eventi in \\mathcal{F} tale che A_n \\subseteq A_{n+1} per ogni n, e sia A = \\bigcup_{n=1}^{\\infty} A_n.\nDefiniamo una nuova successione di eventi {B_n}_{n \\in \\mathbb{N}} tale che B_1 = A_1 e B_{n+1} = A_{n+1} \\setminus A_n per ogni n \\geq 1. Gli eventi B_n sono a due a due incompatibili.\nSi ha che A_n = \\bigcup_{k=1}^{n} B_k, quindi P(A_n) = P(\\bigcup_{k=1}^{n} B_k) = \\sum_{k=1}^{n} P(B_k) (per additività finita).\nInoltre, A = \\bigcup_{n=1}^{\\infty} A_n = \\bigcup_{k=1}^{\\infty} B_k, quindi P(A) = P(\\bigcup_{k=1}^{\\infty} B_k) = \\sum_{k=1}^{\\infty} P(B_k) (per \\sigma-additività).\nPrendendo il limite per n \\to \\infty di P(A_n), si ottiene \\lim_{n \\to \\infty} P(A_n) = \\lim_{n \\to \\infty} \\sum_{k=1}^{n} P(B_k) = \\sum_{k=1}^{\\infty} P(B_k) = P(A).\nQuindi, P(A_n) converge a P(A).\n\n\n\n\n\nEquivalenza con la Sigma-Additività\n\nTeorema: Sia P una funzione da F a tale che P(Ω) = 1 e P(A₁ ∪ A₂) = P(A₁) + P(A₂) per ogni A₁ e A₂ disgiunti. Allora\n\nP è sigma-additiva se e solo se per ogni successione Bₙ convergente all’insieme vuoto, si ha che lim (n→∞) P(Bₙ) = 0.\n\n\n\n\ndimostrazione\n\n\n\nSubadditività Finita e Numerabile\n\n\nMANCA LA DIMOSTRAZIONE\n\n\nTeorema: Sia P una misura di probabilità su F e sia {Aₖ} una successione di eventi in F. Allora:\n\n\nSubadditività finita:\nP(⋃ₖ₌₁ⁿ Aₖ) ≤ ∑ₖ₌₁ⁿ P(Aₖ)\n\n\n\nSubadditività completa:\nP(⋃ₖ₌₁^∞ Aₖ) ≤ ∑ₖ₌₁^∞ P(Aₖ)\n\n\n\n\n\nCaso di eventi disgiunti: Se gli Aₖ sono a due a due disgiunti, vale l’uguaglianza.\n\n\nFormula per due eventi: Per due eventi qualsiasi A e B:\nP(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n\n\n\n\n\n\n\n\nSubadditività finita e numerabile di una misura di probabilità\n\n\n\n\nEnunciato: Sia P una misura di probabilità su \\mathcal{F} e {A_n}_{n \\in \\mathbb{N}} una successione di eventi in \\mathcal{F}. Allora:\n\nP(\\bigcup_{k=1}^{n} A_k) \\leq \\sum_{k=1}^{n} P(A_k) (subadditività finita).\nP(\\bigcup_{k=1}^{\\infty} A_k) \\leq \\sum_{k=1}^{\\infty} P(A_k) (subadditività completa).\n\n\n\nDimostrazione:\n\nLa subadditività finita si dimostra per induzione. Per n=2, P(A \\cup B) = P(A) + P(B) - P(A \\cap B) \\leq P(A) + P(B).\nPer il passo induttivo, supponiamo che valga per n e dimostriamo per n+1:\n\nP(\\bigcup_{k=1}^{n+1} A_k) = P(\\bigcup_{k=1}^{n} A_k \\cup A_{n+1}) \\leq P(\\bigcup_{k=1}^{n} A_k) + P(A_{n+1}) \\leq \\sum_{k=1}^{n} P(A_k) + P(A_{n+1}) = \\sum_{k=1}^{n+1} P(A_k).\n\n\nPer la subadditività completa, sia C_n = \\bigcup_{k=1}^{n} A_k. Allora C_n converge monotonicamente (crescendo) a \\bigcup_{k=1}^{\\infty} A_k.\nPer la continuità della misura di probabilità, P(\\bigcup_{k=1}^{\\infty} A_k) = \\lim_{n \\to \\infty} P(C_n) = \\lim_{n \\to \\infty} P(\\bigcup_{k=1}^{n} A_k).\nDalla subadditività finita, P(\\bigcup_{k=1}^{n} A_k) \\leq \\sum_{k=1}^{n} P(A_k).\nQuindi, \\lim_{n \\to \\infty} P(\\bigcup_{k=1}^{n} A_k) \\leq \\lim_{n \\to \\infty} \\sum_{k=1}^{n} P(A_k) = \\sum_{k=1}^{\\infty} P(A_k).\nPertanto, P(\\bigcup_{k=1}^{\\infty} A_k) \\leq \\sum_{k=1}^{\\infty} P(A_k).\n\n\n\n\n\nSigma-algebra di Borel su \\mathbb{R} e \\mathbb{R^d}\n\n\n\nIntroduzione della sigma-algebra di Borel su R.\n\n\nDefinizione: La sigma-algebra di Borel (B(R)) è la sigma-algebra generata dagli insiemi aperti di R.\n\n\nAperti in R: Un insieme A ⊆ R è aperto se per ogni x ∈ A esiste un intervallo aperto (x - ε, x + ε) ⊆ A.\n\n\n\n\n\nObiettivo: Restringere l’attenzione agli insiemi boreliani, che includono intervalli, semirette e altri insiemi “ragionevoli”.\n\n\nClassi di Insiemi: Definizione di diverse classi di insiemi che generano la sigma-algebra di Borel:\n\nC₀: Intervalli aperti (a, b).\nC₁: Intervalli chiusi [a, b].\nC₂: Semirette (-∞, x].\n\n\n\n\nAlgebra generata da C₁ ∪ C₂ ∪ C₃: Si può costruire un’algebra A a partire da C₁, C₂, e C₃, formata da unioni finite di elementi di queste classi. Gli elementi di A sono unioni di intervallini di vario tipo, eventualmente con semirette.\n\n\n\n\n\nEquivalenza tra generatori: B(R) può essere ottenuta generando la sigma-algebra a partire da C₀ o C₂.\nB(R) = σ(C₀) = σ(C₂) = σ(A)\n\n\n\nMotivazioni: Questo risultato è utile per:\n\nAvere un’idea concreta degli insiemi boreliani.\nSemplificare le dimostrazioni, usando il teorema di Caratheodory per estendere le misure da un’algebra alla sigma-algebra generata.\nIdentificare misure di probabilità, mostrando che coincidono su una P-classe che genera B(R).\n\n\n\nChiusi: Poiché la sigma-algebra di Borel contiene gli aperti, contiene anche i chiusi (complementari degli aperti). Quindi, contiene anche i singoli punti.\n\n\n\n\n\nSemirette: Le semirette del tipo (-∞, x] appartengono a B(R). Questo si può dimostrare approssimando la semiretta con unioni numerabili di intervalli chiusi.\n\n\n\n\nEquivalenza di generatori della \\sigma-algebra di Borel su \\mathbb{R}\n\n\nEnunciato: Sia \\mathcal{B}(\\mathbb{R}) la \\sigma-algebra di Borel su \\mathbb{R}. Allora: \\sigma(\\mathcal{C}_0) = \\sigma(\\mathcal{C}_1) = \\sigma(\\mathcal{C}_2) = \\mathcal{B}(\\mathbb{R}) dove:\n\n\\mathcal{C}_0 è la famiglia degli intervalli aperti (a, b).\n\\mathcal{C}_1 è la famiglia degli intervalli chiusi [a, b].\n\\mathcal{C}_2 è la famiglia delle semirette (-\\infty, x].\n\n\nDimostrazione (solo \\sigma(\\mathcal{C}_0) = \\mathcal{B}(\\mathbb{R}) ):\n\nPer definizione, \\mathcal{B}(\\mathbb{R}) = \\sigma(\\mathcal{A}), dove \\mathcal{A} è la famiglia degli aperti di \\mathbb{R}.\nPasso 1: \\mathcal{C}_0 \\subseteq \\mathcal{A}. Quindi \\sigma(\\mathcal{C}_0) \\subseteq \\sigma(\\mathcal{A}) = \\mathcal{B}(\\mathbb{R}).\nPasso 2: Ogni aperto A \\subseteq \\mathbb{R} si può scrivere come un’unione numerabile di intervalli aperti.\nQuindi, \\mathcal{A} \\subseteq \\sigma(\\mathcal{C}_0) perché \\sigma(\\mathcal{C}_0) è una \\sigma-algebra e contiene tutti gli intervalli aperti, quindi deve contenere anche le loro unioni numerabili.\nApplicando di nuovo la proprietà che se una classe è contenuta nell’altra, quando generate le sigma algebre, le due sigma algebre sono contenute. Quindi \\sigma(\\mathcal{A}) \\subseteq \\sigma(\\mathcal{C}_0).\nConcludiamo che \\mathcal{B}(\\mathbb{R}) = \\sigma(\\mathcal{A}) \\subseteq \\sigma(\\mathcal{C}_0).\nCombinando i due passi, otteniamo \\sigma(\\mathcal{C}_0) = \\mathcal{B}(\\mathbb{R}).\n\n\n\n\n\nSigma-algebra di Borel su Rᵈ\n\n\n\nEstensione del concetto di sigma-algebra di Borel a Rᵈ.\n\n\nDefinizione: La sigma-algebra di Borel su Rᵈ (B(Rᵈ)) è la sigma-algebra generata dagli insiemi aperti di Rᵈ.\n\n\n\n\n\nRettangoli aperti: Generalizzazione degli intervalli aperti tramite rettangoli aperti, prodotti cartesiani di intervalli aperti.\n\n\n\n\n\nClassi di Insiemi:\n\nD₀: Rettangoli aperti in Rᵈ, prodotti cartesiani di intervalli aperti.\n\n\n\n\nC₂: “Quadranti” in Rᵈ, insiemi della forma (-∞, x], dove x ∈ Rᵈ. Sono insiemi di punti y ∈ Rᵈ tali che ogni coordinata di y è minore o uguale della corrispondente coordinata di x.\n\n\n\n\n\n\n\nEquivalenza tra generatori: B(Rᵈ) può essere generata a partire da D₀ o da C₂.\nB(Rᵈ) = σ(C_0) = σ(D₀) = σ(C₂)\n\n\n\nConseguenza: Se due misure di probabilità P e Q su B(Rᵈ) coincidono su tutti i quadranti, allora sono uguali.\n\n\nMANCA UNA DELUCIDAZIONE\n\n\nMisura di Lebesgue\n\n\n\nIntroduzione della misura di Lebesgue, che rappresenta lunghezza, area o volume.\n\n\nTeorema: Esiste un’unica misura sigma-finita μ su B(R) tale che μ((a, b]) = b - a per ogni a, b ∈ R.\n\n\nGeneralizzazione a Rᵈ: Esiste un’unica misura sigma-finita μ su B(Rᵈ) tale che, per ogni rettangolo R = (a₁, b₁] × … × (a𝒹, b𝒹], si ha μ(R) = (b₁ - a₁) * … * (b𝒹 - a𝒹).\n\n\n\n\n\nMisura di Lebesgue: Questa misura si chiama misura di Lebesgue e non è una misura di probabilità.\n\n\nCostruzione: Per costruire la misura di Lebesgue, si definisce una funzione finitamente additiva su un’algebra di insiemi (unioni finite di intervallini) e poi la si estende usando il teorema di Caratheodory.\n\n\n\n\n\nNotazione: La misura di Lebesgue è definita sui boreliani di Rᵈ.\n\n\nReferences"},"6--full-note/Untitled-1":{"slug":"6--full-note/Untitled-1","filePath":"6- full note/Untitled 1.md","title":"Untitled 1","links":[],"tags":[],"content":""},"6--full-note/Untitled":{"slug":"6--full-note/Untitled","filePath":"6- full note/Untitled.md","title":"Untitled","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/pensieri"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-08 09:51\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: pensieri\nMatematica e realtà\n\nnella matematica ci si deve rendere conto che nulla di tutto ciò che stai facendo è reale. L’esempio più chiave per me è stata la probabilità.\nla probabilità non ci permette di prevedere nulla perché sono dei modelli previamente decisi.\n\nReferences\narticolo sulla probabilità"},"6--full-note/anna's-archive":{"slug":"6--full-note/anna's-archive","filePath":"6- full note/anna's archive.md","title":"anna's archive","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/personale","tags/B8GPqcf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero","B8GPqcf"],"content":"2025-04-24 14:29\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: personale\nanna’s archive\npassword:\nAccount ID: B8GPqcf\nPublic profile: B8GPqcf\nSecret key (don’t share!): B8GPqcf7rBhubx7kQU5yEeCPeiZUK\nReferences"},"6--full-note/chimica-Lez01":{"slug":"6--full-note/chimica-Lez01","filePath":"6- full note/chimica-Lez01.md","title":"chimica-Lez01","links":["tags/flashcard_zero","tags/riscritto_finito","tags/revisione_finita","3--tag/sbobine","3--tag/chimica"],"tags":["flashcard_zero","riscritto_finito","revisione_finita"],"content":"2025-03-02 11:11\n_Status: flashcard_zero  riscritto_finito   revisione_finita\n_Tags:sbobine   chimica\nchimica-Lez01\nEcco una spiegazione dettagliata del corso di chimica basata sulle parole del professore Parmegiani, estratte dalla flashcard. Ho incluso esempi, esercizi e spiegazioni, formattando il testo per chiarezza e leggibilità.\nInformazioni generali sul corso di chimica\n\nDocente: Fabio Parmegiani, Dipartimento di Chimica, Materiali e Ingegneria Chimica.\nContatti: L’email è il metodo di contatto preferibile, oppure durante o dopo le lezioni. L’ufficio si trova in via Mancinelli, a 10-15 minuti da via Ampera.\nOrganizzazione del corso: Il corso è composto da lezioni ed esercitazioni.\n\nLezioni: Sono previste 21 lezioni da 2 ore ciascuna. Il professore cerca di iniziare verso le 8:20 e finire entro le 10:00. Ad ogni lezione saranno associati dei PowerPoint disponibili sulla pagina Webip.\nEsercitazioni: Sono sempre frontali. Gli esercizi saranno forniti in anticipo rispetto alle lezioni, per permettere agli studenti di provare a risolverli autonomamente. Sono previste 28 ore di esercitazioni, che diventeranno 30 grazie a una lezione aggiuntiva facoltativa di riepilogo.\n\n\nFrequenza: La frequenza non è obbligatoria, ma è fortemente consigliata.\nDifficoltà degli esercizi: Gli esercizi dei temi d’esame non saranno più difficili di quelli svolti a lezione.\nMateriale didattico: Tutto il materiale didattico sarà disponibile sulla piattaforma WBIP. Il professore si impegna a caricare il materiale in anticipo, idealmente il giorno prima della lezione.\nOrario:\n\nLunedì 9:01,\nMartedì T11 (aule del trifoglio nuove e ristrutturate),\nGiovedì 26 615 (aula un po’ piccola per le esercitazioni).\n\n\nProgrammazione del corso: Fare riferimento al documento su WVip per il calendario dettagliato delle lezioni. In caso di variazioni, il professore avviserà in aula e aggiornerà il documento su WVip.\nRegistrazioni: Le lezioni saranno disponibili in streaming e registrate sul sito Webex. I link saranno disponibili su WVip e sui servizi online.\n\nLibri di testo\n\nNon è richiesto un libro di testo specifico, ma un qualsiasi testo di chimica a livello universitario è adatto. Molti testi includono già numerosi esercizi. Il professore consiglia alcuni testi utilizzati per preparare le lezioni:\n\nBrownly May (il più allineato ai contenuti del corso)\nSilverberg\nAtkins, Petrucci e Coz (più approfonditi, utili per consultazione)\n\n\nL’ordine degli argomenti può variare da un testo all’altro, ma la chimica è un argomento circolare.\nLa videografia è disponibile sulla scheda del corso e sulle slide.\n\nProgramma del corso\nIl programma del corso coincide con quello di un eventuale corso di chimica del liceo, ma a un livello più approfondito. Gli argomenti principali includono:\n\nStruttura dell’atomo\nStechiometria e nomenclatura (considerato un argomento ostico, affrontato subito)\nTavola periodica degli elementi\nLegami chimici\nTermochimica (influenza dell’energia nelle reazioni chimiche)\nStati della materia (solidi, liquidi, gas e soluzioni)\nEquilibrio chimico\nTermodinamica chimica\nAcidi e basi\nCinetica\nElettrochimica e corrosione (quest’ultimo argomento potrebbe essere escluso a seconda dei tempi)\n\nEsame\n\nModalità: Esami scritti da 2 ore con 10 quesiti (teoria, applicazioni, esercizi).\nTeoria e pratica: Entrambe le componenti sono fondamentali. Non è sufficiente saper fare gli esercizi, è necessario comprendere i concetti teorici.\nOrale: L’orale è facoltativo e a discrezione del docente, solitamente richiesto solo in caso di lacune gravi nello scritto.\nAppelli: Sono disponibili cinque appelli all’anno, senza vincoli o salti d’appello.\nProve in itinere: Non sono previste prove in itinere per il corso di chimica.\nIscrizione: L’iscrizione all’esame è obbligatoria per poter verbalizzare il voto. L’iscrizione si apre con mesi di anticipo e si chiude pochi giorni prima dell’appello.\nDate appelli Gli appelli sono a gennaio, febbraio, giugno, luglio e settembre.\n\nPerché studiare chimica?\nLa chimica è fondamentale perché pervade la vita quotidiana. Anche se non si lavorerà direttamente in ambito chimico, è importante conoscere le nozioni di base per interfacciarsi con i colleghi e non fare brutta figura.\nIntroduzione alla prima lezione\nLa prima lezione inizia con un’immagine della “Scuola di Atene” di Raffaello, in particolare con un focus su Aristotele, figura centrale nello sviluppo della chimica. Il gruppo di figure che rappresenta un geometra con un compasso è all’origine del logo del Politecnico.\nMateria: atomi, molecole e ioni\n\nDefinizione di chimica: Scienza che studia la struttura, la composizione, le proprietà e le trasformazioni della materia.\nTrasformazioni della materia: Le trasformazioni della materia sono chiamate reazioni chimiche.\n\nEsempi di reazioni chimiche: Trasformazione di soluzioni colorate, combustione di una candela, trasformazione di cellulosa.\n\n\nDefinizione di materia: Tutto ciò che ha massa e volume.\nProprietà della materia:\n\nEstensive: Dipendono dalla quantità (es. massa).\nIntensive: Non dipendono dalla quantità (es. temperatura).\n\n\nTrasformazioni della materia:\n\nFisiche: Non cambiano la composizione chimica (es. fusione del ghiaccio, riscaldamento di un metallo).\nChimiche: Cambiano la composizione chimica (es. arrugginimento del ferro, combustione).\n\n\nMetodo scientifico: Si basa sull’osservazione, la formulazione di una teoria e la verifica sperimentale. La teoria deve essere modificata se i dati sperimentali non corrispondono.\nStati di aggregazione della materia: Solido, liquido e gas.\n\nSolido: Forma e volume propri.\nLiquido: Volume proprio, ma non forma propria.\nGas: Né forma né volume propri.\n\n\nLivelli di studio della chimica:\n\nMacroscopico (ciò che si può vedere e misurare)\nMicroscopico (particelle fondamentali, atomi e interazioni)\nSimbolico (introdotto successivamente)\n\n\n\nTeorie sulla composizione della materia\n\nTeoria dei quattro elementi (Empedocle e Aristotele): Aria, acqua, terra e fuoco combinati in proporzioni diverse costituiscono la materia.\nTeoria atomica (Democrito): La materia è costituita da atomi indivisibili e vuoto. Questa teoria non ebbe successo nell’antichità a causa dell’influenza di Aristotele.\nRobert Boyle: Mette in crisi la teoria dei quattro elementi con il libro “Il chimico scettico”.\n\nClassificazione della materia\nLa materia può essere distinta in miscele e sostanze pure.\n\nMiscele: Combinazioni di due o più sostanze.\n\nOmogenee: Appaiono uniformi ad occhio nudo (es. tè, soluzioni).\nEterogenee: Presentano differenze visibili nella composizione (es. granito).\n\n\nSostanze pure: Chimicamente omogenee, costituite da un solo tipo di molecola o atomo.\n\nElementi: Costituiti da un singolo tipo di atomo (es. ossigeno).\nComposti: Costituiti da atomi diversi (es. acqua). Possono essere molecolari o ionici.\n\n\nMetodi di separazione:\n\nMiscele → Sostanze pure: Metodi fisici (es. distillazione, cristallizzazione).\nComposti → Elementi: Trasformazioni chimiche (rottura dei legami chimici).\n\n\n\nElementi chimici\n\nNumero: 118 elementi conosciuti, rappresentati nella tavola periodica. Circa 92 presenti in natura.\nTavola periodica: Organizzazione degli elementi in base alle loro proprietà.\n\nPeriodi: Righe orizzontali.\nGruppi: Colonne verticali.\n\n\nNomenclatura: Non è necessario memorizzare i nomi e i simboli degli elementi, sono disponibili sulla tavola periodica.\n\nComposti e miscele a livello microscopico\n\nElemento in forma atomica: Atomi singoli dello stesso tipo (es. elio).\nMolecole di un elemento: Molecole biatomiche dello stesso elemento (es. ossigeno O₂, azoto N₂).\nComposto molecolare: Molecole formate da atomi di elementi diversi (es. acqua H₂O, fluoruro di boro BF₃).\nMiscela: Coesistenza di elementi e composti diversi a livello microscopico.\nReazione chimica a livello microscopico: Trasformazione di un insieme di atomi in un altro, con formazione o rottura di legami chimici.\nEsempio di reazione chimica: Trasformazione di una miscela eterogenea di polvere di ferro e zolfo in solfuro di ferro (composto omogeneo) tramite riscaldamento.\n\nFondamenti della chimica moderna: leggi ponderali\nLe leggi ponderali sono osservazioni sperimentali sulle masse delle sostanze che si combinano.\nLegge di Conservazione della Massa (Lavoisier)\n\nDefinizione: Durante una trasformazione fisica o chimica, la massa si conserva. In altre parole, in una reazione, la somma delle masse dei reagenti è uguale alla somma delle masse dei prodotti.\nImportanza Storica: Antoine Lavoisier è considerato il padre della chimica moderna perché ha introdotto l’uso della bilancia per misurazioni precise in laboratorio. Questo approccio ha permesso di trasformare la chimica in una scienza quantitativa.\nEsempio: Immagina una reazione chimica come un foglio di calcolo Excel dove devi sommare tutte le quantità a destra (prodotti) e a sinistra (reagenti) dell’equazione; la massa totale deve essere la stessa prima e dopo la reazione.\nEccezioni: La legge è valida a meno che non si verifichi una conversione di massa in energia secondo la teoria di Einstein (E=mc²), ma queste conversioni sono trascurabili nelle reazioni chimiche ordinarie.\n\nLegge delle Proporzioni Definite (Proust)\n\nDefinizione: Il rapporto tra le masse degli elementi che si combinano per formare un composto è costante e indipendente dal metodo di ottenimento.\nEsempio: L’acqua (H₂O) avrà sempre lo stesso rapporto di massa tra idrogeno e ossigeno, sia che provenga da un oceano, da un lago, dalla pioggia, o sia sintetizzata in laboratorio. La composizione di una molecola è indipendente dalla sua storia.\n\nLegge delle Proporzioni Multiple (Dalton)\n\nDefinizione: Quando due elementi si combinano per formare più di un composto, le masse di un elemento che si combinano con una data massa dell’altro stanno tra loro in un rapporto espresso da numeri interi piccoli.\nEsempio: Considera il carbonio e l’ossigeno che formano monossido di carbonio (CO) e biossido di carbonio (CO₂). Il rapporto tra la massa dell’ossigeno in CO e la massa dell’ossigeno in CO₂ è di 1:2. Questo perché in CO c’è un atomo di ossigeno, mentre in CO₂ ce ne sono due.\nContesto Storico: Questa legge ha fornito uno spunto importante per la teoria atomica di Dalton, suggerendo che la materia è composta da particelle indivisibili (atomi).\n\nTeoria Atomica di Dalton\n\nPrincipi Fondamentali:\n\nLa materia è fatta di particelle indivisibili chiamate atomi.\nTutti gli atomi di un dato elemento sono identici e hanno le stesse proprietà.\nAtomi di elementi diversi sono diversi.\nLe reazioni chimiche comportano la combinazione o il rimescolamento degli atomi.\nGli atomi non possono essere interconvertiti in altri atomi tramite reazioni chimiche ordinarie.\n\n\nRappresentazione degli Elementi: Dalton tentò di identificare gli elementi con simboli grafici, ma questo sistema fu presto sostituito da simboli alfabetici.\n\nSimboli Chimici di Berzelius\n\nIntroduzione dei Simboli Alfabetici: Jöns Jacob Berzelius propose di usare lettere al posto dei disegni per rappresentare gli elementi, usando le iniziali dei nomi latini.\nEsempi:\n\nL’azoto è rappresentato con N (dal latino Nitrogenium).\nIl sodio è rappresentato con Na (dal latino Natrium).\nQuando più elementi hanno la stessa iniziale, si usano le prime due lettere, con la prima maiuscola e la seconda minuscola (es. Cl per il cloro).\n\n\n\nModelli Atomici\n\nModello di Thomson (Plum Pudding Model): L’atomo è descritto come una sfera di carica positiva diffusa con elettroni (cariche negative) sparsi al suo interno, come l’uvetta in un panettone.\n\n\n\n\nEsperimento di Crookes e i Raggi Catodici:\n\nProcedimento: In un tubo di vetro sotto vuoto spinto, si applica un’alta tensione tra due elettrodi, catodo (negativo) e anodo (positivo). Questo genera un’emanazione dal catodo che viaggia in linea retta verso l’anodo.\nOsservazioni: I raggi catodici proiettano ombre di oggetti posti sul loro cammino e fanno illuminare materiali fluorescenti.\n\n\n\nEsperimento di Thomson:\n\nModifiche all’Esperimento di Crookes: Thomson perfezionò l’esperimento usando un anodo a forma di ciambella per collimare i raggi catodici in un fascio stretto. Applicò campi elettrici e magnetici esterni al tubo.\n\nOsservazioni e Conclusioni:\n\n\nI raggi catodici deviano verso il polo positivo di un campo elettrico, indicando che sono composti da particelle cariche negativamente.\n\n\nLa deviazione dei raggi in campi elettrici e magnetici permette di calcolare il rapporto carica/massa delle particelle.\n\n\nIl rapporto carica/massa è indipendente dal materiale del catodo, suggerendo che queste particelle sono costituenti universali di tutti gli atomi. Thomson chiamò queste particelle elettroni.\n\n\n\n\n\nEsperimento di Millikan (Gocce d’Olio):\n\n\nGocce d’olio: Millikan utilizzò un nebulizzatore per spruzzare goccioline d’olio cariche elettricamente tra due elettrodi.\n\n\nRaggi X: Le goccioline venivano caricate con raggi X.\n\n\nEquilibrio delle forze: Millikan regolò il campo elettrico per sospendere le goccioline a mezz’aria (catodo in alto), bilanciando la forza di gravità con la forza elettrostatica.\n\n\nCalcolo della carica: Da questo equilibrio, Millikan calcolò la carica dell’elettrone.\n\n\nMassa dell’elettrone: Combinando la carica con il rapporto carica/massa di Thomson, si determinò anche la massa dell’elettrone.\n\n\n\n\nEsperimento di Rutherford (Foglia d’Oro):\n\nProcedimento: Un fascio di particelle alfa (nuclei di elio carichi positivamente) viene diretto verso una sottile lamina d’oro. Uno schermo fluorescente circonda la lamina per rilevare la diffusione delle particelle.\nOsservazioni:\n\nLa maggior parte delle particelle alfa attraversa la lamina senza deviazioni significative.\nAlcune particelle alfa vengono deviate a grandi angoli.\nRaramente, alcune particelle alfa vengono respinte indietro.\n\n\nConclusioni:\n\nLa maggior parte dell’atomo è spazio vuoto.\nQuasi tutta la massa dell’atomo e tutta la carica positiva sono concentrate in un nucleo piccolo e denso al centro.\nGli elettroni orbitano attorno al nucleo.\nQuesto portò Rutherford a proporre un modello planetario dell’atomo.\n \n\n\n\n\n\nStruttura dell’Atomo\n\n\nNucleo: Contiene protoni (cariche positive) e neutroni (neutri).\n\n\nElettroni: Particelle cariche negativamente che orbitano attorno al nucleo.\n\n\nDimensioni: Il diametro dell’atomo è circa 10⁻¹⁰ m, mentre il nucleo è circa 10⁻¹⁴ m. Se l’atomo fosse grande come uno stadio di calcio, il nucleo sarebbe come una ciliegia.\n\n\nle particelle nucleari (protoni e neutroni ) sono detti nucleoni\n\n\nper indicare genericamente diversi tipi di atomi e/o loro nuclei si parla di nuclidi\n\n\nMasse:\n\nProtone: circa 1.672 x 10⁻²⁴ g\nNeutrone: circa 1.674 x 10⁻²⁴ g (leggermente più pesante del protone)\nElettrone: circa 9.1 x 10⁻²⁸ g (molto più leggero di protoni e neutroni)\n\n\n\nCariche:\n\nProtone: +1.6 x 10⁻¹⁹ C\nElettrone: -1.6 x 10⁻¹⁹ C\nNeutrone: 0\n\n\n\nNumero Atomico (Z): Numero di protoni nel nucleo. Definisce l’elemento chimico.\n\n\nNumero di Massa (A): Somma del numero di protoni e neutroni nel nucleo.\n\n\n\nIsotopi: Atomi dello stesso elemento (stesso Z) con diverso numero di neutroni (diverso A). Esempi: carbonio-12, carbonio-13, carbonio-14. L’idrogeno ha tre isotopi: prozio, deuterio e trizio.\n\n\nMassa Atomica Relativa (UMA o Dalton): Massa di un atomo relativa a 1/12 della massa del carbonio-12. Il carbonio-12 ha una massa di 12 UMA (unità massa atomica) per definizione.\n\n\n\nMassa Atomica Media: Media ponderata delle masse degli isotopi di un elemento, tenendo conto delle loro abbondanze naturali. Questo è il valore che si trova sulla tavola periodica.\n\n\n\nIoni\n\n\nFormazione: Un atomo che guadagna o perde elettroni forma uno ione.\nCationi: Ioni positivi formati dalla perdita di elettroni (es. Na⁺).\nAnioni: Ioni negativi formati dall’acquisto di elettroni (es. Cl⁻).\n\nReferences"},"6--full-note/chimica-Lez02":{"slug":"6--full-note/chimica-Lez02","filePath":"6- full note/chimica-Lez02.md","title":"chimica-Lez02","links":["tags/flashcard_zero","tags/riscritto_finito","tags/revisione_finita","3--tag/sbobine","3--tag/chimica"],"tags":["flashcard_zero","riscritto_finito","revisione_finita"],"content":"2025-03-02 16:53\n_Status: flashcard_zero  riscritto_finito   revisione_finita\n_Tags: sbobine  chimica\nchimica-Lez02\nStechiometria e Nomenclatura: La Ricetta della Chimica\n\nStechiometria: Viene definita come “l’aritmetica della chimica”. Si tratta della ricetta da seguire e quantificare per una reazione chimica. L’esempio del panino viene usato per spiegare come un oggetto complesso sia fatto di più parti e preparato seguendo una ricetta.\nNomenclatura: È definita come “una parte un po’ noiosa” ma necessaria per dare un nome corretto alle sostanze e capirsi in chimica.\n\nMasse Atomiche, Molecolari e UMA\n\nMassa vs. Peso: È fondamentale parlare di massa (proprietà assoluta di un atomo/molecola) e non di peso (legato alla forza di gravità).\nElementi e Molecole: Gli elementi possono esistere come singoli atomi (metalli, gas nobili come l’elio) o in forma molecolare (O2, P4).\nComposti Molecolari vs. Ionici: I composti molecolari hanno legami covalenti, mentre quelli ionici sono formati da ioni in reticoli cristallini. Nei composti ionici non si parla di molecole.\nCalcolo della Massa:\n\nMassa atomica: espressa in uma per un atomo.\nMassa molecolare: per una molecola (somma delle masse atomiche). Esempio: O2 = 2 * 16 uma = 32 uma.\nMassa formula: per composti ionici (somma delle masse atomiche), usata al posto di “massa molecolare”. Esempio: NaCl = massa atomica Na + massa atomica Cl.\n\n\n\nDal Livello Microscopico al Macroscopico: Il Concetto di Mole\n\n\nUnità di Massa Atomica (UMA): Gli UMA sono unità piccolissime (1/12 della massa del carbonio-12). In laboratorio si usano grammi, kg, tonnellate.\n\n\nLa Mole come Ponte: La mole è la “moneta di scambio” tra il livello microscopico (UMA) e macroscopico (grammi).\n\nSe un atomo di elio pesa come quattro atomi di idrogeno, allora n atomi di elio peseranno come 4_n_ atomi di idrogeno.\nSi sceglie un n sufficientemente grande per cui 4 g di elio contengono tanti atomi quanti 1 g di idrogeno.\n\n\n\nNumero di Avogadro (Na): È il valore di n che rende la massa molecolare in uma uguale alla massa in grammi. Na = 6,022 x 10^23.\n\n\n1 g di idrogeno (massa 1 uma) contiene 6,022 x 10^23 atomi.\n4 g di elio (massa 4 uma) contengono lo stesso numero di atomi.\n\n\n\nDefinizione di Mole (2018): Una mole contiene esattamente un numero di Avogadro di particelle.\n\nEsempio: una mole di molecole d’acqua = 6,02 x 10^23 molecole d’acqua.\n\n\n\nMassa Molare: È la massa di una mole di una sostanza, espressa in grammi.\n\nUna mole di atomi di carbonio pesa 12,01 g (massa atomica del carbonio dalla tavola periodica convertita in grammi).\nEsempio: la massa molare del carbonio è 12,01 g/mol.\n\n\n\nStechiometria di Reazione ed Equazioni Chimiche\n\n\nDefinizione: La stechiometria di reazione indica i rapporti in massa dei componenti in una reazione chimica.\n\n\nEquazioni Chimiche: Devono essere bilanciate per rispettare la conservazione della massa.\n\nI coefficienti stechiometrici sono i numeri davanti ai reagenti e prodotti che bilanciano l’equazione.\n\n\n\nEsempio del Panino: 1 pane + 1 carne + 2 formaggio + 5 cetrioli → 1 panino\n\nI coefficienti stechiometrici indicano il rapporto molare tra i componenti.\n\n\n\nEsempio della Combustione del Metano: CH4 + O2 → CO2 + H2O (non bilanciata)\n\n\nBilanciamento: CH4 + 2 O2 → CO2 + 2 H2O\n\n\nSignificato: 1 mole di metano reagisce con 2 moli di ossigeno.\n\n\nTraduzione in grammi: 16 g di metano reagiscono con 64 g di ossigeno.\n\n\n\n\nConservazione della Massa: La somma delle masse dei reagenti deve essere uguale alla somma delle masse dei prodotti. Il numero di moli non si conserva necessariamente.\n\n\nLivelli di Analisi: Macroscopico (ciò che si osserva), Microscopico (composizione a livello atomico/molecolare), Simbolico (equazioni chimiche).\n\n\nEsempio del Magnesio che Brucia:\n\nMacroscopico: Magnesio metallico brucia producendo un fumo bianco e un prodotto bianco.\nMicroscopico: Atomi di magnesio e molecole di ossigeno si ricombinano. Il prodotto è un reticolo di ioni Mg2+ e O2-.\nSimbolico: Mg(s) + O2(g) → MgO(s) (non bilanciata).\nBilanciata: 2Mg(s) + O2(g) → 2MgO(s).\n\n\n\n\n\nReagente Limitante\n\nIl reagente limitante è il reagente che determina la quantità massima di prodotto che si può formare in una reazione chimica. Per identificarlo, bisogna confrontare le quantità disponibili dei reagenti con i loro coefficienti stechiometrici.\nProcedura:\n\nContare gli ingredienti in moli: Convertire la quantità di ciascun reagente in moli.\nDividere per il coefficiente stechiometrico: Dividere il numero di moli di ciascun reagente per il suo coefficiente stechiometrico nell’equazione bilanciata.\nConfrontare i rapporti: Il reagente con il rapporto più basso è il reagente limitante.\n\nEsempio:\nConsideriamo la preparazione di un panino. La “ricetta” è:\n\n1 panino\n1 fetta di carne\n2 fette di formaggio\n5 cetrioli\n\nSe abbiamo:\n\n3 panini\n10 fette di carne\n20 fette di formaggio\n50 cetrioli\n\nDividiamo ciascuna quantità per il coefficiente stechiometrico corrispondente:\n\nPanini: 3 / 1 = 3\nCarne: 10 / 1 = 10\nFormaggio: 20 / 2 = 10\nCetrioli: 50 / 5 = 10\n\nIl rapporto più basso è 3, corrispondente ai panini. Quindi, il reagente limitante sono i panini: possiamo fare solo 3 panini.\n\nCalcolo dell’eccesso: Possiamo anche calcolare quanto rimane degli altri ingredienti.\n\nFormaggio avanzato: 20 - (3 * 2) = 14 fette\nCetrioli avanzati: 50 - (3 * 5) = 35 cetrioli\n\n\n\nResa Percentuale\nLa resa percentuale indica quanto prodotto si ottiene effettivamente rispetto alla quantità massima teorica possibile.\nFormula:\nResa percentuale = (Quantità di prodotto effettivamente ottenuta / Quantità massima teorica ottenibile) * 100\n\n\nQuantità effettivamente ottenuta: La quantità di prodotto misurata sperimentalmente.\nQuantità massima teorica: La quantità di prodotto calcolata in base al reagente limitante.\n\nEsempio:\nSe teoricamente dovremmo ottenere 3.5 grammi di ossido di magnesio (MgO), ma ne otteniamo solo 3.3 grammi, la resa percentuale è:\nResa percentuale = (3.3 g / 3.5 g) * 100 = 94.29%\n\nReazione Quantitativa:\nUna reazione con una resa del 100% è detta quantitativa.\nPossibili Cause di Resa Inferiore al 100%:\n\nErrori sperimentali: Perdita di prodotto durante la manipolazione.\nReazioni secondarie: Formazione di sottoprodotti indesiderati.\n\nNomenclatura Chimica\nLa nomenclatura chimica è un sistema di regole per assegnare nomi univoci ai composti chimici, permettendo a tutti i chimici di comunicare in modo chiaro e preciso. L’IUPAC (International Union of Pure and Applied Chemistry) è l’organizzazione che si occupa di standardizzare la nomenclatura chimica.\nMetalli e Non Metalli\nLa tavola periodica può essere divisa in due zone principali:\n\n\nMetalli: Generalmente lucenti, buoni conduttori di elettricità, duttili e malleabili. Si trovano principalmente nella parte inferiore a sinistra della tavola periodica.\nNon Metalli: Generalmente solidi o gas, poco conduttivi e fragili. Si trovano nella parte superiore a destra della tavola periodica.\nSemimetalli: Elementi con proprietà intermedie tra metalli e non metalli, situati nella zona di confine tra le due categorie. Ai fini della nomenclatura, i semimetalli sono assimilati ai non metalli.\n\nNumero di Ossidazione\nIl numero di ossidazione (N.O.) rappresenta la carica che un atomo avrebbe se tutti i legami fossero ionici. È un concetto utile per la nomenclatura, anche se non sempre corrisponde alla reale distribuzione di carica.\nRegole per Assegnare il Numero di Ossidazione:\n\n\nElementi Liberi: Il numero di ossidazione di un atomo in un elemento libero è sempre zero. Esempio: He, Cl_2.\n\n\nSomma dei Numeri di Ossidazione:\n\nIn una specie neutra, la somma dei numeri di ossidazione è zero.\nIn uno ione, la somma dei numeri di ossidazione è uguale alla carica dello ione.\n\nEsempio: Fe^{3+}, N.O. = +3; MnO_4^-, la somma dei N.O. deve essere -1.\n\n\n\n\n\nMetalli dei Gruppi 1 e 2:\n\nI metalli del gruppo 1 hanno sempre N.O. +1.\nI metalli del gruppo 2 hanno sempre N.O. +2.\n\nEsempio: K in K_2CO_3 ha N.O. +1; Mg in Mg(NO_3)_2 ha N.O. +2.\n\n\n\n\n\nFluoro: Il fluoro ha sempre N.O. -1.\n\n\nIdrogeno: L’idrogeno ha N.O. +1, tranne quando è legato a un metallo, nel qual caso ha N.O. -1.\n\nEsempio: H in H_2O ha N.O. +1; H in NaH ha N.O. -1.\n\n\n\nOssigeno: L’ossigeno ha N.O. -2, tranne nei composti con il fluoro e nei perossidi (dove è -1).\n\nEsempio: O in H_2SO_4 ha N.O. -2; O in H_2O_2 ha N.O. -1.\n\n\n\nElementi dei Gruppi 15, 16 e 17: Quando si combinano con i metalli in composti binari, hanno N.O. rispettivamente -3, -2 e -1.\n\nEsempio: N in Li_3N ha N.O. -3; S in K_2S ha N.O. -2; I in MgI_2 ha N.O. -1.\n\n\n\nNomenclatura degli Ioni e Ossidi Metallici\n\nIoni Metallici (Cationi)\n\nDefinizione: I cationi metallici derivano da metalli che hanno perso elettroni.\nNomenclatura Generale: Si usa la formula “ione + nome del metallo”.\n\nEsempio: Na^+ si chiama ione sodio.\n\n\n\nMetalli con molteplicità di ossidazione\n\n\nAmbiguità: Nei metalli che possono avere diversi numeri di ossidazione, è necessario specificare quale numero di ossidazione è presente.\n\n\nNotazione di Stock: Si indica il numero di ossidazione con un numero romano tra parentesi dopo il nome del metallo.\n\nEsempio: Ione rame (I) per Cu^+.\n\n\n\nNomenclatura Tradizionale (suffissi oso e ico): Si usano i suffissi oso per il numero di ossidazione più basso e ico per il numero di ossidazione più alto, applicandoli al nome del metallo.\n\nEsempio:\n\nIone rameoso per Cu^+ (rame (I)).\nIone rameico per Cu^{2+} (rame (II)).\n\n\n\n\n\nOssidi Metallici\n\n\nDerivazione: Formalmente derivati dalla reazione di un metallo con l’ossigeno.\n\n\nNomenclatura: Si utilizza la formula “ossido di + nome del metallo”. L’ossigeno in questi composti è presente come ione O^{2-}.\n\nEsempio: Ossido di potassio (K_2O).\n\n\n\nMetalli con più numeri di ossidazione: Anche qui è necessario specificare il numero di ossidazione.\n\nEsempio:\n\nOssido di ferro (II) (FeO) o ossido ferroso.\nOssido di ferro (III) (Fe_2O_3) o ossido ferrico.\n\n\n\n\n\nIdrossidi Metallici\n\n\nDerivazione: Formalmente derivati dalla reazione di un ossido metallico con l’acqua. Contengono lo ione idrossido OH^-.\n\n\nNomenclatura: “Idrossido di + nome del metallo”.\n\nEsempio: Idrossido di potassio (KOH).\n\n\n\nEsempio pratico: Reazione dell’ossido di magnesio (MgO) con acqua per formare idrossido di magnesio (Mg(OH)_2). L’idrossido di magnesio, in sospensione, fa cambiare colore a un indicatore, evidenziando la presenza di ioni idrossido.\n\n\nIoni con più numeri di ossidazione:\n\nIdrossido ferrico (Fe(OH)_3).\n\n\n\nIdruri Metallici\n\nDerivazione: Derivano formalmente dalla combinazione di un metallo con l’idrogeno. In questi composti, l’idrogeno ha numero di ossidazione -1 e si presenta come ione H^-.\nNomenclatura: “Idruro di + nome del metallo”.\n\nEsempi:\n\nIdruro di sodio (NaH).\nIdruro di calcio (CaH_2).\n\n\n\n\n\nIdruri Non Metallici\n\nIdruri Molecolari: Composti binari di non metalli con idrogeno. Hanno nomi comuni (non sistematici).\n\nEsempi:\n\nAcqua (H_2O).\nMetano (CH_4).\nAmmoniaca (NH_3).\n\n\n\n\nIdracidi: Composti binari di idrogeno con non metalli che presentano proprietà acide. Hanno una nomenclatura sistematica.\n\nNomenclatura degli idracidiGli idracidi derivano da un non metallo e idrogeno se puri e anidri si considerano composti molecolari: suffisso -uro di idrogeno se in soluzione acquosa si considerano acidi: acido suffisso -idrico\n\\text{HCl} cloruro di idrogeno in acqua: acido cloridrico\n\n\n\n\nAnidridi (Ossidi Non Metallici)\n\nDerivazione: Derivano formalmente dalla reazione di un non metallo con l’ossigeno.\nNomenclatura: Ci sono due approcci:\n\n\nTradizionale: “Anidride + [prefisso]nome del non metallo[suffisso]” dove prefisso e suffisso dipendono dal numero di ossidazione.\n\n\nIUPAC (più semplice): Si usa un prefisso per indicare il numero di atomi di ossigeno presenti, seguito da “ossido di + nome del non metallo”.\n\n\nEsempi con lo zolfo (numeri di ossidazione +4 e +6):\n\nSO_2:\n\nTradizionale: Anidride solforosa.\nIUPAC: Diossido di zolfo.\n\n\nSO_3:\n\nTradizionale: Anidride solforica.\nIUPAC: Triossido di zolfo.\n\n\n\n\n\nse più di 2 si aggiunge ipo per il più basso e per per il più alto\n\n\n\n\nOssiacidi e Ossianioni\n\nOssiacidi: Acidi contenenti ossigeno, idrogeno e un altro elemento (spesso un non metallo).\n\nOssianioni: Ioni negativi derivati dagli ossiacidi per rimozione di uno o più ioni H^+.\n\n\nLa nomenclatura degli ossianioni cambia i suffissi rispetto agli acidi:\n\n-oso diventa -ito\n-ico diventa -ato\n\nEsempio: L’acido carbonico (H_2CO_3) forma lo ione carbonato (CO_3^{2-}).\n\n\n\n\n\nSali\n\n\nFormazione: Derivano dalla combinazione di cationi (generalmente metallici) e anioni (spesso ossianioni).\nNomenclatura: Si nomina prima l’anione e poi il catione.\n\nEsempio: Solfato di rame (II) (CuSO_4).\n\n\nSali idrati: Alcuni sali cristallizzano incorporando molecole d’acqua nella loro struttura.\n\nPer nominare questi sali, si aggiunge il termine “-idrato” preceduto da un prefisso che indica il numero di molecole d’acqua per unità formula del sale.\n\nEsempio: Solfato di rame (II) pentaidrato (CuSO_4 \\cdot 5H_2O).\n\n\n\n\n\n\nReazioni Redox\n\n\nDefinizione: Reazioni in cui cambia il numero di ossidazione di almeno uno degli elementi coinvolti. Implicano trasferimento di elettroni.\n\nOssidazione: Aumento del numero di ossidazione (perdita di elettroni).\nRiduzione: Diminuzione del numero di ossidazione (acquisto di elettroni).\n\n\n\nTerminologia:\n\nAgente riducente: Specie che causa la riduzione di un’altra specie ossidandosi a sua volta.\nAgente ossidante: Specie che causa l’ossidazione di un’altra specie riducendosi a sua volta.\n\n\n\n\nReferences"},"6--full-note/collegamenti":{"slug":"6--full-note/collegamenti","filePath":"6- full note/collegamenti.md","title":"collegamenti","links":["6--full-note/meccanica-lez05"],"tags":[],"content":"\nmeccanica-lez05  Rappresentazione Matematica dei Vincoli di Posizione con i  vincoli di automatica\n\n"},"6--full-note/fisica-1---Lez01":{"slug":"6--full-note/fisica-1---Lez01","filePath":"6- full note/fisica 1 - Lez01.md","title":"fisica 1 - Lez01","links":["tags/flashcard_finite","tags/revisione_zero","tags/riscritto_zero","3--tag/fisica-1","3--tag/sbobine"],"tags":["flashcard_finite","revisione_zero","riscritto_zero"],"content":"2025-02-21 16:20\n_Status: flashcard_finite revisione_zero riscritto_zero\n_Tags: fisica 1   sbobine\nlez01- fisica 1\nEcco una rielaborazione della spiegazione del professore, integrata con dettagli, esempi, e passaggi matematici cruciali, presentata in formato flashcard per facilitare lo studio e la memorizzazione.\nFlashcard: Fisica Sperimentale I\nParte Organizzativa del Corso\n\nProiezione in aula: Mantenere la proiezione sullo schermo per chi ha difficoltà a vedere la lavagna.\nRegistrazioni: Le lezioni saranno registrate e disponibili subito dopo la lezione.\nFrequenza: La frequenza in presenza è caldamente consigliata per favorire l’interazione e lo scambio di informazioni tra studenti. Streaming non sarà disponibile regolarmente, ma potrebbe essere considerato se l’aula non permette una buona fruizione della lezione a tutti.\nPersone di riferimento: Individuare un paio di persone di riferimento nella classe per condividere problematiche comuni.\nDocente: Daniela Comelli, docente del corso di Fisica Sperimentale 1.\nOrario lezioni: 4-6 ore di lezione a settimana.\nEsercitazioni: Esercitazioni tenute da Federico Simoni e Andrea Farina, utili per imparare a risolvere i problemi.\nCalendario: Consultare il calendario delle attività didattiche pubblicato settimanalmente.\nTutorato: Attività didattica non obbligatoria, con incontri tenuti insieme all’altra classe (MZ), per risolvere problemi.\nSito del corso: Consultare il sito del corso su Wibip per informazioni sull’organizzazione, esercizi proposti per le esercitazioni e temi d’esame degli anni passati con soluzioni. Non ci saranno dispense, quindi è importante prendere appunti.\n\nModalità d’Esame\n\nProve in itinere: Sono previste due prove scritte in itinere. La prima si terrà il 9 aprile e la seconda il 20 giugno. Ogni prova sarà composta da tre problemi, di cui uno potrebbe essere una domanda di teoria.\nVoto: Il voto finale è la media delle due prove in itinere, se entrambe sufficienti (&gt;=18).\nAppelli d’esame: In alternativa, è possibile sostenere un’unica prova scritta su tutto il programma, della durata di 2 ore e composta da quattro problemi, di cui uno potrebbe essere di teoria.\nDate appelli: Gli appelli sono previsti il 20 giugno, 7 luglio, 9 settembre, e altri due a gennaio e febbraio 2026 (date non ancora definite).\nOrale integrativo: Dopo aver superato le prove scritte (in itinere o appello), è possibile sostenere un orale integrativo facoltativo per migliorare il voto. L’orale verte su tutti gli argomenti del corso.\n\nProgramma del Corso\n\nArgomenti: Il corso copre argomenti di meccanica e termodinamica.\nMeccanica: Si suddivide in cinematica (studio del movimento) e dinamica (studio delle cause del moto).\n\nCinematica: Studia il movimento di un corpo indipendentemente dalle cause che lo determinano.\nDinamica: Studia le cause del moto di un corpo, ovvero le interazioni e le forze.\nPunto materiale: Inizialmente, si approssima l’oggetto come un punto materiale.\nSistemi di punti materiali: Successivamente, si studia la meccanica di sistemi di punti materiali.\nCorpo rigido: Infine, si introduce il concetto di corpo rigido, un corpo esteso non deformabile.\n\n\nTermodinamica: Introduce i concetti di temperatura e scambi di calore, e la loro trasformazione in energia meccanica e viceversa.\n\nFisica Sperimentale: Metodo Scientifico\n\nFisica: Deriva dal greco “physis” (natura) e si occupa dello studio di alcuni fenomeni naturali.\nMetodo sperimentale: Si basa sull’osservazione dei fenomeni, la riproduzione semplificata in laboratorio (esperimenti), e la formulazione di teorie fisiche espresse in leggi matematiche.\nLeggi fisiche: Sono sintesi di teorie, espresse in linguaggio matematico, valide in un certo ambito. È importante capire il campo di validità e il significato fisico di una legge.\n\nGrandezze Fisiche\n\nScalari: Completamente definite da valore e unità di misura (es. massa, temperatura).\nVettoriali: Richiedono valore, direzione e verso per essere completamente definite (es. spostamento, forza).\n\nMetrologia e Unità di Misura\n\nMisura: Confronto con un’unità di misura di riferimento.\nSistema Internazionale (SI): Definisce sette grandezze fondamentali con le relative unità di misura.\n\nGrandezze fondamentali: massa (kilogrammo), lunghezza (metro), tempo (secondo), temperatura (kelvin), quantità di materia (mole), intensità di corrente elettrica (ampere), intensità luminosa (candela).\nGrandezze derivate: Derivate dalle grandezze fondamentali tramite leggi fisiche (es. velocità = spazio/tempo).\n\n\nImportanza dell’unità di misura: Fondamentale per dare significato a un valore.\nDimensioni di una grandezza: Rappresentazione formale delle unità di misura utilizzate (es. [v] = LT^{-1}).\n\nCinematica del Punto Materiale\n\nPunto materiale: Approssimazione di un oggetto con dimensioni trascurabili.\n\nHa senso quando le dimensioni sono piccole rispetto allo spazio percorso o quando interessa solo il movimento senza rotazione.\n\n\nCinematica: Studio del moto indipendentemente dalle cause.\nDefinire il moto: Conoscere la posizione dell’oggetto in ogni istante di tempo.\nRiferimenti fondamentali: Sistema di riferimento (per definire la posizione) e orologio (per misurare il tempo).\nSistema di riferimento: Può essere cartesiano (x, y, z) o altro, scelto per semplificare la descrizione.\nVettore posizione: Vettore che congiunge l’origine del sistema di riferimento con la posizione del punto materiale. Conoscere il vettore posizione in ogni istante di tempo equivale a conoscere tutto del moto.\nCoordinate cartesiane: In alternativa al vettore posizione, si possono usare le coordinate cartesiane (x(t), y(t), z(t)).\n\nTraiettoria\n\nDefinizione: Luogo dei punti occupati dal punto materiale mentre si muove.\nCinematica scalare: Mette in evidenza la traiettoria.\nVerso di percorrenza: Definito sulla traiettoria.\nOrigine: Punto di riferimento sulla traiettoria.\nAscissa curvilinea (s): Spazio percorso sulla traiettoria rispetto all’origine.\n\nÈ una grandezza scalare con dimensioni di lunghezza.\nPuò essere positiva o negativa a seconda della posizione rispetto all’origine e al verso.\n\n\nLegge oraria: Relazione che descrive come evolve l’ascissa curvilinea nel tempo, s(t).\nTipi di moto: Rettilineo, circolare, elicoidale.\nDiagramma orario: Grafico che rappresenta la legge oraria, s(t). Permette di visualizzare come si muove il punto materiale sulla traiettoria.\n\nEsempio di Diagramma Orario\nConsideriamo un punto materiale che si muove su una retta orizzontale. Il diagramma orario mostra come varia la sua posizione nel tempo.\n\nDa 0 a T1: Il punto è fermo a una posizione iniziale s0.\nDopo T1: Il punto inizia a muoversi verso destra (ascissa curvilinea aumenta) fino a raggiungere una posizione massima sMax.\nSuccessivamente: Il punto inverte il moto e torna indietro, superando l’origine.\n\nFormule Utili\n\nPosizione angolare: \\theta = \\frac{s}{R}\nVelocità angolare: \\omega = \\frac{d\\theta}{dt}\nAccelerazione angolare: \\alpha = \\frac{d\\omega}{dt}\nVelocità scalare: v = R\\omega\nAccelerazione scalare: a = R\\alpha\nVettore posizione: \\overrightarrow{r}(t) = x(t) \\hat{i} + y(t) \\hat{j} + z(t) \\hat{k}\nVettore spostamento medio: \\overrightarrow{v}_{media} = \\frac{\\Delta \\overrightarrow{r}}{\\Delta t} = \\frac{\\overrightarrow{r}(t_2) - \\overrightarrow{r}(t_1)}{t_2 - t_1}\nVelocità vettoriale istantanea: \\overrightarrow{v}(t) = \\frac{dx}{dt} \\hat{i} + \\frac{dy}{dt} \\hat{j} + \\frac{dz}{dt} \\hat{k} = v_x(t) \\hat{i} + v_y(t) \\hat{j} + v_z(t) \\hat{k}\n\n\nGrandezze Fondamentali e Derivate nel Sistema Internazionale di Misura\nIntroduzione alle Grandezze e Unità di Misura\nNel contesto della misurazione, si distinguono grandezze fondamentali e grandezze derivate. Il Sistema Internazionale delle Unità di Misura (SI), adottato globalmente (eccetto in alcuni paesi che usano il sistema britannico), definisce sette grandezze fondamentali con le relative unità di misura. Queste unità sono create per essere costanti nel tempo, uniformi in ogni luogo e facili da usare.\nLe Sette Grandezze Fisiche Fondamentali\n\nMassa: La cui unità di misura è il kilogrammo (kg).\nLunghezza: La cui unità di misura è il metro (m).\nIntervallo di Tempo (Durata di un Evento): La cui unità di misura è il secondo (s).\nTemperatura: Misurata in gradi Kelvin (K). Il grado Kelvin prende il nome dallo scienziato Kelvin e si scrive con lettera minuscola quando scritto per esteso. Il simbolo è invece K (maiuscolo).\nQuantità di Materia: Misurata in moli (mol).\nIntensità di Corrente Elettrica: Misurata in ampere (A) (incontrata in fisica 2). Amper si scrive con lettera minuscola quando scritto per esteso.\nIntensità Luminosa: Misurata in candele.\n\nDefinizione e Importanza delle Unità di Misura\nLe unità di misura devono essere facili da definire e mantenere la loro misura costante nel tempo. Inizialmente, il metro era definito come una frazione della lunghezza del meridiano passante per Parigi. Attualmente, è legato alla velocità della luce nel vuoto, definendo 1 metro come lo spazio percorso dalla luce in un intervallo di tempo pari all’inverso della velocità della luce. Similmente, il kilogrammo, precedentemente legato a un campione fisico conservato, è stato ridefinito nel 2018 collegandolo alla costante di Planck.\nGrandezze Derivate\nLe grandezze derivate sono misurate indirettamente, attraverso leggi fisiche che legano queste grandezze alle grandezze fondamentali.\n\n\nEsempio: Velocità Media La velocità media è definita come lo spazio percorso (\\Delta x) diviso per l’intervallo di tempo (\\Delta t) impiegato per percorrerlo:\nv = \\frac{\\Delta x}{\\Delta t}\nDimensionalmente, la velocità è espressa come:\n[v] = \\frac{[L]}{[T]} = [L][T]^{-1}\nDove [L] rappresenta la dimensione della lunghezza (metro) e [T] rappresenta la dimensione del tempo (secondi). Quindi, l’unità di misura della velocità è metri al secondo (m/s).\n\n\nImportanza dell’Unità di Misura Ogni risultato sperimentale o calcolo deve essere sempre accompagnato dall’unità di misura appropriata. Un valore numerico senza unità di misura è privo di significato.\n\n\nRappresentazione Dimensionale\nPer indicare le dimensioni di una grandezza fisica, si utilizza la seguente notazione:\n\n[L] rappresenta la dimensione della lunghezza.\n[v] rappresenta la dimensione della velocità.\n\nEsempio: la dimensione della velocità scalare media v è data da:\n[v] = [L][T]^{-1}\nQuesto indica che la velocità è misurata in metri al secondo (m/s).\nSpero che questa risposta ti sia utile e completa!\nReferences"},"6--full-note/fisica-1--Lez02":{"slug":"6--full-note/fisica-1--Lez02","filePath":"6- full note/fisica 1- Lez02.md","title":"fisica 1- Lez02","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/fisica-1","3--tag/sbobine"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-02-21 16:40\n_Status: flashcard_zero   riscritto_zero   revisione_zero\n_Tags:  fisica 1    sbobine\nLez02- fisica 1\nTrattazione Scalare della Cinematica del Punto Materiale\nNella trattazione scalare della cinematica del punto materiale, si considera un punto materiale che si muove lungo una traiettoria nota \\gamma. Questa traiettoria è definita da una legge dello spazio, che può essere espressa in coordinate cartesiane come l’intersezione tra due superfici.\nAscissa Curvilinea e Legge Oraria\nUna volta nota la traiettoria, il moto del punto materiale può essere descritto attraverso l’ascissa curvilinea s(t), che rappresenta la lunghezza del percorso lungo la traiettoria a partire da un’origine \\Omega fissata, con un verso positivo definito. La funzione s(t) è nota in ogni istante di tempo e viene chiamata legge oraria del moto. Conoscere la traiettoria e la legge oraria permette di descrivere completamente il moto del punto materiale nello spazio.\n\nEsempio: Immagina una traiettoria complessa nello spazio. Si definisce un’origine \\Omega e un verso positivo. Per una posizione del punto materiale all’istante t, l’ascissa curvilinea è la lunghezza del percorso da \\Omega a quel punto, presa come positiva se il punto si trova nel verso positivo rispetto all’origine, negativa altrimenti.\n\nLa legge oraria s(t) può essere rappresentata sia come funzione analitica del tempo, sia attraverso un grafico chiamato diagramma orario.\n\nEsempio di diagramma orario: Un punto è inizialmente fermo a distanza s_0 dall’origine all’istante t_0 = 0. Rimane fermo per un certo tempo, poi inizia ad allontanarsi dall’origine, si ferma di nuovo e infine torna indietro rapidamente, attraversando l’origine.\n\nVelocità Scalare\nVelocità Scalare Media\nLa velocità scalare media v_m in un intervallo di tempo \\Delta t = t_2 - t_1 è definita come la variazione dell’ascissa curvilinea divisa per l’intervallo di tempo:\nv_m = \\frac{s(t_2) - s(t_1)}{t_2 - t_1} = \\frac{\\Delta s}{\\Delta t}\nLe dimensioni di una velocità sono il rapporto tra una lunghezza e un tempo, quindi nel sistema internazionale si misurano in metri al secondo (m/s).\nIl segno della velocità indica la direzione del moto rispetto al verso positivo scelto sulla traiettoria. Una velocità positiva indica che il punto si muove nel verso positivo, mentre una velocità negativa indica che si muove nel verso opposto.\nGeometricamente, la velocità scalare media corrisponde alla pendenza della retta secante il diagramma orario nei punti t_1 e t_2.\nVelocità Scalare Istantanea\nLa velocità scalare istantanea v(t) è definita come il limite della velocità scalare media quando l’intervallo di tempo \\Delta t tende a zero:\nv(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta s}{\\Delta t} = \\frac{ds}{dt}\nQuindi, la velocità istantanea è la derivata dell’ascissa curvilinea rispetto al tempo. Geometricamente, corrisponde alla pendenza della retta tangente al diagramma orario in un dato istante t.\nAccelerazione Scalare\nAccelerazione Scalare Media\nL’accelerazione scalare media a_m in un intervallo di tempo \\Delta t = t_2 - t_1 è definita come la variazione della velocità scalare divisa per l’intervallo di tempo:\na_m = \\frac{v(t_2) - v(t_1)}{t_2 - t_1} = \\frac{\\Delta v}{\\Delta t}\nLe dimensioni di un’accelerazione sono il rapporto tra una velocità e un tempo, quindi nel sistema internazionale si misurano in metri al secondo quadrato (m/s^2).\nUn’accelerazione positiva indica un aumento della velocità, mentre un’accelerazione negativa indica una diminuzione della velocità (decelerazione).\nGeometricamente, l’accelerazione scalare media rappresenta la pendenza della retta secante il grafico della velocità in funzione del tempo nei punti t_1 e t_2.\nAccelerazione Scalare Istantanea\nL’accelerazione scalare istantanea a(t) è definita come il limite dell’accelerazione scalare media quando l’intervallo di tempo \\Delta t tende a zero:\na(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta v}{\\Delta t} = \\frac{dv}{dt}\nL’accelerazione istantanea è quindi la derivata della velocità rispetto al tempo. Geometricamente, corrisponde alla pendenza della retta tangente al grafico della velocità in funzione del tempo in un dato istante t.\nProblema Inverso della Cinematica\nIl problema inverso della cinematica consiste nel determinare la legge oraria s(t) a partire dalla conoscenza dell’accelerazione a(t) e della traiettoria. Questo problema richiede l’integrazione successiva dell’accelerazione per ottenere la velocità e poi l’ascissa curvilinea.\nCalcolo della Velocità a Partire dall’Accelerazione\nDalla definizione di accelerazione istantanea a(t) = \\frac{dv}{dt}, si può ricavare la variazione infinitesima della velocità dv = a(t) dt. Integrando entrambi i membri tra un istante iniziale t_0 e un istante generico t, si ottiene:\n\\int_{t_0}^{t} a(t&#039;) dt&#039; = \\int_{v(t_0)}^{v(t)} dv&#039;\nv(t) = v(t_0) + \\int_{t_0}^{t} a(t&#039;) dt&#039;\nDove v(t_0) è la velocità iniziale del punto materiale.\nCalcolo dell’Ascissa Curvilinea a Partire dalla Velocità\nAnalogamente, dalla definizione di velocità istantanea v(t) = \\frac{ds}{dt}, si ricava ds = v(t) dt. Integrando entrambi i membri tra t_0 e t, si ottiene:\n\\int_{t_0}^{t} v(t&#039;) dt&#039; = \\int_{s(t_0)}^{s(t)} ds&#039;\ns(t) = s(t_0) + \\int_{t_0}^{t} v(t&#039;) dt&#039;\nDove s(t_0) è la posizione iniziale del punto materiale.\nQuindi, per risolvere il problema inverso, è necessario conoscere l’accelerazione a(t) e le condizioni iniziali per la velocità v(t_0) e la posizione s(t_0).\nEsempi di Moti Particolari\nMoto Uniforme\nNel moto uniforme, l’accelerazione è nulla (a(t) = 0). La velocità rimane costante e pari alla velocità iniziale v(t) = v_0. La legge oraria è data da:\ns(t) = s_0 + v_0 (t - t_0)\nDove s_0 è la posizione iniziale all’istante t_0. Il diagramma orario è una retta con pendenza v_0.\nMoto Uniformemente Accelerato\nNel moto uniformemente accelerato, l’accelerazione è costante (a(t) = a_0). La velocità varia linearmente nel tempo:\nv(t) = v_0 + a_0 (t - t_0)\nLa legge oraria è data da:\ns(t) = s_0 + v_0 (t - t_0) + \\frac{1}{2} a_0 (t - t_0)^2\nDove s_0 è la posizione iniziale e v_0 la velocità iniziale. Il diagramma orario è una parabola.\nEsempio di Applicazione: Moto di un Proiettile\nConsideriamo il moto di un punto materiale lanciato verticalmente verso l’alto con una velocità iniziale v_0. La traiettoria è rettilinea verticale, con origine al suolo e verso positivo verso l’alto. L’accelerazione è costante e pari all’accelerazione di gravità, diretta verso il basso (a(t) = -g, con g = 9.81 m/s^2).\nLe condizioni iniziali sono: posizione iniziale y(0) = h (altezza iniziale) e velocità iniziale v(0) = v_0.\nIntegrando l’accelerazione, si ottiene la velocità:\nv(t) = v_0 - gt\nIntegrando la velocità, si ottiene la legge oraria:\ny(t) = h + v_0 t - \\frac{1}{2} gt^2\nPer trovare l’istante t^* in cui il punto raggiunge la massima quota, si pone v(t^*) = 0:\nv_0 - gt^* = 0\nt^* = \\frac{v_0}{g}\nQuesto risultato può essere verificato dimensionalmente, mostrando che le dimensioni di \\frac{v_0}{g} sono quelle di un tempo.\n\nCinematica del Punto Materiale: Trattazione Scalare\nNella trattazione scalare della cinematica, si considera un punto materiale che si muove lungo una traiettoria nota \\gamma. La traiettoria è definita da una legge nello spazio, ad esempio tramite equazioni cartesiane.\nAscissa Curvilinea e Legge Oraria\nPer descrivere il moto del punto materiale sulla traiettoria, si introduce l’ascissa curvilinea s(t), che rappresenta la lunghezza del percorso lungo la traiettoria a partire da un’origine fissata \\Omega. La funzione s(t) è nota in ogni istante di tempo e prende il nome di legge oraria del moto.\n\nDefinizione di Ascissa Curvilinea: Immaginando una traiettoria complessa, si fissa un’origine \\Omega e un verso positivo. La posizione del punto materiale all’istante t è data dalla lunghezza del tratto di traiettoria tra \\Omega e il punto, presa con segno positivo se il punto si trova nel verso positivo, negativo altrimenti.\n\nVelocità\nVelocità Media\nLa velocità scalare media v_m in un intervallo di tempo \\Delta t = t_2 - t_1 è definita come la variazione dell’ascissa curvilinea divisa per l’intervallo di tempo:\nv_m = \\frac{s(t_2) - s(t_1)}{t_2 - t_1} = \\frac{\\Delta s}{\\Delta t}\nDimensionalmente, la velocità è il rapporto tra una lunghezza e un tempo. Il segno della velocità indica la direzione del moto rispetto al verso positivo scelto sulla traiettoria.\nGeometricamente, la velocità media corrisponde alla pendenza della retta secante il diagramma orario nei punti t_1 e t_2.\nVelocità Istantanea\nLa velocità scalare istantanea v(t) è definita come il limite della velocità media quando l’intervallo di tempo \\Delta t tende a zero:\nv(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta s}{\\Delta t} = \\frac{ds}{dt}\nLa velocità istantanea è la derivata della legge oraria rispetto al tempo. Geometricamente, la velocità istantanea corrisponde alla pendenza della retta tangente al diagramma orario in un dato istante t.\nAccelerazione\nAccelerazione Media\nL’accelerazione scalare media a_m in un intervallo di tempo \\Delta t = t_2 - t_1 è definita come la variazione della velocità divisa per l’intervallo di tempo:\na_m = \\frac{v(t_2) - v(t_1)}{t_2 - t_1} = \\frac{\\Delta v}{\\Delta t}\nDimensionalmente, l’accelerazione è il rapporto tra una velocità e un tempo, quindi una lunghezza divisa per il tempo al quadrato. Il segno dell’accelerazione indica se la velocità sta aumentando (accelerazione positiva) o diminuendo (accelerazione negativa).\nAccelerazione Istantanea\nL’accelerazione scalare istantanea a(t) è definita come il limite dell’accelerazione media quando l’intervallo di tempo \\Delta t tende a zero:\na(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta v}{\\Delta t} = \\frac{dv}{dt}\nL’accelerazione istantanea è la derivata della velocità rispetto al tempo. Derivando graficamente la velocità, si considera la retta tangente al grafico della velocità in ogni istante di tempo e si guarda la pendenza di questa retta.\nRelazione tra Ascissa Curvilinea, Velocità e Accelerazione\nIn sintesi, si ha:\n\nVelocità: v(t) = \\frac{ds}{dt}\nAccelerazione: a(t) = \\frac{dv}{dt} = \\frac{d^2s}{dt^2}\n\nProblema Inverso della Cinematica\nIl problema inverso della cinematica consiste nel ricavare la legge oraria s(t) a partire dalla conoscenza dell’accelerazione a(t). Questo problema è rilevante perché, studiando la dinamica, si può dedurre l’accelerazione di un oggetto a partire dalle forze agenti su di esso.\nIntegrazione e Condizioni Iniziali\nPer ricavare la legge oraria dall’accelerazione, è necessario integrare due volte. Tuttavia, l’integrazione introduce costanti arbitrarie, quindi è necessario conoscere le condizioni iniziali del moto. Le condizioni iniziali specificano la posizione s(t_0) e la velocità v(t_0) del punto materiale all’istante iniziale t_0.\nPassaggi Matematici\n\n\nRicavare la Velocità dall’Accelerazione:\nSi parte dalla definizione di accelerazione istantanea:\na(t) = \\frac{dv}{dt}\nSi separa le variabili e si integra:\ndv = a(t) dt\n\\int_{v(t_0)}^{v(t)} dv = \\int_{t_0}^{t} a(t&#039;) dt&#039;\nv(t) - v(t_0) = \\int_{t_0}^{t} a(t&#039;) dt&#039;\nv(t) = v(t_0) + \\int_{t_0}^{t} a(t&#039;) dt&#039;\nDove v(t_0) è la velocità iniziale.\n\n\nRicavare l’Ascissa Curvilinea dalla Velocità:\nSi parte dalla definizione di velocità istantanea:\nv(t) = \\frac{ds}{dt}\nSi separa le variabili e si integra:\nds = v(t) dt\n\\int_{s(t_0)}^{s(t)} ds = \\int_{t_0}^{t} v(t&#039;) dt&#039;\ns(t) - s(t_0) = \\int_{t_0}^{t} v(t&#039;) dt&#039;\ns(t) = s(t_0) + \\int_{t_0}^{t} v(t&#039;) dt&#039;\nDove s(t_0) è la posizione iniziale.\n\n\nIn sintesi, per risolvere il problema inverso, si integrano due volte l’accelerazione, utilizzando le condizioni iniziali per determinare le costanti di integrazione.\nEsempi di Moti Particolari\nMoto Uniforme\nIl moto uniforme è caratterizzato da accelerazione nulla: a(t) = 0.\n\nVelocità: Integrando l’accelerazione, si ottiene una velocità costante: v(t) = v_0.\nLegge Oraria: Integrando la velocità, si ottiene una legge oraria lineare: s(t) = s_0 + v_0 (t - t_0).\n\nIl diagramma orario è una retta la cui pendenza rappresenta la velocità.\nMoto Uniformemente Accelerato\nIl moto uniformemente accelerato è caratterizzato da accelerazione costante: a(t) = a_0.\n\nVelocità: Integrando l’accelerazione, si ottiene una velocità che varia linearmente nel tempo: v(t) = v_0 + a_0 (t - t_0).\nLegge Oraria: Integrando la velocità, si ottiene una legge oraria quadratica: s(t) = s_0 + v_0 (t - t_0) + \\frac{1}{2} a_0 (t - t_0)^2.\n\nIl diagramma orario è una parabola.\nEsempio: Moto di un Proiettile Lanciato Verticalmente\nSi consideri un punto materiale lanciato verticalmente verso l’alto con una velocità iniziale v_0. L’accelerazione è costante e pari all’accelerazione di gravità, diretta verso il basso: a(t) = -g.\n\n\nDefinizione del sistema di riferimento: Si sceglie un asse verticale y con origine al suolo e verso positivo verso l’alto.\n\n\nCondizioni iniziali:\n\ny(t_0) = h, dove h è l’altezza iniziale.\nv(t_0) = v_0, positiva perché diretta verso l’alto.\n\n\n\nVelocità: Integrando l’accelerazione, si ottiene: v(t) = v_0 - gt.\n\n\nLegge Oraria: Integrando la velocità, si ottiene: y(t) = h + v_0t - \\frac{1}{2}gt^2.\n\n\nTempo per raggiungere la massima quota: Si impone v(t) = 0 e si ricava t^* = \\frac{v_0}{g}.\n\n\nVerifica dimensionale\nVerifichiamo che t^* = \\frac{v_0}{g} abbia le dimensioni di un tempo.\n\n[v_0] = \\frac{L}{T} (lunghezza su tempo)\n[g] = \\frac{L}{T^2} (lunghezza su tempo al quadrato)\n\nQuindi, [\\frac{v_0}{g}] = \\frac{L/T}{L/T^2} = T, che ha le dimensioni di un tempo.\n\nEcco la spiegazione del professore, integrata con i dettagli dei PDF forniti, riguardo al moto uniformemente accelerato e alla sua derivazione matematica, con particolare attenzione ai passaggi, agli esempi e agli esercizi.\nMoto Uniformemente Accelerato: Derivazione della Legge Oraria\nDefinizioni Preliminari\n\nTraiettoria: Si assume che la traiettoria del punto materiale sia nota.\nAscissa curvilinea (s(t)): È la grandezza scalare che descrive la posizione del punto materiale lungo la traiettoria in funzione del tempo.\nLegge oraria: La funzione s(t) che descrive come l’ascissa curvilinea varia nel tempo.\n\nProblema Inverso della Cinematica\nL’obiettivo è ricavare la legge oraria s(t) a partire dalla conoscenza dell’accelerazione a(t) e delle condizioni iniziali.\nPassaggi Matematici\n\n\nRicavare la velocità v(t) dall’accelerazione a(t):\n\nSi parte dalla definizione di accelerazione istantanea: a(t) = \\frac{dv}{dt}\nSi separa le variabili: dv = a(t) , dt\nSi integra entrambi i membri: \\int_{t_0}^{t} a(t&#039;) , dt&#039; = \\int_{v(t_0)}^{v(t)} dv\nRisolvendo l’integrale, si ottiene: v(t) = v(t_0) + \\int_{t_0}^{t} a(t&#039;) , dt&#039; dove v(t_0) è la velocità iniziale.\n\n\n\nRicavare l’ascissa curvilinea s(t) dalla velocità v(t):\n\nSi parte dalla definizione di velocità istantanea: v(t) = \\frac{ds}{dt}\nSi separa le variabili: ds = v(t) , dt\nSi integra entrambi i membri: \\int_{t_0}^{t} v(t&#039;) , dt&#039; = \\int_{s(t_0)}^{s(t)} ds\nRisolvendo l’integrale, si ottiene: s(t) = s(t_0) + \\int_{t_0}^{t} v(t&#039;) , dt&#039; dove s(t_0) è la posizione iniziale. Condizioni Iniziali: Per risolvere il problema inverso, è necessario conoscere sia la velocità iniziale v_0 = v(t_0) che la posizione iniziale s_0 = s(t_0).\n\n\n\nEsempio di Moto Uniformemente Accelerato\n\nDefinizione: Moto con accelerazione costante a(t) = a_0.\nVelocità: v(t) = v_0 + \\int_{t_0}^{t} a_0 , dt&#039; = v_0 + a_0 (t - t_0)\nLegge Oraria: s(t) = s_0 + \\int_{t_0}^{t} [v_0 + a_0 (t&#039; - t_0)] , dt&#039; s(t) = s_0 + v_0 (t - t_0) + \\frac{1}{2} a_0 (t - t_0)^2\n\nCambio di Variabile\nPer semplificare l’integrale nella derivazione della legge oraria, si introduce un cambio di variabile:\n\nSi definisce t^* = t - t_0, quindi dt^* = dt.\nL’integrale diventa: \\int a_0 t^* , dt^* = a_0 \\frac{(t^*)^2}{2} = a_0 \\frac{(t - t_0)^2}{2}\n\nRisultato Finale\nLa legge oraria per il moto uniformemente accelerato è:\ns(t) = s_0 + v_0 (t - t_0) + \\frac{1}{2} a_0 (t - t_0)^2\nSe l’istante iniziale di osservazione è t_0 = 0, la legge si semplifica in:\ns(t) = s_0 + v_0 t + \\frac{1}{2} a_0 t^2\nGrafico della Legge Oraria\nLa legge oraria è una parabola, con concavità verso l’alto se a_0 &gt; 0 e verso il basso se a_0 &lt; 0.\nEsempio di Caduta di un Corpo\n\nDefinizione del problema:\n\nUn corpo viene lanciato verticalmente verso l’alto con velocità iniziale v_0 da un’altezza h rispetto al suolo.\nL’accelerazione è costante e pari all’accelerazione di gravità, a = -g (negativa perché diretta verso il basso).\n\n\nDefinizione delle condizioni iniziali:\n\ny(0) = h (posizione iniziale)\nv(0) = v_0 (velocità iniziale)\n\n\nCalcolo della velocità in funzione del tempo: v(t) = v_0 - gt\nCalcolo della posizione in funzione del tempo (legge oraria): y(t) = h + v_0 t - \\frac{1}{2} g t^2\nCalcolo del tempo per raggiungere la massima quota:\n\nSi imposta v(t^*) = 0 per trovare l’istante t^* in cui la velocità è zero (punto di massima quota).\nv_0 - gt^* = 0 \\Rightarrow t^* = \\frac{v_0}{g}\n\n\n\nAnalisi Dimensionale\nVerificare che le dimensioni fisiche delle equazioni siano coerenti. Ad esempio, per il tempo di massima quota t^* = \\frac{v_0}{g}:\n\n[t^*] = T (tempo)\n[\\frac{v_0}{g}] = \\frac{L/T}{L/T^2} = T Le dimensioni sono coerenti.\n\nSpero che questa riformulazione dettagliata e ben formattata ti sia utile.\nReferences"},"6--full-note/fisica-lez03'":{"slug":"6--full-note/fisica-lez03'","filePath":"6- full note/fisica-lez03'.md","title":"fisica-lez03'","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-04 17:59\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nfisica-lez03’\nRisoluzione del Problema Inverso della Cinematica Scalare nel Moto Uniformemente Accelerato\nSituazione Iniziale\nSi considera una situazione in cui è nota l’accelerazione costante nel tempo (a_0) e sono note le condizioni iniziali, ovvero la velocità (v_0) e la posizione (s_0) all’istante t_0.\nRicavare l’Andamento della Velocità nel Tempo\nLa velocità nel tempo si ricava integrando l’accelerazione nel tempo:\nv(t) = v_0 + \\int_{t_0}^{t} a(t&#039;) dt&#039;\nPoiché l’accelerazione è costante (a(t) = a_0), l’integrale diventa:\nv(t) = v_0 + \\int_{t_0}^{t} a_0 dt&#039; = v_0 + a_0(t - t_0)\nQuindi, la velocità varia linearmente con il tempo.\nRicavare la Legge Oraria\nLa legge oraria si ricava integrando la velocità nel tempo:\ns(t) = s_0 + \\int_{t_0}^{t} v(t&#039;) dt&#039;\nSostituendo l’espressione della velocità:\ns(t) = s_0 + \\int_{t_0}^{t} [v_0 + a_0(t&#039; - t_0)] dt&#039;\nSpezzando l’integrale in due parti:\ns(t) = s_0 + \\int_{t_0}^{t} v_0 dt&#039; + \\int_{t_0}^{t} a_0(t&#039; - t_0) dt&#039;\nIntegrando il primo termine:\n\\int_{t_0}^{t} v_0 dt&#039; = v_0 (t - t_0)\nPer il secondo integrale, si effettua una sostituzione di variabile:\n\\tau = t&#039; - t_0\nd\\tau = dt&#039;\nQuando t&#039; = t_0, \\tau = 0; quando t&#039; = t, \\tau = t - t_0. Quindi l’integrale diventa:\n\\int_{0}^{t - t_0} a_0 \\tau d\\tau = a_0 \\int_{0}^{t - t_0} \\tau d\\tau = a_0 \\left[ \\frac{\\tau^2}{2} \\right]_{0}^{t - t_0} = \\frac{1}{2} a_0 (t - t_0)^2\nMettendo insieme i risultati, si ottiene la legge oraria:\ns(t) = s_0 + v_0 (t - t_0) + \\frac{1}{2} a_0 (t - t_0)^2\nCaso Particolare: Se t_0 = 0:\ns(t) = s_0 + v_0 t + \\frac{1}{2} a_0 t^2\nOsservazioni sui Grafici\n\nAccelerazione Costante (Negativa): Si supponga di avere un corpo che viene rallentato, con accelerazione a_0 costante e negativa, ad esempio a_0 = -2 , \\text{m/s}^2.\nGrafico della Velocità: Se la velocità iniziale v_0 è positiva, il grafico della velocità è una retta che diminuisce linearmente nel tempo. La pendenza della retta è determinata dal valore di a_0.\nGrafico della Posizione: Se la posizione iniziale s_0 è positiva, il grafico della posizione è una parabola con concavità verso il basso. Inizialmente, il punto materiale aumenta la sua posizione perché ha una velocità positiva, ma questa velocità diminuisce fino a diventare zero nel vertice della parabola. A quel punto, il corpo inverte il suo moto e torna indietro verso l’origine.\n\nEsempio Concreto: Oggetto Lanciato Verticalmente\nSi considera un oggetto lanciato verticalmente verso l’alto da una quota iniziale H rispetto al pavimento.\n\nTraiettoria: La traiettoria è una retta verticale.\nAsse Orientato: Si sceglie un asse y orientato verso l’alto, con l’origine posizionata al livello del pavimento.\nAccelerazione: L’accelerazione è dovuta alla gravità ed è diretta verso il basso, quindi a = -g, dove g è l’accelerazione di gravità.\nCondizioni Iniziali:\n\nt_0 = 0 , \\text{s}\nv(0) = +v_0 (positiva perché l’oggetto è lanciato verso l’alto)\ny(0) = H\n\n\n\nRisoluzione del Problema\n\n\nVelocità nel Tempo:\nv(t) = v_0 + \\int_{0}^{t} (-g) dt&#039; = v_0 - gt\n\n\nPosizione nel Tempo (Legge Oraria):\ny(t) = H + \\int_{0}^{t} (v_0 - gt&#039;) dt&#039; = H + v_0 t - \\frac{1}{2}gt^2\n\n\nDomande\n\nIstante di Massima Quota (t_{\\text{max}}):\n\nSi impone che la velocità sia zero: v(t_{\\text{max}}) = 0.\nv_0 - gt_{\\text{max}} = 0\nt_{\\text{max}} = \\frac{v_0}{g}\nLa quota massima si trova sostituendo t_{\\text{max}} nella legge oraria: y(t_{\\text{max}}) = H + v_0 \\left(\\frac{v_0}{g}\\right) - \\frac{1}{2}g\\left(\\frac{v_0}{g}\\right)^2\n\n\nIstante Finale (t_{\\text{finale}}) in cui l’Oggetto Tocca il Pavimento:\n\nSi impone che la quota sia zero: y(t_{\\text{finale}}) = 0.\nH + v_0 t_{\\text{finale}} - \\frac{1}{2}gt_{\\text{finale}}^2 = 0\nQuesta è un’equazione di secondo grado in t_{\\text{finale}}. Risolvendo l’equazione, si troveranno due soluzioni: una positiva (quella che interessa) e una negativa (priva di significato fisico nel contesto del problema, ma matematicamente valida).\n\n\n\nApprossimazioni\nDurante gli esami, è accettabile approssimare g \\approx 10 , \\text{m/s}^2 se non si ha la calcolatrice a disposizione.\nCinematica Vettoriale\nLa cinematica vettoriale è utile quando non si conosce a priori la traiettoria del punto materiale. In questo caso, si descrive la posizione del punto materiale nello spazio tridimensionale usando un sistema di riferimento, ad esempio cartesiano.\nSistemi di riferimento\nOltre al sistema di riferimento cartesiano, esistono altri sistemi di riferimento come quello cilindrico e coordinate polari.\n\nEcco una spiegazione dettagliata del professore, basata sul flashcard fornito, con particolare attenzione ai passaggi matematici, agli esempi e agli esercizi, formattata per chiarezza e leggibilità.\nSistemi di riferimento e vettore posizione\n\nSistemi di coordinate alternativi: Oltre ai sistemi di riferimento standard, esistono sistemi di coordinate che utilizzano meridiani e paralleli su una sfera.\nSistema di riferimento cartesiano: In un sistema di riferimento cartesiano, la posizione di un punto nello spazio 3D è definita dal vettore posizione \\overrightarrow{r}(t), che congiunge l’origine del sistema di riferimento con la posizione del punto materiale.\nFunzione vettoriale: Definire una funzione vettoriale significa specificare tre funzioni scalari che descrivono la variazione della posizione del punto materiale lungo gli assi x, y e z: x(t), y(t) e z(t).\nLegge oraria del moto: La legge oraria del moto in forma vettoriale è rappresentata da \\overrightarrow{r}(t). In forma cartesiana, è data dalle tre equazioni x(t), y(t) e z(t).\n\nVelocità media e istantanea\n\n\nVelocità media vettoriale: La velocità media vettoriale \\overrightarrow{v}_m in un intervallo di tempo \\Delta t è definita come la variazione del vettore posizione divisa per l’intervallo di tempo:\n\\qquad \\overrightarrow{v}_m = \\frac{\\Delta \\overrightarrow{r}}{\\Delta t}\nDove \\Delta \\overrightarrow{r} = \\overrightarrow{r}(T_2) - \\overrightarrow{r}(T_1) è il vettore spostamento medio.\n\n\nComponenti della velocità media: La velocità media vettoriale può essere espressa attraverso le sue componenti cartesiane:\n\nv_{mx} = \\frac{\\Delta x}{\\Delta t} = \\frac{x_2 - x_1}{t_2 - t_1}\nv_{my} = \\frac{\\Delta y}{\\Delta t} = \\frac{y_2 - y_1}{t_2 - t_1}\nv_{mz} = \\frac{\\Delta z}{\\Delta t} = \\frac{z_2 - z_1}{t_2 - t_1}\n\n\n\nVelocità istantanea vettoriale: La velocità istantanea vettoriale \\overrightarrow{v}(t) è definita come il limite della velocità media per \\Delta t che tende a zero, ovvero la derivata del vettore posizione rispetto al tempo:\n\\qquad \\overrightarrow{v}(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta \\overrightarrow{r}}{\\Delta t} = \\frac{d\\overrightarrow{r}}{dt} = \\overrightarrow{r}&#039;(t)\n\n\nDerivata di un vettore: La derivata di un vettore \\overrightarrow{r}(t) = x(t)\\hat{u}_x + y(t)\\hat{u}_y + z(t)\\hat{u}_z si calcola derivando le sue componenti:\n\\qquad \\frac{d\\overrightarrow{r}}{dt} = \\frac{dx}{dt}\\hat{u}_x + \\frac{dy}{dt}\\hat{u}_y + \\frac{dz}{dt}\\hat{u}_z\n\n\nComponenti della velocità istantanea: La velocità istantanea vettoriale può essere espressa attraverso le sue componenti cartesiane:\n\nv_x = \\frac{dx}{dt}\nv_y = \\frac{dy}{dt}\nv_z = \\frac{dz}{dt}\n\nDare il vettore velocità vettoriale istantanea è equivalente a scomporlo nelle sue componenti cartesiane e a vedere come varia nel tempo la posizione del punto materiale lungo x, y e z, il che equivale a dare tre velocità scalari che sono le componenti della velocità sui tre assi.\n\n\nAccelerazione media e istantanea\n\n\nAccelerazione media vettoriale: L’accelerazione media vettoriale \\overrightarrow{a}_m in un intervallo di tempo \\Delta t è definita come la variazione del vettore velocità divisa per l’intervallo di tempo:\n\\qquad \\overrightarrow{a}_m = \\frac{\\Delta \\overrightarrow{v}}{\\Delta t}\n\n\nAccelerazione istantanea vettoriale: L’accelerazione istantanea vettoriale \\overrightarrow{a}(t) è definita come il limite dell’accelerazione media per \\Delta t che tende a zero, ovvero la derivata del vettore velocità rispetto al tempo:\n\\qquad \\overrightarrow{a}(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta \\overrightarrow{v}}{\\Delta t} = \\frac{d\\overrightarrow{v}}{dt}\n\n\nComponenti dell’accelerazione istantanea: L’accelerazione istantanea vettoriale può essere espressa attraverso le sue componenti cartesiane:\n\na_x = \\frac{dv_x}{dt}\na_y = \\frac{dv_y}{dt}\na_z = \\frac{dv_z}{dt}\n\n\n\nEsempio di moto in 3D\n\n\nLegge oraria: Consideriamo un punto materiale che si muove nello spazio tridimensionale con la seguente legge oraria:\n\nx(t) = 2t\ny(t) = t^2 - 1\nz(t) = 2\n\n\n\nTraiettoria: Per ricavare la traiettoria, possiamo esprimere il tempo t in funzione di x dalla prima equazione: t = \\frac{x}{2}. Sostituendo nella seconda equazione, otteniamo:\n\\qquad y = \\left(\\frac{x}{2}\\right)^2 - 1 = \\frac{x^2}{4} - 1\nQuesta è l’equazione di una parabola nel piano z = 2.\n\n\nAnalisi del moto: Il moto del punto materiale è la combinazione di un moto uniforme lungo l’asse x e un moto uniformemente accelerato lungo l’asse y, mentre l’asse z rimane costante.\n\n\nVisualizzazione: Il professore suggerisce di visualizzare il moto proiettandolo su un piano, in questo caso il piano xy a quota z=2, per semplificare l’analisi.\n\n\nDerivate: Il professore spiega come, partendo dalla legge oraria, si possono ricavare velocità e accelerazione derivando le componenti cartesiane.\n\n\nSpero che questa riformulazione dettagliata e ben formattata ti sia utile!\n\nEcco una spiegazione dettagliata, comprensiva di passaggi matematici, esempi ed esercizi, basata sul contenuto della flashcard:\nAnalisi della Traiettoria di un Moto\n\nDeterminazione della Traiettoria Si parte dall’equazione parametrica del moto per determinare la traiettoria. L’obiettivo è eliminare il parametro tempo (t) per ottenere una relazione diretta tra le coordinate x e y.\nEsempio Specifico Data una relazione in cui x dipende da t e y dipende da t^2, si cerca di esprimere t in funzione di x e sostituire questa espressione nell’equazione di y. Questo processo porta a una equazione del tipo y = ax^2 + b, che rappresenta una parabola.\nPunti Chiave Per y = 0, si risolve l’equazione risultante per trovare i punti in cui la traiettoria interseca l’asse x. Ad esempio, se x^2/4 = 1, allora x = \\pm 2.\n\nAnalisi del Verso di Percorrenza\n\nConsiderazioni Iniziali Si analizza come il punto materiale si muove lungo la traiettoria, da x negativi a x positivi o viceversa.\nImportanza del Parametro Tempo Si osserva che x è proporzionale a t. Quando t è positivo, x è positivo, e quando t è negativo, x è negativo.\nPunto di Partenza All’istante t = 0, il punto materiale si trova in x = 0. Per t &gt; 0, il punto si muove verso destra, mentre per t &lt; 0 si trovava nella parte opposta.\n\nCalcolo del Vettore Velocità\n\nDefinizione Il vettore velocità istantanea è rappresentato in termini delle sue componenti lungo gli assi x, y e z.\nComponente lungo l’asse x Si calcola la derivata di x rispetto al tempo (t). Se x = 2t, allora v_x = 2 m/s, il che significa che il punto materiale si muove lungo l’asse x con velocità costante.\nComponente lungo l’asse y Si calcola la derivata di y rispetto al tempo. Se y = t^2 - 1, allora v_y = 2t. La velocità lungo y non è costante, ma aumenta linearmente con il tempo, ed è zero per t = 0.\nVariazione della Velocità Per t negativi, v_y è negativa (diretta verso il basso), poi diminuisce fino a zero per t = 0, e poi diventa positiva per t &gt; 0 (diretta verso l’alto).\nTangente alla Traiettoria Il vettore velocità, ottenuto sommando vettorialmente le componenti v_x e v_y, è tangente alla traiettoria.\n\nCalcolo del Vettore Accelerazione\n\nDefinizione Il vettore accelerazione è costituito dalle componenti a_x, a_y e a_z.\nComponente lungo l’asse x Si calcola la derivata di v_x rispetto al tempo. Poiché v_x è costante e pari a 2, a_x = 0.\nComponente lungo l’asse y Si calcola la derivata di v_y rispetto al tempo. Se v_y = 2t, allora a_y = 2 m/s².\nComponente lungo l’asse z La derivata di v_z rispetto al tempo è 0.\nDirezione L’accelerazione è costante e diretta lungo l’asse y. Questo spiega perché la traiettoria è una parabola con concavità verso l’alto. Il vettore accelerazione non è tangente né perpendicolare alla traiettoria.\n\nApplicazione al Moto Parabolico\n\nScomposizione del Moto Quando si lancia un oggetto soggetto solo all’accelerazione di gravità, è utile scomporre il moto nelle componenti orizzontale e verticale.\nDefinizione degli Assi Si definiscono due assi cartesiani (x e y) nel piano del moto. Un asse (tipicamente y) è allineato con l’accelerazione di gravità.\nMoto Uniforme e Accelerato Lungo l’asse y, il moto è uniformemente accelerato (o decelerato, a seconda della direzione scelta per l’asse). Lungo l’asse x, il moto è uniforme.\n\nRisoluzione di un Problema di Moto Parabolico\n\nScenario Un oggetto viene lanciato con una certa velocità iniziale e soggetto alla sola accelerazione di gravità. Si vuole sapere quanto tempo impiega a cadere al suolo e quanto spazio percorre orizzontalmente.\nDefinizione degli Assi Si sceglie un sistema di riferimento con l’asse y parallelo all’accelerazione di gravità (verso l’alto per convenzione) e l’origine a terra. L’asse x è orizzontale.\nCondizioni Iniziali Si definiscono le condizioni iniziali del moto: il vettore velocità iniziale (v_0) e la posizione iniziale. L’angolo di lancio (\\theta) rispetto all’asse orizzontale è noto.\nComponenti della Velocità Iniziale La componente x della velocità iniziale è v_0 \\cos(\\theta), mentre la componente y è v_0 \\sin(\\theta).\nPosizione Iniziale La posizione iniziale è definita da x_0 = 0 e y_0 = h, dove h è l’altezza iniziale dell’oggetto.\n\nRisoluzione del Problema Inverso\n\nCalcolo delle Velocità Si calcolano le componenti della velocità in funzione del tempo.\n\nv_x(t) = v_0 \\cos(\\theta) (costante)\nv_y(t) = v_0 \\sin(\\theta) - gt\n\n\nCalcolo della Posizione Si integrano le equazioni della velocità per ottenere le equazioni della posizione.\n\nx(t) = x_0 + \\int v_x(t) dt = v_0 \\cos(\\theta) \\cdot t\ny(t) = y_0 + \\int v_y(t) dt = h + v_0 \\sin(\\theta) \\cdot t - \\frac{1}{2}gt^2\n\n\nCalcolo della Gittata Per trovare la gittata, si impone y(t) = 0 e si risolve per t (tempo di volo). Poi si sostituisce questo valore di t nell’equazione di x(t) per ottenere la distanza orizzontale percorsa.\n\nGittata = x(t_{finale}) quando y(t_{finale}) = 0\n\n\n\nReferences"},"6--full-note/fisica1--Ese01":{"slug":"6--full-note/fisica1--Ese01","filePath":"6- full note/fisica1- Ese01.md","title":"fisica1- Ese01","links":[],"tags":[],"content":""},"6--full-note/fisica1--Ese08":{"slug":"6--full-note/fisica1--Ese08","filePath":"6- full note/fisica1- Ese08.md","title":"fisica1- Ese08","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-12 09:29\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nfisica1- Ese08\nEsercizio 4.23: Due corpi collegati tramite carrucola\nDescrizione del Problema\n\nDue corpi di massa m_1 = 5 kg e m_2 = 15 kg sono fissati alle estremità di una fune inestensibile che appoggia su una carrucola di massa trascurabile. Alla carrucola è applicata una forza \\mathbf{F} diretta verso l’alto. Trascurando gli attriti e ipotizzando che la fune sia tesa, si chiede di calcolare:\n\nLa massima intensità della forza F_M per cui la massa m_2 rimane a contatto con il suolo.\nL’accelerazione della massa m_1 in corrispondenza di tale forza F_M.\n\nLa carrucola ha massa trascurabile, il che implica che la tensione è uguale in tutti i punti della fune. Una fune tira, non spinge, e per agire deve essere tesa.\nDiagramma delle Forze e Sistema di Riferimento\nSi considerano i tre corpi: la massa m_1, la massa m_2, e la carrucola. Si sceglie un sistema di riferimento con l’asse verticale orientato verso l’alto, considerando positiva la forza \\mathbf{F}.\n\nCorpo 1 (m_1):\n\n\nForza peso: m_1 g (diretta verso il basso, quindi negativa nel nostro sistema di riferimento).\nTensione della fune: T (diretta verso l’alto, quindi positiva).\n\n\nCorpo 2 (m_2):\n\n\nForza peso: m_2 g (diretta verso il basso, quindi negativa).\nTensione della fune: T (diretta verso l’alto, quindi positiva).\nReazione normale del suolo: R_n (diretta verso l’alto, quindi positiva). Questa forza agisce solo finché il corpo rimane a contatto con il suolo.\n\n\nCarrucola (massa trascurabile):\n\n\nForza applicata: F (diretta verso l’alto, quindi positiva).\nTensione della fune (due tratti che tirano verso il basso): -T e -T (negative).\nForza peso della carrucola: m_{carrucola} g = 0 (perché la massa è trascurabile).\n\n\n\nEquazioni della Dinamica\nApplicando la seconda legge di Newton (\\mathbf{F}_{ris} = m\\mathbf{a}) per ciascun corpo:\n\n\nCorpo 1 (m_1): T - m_1 g = m_1 a_1 dove a_1 è l’accelerazione della massa m_1 (positiva se diretta verso l’alto).\n\n\nCorpo 2 (m_2): R_n + T - m_2 g = m_2 a_2 Il problema specifica che m_2 rimane a contatto con il suolo, quindi la sua accelerazione a_2 = 0. L’equazione diventa: R_n + T - m_2 g = 0\n\n\nCarrucola (massa trascurabile): F - 2T = m_{carrucola} a_{carrucola} = 0 \\cdot a_{carrucola} = 0 Da cui si ottiene la relazione tra la forza applicata e la tensione: F = 2T\n\n\nCondizione per m_2 a Contatto con il Suolo\nLa condizione affinché la massa m_2 rimanga a contatto con il suolo è che la reazione normale R_n sia maggiore o uguale a zero: R_n \\ge 0 Il valore limite per il distacco si ha quando R_n = 0.\nDall’equazione per m_2 con a_2 = 0, abbiamo: R_n = m_2 g - T\nImponendo R_n \\ge 0: m_2 g - T \\ge 0 T \\le m_2 g\nCalcolo della Forza Massima F_M\nUtilizzando la relazione trovata per la carrucola (F = 2T), la condizione sulla tensione si traduce in una condizione sulla forza: F \\le 2 m_2 g\nLa massima intensità della forza F_M per cui m_2 rimane a contatto con il suolo è quindi: F_M = 2 m_2 g\nSostituendo il valore di m_2 = 15 kg e g \\approx 9.8 , \\text{m/s}^2: F_M = 2 \\cdot 15 , \\text{kg} \\cdot 9.8 , \\text{m/s}^2 = 294 , \\text{N} Il professore indica che il risultato è 294 N.\nCalcolo dell’Accelerazione di m_1 in Corrispondenza di F_M\nQuando F = F_M, abbiamo T = \\frac{F_M}{2} = \\frac{2 m_2 g}{2} = m_2 g.\nSostituiamo questo valore di T nell’equazione della dinamica per m_1: T - m_1 g = m_1 a_1 m_2 g - m_1 g = m_1 a_1 (m_2 - m_1) g = m_1 a_1\nRisolvendo per l’accelerazione a_1: a_1 = \\frac{m_2 - m_1}{m_1} g\nSostituendo i valori di m_1 = 5 kg e m_2 = 15 kg: a_1 = \\frac{15 , \\text{kg} - 5 , \\text{kg}}{5 , \\text{kg}} g = \\frac{10 , \\text{kg}}{5 , \\text{kg}} g = 2g\nUtilizzando g \\approx 9.8 , \\text{m/s}^2: a_1 = 2 \\cdot 9.8 , \\text{m/s}^2 = 19.6 , \\text{m/s}^2\nL’accelerazione di m_1 è diretta verso l’alto perché il risultato è positivo nel nostro sistema di riferimento.\nOsservazioni del Professore\nIl professore sottolinea l’importanza di isolare i corpi, fare il diagramma delle forze e scegliere un sistema di riferimento opportuno. Nel contesto di questo problema, tutto si svolge lungo la direzione verticale.\nRiguardo alla condizione di contatto con il suolo, il professore spiega che tradurre la frase “rimane a contatto con il suolo” nell’equazione o disequazione R_n \\ge 0 è fondamentale. Il caso limite (R_n = 0) corrisponde al valore massimo della forza.\nInfine, il professore fa notare che l’accelerazione di m_1 è costante, il che implica un moto accelerato fino a quando la corda non finisce o m_1 raggiunge la carrucola.\n\nSpiegazione dell’Esercizio 4.24\nIntroduzione al Problema\n\nIl professore introduce l’esercizio 4.24, che coinvolge due masse (m_1 e m_2) collegate da una fune inestensibile. La fune ha un’estremità fissata al soffitto e passa attraverso due carrucole di massa trascurabile: una fissa (C_1) e una mobile (C_2). La massa m_1 si trova su un piano orizzontale liscio (senza attrito), mentre la massa m_2 pende verticalmente. L’obiettivo è calcolare le accelerazioni delle due masse e, come aggiunge il professore, le tensioni della fune (T_1 e T_2).\nAnalisi Cinematica della Fune\nIl professore sottolinea l’importanza di capire la relazione tra le accelerazioni delle due masse a causa del vincolo imposto dalla fune inestensibile e dalla carrucola mobile. Per fare ciò, esegue un’analisi cinematica della fune.\nConsiderando un sistema di riferimento con x_1 come la coordinata orizzontale di m_1 e x_2 come la coordinata verticale di m_2 (con verso positivo verso il basso), la lunghezza totale (L) della fune, che è costante, può essere espressa come la somma di diversi segmenti:\n\nL = x_1 + \\frac{2 \\pi r_1}{4} + x_{C2} + \\frac{2 \\pi R_2}{2} + x_{C2} + L&#039;\nDove:\n\nx_1 è la coordinata di m_1.\n\\frac{2 \\pi r_1}{4} è un quarto della circonferenza della carrucola fissa C_1 (un termine costante).\nx_{C2} è la coordinata verticale della carrucola mobile C_2.\n\\frac{2 \\pi R_2}{2} è metà della circonferenza della carrucola mobile C_2 (un termine costante).\nL&#039; rappresenta la lunghezza costante del tratto di fune tra la carrucola fissa e il punto di attacco al soffitto.\n\nPoiché la lunghezza L è costante, la sua derivata rispetto al tempo è zero. Derivando due volte l’espressione per L rispetto al tempo, e considerando che l’accelerazione della carrucola mobile C_2 è la stessa dell’accelerazione della massa m_2 (a_2 = \\ddot{x}_{C2}), si ottiene la relazione tra le accelerazioni:\n0 = \\ddot{x}_1 + 2 \\ddot{x}_{C2}\nDa cui:\n\\ddot{x}_1 = -2 \\ddot{x}_2\nQuindi, l’accelerazione del corpo 1 (a_1) è il doppio e in verso opposto all’accelerazione del corpo 2 (a_2). Se si considera il verso positivo di x_1 verso destra e il verso positivo di x_2 verso il basso, allora:\na_1 = -2 a_2\nIl segno negativo indica che se m_2 accelera verso il basso (a_2 &gt; 0), allora m_1 accelera verso sinistra (a_1 &lt; 0), e viceversa. Il professore spiega che uno spostamento \\Delta x di m_1 comporta uno spostamento di \\frac{\\Delta x}{2} della carrucola mobile e quindi di m_2.\nDiagramma delle Forze\n\nIl professore procede a disegnare e analizzare le forze agenti su ciascun corpo:\n\n\nMassa m_1:\n\nForza peso: m_1 g (verticale verso il basso).\nReazione normale del piano: R_n (verticale verso l’alto). Questa forza bilancia il peso di m_1 in direzione verticale e non influenza il moto orizzontale.\nTensione della fune: T_1 (orizzontale verso sinistra, poiché la fune tira m_1).\n\n\n\nMassa m_2:\n\nForza peso: m_2 g (verticale verso il basso).\nTensione della fune: T_2 (verticale verso l’alto, poiché la fune tira m_2).\n\n\n\nCarrucola Mobile C_2 (massa trascurabile):\n\nTensione della fune: Due segmenti di fune esercitano una tensione T_1 ciascuno verso l’alto.\nTensione della fune: Un segmento di fune esercita una tensione T_2 verso il basso.\n\n\n\nApplicazione della Seconda Legge di Newton\nIl professore applica la seconda legge di Newton (\\vec{F}_{ris} = m \\vec{a}) a ciascun corpo lungo le direzioni del moto:\n\n\nMassa m_1 (moto orizzontale): -T_1 = m_1 a_1\n\n\nMassa m_2 (moto verticale): m_2 g - T_2 = m_2 a_2\n\n\nCarrucola Mobile C_2 (massa trascurabile): Poiché la massa della carrucola è trascurabile, la risultante delle forze su di essa deve essere zero: 2 T_1 - T_2 = 0 \\implies T_2 = 2 T_1\n\n\nRisoluzione del Sistema di Equazioni\nSi ha un sistema di quattro equazioni con quattro incognite (T_1, T_2, a_1, a_2):\n\n-T_1 = m_1 a_1\nm_2 g - T_2 = m_2 a_2\nT_2 = 2 T_1\na_1 = -2 a_2\n\nIl professore mostra i passaggi per risolvere questo sistema:\nSostituendo l’equazione 4 nella 1: -T_1 = m_1 (-2 a_2) \\implies T_1 = 2 m_1 a_2\nSostituendo l’equazione 3: T_2 = 2 (2 m_1 a_2) = 4 m_1 a_2\nSostituendo l’espressione per T_2 nell’equazione 2: m_2 g - 4 m_1 a_2 = m_2 a_2\nRisolvendo per a_2: m_2 g = m_2 a_2 + 4 m_1 a_2 m_2 g = (m_2 + 4 m_1) a_2 a_2 = \\frac{m_2}{4 m_1 + m_2} g\nRisultati per l’Accelerazione\nL’accelerazione della massa m_2 è:\na_2 = \\frac{m_2}{4 m_1 + m_2} g\nUtilizzando la relazione cinematica a_1 = -2 a_2, l’accelerazione della massa m_1 è:\na_1 = -2 \\frac{m_2}{4 m_1 + m_2} g\nRisultati per la Tensione\nSostituendo l’espressione per a_2 nelle equazioni per le tensioni, si ottiene:\nTensione T_1: T_1 = 2 m_1 a_2 = 2 m_1 \\frac{m_2}{4 m_1 + m_2} g = \\frac{2 m_1 m_2}{4 m_1 + m_2} g\nTensione T_2: T_2 = 2 T_1 = 2 \\frac{2 m_1 m_2}{4 m_1 + m_2} g = \\frac{4 m_1 m_2}{4 m_1 + m_2} g\nIl professore invita a verificare a casa i risultati ottenuti risolvendo il sistema di equazioni.\nUlteriori Considerazioni ed Esempi\nIl professore menziona come il principio della carrucola mobile possa essere esteso per creare un sistema di carrucole utilizzato da Archimede per sollevare grandi pesi. Ogni carrucola mobile aggiuntiva riduce ulteriormente l’accelerazione e la forza necessaria per sollevare un carico.\nCome esempio, propone di analizzare un sistema con più carrucole, suggerendo che in una configurazione specifica si potrebbe raggiungere l’equilibrio (a=0) quando m_2 = 4 m_1. Questo significa che una massa m_1 può equilibrare una massa m_2 quattro volte più grande grazie al vantaggio meccanico fornito dal sistema di carrucole . Il professore conclude invitando a provare a risolvere un sistema di carrucole più complesso come esercizio .\nCertamente. Ripercorriamo la spiegazione del professore sull’esercizio 3, integrando i passaggi matematici e fornendo una struttura chiara con titoli e sottotitoli.\nEsercizio sul Sistema di Masse Senza Attriti\n\nDescrizione del Problema\nSi considera un sistema composto da una massa M appoggiata su una superficie orizzontale priva di attrito. Sopra questa massa M è appoggiata una massa m_1. Una carrucola è fissata alla massa M, e una fune ideale, anch’essa priva di massa, collega la massa m_1 a una massa m_2 che pende verticalmente. Una forza costante F è applicata orizzontalmente alla massa M. L’obiettivo è determinare il valore della forza F tale che le masse m_1 e m_2 rimangano ferme rispetto alla massa M.\nComprensione del Fenomeno Fisico\nIl professore introduce il problema sottolineando l’assenza di attriti nel sistema. Per aiutare a visualizzare la situazione, propone un esperimento mentale: se la forza F fosse zero (ovvero se il corpo M fosse fermo), le masse m_1 e m_2, a causa della gravità e dell’assenza di attrito, scivolerebbero inevitabilmente. L’idea è che, applicando una forza F opportuna a M, si possa indurre un’accelerazione tale che le masse m_1 e m_2 rimangano in equilibrio relativo rispetto a M.\nViene fornito un esempio analogico: immaginare di essere in auto su un sedile di ghiaccio. Se l’auto è ferma, si scivola. Tuttavia, se l’auto sta accelerando, si viene schiacciati contro il sedile e, in qualche modo, si potrebbe rimanere in equilibrio relativo.\nDiagramma delle Forze\n\nPer risolvere il problema, è fondamentale analizzare le forze agenti su ciascun corpo. Il professore procede a disegnare il diagramma delle forze per le masse M, m_1 e m_2, e per la carrucola (considerando la carrucola e M come un unico sistema per alcune forze).\n\n\nMassa M:\n\nForza esterna applicata: \\vec{F} (orizzontale)\nForza peso: M\\vec{g} (verticale verso il basso)\nReazione vincolare del suolo: \\vec{R}_N (verticale verso l’alto)\nReazione parallela dovuta al contatto con m_1: \\vec{R}_P (orizzontale, verso sinistra, esercitata da m_1 su M)\nTensione della fune: \\vec{T} (orizzontale, verso sinistra, applicata alla carrucola, e quindi indirettamente a M)\n\n\n\nMassa m_1:\n\nForza peso: m_1\\vec{g} (verticale verso il basso)\nReazione vincolare di M su m_1: \\vec{R}_{N1} (verticale verso l’alto)\nReazione parallela dovuta al contatto con M: \\vec{R} (orizzontale, verso destra, esercitata da M su m_1)\nTensione della fune: \\vec{T} (orizzontale, verso destra)\n\n\n\nMassa m_2:\n\nForza peso: m_2\\vec{g} (verticale verso il basso)\nTensione della fune: \\vec{T} (verticale verso l’alto)\n\n\n\nImposizione della Condizione di Equilibrio Relativo\nLa condizione affinché le masse m_1 e m_2 siano ferme rispetto a M è che tutti i corpi del sistema abbiano la stessa accelerazione. Indichiamo questa accelerazione comune con A (diretta orizzontalmente verso destra, nella direzione della forza F).\nScrittura delle Equazioni della Dinamica\nApplichiamo la seconda legge di Newton (\\vec{F} = m\\vec{a}) a ciascun corpo, considerando solo le componenti orizzontali rilevanti per il moto e l’equilibrio relativo.\n\n\nMassa m_1 (componente orizzontale): La forza orizzontale agente su m_1 è la tensione della fune T e la reazione parallela R esercitata da M. Però, considerando il sistema nel suo complesso, la condizione di equilibrio relativo si traduce in un’unica accelerazione orizzontale A. Quindi: T = m_1 A Il professore inizialmente scrive solo T = m_1 A, suggerendo implicitamente che la reazione R sia la forza che causa l’accelerazione di m_1 insieme alla tensione.\n\n\nMassa m_2 (componente verticale): Poiché m_2 deve rimanere ferma rispetto a M (nella direzione orizzontale), la tensione nella fune deve bilanciare il suo peso per quanto riguarda la relazione con m_1 tramite la carrucola. Tuttavia, l’accelerazione del sistema influenza la tensione. Considerando che la lunghezza della fune non cambia, l’accelerazione orizzontale di m_1 implica una “pseudo-forza” che influenzerà l’equilibrio verticale apparente di m_2 rispetto a M. Però, il professore impone direttamente l’equilibrio verticale per determinare la tensione: T = m_2 g Questo perché se m_2 è ferma rispetto a M, la sua accelerazione verticale è zero nel sistema di riferimento di M. Nel sistema di riferimento inerziale, la sua accelerazione orizzontale è A.\nSuccessivamente, introduce la reazione R_P agente su M dovuta al contatto con m_1: R_P = m_2 A Questa forza R_P è la reazione alla forza R che M esercita su m_1.\n\n\nMassa M (componente orizzontale): Le forze orizzontali agenti su M sono la forza applicata F, la reazione parallela -R_P esercitata da m_1, e la tensione -T esercitata dalla fune (tramite la carrucola): F - R_P - T = M A Il professore sottolinea l’importanza di considerare la tensione applicata anche a M tramite la carrucola.\n\n\nRisoluzione del Sistema di Equazioni\nOra abbiamo un sistema di tre equazioni con tre incognite (F, A, T):\n\nT = m_1 A\nT = m_2 g\nF - R_P - T = M A, dove R_P = m_2 A\n\nDalle prime due equazioni, possiamo uguagliare le espressioni per la tensione T: m_1 A = m_2 g Da cui si ricava l’accelerazione comune del sistema: A = \\frac{m_2}{m_1} g\nOra sostituiamo le espressioni per A, T, e R_P nella terza equazione: F - (m_2 A) - (m_2 g) = M A F - m_2 \\left(\\frac{m_2}{m_1} g\\right) - m_2 g = M \\left(\\frac{m_2}{m_1} g\\right) F - \\frac{m_2^2}{m_1} g - m_2 g = \\frac{M m_2}{m_1} g\nOra isoliamo la forza F: F = \\frac{M m_2}{m_1} g + \\frac{m_2^2}{m_1} g + m_2 g\nPossiamo raccogliere il termine g: F = g \\left( \\frac{M m_2}{m_1} + \\frac{m_2^2}{m_1} + m_2 \\right)\nPer rendere l’espressione più compatta, possiamo mettere m_2/m_1 in evidenza nei primi due termini: F = g \\left( \\frac{m_2}{m_1} (M + m_2) + m_2 \\right)\nOppure, mettendo m_2 g / m_1 in evidenza da tutti i termini (come fatto dal professore, con una piccola imprecisione iniziale): F = \\frac{m_2}{m_1} g \\left( M + m_2 + m_1 \\right)\nVerifica dei Passaggi Algebrici (Chiarimento del Professore)\nIl professore ripercorre i passaggi per chiarire come si arriva al risultato finale: Dall’equazione per F: F = \\frac{M m_2}{m_1} g + \\frac{m_2^2}{m_1} g + m_2 g\nSi vuole riscrivere in una forma più compatta. Si può notare che ogni termine contiene g. Raccogliendo g: F = g \\left( \\frac{M m_2}{m_1} + \\frac{m_2^2}{m_1} + m_2 \\right)\nOra, per far apparire il termine \\frac{m_2}{m_1} g come fattore comune, si può moltiplicare e dividere l’ultimo termine (m_2 g) per m_1: m_2 g = \\frac{m_1 m_2 g}{m_1} = \\frac{m_2}{m_1} g \\cdot m_1\nSostituendo questo nell’espressione per F: F = \\frac{M m_2}{m_1} g + \\frac{m_2^2}{m_1} g + \\frac{m_2}{m_1} g \\cdot m_1\nOra si può raccogliere il fattore comune \\frac{m_2}{m_1} g: F = \\frac{m_2}{m_1} g (M + m_2 + m_1)\nQuesto è il risultato finale ottenuto dal professore.\nOsservazioni Finali sull’Esercizio\nIl professore conclude sottolineando che la chiave per risolvere questo problema era imporre che tutte le masse avessero la stessa accelerazione orizzontale. In un contesto di sistemi di riferimento relativi (che sarebbe affrontato in seguito), questa accelerazione si tradurrebbe in condizioni di statica apparente per le masse m_1 e m_2 rispetto al sistema accelerato M. L’esercizio illustra come l’applicazione della seconda legge di Newton e la corretta analisi delle forze, unitamente alla comprensione del vincolo cinematico (stessa accelerazione), portino alla soluzione del problema.\nForza Elastica e Combinazioni di Molle (Esercizio 437)\n\nForza Elastica\nUna molla è un elemento meccanico che, se deformato dalla sua lunghezza a riposo L_0, esercita una forza elastica di richiamo. L’intensità di questa forza è direttamente proporzionale all’allungamento \\Delta L della molla, secondo la legge di Hooke:\nF = k |\\Delta L|\ndove k è la costante elastica della molla, che misura la sua rigidità. L’allungamento \\Delta L è la differenza tra la lunghezza attuale della molla e la sua lunghezza a riposo.\nIn forma vettoriale, introducendo un sistema di riferimento con asse x e considerando la coordinata x dell’estremo della molla, la forza elastica può essere espressa come:\n\\vec{F} = -k(x - L_0) \\hat{x}\nQuesto significa che se la molla è allungata (x &gt; L_0), la forza è di richiamo e diretta nel verso opposto all’allungamento. Se la molla è compressa (x &lt; L_0), la forza spinge e ha lo stesso verso dell’accorciamento. In alcuni casi, la lunghezza a riposo L_0 può essere considerata trascurabile, semplificando l’espressione.\nCombinazioni di Molle: Serie e Parallelo\nQuando più molle sono collegate tra loro, possono formare configurazioni in serie o in parallelo. Queste configurazioni si ritrovano in diversi ambiti della meccanica e dell’elettromagnetismo.\nMolle in Serie\nIn una configurazione in serie, le molle sono collegate una di seguito all’altra. Consideriamo l’esercizio 437 come spunto, dove inizialmente si ha un corpo di massa M collegato al soffitto mediante due molle con costanti elastiche K_1 e K_2 disposte in serie.\nPer analizzare le forze in gioco, consideriamo le molle e la massa come corpi separati in una situazione statica:\n\n\nIl soffitto esercita una forza F_0 sulla molla superiore (K_1), che a sua volta esercita una forza uguale e contraria sul soffitto (terzo principio della dinamica).\nLa molla superiore (K_1) esercita una forza F_1 sulla molla inferiore (K_2), e per il terzo principio, la molla inferiore esercita una forza uguale e contraria sulla molla superiore.\nLa molla inferiore (K_2) esercita una forza F_2 sulla massa M, e per il terzo principio, la massa esercita una forza uguale e contraria sulla molla inferiore.\nSulla massa M agisce anche la forza peso mg diretta verso il basso.\n\nSe le masse delle molle sono trascurabili, per la seconda legge di Newton, la forza netta su ciascuna molla deve essere zero in condizioni statiche. Questo implica che la forza si trasmette inalterata attraverso le molle in serie:\nF_0 = F_1 F_1 = F_2\nAll’equilibrio statico, la forza esercitata dalla molla inferiore sulla massa deve bilanciare la forza peso:\nF_2 = mg\nQuindi, per molle in serie, la forza che attraversa ciascuna molla è la stessa e uguale alla forza esterna applicata al sistema (in questo caso, la forza peso).\nL’allungamento totale del sistema di molle in serie (\\Delta x) è la somma degli allungamenti delle singole molle (\\Delta x_1 e \\Delta x_2):\n\\Delta x = \\Delta x_1 + \\Delta x_2\nL’allungamento di ciascuna molla è legato alla forza che la attraversa e alla sua costante elastica:\n\\Delta x_1 = \\frac{F_1}{K_1} \\Delta x_2 = \\frac{F_2}{K_2}\nPoiché F_1 = F_2 = F_{eq} (dove F_{eq} è la forza equivalente esercitata dal sistema combinato), possiamo scrivere l’allungamento totale come:\n\\Delta x = \\frac{F_{eq}}{K_1} + \\frac{F_{eq}}{K_2} = F_{eq} \\left( \\frac{1}{K_1} + \\frac{1}{K_2} \\right)\nSe consideriamo il sistema delle due molle in serie come un’unica molla equivalente con costante elastica K_{eq}, l’allungamento totale sarebbe:\n\\Delta x = \\frac{F_{eq}}{K_{eq}}\nUguagliando le due espressioni per \\Delta x, otteniamo la relazione per la costante elastica equivalente di molle in serie:\n\\frac{F_{eq}}{K_{eq}} = F_{eq} \\left( \\frac{1}{K_1} + \\frac{1}{K_2} \\right)\n\\frac{1}{K_{eq}} = \\frac{1}{K_1} + \\frac{1}{K_2}\nIn generale, per n molle in serie, la costante elastica equivalente è data da:\n\\frac{1}{K_{eq}} = \\sum_{i=1}^{n} \\frac{1}{K_i}\nIl professore conclude che l’allungamento totale del sistema di molle in serie è la somma delle elongazioni delle singole molle, e per trovare la molla equivalente si devono sommare gli inversi delle costanti elastiche.\nMolle in Parallelo\n\nIn una configurazione in parallelo, le molle sono collegate allo stesso punto e agiscono contemporaneamente sulla stessa massa. Per avere un sistema equivalente semplice, è necessario che le molle abbiano la stessa lunghezza a riposo L_0.\nConsideriamo due molle con costanti elastiche K_1 e K_2 collegate in parallelo a una massa. Quando la massa si sposta di una quantità \\Delta x, entrambe le molle subiscono lo stesso allungamento. La forza totale esercitata dalle molle sulla massa è la somma delle forze esercitate da ciascuna molla:\n\nF = F_1 + F_2\ndove:\nF_1 = K_1 \\Delta x F_2 = K_2 \\Delta x\nQuindi, la forza totale è:\nF = K_1 \\Delta x + K_2 \\Delta x = (K_1 + K_2) \\Delta x\nSe consideriamo il sistema delle due molle in parallelo come un’unica molla equivalente con costante elastica K_{eq}, la forza totale sarebbe:\nF = K_{eq} \\Delta x\nUguagliando le due espressioni per F, otteniamo la relazione per la costante elastica equivalente di molle in parallelo:\nK_{eq} \\Delta x = (K_1 + K_2) \\Delta x\nK_{eq} = K_1 + K_2\nIn generale, per n molle in parallelo con la stessa lunghezza a riposo, la costante elastica equivalente è data da:\nK_{eq} = \\sum_{i=1}^{n} K_i\nEsercizio del Tema d’Esame (Esercizio 5)\nDeterminazione della Posizione di Equilibrio\n\nIl problema considera un sistema composto da due molle collegate a un soffitto e a una massa M. La prima molla ha una costante elastica K_1 ed è collegata direttamente al soffitto. La seconda molla, con costante elastica K_2, è collegata alla massa M. Sia H la quota del pavimento. Si vuole determinare la posizione di equilibrio verticale Z_{eq} della massa M.\nPer trovare la posizione di equilibrio, è necessario imporre che la risultante delle forze agenti sulla massa M sia nulla. Le forze in gioco sono:\n\n\nLa forza elastica della prima molla, F_1, che agisce verso il basso. Dato che la lunghezza a riposo è considerata nulla (come suggerito dal professore), l’allungamento della prima molla è H - Z_{eq}, quindi F_1 = K_1 (H - Z_{eq}).\nLa forza peso della massa M, P = Mg, che agisce verso il basso.\nLa forza elastica della seconda molla, F_2, che agisce verso l’alto. L’allungamento della seconda molla è Z_{eq}, quindi F_2 = K_2 Z_{eq}.\n\nAll’equilibrio, la somma delle forze verso il basso deve essere uguale alla somma delle forze verso l’alto:\nF_1 + Mg = F_2\nSostituendo le espressioni delle forze elastiche, otteniamo:\nK_1 (H - Z_{eq}) + Mg = K_2 Z_{eq}\nOra, risolviamo questa equazione per trovare Z_{eq}:\nK_1 H - K_1 Z_{eq} + Mg = K_2 Z_{eq}\nK_1 H + Mg = K_2 Z_{eq} + K_1 Z_{eq}\nK_1 H + Mg = (K_1 + K_2) Z_{eq}\nPertanto, la posizione di equilibrio Z_{eq} è data da:\nZ_{eq} = \\frac{K_1 H + Mg}{K_1 + K_2}\nSembra esserci stata una discrepanza con la formula fornita successivamente dal professore (Z_{eq} = \\frac{K_1 H - MG}{K_1 + K_2}). È importante seguire attentamente i passaggi logici per la derivazione. Riconsiderando l’equilibrio delle forze:\nForze verso il basso: F_1 = K_1 (H - Z_{eq}), Mg Forze verso l’alto: F_2 = K_2 Z_{eq}\nEquilibrio: K_1 (H - Z_{eq}) + Mg = K_2 Z_{eq}\nK_1 H - K_1 Z_{eq} + Mg = K_2 Z_{eq}\nK_1 H + Mg = K_1 Z_{eq} + K_2 Z_{eq}\nK_1 H + Mg = (K_1 + K_2) Z_{eq}\nZ_{eq} = \\frac{K_1 H + Mg}{K_1 + K_2}\nLa formula corretta, derivata dai principi dell’equilibrio statico, è Z_{eq} = \\frac{K_1 H + Mg}{K_1 + K_2}. La formula fornita in seguito dal professore in sembra contenere un errore di segno per il termine Mg.\nAnalisi dello Spostamento Orizzontale e Mantenimento dell’Equilibrio Verticale\n\nIl professore introduce poi uno spostamento orizzontale della massa M mantenendo la stessa quota verticale. In questo scenario, le molle diventano oblique. Tuttavia, per piccole oscillazioni orizzontali e considerando l’equilibrio verticale, l’allungamento verticale di ciascuna molla rimane approssimativamente lo stesso.\nCome spiegato dal professore, una molla obliqua può essere scomposta in una forza verticale (F_y) e una forza orizzontale (F_x). L’allungamento verticale determina la forza verticale secondo la relazione F_y = k \\Delta y, dove \\Delta y è l’elongazione verticale.\nSe la massa viene spostata orizzontalmente mantenendo la stessa quota verticale, l’elongazione verticale di ciascuna molla non cambia (per piccole oscillazioni). Di conseguenza, le forze verticali esercitate dalle molle rimangono le stesse di quando il sistema era in equilibrio verticale. Pertanto, il sistema rimane in equilibrio nella direzione verticale anche quando la massa viene spostata orizzontalmente a quella quota.\nDeterminazione della Velocità Angolare in Caso di Rotazione\n\nSe il sistema viene fatto ruotare in un piano orizzontale attorno alla posizione di equilibrio verticale, la massa M sarà soggetta a un’accelerazione centripeta diretta verso il centro della rotazione (la proiezione verticale del punto di attacco delle molle).\nLa forza centripeta (F_c) necessaria per mantenere la massa in rotazione con velocità angolare \\omega a un raggio x (lo spostamento orizzontale) è data da:\nF_c = M \\omega^2 x\nQuesta forza centripeta è fornita dalle componenti orizzontali delle forze elastiche delle due molle. Dato che le lunghezze a riposo delle molle sono nulle, le forze elastiche sono direttamente proporzionali all’allungamento. Per un piccolo spostamento orizzontale x, anche le componenti orizzontali delle forze elastiche saranno proporzionali a x:\n\nLa componente orizzontale della forza della prima molla è K_1 x.\nLa componente orizzontale della forza della seconda molla è K_2 x.\n\nEntrambe queste forze orizzontali agiscono come forze di richiamo verso la posizione di equilibrio orizzontale e quindi contribuiscono alla forza centripeta:\nF_c = K_1 x + K_2 x\nEguagliando le due espressioni per la forza centripeta:\nM \\omega^2 x = K_1 x + K_2 x\nM \\omega^2 x = (K_1 + K_2) x\nSe x \\neq 0 (c’è una rotazione), possiamo dividere per x:\nM \\omega^2 = K_1 + K_2\nRisolvendo per la velocità angolare \\omega:\n\\omega^2 = \\frac{K_1 + K_2}{M}\n\\omega = \\sqrt{\\frac{K_1 + K_2}{M}}\nQuesta è l’espressione per la velocità angolare del sistema in rotazione orizzontale. Il professore ha correttamente derivato questa formula nel passaggio finale.\nIn sintesi, l’esercizio analizza l’equilibrio statico verticale di un sistema con due molle e una massa, per poi considerare il comportamento del sistema quando la massa viene spostata orizzontalmente e fatta ruotare, evidenziando come le forze elastiche determinano la velocità angolare della rotazione. È fondamentale notare la potenziale imprecisione nella formula per la posizione di equilibrio fornita oralmente dal professore e fare riferimento alla derivazione basata sull’equilibrio delle forze.\nReferences"},"6--full-note/fisica1--Lez0":{"slug":"6--full-note/fisica1--Lez0","filePath":"6- full note/fisica1- Lez0.md","title":"fisica1- Lez0","links":[],"tags":[],"content":""},"6--full-note/fisica1--Lez03":{"slug":"6--full-note/fisica1--Lez03","filePath":"6- full note/fisica1- Lez03.md","title":"fisica1- Lez03","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/fisica-1","3--tag/sbobine"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-02-22 23:39\n_Status:  flashcard_zero    riscritto_zero    revisione_zero\n_Tags: fisica 1   sbobine\nlez03- fisica1\nMoto Circolare\nDefinizione: Il moto circolare è un moto la cui traiettoria è una circonferenza.\n\nRaggio: Sia R il raggio della circonferenza.\nOrigine: Si definisce un’origine sulla circonferenza. Per comodità, l’origine è posta dove la circonferenza è intersecata da un asse orizzontale.\nVerso di percorrenza: Per convenzione, il verso di percorrenza è antiorario.\n\nAscissa curvilinea\nL’ascissa curvilinea, s, rappresenta lo spazio percorso dal punto materiale lungo la circonferenza a partire dall’origine. La legge oraria s(t) descrive come varia l’ascissa curvilinea nel tempo.\nPosizione angolare\nIn alternativa all’ascissa curvilinea, si può definire la posizione angolare \\theta del punto materiale.\nRelazione tra posizione angolare e ascissa curvilinea:\n\\qquad \\theta = \\frac{s}{R}\n\\qquad s = R \\cdot \\theta\nDare la legge oraria come posizione angolare \\theta(t) è equivalente a darla come ascissa curvilinea s(t).\nVelocità angolare\nLa velocità angolare \\omega misura la rapidità con cui l’angolo \\theta viene spazzato nel tempo.\n\nDefinizione: La velocità angolare \\omega è la derivata della posizione angolare rispetto al tempo:\n\n\\qquad \\omega = \\frac{d\\theta}{dt}\n\nDimensioni: Dimensionalmente, \\omega è un tempo^{-1}.\nUnità di misura: L’unità di misura è radianti al secondo (rad/s).\n\nLegame tra velocità scalare e velocità angolare:\n\\qquad v = \\frac{ds}{dt} = R \\frac{d\\theta}{dt} = R\\omega\nAccelerazione angolare\nL’accelerazione angolare \\alpha misura la rapidità con cui varia la velocità angolare nel tempo.\n\nDefinizione: L’accelerazione angolare \\alpha è la derivata della velocità angolare rispetto al tempo:\n\n\\qquad \\alpha = \\frac{d\\omega}{dt}\n\nDimensioni: Dimensionalmente, \\alpha è un tempo^{-2}.\nUnità di misura: L’unità di misura è radianti al secondo quadro (rad/s^2).\n\nLegame tra accelerazione scalare e accelerazione angolare:\n\\qquad a = \\frac{dv}{dt} = R \\frac{d\\omega}{dt} = R\\alpha\nPassaggi cinematici\n\nDalla posizione angolare \\theta si ottiene la velocità angolare \\omega derivando rispetto al tempo.\nDalla velocità angolare \\omega si ottiene l’accelerazione angolare \\alpha derivando rispetto al tempo.\nViceversa, dall’accelerazione angolare \\alpha si ottiene la velocità angolare \\omega integrando rispetto al tempo, e dalla velocità angolare \\omega si ottiene la posizione angolare \\theta integrando rispetto al tempo.\n\nCinematica Vettoriale\nNella cinematica vettoriale, la posizione, la velocità e l’accelerazione sono descritte tramite vettori.\nVettore posizione\nPer definire la posizione di un punto nello spazio 3D, è necessario un sistema di riferimento (ad esempio, cartesiano) e un orologio. La posizione del punto è data dalle coordinate x(t), y(t) e z(t) in ogni istante di tempo.\nIl vettore posizione \\overrightarrow{r}(t) è definito come:\n\\qquad \\overrightarrow{r}(t) = x(t) \\hat{i} + y(t) \\hat{j} + z(t) \\hat{k}\ndove \\hat{i}, \\hat{j} e \\hat{k} sono i versori degli assi x, y e z, rispettivamente.\nTraiettoria\nLa traiettoria è la curva descritta dal punto materiale al variare del tempo. Nella cinematica vettoriale, la traiettoria è implicita nelle funzioni x(t), y(t) e z(t).\nEsempio\nConsideriamo un punto materiale con:\n\nx(t) = 2t\ny(t) = t^2 + 1\nz(t) = 4 (costante)\n\nPer trovare la traiettoria, si ricava il tempo da una delle equazioni e si sostituisce nelle altre:\n\\qquad t = \\frac{x}{2}\nSostituendo in y(t):\n\\qquad y = \\left(\\frac{x}{2}\\right)^2 + 1 = \\frac{x^2}{4} + 1\nQuindi la traiettoria è una parabola nel piano z = 4.\nVettore spostamento medio\nIl vettore spostamento medio \\Delta \\overrightarrow{r} tra due istanti t_1 e t_2 è definito come:\n\\qquad \\Delta \\overrightarrow{r} = \\overrightarrow{r}(t_2) - \\overrightarrow{r}(t_1)\nIn generale, il modulo di \\Delta \\overrightarrow{r} è diverso dalla lunghezza dello spostamento effettivo sulla traiettoria \\Delta s.\nVelocità vettoriale media\nLa velocità vettoriale media \\overrightarrow{v}_{media} nell’intervallo di tempo \\Delta t = t_2 - t_1 è definita come:\n\\qquad \\overrightarrow{v}_{media} = \\frac{\\Delta \\overrightarrow{r}}{\\Delta t} = \\frac{\\overrightarrow{r}(t_2) - \\overrightarrow{r}(t_1)}{t_2 - t_1}\nLa direzione di \\overrightarrow{v}_{media} è parallela a \\Delta \\overrightarrow{r}.\nVelocità vettoriale istantanea\nLa velocità vettoriale istantanea \\overrightarrow{v}(t) è la derivata del vettore posizione rispetto al tempo:\n\\qquad \\overrightarrow{v}(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta \\overrightarrow{r}}{\\Delta t} = \\frac{d\\overrightarrow{r}}{dt}\nIn coordinate cartesiane:\n\\qquad \\overrightarrow{v}(t) = \\frac{dx}{dt} \\hat{i} + \\frac{dy}{dt} \\hat{j} + \\frac{dz}{dt} \\hat{k} = v_x(t) \\hat{i} + v_y(t) \\hat{j} + v_z(t) \\hat{k}\nReferences"},"6--full-note/fisica1--Lez04":{"slug":"6--full-note/fisica1--Lez04","filePath":"6- full note/fisica1- Lez04.md","title":"fisica1- Lez04","links":[],"tags":[],"content":"Velocità Vettoriale\nDefinizione\n\nLa velocità vettoriale in un certo istante è definita come il rapporto tra il vettore spostamento medio e l’intervallo di tempo in cui avviene questo spostamento, valutato per un intervallo di tempo piccolo. Matematicamente:\n\\vec{v}(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta \\vec{r}}{\\Delta t} = \\frac{d\\vec{r}}{dt}\nDove:\n\n\\vec{v} è il vettore velocità.\n\\Delta \\vec{r} è il vettore spostamento.\n\\Delta t è l’intervallo di tempo.\n\\frac{d\\vec{r}}{dt} è la derivata del vettore posizione rispetto al tempo.\n\nInterpretazione Grafica\nConsideriamo due istanti di tempo, t_1 e t_2, con i corrispondenti vettori posizione \\vec{r_1} e \\vec{r_2}. Il vettore spostamento \\Delta \\vec{r} è dato da \\vec{r_2} - \\vec{r_1}.\n\nDirezione: \\Delta \\vec{r} è diretto come la corda che congiunge i due punti sulla traiettoria tra t_1 e t_2.\nModulo: In generale, il modulo di \\Delta \\vec{r} è diverso dallo spazio percorso sulla traiettoria, \\Delta s. Quindi: |\\Delta \\vec{r}| \\neq \\Delta s.\n\nCosa Succede Quando \\Delta t Diventa Molto Piccolo?\nQuando l’intervallo di tempo \\Delta t tende a zero (cioè, t_2 si avvicina a t_1):\n\nModulo: La lunghezza del vettore \\Delta \\vec{r} tende a diventare uguale allo spazio percorso sulla traiettoria, \\Delta s. Quindi: \\lim_{\\Delta t \\to 0} |\\Delta \\vec{r}| = ds.\nDirezione: Il vettore \\Delta \\vec{r} diventa tangente alla traiettoria nel punto considerato.\n\nVettore Spostamento Infinitesimo\nQuando \\Delta t \\to 0, il vettore \\Delta \\vec{r} diventa un vettore infinitesimo, d\\vec{r}. Questo vettore ha le seguenti proprietà:\n\nModulo: |d\\vec{r}| = ds, dove ds è la variazione infinitesima della scissa curvilinea.\nDirezione: d\\vec{r} è tangente alla traiettoria.\n\nIntroducendo il versore tangente \\hat{u}_t, che ha direzione tangente alla traiettoria, possiamo scrivere:\nd\\vec{r} = ds \\cdot \\hat{u}_t\n\nVelocità Vettoriale in Termini di Versore Tangente\nSostituendo l’espressione di d\\vec{r} nella definizione di velocità vettoriale, otteniamo:\n\\vec{v} = \\frac{d\\vec{r}}{dt} = \\frac{ds}{dt} \\hat{u}_t\nNotiamo che \\frac{ds}{dt} è la velocità scalare istantanea, che indichiamo con v. Quindi:\n\\vec{v} = v \\hat{u}_t\nQuesto significa che il vettore velocità è sempre tangente alla traiettoria e il suo valore è dato dalla velocità scalare. Il segno della velocità scalare indica il verso del moto rispetto al verso positivo scelto sulla traiettoria.\nComponenti Intrinseche alla Traiettoria\n\nData una traiettoria, si definiscono due versori caratteristici in ogni punto:\n\nVersore Tangente (\\hat{u}_t): Indica la direzione tangente alla traiettoria e ha il verso positivo scelto sulla traiettoria.\nVersore Normale (\\hat{u}_n): È ortogonale al versore tangente e giace nel piano osculatore (il piano che meglio approssima la traiettoria in un intorno del punto). Il suo verso è convenzionalmente scelto verso l’interno della concavità della traiettoria.\n\n\nCaso di Moto Rettilineo: Se il punto si muove su una retta, il versore normale non è definito in quanto non c’è curvatura.\n\nAccelerazione Vettoriale\nDefinizione\nL’accelerazione vettoriale istantanea è definita come la derivata del vettore velocità rispetto al tempo:\n\\vec{a} = \\frac{d\\vec{v}}{dt}\nVariazione del Vettore Velocità\nIl vettore velocità può variare sia in modulo (velocità scalare) che in direzione.\nCalcolo Analitico\nUtilizziamo l’espressione del vettore velocità in termini di velocità scalare e versore tangente:\n\\vec{v} = v \\hat{u}_t\nDeriviamo rispetto al tempo:\n\\vec{a} = \\frac{d\\vec{v}}{dt} = \\frac{d}{dt} (v \\hat{u}_t) = \\frac{dv}{dt} \\hat{u}_t + v \\frac{d\\hat{u}_t}{dt}\nQuesta formula mostra che l’accelerazione vettoriale ha due componenti: una dovuta alla variazione del modulo della velocità e una dovuta alla variazione della direzione.\n\nEcco una spiegazione dettagliata, passo per passo, di come il professore spiega la derivata del vettore tangente nel tempo, con particolare attenzione ai passaggi matematici, agli esempi e agli esercizi, formattata per chiarezza e leggibilità.\nDerivata del Vettore Tangente\nDerivata di un Prodotto\nLa derivata di un prodotto è fondamentale per capire come varia il vettore accelerazione. Il vettore accelerazione è una derivata di un prodotto tra la velocità scalare e il versore tangente. Perciò, si applicano le regole di derivazione di un prodotto.\nSiano v(t) la velocità scalare e \\hat{T}(t) il versore tangente. Il vettore accelerazione \\vec{a}(t) è dato da:\n\\qquad \\vec{a}(t) = \\frac{d}{dt} [v(t) \\cdot \\hat{T}(t)]\nApplicando la regola della derivata del prodotto:\n\\qquad \\vec{a}(t) = \\frac{dv(t)}{dt} \\hat{T}(t) + v(t) \\frac{d\\hat{T}(t)}{dt}\nQuesta equazione mostra che l’accelerazione vettoriale ha due componenti:\n\nVariazione della velocità scalare nel tempo.\nVariazione della direzione del versore tangente nel tempo.\n\nSignificato Fisico dei Termini\n\n\nPrimo Termine: \\frac{dv(t)}{dt} \\hat{T}(t)\n\nQuesto termine esiste quando la velocità scalare varia nel tempo, ovvero quando c’è un’accelerazione scalare.\nÈ diretto tangenzialmente alla traiettoria.\nRappresenta l’accelerazione tangente, che indica come il valore della velocità cambia.\nIl modulo di questo vettore è l’accelerazione scalare istantanea.\n\n\n\nSecondo Termine: v(t) \\frac{d\\hat{T}(t)}{dt}\n\nQuesto termine esiste se varia nel tempo la direzione del versore tangente, il che accade quando il moto è curvilineo.\nRappresenta la variazione della direzione della velocità.\nQuesto termine è legato all’accelerazione normale, che è diretta ortogonalmente alla traiettoria.\n\n\n\nComponenti dell’Accelerazione\nIn generale, il vettore accelerazione è composto da due componenti che si sommano vettorialmente: l’accelerazione tangente e l’accelerazione normale.\n\\qquad \\vec{a} = \\vec{a}_T + \\vec{a}_N\nDove:\n\n\\vec{a}_T è l’accelerazione tangente.\n\\vec{a}_N è l’accelerazione normale.\n\nProgetto di un’Automobile\nConsiderando il progetto di un’automobile di Formula 1, si devono considerare entrambe le componenti dell’accelerazione:\n\nAccelerazione Tangente: Per raggiungere una certa velocità massima, è necessario progettare un motore che sia in grado di imprimere una certa accelerazione scalare massima.\nAccelerazione Normale: Per fare in modo che la macchina riesca a percorrere una curva senza uscire di strada, bisogna lavorare sull’accelerazione normale. Questo implica considerare l’aderenza delle gomme e la forza che spinge l’auto verso il centro della traiettoria.\n\nCalcolo dell’Accelerazione Normale\nL’attenzione si sposta sul termine dell’accelerazione normale: v(t) \\frac{d\\hat{T}(t)}{dt}. La domanda chiave è come calcolare la derivata di un versore.\nDirezione della Derivata del Versore Tangente\nPer trovare la direzione del vettore derivata del versore tangente, si utilizza un trucco matematico.\nSi parte dall’identità:\n\\qquad \\hat{T}(t) \\cdot \\hat{T}(t) = 1\nDerivando entrambi i membri rispetto al tempo:\n\\qquad \\frac{d}{dt} [\\hat{T}(t) \\cdot \\hat{T}(t)] = \\frac{d}{dt}\n\\qquad \\frac{d\\hat{T}(t)}{dt} \\cdot \\hat{T}(t) + \\hat{T}(t) \\cdot \\frac{d\\hat{T}(t)}{dt} = 0\nPoiché il prodotto scalare è commutativo:\n\\qquad 2 \\left( \\hat{T}(t) \\cdot \\frac{d\\hat{T}(t)}{dt} \\right) = 0\nQuesto implica che:\n\\qquad \\hat{T}(t) \\cdot \\frac{d\\hat{T}(t)}{dt} = 0\nIl prodotto scalare è zero quando i due vettori sono ortogonali. Quindi, la derivata del versore tangente è ortogonale al versore tangente stesso. La direzione ortogonale al versore tangente è definita dal versore normale \\hat{N}(t).\nEspressione della Derivata del Versore Tangente\nSi può esprimere la derivata del versore tangente come:\n\\qquad \\frac{d\\hat{T}(t)}{dt} = \\left( \\frac{d\\theta}{dt} \\right) \\hat{N}(t)\nDove \\frac{d\\theta}{dt} rappresenta la variazione infinitesima dell’angolo del versore tangente nel tempo, e \\hat{N}(t) è il versore normale.\nCalcolo del Valore di d\\theta\nPer capire quanto vale d\\theta, si considera la differenza tra il versore \\hat{T}(t_1) all’istante t_1 e il versore \\hat{T}(t_2) all’istante t_2.\nSi disegnano i due versori con origine comune e si calcola il vettore differenza \\Delta \\hat{T}. La lunghezza di questo vettore differenza è approssimativamente uguale alla lunghezza dell’arco di circonferenza sotteso dall’angolo d\\theta.\nLa lunghezza dell’arco di circonferenza è data da r \\cdot d\\theta, dove r è il raggio della circonferenza. In questo caso, il raggio è il modulo del versore tangente, che è 1.\n\nEcco una spiegazione dettagliata, formattata e con notazione matematica in LaTeX, dei concetti espressi nella flashcard, seguendo l’ordine e il contenuto presentato.\nCirconferenza di Raggio Unitario e Delta UDT\n\nDefinizione: Si parte da una circonferenza centrata nell’origine di un versore, con raggio unitario.\nDelta UD(t): Viene identificato come un d\\theta, dove d\\theta rappresenta l’ampiezza dell’angolo.\nLimite per \\Delta t \\to 0: \\lim_{\\Delta t \\to 0} |\\Delta \\vec{U_D}(t)| = d\\theta. Questo significa che la lunghezza del vettore \\Delta \\vec{U_D}(t) tende a d\\theta quando \\Delta t si avvicina a zero.\n\nAngolo d\\theta e Direzioni Ortogonali alla Traiettoria\n\nDefinizione di d\\theta: L’angolo d\\theta è formato dalla direzione del versore \\vec{u_t} all’istante t_1 e dalla direzione del versore \\vec{u_t} all’istante t_2.\nDirezioni Normali: Si considerano le direzioni ortogonali alla traiettoria (direzioni del versore normale) negli istanti t_1 e t_2.\nIncontro delle Direzioni Normali: Queste direzioni si incontrano in un punto formando un angolo. L’ampiezza di questo angolo è proprio d\\theta. Questo perché le rette normali sono mutuamente ortogonali alle direzioni dei versori tangenti.\n\nCerchio Osculatore\n\nDefinizione: Dato un punto su una traiettoria, il cerchio osculatore è quella particolare circonferenza che meglio approssima la traiettoria in quel punto.\nCondizioni:\n\nPassa per il punto P sulla traiettoria.\nHa la stessa tangente alla curva in P.\nHa la stessa curvatura della traiettoria in P. Matematicamente, questo significa che ha la stessa derivata prima e seconda della traiettoria in P.\n\n\nRaggio Osculatore (\\rho): Ogni punto della traiettoria può essere approssimato da una circonferenza con un certo raggio \\rho, chiamato raggio osculatore.\n\nCome Disegnare la Circonferenza Osculatrice\n\nIntorno del Punto P: Si prende un intorno attorno al punto P sulla traiettoria.\nRetta Ortogonale: Si tracciano le rette ortogonali alla traiettoria negli estremi di questo intorno.\nCentro del Cerchio: Le rette si incontrano in un punto, che è il centro del cerchio osculatore.\n\n\nRelazione tra Curvatura e Raggio Osculatore: Il raggio osculatore è inversamente proporzionale alla curvatura della traiettoria.\n\nCurvatura Accentata: Se la traiettoria ha una curvatura accentuata, il raggio osculatore è piccolo.\nCurvatura Dolce: Se la traiettoria ha una curvatura dolce, il raggio osculatore è grande.\n\n\n\nLegame tra d\\theta, Raggio Osculatore e Spazio Percorso\n\nArco di Circonferenza: L’angolo d\\theta “vede” sopra di sé un tratto di traiettoria (arco di circonferenza) di lunghezza ds.\nRelazione Fondamentale: d\\theta = \\frac{ds}{\\rho}, dove ds è l’arco di circonferenza e \\rho è il raggio del cerchio osculatore.\n\nDerivazione dell’Accelerazione Normale\n\nEquazione di Partenza: a = v \\frac{d\\vec{u_t}}{dt}.\nSostituzione di d\\theta: Si sostituisce d\\theta con \\frac{ds}{\\rho}.\nEspressione per l’Accelerazione Normale: a_N = v \\frac{ds}{\\rho dt} \\vec{u_N} = \\frac{v^2}{\\rho} \\vec{u_N}.\n\nAccelerazione Normale: \\vec{a_N} = \\frac{v^2}{\\rho} \\vec{u_N}, dove v è la velocità scalare, \\rho è il raggio del cerchio osculatore, e \\vec{u_N} è il versore normale.\n\n\n\nComponenti dell’Accelerazione\n\nAccelerazione Tangente (a_T): Informa su come varia il valore della velocità.\nAccelerazione Normale (a_N): Informa sul cambio di direzione della traiettoria. Non dipende dalla derivata della velocità nel tempo, ma solo dal suo valore al quadrato.\n\nSignificato del Raggio di Curvatura nell’Accelerazione Normale\n\nCurva Stretta: Raggio di curvatura piccolo \\implies accelerazione normale alta (cambio di direzione elevato).\nCurva Dolce: Raggio di curvatura grande \\implies accelerazione normale bassa (cambio di direzione lieve).\nMoto Rettilineo: Raggio di curvatura infinito \\implies accelerazione normale nulla (nessun cambio di direzione).\n\nTabella Riassuntiva: Moto e Accelerazioni\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipo di MotoTraiettoriaa_Ta_NRettilineo UniformeRettilinea00Rettilineo AccelleratoRettilineaCostante (\\neq 0)0Circolare UniformeCircolare0\\frac{v_0^2}{R}Circolare AccelleratoCircolareCostante (\\neq 0)\\frac{v(t)^2}{R}, v(t) lineare\n\nMoto Rettilineo: L’accelerazione normale è sempre zero.\nMoto Circolare: L’accelerazione normale è v^2 / R, dove R è il raggio della circonferenza.\n\nSpero che questa riscrittura dettagliata e formattata sia di aiuto!"},"6--full-note/fisica1--Lez07":{"slug":"6--full-note/fisica1--Lez07","filePath":"6- full note/fisica1- Lez07.md","title":"fisica1- Lez07","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-11 13:30\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nfisica1- Lez07\nFISICA 1\nDinamica di un Punto Materiale: Le Forze\n1. Forza Elastica\nLa forza elastica è una forza che si manifesta nei corpi con proprietà elastiche. L’azione di questa forza viene modellizzata tramite l’uso di una molla.\n1.1. Caratteristiche della Molla e Costante Elastica\nOgni molla è caratterizzata da un parametro specifico chiamato costante elastica (k).\n\nUna costante elastica elevata indica una molla rigida, difficile da deformare.\nUna costante elastica bassa indica una molla molle, facile da deformare.\nDimensionalmente, la costante elastica si misura in Newton su metri (N/m).\n\n1.2. Legge di Hooke\nQuando una molla viene allungata o compressa di una certa deformazione (\\Delta L = L - L_0), essa reagisce esercitando una forza di richiamo (F_{el}) che tende a riportarla nella sua posizione di equilibrio (L_0). Questa forza è descritta dalla legge di Hooke:\nF_{el} = -k \\Delta L\nDove:\n\nF_{el} è la forza elastica (vettore).\nk è la costante elastica (scalare, sempre positiva).\n\\Delta L = L - L_0 è il vettore spostamento (o deformazione) rispetto alla lunghezza a riposo (L_0).\n\nIl segno meno indica che la forza elastica è una forza di richiamo, ovvero ha la stessa direzione della deformazione ma verso opposto.\n\nSe la molla è allungata (\\Delta L diretto verso destra), la forza elastica è diretta verso sinistra, tendendo a riportare la molla alla sua lunghezza di riposo.\nSe la molla è compressa (\\Delta L diretto verso sinistra), la forza elastica è diretta verso destra, tendendo a riportare la molla alla sua lunghezza di riposo.\n\nÈ importante ragionare sulla direzione della deformazione e sul fatto che la forza elastica è sempre una forza di richiamo, piuttosto che concentrarsi unicamente sulla formula vettoriale. La forza elastica agisce sempre parallelamente alla direzione in cui è disposta la molla.\n1.3. Formulazioni Scalari Lungo un Asse\nPer semplificare la scrittura, si può definire un asse x parallelo alla direzione della molla, con origine in un punto conveniente.\n\n\nSe l’origine è fissata all’estremo vincolato della molla, la posizione della molla è data da x, e la lunghezza a riposo è x_0. La forza elastica può essere scritta come:\nF_{el} = -k (x - x_0) \\hat{u}_x\ndove \\hat{u}_x è il versore dell’asse x.\n\n\nSe l’origine è posta direttamente nella posizione della molla a riposo (x_0 = 0), la formula si semplifica ulteriormente:\nF_{el} = -k x \\hat{u}_x\ndove x rappresenta direttamente l’allungamento (se positivo) o la compressione (se negativo) della molla.\n\n\nIn alcuni esercizi, le molle possono essere considerate di lunghezza trascurabile (x_0 \\approx 0) quando la deformazione è molto maggiore della lunghezza iniziale. In questo caso, la formula si riduce a:\nF_{el} = -k x \\hat{u}_x.\n\n\n1.4. Sistemi Massa-Molla e Moto Armonico\nSe una massa M viene collegata a una molla, deformata e poi lasciata libera, essa oscillerà attorno alla posizione di riposo. Il moto risultante è un moto armonico semplice, descritto dalle leggi orarie studiate in cinematica. Tuttavia, l’analisi dettagliata di questo moto non viene trattata in questa fase.\n2. Funi Ideali\nUna fune ideale è un oggetto che può essere pensato come un filo con sezione infinitesima e presenta le seguenti caratteristiche:\n\nNon è elastica: ha una lunghezza costante.\nMassa trascurabile: la massa della fune ideale è considerata nulla (m_{fune} = 0).\nSopporta solo forze di trazione: non può sopportare forze di compressione, altrimenti si piega.\n\nLe funi vengono utilizzate per trasferire una forza da un punto all’altro lungo la loro direzione.\n2.1. Tensione della Fune\nLa forza che agisce su una fune tesa è chiamata tensione (T). Se si applica una forza a un’estremità di una fune ideale, questa forza si propaga inalterata lungo tutta la fune.\nConsiderando una fune ideale con una tensione T_A all’estremo A e T_B all’estremo B, e applicando il secondo principio della dinamica (\\vec{F}_{ris} = m \\vec{a}) lungo l’asse x parallelo alla fune:\nT_A - T_B = m_{fune} a_x\nDato che la massa della fune ideale è nulla (m_{fune} = 0), si ha:\nT_A - T_B = 0 \\implies T_A = T_B = T\nPertanto, in una fune ideale, la tensione ha lo stesso valore in ogni punto. La tensione è sempre diretta lungo la direzione della fune e verso l’esterno rispetto al corpo a cui è collegata, in quanto la fune può solo tirare (forza di trazione).\n2.2. Vincolo Cinematico Imposto da una Fune Inestensibile\nQuando due o più corpi sono collegati da una fune ideale (inestensibile), i loro movimenti risultano vincolati. Se due vagoni di masse m_A e m_B sono collegati da una fune di lunghezza L_{fune}, e si definisce un asse x, le loro posizioni x_A(t) e x_B(t) soddisfano la relazione:\nx_A(t) = x_B(t) + L_{fune} (o x_B(t) = x_A(t) + L_{fune}, a seconda della scelta dell’origine e del verso dell’asse)\nDerivando questa relazione rispetto al tempo, si ottengono le velocità dei due vagoni:\n\\frac{dx_A}{dt} = \\frac{dx_B}{dt} + \\frac{dL_{fune}}{dt}\nPoiché la lunghezza della fune è costante (\\frac{dL_{fune}}{dt} = 0), si ha:\nv_A(t) = v_B(t)\nDerivando ulteriormente rispetto al tempo, si ottengono le accelerazioni:\n\\frac{dv_A}{dt} = \\frac{dv_B}{dt} \\implies a_A(t) = a_B(t)\nQuesto dimostra che tutti i punti di una fune inestensibile (e gli oggetti ad essa collegati) hanno la stessa velocità e la stessa accelerazione in modulo, anche se la direzione del moto può essere diversa a causa di elementi come le carrucole.\n3. Carrucole Ideali\nUna carrucola (o puleggia) è un disco in grado di ruotare attorno al proprio centro. Le funi possono scorrere attorno alla carrucola senza scivolare, permettendo di trasferire il movimento in direzioni diverse.\nPer la prima parte del corso, le carrucole vengono considerate ideali, ovvero prive di massa (m_{carrucola} = 0). In questa approssimazione, non è necessario considerare la rotazione della carrucola in dettaglio, e la tensione della fune si propaga inalterata attraverso la carrucola.\n4. Esempio di Sistema Massa-Fune-Carrucola\nConsideriamo due corpi di masse m_A e m_B collegati da una fune ideale che passa sopra una carrucola ideale. Supponiamo che m_A &gt; m_B. Ci si aspetta che il corpo A scenda e il corpo B salga con la stessa accelerazione in modulo (a) ma in direzioni opposte.\n4.1. Analisi delle Forze sul Corpo A\n\nForza peso (P_A): diretta verso il basso, con modulo m_A g. In termini vettoriali, se si definisce un asse x verticale diretto verso il basso, \\vec{P}_A = m_A g \\hat{u}_x.\nTensione della fune (T): diretta verso l’alto, che si oppone alla caduta. In termini vettoriali, \\vec{T}_A = -T \\hat{u}_x.\n\nApplicando il secondo principio della dinamica al corpo A lungo l’asse x:\n\\sum F_x = m_A a_x m_A g - T = m_A a (equazione 1)\ndove a è l’accelerazione del corpo A verso il basso (positiva secondo la scelta dell’asse).\n4.2. Analisi delle Forze sul Corpo B\n\nForza peso (P_B): diretta verso il basso, con modulo m_B g. Se si considera un asse y verticale diretto verso l’alto per il corpo B (con accelerazione positiva verso l’alto), \\vec{P}_B = -m_B g \\hat{u}_y.\nTensione della fune (T): diretta verso l’alto, che lo trascina. In termini vettoriali, \\vec{T}_B = T \\hat{u}_y.\n\nApplicando il secondo principio della dinamica al corpo B lungo l’asse y:\n\\sum F_y = m_B a_y T - m_B g = m_B a (equazione 2)\ndove a è il modulo dell’accelerazione del corpo B verso l’alto (positiva secondo la scelta dell’asse), uguale in modulo all’accelerazione del corpo A a causa del vincolo della fune inestensibile.\n4.3. Risoluzione del Sistema di Equazioni\nSi ottiene un sistema di due equazioni con due incognite (a e T):\n\nm_A g - T = m_A a\nT - m_B g = m_B a\n\nSommando le due equazioni, la tensione T si annulla:\n(m_A g - T) + (T - m_B g) = m_A a + m_B a m_A g - m_B g = (m_A + m_B) a (m_A - m_B) g = (m_A + m_B) a\nRisolvendo per l’accelerazione a:\na = \\frac{m_A - m_B}{m_A + m_B} g\n4.4. Interpretazione del Risultato\n\nSe m_A &gt; m_B, allora a &gt; 0, il che significa che il corpo A accelera verso il basso e il corpo B accelera verso l’alto, come previsto.\nSe m_B &gt; m_A, allora a &lt; 0, il che indica che l’accelerazione ha il verso opposto a quello ipotizzato (il corpo B scende e il corpo A sale).\nSe m_A = m_B, allora a = 0, il sistema è in equilibrio (o si muove a velocità costante se inizialmente in movimento).\n\nQuesto esempio dimostra come applicare i concetti di forza peso, tensione e il secondo principio della dinamica a un sistema collegato, tenendo conto del vincolo imposto dalla fune inestensibile e dalla carrucola ideale.\nSpiegazione delle Reazioni Vincolari e dell’Attrito\nIntroduzione\nIl professore introduce il concetto di reazioni vincolari, forze generate da una superficie d’appoggio quando un corpo è a contatto con essa. Queste reazioni impediscono al corpo di penetrare la superficie e possono anche opporsi al suo movimento lungo la superficie.\nReazioni Vincolari (Reazioni di una Superficie d’Appoggio)\nLe reazioni vincolari si manifestano quando un oggetto è appoggiato su un piano o una superficie. La regola è valida sia per superfici orizzontali che inclinate o verticali. La loro esistenza è legata alla struttura della materia che rende rigidi gli oggetti.\nReazione Normale alla Superficie (R_n)\nQuando un oggetto è appoggiato su una superficie, una delle forze generate dalla superficie di appoggio è la reazione normale [R_n].\n\nÈ diretta ortogonalmente (perpendicolarmente) alla superficie di appoggio.\nEsiste sempre quando un oggetto è appoggiato su una superficie e non la sta sfondando.\nSi oppone al tentativo dell’oggetto di penetrare la superficie.\nLa sua direzione è sempre verso l’esterno rispetto al piano d’appoggio.\n\nEsempi:\n\nUn oggetto su un piano orizzontale: la reazione normale è diretta verso l’alto.\nUna mano che spinge contro una parete verticale: la reazione normale esercitata dalla parete sulla mano è orizzontale e opposta alla spinta.\nUn oggetto su un piano inclinato: la reazione normale è perpendicolare al piano inclinato e diretta verso l’esterno.\n\nIntensità della Reazione Normale:\n\nL’intensità della reazione normale non ha un’espressione numerica fissa.\nDipende dalle forze che l’oggetto sta applicando sulla superficie d’appoggio.\nSi calcola imponendo l’equilibrio delle forze in direzione normale al piano d’appoggio, poiché non vogliamo che l’oggetto sfondi la superficie.\n\nMatematicamente, in assenza di accelerazione nella direzione normale (a_n = 0), la somma delle forze in quella direzione è zero: \\sum F_n = m a_n = 0\nQuesto permette di determinare il valore di R_n caso per caso, bilanciando le altre componenti di forza perpendicolari alla superficie.\nCarico di Rottura:\n\nUna superficie d’appoggio ha un carico di rottura, un valore massimo della reazione normale che può generare senza essere sfondata.\nAnche le funi hanno un carico di rottura, una tensione massima che possono sopportare prima di rompersi.\n\nReazione Tangenziale alla Superficie (R_T) o Forza d’Attrito\nUna superficie d’appoggio può generare anche una forza diretta in direzione tangente (parallela) al piano d’appoggio, soprattutto se la superficie non è perfettamente liscia (scabra o rugosa) e quindi presenta attrito.\n\nSe si applica una forza esterna (F_0) tangente alla superficie a un oggetto appoggiato su di essa, e l’oggetto rimane fermo, deve esistere una forza che bilancia F_0.\nQuesta forza è la reazione tangente (R_T), che si oppone al tentativo di movimento.\nÈ più comunemente conosciuta come forza d’attrito.\n\nMatematicamente, per l’equilibrio in direzione tangente (t), la somma delle forze in quella direzione deve essere zero: \\sum F_t = 0 F_0 - R_T = 0 \\implies R_T = F_0\nTipi di Attrito:\nLa reazione tangente (R_T) racchiude diverse forme di attrito:\n\nAttrito Radente: Si manifesta quando un oggetto solido vorrebbe strisciare su una superficie solida.\n\nAttrito Radente Statico (F_s): È la forza che impedisce l’inizio del movimento di strisciamento tra due superfici a contatto. Agisce finché l’oggetto rimane fermo nonostante l’applicazione di una forza esterna.\nAttrito Radente Dinamico: È la forza che si oppone al movimento di strisciamento quando un oggetto è già in movimento su una superficie. Rallenta il movimento del corpo, causando un’accelerazione inferiore rispetto al caso di superficie liscia.\n\n\nAttrito Viscoso: Si verifica quando un oggetto solido si muove all’interno di un fluido (liquido o gas). La forza di attrito viscoso rallenta il movimento dell’oggetto ed è tanto più intensa quanto più viscoso è il fluido.\nAttrito Volvente: Entra in gioco quando un oggetto rotola su una superficie. È generalmente molto inferiore all’attrito radente, motivo per cui è più facile far rotolare un oggetto che farlo strisciare.\n\nEsempio: Attrito Radente Statico su un Piano Inclinato\nConsideriamo una monetina appoggiata su un computer inclinato di un angolo \\theta. Fino a un certo angolo di inclinazione, la monetina rimane ferma. Analizziamo le forze che agiscono sulla monetina di massa M:\n\nForza Peso (P o mg): Diretta verticalmente verso il basso.\nReazione Normale (R_n): Perpendicolare al piano inclinato e diretta verso l’alto.\nReazione Tangenziale (R_T o F_s): Parallela al piano inclinato e diretta verso l’alto (opposta al potenziale movimento verso il basso).\n\nScomponiamo la forza peso in due componenti rispetto al piano inclinato:\n\nComponente Normale (P_n): Perpendicolare al piano inclinato, P_n = mg \\cos(\\theta), diretta verso il piano.\nComponente Tangenziale (P_t): Parallela al piano inclinato, P_t = mg \\sin(\\theta), diretta verso il basso.\n\nApplichiamo la condizione di equilibrio (accelerazione nulla) nelle direzioni normale e tangente:\nDirezione Normale:\nLa monetina non si muove perpendicolarmente al piano, quindi la somma delle forze in direzione normale è zero: R_n - P_n = 0 R_n - mg \\cos(\\theta) = 0 \\boxed{R_n = mg \\cos(\\theta)}\nQuesta equazione ci permette di calcolare l’intensità della reazione normale, che bilancia la componente normale della forza peso.\nDirezione Tangenziale (Piano Liscio):\nSe il piano fosse perfettamente liscio, non ci sarebbe attrito (R_T = 0). In questo caso, la componente tangenziale della forza peso causerebbe un’accelerazione della monetina verso il basso: P_t = ma mg \\sin(\\theta) = ma \\boxed{a = g \\sin(\\theta)}\nAnche una piccola inclinazione causerebbe lo scivolamento della monetina.\nDirezione Tangenziale (Piano Scabro - Attrito Statico):\nPoiché la monetina rimane ferma fino a un certo angolo, deve esistere una forza che bilancia la componente tangenziale della forza peso. Questa forza è la reazione tangente o forza d’attrito radente statico (R_T o F_s).\nPer l’equilibrio in direzione tangente: P_t - R_T = 0 mg \\sin(\\theta) - R_T = 0 \\boxed{R_T = mg \\sin(\\theta)}\nQuindi, la forza d’attrito statico ha un’intensità uguale alla componente tangenziale della forza peso e si oppone al potenziale movimento. Il piano d’appoggio esercita quindi una forza che ha due componenti: la reazione normale che bilancia la componente normale del peso e la reazione tangente (attrito statico) che bilancia la componente tangente del peso, mantenendo la monetina in equilibrio. Questa forza di attrito statico permette al corpo di rimanere in equilibrio nonostante la presenza di una forza che tenderebbe a farlo muovere tangenzialmente al piano d’appoggio. La forza d’attrito statico viene spesso indicata anche con il simbolo F_s.\nSpiegazione della Forza d’Attrito Radente, Viscoso e Moto Circolare\nForza d’Attrito Radente Statico\nLa forza d’attrito radente statico è quella forza che permette il bilancio delle forze in direzione tangente, impedendo al corpo di muoversi in tale direzione. La sua intensità non è nota a priori, ma si calcola imponendo la condizione che il corpo rimanga fermo. In altre parole, l’intensità della forza d’attrito radente statico (RT) è tale da rendere nulla la risultante delle forze in direzione tangente.\nOrigine Fisica della Forza d’Attrito Radente Statico\nL’origine fisica di questa forza è di natura elettromagnetica, dovuta all’interazione tra le cariche presenti sulle superfici degli oggetti a contatto. A livello microscopico, anche superfici apparentemente lisce presentano delle microrugosità. Quando due superfici vengono a contatto, l’attrazione elettrostatica tra le cariche vicine provoca la formazione di super microfusioni, agendo come punti di vincolo che trattengono gli oggetti.\nPiù le superfici sono rugose, maggiori sono le microfusioni, e la forza d’attrito statico è più intensa. Le caratteristiche superficiali del materiale influenzano l’efficacia di questa forza.\nValore Massimo della Forza d’Attrito Radente Statico\nLa reazione tangente al piano d’appoggio (forza d’attrito radente statico) non può bilanciare forze di qualunque intensità. Oltre un certo valore massimo, le microfusioni si rompono e l’oggetto inizia a muoversi. Questo significa che la forza d’attrito radente statico (RT) può assumere tutti i valori fino a un valore massimo (RT_{max}):\nRT \\leq RT_{max}\nSe l’intensità di RT supera RT_{max}, non si è più in condizioni statiche e si ha movimento.\nSperimentalmente si è trovato che il valore massimo della forza d’attrito radente statico è direttamente proporzionale all’intensità della reazione normale (R_N) tramite un coefficiente di proporzionalità chiamato coefficiente di attrito statico (\\mu_s):\nRT_{max} = \\mu_s R_N\nIl coefficiente di attrito statico (\\mu_s) dipende dai materiali a contatto e dalla rugosità delle superfici.\nÈ fondamentale sottolineare che RT = \\mu_s R_N rappresenta il valore massimo della forza d’attrito radente statico, non il suo valore in generale. Il valore effettivo di RT si determina imponendo il bilancio delle forze tangenti.\nEsempio: Moneta su un Piano Inclato\nConsideriamo una moneta appoggiata su un piano inclinato di un angolo \\theta. Per trovare l’angolo massimo (\\theta_{max}) affinché la moneta rimanga ferma, si impone che la forza d’attrito radente statico (RT) sia minore o uguale al suo valore massimo (RT_{max}).\nLe forze agenti sulla moneta sono la forza peso (mg) e la reazione del piano, scomponibile in una componente normale (R_N) e una tangente (forza d’attrito RT).\nDalla componente normale delle forze, imponendo l’equilibrio in direzione perpendicolare al piano, si ha:\nR_N - mg \\cos \\theta = 0 \\implies R_N = mg \\cos \\theta\nDalla componente tangente delle forze, imponendo l’equilibrio in direzione parallela al piano (condizione di non movimento), si ha:\nRT - mg \\sin \\theta = 0 \\implies RT = mg \\sin \\theta\nPerché la moneta rimanga ferma, deve valere la condizione:\nRT \\leq RT_{max}\nSostituendo le espressioni trovate:\nmg \\sin \\theta \\leq \\mu_s R_N\nmg \\sin \\theta \\leq \\mu_s (mg \\cos \\theta)\nDividendo per mg \\cos \\theta (assumendo \\cos \\theta \\neq 0):\n\\frac{\\sin \\theta}{\\cos \\theta} \\leq \\mu_s\n\\tan \\theta \\leq \\mu_s\nQuindi, l’angolo massimo di inclinazione (\\theta_{max}) per cui la moneta rimane ferma è dato da:\n\\theta_{max} = \\arctan(\\mu_s)\nFinché l’angolo di inclinazione \\theta è tale che \\tan \\theta \\leq \\mu_s, l’oggetto non si muove. Oltre questo angolo, l’oggetto inizierà a scivolare.\nForza d’Attrito Radente Dinamico\nLa forza d’attrito radente dinamico (RT) si manifesta quando un corpo è già in movimento su una superficie scabra. È una forza tangente alla direzione del movimento e diretta in verso opposto, con lo scopo di rallentare il movimento, ma non di bloccarlo.\nPer determinare la direzione della forza d’attrito dinamico, si immagina la situazione in assenza di attrito per capire in quale direzione il corpo tenderebbe a muoversi; la forza d’attrito dinamico avrà la stessa direzione ma verso opposto.\nIntensità della Forza d’Attrito Radente Dinamico\nSperimentalmente si è trovato che l’intensità della forza d’attrito radente dinamico (RT) è proporzionale all’intensità della reazione normale (R_N) tramite un coefficiente di proporzionalità chiamato coefficiente di attrito dinamico (\\mu_d):\nRT = \\mu_d R_N\nIl coefficiente di attrito dinamico (\\mu_d) dipende anch’esso dai materiali a contatto.\nRelazione tra \\mu_s e \\mu_d\nSi osserva sperimentalmente che, per una data coppia di superfici, il coefficiente di attrito statico è generalmente maggiore del coefficiente di attrito dinamico (\\mu_s &gt; \\mu_d). Questo significa che è più difficile mettere in movimento un oggetto fermo che mantenerlo in movimento. La ragione risiede nel fatto che, una volta superata la condizione di equilibrio e iniziato il movimento, le microfusioni tra le superfici si rompono e si riformano continuamente, ma in numero minore rispetto alla condizione statica.\nNatura Adimensionale dei Coefficienti d’Attrito\nSia il coefficiente di attrito statico (\\mu_s) che quello dinamico (\\mu_d) sono grandezze adimensionali. Questo perché mettono in relazione due forze (la reazione tangente e la reazione normale), che hanno la stessa dimensione fisica.\nEsempio: Oggetto che Scivola su un Piano Inclnato Scabro\nConsideriamo ora lo stesso oggetto sul piano inclinato, ma con un angolo tale che l’oggetto sta scivolando verso il basso con un’accelerazione. In questo caso, agisce la forza d’attrito radente dinamico (RT).\nRiprendendo le forze scomposte:\n\nComponente normale: R_N = mg \\cos \\theta\nComponente tangente (direzione positiva verso il basso): mg \\sin \\theta - RT = ma\n\nLa forza d’attrito dinamico è data da:\nRT = \\mu_d R_N = \\mu_d (mg \\cos \\theta)\nSostituendo questa espressione nell’equazione del moto lungo la tangente:\nmg \\sin \\theta - \\mu_d mg \\cos \\theta = ma\nDividendo per m, otteniamo l’accelerazione dell’oggetto:\na = g \\sin \\theta - \\mu_d g \\cos \\theta\na = g (\\sin \\theta - \\mu_d \\cos \\theta)\nNel caso di un piano liscio (\\mu_d = 0), l’accelerazione sarebbe a = g \\sin \\theta. La presenza dell’attrito dinamico riduce l’accelerazione dell’oggetto. Maggiore è il coefficiente di attrito dinamico (\\mu_d), minore è l’accelerazione.\nForza d’Attrito Viscoso\nLa forza d’attrito viscoso è la forza che si manifesta quando un corpo si muove all’interno di un fluido. È una forza puramente dinamica, in grado solo di rallentare il movimento, non di impedirlo permanentemente.\nL’intensità della forza d’attrito viscoso (RT) è tanto maggiore quanto è maggiore la velocità (\\vec{v}) dell’oggetto rispetto al fluido. La forza è proporzionale al vettore velocità e opposta ad esso:\nRT = -\\beta \\vec{v}\ndove \\beta è il coefficiente di attrito viscoso.\nIl coefficiente di attrito viscoso (\\beta) dipende dalla viscosità del fluido: più il fluido è viscoso, maggiore è \\beta e quindi più intensa è la forza d’attrito viscoso. Dipende anche dalla forma dell’oggetto, ma questa dipendenza è più complessa e generalmente non trattata negli esercizi di dinamica del punto materiale.\nUn oggetto che cade in un fluido viscoso inizialmente è fermo, quindi la forza d’attrito viscoso è nulla. Appena inizia a muoversi, acquista velocità e quindi si manifesta la forza d’attrito viscoso, che aumenta con la velocità. Questa forza si oppone alla forza peso, diminuendo l’accelerazione dell’oggetto. L’accelerazione diminuisce finché la forza d’attrito viscoso non bilancia la forza peso, raggiungendo una velocità limite.\nLo studio dettagliato del moto con attrito viscoso richiede la risoluzione di equazioni differenziali, che vanno oltre gli strumenti matematici di base. Pertanto, non è una forza facilmente analizzabile con i metodi elementari.\nMoto Circolare e Forza Centripeta: Esempio della Curva Piana\nConsideriamo una macchina che percorre una curva piana, ovvero una strada orizzontale. Vista dall’alto, la macchina segue una traiettoria curva con un certo raggio di curvatura (r).\nLe forze che agiscono sulla macchina sono la forza peso (mg) diretta verso il basso e la reazione normale (R_N) del piano stradale diretta verso l’alto. Tuttavia, queste due forze verticali si bilanciano e non possono causare l’accelerazione necessaria per curvare.\nPerché la macchina possa seguire una traiettoria curva, deve possedere una accelerazione normale (o centripeta) diretta verso il centro della curva, che provoca la variazione della direzione del vettore velocità. Secondo il secondo principio della dinamica, questa accelerazione deve essere causata da una forza netta diretta verso il centro della curva, chiamata forza centripeta.\nNel caso di una curva piana, la forza che permette alla macchina di curvare è la forza d’attrito radente statico (RT) che si sviluppa tra le gomme dell’auto e l’asfalto. Questa forza agisce sulle gomme e punta verso l’interno del raggio di curvatura.\nAnche se la macchina è in movimento, l’attrito coinvolto è statico perché si oppone al tentativo di movimento laterale (slittamento) delle ruote rispetto all’asfalto nella direzione radiale. Le ruote girano in avanti, ma non strisciano lateralmente. Se l’attrito statico non fosse sufficiente (ad esempio, su una strada ghiacciata), la macchina tenderebbe a proseguire in linea retta a causa dell’inerzia, anziché curvare.\nIn inverno, si utilizzano pneumatici invernali che garantiscono un maggiore coefficiente di attrito statico per migliorare l’aderenza e la capacità di curvare su superfici a bassa aderenza.\nReferences"},"6--full-note/fisica1--Lez0boh":{"slug":"6--full-note/fisica1--Lez0boh","filePath":"6- full note/fisica1- Lez0boh.md","title":"fisica1- Lez0boh","links":[],"tags":[],"content":""},"6--full-note/fisica1--Lez11":{"slug":"6--full-note/fisica1--Lez11","filePath":"6- full note/fisica1- Lez11.md","title":"fisica1- Lez11","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-19 10:50\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nfisica1- Lez11\nMANCA LA PRIMA PARTE \nCinematica Relativa: Relazione tra Velocità e Accelerazioni in Sistemi di Riferimento in Moto Relativo\nDefinizioni Preliminari\nPrima di analizzare il moto relativo, è fondamentale ricordare alcune definizioni che legano le quantità scalari alle loro controparti vettoriali nel moto circolare.\nRelazione tra Velocità Scalare e Velocità Angolare\nLa relazione tra la velocità scalare (v) e la velocità angolare (\\omega) di un punto che si muove su una circonferenza di raggio R può essere espressa in forma vettoriale come:\n\\qquad \\mathbf{v} = \\boldsymbol{\\omega} \\times \\mathbf{R}\ndove:\n\n\\mathbf{v} è il vettore velocità vettoriale, tangente alla traiettoria.\n\\boldsymbol{\\omega} è il vettore velocità angolare, ortogonale al piano della circonferenza e diretto secondo la regola della mano destra. Se la rotazione è antioraria, \\boldsymbol{\\omega} punta verso l’alto; se è oraria, punta verso il basso.\n\\mathbf{R} è il vettore raggio, che punta dal centro della circonferenza verso l’esterno.\n\nÈ importante notare che in un disco rotante, il valore della velocità scalare e del modulo della velocità vettoriale aumentano linearmente con la distanza dal centro.\nRelazione tra Accelerazione Tangente e Accelerazione Angolare\nAnalogamente, l’accelerazione tangente (a_t) è legata all’accelerazione angolare (\\alpha) e al raggio R dalla relazione:\n\\qquad a_t = \\alpha R\nIn forma vettoriale, questa relazione diventa:\n\\qquad \\mathbf{a}_t = \\boldsymbol{\\alpha} \\times \\mathbf{R}\nAnche il vettore accelerazione angolare \\boldsymbol{\\alpha} è ortogonale al piano del moto e la sua direzione dipende da come sta variando la velocità angolare. In un disco rotante con accelerazione angolare, il modulo dell’accelerazione tangente aumenta linearmente con la distanza dal centro.\nAccelerazione Normale (Centripeta)\nL’accelerazione normale (a_n), diretta verso il centro della circonferenza, può essere espressa in termini di velocità angolare come:\n\\qquad a_n = \\omega^2 R\nIn forma vettoriale, l’accelerazione normale \\mathbf{a}_n può essere scritta come:\n\\qquad \\mathbf{a}_n = \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{R})\nQuesta espressione vettoriale è coerente con la direzione e il modulo dell’accelerazione normale. Infatti, \\boldsymbol{\\omega} \\times \\mathbf{R} è il vettore velocità \\mathbf{v}, tangente alla traiettoria e ortogonale a \\boldsymbol{\\omega}. Il prodotto vettoriale \\boldsymbol{\\omega} \\times \\mathbf{v} risulta in un vettore diretto radialmente verso il centro, con modulo |\\boldsymbol{\\omega}| |\\mathbf{v}| \\sin(90^\\circ) = \\omega (\\omega R) (1) = \\omega^2 R.\nÈ prassi comune scrivere l’accelerazione normale vettoriale senza parentesi, intendendo che il prodotto vettoriale deve essere eseguito prima sugli ultimi due termini:\n\\qquad \\mathbf{a}_n = \\boldsymbol{\\omega} \\times \\boldsymbol{\\omega} \\times \\mathbf{R}\nDerivata di un Versore e Formula di Poisson\nPer analizzare il moto relativo, è cruciale comprendere come varia nel tempo un versore (un vettore di modulo unitario). Se un versore varia nel tempo, la sua lunghezza non può cambiare (rimane unitaria), quindi deve necessariamente ruotare.\nLa derivata temporale di un versore \\mathbf{u} che sta ruotando con una velocità angolare \\boldsymbol{\\omega} è data dalla formula di Poisson:\n\\qquad \\frac{d\\mathbf{u}}{dt} = \\boldsymbol{\\omega} \\times \\mathbf{u}\nQuesta formula afferma che la derivata di un versore è un vettore ortogonale al versore di partenza, con un modulo pari alla velocità angolare di rotazione del versore.\nLegge di Composizione delle Velocità\nConsideriamo un punto P la cui posizione viene osservata da due sistemi di riferimento:\n\nUn sistema di riferimento fisso Oxyz.\nUn sistema di riferimento mobile O&#039;x&#039;y&#039;z&#039; che può traslare e ruotare rispetto al sistema fisso.\n\nSia \\mathbf{r}(t) il vettore posizione di P rispetto al sistema fisso, e \\mathbf{r}&#039;(t) il vettore posizione di P rispetto al sistema mobile. Sia \\mathbf{R}_{O&#039;}(t) il vettore posizione dell’origine O&#039; del sistema mobile rispetto all’origine O del sistema fisso.\nLa relazione tra questi vettori posizione è:\n\\qquad \\mathbf{r}(t) = \\mathbf{R}_{O&#039;}(t) + \\mathbf{r}&#039;(t)\nEsprimendo \\mathbf{r}&#039;(t) nelle componenti del sistema mobile con i rispettivi versori \\mathbf{u}_{x&#039;}, \\mathbf{u}_{y&#039;}, \\mathbf{u}_{z&#039;}:\n\\qquad \\mathbf{r}&#039;(t) = x&#039;(t) \\mathbf{u}_{x&#039;} + y&#039;(t) \\mathbf{u}_{y&#039;} + z&#039;(t) \\mathbf{u}_{z&#039;}\ne \\mathbf{R}_{O&#039;}(t) nelle componenti del sistema fisso con i versori \\mathbf{u}_x, \\mathbf{u}_y, \\mathbf{u}_z:\n\\qquad \\mathbf{R}_{O&#039;}(t) = X_{O&#039;}(t) \\mathbf{u}_x + Y_{O&#039;}(t) \\mathbf{u}_y + Z_{O&#039;}(t) \\mathbf{u}_z\nDerivando la relazione \\mathbf{r}(t) = \\mathbf{R}_{O&#039;}(t) + \\mathbf{r}&#039;(t) rispetto al tempo, otteniamo la legge di composizione delle velocità:\n\\qquad \\frac{d\\mathbf{r}}{dt} = \\frac{d\\mathbf{R}_{O&#039;}}{dt} + \\frac{d\\mathbf{r}&#039;}{dt}\nAnalizziamo i singoli termini:\nVelocità Assoluta (\\mathbf{v})\n\\frac{d\\mathbf{r}}{dt} = \\mathbf{v} è la velocità assoluta del punto P, cioè la velocità misurata dall’osservatore nel sistema di riferimento fisso Oxyz. In termini delle componenti nel sistema fisso:\n\\qquad \\mathbf{v} = \\frac{dx}{dt} \\mathbf{u}_x + \\frac{dy}{dt} \\mathbf{u}_y + \\frac{dz}{dt} \\mathbf{u}_z\nVelocità di Trascinamento dell’Origine (\\mathbf{v}_{O&#039;})\n\\frac{d\\mathbf{R}_{O&#039;}}{dt} = \\mathbf{v}_{O&#039;} è la velocità dell’origine del sistema mobile O&#039; rispetto al sistema fisso Oxyz. Questa è la velocità di traslazione del sistema mobile. In termini delle componenti nel sistema fisso:\n\\qquad \\mathbf{v}_{O&#039;} = \\frac{dX_{O&#039;}}{dt} \\mathbf{u}_x + \\frac{dY_{O&#039;}}{dt} \\mathbf{u}_y + \\frac{dZ_{O&#039;}}{dt} \\mathbf{u}_z\nDerivata di \\mathbf{r}&#039;(t)\nLa derivata di \\mathbf{r}&#039;(t) = x&#039;(t) \\mathbf{u}_{x&#039;} + y&#039;(t) \\mathbf{u}_{y&#039;} + z&#039;(t) \\mathbf{u}_{z&#039;} richiede l’applicazione della regola della derivata del prodotto, poiché sia le coordinate (x&#039;, y&#039;, z&#039;) che i versori (\\mathbf{u}_{x&#039;}, \\mathbf{u}_{y&#039;}, \\mathbf{u}_{z&#039;}) possono variare nel tempo a causa del moto di P rispetto al sistema mobile e della rotazione del sistema mobile stesso.\n\\qquad \\frac{d\\mathbf{r}&#039;}{dt} = \\left( \\frac{dx&#039;}{dt} \\mathbf{u}_{x&#039;} + \\frac{dy&#039;}{dt} \\mathbf{u}_{y&#039;} + \\frac{dz&#039;}{dt} \\mathbf{u}_{z&#039;} \\right) + \\left( x&#039;(t) \\frac{d\\mathbf{u}_{x&#039;}}{dt} + y&#039;(t) \\frac{d\\mathbf{u}_{y&#039;}}{dt} + z&#039;(t) \\frac{d\\mathbf{u}_{z&#039;}}{dt} \\right)\nIl primo termine rappresenta la velocità relativa \\mathbf{v}&#039; del punto P rispetto all’osservatore nel sistema mobile O&#039;x&#039;y&#039;z&#039;:\n\\qquad \\mathbf{v}&#039; = \\frac{dx&#039;}{dt} \\mathbf{u}_{x&#039;} + \\frac{dy&#039;}{dt} \\mathbf{u}_{y&#039;} + \\frac{dz&#039;}{dt} \\mathbf{u}_{z&#039;}\nPer il secondo termine, applichiamo la formula di Poisson:\n\\qquad \\frac{d\\mathbf{u}_{x&#039;}}{dt} = \\boldsymbol{\\omega} \\times \\mathbf{u}_{x&#039;} \\qquad \\frac{d\\mathbf{u}_{y&#039;}}{dt} = \\boldsymbol{\\omega} \\times \\mathbf{u}_{y&#039;} \\qquad \\frac{d\\mathbf{u}_{z&#039;}}{dt} = \\boldsymbol{\\omega} \\times \\mathbf{u}_{z&#039;}\ndove \\boldsymbol{\\omega} è la velocità angolare del sistema mobile rispetto al sistema fisso. Sostituendo queste espressioni, otteniamo:\n\\qquad x&#039;(t) (\\boldsymbol{\\omega} \\times \\mathbf{u}_{x&#039;}) + y&#039;(t) (\\boldsymbol{\\omega} \\times \\mathbf{u}_{y&#039;}) + z&#039;(t) (\\boldsymbol{\\omega} \\times \\mathbf{u}_{z&#039;})\nUtilizzando la proprietà distributiva del prodotto vettoriale:\n\\qquad \\boldsymbol{\\omega} \\times (x&#039;(t) \\mathbf{u}_{x&#039;} + y&#039;(t) \\mathbf{u}_{y&#039;} + z&#039;(t) \\mathbf{u}_{z&#039;}) = \\boldsymbol{\\omega} \\times \\mathbf{r}&#039;(t)\nQuesto termine rappresenta la velocità di trascinamento dovuta alla rotazione del sistema mobile nel punto P.\nLegge di Composizione delle Velocità Completa\nCombinando tutti i termini, la legge di composizione delle velocità diventa:\n\\qquad \\mathbf{v} = \\mathbf{v}_{O&#039;} + \\mathbf{v}&#039; + \\boldsymbol{\\omega} \\times \\mathbf{r}&#039;\nDove:\n\n\\mathbf{v} è la velocità assoluta.\n\\mathbf{v}_{O&#039;} è la velocità di traslazione del sistema mobile.\n\\mathbf{v}&#039; è la velocità relativa.\n\\boldsymbol{\\omega} \\times \\mathbf{r}&#039; è la velocità di trascinamento dovuta alla rotazione.\n\nLa velocità di trascinamento \\mathbf{v}_{trascinamento} è quindi la somma della velocità di traslazione e della velocità dovuta alla rotazione:\n\\qquad \\mathbf{v}_{trascinamento} = \\mathbf{v}_{O&#039;} + \\boldsymbol{\\omega} \\times \\mathbf{r}&#039;\nUn punto solidale al sistema mobile, pur avendo velocità relativa nulla (\\mathbf{v}&#039; = 0), avrà una velocità assoluta pari alla velocità di trascinamento.\nLegge di Composizione delle Accelerazioni\nPer ottenere la legge di composizione delle accelerazioni, deriviamo la legge di composizione delle velocità rispetto al tempo:\n\\qquad \\frac{d\\mathbf{v}}{dt} = \\frac{d\\mathbf{v}_{O&#039;}}{dt} + \\frac{d\\mathbf{v}&#039;}{dt} + \\frac{d}{dt}(\\boldsymbol{\\omega} \\times \\mathbf{r}&#039;)\nAnalizziamo i singoli termini:\nAccelerazione Assoluta (\\mathbf{a})\n\\frac{d\\mathbf{v}}{dt} = \\mathbf{a} è l’accelerazione assoluta del punto P, misurata nel sistema fisso.\nAccelerazione di Trascinamento dell’Origine (\\mathbf{a}_{O&#039;})\n\\frac{d\\mathbf{v}_{O&#039;}}{dt} = \\mathbf{a}_{O&#039;} è l’accelerazione dell’origine del sistema mobile, cioè l’accelerazione di traslazione del sistema mobile. In termini delle componenti nel sistema fisso:\n\\qquad \\mathbf{a}_{O&#039;} = \\frac{d^2X_{O&#039;}}{dt^2} \\mathbf{u}_x + \\frac{d^2Y_{O&#039;}}{dt^2} \\mathbf{u}_y + \\frac{d^2Z_{O&#039;}}{dt^2} \\mathbf{u}_z\nDerivata di \\mathbf{v}&#039;\n\\frac{d\\mathbf{v}&#039;}{dt} = \\mathbf{a}&#039; = \\mathbf{a}_{relativa} è l’accelerazione relativa del punto P rispetto al sistema mobile O&#039;x&#039;y&#039;z&#039;. In termini delle componenti nel sistema mobile:\n\\qquad \\mathbf{a}&#039; = \\frac{d^2x&#039;}{dt^2} \\mathbf{u}_{x&#039;} + \\frac{d^2y&#039;}{dt^2} \\mathbf{u}_{y&#039;} + \\frac{d^2z&#039;}{dt^2} \\mathbf{u}_{z&#039;}\nDerivata di \\boldsymbol{\\omega} \\times \\mathbf{r}&#039;\nApplicando la regola della derivata del prodotto vettoriale:\n\\qquad \\frac{d}{dt}(\\boldsymbol{\\omega} \\times \\mathbf{r}&#039;) = \\frac{d\\boldsymbol{\\omega}}{dt} \\times \\mathbf{r}&#039; + \\boldsymbol{\\omega} \\times \\frac{d\\mathbf{r}&#039;}{dt}\n\n\\frac{d\\boldsymbol{\\omega}}{dt} = \\boldsymbol{\\alpha} è l’accelerazione angolare del sistema mobile. Quindi il primo termine è \\boldsymbol{\\alpha} \\times \\mathbf{r}&#039;.\nAbbiamo già visto che \\frac{d\\mathbf{r}&#039;}{dt} = \\mathbf{v}&#039; + \\boldsymbol{\\omega} \\times \\mathbf{r}&#039;. Quindi il secondo termine diventa \\boldsymbol{\\omega} \\times (\\mathbf{v}&#039; + \\boldsymbol{\\omega} \\times \\mathbf{r}&#039;) = \\boldsymbol{\\omega} \\times \\mathbf{v}&#039; + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r}&#039;).\n\nLegge di Composizione delle Accelerazioni Completa\nCombinando tutti i termini, la legge di composizione delle accelerazioni diventa:\n\\qquad \\mathbf{a} = \\mathbf{a}_{O&#039;} + \\mathbf{a}&#039; + \\boldsymbol{\\alpha} \\times \\mathbf{r}&#039; + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r}&#039;) + 2 \\boldsymbol{\\omega} \\times \\mathbf{v}&#039;\nDove:\n\n\\mathbf{a} è l’accelerazione assoluta.\n\\mathbf{a}_{O&#039;} è l’accelerazione di traslazione del sistema mobile.\n\\mathbf{a}&#039; è l’accelerazione relativa.\n\\boldsymbol{\\alpha} \\times \\mathbf{r}&#039; è la componente dell’accelerazione di trascinamento dovuta all’accelerazione angolare.\n\\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r}&#039;) = -\\omega^2 \\mathbf{r}&#039;_{\\perp} (dove \\mathbf{r}&#039;_{\\perp} è la componente di \\mathbf{r}&#039; perpendicolare all’asse di rotazione) è l’accelerazione centripeta di trascinamento.\n2 \\boldsymbol{\\omega} \\times \\mathbf{v}&#039; è l’accelerazione di Coriolis (o accelerazione complementare).\n\nLa accelerazione di trascinamento \\mathbf{a}_{trascinamento} è la somma di tutti i termini che il punto P avrebbe se fosse solidale al sistema mobile (\\mathbf{v}&#039; = 0, \\mathbf{a}&#039; = 0):\n\\qquad \\mathbf{a}_{trascinamento} = \\mathbf{a}_{O&#039;} + \\boldsymbol{\\alpha} \\times \\mathbf{r}&#039; + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{r}&#039;)\nL’accelerazione assoluta è quindi la somma dell’accelerazione relativa, dell’accelerazione di trascinamento e dell’accelerazione di Coriolis:\n\\qquad \\mathbf{a} = \\mathbf{a}&#039; + \\mathbf{a}_{trascinamento} + \\mathbf{a}_{Coriolis}\nLa comprensione di queste leggi di composizione è fondamentale per l’analisi del moto di corpi osservati da sistemi di riferimento non inerziali.\nReferences"},"6--full-note/intervista-AI":{"slug":"6--full-note/intervista-AI","filePath":"6- full note/intervista AI.md","title":"intervista AI","links":[],"tags":[],"content":""},"6--full-note/los-sonideros---grafica":{"slug":"6--full-note/los-sonideros---grafica","filePath":"6- full note/los sonideros - grafica.md","title":"los sonideros - grafica","links":["3--tag/los-sonideros"],"tags":[],"content":"2025-04-20 17:05\n_Status:\n_Tags:los sonideros\nlos sonideros - grafica\n\n\n\ni colori molto belli, ma vorrei più movimento, idea per possibili grafiche con una foto scontornata\n\n\n\n\nbello il logo della FANIA records (soprattutto per la prospettiva)\n\n\n\ngrafica in 16:9???\n\n\n\nbello il font e la prospettiva e i colori. semplice ma fuznioale (la texture di muro ottimo )\n\nanche se ho un dubbio con un testo più arrotondato. (grana e effetto cinepresa al massimo come con tarantino )\noppure invecedi un muro dietro si può mettere una foto di qualcosa\n\ngrafica di un poster dei sonideros. alla fine è stra easy con testo in prospettiva e un sottotitolo al massimo .\nmagari si può fare un poster del tipo.\n\nil dettaglio bimbo che dorme sulla sedia è bello bello (non riuscirò mai a inserirlo nella grafica )\n\nfiltro glamour a gogo\n\nprimi risultati\n\n\nReferences"},"6--full-note/los-sonideros---suoni":{"slug":"6--full-note/los-sonideros---suoni","filePath":"6- full note/los sonideros - suoni.md","title":"los sonideros - suoni","links":["3--tag/los-sonideros"],"tags":[],"content":"2025-04-20 19:24\n_Status:\n_Tags: los sonideros\nlos sonideros - suoni\n\nsicuro tanti liner “estas escuchando Los sonideros. Toda las musicas…”\n\nReferences"},"6--full-note/mateNum--Lez02":{"slug":"6--full-note/mateNum--Lez02","filePath":"6- full note/mateNum- Lez02.md","title":"mateNum- Lez02","links":["tags/flashcard_finite","tags/riscritto_finito","tags/revisione_finita","3--tag/sbobine","3--tag/matematica-numerica"],"tags":["flashcard_finite","riscritto_finito","revisione_finita"],"content":"2025-02-19 15:25\n_Status: flashcard_finite   riscritto_finito  revisione_finita\n_Tags:sbobine matematica numerica\nlez02- mateNum\nIntroduzione al Metodo di Eliminazione Gaussiana (MEG)\nL’obiettivo principale del Metodo di Eliminazione Gaussiana (MEG) è trasformare una matrice A in una matrice triangolare superiore (U) tramite operazioni elementari sulle righe. Questo processo è fondamentale sia per risolvere sistemi lineari del tipo Ax = b sia per ottenere la fattorizzazione LU della matrice A.\n\nMetodo Analitico: fornisce la soluzione esatta.\nMetodo Numerico: fornisce una soluzione approssimata.\n\nIn un contesto di aritmetica esatta, la fattorizzazione LU conduce alla soluzione precisa. Tuttavia, a causa degli errori di arrotondamento intrinseci ai calcolatori (che utilizzano una rappresentazione binaria dei numeri reali), la soluzione ottenuta tramite calcolatore potrebbe discostarsi leggermente da quella esatta. La precisione della soluzione è strettamente legata alla condizione della matrice: matrici ben condizionate tendono a produrre soluzioni più accurate.\nOperazioni Ammesse nel MEG\nPer preservare la soluzione del sistema lineare Ax = b, le uniche operazioni consentite sono:\n\nScambio di righe\nCombinazioni lineari delle righe\n\nPasso Generico del MEG per la Fattorizzazione LU\nIl MEG trasforma la matrice A in una matrice triangolare superiore U attraverso una sequenza di passi. Ad ogni passo, si introducono dei moltiplicatori, elementi chiave per azzerare gli elementi situati sotto la diagonale principale.\nNotazione\n\nA^{(k)}: Rappresenta la matrice A al passo k, dove k indica il numero di aggiornamenti effettuati.\na_{ij}^{(k)}: Indica l’elemento situato nella posizione (i, j) della matrice al passo k.\nm_{ik}: Denota il moltiplicatore impiegato per azzerare l’elemento nella posizione (i, k).\nPivot: È l’elemento diagonale a_{kk}, utilizzato come riferimento per il calcolo dei moltiplicatori. È anche il protagonista del pivoting.\n\nPasso 1: Azzeramento degli elementi sotto il primo pivot a_{11}\n\n\nsia A = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{bmatrix}\nDefinizione dei moltiplicatori:\n\n\nm_{21} = \\frac{a_{21}^{(1)}}{a_{11}^{(1)}}\n\n\nm_{31} = \\frac{a_{31}^{(1)}}{a_{11}^{(1)}}\n\n\nAggiornamento delle righe:\nLa riga i-esima della matrice aggiornata A^{(2)} si ottiene come combinazione lineare della riga i-esima di A^{(1)} e della prima riga di A^{(1)}:\n\nR_2^{(2)} = R_2^{(1)} - m_{21} \\cdot R_1^{(1)}\nR_3^{(2)} = R_3^{(1)} - m_{31} \\cdot R_1^{(1)}\n\nVerifica dell’azzeramento:\nL’elemento (a_{21}^{(2)}) diventa zero:\n\na_{21}^{(2)} = a_{21}^{(1)} - m_{21} \\cdot a_{11}^{(1)} = a_{21}^{(1)} - \\frac{a_{21}^{(1)}}{a_{11}^{(1)}} \\cdot a_{11}^{(1)} = 0\n\nAggiornamento degli altri elementi:\nGli altri elementi della riga 2 vengono aggiornati di conseguenza:\n\na_{22}^{(2)} = a_{22}^{(1)} - m_{21} \\cdot a_{12}^{(1)}\na_{23}^{(2)} = a_{23}^{(1)} - m_{21} \\cdot a_{13}^{(1)}\n\nottenendo cosi la matrice A^{(2)} = \\begin{bmatrix} a_{11}^{(1)} &amp; a_{12}^{(1)} &amp; a_{13}^{(1)} \\\\ \\cdot &amp; a_{22}^{(2)} &amp; a_{23}^{(2)} \\\\ \\cdot &amp; a_{32}^{(2)} &amp; a_{33}^{(2)} \\end{bmatrix}\nPasso 2: Azzeramento dell’elemento a_{32}\nIn questo passo, si sfrutta il secondo pivot a_{22}^{(2)} per azzerare l’elemento a_{32}^{(2)}.\nDefinizione del moltiplicatore:\n\nm_{32} = \\frac{a_{32}^{(2)}}{a_{22}^{(2)}}\n\nAggiornamento della riga 3:\nLa riga 3 viene aggiornata impiegando la riga 2 come riferimento:\n\nR_3^{(3)} = R_3^{(2)} - m_{32} \\cdot R_2^{(2)}\n\nVerifica dell’azzeramento:\n\na_{32}^{(3)} = a_{32}^{(2)} - m_{32} \\cdot a_{22}^{(2)} = a_{32}^{(2)} - \\frac{a_{32}^{(2)}}{a_{22}^{(2)}} \\cdot a_{22}^{(2)} = 0\n\nAggiornamento degli altri elementi:\n\na_{33}^{(3)} = a_{33}^{(2)} - m_{32} \\cdot a_{23}^{(2)}\n\nottenendo la matrice A^{(3)} = \\begin{bmatrix} a_{11}^{(1)} &amp; a_{12}^{(1)} &amp; a_{13}^{(1)} \\\\ 0 &amp; a_{22}^{(2)} &amp; a_{23}^{(2)} \\\\ 0 &amp; 0 &amp; a_{33}^{(3)} \\end{bmatrix}\nCostruzione delle Matrici L e U\n\n\nMatrice U: Rappresenta il risultato diretto del MEG, ovvero la matrice triangolare superiore ottenuta alla fine dei vari passi.\n\n\nMatrice L: È una matrice triangolare inferiore con elementi diagonali pari a 1. Gli elementi al di sotto della diagonale principale corrispondono ai moltiplicatori m_{ik} impiegati durante il processo di eliminazione.\n\nL = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ m_{21} &amp; 1 &amp; 0 \\\\ m_{31} &amp; m_{32} &amp; 1 \\end{bmatrix}\n\n\n\nEsempio Numerico\nConsideriamo la matrice:\n\nA = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 2 &amp; 0 &amp; -1 \\\\ -1 &amp; 1 &amp; 5 \\end{bmatrix}\n\nPasso 1\n\nm_{21} = \\frac{2}{1} = 2\nm_{31} = \\frac{-1}{1} = -1\n\nApplicando le operazioni di riga:\n\\begin{align*} a_{21}^{(2)} &amp;= 2 - 2 \\cdot 1 = 0 \\\\ a_{22}^{(2)} &amp;= 0 - 2 \\cdot 2 = -4 \\\\ a_{23}^{(2)} &amp;= -1 - 2 \\cdot 1 = -3 \\\\ a_{31}^{(2)} &amp;= 1 - (+1) \\cdot 1 = 0 \\\\ a_{32}^{(2)} &amp;= 1 - (-1) \\cdot 2 = 3 \\\\ a_{33}^{(2)} &amp;= 5 - (-1) \\cdot 1 = 6 \\end{align*}\n\nA^{(2)} = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; -4 &amp; -3 \\\\ 0 &amp; 3 &amp; 6 \\end{bmatrix}\n\nPasso 2\n\nm_{32} = \\frac{3}{-4} = -\\frac{3}{4}\n\nApplicando l’operazione di riga:\n\n\n\n\n\na_{32}^{(3)} &amp;= 3 - \\left( -\\frac{3}{4} \\right) \\cdot (-4) = 0 \\\na_{33}^{(3)} &amp;= 6 - \\left( -\\frac{3}{4} \\right) \\cdot (-3) = \\frac{15}{4}\n\\end{align*}$$\n\nA^{(3)} = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; -4 &amp; -3 \\\\ 0 &amp; 0 &amp; \\frac{15}{4} \\end{bmatrix}\n\nFattorizzazione LU\n\nL = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 2 &amp; 1 &amp; 0 \\\\ -1 &amp; -\\frac{3}{4} &amp; 1 \\end{bmatrix}\nU = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; -4 &amp; -3 \\\\ 0 &amp; 0 &amp; \\frac{15}{4} \\end{bmatrix}\n\nGeneralizzazione del Passo K\n\n A= A^{(1)} = \\begin{bmatrix} a_{11}^{(1)} &amp; \\cdots &amp; a_{1n}^{(1)} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1}^{(1)} &amp; \\cdots &amp; a_{nn}^{(1)} \\end{bmatrix}\ndopo (n-1) passi per portarlo in forma triangolare A^{(2)} = \\begin{bmatrix} a_{11}^{(1)} &amp; \\cdots &amp; \\cdots &amp; \\cdots &amp; a_{1n}^{(1)} \\\\ 0 &amp; a_{22}^{(2)} &amp; \\cdots &amp; \\cdots &amp; a_{2n}^{(2)} \\\\ 0 &amp; 0  &amp; \\cdots &amp; a_{kk}^{(k)} &amp; a_{kn}^{(k)} \\\\ 0 &amp; 0 &amp; \\ddots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{nk}^{(k)} &amp; a_{nn}^{(k)} \\end{bmatrix}\n\nAl passo k, le prime k-1 colonne sono state già azzerate sotto la diagonale. Si lavora sulla sottomatrice di dimensione (n-k+1) x (n-k+1).\n\n\ndopo n passi A^{(n)} = U = \\begin{bmatrix} a_{11}^{(1)} &amp; \\cdots &amp; \\cdots &amp; a_{1n}^{(1)} \\\\ 0 &amp; a_{22}^{(2)} &amp; \\cdots &amp; a_{2n}^{(2)} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{nn}^{(n)} \\end{bmatrix}\n\nImplementazione Algoritmica\nL’implementazione dell’algoritmo per la fattorizzazione LU richiede l’utilizzo di tre cicli for:\nfor k = 1 to n-1 do\n    for i = k+1 to n do\n        m_ik = A(i,k) / A(k,k)  // Calcolo moltiplicatore\n        for j = k to n do\n            A(i,j) = A(i,j) - m_ik * A(k,j)  // Aggiornamento elementi\n        end\n    end\nend\n\n\nk: Rappresenta l’indice delle colonne.\ni: Rappresenta l’indice delle righe.\nj: Indice utilizzato per scorrere la sottomatrice da modificare.\n\n\n\n\n\nCosto Computazionale\nIl costo computazionale del MEG si aggira intorno a \\frac{2}{3}n^3 + O(n^2) operazioni.\nComandi di MATLAB\nMATLAB offre diversi comandi utili per la fattorizzazione LU e la risoluzione di sistemi lineari.\n\nlu(A): Calcola la fattorizzazione LU della matrice A.\nA\\b: Risolve il sistema lineare Ax = b utilizzando il solver diretto più appropriato.\ntril(A): Estrae la parte triangolare inferiore di A.\ntriu(A): Estrae la parte triangolare superiore di A.\n\nStrategie per la Risoluzione di Sistemi Lineari\n\n\n\nEsistono diverse strategie per risolvere sistemi lineari, ognuna con specifici costi computazionali.\n\n\nFattorizzazione LU e Sostituzioni Successive:\n\nCalcolare la fattorizzazione LU di A.\nRisolvere Ly = b.\nRisolvere Ux = y.\nCosto: \\frac{2}{3}n^3 + 2n^2\n\n\n\nMetodo di Eliminazione Gaussiana con Termine Noto Esteso:\n\nAffiancare la matrice A con il vettore b.\nEseguire le operazioni di riga per trasformare A in una matrice triangolare superiore, aggiornando contemporaneamente il vettore b.\nRisolvere il sistema triangolare superiore risultante con sostituzione all’indietro.\nCosto: leggermente superiore a \\frac{2}{3}n^3 + n^2\n\n\n\nCalcolo dell’Inversa di A:\n\nCalcolare l’inversa di A.\nCalcolare x = A^{(-1)} \\cdot b.\nCosto: \\frac{8}{3}n^3\nSconsigliato per via del costo computazionale elevato.\n\n\n\n\nLa scelta della strategia dipende dal contesto.\nSe si deve risolvere più volte lo stesso sistema con matrici dei coefficienti uguali ma termini noti diversi, conviene calcolare la fattorizzazione LU una sola volta e poi risolvere i sistemi triangolari corrispondenti.\n\n\n\n\n\nAx &amp;= \\tilde{b_1} \\\nAx &amp;= \\tilde{b_2} \\\n&amp; \\vdots \\\nAx &amp;= \\tilde{b_q}\n\\end{align*}$$\nPivoting\nIl pivoting è una tecnica impiegata per gestire situazioni in cui un pivot è pari a zero o presenta un valore molto piccolo, eventualità che può condurre a instabilità numerica. Il pivoting consiste nello scambio di righe (o colonne) al fine di collocare un elemento con un valore assoluto maggiore in posizione di pivot.\nCondizione Necessaria e Sufficiente per l’Esistenza e l’Unicità della Fattorizzazione LU\nSia A una matrice n x n. Esiste un’unica fattorizzazione LU di A se e solo se le sottomatrici principali di A di ordine i, con i che va da 1 a n-1, sono non singolari.\n\nNOTA BENE: non ho richiesto la non-singolarità di A\nSottomatrice principale di ordine i: è la sottomatrice ottenuta intersecando le prime i righe e le prime i colonne di A.\n\nEsempi Dimostrativi\nGli esempi forniti illustrano come la violazione della condizione necessaria e sufficiente possa portare alla perdita dell’esistenza o dell’unicità della fattorizzazione LU.\n\nEsempio 1: A = \\begin{bmatrix} 1 &amp; 2 \\\\ 1 &amp; 2 \\end{bmatrix}\n\nSingolare, ma soddisfa la condizione necessaria e sufficiente.\nEsiste un’unica fattorizzazione LU.\n\n\n\nEsempio 2: A = \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 2 \\end{bmatrix}\n\nNon soddisfa la condizione necessaria e sufficiente.\nNon esiste la fattorizzazione LU.\n\n\n\nEsempio 3: A = \\begin{bmatrix} 0 &amp; 1 \\\\ 0 &amp; 2 \\end{bmatrix}\n\nNon soddisfa la condizione necessaria e sufficiente.\nEsistono infinite fattorizzazioni LU.\n\n\n\n\nReferences"},"6--full-note/mateNum--Lez05":{"slug":"6--full-note/mateNum--Lez05","filePath":"6- full note/mateNum- Lez05.md","title":"mateNum- Lez05","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","2--source-materials/Appunti-Mate-Num-lez05.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-02-26 15:31\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:   sbobine   matematica numerica\nmateNum- Lez05\nPerturbazione dei sistemi lineari e condizionamento\n\n\nProblema: Risolvere accuratamente un sistema lineare Ax = b quando si usa la fattorizzazione LU. Anche se la fattorizzazione LU è accurata, l’output di MATLAB per x può differire significativamente dalla soluzione x.\n\n\nMotivo: MATLAB risolve un sistema perturbato: (A + \\delta A)x = b + \\delta b dove \\delta A è una perturbazione sulla matrice dei coefficienti e \\delta b è una perturbazione sul termine noto. Queste perturbazioni inducono una perturbazione \\delta x sulla soluzione.\n\n\nAnalisi semplificata: Inizialmente, si considera solo la perturbazione sul termine noto, quindi \\delta A = 0.\n\n\nRelazione tra perturbazione sulla soluzione e perturbazione sul termine noto\nSi cerca una relazione tra la perturbazione sulla soluzione (\\delta x) e la perturbazione sul termine noto (\\delta b).\n\n\nNumero di condizionamento: Definito come il prodotto della norma di A per la norma dell’inversa di A, cioè cond(A) = ||A|| \\cdot ||A^{-1}||. Esistono diverse definizioni di norma di matrice e, di conseguenza, diverse definizioni di condizionamento.\n\n\nImportanza del condizionamento:\n\nSe il numero di condizionamento è piccolo, una piccola perturbazione sui dati (\\delta b) porta a una piccola perturbazione sulla soluzione (\\delta x). In questo caso, il sistema è ben condizionato.\nViceversa, un numero di condizionamento grande amplifica anche piccole perturbazioni sui dati, portando a una soluzione molto diversa. Un esempio è la matrice di Hilbert.\n\n\n\n==Caso generale: perturbazioni su A e b\nSi rimuove l’ipotesi semplificativa \\delta A = 0 per considerare il caso reale con perturbazioni sia su A che su b.\n\n\nCondizione: Si assume che || \\delta A || \\cdot || A^{-1} || &lt; 1.\n\n\nRisultato generale: La perturbazione sulla soluzione è controllata dalla seguente relazione: \\frac{||\\delta x||}{||x||} \\leq \\frac{cond(A)}{1 - cond(A) \\frac{||\\delta A||}{||A||}} \\left( \\frac{||\\delta A||}{||A||} + \\frac{||\\delta b||}{||b||} \\right) Questo risultato generalizza il caso semplificato. Se \\delta A = 0, si ritrova la relazione precedente.\n\n\nVerifica della positività del denominatore: La condizione || \\delta A || \\cdot || A^{-1} || &lt; 1 assicura che il denominatore sia strettamente positivo. Dividendo entrambi i membri per ||A|| \\cdot ||A^{-1}||, si ottiene:\n\n\n\n\n\n\\frac{||\\delta A||}{||A||} &lt; \\frac{1}{cond(A)} Moltiplicando per -cond(A), si ha 1 - cond(A) \\frac{||\\delta A||}{||A||} &gt; 0.\n\n\nResiduo\n\n\nDefinizione: Il residuo R è ciò che rimane quando si sostituisce la soluzione approssimata nel problema esatto. R = b - A\\tilde{x} dove \\tilde{x} è la soluzione approssimata. Idealmente, se \\tilde{x} è vicino alla soluzione esatta, R è vicino a zero.\n\n\nRelazione con la perturbazione: Si dimostra che \\delta b = -R quando \\delta A = 0. \\delta b = A(x + \\delta x) - Ax = A \\delta x e R = b - A\\tilde{x} = Ax - A\\tilde{x} = -A \\delta x.\n\n\n\n\n\nStima equivalente: La stima della perturbazione sulla soluzione può essere riscritta usando il residuo normalizzato (immagino con delta A = 0 ):\n\\frac{||\\delta x||}{||x||} \\leq cond(A) \\frac{||R||}{||b||}\n\n\nPrecondizionatore\n\nProblema: Cosa fare se il problema è mal condizionato?\nSoluzione: Utilizzare un precondizionatore P, una matrice invertibile. L’obiettivo è trovare un P tale che il condizionamento della matrice precondizionata P^{-1}A sia molto più piccolo del condizionamento di A: cond(P^{-1}A) &lt;&lt; cond(A)\nRiscrivere il sistema: Moltiplicare il sistema Ax = b per P^{-1}: P^{-1}Ax = P^{-1}b Si risolve quindi A_{new}x = b_{new}, dove A_{new} = P^{-1}A e b_{new} = P^{-1}b.\nPrecondizionatore ideale: Idealmente, P dovrebbe essere A^{-1}, in modo che P^{-1}A = I (matrice identità) e cond(I) = 1. Questo non è sempre possibile, ma fornisce una direzione.\n\nMetodi iterativi\nTerminologia\n\n\nMetodo iterativo: Una “black box” in cui entra un valore iniziale (guess iniziale) x_0 e produce un’approssimazione x_1, che viene reintrodotta nella black box per generare x_2, e così via.\n\n\nGuess iniziale: Un’ipotesi iniziale per la soluzione.\n\n\nApprossimazioni successive: Partendo dal guess iniziale, il metodo genera una collezione di approssimazioni x_k per la soluzione x: \\set{x_k}_{k=0}^{\\infty}, \\quad x_k \\in \\mathbb{R}^n, \\quad x_k \\approx x\n\n\nCriteri di arresto\nPoiché non si può iterare all’infinito, è necessario un criterio di arresto.\n\nNumero massimo di iterazioni (N_{max}): Si fissa un numero massimo di iterazioni. Questo può essere scelto arbitrariamente o in base al tempo massimo consentito per la computazione.\nControllo sull’accuratezza: Si cerca di controllare l’accuratezza della soluzione. Idealmente, si vorrebbe che: ||x - x_k|| &lt; tolleranza dove la tolleranza è un valore fissato dall’utente (es. 10^{-q}). Tuttavia, poiché x è sconosciuta, si controlla uno stimatore dell’errore.\n\nStimatori dell’errore\n\nIncremento: La differenza tra due iterazioni successive: ||x_{k+1} - x_k|| &lt; tolleranza L’idea è che, se il metodo converge, le iterazioni successive saranno sempre più vicine.\nResiduo: Si utilizza il residuo R = b - Ax_k: ||R|| = ||b - Ax_k|| &lt; tolleranza Se x_k fosse la soluzione esatta, il residuo sarebbe zero.\n\n\nAffidabilità degli stimatori: È fondamentale studiare l’affidabilità degli stimatori, perché potrebbe esserci una costante che influenza la stima dell’errore: ||x - x_k|| \\leq C \\cdot ||x_{k+1} - x_k|| Se C è molto grande, lo stimatore potrebbe non essere affidabile.\n\nConvergenza\n\n\nDefinizione: Si desidera che la successione di approssimazioni converga alla soluzione esatta: \\lim_{k \\to \\infty} x_k = x Questo limite va inteso componente per componente.\n\n\nErrore all’iterata k-esima: e_k = x - x_k. La convergenza può essere espressa come: \\lim_{k \\to \\infty} e_k = 0\n\n\nSchema iterativo generico\nSi ipotizza che la black box generi una nuova approssimazione attraverso una combinazione lineare: x_{k+1} = Bx_k + G dove B \\in \\mathbb{R}^{n \\times n} e G \\in \\mathbb{R}^n. B e G definiscono il metodo iterativo. B è legata alla matrice A, mentre G è legata sia ad A che al termine noto b.\nConsistenza\n\n\nDefinizione: Un metodo numerico è consistente con il problema se, sostituendo la soluzione esatta nello schema, l’uguaglianza è soddisfatta: x = Bx + G Questo certifica che il metodo non è “folle” e che è coerente con il problema che si vuole risolvere.\n\n\nLegame tra G, A e b: Dalla consistenza, si può dimostrare che G dipende sia da A che da b.\n\n\nAnalisi di convergenza\n\n\nLa sola consistenza non è sufficiente: Un esempio è B = I (matrice identità) e G = 0. In questo caso, x_{k+1} = x_k, quindi non c’è convergenza a meno che x_0 = x.\n\n\nCondizione sufficiente per la convergenza: Supponendo che il metodo sia consistente, si sottrae lo schema iterativo dalla relazione di consistenza: x_{k+1} - x = Bx_k + G - (Bx + G) = B(x_k - x) Quindi e_{k+1} = Be_k. Prendendo le norme: ||e_{k+1}|| = ||Be_k|| \\leq ||B|| \\cdot ||e_k|| Iterando, si ottiene:\n\n\n||e_{k+1}|| \\leq ||B||^{k+1} \\cdot ||e_0|| Affinché ||e_k|| \\to 0 per k \\to \\infty, è sufficiente che ||B|| &lt; 1.\n\n\nCondizione necessaria e sufficiente per la convergenza: Il teorema fondamentale afferma che, se lo schema è consistente, allora converge per ogni scelta di x_0 se e solo se il raggio spettrale di B è minore di 1: \\rho(B) &lt; 1 dove \\rho(B) = \\max{|\\lambda| : \\lambda \\text{ autovalore di } B}.\n\n\nLemma utile: Per dimostrare il teorema, data una C \\in \\mathbb{R}^{n x n} si usa il fatto che C^k \\to 0 se e solo se \\rho(C) &lt; 1. Inoltre, \\rho(C) \\leq ||C||.\n\n\nVelocità di convergenza: Più piccolo è il raggio spettrale, più rapida è la convergenza.\n\n\nSchema iterativo di Richardson\n\n\nPartenza: Si parte dal sistema Ax = b e si moltiplica per una costante \\alpha_k: \\alpha_k Ax = \\alpha_k b\n\n\nManipolazione algebrica: Si riscrive \\alpha_k A come P - (P - \\alpha_k A), dove P è una matrice invertibile (il precondizionatore): Px - (P - \\alpha_k A)x = \\alpha_k b\n\n\nSchema iterativo: Si decide arbitrariamente di associare il termine a sinistra con la nuova iterata e quello a destra con la vecchia iterata: Px_{k+1} = (P - \\alpha_k A)x_k + \\alpha_k b\n\n\nConsistenza per costruzione: Questo schema è consistente per costruzione, perché si è partiti dall’equazione esatta e si è semplicemente manipolata algebricamente.\n\n\nForma esplicita: Moltiplicando per P^{-1}, si ottiene la forma x_{k+1} = Bx_k + G: x_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b dove B_{\\alpha_k} = I - \\alpha_k P^{-1} A e G_{\\alpha_k} = \\alpha_k P^{-1} b.\n\n\nAlgoritmo:\n\nDato x_0 (guess iniziale).\nPer k \\geq 0, calcola: x_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\n\n\n\nMetodi di Richardson stazionari e dinamici:\n\nStazionario: \\alpha_k = \\alpha per ogni k (parametro costante).\nDinamico: \\alpha_k varia ad ogni iterazione.\n\n\n\n\nMetodi Iterativi per Sistemi di Equazioni Lineari\nIntroduzione ai Metodi Iterativi\nI metodi iterativi rappresentano un blocco fondamentale per la risoluzione di sistemi di equazioni lineari, in alternativa ai metodi diretti.\nTerminologia e Concetti Chiave\nQuando si parla di un metodo iterativo, si può immaginare una “scatola nera” (black box).\n\nGuess Iniziale: All’interno di questa scatola nera entra un valore iniziale, chiamato “guess iniziale” (o ipotesi iniziale). Il guess iniziale viene indicato con x_0. Il verbo “guess” significa “ipotizzare”.\nApprossimazione della Soluzione: In corrispondenza di x_0, la scatola nera produce una quantità x_1, che rappresenta la prima approssimazione della soluzione.\nIterazione: Questa x_1 rientra nella scatola nera, generando x_2, e così via. Quindi, partendo dal guess iniziale, si genera una sequenza di approssimazioni.\n\nNel contesto specifico della risoluzione di sistemi di equazioni lineari (Ax = b), x_0 è un’approssimazione per x, che è un vettore di R^n. Ogni approssimazione successiva (x_k) sarà anch’essa un vettore di R^n.\nIdealmente, la black box genera una collezione infinita di approssimazioni per x. Avremo quindi una collezione di x_k, con k che varia da 0 a infinito, dove ogni x_k appartiene a R^n e approssima x.\nCriterio d’Arresto\nDato che il concetto di infinito non è gestibile da un calcolatore, ogni metodo iterativo deve essere dotato di un criterio d’arresto (stop). Questo criterio indica quando fermare il processo iterativo.\nTipi di Criteri d’Arresto\n\n\nNumero Massimo di Iterazioni: Si fissa un numero massimo di iterazioni (N_{max}). Questo valore può essere scelto arbitrariamente o in base al tempo massimo consentito per l’esecuzione. Tuttavia, questo criterio da solo non garantisce una buona accuratezza.\n\n\nControllo sull’Accuratezza: Si cerca di controllare l’accuratezza, imponendo che la differenza tra la soluzione esatta (x) e l’approssimazione corrente (x_k) sia inferiore a una certa tolleranza (\\epsilon):\n||x - x_k|| &lt; \\epsilon\nLa tolleranza (\\epsilon = 10^{-q}) è definita dall’utente e deve essere coerente con i valori misurati.\n\n\nIdealmente, si utilizzano entrambi i criteri in combinazione:\n\nIl criterio sul numero massimo di iterazioni evita di iterare all’infinito se l’accuratezza desiderata non viene mai raggiunta.\nIl criterio sull’accuratezza permette di fermarsi prima se si raggiunge la tolleranza desiderata.\n\nStima dell’Errore\nDato che la soluzione esatta x non è nota, si utilizzano degli stimatori per controllare l’accuratezza. Due stimatori comuni sono:\n\nIncremento: La differenza tra due approssimazioni successive: ||x_{k+1} - x_k||.\nResiduo: Definito come r_k = b - Ax_k. Il residuo indica quanto la soluzione approssimata soddisfa l’equazione originale.\n\nIdealmente, si vorrebbe che:\n||x - x_k|| \\le S &lt; \\epsilon\nDove S è lo stimatore. Tuttavia, in pratica, esiste una costante che può influenzare l’affidabilità dello stimatore:\n||x - x_k|| \\le C \\cdot S\nSe C è molto grande, lo stimatore potrebbe non essere affidabile.\nConvergenza\nIdealmente, si desidera che la successione di approssimazioni x_k converga alla soluzione esatta x per k che tende a infinito:\n\\lim_{k \\to \\infty} x_k = x\nQuesto significa che ogni componente del vettore x_k deve tendere alla corrispondente componente del vettore x.\nIn modo equivalente, si può definire l’errore all’iterata k-esima come:\ne_k = x - x_k\nE richiedere che:\n\\lim_{k \\to \\infty} e_k = 0\nDove 0 è il vettore nullo.\nForma Generale di uno Schema Iterativo\nSi ipotizza che la black box generi una nuova approssimazione x_{k+1} a partire dalla precedente x_k attraverso una combinazione lineare:\nx_{k+1} = Bx_k + g\nDove:\n\nB è una matrice di iterazione di dimensioni n \\times n.\ng è un vettore.\n\nB e g identificano il metodo iterativo. La matrice B è legata alla matrice A del sistema originale, mentre il vettore g è legato sia ad A che al termine noto b.\nConsistenza\nUn metodo numerico si dice consistente con il problema se, rimpiazzando nel metodo la soluzione esatta, l’uguaglianza è verificata:\nx = Bx + g\nIn altre parole, il metodo è coerente con il problema che si sta cercando di risolvere.\nLegame tra g, A e b\nIl vettore g dipende sia dalla matrice A che dal termine noto b. Possiamo riscrivere l’equazione di consistenza come:\nx = Bx + g \\implies g = x - Bx = (I - B)x\nDato che x = A^{-1}b, possiamo scrivere:\ng = (I - B)A^{-1}b\nQuesto dimostra che g dipende sia da A che da b.\nCondizione Sufficiente per la Convergenza\nLa sola consistenza non è sufficiente a garantire la convergenza.\nEsempio:\nSe si sceglie B = I (matrice identità) e g = 0 (vettore nullo), il metodo è consistente, ma x_{k+1} = x_k, quindi non c’è convergenza a meno che il guess iniziale non sia già la soluzione esatta.\nSupponendo che il metodo sia consistente, sottraiamo la relazione di consistenza dallo schema iterativo:\nx_{k+1} - x = Bx_k + g - (Bx + g) = B(x_k - x)\nDefinendo l’errore come e_k = x - x_k, otteniamo:\ne_{k+1} = Be_k\nPrendendo la norma (ad esempio, la norma 2) di entrambi i membri:\n||e_{k+1}|| = ||Be_k|| \\le ||B|| \\cdot ||e_k||\nIterando, otteniamo:\n||e_{k+1}|| \\le ||B||^{k+1} \\cdot ||e_0||\nAffinché l’errore tenda a zero per k \\to \\infty, è sufficiente che:\n||B|| &lt; 1\nQuindi, se il metodo è consistente e la norma di B è strettamente minore di 1, il metodo è convergente.\nCondizione Necessaria e Sufficiente per la Convergenza\nUn teorema fondamentale stabilisce una condizione necessaria e sufficiente per la convergenza:\nTeorema: Sia lo schema x_{k+1} = Bx_k + g consistente. Allora, il metodo converge per ogni scelta del guess iniziale x_0 se e solo se il raggio spettrale di B è strettamente minore di 1.\nRaggio Spettrale\nIl raggio spettrale di una matrice B, indicato con \\rho(B), è il massimo dei moduli degli autovalori di B:\n\\rho(B) = \\max_i |\\lambda_i|\nDove \\lambda_i sono gli autovalori di B.\nLemma\nPer dimostrare il teorema, abbiamo bisogno di due risultati preliminari:\n\nSia C una matrice a entrate reali. Allora, C^k \\to 0 (componente per componente) se e solo se \\rho(C) &lt; 1.\nEsiste una relazione tra il raggio spettrale e la norma 2 di una matrice: \\rho(B) \\le ||B||_2.\n\nDimostrazione del Teorema\nPartiamo dalla relazione:\ne_{k+1} = Be_k\nIterando:\ne_{k+1} = B^{k+1}e_0\nL’errore e_{k+1} tende a zero indipendentemente da e_0 se e solo se B^{k+1} tende alla matrice nulla. Grazie al lemma (punto 1), questo accade se e solo se \\rho(B) &lt; 1.\nOsservazione\nSe ||B||_2 &lt; 1, allora, grazie al lemma (punto 2), anche \\rho(B) &lt; 1, e quindi il metodo converge. Tuttavia, può succedere che \\rho(B) &lt; 1 ma ||B||_2 &gt; 1, quindi la condizione sulla norma è solo sufficiente.\nVelocità di Convergenza\nLa grandezza del raggio spettrale determina anche la velocità di convergenza: più piccolo è \\rho(B), più rapida è la convergenza. Se abbiamo due metodi con matrici di iterazione B_1 e B_2 e \\rho(B_1) = 0.9 e \\rho(B_2) = 0.1, allora il secondo metodo converge più rapidamente.\nCostruzione di uno Schema Iterativo Generico: Metodo di Richardson\nPartiamo dal sistema lineare:\nAx = b\nMoltiplichiamo entrambi i membri per una costante \\alpha_k:\n\\alpha_k Ax = \\alpha_k b\nIntroduciamo una matrice invertibile P (precondizionatore) e riscriviamo \\alpha_k A come:\n\\alpha_k A = P - (P - \\alpha_k A)\nQuindi, il sistema diventa:\nPx - (P - \\alpha_k A)x = \\alpha_k b\nRisolvendo per Px:\nPx = (P - \\alpha_k A)x + \\alpha_k b\nIn modo arbitrario, associamo il membro di sinistra con la nuova iterata x_{k+1} e il membro di destra con la vecchia iterata x_k:\nPx_{k+1} = (P - \\alpha_k A)x_k + \\alpha_k b\nQuesto schema è consistente per costruzione. Per scriverlo nella forma x_{k+1} = Bx_k + g, moltiplichiamo per P^{-1}:\nx_{k+1} = P^{-1}(P - \\alpha_k A)x_k + \\alpha_k P^{-1}b\nQuindi:\nB_{\\alpha_k} = P^{-1}(P - \\alpha_k A) = I - \\alpha_k P^{-1}A\ng_{\\alpha_k} = \\alpha_k P^{-1}b\nL’algoritmo iterativo è:\n\nDato x_0 (guess iniziale)\nPer k \\ge 0: x_{k+1} = B_{\\alpha_k}x_k + g_{\\alpha_k}\n\nQuesto schema è noto come metodo di Richardson.\nMetodo di Richardson Stazionario e Dinamico\n\nStazionario: Se il parametro \\alpha_k è costante (\\alpha_k = \\alpha per ogni k), il metodo è detto stazionario.\nDinamico: Se il parametro \\alpha_k varia ad ogni iterazione, il metodo è detto dinamico.\n\nIn generale, un metodo dinamico può adattarsi meglio al problema, ma richiede un costo computazionale maggiore per la determinazione di \\alpha_k ad ogni iterazione.\n\nTeorema Fondamentale per i Metodi Iterativi\nIl teorema cardine per i metodi iterativi stabilisce una condizione necessaria e sufficiente per la convergenza di uno schema iterativo.\nIpotesi:\n\nSi considera uno schema iterativo nella forma: x_{k+1} = Bx_k + g\nLo schema è consistente, ovvero x = Bx + g\n\nTesi:\nEsiste equivalenza tra le seguenti affermazioni:\n\nIl raggio spettrale di B, indicato con \\rho(B), è strettamente minore di 1, cioè \\rho(B) &lt; 1\nLo schema converge, indipendentemente dalla scelta del guess iniziale x_0 \\in \\mathbb{R}^n\n\nDefinizione di Raggio Spettrale\nIl raggio spettrale \\rho(B) è definito come il massimo dei moduli degli autovalori della matrice B. Formalmente:\n\\rho(B) = \\max_i |\\lambda_i| dove \\lambda_i sono gli autovalori di B.\nIn MATLAB, il raggio spettrale può essere calcolato con la seguente sequenza di comandi:\neig(B); % Calcola gli autovalori di B\nabs();   % Calcola il valore assoluto (modulo) degli autovalori\nmax();   % Trova il massimo tra i moduli degli autovalori\n\nLemmi Utili per la Dimostrazione\nPer dimostrare il teorema, sono necessari due lemmi:\nLemma 1:\nSe C è una matrice a elementi reali, allora C^k \\rightarrow 0 (la potenza k-esima di C tende a zero) se e solo se \\rho(C) &lt; 1.\nLemma 2:\nEsiste una relazione tra il raggio spettrale di una matrice e la sua norma 2, ma solo in una direzione: \\rho(B) \\le ||B||_2. Non vale il viceversa.\nDimostrazione del Teorema\n\n\nPunto di partenza: Si sottrae lo schema iterativo dalla relazione di consistenza:\ne_{k+1} = x_{k+1} - x = Bx_k + g - (Bx + g) = B(x_k - x) = Be_k\ndove e_k rappresenta l’errore al passo k.\n\n\nIterazione: Iterando la relazione, si ottiene:\ne_{k+1} = B e_k = B^2 e_{k-1} = \\dots = B^{k+1} e_0\n\n\nConvergenza: L’errore e_{k+1} tende a zero indipendentemente da x_0 se e solo se B^{k+1} \\rightarrow 0.\n\n\nApplicazione del Lemma 1: Per il Lemma 1, B^{k+1} \\rightarrow 0 se e solo se \\rho(B) &lt; 1.\n\n\nPertanto, la convergenza dello schema è equivalente alla condizione \\rho(B) &lt; 1.\nOsservazioni aggiuntive\n\n\nImportanza della libertà di scelta del guess iniziale: La possibilità di scegliere liberamente il guess iniziale è fondamentale, specialmente in contesti come i metodi per equazioni non lineari, dove una scelta errata può compromettere la convergenza.\n\n\nLegame tra norma 2 e raggio spettrale: Se ||B||_2 &lt; 1, allora, grazie al Lemma 2, \\rho(B) &lt; 1, e quindi il metodo converge. Tuttavia, la convergenza può verificarsi anche se ||B||_2 &gt; 1, purché \\rho(B) &lt; 1.\n\n\nVelocità di convergenza: La grandezza del raggio spettrale determina la velocità di convergenza: più piccolo è \\rho(B), più rapida è la convergenza.\nEsempio: Dati due metodi, M1 con \\rho(B_1) = 0.9 e M2 con \\rho(B_2) = 0.1, si preferirà M2 perché converge più rapidamente.\n\n\nCostruzione di uno Schema Iterativo Generico: Il Metodo di Richardson\nIl professore introduce un metodo iterativo generico, noto come metodo di Richardson, partendo dal sistema lineare Ax = b e manipolandolo algebricamente per ottenere uno schema iterativo nella forma x_{k+1} = Bx_k + g.\nPassaggi Chiave\n\n\nMoltiplicazione per una costante: Si moltiplica il sistema per una costante \\alpha_k:\n\\alpha_k Ax = \\alpha_k b\n\n\nIntroduzione della matrice P: Si riscrive \\alpha_k A introducendo una matrice invertibile P (il precondizionatore):\n\\alpha_k A = P - (P - \\alpha_k A)\n\n\nRiscrittura del sistema: Si sostituisce questa espressione nel sistema originale:\nPx - (P - \\alpha_k A)x = \\alpha_k b\n\n\nDefinizione dello schema iterativo: Si associa il termine Px con la nuova iterata x_{k+1} e il resto con l’iterata precedente x_k:\nPx_{k+1} = (P - \\alpha_k A)x_k + \\alpha_k b\n\n\nForma Finale dello Schema di Richardson\nPer ottenere la forma canonica x_{k+1} = Bx_k + g, si moltiplica per P^{-1}:\nx_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\nDove:\n\nB_{\\alpha_k} = I - \\alpha_k P^{-1} A è la matrice di iterazione\ng_{\\alpha_k} = \\alpha_k P^{-1} b è il termine noto\n\nL’algoritmo risultante è:\n\nDato x^{(0)} (guess iniziale)\nPer k \\ge 0: x_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\n\nMetodi di Richardson Stazionari e Dinamici\n\nStazionario: \\alpha_k = \\alpha (costante per ogni k)\nDinamico: \\alpha_k varia ad ogni iterazione\n\nLa scelta tra stazionario e dinamico dipende dal problema specifico e dagli obiettivi di convergenza.\nGli schemi di Richardson sono consistenti per costruzione, il che significa che non è necessario verificare esplicitamente la condizione di consistenza quando si studia la convergenza. È sufficiente dimostrare che il raggio spettrale della matrice di iterazione è minore di 1.\nReferences\nAppunti Mate Num-lez05.pdf"},"6--full-note/mateNum--Lez06":{"slug":"6--full-note/mateNum--Lez06","filePath":"6- full note/mateNum- Lez06.md","title":"mateNum- Lez06","links":["tags/flashcard_finite","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","2--source-materials/Appunti-Mate-Num--Lez06.pdf"],"tags":["flashcard_finite","riscritto_zero","revisione_zero"],"content":"2025-03-03 18:01\n_Status: flashcard_finite  riscritto_zero  revisione_zero\n_Tags:sbobine matematica numerica\nmateNum- Lez06\nMetodi Iterativi per Sistemi di Equazioni Lineari\nI metodi iterativi sono utilizzati per risolvere sistemi di equazioni lineari attraverso una successione di approssimazioni. L’idea fondamentale è di partire da una stima iniziale della soluzione e di raffinare iterativamente questa stima fino a raggiungere un livello di accuratezza desiderato.\nSchema Generale\nUn metodo iterativo genera una successione di iterate regolata dalla legge:\nx_{k+1} = Bx_k + g\ndove:\n\nx_{k+1} è la nuova iterazione\nx_k è l’iterazione precedente\nB è la matrice di iterazione\ng è un vettore\n\nConvergenza e Consistenza\n\nConvergenza: Si desidera che la successione delle iterate converga alla soluzione del sistema lineare.\nConsistenza: Il metodo deve essere consistente, ovvero la soluzione del sistema deve essere un punto fisso dell’iterazione.\n\nCondizione Necessaria e Sufficiente per la Convergenza\nLa condizione necessaria e sufficiente per la convergenza è che il raggio spettrale della matrice di iterazione B sia strettamente minore di 1.\nMetodo di Richardson\nIl metodo di Richardson è una famiglia di metodi iterativi che parte dalla riscrittura del sistema lineare originale.\nSplitting\nSi introduce una matrice di precondizionamento P e un parametro \\alpha_k. Il sistema viene riscritto come:\n\\alpha_k A = P - (P - \\alpha_k A)\nSchema Iterativo\nLo schema iterativo di Richardson è dato da:\nx_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\ndove:\n\nI è la matrice identità\nP è la matrice di precondizionamento\n\\alpha_k è un parametro di accelerazione\n\nMetodo di Richardson Stazionario e Dinamico\n\nStazionario: Se \\alpha_k è uguale ad ogni iterazione (\\alpha_k = \\alpha).\nDinamico: Se \\alpha_k varia ad ogni iterazione.\n\nRiscrittura del Metodo di Richardson\n\nUn modo computazionalmente utile per riscrivere il metodo di Richardson è:\nx_{k+1} = x_k + \\alpha_k P^{-1} (b - Ax_k)\ndove r_k = b - Ax_k è il residuo.\nResiduo Precondizionato\nLa correzione z_k = P^{-1} r_k è chiamata residuo precondizionato. In pratica, per calcolare z_k, si risolve il sistema lineare Pz_k = r_k.\nScelta del Precondizionatore\nLa scelta del precondizionatore P è cruciale. Idealmente, P dovrebbe essere:\n\nInvertibile\nFacile da invertire (ad esempio, una matrice diagonale o tridiagonale)\nIn grado di migliorare il condizionamento del sistema\n\nTuttavia, non esiste un criterio univoco per scegliere P, e la scelta è spesso dipendente dal problema.\nMetodo di Jacobi\nIl metodo di Jacobi è un metodo iterativo in cui si usa la prima equazione per trovare la prima incognita, la seconda equazione per trovare la seconda incognita, e così via.\nDerivazione\nPartendo da un sistema di tre equazioni in tre incognite:\na_{11}x_1 + a_{12}x_2 + a_{13}x_3 = b_1\na_{21}x_1 + a_{22}x_2 + a_{23}x_3 = b_2\na_{31}x_1 + a_{32}x_2 + a_{33}x_3 = b_3\nSi ricavano le incognite:\nx_1 = \\frac{1}{a_{11}}(b_1 - a_{12}x_2 - a_{13}x_3)\nx_2 = \\frac{1}{a_{22}}(b_2 - a_{21}x_1 - a_{23}x_3)\nx_3 = \\frac{1}{a_{33}}(b_3 - a_{31}x_1 - a_{32}x_2)\nSchema Iterativo per Componenti\nSi associa la nuova iterazione alle quantità a sinistra e l’iterazione precedente a quelle a destra:\nx_1^{k+1} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^k - a_{13}x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^k - a_{23}x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}}(b_3 - a_{31}x_1^k - a_{32}x_2^k)\nGeneralizzazione per Componenti\nIn generale, per un sistema di n equazioni:\nx_i^{k+1} = \\frac{1}{a_{ii}}(b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k)\nper i = 1, \\dots, n e k \\geq 0 e a_{ii}\\neq 0.\nImplementazione Parallela\nL’algoritmo di Jacobi è ben parallelizzabile, poiché ogni componente della nuova iterazione può essere calcolata indipendentemente dalle altre.\nRiscrittura Matriciale\n\nSia D la matrice diagonale formata dalle entrate diagonali di A:\nD = \\begin{bmatrix} a_{11} &amp; 0 &amp; 0 \\\\ 0 &amp; \\ddots &amp; 0 \\\\ 0 &amp; 0 &amp; a_{nn} \\end{bmatrix}\nLo schema iterativo può essere riscritto in forma matriciale come:\nx^{k+1} = D^{-1}(b - (A - D)x^k)\nIdentificazione di B e G\nDalla forma matriciale, si identifica:\n\nB_J = D^{-1}(A - D)\ng_J = D^{-1}b\n\nRiscrittura come Metodo di Richardson\nLo schema di Jacobi può essere visto come un metodo di Richardson con:\n\nP = D (matrice diagonale)\n\\alpha_k = 1 (stazionario)\n\nQuindi:\nx^{k+1} = x^k + D^{-1}r^k\ndove r^k = b - Ax^k è il residuo.\n\nMetodo di Gauss-Seidel\nIl metodo di Gauss-Seidel è una variante del metodo di Jacobi in cui, nel calcolo di una componente, si utilizzano le componenti già aggiornate nella stessa iterazione.\nSchema Iterativo per Componenti (3x3)\nx_1^{k+1} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^k - a_{13}x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^{k+1} - a_{23}x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}}(b_3 - a_{31}x_1^{k+1} - a_{32}x_2^{k+1})\nGeneralizzazione per Componenti\nx_i^{k+1} = \\frac{1}{a_{ii}}(b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij}x_j^k)\nper i = 1, \\dots, n e k \\geq 0 e a_{ii} \\neq o.\nImplementazione Seriale\nA differenza di Jacobi, Gauss-Seidel è intrinsicamente seriale, poiché ogni componente dipende dalle precedenti già aggiornate.\nRiscrittura Matriciale\nSi decompone la matrice A come:\nA = D - E - F\ndove:\n\n\nD è la matrice diagonale\n-E è la parte strettamente triangolare inferiore di A\nA-D-(-E) è la parte strettamente triangolare superiore di A\n\nSchema Iterativo Matriciale\n\n(D - E)x^{k+1} = b + (D-E-A)x^k\nIdentificazione di B e G\nB_{GS} = (D - E)^{-1}(D-E-A)\ng_{GS} = (D - E)^{-1}b\nRiscrittura come Metodo di Richardson\nx^{k+1} = x^k + (D - E)^{-1}r^k\ndove r^k = b - Ax^k è il residuo. Quindi:\n\nP = D - E\n\\alpha_k = 1\n\nMetodo di Rilassamento di Jacobi (JOR)\nIl metodo JOR (Jacobi Over-Relaxation) introduce un parametro di rilassamento \\omega per accelerare la convergenza.\nSchema Iterativo per Componenti\nx_i^{k+1} = \\frac{\\omega}{a_{ii}}(b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k) + (1 - \\omega)x_i^k\nParametro di Rilassamento \\omega\n\n0 &lt; \\omega &lt; 1: Sottorilassamento\n\\omega &gt; 1: Sovrarilassamento\n\\omega = 1: Metodo di Jacobi\n\nRiscrittura Matriciale\n\nDx^{k+1} = \\omega(b - (A - D)x^k) + (1 - \\omega)Dx^k\nIdentificazione di B e G\nB_{JOR} = \\omega D^{-1}(A - D) + (1 - \\omega)I\ng_{JOR} = \\omega D^{-1}b\nRiscrittura come Metodo di Richardson\n\nx^{k+1} = x^k + \\omega D^{-1}r^k\nQuindi:\n\nP = D\n\\alpha_k = \\omega\n\nMetodo di Rilassamento di Gauss-Seidel (SOR)\nIl metodo SOR (Successive Over-Relaxation) combina le idee di Gauss-Seidel e del rilassamento.\nSchema Iterativo per Componenti\nx_i^{k+1} = \\frac{\\omega}{a_{ii}}(b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij}x_j^k) + (1 - \\omega)x_i^k\nRiscrittura Matriciale\n\n(D - \\omega E)x^{k+1} = \\omega b + (\\omega F + (1 - \\omega)D)x^k\nIdentificazione di B e G\nB_{SOR} = (D - \\omega E)^{-1}(\\omega F + (1 - \\omega)D)\ng_{SOR} = (D - \\omega E)^{-1}\\omega b\nRiscrittura come Metodo di Richardson\nx^{k+1} = x^k + (D - \\omega E)^{-1}r^k\nQuindi:\n\nP = (D - \\omega E)\n\\alpha_k = \\omega\n\nConvergenza di Jacobi e Gauss-Seidel\nCondizioni Sufficienti\n\nSe A è a dominanza diagonale stretta per righe o per colonne, allora sia Jacobi che Gauss-Seidel convergono.\nUlteriore Condizione per Gauss-Seidel\nSe A è simmetrica definita positiva (SPD), allora Gauss-Seidel converge.\nOsservazione\nLe condizioni sufficienti per la convergenza di Jacobi e Gauss-Seidel si basano sulle proprietà della matrice A, non sulle matrici di iterazione B_J e B_{GS}.\n\nEcco una spiegazione dettagliata e formattata dei metodi iterativi di Jacobi e Gauss-Seidel, includendo i passaggi matematici, esempi ed esercizi forniti, basata sulle fonti fornite.\nMetodi Iterativi per la Risoluzione di Sistemi di Equazioni Lineari\nL’obiettivo è risolvere sistemi di equazioni lineari utilizzando metodi iterativi. Questi metodi generano una successione di approssimazioni che, idealmente, convergono alla soluzione esatta.\nSchema Generale di Iterazione\n\nSi parte da una legge di ricorrenza: la nuova iterazione è una modifica della precedente.\nMatematicamente: x_{k+1} = B x_k + g, dove:\n\nx_{k+1} è la nuova iterazione.\nB è la matrice di iterazione.\nx_k è l’iterazione precedente.\ng è un vettore.\n\n\nObiettivi:\n\nConvergenza: la successione di iterazioni deve convergere alla soluzione esatta.\nConsistenza: ogni iterazione deve essere “sensata” rispetto al sistema originale.\n\n\nCondizione Sufficiente per la Convergenza: |B| &lt; 1 per qualche norma matriciale.\nCondizione Necessaria e Sufficiente per la Convergenza: il raggio spettrale di B deve essere minore di 1.\n\nSchemi di Richardson\n\nSono una famiglia di metodi iterativi.\nSi parte dal sistema Ax = b.\nSi moltiplica il sistema per una quantità reale \\alpha_k: \\alpha_k Ax = \\alpha_k b.\nSi introduce uno splitting della matrice A: \\alpha_k A = P - (P - \\alpha_k A), dove P è il precondizionatore.\nSi riscrive il problema come: Px = (P - \\alpha_k A)x + \\alpha_k b.\nSi identifica il termine a sinistra con la nuova iterazione e quello a destra con la vecchia:\n\nx_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\n\n\nMatrice di Iterazione: B(\\alpha_k) = I - \\alpha_k P^{-1} A\nVettore: g(\\alpha_k) = \\alpha_k P^{-1} b\nTipi di Schemi di Richardson:\n\nStazionario: \\alpha_k = \\alpha (costante per ogni iterazione).\nDinamico: \\alpha_k varia ad ogni iterazione.\n\n\n\nRiscrittura dello Schema di Richardson\n\nPartendo da x_{k+1} = x_k - \\alpha_k P^{-1} A x_k + \\alpha_k P^{-1} b\nSi espande il prodotto: x_{k+1} = x_k + \\alpha_k P^{-1} (b - A x_k)\nSi definisce il residuo r_k = b - A x_k.\nLo schema diventa: x_{k+1} = x_k + \\alpha_k P^{-1} r_k\nSi introduce la correzione z_k = P^{-1} r_k, detta residuo precondizionato.\n\nPer calcolare z_k, si risolve il sistema lineare P z_k = r_k.\n\n\nConsiderazioni Implementative:\n\nCalcolare l’inversa di una matrice è computazionalmente costoso.\nSi risolve il sistema lineare Pz_k = r_k invece di calcolare P^{-1}.\nSe si risolve un sistema con la stessa matrice P ad ogni iterazione, si può calcolare la fattorizzazione LU di P una sola volta.\nSi può scegliere P diagonale, tridiagonale o triangolare per semplificare la risoluzione del sistema.\n\n\nScelta del Precondizionatore:\n\nP deve essere invertibile.\nLa risoluzione del sistema Pz_k = r_k deve essere semplice.\nP deve migliorare il condizionamento del sistema originale.\nLa scelta di P è problem-dependent.\n\n\n\nMetodo di Jacobi\nDerivazione\n\nPartiamo da un sistema di 3 equazioni in 3 incognite:\n\na_{11}x_1 + a_{12}x_2 + a_{13}x_3 = b_1\na_{21}x_1 + a_{22}x_2 + a_{23}x_3 = b_2\na_{31}x_1 + a_{32}x_2 + a_{33}x_3 = b_3\n\n\nRicaviamo ogni incognita dalla corrispondente equazione:\n\nx_1 = \\frac{1}{a_{11}}(b_1 - a_{12}x_2 - a_{13}x_3)\nx_2 = \\frac{1}{a_{22}}(b_2 - a_{21}x_1 - a_{23}x_3)\nx_3 = \\frac{1}{a_{33}}(b_3 - a_{31}x_1 - a_{32}x_2)\n\n\nAssociamo le quantità a sinistra con la nuova iterazione (k+1) e quelle a destra con l’iterazione precedente (k):\n\nx_1^{k+1} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^k - a_{13}x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^k - a_{23}x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}}(b_3 - a_{31}x_1^k - a_{32}x_2^k)\n\n\n\nGeneralizzazione del Metodo di Jacobi\nPer un sistema di n equazioni in n incognite, la componente i-esima del vettore all’iterazione k+1 è data da:\nx_i^{k+1} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k \\right)\ndove:\n\nx_i^{k+1} è la componente i-esima del vettore x all’iterazione k+1.\na_{ii} è l’elemento diagonale della matrice A (deve essere diverso da zero).\nb_i è la componente i-esima del vettore b.\na_{ij} sono gli elementi della matrice A.\nx_j^k è la componente j-esima del vettore x all’iterazione k.\nLa sommatoria calcola la somma di tutti i termini tranne quello sulla diagonale.\n\nImplementazione\n\nImplementabile in parallelo: ogni processore può calcolare una componente del vettore x^{k+1} indipendentemente dagli altri.\n\nRiscrittura Matriciale\n\nIntroduzione della matrice diagonale D: matrice che contiene solo gli elementi diagonali di A.\nIntroduzione dei vettori x^k e x^{k+1}: vettori colonna contenenti le componenti delle iterazioni k e k+1.\nMoltiplicando entrambi i membri per a_{ii}: a_{ii} x_i^{k+1} = b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k\nRiscrivendo in forma matriciale: Dx^{k+1} = b - (A-D)x^k\nMoltiplicando per D^{-1}: x^{k+1} = D^{-1}b - D^{-1}(A-D)x^k\nSemplificando: x^{k+1} = D^{-1}b + (I - D^{-1}A)x^k\n\nForma A e B\n\nForma A: x^{k+1} = B_J x^k + g_J, dove:\n\nB_J = I - D^{-1}A (matrice di iterazione di Jacobi).\ng_J = D^{-1}b (vettore di Jacobi).\n\n\n\nRiscrittura alla Richardson\n\nx^{k+1} = x^k + D^{-1}(b - Ax^k)\nx^{k+1} = x^k + D^{-1}r^k, dove r^k è il residuo.\n\nIdentificazione con lo Schema di Richardson\n\nIl metodo di Jacobi è uno schema di Richardson stazionario.\nP_J = D (precondizionatore è la matrice diagonale).\n\\alpha_k = 1 (parametro di accelerazione è costante e uguale a 1).\n\n==Metodo di Gauss-Seidel\nModifica al Metodo di Jacobi\n\nSi utilizzano le componenti già aggiornate della nuova iterazione (k+1) non appena sono disponibili.\nQuesto dovrebbe accelerare la convergenza (ma non è sempre vero).\n\nImplementazione\n\nImplementazione seriale: a differenza di Jacobi, Gauss-Seidel non è parallelizzabile perché ogni componente dipende dalle precedenti già aggiornate.\n\nFormulazione per Componenti\n\nx_1^{k+1} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^k - a_{13}x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^{k+1} - a_{23}x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}}(b_3 - a_{31}x_1^{k+1} - a_{32}x_2^{k+1})\n\nGeneralizzazione\nx_i^{k+1} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij}x_j^k \\right)\nRiscrittura con Sommatorie\nLa sommatoria di Jacobi viene divisa in due somme: una per le componenti “nuove” (k+1) e una per le componenti “vecchie” (k).\nNotazione Matriciale\n\nDecomposizione della matrice A: A = D - E + (A - D + E), dove:\n\nD è la matrice diagonale.\n-E è la parte strettamente triangolare inferiore di A.\nA - D + E è la parte strettamente triangolare superiore di A.\n\n\n\nRiscrittura Matriciale\n\nPartendo dall’equazione: Dx^{k+1} = b + E x^{k+1} - (A - D + E)x^k\nRiorganizzando: (D - E)x^{k+1} = b - (A - D + E)x^k\n\nForma A e B\n\nForma A: x^{k+1} = B_{GS} x^k + g_{GS}, dove:\n\nB_{GS} = (D - E)^{-1}(D - E - A)\ng_{GS} = (D - E)^{-1}b\n\n\n\nRiscrittura alla Richardson\n\nx^{k+1} = x^k + (D - E)^{-1}(b - Ax^k)\nP_{GS} = D - E (precondizionatore è la matrice triangolare inferiore).\n\\alpha_k = 1 (parametro di accelerazione è costante e uguale a 1).\n\nMetodo di Rilassamento di Jacobi (JOR)\n\nÈ una combinazione lineare del sistema classico e di x_i^k.\nx_i^{k+1} = \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k \\right) + (1-\\omega)x_i^k\n\\omega è il parametro di rilassamento:\n\n0 &lt; \\omega &lt; 1: sottorilassamento.\n\\omega &gt; 1: sovrarilassamento.\n\\omega = 1: metodo di Jacobi.\n\n\n\nRiscrittura\nx_i^{k+1} = \\omega D^{-1}(b - (A-D)x^k)+(1-\\omega)x^k\nForma A e B\n\nB_{JOR} = \\omega(I - D^{-1}A) + (1-\\omega)I = \\omega B_J + (1-\\omega)I\n\nRiscrittura alla Richardson\nx^{k+1} = x^k + \\omega D^{-1} r^k\nP_{JOR} = D precondizionatore come Jacobi \\alpha_k = \\omega parametro di accelerazione\nMetodo di Rilassamento di Gauss-Seidel (SOR)\n\nSuccessive Over-Relaxation.\nx_i^{k+1} = \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij}x_j^k \\right) + (1-\\omega)x_i^k\nSe \\omega = 1, si ottiene Gauss-Seidel.\n\nForma matriciale\nD x^{k+1} = \\omega b + \\omega E x^{k+1} - \\omega (A-D+E) x^k + (1-\\omega) D x^k\nForma A e B\n\nB_{SOR} = (I - \\omega D^{-1} E)^{-1}((1-\\omega)I + \\omega D^{-1} (D-E-A))\ng_{SOR} = (I - \\omega D^{-1} E)^{-1} \\omega D^{-1}b\n\nRiscrittura alla Richardson\nx^{k+1} = x^k + \\omega (D - \\omega E)^{-1} r^k\nP_{SOR} = (D - \\omega E) \\alpha_k = \\omega\nConvergenza\n\nCondizione Necessaria e Sufficiente: il raggio spettrale della matrice di iterazione (BJ, BGS, BJSR, BSOR) deve essere minore di 1.\nCondizioni Sufficienti per Jacobi e Gauss-Seidel: se la matrice A è a dominanza diagonale stretta per righe o per colonne, allora Jacobi e Gauss-Seidel convergono.\nCondizione Sufficiente Aggiuntiva per Gauss-Seidel: se A è definita positiva, allora Gauss-Seidel converge.\n\n\nEcco la spiegazione del professore riguardo alle flashcard, integrata con i passaggi matematici, gli esempi e gli esercizi, formattata in modo chiaro e leggibile.\n==Metodo di Gauss-Seidel: spiegazione dettagliata\nIdea di base\nL’idea alla base del metodo di Gauss-Seidel è di utilizzare le componenti già aggiornate durante il calcolo delle nuove iterate. Invece di aspettare di completare un’intera iterazione per aggiornare tutte le componenti del vettore soluzione, Gauss-Seidel sfrutta immediatamente i nuovi valori non appena sono disponibili.\nIterazione\n\nNel metodo di Jacobi, la componente i-esima della nuova iterazione dipende solo dalle componenti dell’iterata precedente.\nNel metodo di Gauss-Seidel, la componente i-esima della nuova iterazione dipende dalle componenti dell’iterata precedente, ma anche dalle componenti già aggiornate nella stessa iterazione.\n\nEsempio 3x3\nConsideriamo un sistema 3x3:\nx_1^{k+1} = \\frac{1}{a_{11}} (b_1 - a_{12} x_2^k - a_{13} x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}} (b_2 - a_{21} x_1^{\\color{red}{k+1}} - a_{23} x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}} (b_3 - a_{31} x_1^{\\color{red}{k+1}} - a_{32} x_2^{\\color{red}{k+1}})\nSi noti come, nel calcolo di x_2^{k+1} e x_3^{k+1}, si utilizzino i valori di x_1^{k+1} e x_2^{k+1} già calcolati nella stessa iterazione (indicati in rosso).\nImplementazione\nL’implementazione del metodo di Gauss-Seidel è seriale, poiché ogni componente dipende dalle precedenti già aggiornate. Questo significa che non è possibile parallelizzare facilmente l’algoritmo come nel caso di Jacobi.\nFormulazione generale\nLa formula generale per il metodo di Gauss-Seidel è:\nx_i^{k+1} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij} x_j^k \\right)\ndove:\n\nx_i^{k+1} è la i-esima componente del vettore soluzione all’iterazione k+1.\na_{ii} è l’elemento diagonale della matrice dei coefficienti.\nb_i è la i-esima componente del vettore dei termini noti.\nLa prima sommatoria considera le componenti già aggiornate (x_j^{k+1}).\nLa seconda sommatoria considera le componenti dell’iterata precedente (x_j^k).\n\nRiscrittura in forma matriciale\nPer riscrivere il metodo di Gauss-Seidel in forma matriciale, è utile decomporre la matrice A come segue:\nA = D - E - F\ndove:\n\nD è la matrice diagonale contenente gli elementi diagonali di A.\n-E è la matrice triangolare inferiore stretta (elementi sotto la diagonale).\nA-D-(-E) è la matrice triangolare superiore stretta (elementi sopra la diagonale). Quindi F = A - D + E.\n\nNotazione\nÈ importante prestare attenzione al segno di E, poiché viene definita come -E la parte triangolare inferiore.\nQuindi -E è la matrice triangolare inferiore della matrice A:\nE = \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ -a_{21} &amp; 0 &amp; 0 \\\\ -a_{31} &amp; -a_{32} &amp; 0 \\end{bmatrix}\nForma matriciale del metodo di Gauss-Seidel\nUsando questa decomposizione, il metodo di Gauss-Seidel può essere scritto in forma matriciale come:\nDx^{k+1} = b - Ex^{k+1} - F x^k\nRiordinando i termini:\n(D - E) x^{k+1} = b - F x^k\nIterazione\nx^{k+1} = (D - E)^{-1} (b - F x^k)\nQuesta è la forma matriciale del metodo di Gauss-Seidel.\nUlteriori passaggi\nPer arrivare alle forme A e B, si possono seguire questi passaggi:\nx^{k+1} = (D - E)^{-1} b - (D - E)^{-1} F x^k\nx^{k+1} = (D - E)^{-1} b + (I - (D - E)^{-1} A )x^k\n\nMatrice di iterazione: B_{GS} = -(D-E)^{-1}F = I - (D - E)^{-1} A\nVettore G: G_{GS} = (D - E)^{-1} b\n\nRiscrittura alla Richardson\nPartendo dalla forma matriciale:\nx^{k+1} = (D - E)^{-1} b - (D - E)^{-1} F x^k\nSi aggiunge e sottrae x^k:\nx^{k+1} = x^k + (D - E)^{-1} b - (D - E)^{-1} F x^k - x^k\nx^{k+1} = x^k + (D - E)^{-1} (b - F x^k - (D - E)x^k)\nx^{k+1} = x^k + (D - E)^{-1} (b - (F + D - E)x^k)\nx^{k+1} = x^k + (D - E)^{-1} (b - A x^k)\nQuindi:\nx^{k+1} = x^k + (D - E)^{-1} r^k\ndove r^k = b - A x^k è il residuo all’iterazione k.\nParametri di Richardson\nDa questa forma, si identifica:\n\nPrecondizionatore: P_{GS} = (D - E)\nParametro di accelerazione: \\alpha_k = 1 (stazionario)\n\nMetodo di Jacobi\nIterazione\nx_i^{k+1} = \\frac{1}{a_{ii}} (b_i - \\sum_{j\\ne i} a_{ij} x_j^k)\nRiscrittura alla Richardson\nx^{k+1} = x^k + D^{-1} r^k\nParametri di Richardson\nDa questa forma, si identifica:\n\nPrecondizionatore: P_{J} = D\nParametro di accelerazione: \\alpha_k = 1 (stazionario)\n\nMetodo di Rilassamento (SOR)\nSOR\nIl metodo SOR (Successive Over-Relaxation) è una variante del metodo di Gauss-Seidel che introduce un parametro di rilassamento \\omega per accelerare la convergenza.\nIterazione\nx_i^{k+1} = (1-\\omega)x_i^k + \\frac{\\omega}{a_{ii}} \\left(b_i - \\sum_{j&lt;i} a_{ij}x_j^{k+1} - \\sum_{j&gt;i} a_{ij}x_j^k\\right)\nImplementazione\nCome Gauss-Seidel, SOR è un algoritmo seriale.\nConvergenza\nCondizione necessaria e sufficiente\nPer tutti gli schemi iterativi nella forma x^{k+1} = Bx^k + G, la condizione necessaria e sufficiente per la convergenza è che il raggio spettrale della matrice di iterazione B sia minore di 1:\n\\rho(B) &lt; 1\ndove \\rho(B) è il massimo degli autovalori in modulo della matrice B.\nConsistenza\nPer gli schemi di Richardson, la consistenza è garantita per costruzione.\nCondizioni sufficienti per Jacobi e Gauss-Seidel\nSe la matrice A è a dominanza diagonale stretta per righe o per colonne, allora sia il metodo di Jacobi che il metodo di Gauss-Seidel convergono.\nPer Gauss-Seidel, se A è simmetrica definita positiva, allora il metodo converge.\nReferences\nAppunti Mate Num- Lez06.pdf"},"6--full-note/mateNum--Lez07":{"slug":"6--full-note/mateNum--Lez07","filePath":"6- full note/mateNum- Lez07.md","title":"mateNum- Lez07","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","paste/Appunti-Mate-Num--Lez07.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-04 16:47\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:  sbobine   matematica numerica\nmateNum- Lez07\nConvergenza dei Metodi Iterativi di Richardson\nCondizione Necessaria e Sufficiente\nPer tutti gli schemi iterativi della forma x^{k+1} = Bx^k + G, si può utilizzare la condizione necessaria e sufficiente che richiede la consistenza più il fatto che il raggio spettrale della corrispondente matrice B sia strettamente minore di 1.\nCondizioni Sufficienti per Jacobi e Gauss-Seidel\nEsistono condizioni sufficienti che riguardano la matrice A che permettono di stabilire la convergenza di Jacobi e Gauss-Seidel:\n\nJacobi: Se A è una matrice a dominanza diagonale stretta per righe o per colonne, allora Jacobi è convergente.\nGauss-Seidel: Valgono le stesse affermazioni di Jacobi, e in più, se A è una matrice simmetrica definita positiva, allora Gauss-Seidel è convergente.\n\nConfronto tra Jacobi e Gauss-Seidel\nIn generale, si potrebbe pensare che Gauss-Seidel converga meglio di Jacobi perché utilizza in corso le componenti già aggiornate. Tuttavia, ci sono casi in cui Jacobi converge e Gauss-Seidel diverge, o Jacobi performa meglio di Gauss-Seidel.\nProposizione\nSe A è una matrice di ordine n a elementi reali tridiagonale e non singolare, con tutte le entrate diagonali a_{ii} diverse da 0 per i da 1 a n, allora:\n\nGauss-Seidel e Jacobi convergono entrambi o divergono entrambi.\nSe entrambi convergono, il raggio spettrale della matrice B associata a Gauss-Seidel è uguale al quadrato del raggio spettrale della matrice di Jacobi: \\rho(B_{GS}) = \\rho(B_{Jac})^2.\n\nEsempio\nSupponiamo che il raggio spettrale della matrice di iterazione associata a Jacobi sia \\rho(B_{Jac}) = \\frac{1}{4}. Fissiamo una tolleranza TOL e cerchiamo il numero minimo di iterazioni k \\in \\mathbb{N} tale che \\rho(B_{Jac})^k \\le TOL.\n\\left(\\frac{1}{4}\\right)^k \\le TOL\n\\frac{1}{TOL} \\le 4^k\n\\log_4\\left(\\frac{1}{TOL}\\right) \\le k\nQuindi, k \\ge \\lceil\\log_4\\left(\\frac{1}{TOL}\\right)\\rceil.\nPer Gauss-Seidel, \\rho(B_{GS}) = \\left(\\frac{1}{4}\\right)^2 = \\frac{1}{16}. Quindi:\n\\left(\\frac{1}{16}\\right)^k \\le TOL\n\\frac{1}{TOL} \\le 16^k = (4^2)^k = 4^{2k}\n\\log_4\\left(\\frac{1}{TOL}\\right) \\le 2k\nk \\ge \\lceil{\\frac{1}{2}\\log_4\\left(\\frac{1}{TOL}\\right)}\\rceil\nQuesto esempio mostra che il numero di iterazioni richieste da Gauss-Seidel è circa la metà di quelle richieste da Jacobi per raggiungere la stessa accuratezza.\nEsempio numerico: Risolvendo un sistema Ax = b con A tridiagonale \\begin{bmatrix}\n  3 &amp; -1 &amp; 0 &amp; \\cdots &amp; 0 \\\\\n  -2 &amp; 3 &amp; -1 &amp; \\cdots &amp; 0 \\\\\n  0 &amp; -2 &amp; 3 &amp; \\cdots &amp; 0 \\\\\n  \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n  0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 3\n\\end{bmatrix}, e b = \\begin{bmatrix} 1,\\cdots, 1 \\end{bmatrix} si trova che Jacobi richiede  it_j= 277 iterazioni mentre Gauss-Seidel ne richiede it_{GS}= 143 per x^{(0)}=0 una tolleranza di 10^{-12}.\nConvergenza di JOR e SOR\nJOR\nSe A è una matrice simmetrica definita positiva, allora lo schema di JOR converge se 0 &lt; \\omega &lt; \\frac{2}{\\rho(D^{-1}A)}, dove D è la diagonale di A (il precondizionatore di Jacobi e JOR).\nSOR\n\nSe A è simmetrica definita positiva, allora SOR converge se e solo se 0 &lt; \\omega &lt; 2.\nSe A è simmetrica definita positiva e tridiagonale, allora SOR converge per 0 &lt; \\omega &lt; 2 e esiste un valore ottimale per il parametro di rilassamento \\omega.\n\n\\omega_{opt} = \\frac{2}{1 + \\sqrt{1 - \\rho(B_{Jac})^2}}\nQuesto valore ottimale massimizza la velocità di convergenza.\nCriteri di Arresto nelle Iterazioni\nIntroduzione\nQuando si implementano metodi iterativi per approssimare la soluzione di un sistema lineare, è fondamentale stabilire dei criteri di arresto per interrompere il processo iterativo. Questi criteri servono a bilanciare l’accuratezza della soluzione con il costo computazionale.\nCriteri di Arresto Principali\n\nNumero Massimo di Iterazioni:\n\nÈ cautelativo fissare un numero massimo di iterazioni (N_{\\text{max}}).\nLa scelta di N_{\\text{max}} è arbitraria e dipende dall’utente.\nServe a garantire che l’algoritmo termini anche se la convergenza è lenta.\n\n\nControllo sull’Errore (Tolleranza):\n\nSi cerca un indice k tale che l’errore (la differenza tra la soluzione esatta x e l’approssimazione x^k) sia minore di una tolleranza fissata (\\text{tol}).\nMatematicamente: |x - x^k| &lt; \\text{tol}.\nIn pratica, non si conosce x, quindi si utilizza uno stimatore S.\nSi arresta il loop quando S &lt; \\text{tol}, combinando questo criterio con il numero massimo di iterazioni.\n\n\n\nStimatore S e Affidabilità\n\n\nL’obiettivo è trovare una quantità S che surroghi l’errore, ovvero che lo approssimi.\n\n\nIdealmente, S dovrebbe essere molto vicino all’errore reale.\n\n\nSi introduce una costante C tale che \\text{Errore} \\approx C \\cdot S.\n\nSe C è piccola (dell’ordine di 10^0 o 10^1), lo stimatore è affidabile.\nSe C è grande (es. 3 \\times 10^6), lo stimatore non è affidabile.\n\n\n\nSi utilizzano due stimatori (S_1 e S_2) per avere alternative nel caso uno non sia affidabile.\n\n\nStimatore 1: Residuo Relativo\nDefinizione del Residuo\n\n\nIl residuo r^k è definito come r^k = b - Ax^k, dove x^k è l’approssimazione della soluzione al passo k.\n\n\nIl razionale è che, se x^k fosse la soluzione esatta x, allora r^k sarebbe zero.\n\n\nSi utilizza il residuo relativo come stimatore S_1:\nS_1 = \\frac{|r^k|}{|b|}\n\n\nSi cerca il minimo k tale che \\frac{|r^k|}{|b|} \\leq \\text{tol}.\n\n\nLegame con l’Errore Relativo\n\n\nSi vuole trovare una relazione tra l’errore relativo e il residuo relativo:\n\\frac{|x - x^k|}{|x|} \\leq C \\cdot \\frac{|r^k|}{|b|}\n\n\nLa costante C in questo caso è il numero di condizionamento K(A) della matrice A.\n\n\nNumero di Condizionamento\n\nSe la matrice A è ben condizionata (K(A) piccolo), allora S_1 è uno stimatore affidabile.\nSe la matrice A è mal condizionata (K(A) grande), allora S_1 non è affidabile.\nIl numero di condizionamento è legato alla sensibilità della soluzione del sistema lineare alle perturbazioni nei dati.\n\nDerivazione della Relazione\n\n\nSi parte dalla relazione nota (vista durante lo studio del condizionamento):\n\\frac{|\\delta x|}{|x|} \\leq K(A) \\frac{|\\delta b|}{|b|}\n\n\nDove \\delta x è la perturbazione sulla soluzione e \\delta b è la perturbazione sul dato.\n\n\nSi identifica \\delta b con -r^k, ottenendo:\n\\frac{|x - x^k|}{|x|} \\leq K(A) \\frac{|r^k|}{|b|}\n\n\nStimatore 2: Incremento\nDefinizione dell’Incremento\n\nL’incremento \\delta^k è definito come la differenza tra due iterate successive: \\delta^k = x_{k+1} - x^k.\nQuesto stimatore è usato per controllare l’errore assoluto.\n\nRelazione con l’Errore Assoluto\n\n\nSi cerca una relazione tra l’errore assoluto e l’incremento:\n|x - x^k| \\leq C \\cdot |\\delta^k|\n\n\nSi aggiunge e sottrae x_{k+1} all’errore:\n|x - x^k| = |x - x_{k+1} + x_{k+1} - x^k|\n\n\nSi ottiene:\n|x - x^k| = |(x - x_{k+1}) + (x_{k+1} - x^k)| = |e_{k+1} + \\delta^k|\n\n\nUsando la disuguaglianza triangolare:\n|e_{k+1} + \\delta^k| \\leq |e_{k+1}| + |\\delta^k|\n\n\nUlteriori Passaggi (con B Simmetrica Definitiva Positiva)\n\n\nSi assume che la matrice di precondizionamento B sia simmetrica definita positiva per semplificare i calcoli.\n\n\nSi usa la relazione e_{k+1} = B e^k, quindi |e_{k+1}| = |B e^k|.\n\n\nUsando la compatibilità tra norma matriciale e vettoriale:\n|B e^k| \\leq |B| |e^k|\n\n\nSi ha:\n|x - x^k| \\leq |B| |e^k| + |\\delta^k|\n\n\nDa cui:\n|e^k| \\leq |B| |e^k| + |\\delta^k|\n\n\nSe B è simmetrica definita positiva, allora |B|_2 = \\rho(B), il raggio spettrale di B.\n\n\nRiarrangiando:\n|e^k|(1 - \\rho(B)) \\leq |\\delta^k|\n\n\nInfine:\n|x - x^k| \\leq \\frac{1}{1 - \\rho(B)} |\\delta^k|\n\n\nAffidabilità dello Stimatore\n\nLa costante C è \\frac{1}{1 - \\rho(B)}.\nAffinché S_2 sia affidabile, \\rho(B) deve essere il più vicino possibile a zero.\nQuesto significa che il metodo deve convergere velocemente.\n\nConclusioni\n\nSe la matrice A è ben condizionata, si può usare il residuo relativo S_1.\nSe il metodo converge velocemente, si può usare l’incremento S_2.\nIn caso contrario, è necessario utilizzare altri metodi.\n\nConvergenza del Metodo di Richardson Stazionario\nTeorema di convergenza: Per un generico schema di Richardson stazionario, con precondizionatore invertibile P, la convergenza è garantita indipendentemente dalla scelta del guess iniziale \\forall x_0 \\in \\mathbb{R}^n se e solo se il parametro di accelerazione \\alpha soddisfa una specifica relazione.\nCondizione necessaria e sufficiente: La condizione è definita in termini degli autovalori \\lambda_i della matrice precondizionata P^{-1}A. In particolare, \\alpha deve soddisfare la seguente disuguaglianza:\n2 \\frac{Re(\\lambda_i)}{\\alpha |\\lambda_i|^2} &gt; 1 \\quad \\forall i\ndove:\n\nRe(\\lambda_i) è la parte reale dell’autovalore \\lambda_i\n|\\lambda_i|^2 è il modulo quadrato dell’autovalore \\lambda_i\n\nOsservazioni:\n\nAnche se la matrice A ha coefficienti reali, gli autovalori \\lambda_i di P^{-1}A possono essere complessi.\nSe gli autovalori sono reali, la condizione si semplifica.\n\nRaggio Spettrale e Matrice di Iterazione\nLa condizione di convergenza è strettamente legata al raggio spettrale della matrice di iterazione.\nMatrice di iterazione: Per il metodo di Richardson stazionario, la matrice di iterazione B_\\alpha è data da:\nB_\\alpha = I - \\alpha P^{-1}A\ndove I è la matrice identità.\nAutovalori di B_\\alpha: Se \\lambda_i sono gli autovalori di P^{-1}A, allora gli autovalori corrispondenti di B_\\alpha sono:\n1 - \\alpha \\lambda_i\nCondizione di convergenza basata sul raggio spettrale: La convergenza è assicurata se il modulo di questi autovalori è minore di 1 per ogni i:\n|1 - \\alpha \\lambda_i| &lt; 1 \\quad \\forall i\nAnalisi del Modulo e Derivazione della Condizione\nPer analizzare la condizione |1 - \\alpha \\lambda_i| &lt; 1, è necessario considerare la parte reale e immaginaria del numero complesso 1 - \\alpha \\lambda_i.\nCalcolo del modulo: Il modulo al quadrato è dato da:\n|1 - \\alpha \\lambda_i|^2 = Re(1 - \\alpha \\lambda_i)^2 + Im(1 - \\alpha \\lambda_i)^2\ndove:\n\nRe(1 - \\alpha \\lambda_i) = 1 - \\alpha Re(\\lambda_i)\nIm(1 - \\alpha \\lambda_i) = -\\alpha Im(\\lambda_i)\n\nSviluppo della disuguaglianza: Sostituendo e sviluppando, si ottiene:\n[1 - \\alpha Re(\\lambda_i)]^2 + [-\\alpha Im(\\lambda_i)]^2 &lt; 1\n1 - 2\\alpha Re(\\lambda_i) + \\alpha^2 Re(\\lambda_i)^2 + \\alpha^2 Im(\\lambda_i)^2 &lt; 1\nSemplificazione: Dopo alcune semplificazioni algebriche, si arriva a:\n\\alpha^2 |\\lambda_i|^2 - 2\\alpha Re(\\lambda_i) &lt; 0\nCondizione finale: Dividendo per \\alpha^2 |\\lambda_i|^2 (e notando che la quantità 2\\alpha Re(\\lambda_i) deve essere positiva), si ottiene:\n2 \\frac{Re(\\lambda_i)}{\\alpha |\\lambda_i|^2} &gt; 1\nche è la condizione di convergenza iniziale.\nScelta Ottimale di \\alpha\nIn condizioni più restrittive, si può determinare un valore ottimale per \\alpha che massimizza la velocità di convergenza.\nIpotesi aggiuntive:\n\nP^{-1}A ha tutti gli autovalori reali e positivi\nGli autovalori sono ordinati in modo decrescente: \\lambda_1 &gt; \\lambda_2 &gt; ... &gt; \\lambda_n &gt; 0\n\nIntervallo di convergenza per \\alpha: In queste condizioni, il metodo di Richardson stazionario converge se \\alpha appartiene all’intervallo:\n0 &lt; \\alpha &lt; \\frac{2}{\\lambda_1}\ndove \\lambda_1 è l’autovalore massimo di P^{-1}A.\nValore ottimale di \\alpha: Il raggio spettrale della matrice di iterazione B_\\alpha è minimizzato quando \\alpha è scelto come:\n\\alpha_{ott} = \\frac{2}{\\lambda_1 + \\lambda_n}\ndove \\lambda_n è l’autovalore minimo di P^{-1}A.\nDimostrazione Grafica del Valore Ottimale di \\alpha\nLa determinazione del valore ottimale di \\alpha può essere compresa graficamente analizzando come varia il modulo degli autovalori di B_\\alpha in funzione di \\alpha.\nSetup del grafico:\n\nSi considerano tre autovalori \\lambda_1 &gt; \\lambda_2 &gt; \\lambda_3 &gt; 0 di P^{-1}A.\nSi tracciano i grafici delle funzioni |1 - \\alpha \\lambda_i| per i = 1, 2, 3 in funzione di \\alpha.\n\n\nAndamento dei grafici:\n\nOgni grafico ha una forma a “V” e interseca l’asse \\alpha in \\frac{1}{\\lambda_i}.\nTutti i grafici partono dal punto (0, 1).\n\nDeterminazione grafica di \\alpha_{ott}:\n\nPer ogni valore di \\alpha, si identificano i tre valori |1 - \\alpha \\lambda_i|.\nSi considera il massimo di questi tre valori, che corrisponde al raggio spettrale.\nSi cerca il valore di \\alpha che minimizza questo massimo.\n\nPunto di minimo: Il minimo del massimo si trova nel punto di intersezione tra il ramo decrescente della funzione associata a \\lambda_1 e il ramo crescente della funzione associata a \\lambda_3\n\nCalcolo geometrico: Si impone l’uguaglianza tra le due rette:\n1 - \\alpha \\lambda_3 = \\alpha \\lambda_1 - 1\nDa cui si ricava:\n\\alpha_{ott} = \\frac{2}{\\lambda_1 + \\lambda_3}\nChe generalizzato al caso di n autovalori diventa:\n\\alpha_{ott} = \\frac{2}{\\lambda_1 + \\lambda_n}\nConsiderazioni Finali\nLa scelta di \\alpha è cruciale per la convergenza e l’efficienza del metodo di Richardson stazionario. Mentre le condizioni teoriche forniscono un quadro generale, la determinazione del valore ottimale richiede ulteriori ipotesi sugli autovalori della matrice precondizionata P^{-1}A.\nInoltre, mentre ci sono delle indicazioni su come scegliere \\alpha in modo ottimale, non ci sono altrettante indicazioni su come scegliere P.\nReferences\nAppunti Mate Num- Lez07.pdf"},"6--full-note/mateNum--Lez08":{"slug":"6--full-note/mateNum--Lez08","filePath":"6- full note/mateNum- Lez08.md","title":"mateNum- Lez08","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","2--source-materials/Appunti-Mate-Num--lez08.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-06 15:28\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine   matematica numerica\nmateNum- Lez08\nMetodo di Richardson Stazionario Precondizionato\nRichiamo sulla Lezione Precedente\nNella lezione precedente, abbiamo introdotto il metodo di Richardson stazionario precondizionato e iniziato a esplorare il ruolo del parametro di accelerazione \\alpha. L’obiettivo era di comprendere come questo parametro potesse influenzare la convergenza del metodo, in analogia a quanto osservato con i metodi di Jacobi e Gauss-Seidel, dove un parametro \\omega (simile ad \\alpha) veniva utilizzato per accelerare la convergenza. Ricordiamo che in Jacobi e Gauss-Seidel, il parametro era fissato a uno, mentre con il metodo di Richardson stazionario precondizionato, abbiamo la libertà di scegliere \\alpha in modo più strategico.\nRicerca del Parametro Ottimale \\alpha_{opt}\nAbbiamo derivato un teorema che, sotto l’ipotesi che la matrice di precondizionamento P sia non singolare e che la matrice P^{-1}A abbia tutti gli autovalori reali e positivi, ci permette di definire un intervallo di valori ammissibili per \\alpha e di calcolare un valore ottimale \\alpha_{opt} per questo parametro. Questo valore ottimale è dato da:\n\\qquad \\alpha_{opt} = \\frac{2}{\\lambda_1 + \\lambda_n}\ndove \\lambda_1 e \\lambda_n rappresentano rispettivamente l’autovalore massimo e l’autovalore minimo della matrice P^{-1}A.\nVelocità di Convergenza con \\alpha_{opt}\nSuccessivamente, abbiamo analizzato la velocità di convergenza raggiungibile quando il parametro \\alpha è scelto uguale al suo valore ottimale \\alpha_{opt}. La velocità di convergenza è determinata dal raggio spettrale \\rho(B(\\alpha)) della matrice di iterazione B(\\alpha) = I - \\alpha P^{-1}A. Gli autovalori di B(\\alpha) sono dati da 1 - \\alpha \\lambda_i, dove \\lambda_i sono gli autovalori di P^{-1}A. Pertanto, quando \\alpha = \\alpha_{opt}, il raggio spettrale \\rho(B(\\alpha_{opt})) è il massimo modulo degli autovalori 1 - \\alpha_{opt} \\lambda_i.\nConsiderando che gli autovalori \\lambda_i sono reali e positivi, il valore massimo di |1 - \\alpha_{opt} \\lambda_i| si ottiene per l’autovalore più piccolo \\lambda_n (poiché \\alpha_{opt} è positivo). Quindi, la velocità di convergenza è data da:\n\\qquad \\rho(B(\\alpha_{opt})) = |1 - \\alpha_{opt} \\lambda_n| = \\left|1 - \\frac{2}{\\lambda_1 + \\lambda_n} \\lambda_n\\right|\nSemplificando l’espressione:\n\\qquad \\rho(B(\\alpha_{opt})) = \\left|\\frac{\\lambda_1 + \\lambda_n - 2\\lambda_n}{\\lambda_1 + \\lambda_n}\\right| = \\left|\\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n}\\right|\nPoiché \\lambda_1 \\ge \\lambda_n &gt; 0, l’espressione è sempre non negativa, quindi:\n\\qquad \\rho(B(\\alpha_{opt})) = \\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n}\nQuesto risultato è importante perché ci permette di quantificare teoricamente la velocità di convergenza del metodo di Richardson stazionario precondizionato quando si utilizza il parametro ottimale \\alpha_{opt}, una volta che conosciamo gli autovalori estremi di P^{-1}A.\nCaso Particolare: P^{-1}A Simmetrica Definita Positiva (SDP)\nFacciamo ora un’osservazione importante: se la matrice P^{-1}A è simmetrica definita positiva (SDP), questo rappresenta un sottocaso particolare del teorema precedentemente enunciato, in quanto una matrice SDP ha tutti gli autovalori reali e positivi.\nIn questo caso, possiamo introdurre il concetto di numero di condizionamento rispetto alla norma spettrale 2, denotato come K_2(M) per una generica matrice M. Per una matrice SDP come P^{-1}A, il numero di condizionamento K_2(P^{-1}A) è dato dal rapporto tra l’autovalore massimo e l’autovalore minimo:\n\\qquad K_2(P^{-1}A) = \\frac{\\lambda_1}{\\lambda_n}\nUtilizzando questa definizione, possiamo riscrivere la velocità di convergenza \\rho(B(\\alpha_{opt})) in termini del numero di condizionamento di P^{-1}A:\n\\qquad \\rho(B(\\alpha_{opt})) = \\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n} = \\frac{\\frac{\\lambda_1}{\\lambda_n} - 1}{\\frac{\\lambda_1}{\\lambda_n} + 1} = \\frac{K_2(P^{-1}A) - 1}{K_2(P^{-1}A) + 1}\nQuesto risultato evidenzia un ruolo cruciale della matrice di precondizionamento P: oltre a dover essere invertibile e “facile” da usare, il suo compito principale è quello di migliorare il condizionamento della matrice A, ovvero rendere il numero di condizionamento K_2(P^{-1}A) il più piccolo possibile. Un valore di K_2(P^{-1}A) vicino a 1 implica una velocità di convergenza \\rho(B(\\alpha_{opt})) vicina a 0, che è desiderabile per una rapida convergenza.\nIl professore sottolinea che, a differenza della scelta del parametro \\alpha per cui esistono delle “ricette” anche in modalità dinamica, non esiste una ricetta ottimale universale per il precondizionatore P. La scelta del precondizionatore è spesso dipendente dal problema specifico.\nCaso di Richardson Stazionario Non Precondizionato\nConsideriamo ora il caso in cui non si utilizzi un precondizionatore, ovvero P = I. In questo scenario, il metodo di Richardson stazionario non precondizionato si applica direttamente alla matrice A.\nSupponiamo che la matrice A sia simmetrica definita positiva (SDP) e abbia autovalori reali e positivi 0 &lt; \\lambda_n \\le \\dots \\le \\lambda_1. In questo caso, il metodo di Richardson stazionario non precondizionato con un parametro \\alpha scelto opportunamente, ad esempio nell’intervallo (0, \\frac{2}{\\lambda_1}), converge.\nInoltre, si può derivare una stima per l’errore all’iterata k-esima, misurato nella norma A (o norma in energia) definita per un vettore z \\in \\mathbb{R}^n come |z|_A^2 = z^T A z. La stima è data da:\n\\qquad |e^{(k)}|_A \\le \\rho(B(\\alpha)) |e^{(k-1)}|_A\ndove e^{(k)} = x^* - x^{(k)} è l’errore all’iterata k-esima e B(\\alpha) = I - \\alpha A è la matrice di iterazione. Iterando questa relazione, si ottiene:\n\\qquad |e^{(k)}|_A \\le \\rho(B(\\alpha))^k |e^{(0)}|_A\nSe si sceglie il parametro ottimale per il caso non precondizionato, che è \\alpha_{opt} = \\frac{2}{\\lambda_1 + \\lambda_n} (analogamente al caso precondizionato ma applicato ad A invece di P^{-1}A), il raggio spettrale diventa:\n\\qquad \\rho(B(\\alpha_{opt})) = \\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n} = \\frac{K_2(A) - 1}{K_2(A) + 1}\ndove K_2(A) = \\frac{\\lambda_1}{\\lambda_n} è il numero di condizionamento di A rispetto alla norma 2.\nLa norma A è una norma dipendente dal problema (dalla matrice A) e rappresenta una sorta di “cambio di metrica” in cui la valutazione degli errori è adattata specificamente al sistema che stiamo risolvendo. Questa norma è anche detta norma in energia e trova applicazioni, ad esempio, nell’analisi di sistemi fisici come le strutture elastiche, dove è legata all’energia associata all’equilibrio del sistema.\nAlgoritmo di Richardson Stazionario Precondizionato\nIl professore ha quindi descritto i passaggi fondamentali dell’algoritmo di Richardson stazionario precondizionato:\nInput:\n\nGuess iniziale x_0.\nParametro di accelerazione \\alpha (idealmente \\alpha_{opt}).\nMatrice di precondizionamento P.\n\nPassaggi:\n\nCalcolare il residuo iniziale r_0 = b - Ax_0.\nIniziare un ciclo iterativo (ad esempio, un ciclo while basato su un criterio di convergenza).\nAd ogni iterazione k (partendo da k=0):\n\nRisolvere il sistema precondizionato Pz_k = r_k per ottenere il residuo precondizionato z_k.\nAggiornare la soluzione corrente: x_{k+1} = x_k + \\alpha z_k.\nAggiornare il residuo: r_{k+1} = b - Ax_{k+1}.\n\n\n\nPer l’aggiornamento del residuo, esiste una formula ricorsiva più efficiente dal punto di vista computazionale:\n\\qquad r_{k+1} = b - A(x_k + \\alpha z_k) = (b - Ax_k) - \\alpha Az_k = r_k - \\alpha Az_k\nQuindi, ad ogni iterazione, invece di ricalcolare b - Ax_{k+1} da zero, si aggiorna il residuo utilizzando il residuo precedente e il residuo precondizionato z_k moltiplicato per A e per -\\alpha.\nCosto Computazionale e Scelta tra Metodo Stazionario e Dinamico\nInfine, il professore ha discusso brevemente il costo computazionale associato alla scelta del parametro \\alpha ottimale nel metodo stazionario e ha introdotto una riflessione sul confronto con i metodi dinamici.\nMentre in un metodo stazionario il parametro \\alpha viene calcolato una sola volta, il calcolo di \\alpha_{opt} = \\frac{2}{\\lambda_1 + \\lambda_n} richiede la conoscenza (o l’approssimazione) degli autovalori massimo \\lambda_1 e minimo \\lambda_n della matrice P^{-1}A (o di A nel caso non precondizionato). Se la matrice A è di grandi dimensioni (ad esempio, 10000 \\times 10000), calcolare tutti gli autovalori sarebbe proibitivo.\nTuttavia, esistono metodi numerici specializzati per approssimare solo l’autovalore massimo e il corrispondente autovettore, o solo l’autovalore minimo e il corrispondente autovettore, senza dover calcolare l’intero spettro della matrice. Questo rende il calcolo (o l’approssimazione) di \\alpha_{opt} potenzialmente fattibile anche per problemi di grandi dimensioni.\nIl professore ha anticipato che nei metodi di Richardson dinamici, il parametro di accelerazione \\alpha (o \\alpha_k per indicare la sua dipendenza dall’iterazione k) viene aggiornato ad ogni iterazione. Sebbene questo approccio possa offrire una maggiore flessibilità nell’adattare il parametro all’evoluzione della soluzione, è necessario considerare il costo computazionale di questo aggiornamento ad ogni passo. Al momento, non sappiamo ancora quanto costerà calcolare \\alpha_k nel caso dinamico, ma è un aspetto importante da tenere in considerazione nel confronto tra i due approcci (stazionario e dinamico). La scelta tra un metodo stazionario con un \\alpha_{opt} calcolato una volta e un metodo dinamico con \\alpha_k variabile dipende quindi da diversi fattori, tra cui l’efficacia del metodo dinamico nel migliorare la convergenza e il costo computazionale associato all’aggiornamento del parametro.\n\nCertamente, ecco la spiegazione del professore riguardo alle flashcard, integrata con i passaggi matematici, gli esempi e i commenti, formattata come richiesto:\nMetodi Iterativi per la Risoluzione di Sistemi Lineari\nAlgoritmo di Richardson Stazionario Precondizionato\nIl professore inizia accennando all’algoritmo di Richardson stazionario precondizionato. L’aggiornamento del residuo avviene in un modo specifico, indicato nel testo con un “così”, la cui forma esatta non è riportata nell’estratto fornito.\nViene poi suggerita una possibile ottimizzazione: eseguire una volta per tutte la fattorizzazione LUD della matrice di precondizionamento P. In questo modo, il passaggio di risoluzione con P^{-1} si trasformerebbe in due schemi di sostituzioni in avanti e all’indietro, che sono computazionalmente più efficienti. Tuttavia, il professore specifica che questi sono dettagli più approfonditi e che per una comprensione di base è sufficiente considerare che ad ogni iterazione è presente un’operazione di risoluzione con la matrice di precondizionamento P.\nMetodo di Richardson Dinamico (Non Precondizionato)\nIl professore introduce quindi il metodo di Richardson dinamico partendo dal caso non precondizionato.\nSchema Iterativo\nLo schema iterativo generico per il metodo di Richardson dinamico non precondizionato è dato da:\nx_{k+1} = x_k + \\alpha_k z_k\ndove in questo caso, poiché non c’è precondizionamento (P = I, la matrice identità), si ha z_k = r_k, con r_k che rappresenta il residuo alla k-esima iterazione. Quindi lo schema diventa:\nx_{k+1} = x_k + \\alpha_k r_k\nQui, \\alpha_k è un parametro di accelerazione che può variare ad ogni iterazione (da cui “dinamico”).\nScelta Ottimale del Parametro \\alpha_k\nIl professore afferma che esiste una ricetta ottimale per il parametro \\alpha_k, che viene fornita come:\n\\alpha_k = \\frac{r_k^T r_k}{r_k^T A r_k}\ndove:\n\nr_k^T è il trasposto del residuo alla k-esima iterazione.\nr_k è il residuo alla k-esima iterazione (un vettore di dimensione n \\times 1).\nA è la matrice dei coefficienti del sistema lineare.\n\nIl numeratore r_k^T r_k è il prodotto scalare del residuo con se stesso (la norma euclidea al quadrato del residuo), che risulta essere un numero (dimensione 1 \\times n \\cdot n \\times 1 = 1 \\times 1).\nIl denominatore r_k^T A r_k è anch’esso un numero (dimensione 1 \\times n \\cdot n \\times n \\cdot n \\times 1 = 1 \\times 1).\nRelazione con il Metodo del Gradiente\nIl professore sottolinea che per questa scelta ottimale di \\alpha_k e in assenza di precondizionatore, il metodo di Richardson dinamico si identifica con un metodo molto noto in letteratura: il metodo del gradiente.\nIl metodo del gradiente è caratterizzato dall’avere come unica “carta da giocare” la scelta ottimale del parametro \\alpha. Questa scelta di \\alpha_k è quella che massimizza la velocità di convergenza del metodo.\nCosto Computazionale di \\alpha_k\nViene poi discussa la costosità del calcolo di \\alpha_k ad ogni iterazione. Il professore fa notare che, a differenza dell’\\alpha stazionario che richiedeva la stima di autovalori (come \\lambda_1 e \\lambda_n che potrebbero non essere facilmente accessibili), l’\\alpha_k ottimale dipende dal residuo r_k, che è una quantità già calcolata all’interno dell’algoritmo per definire l’aggiornamento x_{k+1}. Pertanto, il calcolo di \\alpha_k non introduce un costo computazionale aggiuntivo significativo, poiché le quantità necessarie sono già disponibili.\nInterpretazione Geometrica e Derivazione dell’\\alpha_k Ottimale: Connessione con l’Ottimizzazione\nPer fornire un’interpretazione geometrica del metodo del gradiente e per derivare l’espressione ottimale di \\alpha_k, il professore introduce un lemma di equivalenza.\nLemma di Equivalenza\nIl lemma si basa sull’ipotesi che la matrice dei coefficienti A sia simmetrica definita positiva (SDP). Questa è un’ipotesi fondamentale per la validità del metodo del gradiente nella sua forma standard.\nSotto questa ipotesi, il lemma afferma che risolvere il sistema lineare Ax = b è equivalente a risolvere un problema di minimo:\n\\min_{y \\in \\mathbb{R}^n} \\phi(y)\ndove \\phi(y) è la funzione energia del sistema, definita come una forma quadratica:\n\\phi(y) = \\frac{1}{2} y^T A y - y^T b\nLa soluzione x del sistema lineare è l’argomento che realizza il minimo di questa funzione, ovvero x = \\text{argmin}_{y} \\phi(y). In altre parole, il vettore x che risolve Ax = b è lo stesso vettore x che rende minima la funzione \\phi(y).\nInterpretazione Geometrica della Funzione Energia\n\nIn due dimensioni (se y = [y_1, y_2]^T), la funzione energia \\phi(y) rappresenta geometricamente un paraboloide, una superficie a forma di “scodella”. La soluzione x = [x_1, x_2]^T del sistema lineare corrisponde al punto di minimo di questa scodella.\nPer dimensioni superiori, la funzione energia è una generalizzazione di questo paraboloide in più dimensioni.\nGradiente della Funzione Energia\nIl professore calcola il gradiente della funzione energia \\phi(y):\n\\nabla \\phi(y) = \\frac{1}{2} (A + A^T) y - b\nSfruttando l’ipotesi che A è simmetrica (A^T = A), l’espressione si semplifica a:\n\\nabla \\phi(y) = A y - b\nIl professore fa notare che questa espressione è strettamente legata al residuo r = b - Ay. Infatti, \\nabla \\phi(y) = -(b - Ay) = -r.\nDimostrazione dell’Equivalenza\nViene dimostrata l’equivalenza tra la risoluzione del sistema lineare e la minimizzazione della funzione energia in entrambe le direzioni.\nDa Minimo a Soluzione (argmin \\implies Ax = b)\nSe x realizza il minimo di \\phi(y), allora il gradiente di f valutato in x deve essere nullo:\n\\nabla \\phi(x) = 0\nSostituendo l’espressione del gradiente, si ottiene:\nA x - b = 0\nDa cui:\nA x = b\nQuesto dimostra che se x minimizza \\phi(y), allora x è una soluzione del sistema lineare.\nDa Soluzione a Minimo (Ax = b \\implies argmin)\nPer dimostrare l’implicazione opposta, si considera l’espansione di Taylor di \\phi(x + y) intorno a x:\n\\phi(x + y) = \\phi(x) + \\nabla \\phi(x)^T y + \\frac{1}{2} y^T H_\\phi(x) y + \\text{termini di ordine superiore}\ndove H_\\phi(x) è la matrice Hessiana di f valutata in x. Per la funzione quadratica \\phi(y) = \\frac{1}{2} y^T A y - y^T b, la matrice Hessiana è semplicemente A. Quindi l’espansione si riduce a:\n\\phi(x + y) = \\phi(x) + \\nabla \\phi(x)^T y + \\frac{1}{2} y^T A y\nSe x è la soluzione del sistema Ax = b, allora \\nabla \\phi(x) = Ax - b = 0. Sostituendo questo nell’espansione di Taylor, si ottiene:\n\\phi(x + y) = \\phi(x) + 0^T y + \\frac{1}{2} y^T A y = \\phi(x) + \\frac{1}{2} y^T A y\nPoiché A è definita positiva, per ogni y \\neq 0, si ha y^T A y &gt; 0. Pertanto:\n\\phi(x + y) &gt; \\phi(x) \\quad \\text{per ogni } y \\neq 0\nQuesto dimostra che se x è la soluzione di Ax = b, allora x è il punto in cui la funzione energia \\phi(y) assume il suo valore minimo.\nInterpretazione Geometrica come Metodo di Discesa Ripida (Steepest Descent)\n\nIl professore utilizza l’analogia di una persona in montagna (la cui altitudine è rappresentata dalla funzione energia) con una fitta nebbia che vuole tornare alla macchina in fondo alla valle (il minimo della funzione energia, la soluzione del sistema). La posizione attuale è x_k, e si vuole determinare la prossima posizione x_{k+1}.\nLa strategia è di muoversi nella direzione di massima pendenza negativa (la discesa più ripida). La direzione di massima pendenza è data dal gradiente \\nabla \\phi(x_k), che punta nella direzione di aumento più rapido della funzione . Pertanto, la direzione di discesa più ripida è -\\nabla \\phi(x_k) .\nRicordando che \\nabla \\phi(x_k) = Ax_k - b = -r_k, la direzione di discesa \\delta(x_k) è data da :\n\\delta(x_k) = -\\nabla \\phi(x_k) = - (Ax_k - b) = b - Ax_k = r_k\nQuindi, nel metodo del gradiente, la direzione di movimento ad ogni iterazione è proprio il residuo .\nLa nuova posizione x_{k+1} sarà data da :\nx_{k+1} = x_k + \\gamma_k \\delta(x_k) = x_k + \\gamma_k r_k\ndove \\gamma_k è la lunghezza del passo da compiere lungo la direzione r_k . Questo \\gamma_k corrisponde al nostro \\alpha_k.\nScelta Ottimale della Lunghezza del Passo \\gamma_k\nPer trovare la lunghezza del passo ottimale \\gamma_k, si vuole minimizzare la funzione energia lungo la direzione di discesa . Si considera quindi la funzione g(\\gamma_k) = \\phi(x_k + \\gamma_k r_k), che rappresenta il valore della funzione energia spostandosi di un passo \\gamma_k nella direzione r_k a partire da x_k .\nUtilizzando l’espansione di Taylor di \\phi(x + y) con x = x_k e y = \\gamma_k r_k, si ottiene :\n\\phi(x_k + \\gamma_k r_k) = \\phi(x_k) + \\nabla \\phi(x_k)^T (\\gamma_k r_k) + \\frac{1}{2} (\\gamma_k r_k)^T A (\\gamma_k r_k)\ng(\\gamma_k) = \\phi(x_k) - r_k^T (\\gamma_k r_k) + \\frac{1}{2} \\gamma_k^2 r_k^T A r_k\ng(\\gamma_k) = \\phi(x_k) - \\gamma_k (r_k^T r_k) + \\frac{1}{2} \\gamma_k^2 (r_k^T A r_k)\nPer trovare il valore di \\gamma_k che minimizza g(\\gamma_k), si calcola la derivata di g rispetto a \\gamma_k e si pone uguale a zero :\ng&#039;(\\gamma_k) = -\\frac{d}{d\\gamma_k} (\\gamma_k (r_k^T r_k)) + \\frac{d}{d\\gamma_k} (\\frac{1}{2} \\gamma_k^2 (r_k^T A r_k))\ng&#039;(\\gamma_k) = -(r_k^T r_k) + \\gamma_k (r_k^T A r_k)\nImponendo g&#039;(\\gamma_k) = 0 per trovare il \\gamma_k ottimale (\\gamma_k^{opt}):\n-(r_k^T r_k) + \\gamma_k^{opt} (r_k^T A r_k) = 0\n\\gamma_k^{opt} (r_k^T A r_k) = r_k^T r_k\n\\gamma_k^{opt} = \\frac{r_k^T r_k}{r_k^T A r_k}\nQuesto \\gamma_k^{opt} è esattamente l’\\alpha_k ottimale derivato precedentemente per il metodo di Richardson dinamico . Questo conferma che il metodo del gradiente utilizza ad ogni passo la lunghezza del passo ottimale lungo la direzione del residuo (che è la direzione di discesa più ripida della funzione energia).\n\nConvergenza del Metodo del Gradiente Non Precondizionato\nIl professore introduce lo studio della convergenza del metodo del gradiente non precondizionato, sottolineando l’importanza dell’ipotesi che la matrice A sia simmetrica definita positiva (SDP). Applicare il metodo del gradiente a una matrice non SDP non è consentito.\nConfronto con Metodi Iterativi Classici (Jacobi e Gauss-Seidel)\nViene proposto un confronto tra il metodo del gradiente non precondizionato e i metodi di Jacobi e Gauss-Seidel su un sistema lineare piccolo:\n2x_1 + x_2 = 1 x_1 + 3x_2 = 0\nLa cui matrice è A = \\begin{pmatrix} 2 &amp; 1 \\\\ 1 &amp; 3 \\end{pmatrix}, che è SDP. La soluzione esatta è x = \\begin{pmatrix} 3/5 \\\\ -1/5 \\end{pmatrix}.\nSi discute l’andamento dell’errore  in scala logaritmica rispetto al numero di iterazioni per i tre metodi. L’obiettivo è confrontare la velocità di convergenza.\nVelocità di Convergenza Empirica\n\nSi prevede che, per questo sistema, il gradiente converga più rapidamente di Gauss-Seidel, che a sua volta converga più rapidamente di Jacobi. Questo si visualizza concettualmente con grafici dell’accuratezza (es. 10^{-qualcosa}) in funzione del numero di iterazioni. Curve più ripide indicano una convergenza più rapida.\n\nJacobi: Convergenza più lenta (retta meno inclinata nel grafico concettuale).\nGauss-Seidel: Convergenza intermedia (retta con inclinazione maggiore di Jacobi).\nGradiente: Convergenza più rapida (retta con inclinazione maggiore di Gauss-Seidel).\n\nQuesti grafici possono essere usati per:\n\nFissare un’accuratezza e determinare il numero di iterazioni richieste da ciascun metodo.\nFissare un numero di iterazioni e confrontare l’accuratezza ottenuta da ciascun metodo.\n\nIl professore menziona che il grafico corretto è disponibile sul libro e sottolinea l’importanza di usare una scala logaritmica per visualizzare l’ordine di convergenza come l’inclinazione della retta.\nVerifica della Convergenza\nPer verificare formalmente la convergenza, si confronta il valore della funzione obiettivo \\phi(x) all’iterata k+1 con quella all’iterata k. Si desidera che \\phi(x_{k+1}) &lt; \\phi(x_k), indicando che ci si sta muovendo verso il minimo.\nPartendo da x_{k+1} = x_k + \\alpha_k r_k (notare il segno positivo qui, il professore usa + \\alpha_k r_k nel derivare, considerando r_k = b - Ax_k, quindi la direzione di ricerca è r_k), e sostituendo l’espressione per \\alpha_k ottimo, si ottiene:\n\\phi(x_{k+1}) = \\phi(x_k) - \\alpha_k |r_k|_2^2 + \\frac{1}{2} \\alpha_k^2 r_k^T A r_k\nSostituendo \\alpha_k = \\frac{r_k^T r_k}{r_k^T A r_k} = \\frac{|r_k|_2^2}{r_k^T A r_k}:\n\\phi(x_{k+1}) = \\phi(x_k) - \\frac{|r_k|_2^4}{r_k^T A r_k} + \\frac{1}{2} \\left(\\frac{|r_k|_2^2}{r_k^T A r_k}\\right)^2 r_k^T A r_k\n\\phi(x_{k+1}) = \\phi(x_k) - \\frac{|r_k|_2^4}{r_k^T A r_k} + \\frac{1}{2} \\frac{|r_k|_2^4}{(r_k^T A r_k)^2} r_k^T A r_k\n\\phi(x_{k+1}) = \\phi(x_k) - \\frac{|r_k|_2^4}{r_k^T A r_k} + \\frac{1}{2} \\frac{|r_k|_2^4}{r_k^T A r_k}\n\\phi(x_{k+1}) = \\phi(x_k) - \\frac{1}{2} \\frac{|r_k|_2^4}{r_k^T A r_k}\nPoiché A è SDP, r_k^T A r_k &gt; 0 per r_k \\neq 0, e |r_k|_2^4 \\ge 0. Pertanto, \\phi(x_{k+1}) \\le \\phi(x_k), e se r_k \\neq 0, allora \\phi(x_{k+1}) &lt; \\phi(x_k), dimostrando che il valore della funzione obiettivo diminuisce ad ogni iterazione, indicando la convergenza verso il minimo.\nTasso di Convergenza\nIl teorema sulla convergenza del gradiente non precondizionato stabilisce una relazione tra l’errore all’iterata k+1 e l’errore all’iterata k, misurati nella norma in energia |e|_A = \\sqrt{e^T A e}, dove e = x - x^k è l’errore e x^k è la soluzione esatta:\n|e_{k+1}|_A^2 \\le \\left( \\frac{\\kappa(A) - 1}{\\kappa(A) + 1} \\right)^2 |e_k|_A^2\ndove \\kappa(A) = \\frac{\\lambda_{max}(A)}{\\lambda_{min}(A)} è il numero di condizionamento della matrice A. Un numero di condizionamento elevato può portare a una convergenza lenta, e in questo caso, non ci sono gradi di libertà per migliorare la situazione nel metodo del gradiente non precondizionato, poiché il passo \\alpha_k è scelto in modo ottimale.\nIl Metodo del Gradiente Precondizionato\nPer accelerare la convergenza, specialmente quando la matrice A ha un elevato numero di condizionamento, si introduce il precondizionamento. L’idea è di trasformare il sistema originale Ax = b in un sistema equivalente con una matrice il cui numero di condizionamento sia più piccolo.\nAlgoritmo del Gradiente Precondizionato\nL’algoritmo del gradiente precondizionato, con un precondizionatore P (simmetrico e definito positivo), procede come segue:\n\nScegli un punto iniziale x_0.\nCalcola il residuo iniziale r_0 = b - Ax_0.\nPer k = 0, 1, 2, \\dots fino a convergenza: a. Risolvi il sistema precondizionato P z_k = r_k per z_k. b. Calcola il passo ottimale \\alpha_k^{pre} (diverso dall’\\alpha_k non precondizionato): \\alpha_k^{pre} = \\frac{z_k^T r_k}{z_k^T A z_k} c. Aggiorna la soluzione: x_{k+1} = x_k + \\alpha_k^{pre} z_k d. Aggiorna il residuo: r_{k+1} = r_k - \\alpha_k^{pre} A z_k\n\nIl professore sottolinea che se il precondizionatore P fosse la matrice identità I, l’algoritmo si ridurrebbe al metodo del gradiente non precondizionato. Inoltre, questo algoritmo generalizza anche il metodo di Richardson stazionario, precondizionato e non precondizionato, a seconda di come viene scelto e utilizzato \\alpha (se costante o variabile) e se P è l’identità o un altro precondizionatore.\nTasso di Convergenza del Gradiente Precondizionato\nIl teorema sulla convergenza del gradiente precondizionato afferma che:\n|e_{k+1}|_{A}^2 \\le \\left( \\frac{\\kappa(P^{-1}A) - 1}{\\kappa(P^{-1}A) + 1} \\right)^2 |e_k|_{A}^2\ndove \\kappa(P^{-1}A) è il numero di condizionamento della matrice precondizionata P^{-1}A. La scelta di un buon precondizionatore P mira a ridurre \\kappa(P^{-1}A), migliorando così il tasso di convergenza.\nOsservazioni Finali\nIl professore conclude suggerendo di utilizzare sempre valori ottimali per i parametri (come \\alpha_k) e di attivare un precondizionatore quando possibile per migliorare l’efficienza dei metodi iterativi.\nReferences\nAppunti Mate Num- lez08.pdf"},"6--full-note/mateNum--Lez10":{"slug":"6--full-note/mateNum--Lez10","filePath":"6- full note/mateNum- Lez10.md","title":"mateNum- Lez10","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","2--source-materials/Appunti-Mate-Num-1--lez10.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-11 12:46\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine matematica numerica\nmateNum- Lez10\nSpiegazione del Metodo del Gradiente e Introduzione al Gradiente Coniugato\nRicapitolo della Lezione Precedente: Metodo del Gradiente\nIl professore inizia la lezione riprendendo i concetti fondamentali del metodo del gradiente, distinguendo tra la versione non precondizionata e quella precondizionata. L’obiettivo odierno è concludere la discussione sui metodi iterativi, in particolare introducendo il metodo del gradiente coniugato. Viene sottolineata l’importanza dei due “mattoni” del corso: i sistemi (già in discussione) e le questioni di differenza nominale (come ultimo argomento). Il prossimo argomento sarà più “soft”.\nMetodo del Gradiente Non Precondizionato\nIl professore riassume l’algoritmo del metodo del gradiente non precondizionato:\nInput: Guess iniziale x_0.\nInizializzazione: Calcolo del residuo iniziale R_0 = b - A x_0.\nIterazione (ciclo): Per k = 0, 1, 2, \\dots:\n\nCalcolo del parametro di discesa \\alpha_k: \\qquad \\alpha_k = \\frac{R_k^T R_k}{R_k^T A R_k} = \\frac{||R_k||_2^2}{R_k^T A R_k} Viene spiegato che \\alpha_k viene aggiornato ad ogni iterazione poiché il gradiente è un esempio di .\nAggiornamento dell’iterata: \\qquad x_{k+1} = x_k + \\alpha_k R_k La nuova iterata è ottenuta correggendo quella precedente nella direzione del residuo.\nAggiornamento del residuo: \\qquad R_{k+1} = R_k - \\alpha_k A R_k Si nota che anche il residuo viene aggiornato ad ogni iterazione.\n\nViene sottolineato che la richiesta fondamentale per l’applicazione di questo metodo è che la matrice A sia simmetrica e definita positiva. Si accenna alla possibilità che questo algoritmo venga implementato in laboratorio.\nMetodo del Gradiente Precondizionato\nIl professore introduce poi la versione precondizionata del metodo del gradiente:\nInput: Guess iniziale x_0, precondizionatore P (opportunamente scelto).\nInizializzazione: Calcolo del residuo iniziale R_0 = b - A x_0.\nIterazione (ciclo): Per k = 0, 1, 2, \\dots:\n\nCalcolo del residuo precondizionato Z_k: \\qquad P Z_k = R_k Questo passaggio implica la risoluzione di un sistema lineare con il precondizionatore P.\nCalcolo del parametro di discesa \\alpha_k: \\qquad \\alpha_k = \\frac{Z_k^T R_k}{Z_k^T A Z_k} In questo caso, il peso \\alpha_k dipende anche dal residuo precondizionato Z_k.\nAggiornamento dell’iterata: \\qquad x_{k+1} = x_k + \\alpha_k Z_k La correzione all’iterata precedente avviene nella direzione del residuo precondizionato Z_k.\nAggiornamento del residuo: \\qquad R_{k+1} = R_k - \\alpha_k A Z_k\n\nLa vera novità del metodo precondizionato è il calcolo del residuo precondizionato Z_k, che introduce uno step aggiuntivo rispetto alla versione non precondizionata.\nOsservazioni sul Metodo del Gradiente Non Precondizionato\nIl professore si concentra ora sulla versione non precondizionata del gradiente, evidenziando due osservazioni fondamentali che motiveranno l’introduzione del metodo del gradiente coniugato.\nOrtogonalità dei Residui Consecutivi\nAffermazione: Due residui relativi consecutivi, R_k e R_{k+1}, sono tra loro ortogonali. Questo significa che il loro prodotto scalare è zero: \\qquad R_{k+1}^T R_k = 0\nVerifica: Il professore procede con la dimostrazione di questa proprietà:\nPartiamo dalla definizione del residuo al passo k+1: \\qquad R_{k+1} = b - A x_{k+1}\nSostituiamo l’espressione per x_{k+1}: \\qquad R_{k+1} = b - A (x_k + \\alpha_k R_k) \\qquad R_{k+1} = (b - A x_k) - \\alpha_k A R_k\nRiconosciamo che b - A x_k è il residuo R_k: \\qquad R_{k+1} = R_k - \\alpha_k A R_k\nOra calcoliamo il prodotto scalare di R_{k+1} con R_k: \\qquad R_k^T R_{k+1} = R_k^T (R_k - \\alpha_k A R_k) \\qquad R_k^T R_{k+1} = R_k^T R_k - \\alpha_k R_k^T A R_k\nSostituiamo l’espressione di \\alpha_k che abbiamo precedentemente derivato: \\qquad R_k^T R_{k+1} = R_k^T R_k - \\left( \\frac{R_k^T R_k}{R_k^T A R_k} \\right) R_k^T A R_k\nOsservando che R_k^T A R_k è uno scalare (così come R_k^T R_k), possiamo semplificare: \\qquad R_k^T R_{k+1} = R_k^T R_k - R_k^T R_k = 0\nQuesto dimostra che R_k e R_{k+1} sono ortogonali.\nImplicazioni: Questa proprietà vale solo tra due residui consecutivi. In generale, R_{k+1} non è ortogonale a R_{k-1}, R_{k-2}, ecc.. Tuttavia, se consideriamo l’intera sequenza dei residui, si formano due famiglie di vettori ortogonali tra loro: tutti i residui con indice pari sono ortogonali tra loro, e tutti i residui con indice dispari sono ortogonali tra loro. All’interno di ciascuna famiglia (pari o dispari), i vettori risultano essere paralleli. Il professore precisa che questa osservazione è valida in un contesto ideale senza errori di floating point.\nInterpretazione Geometrica\n\nIl professore fornisce un’interpretazione geometrica del metodo del gradiente non precondizionato. La funzione obiettivo \\phi(x) = \\frac{1}{2}x^T A x - b^T x (il cui minimo è la soluzione di Ax=b) ha superfici di livello che sono ellissoidi concentrici in \\mathbb{R}^n (paraboloidi se visualizzati in \\mathbb{R}^{n+1}).\nIl segmento che unisce due approssimazioni consecutive, x_k e x_{k+1}, è tangente all’ellissoide che passa per il punto x_{k+1} e definito dall’insieme dei punti x tali che \\phi(x) = \\phi(x_{k+1}).\nIl gradiente, R_k = b - A x_k = -\\nabla \\phi(x_k), è sempre perpendicolare alle curve di livello nel punto x_k. Quindi, il metodo del gradiente si muove lungo direzioni ortogonali (i residui consecutivi) nel tentativo di raggiungere il centro del paraboloide, che rappresenta il minimo della funzione e quindi la soluzione del sistema lineare.\nIl professore illustra ulteriormente questo concetto considerando un caso semplice con una matrice A diagonale 2 \\times 2, A = \\begin{pmatrix} \\lambda_1 &amp; 0 \\\\ 0 &amp; \\lambda_2 \\end{pmatrix}. In questo caso, la funzione \\phi(x) definisce un ellissoide le cui lunghezze dei semiassi sono inversamente proporzionali a \\lambda_1 e \\lambda_2.\nSe l’ellissoide è molto “schiacciato” (alta eccentricità), il percorso a zig-zag compiuto dal metodo del gradiente per raggiungere il centro diventa più lungo, richiedendo un maggior numero di iterazioni. Al contrario, se l’ellissoide è simile a un cerchio, il metodo del gradiente converge più rapidamente, idealmente in una sola iterazione se fosse un cerchio perfetto partendo dal centro.\nQuesta osservazione è il punto di partenza per l’introduzione del metodo del gradiente coniugato.\nIntroduzione al Metodo del Gradiente Coniugato\nMotivazione\nIl metodo del gradiente classico utilizza come direzione di discesa il residuo R_k, che corrisponde alla direzione di massima discesa locale. Il professore si chiede se sia possibile migliorare la velocità di convergenza sostituendo questa direzione di discesa con una nuova direzione, che viene battezzata P_k. L’obiettivo è trovare una sequenza di direzioni di discesa {P_k} che permettano di raggiungere la soluzione in un numero finito di iterazioni (al massimo n, la dimensione del sistema) in assenza di errori di arrotondamento.\nDefinizione di Direzioni A-Coniugate\nPrima di presentare l’algoritmo del gradiente coniugato, è necessario definire il concetto di direzioni A-coniugate.\nUn insieme di l+1 vettori \\set{P_0, P_1, \\dots, P_l} in \\mathbb{R}^n definiscono direzioni A-coniugate rispetto alla matrice A (simmetrica e definita positiva) se soddisfano la seguente proprietà: \\qquad P_i^T A P_j = 0 \\quad \\text{per } i \\neq j\nSi osserva che se A fosse la matrice identità I, la definizione di A-coniugate si ridurrebbe alla definizione classica di ortogonalità (P_i^T P_j = 0 per i \\neq j). Quindi, la coniugatezza rispetto ad A introduce la struttura del problema nel concetto di ortogonalità.\nQuesto concetto è strettamente legato alla definizione di norma A, ||x||_A = \\sqrt{x^T A x}, e al prodotto scalare indotto da A, \\langle x, y \\rangle_A = x^T A y. Dire che due vettori sono A-coniugati significa che sono ortogonali rispetto a questo nuovo prodotto scalare. Questo può essere interpretato come un cambio di metrica.\nIl professore accenna a una domanda riguardante la consistenza del metodo quando si sostituisce R_k con P_k, rimandando la discussione a un momento successivo.\nProprietà delle Direzioni A-Coniugate\nSe si ha un insieme di n direzioni A-coniugate \\set{P_0, P_1, \\dots, P_{n-1}} in \\mathbb{R}^n, allora questo insieme forma una base per \\mathbb{R}^n.\nPer dimostrare che formano una base, è sufficiente dimostrare che questi vettori sono linearmente indipendenti. Il professore inizia la dimostrazione considerando una combinazione lineare di questi vettori uguale al vettore nullo: \\qquad a_0 P_0 + a_1 P_1 + \\dots + a_{n-1} P_{n-1} = 0\nL’obiettivo è dimostrare che tutti i coefficienti a_i devono essere nulli.\n\nMetodo del Gradiente Coniugato\n1. Definizione e Indipendenza Lineare delle Direzioni Accumulate\nDimostrazione della Loro Indipendenza Lineare:\nPer dimostrare che queste n direzioni accumulate formano una base di \\mathbb{R}^n, è necessario dimostrare la loro indipendenza lineare. Si imposta una combinazione lineare di queste direzioni uguale al vettore nullo:\na_0 p_0 + a_1 p_1 + ... + a_{n-1} p_{n-1} = 0\nL’obiettivo è dimostrare che tutti i coefficienti a_i devono essere necessariamente nulli.\nPasso 1: Moltiplicazione per p_0^T A\nSi moltiplica l’intera combinazione lineare a sinistra per p_0^T A:\np_0^T A (a_0 p_0 + a_1 p_1 + ... + a_{n-1} p_{n-1}) = p_0^T A \\cdot 0\nDistribuendo p_0^T A all’interno della parentesi, si ottiene:\na_0 (p_0^T A p_0) + a_1 (p_0^T A p_1) + ... + a_{n-1} (p_0^T A p_{n-1}) = 0\nSecondo la definizione di direzioni accumulate, per i \\neq 0, si ha p_0^T A p_i = 0. Pertanto, tutti i termini successivi al primo si annullano:\na_0 (p_0^T A p_0) = 0\nLa quantità p_0^T A p_0 è strettamente positiva poiché A è definita positiva. Affinché il prodotto a_0 (p_0^T A p_0) sia zero, l’unica possibilità è che a_0 = 0.\nPasso 2: Generalizzazione per gli Altri Coefficienti\nPer dimostrare che anche a_1 = 0, si moltiplica la combinazione lineare iniziale per p_1^T A:\np_1^T A (a_0 p_0 + a_1 p_1 + ... + a_{n-1} p_{n-1}) = p_1^T A \\cdot 0\nDistribuendo, si ha:\na_0 (p_1^T A p_0) + a_1 (p_1^T A p_1) + ... + a_{n-1} (p_1^T A p_{n-1}) = 0\nPer la proprietà delle direzioni accumulate, p_1^T A p_i = 0 per i \\neq 1. Quindi tutti i termini tranne quello con a_1 si annullano:\na_1 (p_1^T A p_1) = 0\nAnche in questo caso, p_1^T A p_1 &gt; 0 (perché A è definita positiva), il che implica che a_1 = 0.\nQuesto processo si ripete per tutti i coefficienti a_i. Moltiplicando la combinazione lineare per p_i^T A, si dimostra che a_i = 0 per ogni i = 0, 1, ..., n-1. Poiché tutti i coefficienti della combinazione lineare sono nulli, le direzioni accumulate p_0, p_1, ..., p_{n-1} sono linearmente indipendenti e formano quindi una base di \\mathbb{R}^n.\n2. Algoritmo del Gradiente Coniugato\nL’algoritmo del gradiente coniugato viene introdotto definendo i suoi passi fondamentali.\nInizializzazione:\n\nSi sceglie un punto iniziale x_0.\nSi calcola il residuo iniziale r_0 = b - A x_0.\nSi inizializza la prima direzione di discesa p_0 uguale al residuo iniziale: p_0 = r_0.\nSi imposta il contatore dell’iterazione k = 0.\n\nIterazione (fino a convergenza):\n\n\nCalcolo del parametro di accelerazione \\alpha_k: \\alpha_k = \\frac{p_k^T r_k}{p_k^T A p_k}\n\n\nAggiornamento della soluzione: x_{k+1} = x_k + \\alpha_k p_k\n\n\nAggiornamento del residuo: r_{k+1} = r_k - \\alpha_k A p_k\n\n\nCalcolo del coefficiente \\beta_k: \\beta_k = \\frac{p_k^T A r_{k+1}}{p_k^T A p_k} oppure \\beta_k = \\frac{r_{k+1}^T A p_k}{p_k^T A p_k} (essendo A simmetrica)\n\n\nAggiornamento della direzione di discesa: p_{k+1} = r_{k+1} - \\beta_k p_k\n\n\nSi incrementa il contatore: k = k + 1.\n\n\nL’algoritmo continua fino a quando un criterio di convergenza (ad esempio, la norma del residuo è sufficientemente piccola) viene soddisfatto.\n3. Giustificazione delle Formule\n4. Proprietà del Metodo del Gradiente Coniugato*\nMANCAA\n\n4.1 Proprietà 1: Ortogonalità dei Residui rispetto alle Direzioni Precedenti\nSi può dimostrare che il nuovo residuo r_{k+1} è ortogonale alla precedente direzione di discesa p_k:\np_k^T r_{k+1} = 0\nVerifica per p_k^T r_{k+1} = 0:\nSi parte dalla definizione di r_{k+1}:\nr_{k+1} = r_k - \\alpha_k A p_k\nSi moltiplica a sinistra per p_k^T:\np_k^T r_{k+1} = p_k^T r_k - \\alpha_k p_k^T A p_k\nSi sostituisce l’espressione di \\alpha_k:\np_k^T r_{k+1} = p_k^T r_k - \\left( \\frac{p_k^T r_k}{p_k^T A p_k} \\right) p_k^T A p_k p_k^T r_{k+1} = p_k^T r_k - p_k^T r_k = 0\nProcedendo per induzione, si può verificare che il residuo r_{k+1} non è solo ortogonale a p_k, ma a tutte le direzioni precedenti p_i per i = 0, 1, ..., k:\np_i^T r_{k+1} = 0, per i = 0, ..., k\n4.2 Proprietà 2: A-Ortogonalità delle Direzioni di Discesa\nPer costruzione (attraverso la scelta di \\beta_k), la nuova direzione di discesa p_{k+1} è A-ortogonale alla precedente direzione p_k:\np_k^T A p_{k+1} = 0\nCome accennato nella giustificazione di \\beta_k, questa condizione è imposta per derivare il valore di \\beta_k. Procedendo per induzione, si può dimostrare che tutte le direzioni di discesa sono mutuamente A-ortogonali:\np_j^T A p_{k+1} = 0, per j = 0, ..., k\nQuesta proprietà di A-ortogonalità delle direzioni di discesa è fondamentale per la convergenza efficiente del metodo del gradiente coniugato.\n3.1 Giustificazione di \\alpha_k\nLa formula per \\alpha_k è derivata minimizzando la funzione obiettivo quadratica lungo la direzione di ricerca p_k a partire dal punto x_k. La funzione obiettivo ha la forma di un paraboloide.\nSi definisce una funzione G(\\alpha) = \\phi(x_k + \\alpha p_k), dove \\phi(x) = \\frac{1}{2} x^T A x - b^T x è la funzione da minimizzare. Utilizzando l’espansione di Taylor di \\phi intorno a x_k, si ottiene:\nG(\\alpha) = \\phi(x_k) + \\nabla \\phi(x_k)^T (\\alpha p_k) + \\frac{1}{2} (\\alpha p_k)^T H\\phi(x_k) (\\alpha p_k) + ...\nDove \\nabla \\phi(x) = Ax - b = -r(x) e H\\phi(x) = A. Quindi:\nG(\\alpha) = \\phi(x_k) + (-r_k)^T (\\alpha p_k) + \\frac{1}{2} (\\alpha p_k)^T A (\\alpha p_k) G(\\alpha) = \\phi(x_k) - \\alpha r_k^T p_k + \\frac{1}{2} \\alpha^2 p_k^T A p_k\nPer trovare il valore di \\alpha = \\alpha_k che minimizza G(\\alpha), si calcola la derivata prima rispetto ad \\alpha e si impone che sia uguale a zero:\nG&#039;(\\alpha) = -r_k^T p_k + \\alpha p_k^T A p_k = 0\nRisolvendo per \\alpha, si ottiene la formula per \\alpha_k:\n\\alpha_k = \\frac{r_k^T p_k}{p_k^T A p_k} = \\frac{p_k^T r_k}{p_k^T A p_k}\nQuesta scelta di \\alpha_k garantisce che ci si muova lungo la direzione p_k fino al punto in cui la funzione obiettivo è minimizzata in quella direzione.\nMANCAAAAA\n\n3.2 Giustificazione di \\beta_k (no)\nIl coefficiente \\beta_k è scelto in modo da garantire che la nuova direzione di discesa p_{k+1} sia A-ortogonale a tutte le direzioni di discesa precedenti p_0, p_1, ..., p_k. In particolare, si impone la condizione di A-ortogonalità tra p_{k+1} e p_k:\np_k^T A p_{k+1} = 0\nSi assume che la nuova direzione p_{k+1} sia una combinazione lineare del nuovo residuo r_{k+1} e della vecchia direzione p_k:\np_{k+1} = r_{k+1} - \\beta_k p_k (seguendo il testo)\nSostituendo questa espressione nella condizione di A-ortogonalità:\np_k^T A (r_{k+1} - \\beta_k p_k) = 0 p_k^T A r_{k+1} - \\beta_k p_k^T A p_k = 0\nRisolvendo per \\beta_k, si ottiene:\n\\beta_k = \\frac{p_k^T A r_{k+1}}{p_k^T A p_k}\n\nMetodo del Gradiente Coniugato\nTeorema di Convergenza del Gradiente Coniugato\nIl professore introduce un teorema fondamentale che sottolinea la potenza del metodo del gradiente coniugato.\nIl teorema afferma che il gradiente coniugato converge alla soluzione esatta in al più n iterazioni, dove n è l’ordine del sistema lineare da risolvere.\nQuesto risultato è notevole perché trasforma un metodo iterativo in qualcosa che assomiglia a un metodo diretto, in quanto il numero massimo di iterazioni necessarie per la convergenza è finito e noto a priori. Non è necessario implementare criteri di stopping basati su una tolleranza, poiché la convergenza è garantita entro n passi. Tuttavia, il professore anticipa che su spazi di Hilbert si osserverà una convergenza ancora più rapida, richiedendo molte meno di n iterazioni.\nStima dell’Errore e Fattore di Convergenza (Non Precondizionato)\nViene presentata una stima non rigorosa ma intuitiva per l’errore associato all’iterata k-esima. L’errore nella norma A, indicata come ||e_k||_A, può essere controllato rispetto alla norma A dell’errore iniziale ||e_0||_A con un fattore che guida la velocità di convergenza.\nPer il metodo del gradiente semplice, il fattore di convergenza che lega due iterazioni consecutive, quando iterato k volte, porta a controllare l’errore come:\n||e_k||_A \\le \\left( \\frac{\\kappa_2(A) - 1}{\\kappa_2(A) + 1} \\right)^k ||e_0||_A\n\ndove \\kappa_2(A) è il condizionamento della matrice A in norma 2. Il professore sottolinea che se il condizionamento \\kappa_2(A) è grande, la convergenza del gradiente semplice può essere molto lenta.\nPer il gradiente coniugato non precondizionato, il fattore di convergenza è diverso e migliora la situazione:\n\\frac{||e_k||_A}{||e_0||_A} \\le 2 \\left( \\frac{\\sqrt{\\kappa_2(A)} - 1}{\\sqrt{\\kappa_2(A)} + 1} \\right)^k = 2 \\left( \\frac{c}{1 + c} \\right)^{2k}, dove c = \\frac{\\sqrt{\\kappa_2(A)} - 1}{\\sqrt{\\kappa_2(A)} + 1}.\nIl professore evidenzia come la radice quadrata del numero di condizionamento nel fattore di convergenza del gradiente coniugato (non precondizionato) rappresenti un miglioramento significativo rispetto al gradiente semplice. Ad esempio, se \\kappa_2(A) = 10^4, la radice diventa 10^2, riducendo notevolmente l’impatto del malcondizionamento.\nGiustificazione delle n Iterazioni\nIl professore fornisce una spiegazione intuitiva del perché il gradiente coniugato converge in al più n iterazioni, basandosi sulle proprietà delle direzioni di discesa e dei residui.\nOrtogonalità delle Direzioni di Discesa\nLe prime n direzioni di discesa p_0, p_1, ..., p_{n-1} generate dal metodo del gradiente coniugato sono A-ortogonali (o coniugate). Questa proprietà (proprietà 2 menzionata dal professore) implica che queste n direzioni formano una base per \\mathbb{R}^n.\nOrtogonalità del Residuo\nIl residuo all’iterazione l, r_l, è ortogonale a tutte le direzioni di discesa precedenti, p_0, p_1, ..., p_{l-1} (proprietà 1 menzionata dal professore).\nConvergenza in n Passi\nConsiderando il residuo all’iterazione n, r_n, per la proprietà 1, esso deve essere ortogonale a tutte le n direzioni di discesa p_0, p_1, ..., p_{n-1}. Poiché queste direzioni formano una base per \\mathbb{R}^n, l’unico vettore ortogonale a tutti i vettori di una base è il vettore nullo.\nPertanto, r_n = 0, il che implica che x_n è la soluzione esatta (x) del sistema lineare Ax = b. Il professore precisa che potrebbe accadere che il residuo diventi nullo anche prima di n iterazioni, quindi n rappresenta uno scenario “peggiore”.\nDimostrazione Alternativa\nSe non si è convinti, si può esprimere r_n come combinazione lineare delle direzioni di discesa:\nr_n = c_0 p_0 + c_1 p_1 + ... + c_{n-1} p_{n-1}\nAndando a calcolare il prodotto scalare di r_n con ciascuna direzione p_i e sfruttando la proprietà di ortogonalità tra il residuo r_i e le direzioni precedenti, si dimostra che tutti i coefficienti c_i devono essere zero, confermando che r_n è il vettore nullo.\nMetodo del Gradiente Coniugato Precondizionato\nIl professore introduce la variante precondizionata del metodo del gradiente coniugato, utile per accelerare la convergenza, specialmente in caso di sistemi mal condizionati. Si assume che la matrice A sia simmetrica e definita positiva.\nAlgoritmo\n\nCalcolo del residuo iniziale: r_0 = b - Ax_0.\nCalcolo del residuo precondizionato iniziale: Risolvere Mz_0 = r_0 per z_0, dove M è la matrice di precondizionamento.\nScelta della prima direzione di discesa: p_0 = z_0 (anziché r_0).\nIterazioni per k = 0, 1, ...:\n\nCalcolo del passo \\alpha_k: \\alpha_k = \\frac{r_k^T z_k}{p_k^T A p_k}.\nAggiornamento della soluzione: x_{k+1} = x_k + \\alpha_k p_k.\nAggiornamento del residuo: r_{k+1} = r_k - \\alpha_k A p_k.\nCalcolo del nuovo residuo precondizionato: Risolvere Mz_{k+1} = r_{k+1} per z_{k+1}.\nCalcolo del coefficiente \\beta_k: \\beta_k = \\frac{p_k^T A z_{k+1}}{p_k^T A p_k} (formula modificata rispetto al non precondizionato).\nAggiornamento della direzione di discesa: p_{k+1} = z_{k+1} - \\beta_k p_k (formula modificata rispetto al non precondizionato, utilizza z_{k+1} invece di r_{k+1}).\n\n\n\nStima dell’Errore e Fattore di Convergenza (Precondizionato)\nSISTEMARE\n\nAnche per il metodo precondizionato, l’errore associato all’iterata k-esima in norma A può essere confrontato con l’errore iniziale tramite un fattore di convergenza:\n\\frac{||e_k||_A}{||e_0||_A} \\le 2 \\left( \\frac{\\sqrt{\\kappa_2(M^{-1}A)} - 1}{\\sqrt{\\kappa_2(M^{-1}A)} + 1} \\right)^k = 2 \\left( \\frac{\\tilde{c}}{1 + \\tilde{c}} \\right)^{2k}, dove \\tilde{c} = \\frac{\\sqrt{\\kappa_2(M^{-1}A)} - 1}{\\sqrt{\\kappa_2(M^{-1}A)} + 1}.\nIl professore sottolinea come il numero di condizionamento della matrice precondizionata M^{-1}A, \\kappa_2(M^{-1}A), influenzi la velocità di convergenza. Una buona scelta della matrice di precondizionamento M può significativamente ridurre questo numero di condizionamento, accelerando la convergenza.\nApplicazione alla Matrice di Hilbert (Inverta)\nIl professore passa a considerare la risoluzione di un sistema lineare Ax = b dove A è la matrice di Hilbert, nota per essere simmetrica definita positiva e mal condizionata. La matrice di Hilbert H_n ha elementi H_{ij} = \\frac{1}{i+j-1}.\nCondizionamento della Matrice di Hilbert\nViene mostrato come il numero di condizionamento della matrice di Hilbert cresca rapidamente con la dimensione n del sistema:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimensione nNumero di Condizionamento \\kappa_2(A)4\\mathcal{O}(10^4)6\\mathcal{O}(10^6)8\\mathcal{O}(10^8)10\\mathcal{O}(10^{11})12\\mathcal{O}(10^{14})14\\mathcal{O}(10^{17})\nQuesta rapida crescita del condizionamento suggerisce che la risoluzione di sistemi con la matrice di Hilbert può essere problematica, specialmente per metodi diretti.\nRisultati con il Metodo Diretto (Slash in Matlab)\nUtilizzando un metodo diretto (rappresentato dal comando “slash” in Matlab), si osservano i seguenti errori nella soluzione:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimensione nErrore Metodo Diretto4\\mathcal{O}(10^{-13})6\\mathcal{O}(10^{-10})14\\mathcal{O}(10^{1})\nI risultati mostrano una rapida perdita di precisione con l’aumentare della dimensione n, confermando le difficoltà nel risolvere sistemi di Hilbert con metodi diretti a causa del suo elevato condizionamento. Per n=14, l’errore è addirittura dell’ordine di 10^1, rendendo la soluzione inaffidabile.\nRisultati con Metodi Iterativi Precondizionati\nVengono considerati il Gradiente Precondizionato (PG) e il Gradiente Coniugato Precondizionato (PCG), entrambi precondizionati con la matrice diagonale D = diag(A) contenente gli elementi diagonali della matrice di Hilbert. Si parte da una guess iniziale nulla e si fissa una tolleranza di 10^{-6} per la convergenza.\nGradiente Precondizionato (GP)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimensione nErrore GP PrecondizionatoNumero Iterazioni GP Precondizionato4\\mathcal{O}(10^{-3})9956\\mathcal{O}(10^{-3})181314\\mathcal{O}(10^{-3})3779\nSi osserva che l’errore rimane costante all’incirca a \\mathcal{O}(10^{-3}) al variare di n, il che è un risultato positivo considerando il malcondizionamento crescente. Tuttavia, l’errore non raggiunge la tolleranza desiderata di 10^{-6}, e il numero di iterazioni cresce con la dimensione del sistema.\nGradiente Coniugato Precondizionato (GCP)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimensione nErrore GCP PrecondizionatoNumero Iterazioni GCP Precondizionato4\\mathcal{O}(10^{-2})36\\mathcal{O}(10^{-3})48\\mathcal{O}(10^{-3})414\\mathcal{O}(10^{-3})5\nIl gradiente coniugato precondizionato mostra un comportamento notevolmente migliore. L’errore si stabilizza anch’esso intorno a \\mathcal{O}(10^{-3}), simile al gradiente precondizionato, ma il numero di iterazioni necessarie per la convergenza rimane estremamente basso e quasi indipendente dalla dimensione del sistema n. Questo dimostra l’efficacia del gradiente coniugato precondizionato nel gestire sistemi mal condizionati come quelli con la matrice di Hilbert, raggiungendo una precisione simile al gradiente precondizionato con un costo computazionale drasticamente inferiore in termini di numero di iterazioni.\nIl professore conclude sottolineando come il gradiente coniugato precondizionato sia vincente nel caso della matrice di Hilbert, riuscendo a controllare l’errore con un numero molto ridotto di iterazioni, a differenza del metodo diretto che fallisce e del gradiente precondizionato che richiede molte più iterazioni.\nReferences\nAppunti Mate Num 1- lez10.pdf"},"6--full-note/mateNum--Lez12":{"slug":"6--full-note/mateNum--Lez12","filePath":"6- full note/mateNum- Lez12.md","title":"mateNum- Lez12","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","2--source-materials/Appunti-Mate-Num-lez12.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-20 10:39\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nmateNum- Lez12\nErrore del Polinomio di Interpolazione di Lagrange\nIntroduzione\nIl professore ha ripreso la lezione precedente, spostando l’attenzione dall’approssimazione della soluzione di sistemi di equazioni lineari all’approssimazione di una funzione continua f o di un insieme di dati. In particolare, la discussione è iniziata con la distinzione tra interpolazione e minimi quadrati, focalizzandosi inizialmente sull’interpolazione.\nÈ stata ricordata l’esistenza e l’unicità del polinomio di interpolazione di Lagrange. Successivamente, l’attenzione si è spostata sull’analisi dell’errore di interpolazione, introducendo un teorema a riguardo.\nTeorema sull’Errore di Interpolazione\nTeorema: Sia f \\in C^{n+1}([x_0, x_n]) e sia p_n(x) il polinomio di interpolazione di Lagrange di grado al più n che interpola f nei nodi x_0, x_1, \\dots, x_n. Allora, per ogni x \\in [x_0, x_n], esiste un punto \\alpha(x) \\in (x_0, x_n) tale che l’errore di interpolazione è dato da: f(x) - p_n(x) = \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} \\omega_{n+1}(x) dove \\omega_{n+1}(x) è il polinomio di grado n+1 definito come: \\omega_{n+1}(x) = \\prod_{k=0}^{n} (x - x_k) Questa stima dell’errore è valida quando si interpola una funzione f e non un semplice insieme di dati. L’ipotesi fondamentale per questo risultato è la regolarità della funzione f, che deve essere C^{n+1}.\nÈ importante notare che, per definizione di interpolazione, l’errore calcolato in corrispondenza dei nodi x_i è zero, poiché \\omega_{n+1}(x_i) = 0 per i = 0, \\dots, n.\nDimostrazione del Teorema\nPer dimostrare il teorema, è stata introdotta una funzione ausiliaria della variabile indipendente t, chiamata g(t): g(t) = f(t) - p_n(t) - W \\omega_{n+1}(t) dove W è una costante definita in modo tale che g(x) = 0 per un fissato x \\neq x_i con i = 0, \\dots, n. Esplicitamente, scegliendo W come: W = \\frac{f(x) - p_n(x)}{\\omega_{n+1}(x)} si ottiene g(x) = f(x) - p_n(x) - \\frac{f(x) - p_n(x)}{\\omega_{n+1}(x)} \\omega_{n+1}(x) = 0.\nRegolarità della Funzione Ausiliaria g(t)\nLa funzione g(t) è definita sull’intervallo I_x = [\\min(x_0, \\dots, x_n, x), \\max(x_0, \\dots, x_n, x)]. La regolarità di g(t) dipende dalla regolarità di f(t) e di p_n(t) e \\omega_{n+1}(t). Sappiamo che f \\in C^{n+1}(I_x), p_n(t) è un polinomio di grado al più n (quindi C^\\infty), e \\omega_{n+1}(t) è un polinomio di grado n+1 (anch’esso C^\\infty)?. Pertanto, g(t) \\in C^{n+1}(I_x).\nZeri della Funzione Ausiliaria g(t)\nLa funzione g(t) si annulla nei nodi di interpolazione x_0, x_1, \\dots, x_n perché f(x_i) - p_n(x_i) = 0 (per definizione di interpolazione) e \\omega_{n+1}(x_i) = 0. Inoltre, per come è stata definita la costante W, abbiamo anche g(x) = 0. Quindi, g(t) ha almeno n+2 zeri distinti in I_x.?\nApplicazione del Teorema di Rolle?\nApplicando ripetutamente il Teorema di Rolle, possiamo dedurre che:\n\ng&#039;(t) ha almeno n+1 zeri distinti in I_x.\ng&#039;&#039;(t) ha almeno n zeri distinti in I_x.\n…\ng^{(n+1)}(t) ha almeno 1 zero in I_x. Sia questo zero \\alpha(x).\n\nCalcolo della Derivata (n+1)-esima di g(t)\nCalcoliamo la derivata (n+1)-esima di g(t): g^{(n+1)}(t) = \\frac{d^{n+1}}{dt^{n+1}} (f(t) - p_n(t) - W \\omega_{n+1}(t)) Poiché p_n(t) è un polinomio di grado al più n, la sua derivata (n+1)-esima è zero: \\frac{d^{n+1}}{dt^{n+1}} p_n(t) = 0. La derivata (n+1)-esima di \\omega_{n+1}(t) = (t - x_0)(t - x_1)\\cdots(t - x_n) è (n+1)!. Questo risultato può essere dimostrato per induzione, osservando che la derivata prima è una somma di prodotti di n termini (t-x_i), la derivata seconda sarà una somma di prodotti di n-1 termini, e così via. La derivata n-esima sarà una somma di termini costanti, e la derivata (n+1)-esima sarà una costante data da (n+1)!.\nQuindi, la derivata (n+1)-esima di g(t) è: g^{(n+1)}(t) = f^{(n+1)}(t) - 0 - W (n+1)! = f^{(n+1)}(t) - W (n+1)!\nDerivazione della Formula dell’Errore?\nSappiamo che esiste un punto \\alpha(x) \\in (x_0, x_n) tale che g^{(n+1)}(\\alpha(x)) = 0. Quindi: f^{(n+1)}(\\alpha(x)) - W (n+1)! = 0 Da cui ricaviamo la costante W: W = \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} Sostituendo questa espressione di W nella definizione di W data in precedenza: \\frac{f(x) - p_n(x)}{\\omega_{n+1}(x)} = \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} otteniamo la formula per l’errore di interpolazione: f(x) - p_n(x) = \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} \\omega_{n+1}(x) Questo completa la dimostrazione.\nOsservazione sulla Struttura dell’Errore e Relazione con Taylor\nIl professore ha sottolineato come la struttura dell’errore di interpolazione sia simile alla struttura del termine di resto della formula di Taylor. Infatti, entrambe presentano una derivata di ordine (n+1), il fattoriale (n+1)! a denominatore e un termine che dipende dalla distanza dal punto di espansione (nel caso di Taylor) o dai nodi di interpolazione (nel nostro caso, \\omega_{n+1}(x) è un polinomio di grado n+1 con radici nei nodi). Esiste una dimostrazione di questo risultato che utilizza proprio il teorema di Taylor, anche se quella presentata si basa sul teorema di Rolle.\nStima dell’Errore: Passaggio alla Norma Infinito\nLa formula esatta per l’errore contiene \\alpha(x), un punto la cui esatta posizione nell’intervallo [x_0, x_n] è generalmente sconosciuta. Per ottenere una stima dell’errore che sia computabile, si passa spesso a considerare una maggiorazione utilizzando la norma infinito.\nLa norma infinito di una funzione h(x) su un intervallo I è definita come: ||h||_{\\infty, I} = \\max_{x \\in I} |h(x)| Applicando la norma infinito all’errore di interpolazione sull’intervallo I_x = [\\min(x_0, \\dots, x_n), \\max(x_0, \\dots, x_n)], otteniamo: ||f - p_n||_{\\infty, I_x} = \\max_{x \\in I_x} |f(x) - p_n(x)| = \\max_{x \\in I_x} \\left| \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} \\omega_{n+1}(x) \\right| Poiché \\alpha(x) \\in (x_0, x_n) \\subseteq I_x, possiamo maggiorare il termine contenente la derivata (n+1)-esima: ||f - p_n||_{\\infty, I_x} \\leq \\frac{1}{(n+1)!} \\max_{x \\in I_x} |f^{(n+1)}(\\alpha(x))| \\cdot \\max_{x \\in I_x} |\\omega_{n+1}(x)| \\Rightarrow ||f - p_n||_{\\infty, I_x} \\leq \\frac{1}{(n+1)!} ||f^{(n+1)}||_{\\infty, I_x} \\cdot ||\\omega_{n+1}||_{\\infty, I_x} Questa stima fornisce un controllo dall’alto sull’errore di interpolazione e dipende sia dalla funzione f (attraverso la norma infinito della sua derivata (n+1)-esima) che dalla scelta dei nodi di interpolazione (attraverso la norma infinito di \\omega_{n+1}(x)).\nCaso di Nodi di Interpolazione Uniformi\nConsideriamo ora il caso in cui i nodi di interpolazione x_0, x_1, \\dots, x_n sono distribuiti uniformemente nell’intervallo [x_0, x_n].\nDefinizione di Nodi Uniformi e Passo Costante\nSe la distribuzione dei nodi è uniforme, la distanza tra due nodi consecutivi è costante. Definiamo il passo di discretizzazione h come: h = \\frac{x_n - x_0}{n} Il passo h rappresenta l’ampiezza di ciascuno degli n sottointervalli in cui [x_0, x_n] è diviso dai nodi.\nEspressioni per i Nodi Uniformi\nCi sono due modi equivalenti per esprimere i nodi uniformi:\n\nRicorsivamente: x_{k+1} = x_k + h, \\quad \\text{per } k = 0, 1, \\dots, n-1 dove x_0 è il primo nodo.\nDirettamente: x_{k} = x_0 + k h, \\quad \\text{per } k = 0, 1, \\dots, n\n\nMaggiorazione di ||\\omega_{n+1}||_{\\infty, I_x} per Nodi Uniformi\nNel caso di nodi uniformi, si può dimostrare (anche se la dimostrazione non è fornita nel testo) che il massimo del valore assoluto di \\omega_{n+1}(x) sull’intervallo [x_0, x_n] può essere maggiorato come: ||\\omega_{n+1}||_{\\infty, [x_0, x_n]} \\leq \\frac{h^{n+1} n!}{4} È importante notare che questa stima non dipende da x grazie all’uniformità del passo.\nStima dell’Errore con Nodi Uniformi\nUtilizzando la maggiorazione di ||\\omega_{n+1}||_{\\infty, [x_0, x_n]}, possiamo riscrivere la stima per la norma infinito dell’errore nel caso di nodi uniformi: ||f - p_n||_{\\infty, [x_0, x_n]} \\leq \\frac{1}{(n+1)!} ||f^{(n+1)}||_{\\infty, [x_0, x_n]} \\cdot \\frac{h^{n+1} n!}{4} Semplificando il termine con i fattoriali ((n+1)! = (n+1) \\cdot n!), otteniamo: ||f - p_n||_{\\infty, [x_0, x_n]} \\leq \\frac{h^{n+1}}{4 (n+1)} ||f^{(n+1)}||_{\\infty, [x_0, x_n]} Questa stima sarà utilizzata in seguito.\nComportamento dell’Errore al Crescere di n\nConsideriamo ora cosa succede all’errore quando aumentiamo il numero di nodi di interpolazione n, mantenendo fisso l’intervallo [x_0, x_n]. In questo caso, il passo h = \\frac{x_n - x_0}{n} tende a zero quando n \\rightarrow \\infty.\nLa stima dell’errore con nodi uniformi può essere vista come il prodotto di due “blocchi”:\n\nBlocco A: \\frac{h^{n+1}}{4 (n+1)} che dipende dalla scelta dei nodi (in particolare dal numero di nodi n). Poiché h \\rightarrow 0 al crescere di n, questo blocco tende a zero per n \\rightarrow \\infty.\nBlocco B: ||f^{(n+1)}||_{\\infty, [x_0, x_n]} che dipende dalla funzione f e dalle sue derivate di ordine elevato. Il comportamento di questo blocco al crescere di n dipende fortemente dalla natura della funzione f.\n\nIdealmente, ci si aspetterebbe che l’errore tenda a zero quando n \\rightarrow \\infty, poiché un numero maggiore di informazioni sulla funzione dovrebbe portare a un’approssimazione migliore. Tuttavia, questo non è sempre garantito.\nPossono verificarsi diversi scenari per il blocco B al tendere di n all’infinito:\n\n||f^{(n+1)}||_{\\infty, [x_0, x_n]} converge a una costante. In questo caso, l’errore complessivo tende a zero perché il blocco A tende a zero.\n||f^{(n+1)}||_{\\infty, [x_0, x_n]} tende a zero. Anche in questo caso, l’errore complessivo tende a zero.\n||f^{(n+1)}||_{\\infty, [x_0, x_n]} tende a più infinito. In questo caso, il comportamento dell’errore complessivo dipende dalla velocità con cui il blocco A tende a zero rispetto alla velocità con cui il blocco B tende a infinito. Se il blocco A converge a zero più rapidamente di quanto il blocco B diverga, l’errore può ancora tendere a zero. Altrimenti, l’errore può divergere.\n\nFenomeno di Runge\nEsistono casi in cui, nonostante l’aumento del numero di nodi, l’errore di interpolazione non diminuisce e, anzi, può addirittura aumentare, specialmente agli estremi dell’intervallo. Questo fenomeno è noto come Fenomeno di Runge.\nUn esempio classico in cui si manifesta il Fenomeno di Runge è la funzione: f(x) = \\frac{1}{1 + x^2} sull’intervallo [-5, 5]. Questa funzione è analitica e apparentemente “ben comportata”.\nTuttavia, se si utilizzano nodi di interpolazione uniformi e si aumenta il numero di nodi, il polinomio interpolante p_n(x) converge bene verso f(x) nella parte centrale dell’intervallo [-5, 5], ma agli estremi si sviluppano oscillazioni spurie sempre più ampie. Queste oscillazioni non rappresentano il comportamento della funzione originale e peggiorano all’aumentare di n, portando a un aumento dell’errore agli estremi.\n\nAnalisi dei Blocchi A e B per la Funzione di Runge\nConsiderando la funzione di Runge, si osserva il seguente comportamento qualitativo per piccoli valori di n:\n\nBlocco A (\\frac{h^{n+1}}{4 (n+1)}): Diminuisce rapidamente all’aumentare di n. Ad esempio, si è visto che l’ordine di grandezza passa da O(10^1) per n=3 a O(10^{-10}) per n=21.\nBlocco B (||f^{(n+1)}||_{\\infty, [-5, 5]}): Aumenta molto rapidamente all’aumentare di n. Ad esempio, si è visto che l’ordine di grandezza passa da O(10^0) per n=3 a O(10^{19}) per n=21.\n\n\nIl prodotto di questi due blocchi determina il comportamento dell’errore. Nel caso della funzione di Runge con nodi uniformi, la crescita del blocco B prevale sulla diminuzione del blocco A per valori di x vicini agli estremi dell’intervallo, causando il fenomeno delle oscillazioni spurie e la mancata convergenza (anzi, la divergenza) del polinomio interpolante verso la funzione f(x) in quelle regioni.\nDefinizione del Fenomeno di Runge\nIl Fenomeno di Runge è la manifestazione di oscillazioni spurie agli estremi del dominio di interpolazione al crescere del numero dei nodi di interpolazione, specialmente quando si utilizzano nodi uniformi.\n\nNodi di Chebyshev-Gauss-Lobatto e il Fenomeno di Runge\nIl Problema: Oscillazioni nell’Interpolazione con Nodi Equispaziati (Fenomeno di Runge)\nIl problema discusso riguarda le oscillazioni che si verificano quando si approssima una funzione mediante un polinomio interpolante costruito su nodi equispaziati, specialmente verso i bordi dell’intervallo di interpolazione. Questo fenomeno è noto come fenomeno di Runge. Il professore introduce questo problema come motivazione per esplorare strategie di scelta dei nodi di interpolazione più efficaci.\nUna Possibile Soluzione: Nodi Non Uniformi\nUna strategia per mitigare il fenomeno di Runge consiste nell’utilizzare nodi di interpolazione non uniformemente distribuiti sull’intervallo. L’idea è di addensare i nodi nelle regioni dove la funzione presenta maggiori variazioni o dove le oscillazioni tendono a essere più pronunciate.\nIntroduzione ai Nodi di Chebyshev-Gauss-Lobatto (CGL)\nIl professore introduce una famiglia di nodi specifici, noti come nodi di Chebyshev-Gauss-Lobatto (CGL). Questi nodi prendono il nome dalle tre persone che hanno contribuito alla loro definizione: Chebyshev, Gauss e Lobatto. Vengono anche chiamati nodi CGL.\nDefinizione dei Nodi CGL sull’Intervallo di Riferimento [-1, 1]\nI nodi di Chebyshev-Gauss-Lobatto vengono definiti inizialmente sull’intervallo di riferimento [-1, 1]. Questi nodi, indicati con \\tilde x_i, per i che va da 0 a n, sono dati dalla seguente formula:\n\\tilde x_i = -\\cos\\left(\\frac{\\pi i}{n}\\right), \\quad i = 0, 1, \\ldots, n\nDefinizione: La formula sopra definisce gli n+1 nodi di Chebyshev-Gauss-Lobatto sull’intervallo [-1, 1].\nInterpretazione Geometrica dei Nodi CGL\n\nLa costruzione di questi nodi può essere visualizzata considerando la semicirconferenza unitaria di raggio 1 centrata nell’origine.\n\nSi divide la mezza circonferenza in n porzioni uguali.\nSi considerano i punti di divisione sulla semicirconferenza.\nI nodi di Chebyshev-Gauss-Lobatto sull’asse x (l’intervallo [-1, 1]) sono le proiezioni di questi punti sull’asse delle ascisse.\n\nEsempio: Per n = 8, la semicirconferenza viene divisa in otto parti uguali. Le proiezioni dei punti di divisione sull’asse x forniscono i nove nodi CGL (per i = 0, \\ldots, 8).\n\nPer i = 0: \\tilde x_0 = -\\cos(0) = -1.\nPer i = 1: \\tilde x_1 = -\\cos(\\frac{\\pi}{8}).\n…\nPer i = 8: \\tilde x_8 = -\\cos(\\pi) = -(-1) = 1.\n\nCome si può notare, i nodi sono più densi agli estremi dell’intervallo [-1, 1] e meno densi nella parte centrale. Questo è dovuto alla natura non lineare della proiezione tramite la funzione coseno.\nMappatura dei Nodi CGL su un Intervallo Generico [a, b] NO\nPoiché l’intervallo di interpolazione di interesse può essere un qualunque intervallo [a, b] della retta reale, è necessario mappare i nodi CGL definiti su [-1, 1] all’intervallo fisico [a, b]. Questa mappatura viene effettuata utilizzando una trasformazione lineare:\nx_i = \\frac{b + a}{2} + \\frac{b - a}{2} \\tilde x_i, \\quad i = 0, 1, \\ldots, n\nDimostrazione della Mappatura: Verifichiamo che questa mappa trasformi correttamente gli estremi e il punto medio dell’intervallo [-1, 1] negli estremi e nel punto medio dell’intervallo [a, b].\n\nSe \\tilde x_i = -1: x_i = \\frac{b + a}{2} + \\frac{b - a}{2} (-1) = \\frac{b + a - b + a}{2} = \\frac{2a}{2} = a Quindi, -1 viene mappato in a.\nSe \\tilde x_i = 1: x_i = \\frac{b + a}{2} + \\frac{b - a}{2} (1) = \\frac{b + a + b - a}{2} = \\frac{2b}{2} = b Quindi, 1 viene mappato in b.\nSe \\tilde x_i = 0: x_i = \\frac{b + a}{2} + \\frac{b - a}{2} (0) = \\frac{b + a}{2} Quindi, 0 (il punto medio di [-1, 1]) viene mappato in \\frac{b + a}{2} (il punto medio di [a, b]).\n\nQuesta mappatura trasferisce la distribuzione non uniforme dei nodi dall’intervallo di riferimento [-1, 1] all’intervallo fisico [a, b], mantenendo la proprietà di maggiore densità agli estremi.\nEffetto dei Nodi CGL sul Fenomeno di Runge\n\nQuando si utilizza lo stesso numero di nodi, ma distribuiti secondo la formula dei nodi CGL, per interpolare la funzione f(x) = \\frac{1}{1 + x^2}, si osserva un comportamento significativamente diverso rispetto all’utilizzo di nodi equispaziati.\n\nLa funzione approssimata inizia ancora ad oscillare, ma le oscillazioni sono più contenute.\nLe oscillazioni più grandi si trovano nella parte centrale dell’intervallo, mentre diminuiscono man mano che ci si avvicina agli estremi.\n\nTeorema (Convergenza con Nodi CGL): Per n \\to \\infty, l’errore di interpolazione E_n(f) = |f - p_n|_\\infty, dove p_n è il polinomio interpolante di grado n costruito sui nodi CGL, tende a 0 anche per funzioni meno regolari rispetto a quanto richiesto per la convergenza con nodi uniformi. In particolare, la convergenza si verifica anche se la funzione f è solamente di classe C^1. Questo è un risultato notevole, in quanto con nodi uniformi si richiederebbe una regolarità C^{n+1} per garantire la convergenza al crescere di n.\nIntroduzione ai Nodi di Chebyshev-Gauss (CG)\nIl professore introduce anche un’altra famiglia di nodi strettamente legata ai nodi CGL, chiamati nodi di Chebyshev-Gauss (CG). La principale differenza è che i nodi CG non includono gli estremi dell’intervallo, ma sono tutti nodi interni.\nDefinizione dei Nodi CG sull’Intervallo di Riferimento [-1, 1]\nI nodi di Chebyshev-Gauss, indicati con x_i^*, per i che va da 0 a n, sull’intervallo [-1, 1] sono definiti come:\nx_i^* = -\\cos\\left(\\frac{(2i + 1)\\pi}{2(n + 1)}\\right), \\quad i = 0, 1, \\ldots, n\nDefinizione: La formula sopra definisce gli n+1 nodi di Chebyshev-Gauss sull’intervallo [-1, 1].\nEsempio: Per n = 8, i nodi CG saranno:\n\nx_0^* = -\\cos\\left(\\frac{\\pi}{18}\\right)\nx_1^* = -\\cos\\left(\\frac{3\\pi}{18}\\right)\n…\nx_8^* = -\\cos\\left(\\frac{17\\pi}{18}\\right)\n\nCome si può osservare, per i = 0, l’argomento del coseno è \\frac{\\pi}{2(n+1)} \\neq 0, e per i = n, l’argomento è \\frac{(2n+1)\\pi}{2(n+1)} = \\pi - \\frac{\\pi}{2(n+1)} \\neq \\pi. Di conseguenza, i nodi x_0 e x_n non coincidono con -1 e 1 rispettivamente, ma sono interni all’intervallo [-1, 1].\nAnche i nodi CG possono essere mappati su un intervallo generico [a, b] utilizzando la stessa trasformazione lineare.\nProprietà dei Nodi CG: Anche i nodi CG godono di simili proprietà di convergenza ai nodi CGL. L’errore di interpolazione tende a zero al crescere di n, anche per funzioni con una regolarità minima.\nMotivazione per l’Uso dei Nodi CG\nIn alcune applicazioni, può essere inutile o indesiderabile includere i bordi dell’intervallo nei punti di interpolazione. Utilizzando i nodi CG, si ottiene un campionamento più fitto all’interno del dominio, il che può essere vantaggioso in certi contesti.\nLimiti dei Nodi di Chebyshev (CGL e CG)\nUn limite di questi approcci basati sui nodi di Chebyshev è che i punti di interpolazione sono predeterminati e non possono essere scelti arbitrariamente. Questo può rappresentare un problema quando si ha a che fare con l’approssimazione di dati sperimentali, dove i punti di misurazione sono fissati e non necessariamente coincidono con i nodi di Chebyshev. In questi casi, potrebbe essere necessario ricorrere a tecniche di approssimazione diverse dall’interpolazione polinomiale su nodi fissi. Il professore accenna al fatto che questa limitazione motiva la ricerca di approcci differenti per l’approssimazione, specialmente nel contesto dell’approssimazione di dati.\n\nInterpolazione Lineare a Tratti\nProblemi con l’Interpolazione Globale e Nodi Uniformi\nInizialmente, si era partiti con un approccio ottimistico all’interpolazione. Tuttavia, sorgono delle problematiche quando si considerano i dati ottenuti, specialmente se questi non corrispondono esattamente agli istanti desiderati per la misurazione. Se i dati sono già raccolti, è necessario avere la fortuna che questi siano stati campionati esattamente nei nodi scelti, altrimenti non possono essere direttamente utilizzati. Questo vincola la scelta dei nodi, che non possono più essere scelti liberamente.\nUtilizzare nodi uniformemente distribuiti si è rivelato problematico. Anche l’intervallo considerato inizialmente piccolo non risolve il problema per intervalli più ampi.\nUn altro fattore critico è il grado del polinomio interpolante. Con un numero elevato di nodi nell’interpolazione globale, si è portati inevitabilmente a utilizzare polinomi di alto grado. I polinomi di alto grado tendono ad avere un andamento oscillatorio, intersecando l’asse delle ascisse più volte.\nPassaggio all’Interpolazione Polinomiale Locale: L’Interpolazione a Tratti\n\nPer superare i limiti dell’interpolazione globale con molti nodi e grado elevato, si introduce l’idea di interpolazione polinomiale locale. Invece di considerare tutti i nodi contemporaneamente, li si considera a piccoli gruppi.\nLa forma più semplice di interpolazione locale consiste nel prendere i nodi a coppie consecutive e interpolare i dati corrispondenti con una retta. Questo porta alla creazione di una spezzata, formata da segmenti di retta che connettono i punti dati. Questa tecnica è nota come interpolazione lineare a tratti.\nDefinizione (Interpolazione Lineare a Tratti): L’interpolazione lineare a tratti consiste nell’approssimare una funzione f(x) su un intervallo [x_0, x_n] mediante una funzione continua formata da segmenti di retta che interpolano i dati (x_i, f(x_i)) in nodi consecutivi x_i e x_{i+1} per i = 0, 1, \\ldots, n-1.\nRappresentazione Grafica: Consideriamo una funzione con alcuni nodi x_0, x_1, x_2, x_3.\n\nApprossimazione Globale: Un polinomio di grado 3 che interpola tutti e quattro i nodi potrebbe avere un andamento oscillatorio tra i nodi.\nApprossimazione a Tratti (Lineare): Si congiungono i punti (x_0, f(x_0)) e (x_1, f(x_1)) con una retta, poi (x_1, f(x_1)) e (x_2, f(x_2)) con un’altra retta, e così via. Questo produce una spezzata che segue l’andamento dei dati in modo più locale.\n\nVantaggi dell’Interpolazione a Tratti:\n\nSe si infittiscono i dati (si aggiungono più nodi), l’approssimazione migliora. La spezzata si avvicina sempre più alla funzione originale.\nNon si introducono oscillazioni indesiderate tra i nodi, a differenza dei polinomi di alto grado.\n\nOltre all’interpolazione lineare a tratti, si possono utilizzare anche interpolazioni quadratiche a tratti e cubiche a tratti, unendo segmenti di parabole o cubiche tra gruppi di nodi. Tuttavia, raramente si utilizzano gradi superiori a 3 per evitare problemi simili al fenomeno di Runge su intervalli più piccoli.\nFormalizzazione dell’Interpolazione Lineare a Tratti\nSia dato un insieme di n+1 nodi x_0 &lt; x_1 &lt; \\ldots &lt; x_n nell’intervallo [a, b] (dove a = x_0 e b = x_n). I nodi non devono necessariamente essere uniformemente distribuiti.\nSi definisce l’intervallino i-esimo come I_i = [x_i, x_{i+1}] per i = 0, 1, \\ldots, n-1.\nL’ampiezza dell’intervallino i-esimo è h_i = x_{i+1} - x_i.\nL’ampiezza massima dei sottointervalli è h = \\max_{i} {h_i}.\nIl polinomio lineare a tratti che interpola la funzione f(x) nei nodi x_i è denotato come \\pi_{1}^hf(x).\nProprietà di \\pi_{1}^hf(x):\n\n\\pi_{1}^hf(x) è una funzione continua sull’intervallo [x_0, x_n].\nLa restrizione di \\pi_{1}^hf(x) al generico intervallo I_i = [x_i, x_{i+1}] è un polinomio di grado 1.\n\\pi_{1}^hf(x) soddisfa le condizioni di interpolazione: P_{1,h}f(x_i) = f(x_i) per i = 0, 1, \\ldots, n.\n\nEspressione del Polinomio Lineare a Tratti su un Intervallo:\nLa restrizione di \\pi_{1}^hf(x) all’intervallo I_i = [x_i, x_{i+1}] è la retta che interpola i punti (x_i, f(x_i)) e (x_{i+1}, f(x_{i+1})). La sua espressione è data da:\n\\pi_{1}^hf(x)|_{I_i} = f(x_i) + \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i} (x - x_i)\nVerifica dell’Interpolazione:\n\n?Se x = x_i: P_{1,h}f(x_i)|_{I_i} = f(x_i) + \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i} (x_i - x_i) = f(x_i) + 0 = f(x_i)\nSe x = x_{i+1}: P_{1,h}f(x_{i+1})|_{I_i} = f(x_i) + \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i} (x_{i+1} - x_i) = f(x_i) + f(x_{i+1}) - f(x_i) = f(x_{i+1}) L’interpolazione è quindi verificata.\n\nErrore dell’Interpolazione Lineare a Tratti\nSi vuole verificare che, aumentando il numero di nodi (e quindi facendo tendere a zero l’ampiezza massima h), l’errore dell’interpolazione lineare a tratti tende a zero.\nConsideriamo l’errore sull’intervallino I_i: |f(x) - \\pi_{1}^hf(x)| per x \\in I_i. Poiché sull’intervallo I_i si utilizzano solo due nodi (gli estremi), si può riciclare la stima dell’errore per l’interpolazione con due nodi uniformi. In questo caso, n+1 = 2, quindi n=1. La formula dell’errore per nodi uniformi (non esplicitata nel testo ma richiamata) suggerisce una dipendenza da h^{n+1} = h^2 e dalla derivata di ordine n+1 = 2 della funzione.\nStima dell’Errore Locale:\nAssumendo che f \\in C^2([x_0, x_n]), l’errore sull’intervallino I_i può essere maggiorato come:\n\\max_{x \\in I_i} |f(x) - \\pi_{1}^hf(x)| \\le \\frac{h_i^2}{8} \\max_{x \\in I_i} |f&#039;&#039;(x)| Questa stima si basa sull’errore di interpolazione di Lagrange per due punti.\nStima dell’Errore Globale:\nPer ottenere una stima dell’errore su tutto l’intervallo [x_0, x_n], si considera il massimo dell’errore locale su tutti gli intervallini:\n\\max_{x \\in [x_0, x_n]} |f(x) - \\pi_{1}^hf(x)| = \\max_{i} \\left( \\max_{x \\in I_i} |f(x) - \\pi_{1}^hf(x)| \\right)\nUtilizzando la stima locale e maggiorando h_i con h = \\max_{i} {h_i} e \\max_{x \\in I_i} |f&#039;&#039;(x)| con \\max_{x \\in [x_0, x_n]} |f&#039;&#039;(x)|, si ottiene:\n\\max_{x \\in [x_0, x_n]} |f(x) - \\pi_{1}^hf(x)| \\le \\frac{h^2}{8} \\max_{x \\in [x_0, x_n]} |f&#039;&#039;(x)|\nAnalisi della Convergenza:\nIn questa stima dell’errore globale, il termine \\max_{x \\in [x_0, x_n]} |f&#039;&#039;(x)| è una costante (blocco B) che dipende dalla funzione f e dall’intervallo [x_0, x_n]. Il termine h^2 (blocco A) dipende dall’ampiezza massima degli intervallini.\nAl contrario dell’interpolazione globale dove, aumentando il grado del polinomio (e quindi potenzialmente il numero di nodi), il comportamento del termine analogo a B poteva portare a divergenza (fenomeno di Runge), qui il termine \\max |f&#039;&#039;(x)| rimane costante.\nQuando si infittiscono i nodi, l’ampiezza massima h tende a zero. Di conseguenza, anche h^2 tende a zero. Pertanto, l’errore dell’interpolazione lineare a tratti:\n\\lim_{h \\to 0} \\max_{x \\in [x_0, x_n]} |f(x) - \\pi_{1}^hf(x)| = 0\nQuesto dimostra che l’interpolazione lineare a tratti converge alla funzione f(x) quando il numero di nodi aumenta (ovvero, quando h diminuisce), a condizione che la funzione f sia sufficientemente regolare (f \\in C^2). Questo approccio risolve il problema del fenomeno di Runge riscontrato con l’interpolazione globale.\nSi può quindi affermare che l’interpolazione lineare a tratti è una soluzione al fenomeno di Runge.\nSi accenna infine che per approssimazioni più accurate, si possono utilizzare interpolazioni a tratti di grado superiore (quadratiche, cubiche) con nodi scelti in modo intelligente (non necessariamente uniformi), come fa ad esempio MATLAB.\nReferences\nAppunti Mate Num-lez12.pdf"},"6--full-note/mateNum--Lez13":{"slug":"6--full-note/mateNum--Lez13","filePath":"6- full note/mateNum- Lez13.md","title":"mateNum- Lez13","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","2--source-materials/Appunti-Mate-Num-lez13.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-18 11:08\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine. matematica numerica\nmateNum- Lez13\nApprossimazione di Dati e Funzioni: Interpolazione a Tratti\nInterpolazione Lineare a Tratti\nLa professoressa ha introdotto l’interpolazione a tratti come una delle possibili soluzioni al fenomeno di Runge. Nello specifico, si è inizialmente concentrata sull’interpolazione lineare a tratti.\nDefinizione\nL’interpolazione lineare a tratti consiste nel congiungere coppie di punti (x_i, y_i) con segmenti di retta. Invece di utilizzare un unico polinomio di alto grado per interpolare tutti i punti, si utilizzano polinomi di grado uno (rette) su ciascun intervallo [x_i, x_{i+1}] definito dai nodi di interpolazione.\nStima dell’Errore\nLa professoressa ha ricordato che era stata ricavata una stima dell’errore per l’interpolazione lineare a tratti. Questa stima presentava una struttura simile a quella con nodi uniformi, con un blocco A e un blocco B.\n\nBlocco A: Era legato alla distanza tra i nodi, tipicamente rappresentata da H (o h per la massima ampiezza degli intervalli), e continuava a tendere a zero all’aumentare del campionamento.\nBlocco B: La novità principale rispetto al caso con nodi uniformi era che il blocco B, invece di avere un andamento asintotico, diventava una costante.\n\nQuesta caratteristica garantiva che il prodotto dei due blocchi (e quindi l’errore) convergesse a zero all’aumentare del campionamento, indipendentemente dal valore della costante nel blocco B.\nComando MATLAB interp1\nLa professoressa ha introdotto il comando MATLAB interp1 come strumento builtin per realizzare l’interpolazione lineare a tratti, in vista del laboratorio.\nSintassi Minimale\nLa sintassi base del comando interp1 prevede tre parametri di input:\ninterp1(X, Y, Z)\n\nDove:\n\nX: è il vettore che raccoglie i nodi di interpolazione x_i.\nY: è il vettore che raccoglie i dati da interpolare, ovvero i valori della funzione nei nodi f(x_i) o i dati misurati.\nZ: è un numero reale o un insieme di numeri reali (un vettore di dimensione S) in corrispondenza dei quali si vuole valutare il polinomio di interpolazione lineare a tratti.\n\nFunzionalità\nLa professoressa ha spiegato che interp1 può essere visto come un “merging” dei comandi polyfit e polyval utilizzati per il polinomio di Lagrange.\n\nMentre polyfit costruiva il polinomio e polyval lo valutava, interp1 costruisce e valuta direttamente l’interpolante lineare a tratti, che è concettualmente semplice essendo un’unione continua di segmenti di retta. Per questo motivo, non è necessario ottenere un’espressione esplicita del polinomio.\n\nOutput\nL’output del comando interp1 è un oggetto (che la professoressa aveva forse chiamato pif) che avrà la stessa dimensionalità di Z. Se Z è un punto, l’output sarà il valore di pif in quel punto; se Z è un vettore, l’output sarà un vettore dei valori di pif nei punti di Z.\nMiglioramento dell’Approssimazione e Scelta Adattativa dei Nodi\nLa professoressa ha sottolineato come l’interpolazione lineare a tratti, pur essendo un’approssimazione “grezza”, funzioni estremamente bene. L’aggiunta di punti nelle zone del dominio dove mancano informazioni porta a un miglioramento dell’approssimazione, come ci si aspetta.\nComando plot in MATLAB e Nodi Adattativi\nÈ stato evidenziato che il comando plot in MATLAB, quando viene utilizzato per disegnare il grafico di una funzione, in realtà si appoggia a un polinomio di interpolazione lineare a tratti. Il campionamento utilizzato è così fitto che la natura “spezzata” della curva non è percepibile a occhio nudo, ma diventa visibile soloZoomando ripetutamente.\nMATLAB utilizza una scelta adattativa dei nodi per il comando plot.\nScelta Adattativa\nUna scelta adattativa dei nodi significa che i nodi di interpolazione vengono posizionati in modo da adattarsi alla funzione.\n\nNelle regioni del dominio in cui la funzione è piatta (con variazioni contenute), viene utilizzato un campionamento lasco (pochi nodi).\nNelle regioni in cui la funzione presenta gradienti più significativi e una maggiore dinamica (come nel caso di uno shock in propagazione), il campionamento viene intensificato (più nodi).\n\nQuesto approccio è ottimale per gestire le informazioni, concentrando i punti dove la funzione ha un comportamento più complesso da descrivere (variazioni rapide, derivate elevate). La scelta adattativa dei nodi si basa sull’analisi dell’andamento della funzione, considerando le derivate prime e seconde (e in più dimensioni l’Hessiana). Dove queste assumono valori elevati, vengono inseriti più nodi.\nGeneralizzazione a Griglie di Calcolo Adattate\n\nLa professoressa ha menzionato come la scelta adattativa dei nodi sia la base per la costruzione di griglie di calcolo adattate in dimensioni superiori (2D e 3D), un argomento di cui si occupa nella sua ricerca.\n\nIn 2D, anziché dividere un intervallo in sottointervalli, si “tassella” il dominio con quadrati o triangoli (questi ultimi più avanzati, tipici del metodo degli elementi finiti).\nIn 3D, le tessere diventano cubi o piramidi.\n\nL’obiettivo delle griglie adattate è sempre lo stesso: ottenere calcoli accurati a basso costo, concentrando la risoluzione (elementi più piccoli) nelle zone di maggiore interesse o dove la soluzione presenta maggiori variazioni.\nInterpolazione Quadratica a Tratti\nSuccessivamente, la professoressa ha considerato l’ipotesi di unire non più tratti di retta, ma tratti di parabola.\nDefinizione\n\nIn questo caso, i nodi iniziali vengono raggruppati a tre a tre. Su ogni tripletta di nodi (x_i, x_{i+1}, x_{i+2}) viene costruito un polinomio di grado due (parabola) che interpola la funzione in quei tre punti. Questo processo viene ripetuto per le triple successive di nodi.\nVantaggi Potenziali\nUnire pezzi di parabola anziché pezzi di retta può potenzialmente portare a una maggiore accuratezza. Aumentando localmente il numero di informazioni (tre punti per intervallo anziché due), ci si aspetta un’approssimazione migliore.\nStima dell’Errore Locale\nSupponendo, per semplicità, che i nodi siano equispaziati all’interno di ogni intervallo, la stima dell’errore locale per l’interpolazione quadratica a tratti presenta la seguente forma:\n\\frac{H_i^{n+1}}{4(n+1)!} \\max_{x \\in [x_i, x_{i+n}]} |f^{(n+1)}(x)|\nDove n è il grado del polinomio (in questo caso n=2), e H_i è l’ampiezza dell’intervallo considerato. Quindi, per l’interpolazione quadratica a tratti (n=2), la stima locale dell’errore diventa:\n\\frac{H_i^{3}}{4 \\cdot 3!} \\max_{x \\in [x_i, x_{i+2}]} |f^{(3)}(x)| = \\frac{H_i^{3}}{24} \\max_{x \\in [x_i, x_{i+2}]} |f^{(3)}(x)|\nPassando alla stima globale, si ottiene una dipendenza da h^3 e dalla derivata terza della funzione:\n\\frac{h^3}{12} \\max_{x \\in [a, b]} |f^{(3)}(x)|\nQuesto indica che l’accuratezza dovrebbe migliorare rispetto all’interpolazione lineare a tratti, dove l’errore dipendeva da h^2 e dalla derivata seconda.\nSvantaggi e Limitazioni\nNonostante la maggiore accuratezza potenziale, l’interpolazione quadratica a tratti presenta degli svantaggi:\n\nMaggiore Regolarità Richiesta: La stima dell’errore coinvolge la derivata terza della funzione, il che significa che la funzione deve essere più regolare (almeno tre volte differenziabile) rispetto al caso lineare (due volte differenziabile). Non tutte le funzioni posseggono questa regolarità.\nPossibili Oscillazioni Spurie: Aumentare localmente il grado del polinomio può portare a oscillazioni spurie, simili a quelle osservate nell’interpolazione globale con polinomi di alto grado (fenomeno di Runge). È consigliabile non esagerare troppo con l’aumento locale del grado.\nRegolarità Globale: Anche se si utilizzano parabole, l’interpolazione quadratica a tratti continua a essere generalmente solo C^0 (continua), proprio come l’interpolazione lineare a tratti. I punti di raccordo tra le parabole potrebbero avere derivate prime diverse, rendendo la funzione globalmente non differenziabile.\n\nLa professoressa ha chiarito che l’interpolazione quadratica a tratti è una scelta alternativa all’interpolazione lineare a tratti, con una diversa gestione delle informazioni, e non un suo sostituto diretto.\nSpline Cubiche Interpolatorie\nPer ottenere approssimazioni più regolari globalmente, la professoressa ha introdotto il concetto di spline.\nDefinizione\nUna spline cubica interpolatoria (S_3) è una funzione definita a tratti, ottenuta unendo tratti di cubiche (polinomi di grado 3). Esistono anche spline di grado inferiore, come le spline quadratiche, ma le spline cubiche sono molto utilizzate, ad esempio, nella computer grafica e nel CAD.\nProprietà Fondamentali\n\nInterpolazione: S_3(x_i) = y_i per tutti i nodi x_i.\nRegolarità Globale Elevata: A differenza dell’interpolazione lineare o quadratica a tratti, le spline cubiche interpolatorie sono tipicamente di classe C^2. Questo significa che non solo la funzione è continua, ma lo sono anche la sua derivata prima e la sua derivata seconda. Questa elevata regolarità le rende adatte ad applicazioni dove è richiesta una “morbidezza” (smoothness) nelle curve e nelle superfici, come nel design automobilistico, computer grafica e CAD.\n\nCostruzione e Gradi di Libertà\nSu ogni sottointervallo [x_i, x_{i+1}], la spline cubica è un polinomio di grado 3, che ha bisogno di quattro coefficienti per essere definito. Con n sottointervalli, si hanno 4n incognite in totale. Le condizioni di interpolazione nei nodi (2n condizioni), la continuità della funzione nei nodi interni (n-1 condizioni), la continuità della derivata prima nei nodi interni (n-1 condizioni) e la continuità della derivata seconda nei nodi interni (n-1 condizioni) portano a un totale di 4n - 2 condizioni. Per definire la spline in modo univoco, mancano due condizioni aggiuntive, che possono essere scelte in diversi modi (ad esempio, condizioni sui valori della derivata prima o seconda agli estremi dell’intervallo).\nComando MATLAB spline\nMATLAB ha un comando dedicato per la realizzazione delle spline, chiamato spline. La sintassi è esattamente la stessa del comando interp1:\nspline(X, Y, Z)\n\nDove X, Y, e Z hanno lo stesso significato descritto per interp1. Per default, spline implementa la spline cubica, ma potrebbe essere possibile scegliere anche spline di grado diverso.\nApprossimazione delle Derivate con le Spline Cubiche\nUn aspetto interessante delle spline cubiche è che, grazie alla loro elevata regolarità, possono essere utilizzate non solo per approssimare la funzione f(x), ma anche le sue derivate.\n\nLa derivata prima di S_3 (S&#039;_3) può essere utilizzata per approssimare la derivata prima di f (f&#039;(x)).\nLa derivata seconda di S_3 (S&#039;&#039;_3) può essere utilizzata per approssimare la derivata seconda di f (f&#039;&#039;(x)).\n\nL’accuratezza di queste approssimazioni delle derivate è generalmente buona, proprio perché S_3 è un’approssimazione accurata di f.\nStima dell’Errore per le Derivate\nLa professoressa ha fornito una stima dell’errore per l’approssimazione sia della funzione che delle sue derivate tramite la spline cubica e le sue derivate:\n\\max_{x} |f^{(q)}(x) - S_3^{(q)}(x)| \\leq C_q h^{4-q} \\max_{x} |f^{(4)}(x)|\nDove:\n\nq = 0 indica l’approssimazione della funzione stessa (f(x) \\approx S_3(x)). In questo caso, l’ordine di convergenza è h^4.\nq = 1 indica l’approssimazione della derivata prima (f&#039;(x) \\approx S&#039;_3(x)). In questo caso, l’ordine di convergenza è h^3.\nq = 2 indica l’approssimazione della derivata seconda (f&#039;&#039;(x) \\approx S&#039;&#039;_3(x)). In questo caso, l’ordine di convergenza è h^2.\nC_q è una costante che dipende da q.\nh è la massima ampiezza degli intervalli tra i nodi.\n\\max_{x} |f^{(4)}(x)| rappresenta il massimo valore assoluto della derivata quarta di f(x) sull’intervallo considerato.\n\nQuesta stima evidenzia che l’accuratezza dell’approssimazione diminuisce man mano che si considerano derivate di ordine superiore. La spline cubica è “nata” per approssimare f, e derivandola si “spreme” l’approssimazione, ottenendo risultati meno accurati per le derivate successive, ma comunque con un ordine di convergenza che tende a zero con h. La potenza di h (4) è legata al grado locale dell’approssimazione (cubica, n=3), e l’ordine si riduce di uno per ogni derivata considerata.\nStabilità dell’Interpolazione di Lagrange\nIntroduzione al Problema della Stabilità\nQuando si approssimano dati o funzioni, è fondamentale considerare la stabilità dell’approssimazione rispetto a piccole variazioni nei dati. Questo problema è analogo a quanto visto per i sistemi di equazioni lineari, dove il numero di condizionamento indicava come gli errori sui dati si propagavano ai risultati. Anche nell’interpolazione, specialmente quando si tratta di dati misurati e quindi soggetti a errori, è importante capire come le perturbazioni nei dati influenzino l’approssimazione.\nDati Originali e Perturbati\nConsideriamo un insieme di dati originali (x_i, f(x_i)) per i che va da 0 a n, con tutti gli x_i distinti. A questi dati è associato il polinomio di interpolazione di Lagrange P_n f(x).\nSupponiamo ora di avere dei dati perturbati (x_i, \\tilde{f}(x_i)) per gli stessi nodi x_i, dove \\tilde{f}(x_i) rappresenta una perturbazione di f(x_i). Questa perturbazione può essere dovuta all’aritmetica floating point o a errori di misurazione. A questi dati perturbati associamo un altro polinomio di interpolazione, \\tilde{P}_n f(x), che rappresenta una perturbazione del polinomio originale.\nRelazione tra la Perturbazione sui Dati e sul Risultato\nL’obiettivo è comprendere come la perturbazione sui dati, |f(x_i) - \\tilde{f}(x_i)|, sia legata alla perturbazione sul risultato, |P_n f(x) - \\tilde{P}_n f(x)|.\nSi cerca una relazione tra la massima perturbazione sulla soluzione e la massima perturbazione sul dato: \\max_{x \\in I} |P_n f(x) - \\tilde{P}_n f(x)| \\leq C \\cdot \\max_{0 \\leq i \\leq n} |f(x_i) - \\tilde{f}(x_i)| dove C è una costante che quantifica l’amplificazione della perturbazione.\nLa Costante di Lebesgue (\\Lambda_n)\nIl ruolo della costante C è svolto dalla costante di Lebesgue, denotata con \\Lambda_n. Questa costante è definita come: \\Lambda_n = \\max_{x \\in I} \\sum_{i=0}^{n} |l_i(x)| dove l_i(x) sono i polinomi caratteristici di Lagrange (o polinomi elementari di Lagrange). Ricordiamo che l_i(x) è un polinomio di grado n che vale 1 nel nodo x_i e 0 in tutti gli altri nodi x_j per j \\neq i. Il polinomio di interpolazione di Lagrange può essere espresso come: P_n f(x) = \\sum_{i=0}^{n} f(x_i) l_i(x)\nDimostrazione della Relazione\nPartiamo dalle espressioni dei polinomi di interpolazione per i dati originali e perturbati: P_n f(x) = \\sum_{i=0}^{n} f(x_i) l_i(x) \\tilde{P}_n f(x) = \\sum_{i=0}^{n} \\tilde{f}(x_i) l_i(x)\nConsideriamo la differenza tra i due polinomi: P_n f(x) - \\tilde{P}_n f(x) = \\sum_{i=0}^{n} f(x_i) l_i(x) - \\sum_{i=0}^{n} \\tilde{f}(x_i) l_i(x) = \\sum_{i=0}^{n} (f(x_i) - \\tilde{f}(x_i)) l_i(x)\nPassando al valore assoluto: |P_n f(x) - \\tilde{P}_n f(x)| = \\left| \\sum_{i=0}^{n} (f(x_i) - \\tilde{f}(x_i)) l_i(x) \\right|\nUtilizzando la disuguaglianza triangolare: |P_n f(x) - \\tilde{P}_n f(x)| \\leq \\sum_{i=0}^{n} |f(x_i) - \\tilde{f}(x_i)| |l_i(x)|\nPer portare fuori dalla sommatoria la massima perturbazione sui dati, prendiamo il massimo di |f(x_i) - \\tilde{f}(x_i)| per i che va da 0 a n: |P_n f(x) - \\tilde{P}_n f(x)| \\leq \\left( \\max_{0 \\leq i \\leq n} |f(x_i) - \\tilde{f}(x_i)| \\right) \\sum_{i=0}^{n} |l_i(x)|\nInfine, per considerare la massima perturbazione sulla soluzione, prendiamo il massimo su x nell’intervallo di interesse I: \\max_{x \\in I} |P_n f(x) - \\tilde{P}_n f(x)| \\leq \\left( \\max_{0 \\leq i \\leq n} |f(x_i) - \\tilde{f}(x_i)| \\right) \\max_{x \\in I} \\sum_{i=0}^{n} |l_i(x)| \\max_{x \\in I} |P_n f(x) - \\tilde{P}_n f(x)| \\leq \\Lambda_n \\cdot \\max_{0 \\leq i \\leq n} |f(x_i) - \\tilde{f}(x_i)|\nQuesta relazione mostra come la costante di Lebesgue \\Lambda_n amplifichi o controlli la perturbazione sui dati nella soluzione interpolante. Una costante di Lebesgue elevata indica una maggiore sensibilità dell’interpolazione a piccole variazioni nei dati, quindi una minore stabilità.\nComportamento della Costante di Lebesgue al Crescere di n\nPer un numero crescente di nodi (n \\rightarrow \\infty), la costante di Lebesgue generalmente tende all’infinito: \\lim_{n \\to \\infty} \\Lambda_n = \\infty Questo significa che, aumentando il grado del polinomio interpolante globale, la stabilità rispetto alle perturbazioni sui dati peggiora.\nTuttavia, la velocità con cui \\Lambda_n diverge dipende dalla scelta dei nodi di interpolazione.\nNodi Equispaziati\nSe si utilizzano nodi equispaziati, la costante di Lebesgue ha un andamento asintotico di tipo esponenziale con n: \\Lambda_n \\sim 2^n Questo comportamento è legato al fenomeno di Runge, dove per nodi equispaziati un polinomio di grado elevato può presentare forti oscillazioni tra i punti di interpolazione, soprattutto vicino agli estremi dell’intervallo. Questa scelta di nodi, sebbene semplice, porta a problemi sia di convergenza (richiedendo funzioni con elevata regolarità) che di stabilità.\nNodi di Chebyshev-Gauss(-Lobatto)\nSe si utilizzano nodi di Chebyshev-Gauss o Chebyshev-Gauss-Lobatto, la costante di Lebesgue ha un andamento logaritmico con n: \\Lambda_n \\sim \\ln(n) Un andamento logaritmico è significativamente migliore di uno esponenziale in termini di stabilità. L’utilizzo di questi nodi mitiga il fenomeno di Runge e garantisce una migliore stabilità dell’interpolazione, richiedendo anche condizioni di regolarità meno stringenti sulla funzione da interpolare (ad esempio, C^1 invece di C^{n+1}).\nConclusioni sulla Scelta dei Nodi\nLa scelta dei nodi di interpolazione ha un impatto cruciale sia sulla convergenza che sulla stabilità dell’interpolazione polinomiale. I nodi equispaziati, pur essendo intuitivi, possono portare al fenomeno di Runge e a una scarsa stabilità per gradi elevati. I nodi di Chebyshev rappresentano una scelta più intelligente, in quanto migliorano sia la convergenza che la stabilità dell’interpolazione globale.\nIl professore ha menzionato anche i nodi adattativi, che sono considerati la scelta migliore perché permettono di concentrare i nodi nelle regioni dove la funzione presenta maggiore variabilità, ottimizzando i risultati in termini di accuratezza e potenzialmente anche di stabilità, sebbene questo non sia stato dettagliato nei passaggi precedenti.\nInfine, il professore ha concluso la discussione sull’interpolazione, preparando il terreno per l’argomento successivo: i minimi quadrati.\nApprossimazione ai Minimi Quadrati\nDistinzione tra Approssimazione e Interpolazione\nL’approssimazione si distingue dall’interpolazione. Quest’ultima si occupa di trovare una funzione che passi esattamente per tutti i punti dati. Invece, l’approssimazione, in particolare quella ai minimi quadrati, è più adatta quando si hanno dati caoticamente disposti, la cosiddetta “nuvola di dati”. In questo scenario, cercare una funzione interpolante che passi per ogni singolo punto risulterebbe in un percorso tortuoso e poco significativo. È più sensato, in questi casi, considerare l’andamento generale dei dati, ad esempio, se tendono a seguire una parabola.\nMotivazioni per l’Approssimazione ai Minimi Quadrati\nDati Caoticamente Disposti\n\nCome accennato, se i dati sono distribuiti in modo irregolare, una funzione che tentasse di interpolarli sarebbe eccessivamente complessa e poco informativa sull’andamento sottostante. L’approssimazione permette di trovare una funzione più semplice che catturi la tendenza generale dei dati.\nEstrapolazione\nUn’altra importante motivazione per l’uso dell’approssimazione ai minimi quadrati è l’estrapolazione. Il termine “extra” di estrapolazione deriva dal latino e significa “fuori”, in contrapposizione a “inter” che significa “dentro”. Estrapolare significa ricostruire l’andamento di una funzione al di fuori dell’intervallo su cui si hanno dati. Questo può essere utile per cercare di prevedere valori futuri o valori non misurati.\n\nConsideriamo l’esempio dell’andamento di un titolo borsistico. I grafici che mostrano l’evoluzione del prezzo di un’azione o di un bond nel tempo sono spesso interpolazioni lineari a tratti dei prezzi misurati a intervalli (ad esempio, a fine giornata). Se volessimo prevedere il valore del titolo il giorno successivo, basarci unicamente sull’interpolazione lineare a tratti tra l’ultimo giorno e il giorno precedente potrebbe essere fuorviante. Infatti, un titolo che globalmente tende a scendere potrebbe aver avuto un rialzo improvviso nell’ultimo periodo a causa di eventi specifici. In questo contesto, un’approssimazione ai minimi quadrati, che tiene conto di tutta la “storia” dei dati, sarebbe uno strumento più utile per l’estrapolazione, in quanto riflette l’andamento medio del grafico. L’approssimazione ai minimi quadrati considera l’intera sequenza di dati, non solo l’ultima variazione, fornendo una stima più robusta della tendenza generale.\nFormalizzazione Matematica dell’Approssimazione ai Minimi Quadrati\nNell’approssimazione ai minimi quadrati, si cerca un surrogato \\tilde f(x) per una funzione o per un insieme di dati (x_i, y_i), dove i = 0, 1, ..., n. Per semplicità, questo surrogato viene spesso scelto come un polinomio di grado m, indicato come \\tilde f(x).\nUna differenza fondamentale rispetto all’interpolazione è che il grado m del polinomio approssimante è indipendente dal numero di dati n+1. Mentre nell’interpolazione di Lagrange, un set di n+1 dati determina un polinomio di grado al più n, nell’approssimazione ai minimi quadrati si può scegliere un grado m qualsiasi, che tipicamente è molto minore di n (m \\ll n).\nIl polinomio \\tilde f(x) di grado m che realizza l’approssimazione ai minimi quadrati è definito come quel polinomio che minimizza la somma dei quadrati degli scarti tra i valori dei dati y_i e i valori del polinomio approssimante \\tilde f(x_i) nei punti x_i. Matematicamente, \\tilde f(x) è tale che:\n\\qquad \\sum_{i=0}^{n} (y_i - f \\tilde(x_i))^2 \\le \\sum_{i=0}^{n} (y_i - p_m(x_i))^2\nper ogni polinomio p_m(x) di grado m.\nIn altre parole, tra tutti i possibili polinomi di grado m, \\tilde f(x) è quello che rende minima la somma dei quadrati delle differenze verticali tra i punti dati e la curva del polinomio. Questo approccio è ampiamente utilizzato in statistica.\nÈ importante notare che la scelta di un polinomio come funzione approssimante è fatta per semplicità e praticità; si potrebbero utilizzare anche combinazioni lineari di altre funzioni, come funzioni sinusoidali o esponenziali. Inoltre, nell’approssimazione, in generale, non si ha più l’esatta corrispondenza tra y_i e \\tilde f (x_i).\nCaso Particolare: m = n (Relazione con l’Interpolazione)\nConsideriamo ora cosa succede quando il grado m del polinomio ai minimi quadrati viene scelto uguale a n, il numero di dati meno uno. In questo caso, la somma degli scarti quadratici, \\sum_{i=0}^{n} (y_i - \\tilde f(x_i))^2, è una somma di termini non negativi (essendo quadrati). Il suo valore minimo possibile è zero.\nQuesta somma è zero se e solo se ogni singolo termine è zero, cioè se y_i - \\tilde f(x_i) = 0 per tutti gli i = 0, 1, ..., n. Ciò significa che \\tilde f(x_i) = y_i per tutti i punti dati, che è esattamente la definizione di interpolazione.\nQuindi, l’interpolazione è un caso particolare dell’approssimazione ai minimi quadrati quando il grado del polinomio approssimante è uguale al grado del polinomio interpolante (per n+1 dati, grado n).\nQuesto giustifica la sintassi della funzione polyfit (presumibilmente in un software come MATLAB o Python), che accetta come argomenti le coordinate x, le coordinate y, e il grado n del polinomio. Specificando il grado n (o la lunghezza di x o y meno 1), si esegue di fatto un’interpolazione polinomiale. Il nome “fit” (adattamento) suggerisce l’idea generale di approssimazione, ma includendo il grado massimo possibile, si ricade nel caso dell’interpolazione.\nIl Caso m = 1: La Retta di Regressione\nUn caso particolarmente importante di approssimazione ai minimi quadrati è quando il grado del polinomio è m = 1. In questo caso, si cerca una retta che meglio approssimi i dati, ed è nota come retta di regressione. Questo è un concetto fondamentale in statistica.\nFormulazione del Problema di Minimizazione\nIl problema di trovare l’approssimazione ai minimi quadrati si traduce in un problema di minimizzazione. Si desidera trovare i coefficienti a_0, a_1, ..., a_m del polinomio \\tilde f(x) = a_0 + a_1 x + ... + a_m x^m che minimizzano la funzione f(b_0, b_1, ..., b_m) definita come la somma dei quadrati degli scarti:\n\\qquad f(b_0, b_1, ..., b_m) = \\sum_{i=0}^{n} (y_i - p_m(x_i))^2 = \\sum_{i=0}^{n} (y_i - (b_0 + b_1 x_i + ... + b_m x_i^m))^2\ndove b_0, b_1, ..., b_m sono i coefficienti di un generico polinomio p_m(x) di grado m. L’obiettivo è trovare i valori dei coefficienti a_0, a_1, ..., a_m che rendono minima questa funzione.\nPer trovare il minimo di una funzione di più variabili, si calcolano le derivate parziali rispetto a ciascuna variabile (in questo caso, i coefficienti b_0, b_1, ..., b_m) e si impone che queste derivate siano uguali a zero. Le soluzioni di questo sistema di equazioni daranno i valori a_0, a_1, ..., a_m che definiscono il polinomio ai minimi quadrati \\tilde f(x).\nCalcolo della Retta di Regressione (m = 1)\nConsideriamo il caso della retta di regressione, dove m = 1. Il polinomio approssimante è \\tilde f(x) = a_0 + a_1 x, e il generico polinomio di grado 1 è p_1(x) = b_0 + b_1 x. La funzione da minimizzare è:\n\\qquad f(b_0, b_1) = \\sum_{i=0}^{n} (y_i - b_0 - b_1 x_i)^2\nEspandendo il quadrato, otteniamo:\n\\qquad f(b_0, b_1) = \\sum_{i=0}^{n} (y_i^2 + b_0^2 + b_1^2 x_i^2 - 2 y_i b_0 - 2 y_i b_1 x_i + 2 b_0 b_1 x_i)\nOra calcoliamo le derivate parziali di f rispetto a b_0 e b_1:\n\\qquad \\frac{\\partial f}{\\partial b_0} = \\sum_{i=0}^{n} (2 b_0 - 2 y_i + 2 b_1 x_i)\n\\qquad \\frac{\\partial f}{\\partial b_1} = \\sum_{i=0}^{n} (2 b_1 x_i^2 - 2 y_i x_i + 2 b_0 x_i)\nImponendo che queste derivate parziali valutate in a_0 e a_1 siano uguali a zero:\n\\qquad \\sum_{i=0}^{n} (2 a_0 - 2 y_i + 2 a_1 x_i) = 0\n\\qquad \\sum_{i=0}^{n} (2 a_1 x_i^2 - 2 y_i x_i + 2 a_0 x_i) = 0\nDividendo per 2 e riorganizzando le somme, otteniamo un sistema di due equazioni lineari nelle due incognite a_0 e a_1:\n\\qquad \\sum_{i=0}^{n} a_0 - \\sum_{i=0}^{n} y_i + \\sum_{i=0}^{n} a_1 x_i = 0 \\implies a_0 \\sum_{i=0}^{n} 1 + a_1 \\sum_{i=0}^{n} x_i = \\sum_{i=0}^{n} y_i\n\\qquad \\sum_{i=0}^{n} a_1 x_i^2 - \\sum_{i=0}^{n} y_i x_i + \\sum_{i=0}^{n} a_0 x_i = 0 \\implies a_0 \\sum_{i=0}^{n} x_i + a_1 \\sum_{i=0}^{n} x_i^2 = \\sum_{i=0}^{n} y_i x_i\nQuesto sistema può essere scritto in forma matriciale come B \\mathbf{a} = \\mathbf{f}, dove \\mathbf{a} = \\begin{pmatrix} a_0 \\ a_1 \\end{pmatrix} è il vettore delle incognite, e:\n\\qquad B = \\begin{pmatrix} \\sum_{i=0}^{n} 1 &amp; \\sum_{i=0}^{n} x_i \\\\ \\sum_{i=0}^{n} x_i &amp; \\sum_{i=0}^{n} x_i^2 \\end{pmatrix} = \\begin{pmatrix} n+1 &amp; \\sum_{i=0}^{n} x_i \\\\ \\sum_{i=0}^{n} x_i &amp; \\sum_{i=0}^{n} x_i^2 \\end{pmatrix}\n\\qquad \\mathbf{f} = \\begin{pmatrix} \\sum_{i=0}^{n} y_i \\ \\sum_{i=0}^{n} y_i x_i \\end{pmatrix}\nLa matrice B è simmetrica. Risolvendo questo sistema lineare, si ottengono i coefficienti a_0 (l’intercetta) e a_1 (la pendenza) della retta di regressione.\nGeneralizzazione al Caso di Grado m\n\nPer un polinomio approssimante di grado m, \\tilde f(x) = a_0 + a_1 x + ... + a_m x^m, il vettore delle incognite è \\mathbf{a} = \\begin{pmatrix} a_0 \\ a_1 \\ \\vdots \\ a_m \\end{pmatrix}. Il sistema di equazioni normali che si ottiene imponendo le derivate parziali a zero è dato da B \\mathbf{a} = \\mathbf{f}, dove la matrice B di dimensione (m+1) \\times (m+1) ha elementi:\n\\qquad B_{jk} = \\sum_{i=0}^{n} x_i^{j+k}\nper j, k = 0, 1, ..., m. Il vettore del termine noto \\mathbf{f} di dimensione (m+1) \\times 1 ha elementi:\n\\qquad f_j = \\sum_{i=0}^{n} y_i x_i^j\nper j = 0, 1, ..., m.\nAd esempio, per una parabola di regressione (m=2), il sistema sarebbe:\n\\qquad \\begin{pmatrix} \\sum_{i=0}^{n} x_i^0 &amp; \\sum_{i=0}^{n} x_i^1 &amp; \\sum_{i=0}^{n} x_i^2 \\\\ \\sum_{i=0}^{n} x_i^1 &amp; \\sum_{i=0}^{n} x_i^2 &amp; \\sum_{i=0}^{n} x_i^3 \\\\ \\sum_{i=0}^{n} x_i^2 &amp; \\sum_{i=0}^{n} x_i^3 &amp; \\sum_{i=0}^{n} x_i^4 \\end{pmatrix} \\begin{pmatrix} a_0 \\\\ a_1 \\\\ a_2 \\end{pmatrix} = \\begin{pmatrix} \\sum_{i=0}^{n} y_i \\\\ \\sum_{i=0}^{n} y_i x_i \\\\ \\sum_{i=0}^{n} y_i x_i^2 \\end{pmatrix}\nQuesto sistema di equazioni lineari è noto come il sistema delle equazioni normali. La matrice B è simmetrica e definita positiva. La risoluzione di questo sistema permette di trovare i coefficienti del polinomio ai minimi quadrati di grado m che meglio approssima i dati.\nConclusione\nL’approssimazione ai minimi quadrati è uno strumento fondamentale per analizzare dati, specialmente quando questi sono rumorosi o si desidera estrapolare tendenze. Essa generalizza il concetto di interpolazione e porta alla risoluzione di un sistema di equazioni lineari noto come sistema delle equazioni normali. Questo argomento conclude la parte relativa all’approssimazione di dati e funzioni per il primo parziale.\nReferences\nAppunti Mate Num-lez13.pdf"},"6--full-note/mateNum--Lez14":{"slug":"6--full-note/mateNum--Lez14","filePath":"6- full note/mateNum- Lez14.md","title":"mateNum- Lez14","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/matematica-numerica","paste/Appunti-Mate-Num-1.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-19 15:08\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags. sbobine  matematica numerica\nmateNum- Lez14\nSistemi Rettangolari (Sistemi Indeterminati)\n\n\nIntroduzione Generalmente, nei corsi si affrontano sistemi lineari con un numero uguale di equazioni e incognite. Tuttavia, esistono sistemi in cui il numero di equazioni è diverso dal numero di incognite. Questi sono chiamati sistemi rettangolari o sistemi indeterminati. Si parla sempre di sistemi nella forma matriciale Ax = b.\n\n\nDimensioni degli Oggetti nel Sistema Ax=b In questo contesto, la matrice A non è quadrata, ma ha dimensioni m \\times n.\n\nLa matrice A \\in \\mathbb{R}^{m \\times n}.\nIl termine noto b \\in \\mathbb{R}^m.\nIl vettore delle incognite x \\in \\mathbb{R}^n. Di conseguenza, la matrice A e i vettori x e b non appartengono necessariamente agli stessi spazi.\n\n\n\nClassificazione dei Sistemi Rettangolari La relazione tra m (numero di equazioni) e n (numero di incognite) determina due casi principali.\n\n\nCaso Sottodeterminato (m &lt; n)\n\nIn questo caso, il numero di equazioni (m) è minore del numero di incognite (n).\nLa matrice A ha meno righe che colonne.\nGeometricamente, questo può essere paragonato a chiedere a una retta di passare per un solo punto; ci sono infinite rette che soddisfano questa condizione.\nIn generale, mancano informazioni per garantire esistenza e unicità della soluzione classica. Si è “sotto misure”.\n\n\n\n\nCaso Sovradeterminato (m &gt; n)\n\nIn questo caso, il numero di equazioni (m) è maggiore del numero di incognite (n).\nLa matrice A ha più righe che colonne.\nGeometricamente, questo può essere paragonato a chiedere a una retta di passare per 100 punti anziché per i due necessari a definirla univocamente. C’è una “sovrabbondanza di informazioni”.\nIn generale, ci sono troppe richieste.\n\n\n\n\n\n\nSoluzione Classica e Sistemi Indeterminati In generale, un sistema indeterminato (sia sovra che sottodeterminato) non ha una soluzione nel senso classico del termine. La definizione di soluzione deve essere modificata per dare significato alla scrittura Ax=b.\n\nCondizione per l’Esistenza di una Soluzione Classica: L’unica eccezione in cui un sistema indeterminato può avere una soluzione nel senso classico è se il termine noto b appartiene al range di A.\nDefinizione di Range(A): Il range di A (o spazio delle immagini di A) è l’insieme di tutti i vettori y \\in \\mathbb{R}^m per i quali esiste almeno un vettore x \\in \\mathbb{R}^n tale che Ax = y. Se b \\in Range(A), allora esiste almeno una x tale che Ax=b.\n\n\n\n\nModifica della Definizione di Soluzione\n\n\nNecessità di un Nuovo Concetto di Soluzione Poiché i sistemi indeterminati spesso non ammettono soluzioni nel senso classico, è necessario modificare la definizione di “soluzione”.\n\nNel caso sottodeterminato (m &lt; n), si tenderà verso una definizione “vincolata”.\nNel caso sovradeterminato (m &gt; n), si tenderà verso una definizione basata sull’approssimazione nel senso dei minimi quadrati. Questo è l’argomento su cui ci si concentra inizialmente.\n\n\n\nRichiamo (non direttamente applicato alla nuova definizione): Teorema di Rouché-Capelli Il teorema di Rouché-Capelli è il teorema classico per l’analisi dell’esistenza e unicità delle soluzioni per sistemi lineari, incluse configurazioni non quadrate nel senso classico.\n\nSchemino riassuntivo: Dato il sistema Ax=b:\n\nSe rank(A) \\neq rank([A|b]) (dove [A|b] è la matrice orlata con il vettore b):\n- Non ci sono soluzioni (nel senso classico).\nSe rank(A) = rank([A|b]): Ci sono soluzioni. In questo caso, ci sono due sottocasi:\n\nSe rank(A) = n (numero di incognite/colonne di A): C’è una e una sola soluzione.\nSe rank(A) &lt; n: Ci sono infinite soluzioni.\n\n\n\n\nIl rango di A gioca un ruolo fondamentale nell’esistenza e unicità della soluzione classica.\n\n\n\nSoluzione nel Senso dei Minimi Quadrati per Sistemi Sovradeterminati (m &gt; n)\n\n\nNuova Definizione Dato un sistema sovradeterminato Ax = b, un vettore x^* \\in \\mathbb{R}^n è detto soluzione nel senso dei minimi quadrati se minimizza la norma al quadrato del residuo Ax - b.\n\nIn termini matematici: \\bar x è la soluzione nel senso dei minimi quadrati se \\bar x è l’argomento che minimizza la quantità ||Ax - b||^2 al variare di x \\in \\mathbb{R}^n.\nSi scrive: x^* = \\arg\\min_{x \\in \\mathbb{R}^n} ||Ax - b||^2.\n\nQuesta definizione equivale a dire che ||Ax^* - b||^2 \\le ||Ax - b||^2 per ogni x \\in \\mathbb{R}^n.\n\n\n\n\nTrovare il Vettore che Minimizza: Metodo del Gradiente Per trovare il vettore \\bar x che minimizza la funzione f(x) = \\frac{1}{2}||Ax - b||^2 (la costante \\frac{1}{2} non cambia la posizione del minimo), si può utilizzare il metodo del gradiente, ponendo il gradiente della funzione uguale a zero nel punto di minimo \\bar x.\n\nDimostrazione: Calcolo del Gradiente di f(x)\nPer trovare il vettore x^* che realizza questo minimo, si considera la funzione obiettivo f(\\mathbf{x}) = \\frac{1}{2}|\\mathbf{A}\\mathbf{x} - \\mathbf{b}|^2. Il minimo di questa funzione, essendo una funzione quadratica e convessa, si trova imponendo che il suo gradiente, valutato in x^*, sia uguale al vettore nullo: \\nabla f(\\mathbf{x}^*) = \\mathbf{0} \\quad Procediamo con il calcolo del gradiente. La funzione f(\\mathbf{x}) può essere scritta usando il prodotto scalare: f(\\mathbf{x}) = \\frac{1}{2} (\\mathbf{A}\\mathbf{x} - \\mathbf{b})^{\\top} (\\mathbf{A}\\mathbf{x} - \\mathbf{b}) \\quad Espandendo il prodotto matriciale: f(\\mathbf{x}) = \\frac{1}{2} (\\mathbf{x}^{\\top}\\mathbf{A}^{\\top}\\mathbf{A}\\mathbf{x} - \\mathbf{x}^{\\top}\\mathbf{A}^{\\top}\\mathbf{b} - \\mathbf{b}^{\\top}\\mathbf{A}\\mathbf{x} + \\mathbf{b}^{\\top}\\mathbf{b}) \\quad Poiché \\mathbf{x}^{\\top}\\mathbf{A}^{\\top}\\mathbf{b} e \\mathbf{b}^{\\top}\\mathbf{A}\\mathbf{x} sono scalari e uno è il trasposto dell’altro, sono uguali (\\mathbf{x}^{\\top}\\mathbf{A}^{\\top}\\mathbf{b} = (\\mathbf{b}^{\\top}\\mathbf{A}\\mathbf{x})^{\\top} = \\mathbf{b}^{\\top}\\mathbf{A}\\mathbf{x}). Combinando i termini: f(\\mathbf{x}) = \\frac{1}{2} (\\mathbf{x}^{\\top}\\mathbf{A}^{\\top}\\mathbf{A}\\mathbf{x} - 2\\mathbf{x}^{\\top}\\mathbf{A}^{\\top}\\mathbf{b} + \\mathbf{b}^{\\top}\\mathbf{b}) \\quad Calcolando il gradiente di f(\\mathbf{x}) rispetto al vettore \\mathbf{x}: \\nabla f(\\mathbf{x}) = \\frac{1}{2} (2\\mathbf{A}^{\\top}\\mathbf{A}\\mathbf{x} - 2\\mathbf{A}^{\\top}\\mathbf{b} + \\mathbf{0}) = \\mathbf{A}^{\\top}\\mathbf{A}\\mathbf{x} - \\mathbf{A}^{\\top}\\mathbf{b} \\quad Imponendo che il gradiente sia nullo nel punto di minimo x^*: \\nabla f(x^*) = \\mathbf{A}^{\\top}\\mathbf{A}\\mathbf{x}^* - \\mathbf{A}^{\\top}\\mathbf{b} = \\mathbf{0} \\quad Si ottiene il sistema lineare noto come sistema delle equazioni normali: \\mathbf{A}^{\\top}\\mathbf{A}\\mathbf{x}^* = \\mathbf{A}^{\\top}\\mathbf{b} \\quad Questo è un sistema lineare con una matrice quadrata \\mathbf{B} = \\mathbf{A}^{\\top}\\mathbf{A} di dimensioni n \\times n e un vettore termine noto \\mathbf{F} = \\mathbf{A}^{\\top}\\mathbf{b}. È un sistema “determinato” del tipo \\mathbf{B}\\mathbf{x}^* = \\mathbf{F}.\n\n\n\n\nEsistenza e Unicità della Soluzione delle Equazioni Normali Un sistema quadrato B x^* = F ha una soluzione unica se e solo se la matrice B è invertibile. Nel nostro caso, B = A^T A.\n\nProposizione: La matrice A^T A è invertibile se e solo se il rango della matrice A è uguale al numero delle sue colonne (n). Cioè, A^T A è invertibile \\iff rank(A) = n.\nQuesta condizione rank(A) = n significa che le colonne della matrice A sono linearmente indipendenti.\nPertanto, la soluzione nel senso dei minimi quadrati x^* esiste ed è unica se e solo se la matrice A ha rango massimo per colonne (rank(A)=n).\n\n\n\nProprietà della Matrice A^T A Se A ha rango massimo per colonne (rank(A) = n), allora la matrice A^T A non è solo invertibile, ma è anche simmetrica definita positiva (SPD).\n\nSimmetrica: (A^T A)^T = A^T (A^T)^T = A^T A.\nDefinita Positiva (quando rank(A)=n): Per ogni vettore non nullo z, z^T (A^T A) z = (Az)^T (Az) = ||Az||^2 &gt; 0. È maggiore di zero perché se Az=0, dato che A ha colonne linearmente indipendenti (perché rank(A)=n), l’unica soluzione è z=0. Quindi per z \\neq 0, Az \\neq 0 e ||Az||^2 &gt; 0.\n\n\n\nMetodi di Risoluzione per il Sistema delle Equazioni Normali Dato che la matrice A^T A è SPD (assumendo rank(A)=n), si possono utilizzare metodi specifici e efficienti per risolvere il sistema A^T A x^* = A^T b.\n\nMetodo Diretto: Scomposizione di Cholesky.\nMetodo Iterativo: Metodo del Gradiente Coniugato (o altri metodi della famiglia del gradiente, come il Gradiente). Il Gradiente Coniugato è generalmente preferibile perché più “furbo”.\n\n\n\n\nConnessione con Argomenti Precedenti Il sistema A^T A x^* = A^T b è chiamato sistema delle equazioni normali. Questo stesso nome è stato usato precedentemente (ad esempio, nel contesto della regressione lineare o polinomiale con minimi quadrati). Esiste un legame tra il sistema discusso qui e quello utilizzato per la retta di regressione.\n\n\nProblemi Numerici con le Equazioni Normali Sebbene la trasformazione nel sistema A^T A x^* = A^T b sembri vantaggiosa perché produce un sistema quadrato, presenta seri problemi a causa degli errori di arrotondamento (floating-point errors).\n\n\nCriticità: L’accumulazione degli errori di arrotondamento può causare due problemi principali:\n\nLa matrice A^T A calcolata in floating-point potrebbe non risultare SDP.\nAncora peggio, anche se A ha rango massimo per colonne in aritmetica esatta, la matrice A^T A calcolata in floating-point potrebbe perdere l’invertibilità, diventando singolare.\n\n\n\nEsempio del Problema Numerico: Consideriamo una semplice matrice A di dimensioni 3 \\times 2: A = \\begin{pmatrix} 1 &amp; 1 \\\\ 2^{-27} &amp; 0 \\\\ 0 &amp; 2^{-27} \\end{pmatrix} In aritmetica esatta, questa matrice ha rango 2 (le colonne sono linearmente indipendenti), quindi rank(A)=n=2. In teoria, A^T A dovrebbe essere invertibile. Calcoliamo A^T A: A^T = \\begin{pmatrix} 1 &amp; 2^{-27} &amp; 0 \\\\ 0 &amp; 0 &amp; 2^{-27} \\end{pmatrix} A^T A = \\begin{pmatrix} 1 &amp; 2^{-27} &amp; 0 \\\\ 0 &amp; 0 &amp; 2^{-27} \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 \\\\ 2^{-27} &amp; 0 \\\\ 0 &amp; 2^{-27} \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 1 + 2^{-27} \\cdot 2^{-27} + 0 \\cdot 0 &amp; 1 \\cdot 0 + 2^{-27} \\cdot 0 + 0 \\cdot 2^{-27} \\\\ 0 \\cdot 1 + 0 \\cdot 2^{-27} + 2^{-27} \\cdot 0 &amp; 0 \\cdot 0 + 0 \\cdot 0 + 2^{-27} \\cdot 2^{-27} \\end{pmatrix} A^T A = \\begin{pmatrix} 1 + 2^{-54} &amp; 0 \\ 0 &amp; 2^{-54} \\end{pmatrix} In aritmetica esatta, questa matrice è diagonale e invertibile. Tuttavia, se si calcola la rappresentazione in floating-point (ad esempio, in singola precisione dove l’epsilon di macchina è circa 2^{-24}), valori molto piccoli come 2^{-54} possono essere considerati zero rispetto all’unità. La rappresentazione floating-point di A^T A potrebbe risultare: fl(A^T A) = \\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0 \\end{pmatrix} Questa matrice floating-point è singolare (non invertibile) perché ha una riga (o colonna) di zeri. Questo dimostra che, a causa degli errori di arrotondamento, il metodo delle equazioni normali può fallire nel fornire una matrice invertibile, anche per matrici A piccole e apparentemente ben condizionate.\n\n\n\n\n\nConclusione: La Strada delle Equazioni Normali è Problematicamente Sebbene la trasformazione in un sistema quadrato A^T A x^* = A^T b sia un primo passo, questo sistema è “fortemente problematico” dal punto di vista numerico a causa degli errori di arrotondamento. Pertanto, calcolare x^* risolvendo direttamente il sistema delle equazioni normali non è la strada giusta.\n\n\nMetodo Alternativo: Fattorizzazione QR\n\n\nDato che il metodo basato sulle Equazioni Normali è numericamente instabile, è necessario un approccio differente per calcolare x^*.\n\n\nQuesto approccio alternativo sarà la fattorizzazione QR\n\n\n\nFattorizzazione QR\nSi parla della fattorizzazione QR, spesso menzionata quando si studiano gli autovalori. Si tratta di un concetto diverso dalla fattorizzazione di Cholesky e dal gradiente coniugato.\nDefinizione di Fattorizzazione QR\nSia A una matrice in \\mathbb{R}^{m \\times n} con un numero di righe maggiore del numero di colonne\n(m &gt; n).\nSi dice che la matrice A ammette una fattorizzazione QR se esistono:\n\nUna matrice Q \\in \\mathbb{R}^{m \\times m} che è ortogonale. Una matrice è ortogonale se la sua trasposta coincide con la sua inversa, ovvero Q^T Q = Q Q^T = I, dove I è la matrice identità.\nUna matrice R \\in \\mathbb{R}^{m \\times n} che è trapezoidale.\n\nLa relazione che lega queste matrici è A = QR.\nStruttura della Matrice R\nLa matrice R ha dimensioni m \\times n, le stesse della matrice A. La sua struttura è triangolare superiore nella sottoparte quadrata di dimensioni n \\times n e contiene un blocco di zeri nelle righe da n+1 a m.\nGraficamente, la matrice A (m \\times n) è il prodotto di Q (m \\times m) e R (m \\times n): A_{m \\times n} = Q_{m \\times m} R_{m \\times n}\nLa matrice R ha la seguente struttura: R = \\begin{bmatrix} R_{n \\times n}^{superiore} \\ \\mathbf{0}_{(m-n) \\times n} \\end{bmatrix} dove R_{n \\times n}^{superiore} è una matrice triangolare superiore di dimensione n \\times n, e \\mathbf{0}_{(m-n) \\times n} è un blocco di zeri di dimensione (m-n) \\times n. Le entrate dalla riga n+1 alla riga m sono identicamente nulle. Questa struttura la rende “trapezoidale”.\n\nProblema dell’Unicità della Fattorizzazione QR\nLa fattorizzazione QR di una matrice A esiste sempre, ma il problema è che non è unica. Avere un oggetto che può essere rappresentato in modi diversi non è sempre agevole, specialmente se si intende utilizzare questa fattorizzazione per trovare la soluzione ai minimi quadrati (x^*).\nIntroduzione alla Fattorizzazione QR Ridotta\nPer ovviare al problema dell’unicità, si utilizza una versione ridotta della fattorizzazione QR. Questa versione ridotta si ottiene ritagliando parti delle matrici Q e R originali.\nLa fattorizzazione QR ridotta esiste e, in certe condizioni, è unica. Questa fattorizzazione ridotta verrà poi utilizzata per calcolare x^*.\nCondizioni per l’Unicità della Fattorizzazione QR Ridotta\nLa fattorizzazione QR ridotta esiste e risulta unica quando sono soddisfatte due condizioni:\n\nIl rango della matrice A è massimo, cioè è uguale a n.\nTutte le entrate sulla diagonale principale della matrice \\tilde{R} (la parte ridotta di R) risultano essere strettamente positive.\n\nDefinizione di Fattorizzazione QR Ridotta\nSupponiamo di avere una matrice A \\in \\mathbb{R}^{m \\times n} con m &gt; n e con rango pari a n. Supponiamo inoltre di conoscere la fattorizzazione QR di A, ovvero A = QR.\nEsiste unica (sotto le condizioni menzionate) una fattorizzazione ridotta che permette di scrivere A come prodotto di due oggetti, chiamati \\tilde{Q} e \\tilde{R}: A = \\tilde{Q} \\tilde{R}\nDove:\n\n\\tilde{Q} è una matrice in \\mathbb{R}^{m \\times n}.\n\\tilde{R} è una matrice in \\mathbb{R}^{n \\times n}.\n\nCome ottenere \\tilde{Q} e \\tilde{R} dalla Fattorizzazione QR standard\n\\tilde{Q} e \\tilde{R} si ottengono come sottoparti di Q e R:\n\n\nMatrice \\tilde{Q}: \\tilde{Q} è la sottoporzione di Q che ha la stessa dimensionalità di A, ovvero m \\times n. Si ottiene prendendo le prime m righe e le prime n colonne di Q. In notazione Matlab-style: \\tilde{Q} = Q(1:m, 1:n). Questo significa prendere tutte le righe (dalla 1 alla m) e le prime n colonne (dalla 1 alla n) della matrice Q. Questa parte è il pezzo di Q che non corrisponde al blocco di zeri in R.\n\n\nMatrice \\tilde{R}: \\tilde{R} è la porzione “informativa” di R. Si ottiene selezionando le prime n righe e le prime n colonne di R. In notazione Matlab-style: \\tilde{R} = R(1:n, 1:n). Questo significa prendere le prime n righe (dalla 1 alla n) e le prime n colonne (dalla 1 alla n) della matrice R. Questa parte corrisponde alla sottoparte triangolare superiore di R. \\tilde{R} ha dimensione n \\times n ed è triangolare superiore.\n\n\n\nProprietà della Fattorizzazione QR Ridotta\nLa fattorizzazione A = \\tilde{Q} \\tilde{R} ha diverse proprietà importanti, oltre all’unicità (sotto le condizioni specificate):\n\nUnicità: Come già detto, sotto le condizioni di rango massimo per A e positività delle entrate diagonali di \\tilde{R}, la fattorizzazione ridotta è unica.\nOrtonormalità delle Colonne di \\tilde{Q}: Le colonne della matrice \\tilde{Q} sono ortonormali. Questo significa che sono ortogonali tra loro e hanno norma unitaria. La proprietà di ortonormalità è utile per costruire una base. Le colonne di \\tilde{Q} formano una base per lo spazio immagine (o “range”) della matrice A. Le colonne di \\tilde{Q} hanno m entrate.\nRelazione con la Fattorizzazione di Cholesky: Il fattore \\tilde{R} coincide con il fattore triangolare superiore (chiamato R) della fattorizzazione di Cholesky della matrice A^T A. La fattorizzazione di Cholesky si applica a matrici simmetriche e definite positive (SDP) e spacchetta una matrice M come M = R^T R (o LL^T). La matrice A^T A è una matrice SDP. Quindi, \\tilde{R} è tale che A^T A = \\tilde{R}^T \\tilde{R}. Questo lega la fattorizzazione QR ridotta alla fattorizzazione di Cholesky, un altro strumento per analizzare matrici.\n\n\nCalcolo Pratico della Fattorizzazione QR\nIl calcolo effettivo dei fattori Q e R (e di conseguenza \\tilde{Q} e \\tilde{R}) non è semplice e non viene dettagliato esplicitamente nelle fonti fornite, al di là di menzionare gli strumenti pratici.\n\nComando Matlab: Per essere pragmatici, esiste un comando built-in in Matlab chiamato qr che calcola questi oggetti. Questo comando può fornire sia la fattorizzazione estesa che quella ridotta; se fornisce quella estesa, si possono semplicemente ritagliare i pezzi necessari.\nAlgoritmo Sottostante: Dietro la costruzione di questi fattori c’è un algoritmo che dovrebbe essere conosciuto, l’algoritmo di ortonormalizzazione di Gram-Schmidt. Questo algoritmo si applica alle colonne della matrice A per ottenere le colonne ortonormali. Gram-Schmidt prende un insieme di vettori e li trasforma in una base ortonormale.\nCosto Computazionale: Il costo computazionale dell’algoritmo di Gram-Schmidt per ottenere la fattorizzazione QR è dell’ordine di O(m n^2). Questo costo è proporzionale alla dimensione più grande (m) e al quadrato della dimensione più piccola (n).\n\nUtilizzo della Fattorizzazione QR Ridotta per la Soluzione ai Minimi Quadrati (x^*)\nL’obiettivo principale dell’introduzione della fattorizzazione QR ridotta è trovare la soluzione ai minimi quadrati \\bar x del sistema lineare sovradeterminato Ax = b. Sappiamo che \\bar x è la soluzione del sistema delle equazioni normali A^T A x = A^T b.\nTeorema sulla Soluzione x^* tramite Fattorizzazione QR Ridotta\nProposizione (Teorema sulla soluzione x^* tramite QR ridotta)\nSia A \\in \\mathbb{R}^{m \\times n} con m &gt; n e supponiamo che A sia una matrice di rango pieno, ovvero \\text{rank}(A) = n.\nAllora, la soluzione del sistema delle equazioni normali A^T A x = A^T b esiste ed è unica, denotata con x^*.\nUna espressione esplicita per \\bar x è data da: \\bar x = \\tilde{R}^{-1} \\tilde{Q}^T b\nQuesta espressione mostra che x^* può essere calcolata usando i fattori della fattorizzazione QR ridotta, senza ricorrere alla fattorizzazione di Cholesky o al gradiente coniugato.\nInoltre, il valore della norma al quadrato del residuo r = b - A \\bar x calcolato in \\bar x può essere quantificato. La norma euclidea del residuo, |b - A x^*|, coincide con la norma euclidea del sottovettore ottenuto prendendo le ultime m-n entrate del vettore Q^T b. |b - A x^*|^2 = \\sum_{i=n+1}^{m} (Q^T b)_i^2 dove (Q^T b)_i è l’i-esima componente del vettore Q^T b. C’è un dubbio nella fonte se debba essere Q o \\tilde{Q} in questa formula del residuo, ma l’indicazione è che sia Q.\nPassaggi Pratici per Calcolare x^* (utilizzando Matlab)\nIn pratica, per calcolare x^*, si seguono questi passi:\n\nCalcolare la fattorizzazione QR: Usare il comando qr in Matlab per ottenere la fattorizzazione QR di A (anche quella estesa va bene).\nOttenere i fattori ridotti: Se si ottiene la fattorizzazione estesa A=QR, ricavare \\tilde{Q} e \\tilde{R} ritagliando i pezzi appropriati (prime n colonne di Q per \\tilde{Q}, prime n \\times n entrate di R per \\tilde{R}).\nCostruire il termine noto modificato: Calcolare il vettore \\tilde{Q}^T b.\nRisolvere il sistema triangolare: Invece di calcolare l’inversa di \\tilde{R} (che è computazionalmente costosa e meno stabile), si risolve il sistema lineare \\tilde{R} x^* = \\tilde{Q}^T b per trovare x^*.\nMetodo di Sostituzione all’Indietro: Dato che \\tilde{R} è una matrice triangolare superiore di dimensione n \\times n, questo sistema lineare può essere risolto in modo efficiente e stabile utilizzando il metodo delle sostituzioni all’indietro (o backward substitution).\n\nQuindi, in sintesi, calcolare x^* utilizzando la fattorizzazione QR ridotta implica l’uso del comando QR, l’eventuale ritaglio dei fattori, e la risoluzione di un sistema lineare triangolare con il metodo delle sostituzioni all’indietro.\n\nDimostrazione Parziale della Formula per x^*\nCaso 1: Matrice A a Rango Massimo\nQuando la matrice A ha rango massimo (cioè, il rango è uguale a n), è possibile utilizzare la fattorizzazione QR.\nUtilizzo della Fattorizzazione QR\nLa fattorizzazione QR permette di scrivere A come il prodotto di una matrice ortogonale Q (m \\times m) e una matrice R (m \\times n). La matrice R ha una struttura particolare: la parte superiore n \\times n, denotata R_{\\text{tilde}}, è triangolare superiore e invertibile, mentre le restanti m-n righe sono composte da zeri.\nA = QR\ndove Q è ortogonale (Q^T Q = I) e R = \\begin{bmatrix} R_{\\text{tilde}} \\ 0 \\end{bmatrix} con R_{\\text{tilde}} \\in \\mathbb{R}^{n \\times n} triangolare superiore e invertibile.\nApplicazione della Rotazione Q^T e Preservazione della Norma (Dimostrazione/Spiegazione)\nSi considera la norma del vettore residuo \\left|Ax - b\\right|. Un’operazione chiave è l’applicazione della matrice ortogonale Q^T al vettore Ax - b. Geometricamente, moltiplicare per una matrice ortogonale come Q^T corrisponde a una rotazione, e le rotazioni preservano la lunghezza (norma euclidea) di un vettore.\nPertanto, la norma del vettore Ax - b è uguale alla norma del vettore (Q^T)(Ax - b):\n\\left|Ax - b\\right| = \\left|Q^T(Ax - b)\\right|\nElevando al quadrato (poiché minimizzare la norma è equivalente a minimizzare il quadrato della norma), si ha:\n\\left|Ax - b\\right|^2 = \\left|Q^T(Ax - b)\\right|^2\nSi distribuisce Q^T:\n\\left|Q^T(Ax - b)\\right|^2 = \\left|Q^TAx - Q^Tb\\right|^2\nSostituendo A = QR e usando la proprietà di ortogonalità Q^TQ = I:\n\\left|Q^T(QRx) - Q^Tb\\right|^2 = \\left|(Q^TQ)Rx - Q^Tb\\right|^2 = \\left|IRx - Q^Tb\\right|^2 = \\left|Rx - Q^Tb\\right|^2\nQuindi, il problema di minimizzare \\left|Ax - b\\right|^2 è equivalente a minimizzare \\left|Rx - Q^Tb\\right|^2.\nScomposizione della Norma in Blocchi (Spiegazione)\nOra, si analizza la struttura del vettore Rx - Q^Tb.\nLa matrice R è m \\times n con la struttura a blocchi \\begin{bmatrix} R_{\\text{tilde}} \\ 0 \\end{bmatrix} dove R_{\\text{tilde}} è n \\times n e 0 è un blocco di zeri (m-n) \\times n. Quando si moltiplica R per il vettore x (n \\times 1), si ottiene un vettore m \\times 1:\nRx = \\begin{bmatrix} R_{\\text{tilde}} \\ 0 \\end{bmatrix} x = \\begin{bmatrix} R_{\\text{tilde}}x \\ 0 \\end{bmatrix}\nLa matrice Q^T è m \\times m. Il vettore b è m \\times 1. Il prodotto Q^Tb è un vettore m \\times 1. Si può partizionare Q^T (o Q^Tb) in due blocchi verticali in corrispondenza della dimensione n. Il primo blocco corrisponde alle prime n righe di Q^T, che sono le trasposte delle prime n colonne di Q, denotate Q_{\\text{tilde}}^T. Il secondo blocco corrisponde alle restanti m-n righe di Q^T, denotate Q_{\\text{rem}}^T.\nQ^Tb = \\begin{bmatrix} Q_{\\text{tilde}}^T \\ Q_{\\text{rem}}^T \\end{bmatrix} b = \\begin{bmatrix} Q_{\\text{tilde}}^T b \\ Q_{\\text{rem}}^T b \\end{bmatrix}\nQuindi, il vettore Rx - Q^Tb è:\nRx - Q^Tb = \\begin{bmatrix} R_{\\text{tilde}}x \\ 0 \\end{bmatrix} - \\begin{bmatrix} Q_{\\text{tilde}}^T b \\ Q_{\\text{rem}}^T b \\end{bmatrix} = \\begin{bmatrix} R_{\\text{tilde}}x - Q_{\\text{tilde}}^T b \\ -Q_{\\text{rem}}^T b \\end{bmatrix}\nLa norma euclidea al quadrato di questo vettore è la somma dei quadrati delle sue componenti. Poiché il vettore è diviso in due blocchi (il primo di dimensione n e il secondo di dimensione m-n), la norma al quadrato si scompone nella somma delle norme al quadrato di questi due blocchi:\n\\left|Rx - Q^Tb\\right|^2 = \\left|R_{\\text{tilde}}x - Q_{\\text{tilde}}^T b\\right|^2 + \\left|-Q_{\\text{rem}}^T b\\right|^2\nPoiché \\left|-v\\right|^2 = \\left|v\\right|^2, il secondo termine è \\left|Q_{\\text{rem}}^T b\\right|^2.\n\\left|Rx - Q^Tb\\right|^2 = \\left|R_{\\text{tilde}}x - Q_{\\text{tilde}}^T b\\right|^2 + \\left|Q_{\\text{rem}}^T b\\right|^2\nDeterminazione della Soluzione (Derivazione)\nDobbiamo minimizzare \\left|R_{\\text{tilde}}x - Q_{\\text{tilde}}^T b\\right|^2 + \\left|Q_{\\text{rem}}^T b\\right|^2 rispetto a x.\nIl termine \\left|Q_{\\text{rem}}^T b\\right|^2 non dipende da x. Pertanto, per minimizzare la somma totale, dobbiamo minimizzare il primo termine, \\left|R_{\\text{tilde}}x - Q_{\\text{tilde}}^T b\\right|^2.\nLa norma al quadrato di un vettore è sempre non negativa, e il suo valore minimo è zero. Possiamo rendere il primo termine uguale a zero se il sistema lineare R_{\\text{tilde}}x = Q_{\\text{tilde}}^T b ha una soluzione.\nPoiché A ha rango massimo, la matrice R_{\\text{tilde}} (che è il fattore triangolare superiore della QR di A) è invertibile. Questo garantisce che il sistema R_{\\text{tilde}}x = Q_{\\text{tilde}}^T b ha una soluzione unica.\nLa soluzione x_{\\text{star}} (o x_{\\text{tilde}} come inizialmente chiamato) che minimizza la norma del residuo è quella che soddisfa:\nR_{\\text{tilde}}x_{\\text{star}} = Q_{\\text{tilde}}^T b\n\nQuesta è un’equazione lineare quadrata n \\times n che può essere risolta per trovare x_{\\text{star}}.\nIl valore minimo del residuo al quadrato, ottenuto quando x = x_{\\text{star}}, è:\n\\min_{x} \\left|Ax - b\\right|^2 = \\left|R_{\\text{tilde}}x_{\\text{star}} - Q_{\\text{tilde}}^T b\\right|^2 + \\left|Q_{\\text{rem}}^T b\\right|^2\nPoiché R_{\\text{tilde}}x_{\\text{star}} - Q_{\\text{tilde}}^T b = 0, il primo termine si annulla. Quindi:\n\\min_{x} \\left|Ax - b\\right|^2 = 0^2 + \\left|Q_{\\text{rem}}^T b\\right|^2 = \\left|Q_{\\text{rem}}^T b\\right|^2\nQuesto valore residuo minimo è \\left|Q_{\\text{rem}}^T b\\right|^2.\nQuesto conclude il caso in cui la matrice A ha rango pieno.\nCaso 2: Matrice A non ha Rango Pieno\nA volte, la matrice A in un sistema sovradeterminato non ha rango pieno, cioè il suo rango è minore di n. In questo caso, la procedura basata sulla fattorizzazione QR descritta sopra non funziona direttamente, in particolare R_{\\text{tilde}} non sarebbe invertibile.\nPerdita di Unicità (Spiegazione)\nSe A non ha rango pieno, il problema di minimizzazione della norma del residuo non ha una soluzione unica. Se x_{\\text{star}} è un vettore che minimizza \\left|Ax - b\\right|^2, allora qualsiasi vettore della forma x_{\\text{star}} + z, dove z appartiene al nucleo (kernel) di A (\\text{ker}(A)), è anch’esso un minimizzatore. Il nucleo di A è l’insieme dei vettori z tali che Az = 0.\nInfatti, per z \\in \\text{ker}(A):\nA(x_{\\text{star}} + z) - b = Ax_{\\text{star}} + Az - b = Ax_{\\text{star}} + 0 - b = Ax_{\\text{star}} - b\nQuindi, \\left|A(x_{\\text{star}} + z) - b\\right| = \\left|Ax_{\\text{star}} - b\\right|, il che significa che x_{\\text{star}} + z produce lo stesso residuo minimo. Poiché il nucleo non contiene solo il vettore nullo quando il rango non è pieno, esistono infiniti minimizzatori.\nRecupero dell’Unicità tramite Vincolo Addizionale\nQuando un problema ha molteplici soluzioni che raggiungono lo stesso risultato ottimale (in questo caso, il minimo residuo), è comune aggiungere un vincolo per selezionare una soluzione unica.\nIl vincolo scelto in questo contesto è quello di cercare la soluzione che, tra tutte quelle che minimizzano il residuo, abbia la norma euclidea minima.\nDefinizione della Soluzione a Norma Minima del Minimo Quadrato (Definizione)\nLa soluzione desiderata, x_{\\text{star}}, è definita come il vettore in \\mathbb{R}^n tale che:\n\nMinimizza il residuo: \\left|Ax_{\\text{star}} - b\\right|^2 \\le \\left|Ax - b\\right|^2 per ogni x \\in \\mathbb{R}^n.\nTra tutti i vettori che soddisfano il punto 1, ha la norma minima: \\left|x_{\\text{star}}\\right| è minima.\n\nQuesta soluzione è unica.\nLa Decomposizione ai Valori Singolari (SVD)\nPer trovare questa soluzione a norma minima del minimo quadrato, si utilizza una generalizzazione della decomposizione agli autovalori e autovettori, chiamata Decomposizione ai Valori Singolari (SVD).\nLa SVD di una matrice A (m \\times n) è data da:\nA = U \\Sigma V^T\ndove:\n\nU è una matrice ortogonale m \\times m; le sue colonne sono i vettori singolari sinistri.\nV è una matrice ortogonale n \\times n; le sue colonne sono i vettori singolari destri.\n\\Sigma è una matrice m \\times n detta pseudo-diagonale. Contiene i valori singolari di A, denotati \\sigma_1, \\sigma_2, \\dots, \\sigma_p (dove p = \\min(m, n)), posti sulla diagonale principale. Per A m \\times n con m &gt; n, \\Sigma ha la forma \\begin{bmatrix} \\text{diag}(\\sigma_1, \\dots, \\sigma_n) \\ 0 \\end{bmatrix} dove \\text{diag}(\\sigma_1, \\dots, \\sigma_n) è n \\times n e 0 è un blocco di zeri (m-n) \\times n. I valori singolari sono solitamente ordinati in modo decrescente (\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_n \\ge 0) fonte non esplicitata, ma implicita nella struttura. Esiste un legame tra i valori singolari di A e gli autovalori di A^TA.\n\nLa SVD è più costosa computazionalmente rispetto alla fattorizzazione QR, con un costo proporzionale a 12 V n^3 (dove ‘V’ potrebbe essere una costante o un fattore legato alle dimensioni).\n\n\n\nLa Pseudo-Inversa (Definizione e Calcolo)\nLa soluzione x_{\\text{star}} a norma minima del minimo quadrato per il sistema Ax \\approx b si ottiene utilizzando la pseudo-inversa di A, denotata A^{\\dagger} (o A con un simbolo a croce).\nLa pseudo-inversa A^{\\dagger} di una matrice A con SVD A = U \\Sigma V^T è calcolata come:\nA^{\\dagger} = V \\Sigma^{\\dagger} U^T\ndove \\Sigma^{\\dagger} è la pseudo-inversa della matrice \\Sigma.\nCalcolo di \\Sigma^{\\dagger} (Definizione)\nLa matrice \\Sigma^{\\dagger} si ottiene da \\Sigma trasponendola e prendendo i reciproci dei valori singolari non nulli sulla diagonale. Se \\Sigma è m \\times n con valori singolari \\sigma_1, \\dots, \\sigma_n sulla diagonale (e zeri sotto, nel caso m&gt;n), allora \\Sigma^{\\dagger} è n \\times m con i valori 1/\\sigma_1, \\dots, 1/\\sigma_n sulla diagonale e zeri altrove.\nEsempio per m &gt; n: Se \\Sigma = \\begin{bmatrix} \\sigma_1 &amp; &amp; &amp; \\ &amp; \\sigma_2 &amp; &amp; \\ &amp; &amp; \\ddots &amp; \\ &amp; &amp; &amp; \\sigma_n \\ 0 &amp; 0 &amp; \\dots &amp; 0 \\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ 0 &amp; 0 &amp; \\dots &amp; 0 \\end{bmatrix}_{m \\times n}, allora \\Sigma^{\\dagger} = \\begin{bmatrix} 1/\\sigma_1 &amp; &amp; &amp; 0 &amp; \\dots &amp; 0 \\ &amp; 1/\\sigma_2 &amp; &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ &amp; &amp; \\ddots &amp; 0 &amp; \\dots &amp; 0 \\ &amp; &amp; &amp; 1/\\sigma_n &amp; 0 &amp; \\dots &amp; 0 \\end{bmatrix}_{n \\times m}.\nLa Soluzione x_{\\text{star}}\nUtilizzando la pseudo-inversa, la soluzione x_{\\text{star}} a norma minima del minimo quadrato è data da:\nx_{\\text{star}} = A^{\\dagger} b\nSostituendo la definizione di A^{\\dagger}:\nx_{\\text{star}} = V \\Sigma^{\\dagger} U^T b\nQuesto fornisce il metodo per risolvere sistemi sovradeterminati anche quando la matrice non ha rango pieno, definendo una soluzione unica tramite il criterio della norma minima tra i minimizzatori del residuo.\nReferences\nAppunti Mate Num 1.pdf"},"6--full-note/mateNum--Lez15":{"slug":"6--full-note/mateNum--Lez15","filePath":"6- full note/mateNum- Lez15.md","title":"mateNum- Lez15","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/matematica-numerica","3--tag/sbobine"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-24 09:27\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: matematica numerica  sbobine\nmateNum- Lez15\nReferences"},"6--full-note/mateNum--Lez16":{"slug":"6--full-note/mateNum--Lez16","filePath":"6- full note/mateNum- Lez16.md","title":"mateNum- Lez16","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/matematica-numerica","3--tag/sbobine","2--source-materials/mateNum--Lez16_trascrizione"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-25 10:33\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: matematica numerica  sbobine\nmateNum- Lez16\nIntroduzione al Contesto: Sistemi Indeterminati\nIniziamo col riprendere la classificazione dei sistemi lineari Ax=y, dove A è una matrice rettangolare m \\times n. Abbiamo distinto tra:\n\nSistemi Sovradeterminati: Caratterizzati da un numero di equazioni maggiore del numero di incognite, ovvero m &gt; n. Per questi sistemi, la definizione classica di soluzione non è sufficiente. Si è quindi passati alla ricerca della soluzione nel senso dei minimi quadrati, quella che minimizza la norma del residuo, ||Ax-y||^2. In questo contesto, abbiamo ulteriormente distinto il caso in cui la matrice A sia a rango pieno (rank(A)=n) e il caso in cui non lo sia. Per il caso a rango pieno, si è visto che la soluzione ai minimi quadrati si ottiene risolvendo le equazioni normali, che possono essere risolte con metodi diretti per matrici simmetriche definite positive o, per evitare errori numerici, tramite fattorizzazione QR. Nel caso non a rango massimo, la soluzione ai minimi quadrati non è unica, e si cerca quella a norma minima, introducendo concetti legati, apparentemente, alla SVD (indicata come ST).\nSistemi Sottodeterminati: Caratterizzati da un numero di equazioni minore del numero di incognite, ovvero m &lt; n. Di questi sistemi si dirà meno inizialmente.\n\nAbbiamo menzionato le equazioni normali in due momenti distinti:\n\nQuando abbiamo studiato la retta di regressione e la sua generalizzazione (l’approssimazione polinomiale ai minimi quadrati).\nQuando abbiamo trattato i sistemi sovradeterminati a rango pieno, trovando la soluzione ai minimi quadrati.\n\nL’obiettivo ora è dimostrare che si tratta della stessa cosa.\nRichiamo sull’Approssimazione Polinomiale ai Minimi Quadrati\nRicordiamo la definizione del polinomio f_T(x) di grado m che approssima un set di dati (x_i, y_i) per i=0, \\dots, n nel senso dei minimi quadrati. Questo polinomio è identificato dai suoi coefficienti a_0, a_1, \\dots, a_m.\nIl polinomio f_T(x) è caratterizzato dalla proprietà di minimizzare la somma degli scarti quadratici. Questo significa che, dati i punti (x_i, y_i), il polinomio f_T(x) valutato in x_i, ossia f_T(x_i), rende minima la quantità: \\sum_{i=0}^n (y_i - f_T(x_i))^2 Questa quantità è minima quando i coefficienti del polinomio p_m(x) = b_0 + b_1 x + \\dots + b_m x^m (un generico polinomio di grado m con coefficienti b_0, \\dots, b_m) coincidono con i coefficienti a_0, \\dots, a_m del polinomio f_T(x). Quindi, stiamo cercando il vettore di coefficienti A = [a_0, a_1, \\dots, a_m]^T che realizza il minimo, al variare del vettore B = [b_0, b_1, \\dots, b_m]^T \\in \\mathbb{R}^{m+1}, della somma degli scarti quadratici: \\sum_{i=0}^n (y_i - (b_0 + b_1 x_i + \\dots + b_m x_i^m))^2 Tradizionalmente, questo problema è stato risolto definendo una funzione F(b_0, \\dots, b_m) = \\sum_{i=0}^n (y_i - (b_0 + b_1 x_i + \\dots + b_m x_i^m))^2 e cercando i valori di b_j che annullano le derivate parziali \\frac{\\partial F}{\\partial b_j} per j=0, \\dots, m. Quando queste derivate sono valutate nei coefficienti a_j, sono uguali a zero. Questa procedura porta al sistema di equazioni normali per i coefficienti a_j.\n\n==Espressione Vettoriale del Problema di Minimizzazione\nOra, riscriviamo questa somma di scarti quadratici in forma vettoriale.\nPassaggio Chiave: Riconoscere la Norma Euclidea\nLa somma di oggetti al quadrato, come \\sum_{i=0}^n (\\text{qualcosa}_i)^2, può essere interpretata come il quadrato della norma euclidea di un vettore le cui componenti sono quel “qualcosa”. Se abbiamo un vettore W = [w_0, w_1, \\dots, w_n]^T, la sua norma euclidea al quadrato è ||W||^2 = \\sum_{i=0}^n w_i^2.\nNel nostro caso, le quantità al quadrato sono (y_i - (b_0 + b_1 x_i + \\dots + b_m x_i^m)). Queste possono essere viste come le componenti i-esime di un vettore. Questo vettore è la differenza tra due vettori:\n\nIl primo vettore ha le componenti y_i. Possiamo definire il vettore dei dati Y = [y_0, y_1, \\dots, y_n]^T.\nIl secondo vettore ha le componenti (b_0 + b_1 x_i + \\dots + b_m x_i^m). Questa forma è tipica di un prodotto riga per colonna in un’operazione matrice-vettore.\n\nDefinizione della Matrice di Vandermonde\nDefiniamo la matrice A (che in questo contesto, per distinguere, chiameremo V per Vandermonde, anche se il source la chiama A) come la matrice (n+1) \\times (m+1) le cui entrate sono V_{i,j} = x_i^j per i=0, \\dots, n e j=0, \\dots, m. Ricordando che x^0 = 1, la matrice ha la seguente struttura: V = \\begin{pmatrix} x_0^0 &amp; x_0^1 &amp; \\dots &amp; x_0^m \\ x_1^0 &amp; x_1^1 &amp; \\dots &amp; x_1^m \\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ x_n^0 &amp; x_n^1 &amp; \\dots &amp; x_n^m \\end{pmatrix} = \\begin{pmatrix} 1 &amp; x_0 &amp; \\dots &amp; x_0^m \\ 1 &amp; x_1 &amp; \\dots &amp; x_1^m \\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ 1 &amp; x_n &amp; \\dots &amp; x_n^m \\end{pmatrix} Questa è la matrice di Vandermonde.\nDefiniamo il vettore dei coefficienti del generico polinomio B = [b_0, b_1, \\dots, b_m]^T.\nIl prodotto matrice-vettore VB ha come componente i-esima: (VB)_i = \\sum_{j=0}^m V_{i,j} b_j = \\sum_{j=0}^m x_i^j b_j = b_0 + b_1 x_i + \\dots + b_m x_i^m Questo è esattamente il valore del generico polinomio p_m(x) valutato in x_i.\nIl vettore delle differenze (il residuo) ha quindi come componente i-esima y_i - (VB)_i, il che corrisponde alla componente i-esima del vettore Y - VB.\nPertanto, la somma degli scarti quadratici può essere riscritta come il quadrato della norma euclidea del vettore residuo Y - VB: \\sum_{i=0}^n (y_i - (b_0 + b_1 x_i + \\dots + b_m x_i^m))^2 = ||Y - VB||^2\nIl problema di trovare i coefficienti A = [a_0, \\dots, a_m]^T che minimizzano la somma degli scarti quadratici è quindi equivalente a cercare il vettore A che minimizza la norma al quadrato del residuo ||Y - VA||^2, dove A è ora il vettore di coefficienti ottimali (usiamo A per coerenza con la notazione finale del source).\nCollegamento ai Sistemi Sovradeterminati\nAbbiamo imparato che la soluzione nel senso dei minimi quadrati per un sistema lineare VX = Y (dove V è una matrice, X è il vettore delle incognite e Y è il vettore termine noto) è il vettore X^* che minimizza ||Y - VX||^2.\nQuando il sistema è sovradeterminato, ovvero V è una matrice con più righe che colonne (come la nostra matrice di Vandermonde V, che è (n+1) \\times (m+1) con n &gt; m tipicamente nel fitting polinomiale), e la matrice V ha rango pieno (rank(V) = m+1), la soluzione X^* è unica ed è data dalle equazioni normali: V^T V X^* = V^T Y\nNel nostro problema di approssimazione polinomiale:\n\nLa matrice è la matrice di Vandermonde V.\nIl vettore delle incognite che vogliamo trovare è il vettore dei coefficienti A = [a_0, \\dots, a_m]^T.\nIl vettore termine noto è il vettore dei dati Y = [y_0, \\dots, y_n]^T.\n\nQuindi, i coefficienti ottimali A sono la soluzione del sistema di equazioni normali: V^T V A = V^T Y\nQuesto sistema è un sistema lineare di (m+1) equazioni in (m+1) incognite (i coefficienti a_0, \\dots, a_m).\nDimostrazione: Coincidenza delle Equazioni Normali\nProcediamo ora a calcolare esplicitamente la matrice V^T V e il vettore V^T Y e mostrare che corrispondono alla matrice e al vettore termine noto ottenuti originariamente derivando le equazioni normali per la regressione tramite annullamento delle derivate parziali.\n1. Calcolo della Matrice V^T V\nLa matrice V è (n+1) \\times (m+1). La sua trasposta V^T è (m+1) \\times (n+1). V^T = \\begin{pmatrix} 1 &amp; 1 &amp; \\dots &amp; 1 \\ x_0 &amp; x_1 &amp; \\dots &amp; x_n \\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ x_0^m &amp; x_1^m &amp; \\dots &amp; x_n^m \\end{pmatrix}\nIl prodotto V^T V è una matrice (m+1) \\times (m+1). L’elemento nella riga j e colonna k (con indici j, k che vanno da 0 a m) di V^T V si ottiene moltiplicando la riga (j+1)-esima di V^T (che è la colonna (j+1)-esima di V) per la colonna (k+1)-esima di V. La riga (j+1)-esima di V^T è [x_0^j, x_1^j, \\dots, x_n^j]. La colonna (k+1)-esima di V è [x_0^k, x_1^k, \\dots, x_n^k]^T.\nL’elemento (j, k) di V^T V è quindi il prodotto scalare tra questi due vettori: (V^T V)_{j,k} = \\sum_{i=0}^n (V^T)_{j,i} V_{i,k} = \\sum_{i=0}^n x_i^j \\cdot x_i^k = \\sum_{i=0}^n x_i^{j+k}\nVediamo alcuni esempi degli elementi di questa matrice:\n\nElemento (0,0): j=0, k=0: \\sum_{i=0}^n x_i^{0+0} = \\sum_{i=0}^n 1 = n+1.\nElemento (0,1): j=0, k=1: \\sum_{i=0}^n x_i^{0+1} = \\sum_{i=0}^n x_i.\nElemento (0,m): j=0, k=m: \\sum_{i=0}^n x_i^{0+m} = \\sum_{i=0}^n x_i^m.\nElemento (1,0): j=1, k=0: \\sum_{i=0}^n x_i^{1+0} = \\sum_{i=0}^n x_i.\nElemento (1,1): j=1, k=1: \\sum_{i=0}^n x_i^{1+1} = \\sum_{i=0}^n x_i^2.\nElemento (m,m): j=m, k=m: \\sum_{i=0}^n x_i^{m+m} = \\sum_{i=0}^n x_i^{2m}.\n\nLa matrice V^T V è quindi: V^T V = \\begin{pmatrix} \\sum_{i=0}^n 1 &amp; \\sum_{i=0}^n x_i &amp; \\dots &amp; \\sum_{i=0}^n x_i^m \\ \\sum_{i=0}^n x_i &amp; \\sum_{i=0}^n x_i^2 &amp; \\dots &amp; \\sum_{i=0}^n x_i^{m+1} \\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ \\sum_{i=0}^n x_i^m &amp; \\sum_{i=0}^n x_i^{m+1} &amp; \\dots &amp; \\sum_{i=0}^n x_i^{2m} \\end{pmatrix} Questa è esattamente la matrice del sistema di equazioni normali ottenuta in precedenza quando abbiamo studiato la retta di regressione e la sua generalizzazione.\n2. Calcolo del Vettore Termine Noto V^T Y\nIl prodotto V^T Y è un vettore (m+1) \\times 1. La componente j-esima (con indice j da 0 a m) di V^T Y si ottiene moltiplicando la riga (j+1)-esima di V^T per il vettore Y. La riga (j+1)-esima di V^T è [x_0^j, x_1^j, \\dots, x_n^j]. Il vettore Y è [y_0, y_1, \\dots, y_n]^T.\nLa componente j di V^T Y è quindi il prodotto scalare: (V^T Y)_j = \\sum_{i=0}^n (V^T)_{j,i} Y_i = \\sum_{i=0}^n x_i^j y_i\nVediamo alcuni esempi delle componenti di questo vettore:\n\nComponente 0: j=0: \\sum_{i=0}^n x_i^0 y_i = \\sum_{i=0}^n y_i.\nComponente 1: j=1: \\sum_{i=0}^n x_i^1 y_i = \\sum_{i=0}^n x_i y_i.\nComponente m: j=m: \\sum_{i=0}^n x_i^m y_i = \\sum_{i=0}^n x_i^m y_i.\n\nIl vettore V^T Y è quindi: V^T Y = \\begin{pmatrix} \\sum_{i=0}^n y_i \\ \\sum_{i=0}^n x_i y_i \\ \\vdots \\ \\sum_{i=0}^n x_i^m y_i \\end{pmatrix} Questo è esattamente il vettore termine noto del sistema di equazioni normali ottenuto in precedenza.\nConclusione sulla Coincidenza (Dimostrazione Completata)\nAvendo dimostrato che la matrice V^T V e il vettore V^T Y ottenuti riformulando il problema di approssimazione polinomiale come la minimizzazione della norma del residuo di un sistema lineare coincidono esattamente con la matrice e il vettore termine noto del sistema di equazioni normali precedentemente derivato per la regressione tramite l’annullamento delle derivate parziali, possiamo affermare che i due approcci portano allo stesso identico sistema di equazioni normali per la determinazione dei coefficienti del polinomio ai minimi quadrati.\nQuesto chiude il cerchio, mostrando che due percorsi apparentemente distinti per affrontare problemi di minimizzazione (uno basato sul calcolo differenziale, l’altro sulla minimizzazione di norme vettoriali) convergono sullo stesso sistema lineare da risolvere.\nProssimo Argomento: Sistemi Sottodeterminati\nSuccessivamente, l’attenzione si sposterà sui sistemi sottodeterminati. Come accennato, questi sistemi hanno meno equazioni che incognite (m &lt; n). La matrice A in questo caso è “larga”. Si supporrà che la matrice A abbia rango massimo, che in questo caso è pari a m (rank(A)=m). Su questi sistemi si dirà meno rispetto ai sovradeterminati, rendendo la ==trattazione più rapida.\n\nCertamente. Di seguito riporto la spiegazione del professore tratta dalle fonti fornite, strutturata e commentata come richiesto.\nSpiegazione sui Sistemi Sottodeterminati e l’Approssimazione di Derivate\nSistemi Lineari Sottodeterminati (Ax=y)\nQuesto argomento riguarda la soluzione di sistemi lineari nella forma Ax=y.\nProblema: Più Incognite che Equazioni\nIl problema sorge quando si ha una configurazione in cui il numero di incognite è maggiore del numero di equazioni. Questa situazione è analoga alla richiesta di far passare una retta per un singolo punto. Per un punto passano infinite rette, il che significa che non si ha un numero sufficiente di condizioni per definire la retta in modo univoco.\nPer identificare in modo univoco una retta specifica all’interno del fascio di rette che passano per un punto, è necessario aggiungere una condizione ulteriore. Analogamente, per un sistema sottodeterminato, una singola soluzione classica (che soddisfa Ax=y) non è unica.\nRicerca della Soluzione a Norma Euclidea Minima\nNei sistemi sottodeterminati, la soluzione viene cercata come la soluzione classica che soddisfa Ax=y, ma con una condizione addizionale che garantisca l’unicità. Si dimostra che aggiungere una condizione è sufficiente per dare l’unicità alla soluzione x.\nUn’opzione che viene sfruttata è quella di cercare la soluzione con norma euclidea minima.\nDefinizione della Soluzione x^*\nLa soluzione X^*, indicata con la notazione dell’argomento che minimizza una funzione (argmin), è definita come il vettore in \\mathbb{R}^n che realizza il minimo della norma euclidea: X^* = \\arg \\min_{x \\in \\mathbb{R}^n} { ||x||_2 \\mid Ax=y }\nQuesta definizione significa cercare una soluzione in senso classico (cioè tale che Ax = y) a cui si aggiunge il vincolo ulteriore di avere la norma minima, per garantire l’unicità. Questo è diverso dal caso dei sistemi sovradeterminati a rango non massimo, dove si minimizzava il residuo (||Ax-y||_2) con il vincolo di avere la soluzione a norma minima. Qui, invece, la soluzione risolve il sistema in senso classico.\nFormula Esplicita per x^*\nSi può dimostrare che la soluzione X^* così definita coincide con la seguente espressione: X^* = A^T (A A^T)^{-1} y\nAdesso si procederà a verificare che questa scelta per x^* soddisfa entrambe le condizioni richieste: che sia una soluzione classica del sistema Ax=y e che realizzi il minimo della norma.\nDimostrazione: Verifica delle Proprietà della Soluzione x^*\nSi verificano due proprietà per la soluzione X^* definita come X^* = A^T (A A^T)^{-1} y.\nVerifica 1: X^* è Soluzione Classica (AX^* = y)\nSi verifica se A x^* è effettivamente uguale a y.\n\n\nSi parte dall’espressione A X^* e si sostituisce la definizione di X^*: A x^* = A (A^T (A A^T)^{-1} y)\n\n\nSi raggruppano i termini A A^T: A (A^T (A A^T)^{-1} y) = (A A^T) (A A^T)^{-1} y\n\n\nSi osserva che il prodotto di una matrice per la sua inversa è la matrice identità: (A A^T) (A A^T)^{-1} = I\n\n\nL’espressione diventa quindi: I y = y\n\n\nConclusione: Si è verificato che A x^* = y, il che significa che x^* è una soluzione in senso classico del sistema Ax=y.\n\n\nVerifica 2: x^* Realizza il Minimo della Norma\nSi deve verificare che la norma euclidea di X^* (anche al quadrato) sia minore o uguale della norma euclidea di qualsiasi altro vettore x \\in \\mathbb{R}^n che sia una soluzione classica del sistema Ax=y (cioè tale che Ax=y). L’obiettivo è dimostrare che ||X^*||_2^2 \\le ||x||_2^2 per ogni x tale che Ax=y.\nRisultato Preliminare\nÈ necessario un risultato preliminare per procedere con la dimostrazione. Questo risultato afferma che per qualsiasi soluzione classica x del sistema Ax=y, si ha: (x - x^*)^\\top x^* = 0\nDimostrazione del Risultato Preliminare\nSi espande l’espressione (x - x^*)^\\top X^*. (x - X^*)^\\top x^*\nSi sostituisce la definizione di X^*: (x - X^*)^\\top (A^T (A A^T)^{-1} y)\nSi riorganizzano i termini sfruttando le proprietà della trasposta di un prodotto (la trasposta di un prodotto è il prodotto delle trasposte in ordine inverso). In particolare, (x-x^*)^\\top A^\\top = (A(x-x^*))^\\top. Questo permette di scrivere l’espressione come: (A(x - x^*))^\\top (A A^T)^{-1} y\nOra si considera il termine A(x - x^*). Poiché x è una soluzione classica, Ax = y. Si è anche dimostrato che X^* è una soluzione classica, quindi AX^* = y. Dunque: A(x - x^*) = Ax - Ax^* = y - y = 0\nSostituendo questo risultato nell’espressione precedente: (0)^\\top (A A^T)^{-1} y = 0\nConclusione del Risultato Preliminare: Si è dimostrato che (x - x^*)^\\top x^* = 0 per qualsiasi soluzione classica x.\nDimostrazione Principale del Minimo della Norma\nSi parte dalla norma al quadrato di un generico vettore soluzione x: ||x||_2^2\nSi aggiunge e si sottrae la stessa quantità, X^*, all’interno della norma: ||x||_2^2 = ||x - X^* + x^*||_2^2\nSi considera x - X^* come un vettore e X^* come un altro vettore. Si applica la definizione di norma euclidea al quadrato di una somma di due vettori (||a+b||^2 = (a+b)^\\top(a+b) = a^\\top a + b^\\top b + a^\\top b + b^\\top a = ||a||^2 + ||b||^2 + 2 a^\\top b, dove a^\\top b = b^\\top a per vettori reali). In questo caso, a = x - X^* e b = X^*. ||x - x^* + X^*||_2^2 = ||x - X^*||_2^2 + ||X^*||_2^2 + 2 (x - X^*)^\\top x^*\nSi utilizza il risultato preliminare (x - x^*)^\\top x^* = 0: ||x||_2^2 = ||x - X^*||_2^2 + ||X^*||_2^2 + 2 (0)\nQuesto porta all’uguaglianza: ||x||_2^2 = ||X^*||_2^2 + ||x - X^*||_2^2\nSi osserva che la norma euclidea al quadrato di un vettore è sempre una quantità maggiore o uguale a zero: ||x - x^*||_2^2 \\ge 0\nConclusione della Dimostrazione: Dall’uguaglianza ||x||_2^2 = ||X^*||_2^2 + ||x - X^*||_2^2 e dal fatto che ||x - X^*||_2^2 \\ge 0, si deduce che: ||x||_2^2 \\ge ||X^*||_2^2 Questo dimostra che la norma al quadrato di qualsiasi altra soluzione classica x è maggiore o uguale della norma al quadrato di X^*, confermando che X^* realizza il minimo della norma euclidea tra le soluzioni classiche.\nInstabilità Numerica della Formula Esplicita\nEsattamente come succedeva nel caso dei sistemi sovradeterminati, il calcolo diretto di X^* usando la formula esplicita X^* = A^T (A A^T)^{-1} y può essere numericamente instabile.\nCalcolo di x^* Tramite Fattorizzazione QR Ridotta di A^T\nPer ovviare all’instabilità numerica, nella pratica si utilizza un percorso alternativo per calcolare x^*: si sfrutta la fattorizzazione QR. In particolare, si usa la fattorizzazione QR ridotta della matrice trasposta di A (A^T). Questo riporta a gestire una fattorizzazione QR di una matrice che, essendo A rettangolare nel senso “lunghezza”, A^T è “alta”, simile a quelle incontrate nei sistemi sovradeterminati.\nDerivazione della Formula tramite QR\nSupponiamo di avere a disposizione la fattorizzazione QR ridotta di A^T, cioè A^T = \\tilde{Q}\\tilde{R}, dove \\tilde{Q} è una matrice con colonne ortonormali (\\tilde{Q}^T \\tilde{Q} = I) e \\tilde{R} è una matrice triangolare superiore.\nSi parte dalla formula esplicita x^* = A^T (A A^T)^{-1} y. Si sostituisce A^T = \\tilde{Q}\\tilde{R} nell’espressione per X^*: X^* = (\\tilde{Q}\\tilde{R}) ((\\tilde{Q}\\tilde{R})^T (\\tilde{Q}\\tilde{R}))^{-1} y\nSi espande la trasposta del prodotto (\\tilde{Q}\\tilde{R})^T = \\tilde{R}^T \\tilde{Q}^T: x^* = \\tilde{Q}\\tilde{R} (\\tilde{R}^T \\tilde{Q}^T \\tilde{Q}\\tilde{R})^{-1} y\nSi sfrutta l’ortogonalità di \\tilde{Q}, per cui \\tilde{Q}^T \\tilde{Q} = I (matrice identità): x^* = \\tilde{Q}\\tilde{R} (\\tilde{R}^T I \\tilde{R})^{-1} y = \\tilde{Q}\\tilde{R} (\\tilde{R}^T \\tilde{R})^{-1} y\nSi espande l’inversa del prodotto (\\tilde{R}^T \\tilde{R})^{-1}. L’inversa di un prodotto è il prodotto delle inverse in ordine inverso. Inoltre, l’inversa della trasposta è la trasposta dell’inversa: (\\tilde{R}^T)^{-1} = (\\tilde{R}^{-1})^T, indicata anche come \\tilde{R}^{-T}. (\\tilde{R}^T \\tilde{R})^{-1} = \\tilde{R}^{-1} (\\tilde{R}^T)^{-1} = \\tilde{R}^{-1} \\tilde{R}^{-T}\nQuindi: x^* = \\tilde{Q}\\tilde{R} \\tilde{R}^{-1} \\tilde{R}^{-T} y\nSi usa il fatto che \\tilde{R} \\tilde{R}^{-1} = I: x^* = \\tilde{Q} I \\tilde{R}^{-T} y = \\tilde{Q} \\tilde{R}^{-T} y\nFormula per il Calcolo Pratico di x^* tramite QR: x^* = \\tilde{Q} \\tilde{R}^{-T} y\nQuesta è la formula con cui la soluzione x^* viene calcolata nella pratica.\nGenerazione della Fattorizzazione QR\nLa fattorizzazione QR (e di conseguenza quella ridotta) di una matrice A^T si ottiene applicando l’algoritmo di ortonormalizzazione di Gram-Schmidt alle colonne di A^T. Se A è una matrice M \\times N con M&lt;N (sottodeterminato), A^T è N \\times M. Le colonne di A^T (che sono i vettori riga di A) sono N vettori in \\mathbb{R}^M. Applicando Gram-Schmidt alle M colonne linearmente indipendenti di A^T, si ottiene una base ortonormale di vettori, ad esempio e_1, \\ldots, e_M. La matrice \\tilde{Q} è la matrice che raccoglie questi vettori ortonormali nelle sue colonne. \\tilde{Q} = [e_1 | \\dots | e_M] La matrice \\tilde{R} raccoglie le proiezioni delle colonne di A^T sui vettori ortonormali. Le sue entrate sono del tipo \\langle e_i, a^T_j \\rangle, dove a^T_j è la j-esima colonna di A^T. \\tilde{R} è una matrice pseudo-triangolare superiore.\nApprossimazione della Derivata di una Funzione in un Punto\nSi cambia completamente argomento, passando dall’algebra lineare all’analisi numerica per funzioni.\nPassaggio ad un Nuovo Argomento\nIl nuovo argomento è l’approssimazione di oggetti completamente diversi, in particolare l’approssimazione di derivate e integrali. Entrambi questi argomenti sono legati al concetto di interpolazione.\nApprossimazione f&#039; Come Funzione\nPrecedentemente si era parlato in modo blando di approssimazione di derivate quando si citavano le spline. Le spline, funzioni interpolanti super regolari, potevano essere usate (con un certo abuso) per approssimare la derivata della funzione approssimando f&#039; come una funzione essa stessa. Si approssimava f&#039; sul suo dominio.\n_Approssimazione di f&#039;(X^*) Come Valore Puntuale*\nAdesso lo scenario cambia. Ci si occupa di approssimare non f&#039; come funzione, ma il valore assunto dalla derivata prima in un certo punto specifico x^* appartenente al dominio di definizione della funzione. L’obiettivo è approssimare un numero reale. Si considera una funzione f definita su un intervallo [a, b] della retta reale, a valori reali, e con una certa regolarità (almeno C^1). Si cerca un’approssimazione per il valore f&#039;(x^*) in un punto x^* \\in [a, b].\nUtilità del Concetto di Derivata (Prospettiva Ingegneristica)\nPrima di addentrarsi negli schemi di approssimazione, è utile comprendere perché il concetto di derivata è importante da un punto di vista fisico o ingegneristico. Il concetto di derivata è associato in generale al concetto di velocità, o più in generale, di cambiamento o variazione. In molte applicazioni, monitorare la variazione di una quantità è molto più importante che monitorare la quantità stessa.\nEsempi:\n\nDeformazione di una membrana: Dietro la deformazione c’è un’equazione (equazione dell’elasticità) la cui incognita è lo spostamento. Quantità legate alle derivate dello spostamento sono le deformazioni e gli sforzi (o stress). Per applicazioni in ingegneria civile, analisi delle strutture, gli sforzi sono molto più importanti da monitorare rispetto alla variazione rispetto alla posizione di equilibrio.\nDiffusione di un inquinante: Se f misura la concentrazione di un inquinante in un fiume o in una bacinella, la sua derivata è legata al flusso di questo inquinante attraverso una porzione del dominio. A fini ambientali, può essere molto più interessante conoscere il flusso di inquinante che deteriora una zona da salvaguardare, piuttosto che la concentrazione esatta.\n\nQuesti esempi giustificano l’interesse nell’approssimare la derivata. A volte, l’interesse è proprio nel monitorare la derivata in punti specifici (es. punti di misurazione, aree protette), anziché su tutto il dominio.\nDefinizione Analitica della Derivata\nIl calcolo della derivata in un punto in analisi si basa sul famoso limite di un rapporto incrementale. Una possibilità per scrivere f&#039;(x^*) è come il limite per h che tende a zero del rapporto incrementale: f&#039;(x^*) = \\lim_{h \\to 0} \\frac{f(X^*+h) - f(X^*)}{h}\nInterpretazione Geometrica: Se f è la funzione e X^* il punto, f&#039;(X^*) è il coefficiente angolare della retta tangente ad f nel punto di coordinate (x^*, f(x^*)). È un numero. La definizione del rapporto incrementale, \\frac{f(X^*+h) - f(X^*)}{h}, corrisponde al coefficiente angolare della retta secante che passa per i punti (x^*, f(x^*)) e (X^*+h, f(X^*+h)). Prendere il limite per h \\to 0 significa far scorrere il secondo punto lungo la curva avvicinandolo al primo punto, in modo che la retta secante tenda a sovrapporsi alla retta tangente.\nProblema della Definizione Analitica per il Calcolo Numerico\nCon riferimento alla definizione analitica della derivata, che è esatta, c’è un aspetto che non è ben gestito dai calcolatori: il limite. Tutto ciò che risuona con l’infinito (come l’asintotico implicito nel concetto di limite) non è un concetto facilmente digeribile da un calcolatore.\nSchema di Approssimazione: Rimozione del Limite\nPer proporre un possibile schema per approssimare f&#039;(x^*), si è deciso semplicemente di rimuovere il limite dalla definizione analitica.\nSi va quindi ad approssimare f&#039;(x^*) con un oggetto che, usando le notazioni della letteratura, viene indicato con \\Delta^+ f(x^*). Il simbolo \\Delta^+ f è considerato un unico blocco. Questo delta ”+” indica una differenza in avanti (forward difference).\nLa definizione di \\Delta^+ f(x^*) coincide semplicemente con il rapporto incrementale della definizione esatta, ma senza il limite: f&#039;(x^*) \\approx \\Delta^+ f(x^*) = \\frac{f(X^*+h) - f(X^*)}{h}\nIl Ruolo di h: Nella definizione analitica, h tendeva a 0. Nello schema di approssimazione, h è una distanza arbitraria scelta. Geometricamente, h rappresenta la distanza tra X^* e il punto X^*+h.\n\nCertamente. Ecco una spiegazione dettagliata dei metodi alle differenze finite per approssimare la derivata prima di una funzione f&#039;(x^*), basata esclusivamente sui contenuti delle fonti fornite e strutturata secondo le tue indicazioni.\nL’obiettivo è trovare delle modalità per approssimare il valore della derivata prima di una funzione f in un punto x^*. La derivata prima in un punto è definita tramite un limite che coinvolge un rapporto incrementale. I metodi alle differenze finite eliminano il limite, utilizzando il rapporto incrementale per un valore di h piccolo ma finito.\nVengono presentati tre schemi principali per questa approssimazione:\n\nSchema alle Differenze Finite in Avanti\nSchema alle Differenze Finite all’Indietro\nSchema alle Differenze Finite Centrate\n\nAnalizzeremo ciascuno schema, la sua definizione, l’analisi dell’errore tramite sviluppo di Taylor e le relative proprietà.\n1. Schema alle Differenze Finite in Avanti\nDefinizione\nQuesto è un primo modo per approssimare f&#039;(x^*). Si basa sul considerare il punto X^*+h, che si trova “in avanti” rispetto a X^*.\nLa formula per l’approssimazione, indicata con \\Delta_+ f(x^*), è data dal rapporto incrementale in avanti: \\Delta_+ f(x^*) = \\frac{f(X^*+h) - f(X^*)}{h}\nAffinché questa approssimazione sia efficace, il valore di h deve essere scelto “opportunamente piccolo”.\nAnalisi dell’Errore tramite Sviluppo di Taylor\nDimostrazione dell’Ordine di Accuratezza\nPer capire quanto sia buona questa approssimazione, si analizza l’errore E_+ = f&#039;(x^*) - \\Delta_+ f(x^*). Uno strumento classico per fare questo è l’espressione di Taylor. Per l’analisi, si richiede che la funzione f sia di classe C^2 sull’intervallo considerato, ad esempio [a, b].\nSi considera lo sviluppo di Taylor di f(X^*+h) centrato in X^* e troncato al secondo ordine: f(X^*+h) = f(X^*) + h f&#039;(x^*) + \\frac{h^2}{2} f&#039;&#039;(\\alpha) dove \\alpha è un punto sconosciuto che si trova tra X^* e X^*+h (\\alpha \\in (x^*, x^*+h)).\nPer isolare il termine della derivata prima f&#039;(x^*), si può riorganizzare l’equazione di Taylor. Dividendo per h: \\frac{f(X^*+h)}{h} = \\frac{f(X^*)}{h} + f&#039;(x^*) + \\frac{h}{2} f&#039;&#039;(\\alpha)\nSpostando i termini in modo da confrontare f&#039;(x^*) con l’approssimazione \\Delta_+ f(x^*), si ottiene: f&#039;(x^*) - \\frac{f(X^*+h) - f(X^*)}{h} = - \\frac{h}{2} f&#039;&#039;(\\alpha)\nQuindi, l’errore di approssimazione per lo schema in avanti è dato da: E_+ = f&#039;(x^*) - \\Delta_+ f(x^*) = - \\frac{h}{2} f&#039;&#039;(\\alpha)\nProprietà dell’Errore\nDall’espressione dell’errore, si possono fare le seguenti osservazioni:\n\nIl punto \\alpha è, come spesso accade negli sviluppi di Taylor con resto di Lagrange, un punto sconosciuto. Per calcolare il massimo errore pratico, si può stimare f&#039;&#039;(\\alpha) prendendo il massimo del valore assoluto della derivata seconda nell’intervallo rilevante e si considera il valore assoluto del coefficiente di h.\nPer h che tende a zero (h \\to 0), l’errore E_+ tende a zero. Questo conferma che l’approssimazione diventa esatta nel limite.\nLa velocità di convergenza dell’errore a zero è data dalla potenza di h nell’espressione dell’errore. Poiché l’errore è proporzionale a h^1 (il termine -h/2 moltiplica f&#039;&#039;(\\alpha)), lo schema alle differenze finite in avanti è uno schema del primo ordine (o “curato al primo ordine”) per h \\to 0. Si dice anche che converge linearmente per h che va a zero.\n\nConnessione all’Interpolazione\nEsercizio Proposto\nC’è una connessione interessante tra questo schema e l’interpolazione polinomiale. Il valore \\Delta_+ f(x^*) rappresenta la derivata del polinomio lineare P_1(x) che interpola la funzione f nei punti (x^*, f(x^*)) e (X^*+h, f(X^*+h)).\nViene suggerito il seguente esercizio per verificare questa connessione e comprendere meglio l’interpolazione di Lagrange:\n\nConsidera le due coppie di dati: (x^*, f(x^*)) e (X^*+h, f(X^*+h)).\nCostruisci il polinomio lineare di Lagrange P_1(x) che interpola questi due punti.\nCalcola la derivata di questo polinomio, P_1&#039;(x).\nValuta la derivata nel punto x^*.\nVerifica che P_1&#039;(x^*) = \\Delta_+ f(x^*).\n\nQuesto esercizio mostra la traduzione geometrica dell’approssimazione: la pendenza della secante tra (x^*, f(x^*)) e (X^*+h, f(X^*+h)) è l’approssimazione \\Delta_+ f(x^*), e questa pendenza è anche la derivata del polinomio che passa per quei due punti.\n2. Schema alle Differenze Finite all’Indietro\nDefinizione\nQuesto è il secondo schema di approssimazione per f&#039;(x^*). Anziché considerare un punto in avanti, si considera un punto “all’indietro”, x^*-h.\nLa definizione si basa sul rapporto incrementale all’indietro: \\Delta_- f(x^*) = \\frac{f(x^*) - f(x^*-h)}{h}\nGraficamente, rappresenta il coefficiente angolare della secante che passa per i punti (x^*-h, f(x^*-h)) e (x^*, f(x^*)). Anche in questo caso, per h \\to 0, la secante tende a sovrapporsi alla tangente in x^*.\nAnalisi dell’Errore tramite Sviluppo di Taylor\nDimostrazione dell’Ordine di Accuratezza\nCome per lo schema in avanti, si analizza l’errore E_- = f&#039;(x^*) - \\Delta_- f(x^*) utilizzando lo sviluppo di Taylor. Si richiede che la funzione f sia di classe C^2.\nSi considera lo sviluppo di Taylor di f(x^*-h) centrato in X^* e troncato al secondo ordine: f(X^*-h) = f(x^*) - h f&#039;(x^*) + \\frac{h^2}{2} f&#039;&#039;(\\beta) dove \\beta è un punto sconosciuto che si trova tra x^*-h e X^* (\\beta \\in (X^*-h, x^*)). Si noti l’alternanza dei segni dovuta alla valutazione in x^*-h.\nPer isolare f&#039;(x^*), si riorganizza l’equazione di Taylor: h f&#039;(x^*) = f(x^*) - f(x^*-h) + \\frac{h^2}{2} f&#039;&#039;(\\beta)\nDividendo per h: f&#039;(x^*) = \\frac{f(x^*) - f(x^*-h)}{h} + \\frac{h}{2} f&#039;&#039;(\\beta)\nQuindi, l’errore di approssimazione per lo schema all’indietro è dato da: E_- = f&#039;(x^*) - \\Delta_- f(x^*) = \\frac{h}{2} f&#039;&#039;(\\beta) Si noti che l’espressione dell’errore è “esattamente identica tranne che per un cambio di segno” rispetto all’errore dello schema in avanti.\nProprietà dell’Errore\n\nAnche per questo schema, per h \\to 0, l’errore E_- tende a zero.\nL’errore è proporzionale a h^1. Pertanto, lo schema alle differenze finite all’indietro è anch’esso uno schema del primo ordine per h \\to 0.\n\nConnessione all’Interpolazione\nEsercizio Proposto\nAnalogamente al caso in avanti, \\Delta_- f(x^*) è la derivata (valutata in X^*) del polinomio lineare che interpola f nei punti (X^*-h, f(x^*-h)) e (x^*, f(x^*)).\n3. Schema alle Differenze Finite Centrate\nMotivazione\nGli schemi in avanti e all’indietro sono entrambi del primo ordine, il che implica una velocità di convergenza dell’errore a zero non particolarmente elevata. L’obiettivo è trovare uno schema con un ordine di accuratezza superiore, idealmente un ordine 2, che convergerebbe “molto più velocemente”.\nGeometricamente, si considera la secante che passa per i punti (x^*-h, f(x^*-h)) e (X^*+h, f(X^*+h)). Questa retta appare “molto più simile alla mia tangente” in x^* rispetto alle secanti utilizzate negli schemi in avanti e all’indietro.\nDefinizione\nQuesto terzo schema si basa sul rapporto incrementale “centrato”, utilizzando i punti x^*-h e X^*+h simmetricamente rispetto a X^*.\nLa formula per l’approssimazione, indicata con \\Delta f(x^*) (senza segno ”+” o ”-”), è data da: \\Delta f(x^*) = \\frac{f(X^*+h) - f(X^*-h)}{2h} Il denominatore è 2h perché la distanza sull’asse x tra i due punti (x^*-h e x^*+h) è 2h.\nAnalisi dell’Errore tramite Sviluppo di Taylor\nDimostrazione dell’Ordine di Accuratezza\nPer analizzare l’errore E = f&#039;(x^*) - \\Delta f(x^*), si utilizza ancora lo sviluppo di Taylor, ma stavolta è necessario troncare ad un ordine superiore. Per ottenere uno schema del secondo ordine, è necessario richiedere che la funzione f sia di classe C^3. Questo è il “prezzo” da pagare per una convergenza più rapida.\nSi considerano gli sviluppi di Taylor di f(X^*+h) e f(X^*-h) centrati in x^* e troncati al terzo ordine:\nSviluppo per f(X^*+h): f(X^*+h) = f(x^*) + h f&#039;(x^*) + \\frac{h^2}{2} f&#039;&#039;(x^*) + \\frac{h^3}{6} f&#039;&#039;&#039;(\\sigma) dove \\sigma \\in (x^*, x^*+h).\nSviluppo per f(x^*-h): f(x^*-h) = f(x^*) - h f&#039;(x^*) + \\frac{h^2}{2} f&#039;&#039;(x^*) - \\frac{h^3}{6} f&#039;&#039;&#039;(\\gamma) dove \\gamma \\in (x^*-h, x^*).\nPer ottenere la forma desiderata \\frac{f(X^*+h) - f(X^*-h)}{2h}, si sottraggono membro a membro i due sviluppi di Taylor: (f(X^*+h) - f(X^*-h)) = [f(x^*) + h f&#039;(x^*) + \\frac{h^2}{2} f&#039;&#039;(x^*) + \\frac{h^3}{6} f&#039;&#039;&#039;(\\sigma)] - [f(x^*) - h f&#039;(x^*) + \\frac{h^2}{2} f&#039;&#039;(x^*) - \\frac{h^3}{6} f&#039;&#039;&#039;(\\gamma)]\nSottraendo, i termini con derivate di ordine pari (f(x^*) e f&#039;&#039;(x^*)) si cancellano, e i termini con derivate di ordine dispari si sommano: f(X^*+h) - f(X^*-h) = 2h f&#039;(x^*) + \\frac{h^3}{6} f&#039;&#039;&#039;(\\sigma) + \\frac{h^3}{6} f&#039;&#039;&#039;(\\gamma)\nOra, per ottenere il rapporto incrementale centrato, si divide tutta l’equazione per 2h: \\frac{f(X^*+h) - f(X^*-h)}{2h} = \\frac{2h f&#039;(x^*)}{2h} + \\frac{h^3}{6} \\frac{f&#039;&#039;&#039;(\\sigma)}{2h} + \\frac{h^3}{6} \\frac{f&#039;&#039;&#039;(\\gamma)}{2h} \\frac{f(X^*+h) - f(X^*-h)}{2h} = f&#039;(x^*) + \\frac{h^2}{12} f&#039;&#039;&#039;(\\sigma) + \\frac{h^2}{12} f&#039;&#039;&#039;(\\gamma)\nRiorganizzando per ottenere l’espressione dell’errore f&#039;(x^*) - \\Delta f(x^*): f&#039;(x^*) - \\frac{f(X^*+h) - f(X^*-h)}{2h} = - \\frac{h^2}{12} f&#039;&#039;&#039;(\\sigma) - \\frac{h^2}{12} f&#039;&#039;&#039;(\\gamma) f&#039;(x^*) - \\Delta f(x^*) = - \\frac{h^2}{12} (f&#039;&#039;&#039;(\\sigma) + f&#039;&#039;&#039;(\\gamma))\nQuindi, l’errore di approssimazione per lo schema centrato è dato da: E = f&#039;(x^*) - \\Delta f(x^*) = - \\frac{h^2}{12} (f&#039;&#039;&#039;(\\sigma) + f&#039;&#039;&#039;(\\gamma))\nProprietà dell’Errore\n\nAnche in questo caso, per h \\to 0, l’errore E tende a zero.\nLa potenza di h nell’espressione dell’errore è 2 (h^2). Ciò significa che lo schema alle differenze finite centrate è uno schema di ordine 2 per h \\to 0.\nUno schema di ordine 2 converge all’esatto valore f&#039;(x^*) “molto più velocemente” rispetto a uno schema di ordine 1, all’avvicinarsi di h a zero.\n\n4. Confronto e Considerazioni Pratiche\nScelta dello Schema\nAlla luce dell’analisi degli errori, si hanno a disposizione tre schemi per approssimare la derivata prima in un punto:\n\n\\Delta_+ f(x^*): Ordine 1, richiede f \\in C^2.\n\\Delta_- f(x^*): Ordine 1, richiede f \\in C^2.\n\\Delta f(x^*): Ordine 2, richiede f \\in C^3.\n\nIn generale, se la funzione f è sufficientemente regolare (almeno C^3), si preferisce utilizzare lo schema centrato (\\Delta f(x^*)) perché, essendo di ordine superiore (ordine 2), garantisce una convergenza dell’errore a zero molto più rapida al diminuire di h rispetto agli schemi di ordine 1.\nVincoli sulla Scelta\nCi sono due motivi principali per cui potrebbe non essere possibile o conveniente utilizzare lo schema centrato:\n\nRegolarità della Funzione: Se la funzione f è solo C^2 (ma non C^3), non si può garantire che l’errore dello schema centrato vada a zero con la velocità di h^2 perché lo sviluppo di Taylor al terzo ordine e l’esistenza della derivata terza potrebbero non essere validi. In questo caso, si è limitati agli schemi in avanti o all’indietro, che richiedono solo la regolarità C^2 per essere di ordine 1.\nDisponibilità delle Informazioni (Estremi dell’Intervallo): Se si deve calcolare la derivata in un punto che si trova all’estremità dell’intervallo di definizione della funzione.\n\nSe si è nel punto iniziale dell’intervallo (ad esempio, il punto A), non si hanno punti disponibili “all’indietro” (x^*-h). In questo caso, non è possibile costruire lo schema all’indietro (\\Delta_-) né lo schema centrato (\\Delta), poiché entrambi richiedono informazioni a x^*-h. L’unica opzione è utilizzare lo schema in avanti (\\Delta_+), che richiede solo informazioni a X^* e X^*+h.\nSe si è nel punto finale dell’intervallo (ad esempio, il punto B), non si hanno punti disponibili “in avanti” (x^*+h). In questo caso, non è possibile costruire lo schema in avanti (\\Delta_+) né lo schema centrato (\\Delta). L’unica opzione è utilizzare lo schema all’indietro (\\Delta_-).\nPer i punti interni all’intervallo, invece, si ha la libertà di scegliere lo schema desiderato, compatibilmente con la regolarità della funzione.\n\n\n\nIn sintesi, si utilizza lo schema centrato quando possibile (funzione C^3 e punto interno), altrimenti si ripiega su uno degli schemi del primo ordine, che sono sempre utilizzabili se la funzione è almeno C^2 (per l’analisi dell’ordine), e diventano obbligatori agli estremi dell’intervallo. Per la mera scrittura della formula, la regolarità C^1 nel punto potrebbe essere sufficiente.\nReferences\nmateNum- Lez16_trascrizione"},"6--full-note/matenum---totale-teoria":{"slug":"6--full-note/matenum---totale-teoria","filePath":"6- full note/matenum - totale teoria.md","title":"matenum - totale teoria","links":["tags/revisione_finita","tags/flashcard_finite","tags/riscritto_in_corso","3--tag/matematica-numerica","3--tag/sbobine","tags/riscritto_finito","2--source-materials/Appunti-Mate-Num-lez03.pdf","tags/riscritto_zero","tags/revisione_zero","2--source-materials/Appunti-Mate-Num--lez04.pdf","tags/flashcard_zero","2--source-materials/Appunti-Mate-Num-lez05.pdf","2--source-materials/Appunti-Mate-Num--Lez06.pdf","paste/Appunti-Mate-Num--Lez07.pdf","2--source-materials/Appunti-Mate-Num--lez08.pdf","2--source-materials/Appunti-Mate-Num-1--lez10.pdf","paste/Appunti-Mate-Num-lez11.pdf","2--source-materials/Appunti-Mate-Num-lez12.pdf","2--source-materials/Appunti-Mate-Num-lez13.pdf"],"tags":["revisione_finita","flashcard_finite","riscritto_in_corso","riscritto_finito","riscritto_zero","revisione_zero","flashcard_zero"],"content":"2025-02-18 10:17\nStatus: revisione_finita flashcard_finite riscritto_in_corso\nTags:matematica numerica sbobine\nlez01-MateNum\nSistemi di Equazioni Lineari e Approssimazione\n\n\nNotazione Compatta: Un sistema di equazioni lineari può essere espresso come Ax = b. Dove:\n\nA è la matrice dei coefficienti (n x n).\nx è il vettore delle incognite.\nb è il termine noto.\n\n\n\n\nNotazione per Componenti: La notazione compatta è equivalente a esprimere il sistema per componenti:\n\na₁₁x₁ + a₁₂x₂ + … + a₁ₙxₙ = b₁\na₂₁x₁ + a₂₂x₂ + … + a₂ₙxₙ = b₂\n…\naₙ₁x₁ + aₙ₂x₂ + … + aₙₙxₙ = bₙ\n\n\n\nEsistenza e Unicità della Soluzione: La condizione necessaria e sufficiente per garantire esistenza e unicità di x è che A sia non singolare (invertibile).\n\n\nRegola di Cramer e Metodo di Laplace\n\n\nRegola di Cramer: La componente i-esima del vettore delle incognite è calcolata come:\n\nxᵢ = det(Aᵢ) / det(A),\ndove Aᵢ è la matrice ottenuta sostituendo la colonna i-esima di A con il vettore b.\ndovremmo calcolare n+1 determinanti\n\n\n\nFormula di Laplace: Usata per il calcolo del determinante:\n\ndet(A) = Σⱼ aᵢⱼ * Δᵢⱼ,\ndove Δᵢⱼ è il complemento algebrico di aᵢⱼ, dato da (-1)ⁱ⁺ʲ * det(Aᵢⱼ), con Aᵢⱼ matrice di dimensione inferiore (n-1) ottenuta eliminando la riga i e la colonna j.\n\n\n\n\nCosto Computazionale: L’uso combinato di Cramer e Laplace porta a un costo computazionale di O(n!), rendendolo inadatto per sistemi di grandi dimensioni.\n\nIl professore sottolinea che questo costo è insostenibile.\n\n\n\nCosto di un algoritmo\n\n\n\n\n\nAlgoritmo di Strassen\n\nL’algoritmo di Strassen ha un costo computazionale di circa O(n^4).\nAnche se migliore di O(n!), è ancora inefficiente per sistemi di dimensioni elevate.\n\nMetodi di Approssimazione: Diretti vs. Iterativi\n\nMetodi Diretti: Forniscono un’approssimazione della soluzione in un numero finito di passi.\nMetodi Iterativi: Generano una successione di approssimazioni che convergono alla soluzione.\n\nL’approssimazione della soluzione si ottiene come il limite di una successione di approssimazioni, partendo da una “black box” che genera approssimazioni successive, con la speranza che convergano alla soluzione esatta.\n\n\n\nFattorizzazione LU ( metodi diretti)\n\n\nDefinizione: La fattorizzazione LU decompone la matrice A nel prodotto di due matrici:\n\nA = L * U,\ndove L è una matrice triangolare inferiore e U è una matrice triangolare superiore.\n\n\n\n\nMatrice Triangolare Inferiore (L):\n\nElementi non nulli nella parte triangolare inferiore e sulla diagonale.\nFormalmente: lᵢⱼ = 0 se i &lt; j.\n\n\n\nMatrice Triangolare Superiore (U):\n\nElementi non nulli nella parte triangolare superiore e sulla diagonale.\nFormalmente: uᵢⱼ = 0 se i &gt; j.\n\n\n\nRisoluzione del Sistema con Fattorizzazione LU\n\nSostituzione: Riscrivere il sistema originale Ax = b come LUx = b.\nVariabile Ausiliaria: Definire Ux = y, trasformando il sistema in Ly = b.\nSistemi Triangolari:\n\nRisolvere Ly = b per trovare y (sistema triangolare inferiore).\nRisolvere Ux = y per trovare x (sistema triangolare superiore).\n\n\n\n\nOrdine di Risoluzione: È necessario risolvere prima Ly = b perché b è noto, mentre y è incognito.\n\nVantaggi della Fattorizzazione LU\n\nEfficienza: Risolvere due sistemi triangolari è più efficiente, soprattutto con matrici sparse.\nMatrici Sparse: Matrici con molti elementi nulli.\n\nUna matrice B (n x n) è sparsa se il numero di elementi diversi da zero è proporzionale a n, non a n².\nLa sparsità rende più efficiente la risoluzione dei sistemi lineari.\n\n\nPattern di Sparsità: La configurazione degli elementi non nulli influenza l’efficienza degli algoritmi.\n\n\nCalcolo del Determinante con LU\n\n\nProprietà: det(A) = det(L) * det(U).\nCalcolo Semplificato: Il determinante di una matrice triangolare è il prodotto degli elementi diagonali.\nEfficienza: Questo metodo è più efficiente rispetto a Laplace.\n\nAlgoritmo delle Sostituzioni in Avanti (Forward Substitution)\n\n\nObiettivo: Risolvere Ly = b, con L triangolare inferiore.\n\n\nProcedimento:\n\n\n\n\n\nInizializzazione: Calcolare y₁ = b₁ / l₁₁.\n\n\nIterazione: Per i = 2, …, n, calcolare:\n\nyᵢ = (bᵢ - Σⱼ lᵢⱼ * yⱼ) / lᵢᵢ, con j che va da 1 a i-1.\n\n\n\n\n\nCosto Computazionale: O(n²).\n\nDivisioni: n divisioni.\nMoltiplicazioni: Σᵢ(i - 1) = n(n - 1) / 2.\nSottrazioni: Σᵢ(i - 1) = n(n - 1) / 2.\nTotale: n + n(n - 1) = n².\n\n\n\nAlgoritmo delle Sostituzioni all’Indietro (Backward Substitution)\n\n\nObiettivo: Risolvere Ux = y, con U triangolare superiore.\n\n\nProcedimento:\n\n\n\n\n\nInizializzazione: Calcolare xₙ = yₙ / uₙₙ.\n\n\nIterazione: Per i = n-1, …, 1, calcolare:\n\nxᵢ = (yᵢ - Σₖ uᵢₖ * xₖ) / uᵢᵢ, con k che va da i+1 a n.\n\n\n\n\n\nCosto Computazionale: O(n²). La struttura è analoga a quella dell’algoritmo in avanti.\n\n\nCalcolo dei Fattori LU e la Scelta di lᵢᵢ = 1\n\nSistema Sottodeterminato: Nel calcolo diretto dei fattori LU, il sistema ha più incognite che equazioni.\nSoluzione: Si impone che gli elementi diagonali di L siano uguali a 1 (lᵢᵢ = 1).\nMotivazione: Questa scelta riduce le incognite, rendendo il sistema determinato e risolvibile.\n\nPassaggi Matematici per il Caso 2x2 (Fattorizzazione LU)\n\n\\begin{bmatrix} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22} \\end{bmatrix} = \\begin{bmatrix} l_{11} &amp; 0 \\\\ l_{21} &amp; l_{22} \\end{bmatrix}\\begin{bmatrix} U_{11} &amp; U_{12} \\\\ 0 &amp; U_{22} \\end{bmatrix} = \\begin{cases} l_{11} U_{11} = a_{11} \\\\ l_{11} l_{12} = a_{12} \\\\ l_{21} U_{11} = a_{21} \\\\ l_{21} U_{12} + l_{22} U_{22} = a_{22} \\end{cases}\n\n4 equazioni e 6 incognite, è un problema, soluzione? rendere la diagonale di L a 1\n\n\n\n\n\n\n\\begin{bmatrix} 1 &amp; 0 \\ l_{21} &amp; 1 \\ \\ \\end{bmatrix} \\\n\\begin{bmatrix} U_{11} &amp; U_{12} \\ 0 &amp; U_{22} \\end{bmatrix}$$\nGeneralizzazione e Costo Computazionale\n\nMatrice nxn: Per una matrice nxn, ci sono n² equazioni.\nNumero di Incognite: Ci sono \\frac{n(n+1)}{2} elementi in L e altrettanti in U, per un totale di n²+n incognite.\nImposizione di lᵢᵢ = 1: Fissare gli elementi diagonali di L a 1 riduce il numero di incognite a n².\n\nReferences\n2025-02-19 15:25\n_Status: flashcard_finite   riscritto_finito  revisione_finita\n_Tags:sbobine matematica numerica\nlez02- mateNum\nIntroduzione al Metodo di Eliminazione Gaussiana (MEG)\nL’obiettivo principale del Metodo di Eliminazione Gaussiana (MEG) è trasformare una matrice A in una matrice triangolare superiore (U) tramite operazioni elementari sulle righe. Questo processo è fondamentale sia per risolvere sistemi lineari del tipo Ax = b sia per ottenere la fattorizzazione LU della matrice A.\n\nMetodo Analitico: fornisce la soluzione esatta.\nMetodo Numerico: fornisce una soluzione approssimata.\n\nIn un contesto di aritmetica esatta, la fattorizzazione LU conduce alla soluzione precisa. Tuttavia, a causa degli errori di arrotondamento intrinseci ai calcolatori (che utilizzano una rappresentazione binaria dei numeri reali), la soluzione ottenuta tramite calcolatore potrebbe discostarsi leggermente da quella esatta. La precisione della soluzione è strettamente legata alla condizione della matrice: matrici ben condizionate tendono a produrre soluzioni più accurate.\nOperazioni Ammesse nel MEG\nPer preservare la soluzione del sistema lineare Ax = b, le uniche operazioni consentite sono:\n\nScambio di righe\nCombinazioni lineari delle righe\n\nPasso Generico del MEG per la Fattorizzazione LU\nIl MEG trasforma la matrice A in una matrice triangolare superiore U attraverso una sequenza di passi. Ad ogni passo, si introducono dei moltiplicatori, elementi chiave per azzerare gli elementi situati sotto la diagonale principale.\nNotazione\n\nA^{(k)}: Rappresenta la matrice A al passo k, dove k indica il numero di aggiornamenti effettuati.\na_{ij}^{(k)}: Indica l’elemento situato nella posizione (i, j) della matrice al passo k.\nm_{ik}: Denota il moltiplicatore impiegato per azzerare l’elemento nella posizione (i, k).\nPivot: È l’elemento diagonale a_{kk}, utilizzato come riferimento per il calcolo dei moltiplicatori. È anche il protagonista del pivoting.\n\nPasso 1: Azzeramento degli elementi sotto il primo pivot a_{11}\n\n\nsia A = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{bmatrix}\nDefinizione dei moltiplicatori:\n\n\nm_{21} = \\frac{a_{21}^{(1)}}{a_{11}^{(1)}}\n\n\nm_{31} = \\frac{a_{31}^{(1)}}{a_{11}^{(1)}}\n\n\nAggiornamento delle righe:\nLa riga i-esima della matrice aggiornata A^{(2)} si ottiene come combinazione lineare della riga i-esima di A^{(1)} e della prima riga di A^{(1)}:\n\nR_2^{(2)} = R_2^{(1)} - m_{21} \\cdot R_1^{(1)}\nR_3^{(2)} = R_3^{(1)} - m_{31} \\cdot R_1^{(1)}\n\nVerifica dell’azzeramento:\nL’elemento (a_{21}^{(2)}) diventa zero:\n\na_{21}^{(2)} = a_{21}^{(1)} - m_{21} \\cdot a_{11}^{(1)} = a_{21}^{(1)} - \\frac{a_{21}^{(1)}}{a_{11}^{(1)}} \\cdot a_{11}^{(1)} = 0\n\nAggiornamento degli altri elementi:\nGli altri elementi della riga 2 vengono aggiornati di conseguenza:\n\na_{22}^{(2)} = a_{22}^{(1)} - m_{21} \\cdot a_{12}^{(1)}\na_{23}^{(2)} = a_{23}^{(1)} - m_{21} \\cdot a_{13}^{(1)}\n\nottenendo cosi la matrice A^{(2)} = \\begin{bmatrix} a_{11}^{(1)} &amp; a_{12}^{(1)} &amp; a_{13}^{(1)} \\\\ \\cdot &amp; a_{22}^{(2)} &amp; a_{23}^{(2)} \\\\ \\cdot &amp; a_{32}^{(2)} &amp; a_{33}^{(2)} \\end{bmatrix}\nPasso 2: Azzeramento dell’elemento a_{32}\nIn questo passo, si sfrutta il secondo pivot a_{22}^{(2)} per azzerare l’elemento a_{32}^{(2)}.\nDefinizione del moltiplicatore:\n\nm_{32} = \\frac{a_{32}^{(2)}}{a_{22}^{(2)}}\n\nAggiornamento della riga 3:\nLa riga 3 viene aggiornata impiegando la riga 2 come riferimento:\n\nR_3^{(3)} = R_3^{(2)} - m_{32} \\cdot R_2^{(2)}\n\nVerifica dell’azzeramento:\n\na_{32}^{(3)} = a_{32}^{(2)} - m_{32} \\cdot a_{22}^{(2)} = a_{32}^{(2)} - \\frac{a_{32}^{(2)}}{a_{22}^{(2)}} \\cdot a_{22}^{(2)} = 0\n\nAggiornamento degli altri elementi:\n\na_{33}^{(3)} = a_{33}^{(2)} - m_{32} \\cdot a_{23}^{(2)}\n\nottenendo la matrice A^{(3)} = \\begin{bmatrix} a_{11}^{(1)} &amp; a_{12}^{(1)} &amp; a_{13}^{(1)} \\\\ 0 &amp; a_{22}^{(2)} &amp; a_{23}^{(2)} \\\\ 0 &amp; 0 &amp; a_{33}^{(3)} \\end{bmatrix}\nCostruzione delle Matrici L e U\n\n\nMatrice U: Rappresenta il risultato diretto del MEG, ovvero la matrice triangolare superiore ottenuta alla fine dei vari passi.\n\n\nMatrice L: È una matrice triangolare inferiore con elementi diagonali pari a 1. Gli elementi al di sotto della diagonale principale corrispondono ai moltiplicatori m_{ik} impiegati durante il processo di eliminazione.\n\nL = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ m_{21} &amp; 1 &amp; 0 \\\\ m_{31} &amp; m_{32} &amp; 1 \\end{bmatrix}\n\n\n\nEsempio Numerico\nConsideriamo la matrice:\n\nA = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 2 &amp; 0 &amp; -1 \\\\ -1 &amp; 1 &amp; 5 \\end{bmatrix}\n\nPasso 1\n\nm_{21} = \\frac{2}{1} = 2\nm_{31} = \\frac{-1}{1} = -1\n\nApplicando le operazioni di riga:\n\\begin{align*} a_{21}^{(2)} &amp;= 2 - 2 \\cdot 1 = 0 \\\\ a_{22}^{(2)} &amp;= 0 - 2 \\cdot 2 = -4 \\\\ a_{23}^{(2)} &amp;= -1 - 2 \\cdot 1 = -3 \\\\ a_{31}^{(2)} &amp;= 1 - (+1) \\cdot 1 = 0 \\\\ a_{32}^{(2)} &amp;= 1 - (-1) \\cdot 2 = 3 \\\\ a_{33}^{(2)} &amp;= 5 - (-1) \\cdot 1 = 6 \\end{align*}\n\nA^{(2)} = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; -4 &amp; -3 \\\\ 0 &amp; 3 &amp; 6 \\end{bmatrix}\n\nPasso 2\n\nm_{32} = \\frac{3}{-4} = -\\frac{3}{4}\n\nApplicando l’operazione di riga:\n\n\n\n\n\na_{32}^{(3)} &amp;= 3 - \\left( -\\frac{3}{4} \\right) \\cdot (-4) = 0 \\\na_{33}^{(3)} &amp;= 6 - \\left( -\\frac{3}{4} \\right) \\cdot (-3) = \\frac{15}{4}\n\\end{align*}$$\n\nA^{(3)} = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; -4 &amp; -3 \\\\ 0 &amp; 0 &amp; \\frac{15}{4} \\end{bmatrix}\n\nFattorizzazione LU\n\nL = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 2 &amp; 1 &amp; 0 \\\\ -1 &amp; -\\frac{3}{4} &amp; 1 \\end{bmatrix}\nU = \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 0 &amp; -4 &amp; -3 \\\\ 0 &amp; 0 &amp; \\frac{15}{4} \\end{bmatrix}\n\nGeneralizzazione del Passo K\n\n A= A^{(1)} = \\begin{bmatrix} a_{11}^{(1)} &amp; \\cdots &amp; a_{1n}^{(1)} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1}^{(1)} &amp; \\cdots &amp; a_{nn}^{(1)} \\end{bmatrix}\ndopo (n-1) passi per portarlo in forma triangolare A^{(2)} = \\begin{bmatrix} a_{11}^{(1)} &amp; \\cdots &amp; \\cdots &amp; \\cdots &amp; a_{1n}^{(1)} \\\\ 0 &amp; a_{22}^{(2)} &amp; \\cdots &amp; \\cdots &amp; a_{2n}^{(2)} \\\\ 0 &amp; 0  &amp; \\cdots &amp; a_{kk}^{(k)} &amp; a_{kn}^{(k)} \\\\ 0 &amp; 0 &amp; \\ddots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{nk}^{(k)} &amp; a_{nn}^{(k)} \\end{bmatrix}\n\nAl passo k, le prime k-1 colonne sono state già azzerate sotto la diagonale. Si lavora sulla sottomatrice di dimensione (n-k+1) x (n-k+1).\n\n\ndopo n passi A^{(n)} = U = \\begin{bmatrix} a_{11}^{(1)} &amp; \\cdots &amp; \\cdots &amp; a_{1n}^{(1)} \\\\ 0 &amp; a_{22}^{(2)} &amp; \\cdots &amp; a_{2n}^{(2)} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{nn}^{(n)} \\end{bmatrix}\n\nImplementazione Algoritmica\nL’implementazione dell’algoritmo per la fattorizzazione LU richiede l’utilizzo di tre cicli for:\nfor k = 1 to n-1 do\n    for i = k+1 to n do\n        m_ik = A(i,k) / A(k,k)  // Calcolo moltiplicatore\n        for j = k to n do\n            A(i,j) = A(i,j) - m_ik * A(k,j)  // Aggiornamento elementi\n        end\n    end\nend\n\n\nk: Rappresenta l’indice delle colonne.\ni: Rappresenta l’indice delle righe.\nj: Indice utilizzato per scorrere la sottomatrice da modificare.\n\n\n\n\n\nCosto Computazionale\nIl costo computazionale del MEG si aggira intorno a \\frac{2}{3}n^3 + O(n^2) operazioni.\nComandi di MATLAB\nMATLAB offre diversi comandi utili per la fattorizzazione LU e la risoluzione di sistemi lineari.\n\nlu(A): Calcola la fattorizzazione LU della matrice A.\nA\\b: Risolve il sistema lineare Ax = b utilizzando il solver diretto più appropriato.\ntril(A): Estrae la parte triangolare inferiore di A.\ntriu(A): Estrae la parte triangolare superiore di A.\n\nStrategie per la Risoluzione di Sistemi Lineari\n\n\n\nEsistono diverse strategie per risolvere sistemi lineari, ognuna con specifici costi computazionali.\n\n\nFattorizzazione LU e Sostituzioni Successive:\n\nCalcolare la fattorizzazione LU di A.\nRisolvere Ly = b.\nRisolvere Ux = y.\nCosto: \\frac{2}{3}n^3 + 2n^2\n\n\n\nMetodo di Eliminazione Gaussiana con Termine Noto Esteso:\n\nAffiancare la matrice A con il vettore b.\nEseguire le operazioni di riga per trasformare A in una matrice triangolare superiore, aggiornando contemporaneamente il vettore b.\nRisolvere il sistema triangolare superiore risultante con sostituzione all’indietro.\nCosto: leggermente superiore a \\frac{2}{3}n^3 + n^2\n\n\n\nCalcolo dell’Inversa di A:\n\nCalcolare l’inversa di A.\nCalcolare x = A^{(-1)} \\cdot b.\nCosto: \\frac{8}{3}n^3\nSconsigliato per via del costo computazionale elevato.\n\n\n\n\nLa scelta della strategia dipende dal contesto.\nSe si deve risolvere più volte lo stesso sistema con matrici dei coefficienti uguali ma termini noti diversi, conviene calcolare la fattorizzazione LU una sola volta e poi risolvere i sistemi triangolari corrispondenti.\n\n\n\n\n\nAx &amp;= \\tilde{b_1} \\\nAx &amp;= \\tilde{b_2} \\\n&amp; \\vdots \\\nAx &amp;= \\tilde{b_q}\n\\end{align*}$$\nPivoting\nIl pivoting è una tecnica impiegata per gestire situazioni in cui un pivot è pari a zero o presenta un valore molto piccolo, eventualità che può condurre a instabilità numerica. Il pivoting consiste nello scambio di righe (o colonne) al fine di collocare un elemento con un valore assoluto maggiore in posizione di pivot.\nCondizione Necessaria e Sufficiente per l’Esistenza e l’Unicità della Fattorizzazione LU\nSia A una matrice n x n. Esiste un’unica fattorizzazione LU di A se e solo se le sottomatrici principali di A di ordine i, con i che va da 1 a n-1, sono non singolari.\n\nNOTA BENE: non ho richiesto la non-singolarità di A\nSottomatrice principale di ordine i: è la sottomatrice ottenuta intersecando le prime i righe e le prime i colonne di A.\n\nEsempi Dimostrativi\nGli esempi forniti illustrano come la violazione della condizione necessaria e sufficiente possa portare alla perdita dell’esistenza o dell’unicità della fattorizzazione LU.\n\nEsempio 1: A = \\begin{bmatrix} 1 &amp; 2 \\\\ 1 &amp; 2 \\end{bmatrix}\n\nSingolare, ma soddisfa la condizione necessaria e sufficiente.\nEsiste un’unica fattorizzazione LU.\n\n\n\nEsempio 2: A = \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 2 \\end{bmatrix}\n\nNon soddisfa la condizione necessaria e sufficiente.\nNon esiste la fattorizzazione LU.\n\n\n\nEsempio 3: A = \\begin{bmatrix} 0 &amp; 1 \\\\ 0 &amp; 2 \\end{bmatrix}\n\nNon soddisfa la condizione necessaria e sufficiente.\nEsistono infinite fattorizzazioni LU.\n\n\n\n\nReferences\n2025-02-24 15:41\n_Status: flashcard_finite riscritto_finito   revisione_finita\n_Tags: matematica numerica. sbobine\nMatenum- lez03\nCondizioni sufficienti per l’esistenza e l’unicità della fattorizzazione LU\nIl professore introduce le condizioni sufficienti per garantire l’esistenza e l’unicità della fattorizzazione LU di una matrice A. Queste condizioni sono alternative tra loro e si basano su tre famiglie di matrici particolari.\n1. Matrici a dominanza diagonale stretta per righe\nSe A è una matrice a dominanza diagonale stretta per righe, allora la fattorizzazione LU esiste ed è unica. Una matrice A è a dominanza diagonale stretta per righe se l’elemento diagonale in valore assoluto è strettamente maggiore della somma dei valori assoluti degli altri elementi sulla stessa riga.\nMatematicamente, questo significa che per ogni riga i:\n|a_{ii}| &gt; \\sum_{j=1, j\\neq i}^{n} |a_{ij}|\ndove i varia da 1 a n.\nEsempio: Consideriamo la matrice:\nA = \\begin{bmatrix} 4 &amp; 0 &amp; -1 \\\\ 3 &amp; -7 &amp; 2 \\\\ -2 &amp; 1 &amp; 9 \\end{bmatrix}\nVerifichiamo se è a dominanza diagonale stretta per righe:\n\nRiga 1: |4| &gt; |0| + |-1| \\implies 4 &gt; 1 (vero)\nRiga 2: |-7| &gt; |3| + |2| \\implies 7 &gt; 5 (vero)\nRiga 3: |9| &gt; |-2| + |1| \\implies 9 &gt; 3 (vero)\n\nQuindi, la matrice A è a dominanza diagonale stretta per righe.\nAttenzione: È fondamentale considerare i valori assoluti. Se si dimenticano i valori assoluti, si potrebbe erroneamente concludere che una matrice non è a dominanza diagonale stretta per righe.\n2. Matrici a dominanza diagonale stretta per colonne\nSe A è una matrice a dominanza diagonale stretta per colonne, allora la fattorizzazione LU esiste ed è unica. Una matrice A è a dominanza diagonale stretta per colonne se l’elemento diagonale in valore assoluto è strettamente maggiore della somma dei valori assoluti degli altri elementi sulla stessa colonna.\nMatematicamente, questo significa che per ogni colonna j:\n|a_{jj}| &gt; \\sum_{i=1, i\\neq j}^{n} |a_{ij}|\ndove j varia da 1 a n.\nImportante: Una matrice a dominanza diagonale stretta per righe non è necessariamente a dominanza diagonale stretta per colonne, e viceversa.\nEsempio: Riprendendo la matrice A dell’esempio precedente:\nA = \\begin{bmatrix} 4 &amp; 0 &amp; -1 \\\\ 3 &amp; -7 &amp; 2 \\\\ -2 &amp; 1 &amp; 9 \\end{bmatrix}\nVerifichiamo se è a dominanza diagonale stretta per colonne:\n\nColonna 1: |4| &gt; |3| + |-2| \\implies 4 &gt; 5 (falso)\n\nQuindi, la matrice A non è a dominanza diagonale stretta per colonne.\n3. Matrici simmetriche definite positive\nSe A è una matrice simmetrica definita positiva, allora la fattorizzazione LU esiste ed è unica.\n\nSimmetria: una matrice A è simmetrica se A = A^T, ovvero a_{ij} = a_{ji} per ogni i e j. In altre parole, la diagonale è uno specchio. In Matlab, si può verificare la simmetria con il comando A == A&#039; (dove &#039; indica la trasposta).\nDefinita positiva: una matrice A è definita positiva se v^T A v &gt; 0 per ogni vettore v \\in \\mathbb{R}^n diverso dal vettore nullo.\n\nCriterio pratico per verificare se una matrice è definita positiva:\n\nVerificare che la matrice sia simmetrica.\nCalcolare gli autovalori della matrice. Se tutti gli autovalori sono reali e positivi, allora la matrice è definita positiva.\n\nIn Matlab, si può usare il comando eig(A) per calcolare gli autovalori di A.\nFattorizzazione LU per Matrici Non Singolari che Non Soddisfano le Condizioni Precedenti\nSe una matrice A non soddisfa le condizioni sufficienti (dominanza diagonale) o necessarie e sufficienti, è comunque possibile trovare la fattorizzazione LU se A è non singolare. In questo caso, si ricorre al pivoting.\nPivoting: Scambio di Righe\nL’idea base è scambiare le righe della matrice per evitare elementi pivotali nulli o troppo piccoli, che potrebbero compromettere la stabilità numerica dell’algoritmo.\nEsempio:\nConsideriamo la matrice:\nA = \\begin{bmatrix} 1 &amp; 1 &amp; 3 \\\\ 2 &amp; 3 &amp; 6 \\\\ 4 &amp; 5 &amp; 4 \\end{bmatrix}\nDopo alcuni passaggi della fattorizzazione LU senza pivoting, si può arrivare a una matrice con un elemento pivotale nullo. Per ovviare a questo, si scambiano le righe.\nMatrici di Permutazione: Lo scambio di righe si realizza moltiplicando la matrice A per una matrice di permutazione P. Una matrice di permutazione si ottiene permutando le righe della matrice identità.\nEsempio: Per scambiare la riga 2 con la riga 3, la matrice di permutazione è:\nP = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 \\end{bmatrix}\nMoltiplicando P per A, si ottiene una nuova matrice con le righe scambiate: PA.\nAlgoritmo con Pivoting\n\nControllo dell’elemento pivotale: Durante la fattorizzazione LU, se si incontra un elemento pivotale a_{ii} uguale a zero, si scambiano le righe per portare un elemento non nullo in quella posizione.\nScelta della riga da scambiare: Si cerca, tra le righe sottostanti alla riga corrente, quella con l’elemento in valore assoluto più grande nella colonna corrente.\nAggiornamento della matrice di permutazione: Si tiene traccia degli scambi effettuati attraverso una matrice di permutazione P.\nFattorizzazione LU di PA: Alla fine del processo, si ottiene la fattorizzazione LU della matrice PA, dove P è il prodotto di tutte le matrici di permutazione utilizzate.\n\nRisoluzione del Sistema Lineare con Pivoting\nSe l’obiettivo è risolvere il sistema lineare Ax = b, e si è effettuato il pivoting, allora si risolve il sistema equivalente PAx = Pb.\n\nSi calcola Pb, applicando le stesse permutazioni al termine noto b.\nSi risolve il sistema triangolare inferiore Ly = Pb.\nSi risolve il sistema triangolare superiore Ux = y.\n\nPivoting Parziale vs. Pivoting Totale\n\nPivoting Parziale: Si cerca l’elemento massimo in valore assoluto solo nella colonna sotto l’elemento pivotale corrente.\nPivoting Totale: Si cerca l’elemento massimo in valore assoluto in tutta la sottomatrice a destra e in basso rispetto all’elemento pivotale corrente. In questo caso, si scambiano sia righe che colonne, utilizzando due matrici di permutazione, P per le righe e Q per le colonne.\n\nNel pivoting totale, la fattorizzazione diventa PAQ = LU. Per risolvere il sistema lineare Ax = b, si procede come segue:\n\nSi calcola Pb.\nSi risolve Lz = Pb.\nSi risolve Uy = z.\nSi calcola x = Qy.\n\nMotivi per Utilizzare il Pivoting\n\nEvitare divisioni per zero: Se l’elemento pivotale è zero, la fattorizzazione LU si blocca.\nStabilità numerica: Anche se l’elemento pivotale non è zero, ma è molto piccolo, la divisione per questo elemento può amplificare gli errori di arrotondamento, portando a una soluzione inaccurata. Il pivoting aiuta a scegliere elementi pivotali più grandi, riducendo l’amplificazione degli errori.\n\nComando LU in Matlab\nIl comando LU in Matlab implementa sempre il pivoting. La sintassi consigliata è [L, U, P] = lu(A), che restituisce le matrici L, U e P tali che PA = LU.\nPerché Usare [L, U, P] = lu(A) in Matlab invece di [L, U] = lu(A)\nIl professore suggerisce di utilizzare la sintassi completa [L, U, P] = lu(A) invece della sintassi incompleta [L, U] = lu(A) per due motivi principali:\n\nMatlab Implementa Sempre il Pivoting: Il comando lu in Matlab implementa sempre il pivoting. Usando la sintassi [L, U, P] = lu(A), si ottiene esplicitamente la matrice di permutazione P, che permette di tenere traccia degli scambi di righe effettuati durante la fattorizzazione. Questo è utile per capire se il pivoting è stato necessario o meno. Se P è la matrice identità, allora non ci sono stati scambi di righe.\nChiarezza e Controllo: La sintassi completa rende più chiaro il fatto che il pivoting è stato applicato e permette di controllare la matrice di permutazione P. Questo è importante per la stabilità numerica e per la corretta risoluzione del sistema lineare.\n\nUsando la sintassi incompleta [L, U] = lu(A), Matlab esegue comunque il pivoting, ma restituisce matrici L e U tali che A = LU. In realtà, la fattorizzazione calcolata è PA = LU, e la matrice L restituita è in realtà P^{-1}L, dove L è la matrice triangolare inferiore “vera”. Questo può portare a confusione, perché la matrice L ottenuta potrebbe non essere triangolare inferiore.\nImportanza del Pivoting Anche con Elementi Diversi da Zero (ma Piccoli)\nIl pivoting non è necessario solo quando si incontrano elementi pivotali nulli, ma è altamente raccomandato anche quando gli elementi pivotali sono molto piccoli. Questo perché:\n\nStabilità Numerica: La divisione per un elemento pivotale molto piccolo può amplificare gli errori di arrotondamento presenti nei calcoli. Questo può portare a una fattorizzazione LU inaccurata e a una soluzione del sistema lineare molto distante dalla soluzione esatta.\nMoltiplicatori Grandi: Un elemento pivotale piccolo porta a moltiplicatori grandi durante l’eliminazione gaussiana. Questi moltiplicatori, quando applicati ad altre righe, possono amplificare gli errori di arrotondamento, rendendo la soluzione finale inaccurata.\n\nEsempio:\nConsideriamo una matrice A con un elemento pivotale piccolo:\nA = \\begin{bmatrix}1 &amp; 1 + 0.5 \\cdot 10^{-15} &amp; 3 \\\\ 2 &amp; 2 &amp; 20 \\\\ 3 &amp; 6 &amp; 4 \\end{bmatrix}\nAnche se la condizione necessaria e sufficiente per l’esistenza della fattorizzazione LU è soddisfatta, la fattorizzazione LU calcolata senza pivoting può essere molto inaccurata. Questo perché i moltiplicatori risultano essere molto grandi, amplificando gli errori di arrotondamento.\nSoluzione: Pivoting Parziale o Totale\nPer evitare questi problemi, si utilizza il pivoting. L’idea è scambiare le righe (e/o le colonne nel pivoting totale) per portare un elemento pivotale più grande in valore assoluto nella posizione corretta. Questo riduce i moltiplicatori e minimizza l’amplificazione degli errori di arrotondamento, portando a una soluzione più accurata.\nIn sintesi, il pivoting è una tecnica fondamentale per garantire la stabilità numerica della fattorizzazione LU, anche quando gli elementi pivotali non sono esattamente zero. Utilizzare la sintassi [L, U, P] = lu(A) in Matlab permette di tenere traccia degli scambi di righe effettuati e di ottenere una fattorizzazione LU più accurata.\n==Fattorizzazione LU di una matrice tridiagonale\nUna matrice tridiagonale è una matrice in cui gli elementi diversi da zero sono situati solo sulla diagonale principale, sulla prima sovradiagonale e sulla prima sottodiagonale.\nQuando si effettua la fattorizzazione LU di una matrice tridiagonale, le matrici L e U risultano essere bidiagonali.\n\nL è una matrice bidiagonale inferiore con tutti 1 sulla diagonale principale.\nU è una matrice bidiagonale superiore.\n\nEsempio: Consideriamo una matrice tridiagonale 3x3:\nA = \\begin{bmatrix} a_1 &amp; c_1 &amp; 0 \\\\ e_2 &amp; a_2 &amp; c_2 \\\\ 0 &amp; e_3 &amp; a_3 \\end{bmatrix}\nLa sua fattorizzazione LU sarà:\nL = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ \\beta_2 &amp; 1 &amp; 0 \\\\ 0 &amp; \\beta_3 &amp; 1 \\end{bmatrix}\nU = \\begin{bmatrix} \\alpha_1 &amp; \\gamma_1 &amp; 0 \\\\ 0 &amp; \\alpha_2 &amp; \\gamma_2 \\\\ 0 &amp; 0 &amp; \\alpha_3 \\end{bmatrix}\ndove \\gamma_1 = c_1 e \\gamma_2 = c_2.\nPer trovare i valori di \\alpha_i e \\beta_i, si uguagliano gli elementi corrispondenti delle matrici A e LU.\n\n\nCalcolo di \\alpha_1: \\alpha_1 è semplicemente uguale a a_1, dove a_1 è l’elemento diagonale nella prima riga e prima colonna della matrice tridiagonale originale A.\n\n\nCalcolo di \\beta_i per i \\ge 2: \\beta_i è calcolato come:\n\\beta_i = \\frac{e_i}{\\alpha_{i-1}}\ndove e_i è l’elemento sulla sotto-diagonale (i-esima riga, i-1-esima colonna) della matrice originale A e \\alpha_{i-1} è il valore di alfa calcolato al passo precedente. È fondamentale che \\alpha_{i-1} sia diverso da zero per evitare divisioni per zero.\n\n\nCalcolo di \\alpha_i per i \\ge 2: \\alpha_i è calcolato come:\n\\alpha_i = a_i - \\beta_i \\cdot c_{i-1}\ndove:\n\na_i è l’elemento diagonale nella i-esima riga e i-esima colonna della matrice originale A.\n\\beta_i è il valore di beta calcolato al passo corrente.\nc_{i-1} è l’elemento sulla sovra-diagonale (i-1-esima riga, i-esima colonna) della matrice originale A.\n\n\n\nAlgoritmo Generale:\n\nInizia con \\alpha_1 = a_1.\nAlterna il calcolo di \\beta_i e \\alpha_i per ogni i da 2 fino a n.\nPer ogni i, calcola prima \\beta_i usando il valore di \\alpha_{i-1} calcolato precedentemente.\nSuccessivamente, usa il valore di \\beta_i appena calcolato per trovare \\alpha_i.\n\nCosto Computazionale:\nIl costo computazionale di questo algoritmo è 3(n-1), poiché per ogni i (da 2 a n) si eseguono tre operazioni: una divisione per calcolare \\beta_i e una moltiplicazione e una sottrazione per calcolare \\alpha_i. Questo è significativamente più efficiente rispetto alla fattorizzazione LU classica, che ha un costo di O(n^3).\nReferences\nAppunti Mate Num-lez03.pdf\n2025-02-25 12:45\n_Status: flashcard_finite   riscritto_zero  revisione_zero\n_Tags: sbobine  matematica numerica\nMatenum- lez04\n1. Fattorizzazione LU per Matrici Tridiagonali\n1.1. Descrizione del Metodo\nIl metodo della fattorizzazione LU è particolarmente efficace per matrici tridiagonali, ovvero matrici con elementi non nulli solo sulla diagonale principale, sulla prima sopra-diagonale e sulla prima sotto-diagonale.\nLa fattorizzazione LU di una matrice tridiagonale A porta a identificare due fattori:\n\nL (matrice triangolare inferiore) che, in questo caso, è una matrice bidiagonale inferiore con tutti 1 sulla diagonale principale.\nU (matrice triangolare superiore) che, in questo caso, è una matrice bidiagonale superiore.\n\nInoltre, la sopra-diagonale di U coincide esattamente con la sopra-diagonale della matrice A originale.\n1.2. Algoritmo\nL’algoritmo per calcolare la fattorizzazione LU di una matrice tridiagonale ha un costo computazionale di 3n - 1, significativamente inferiore rispetto al costo di \\frac{2}{3} n^3 della fattorizzazione LU standard fornita dalla libreria LAPACK.\n1.3. Risoluzione di Sistemi Lineari con Fattorizzazione LU\nDopo aver ottenuto la fattorizzazione LU, il sistema lineare originale Ax = b viene trasformato in due sistemi più semplici:\n\nLy = b (sistema bidiagonale inferiore)\nUx = y (sistema bidiagonale superiore)\n\nRisolvere questi sistemi bidiagonali è più economico rispetto alla risoluzione di sistemi triangolari standard.\n1.4. Sistema Bidiagonale Inferiore: Ly = b\nConsideriamo un sistema bidiagonale inferiore Ly = b, dove L è una matrice bidiagonale inferiore:\nL = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ \\beta_2 &amp; 1 &amp; 0 \\\\ 0 &amp; \\beta_3 &amp; 1 \\ \\end{bmatrix}, y = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\end{bmatrix}, b = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix}\nRisolvendo il sistema Ly = b, si ottiene:\n\ny_1 = b_1\n\\beta_2 y_1 + y_2 = b_2 \\Rightarrow y_2 = b_2 - \\beta_2 y_1\n\\beta_3 y_2 + y_3 = b_3 \\Rightarrow y_3 = b_3 - \\beta_3 y_2\n\nGeneralizzando per una matrice L di ordine n, l’algoritmo è:\n\ny_1 = b_1\ny_i = b_i - \\beta_i y_{i-1}, per i = 2, \\dots, n\n\nQuesto algoritmo ha un costo di 2n - 1.\n1.5. Sistema Bidiagonale Superiore: Ux = y\nConsideriamo un sistema bidiagonale superiore Ux = y, dove U è una matrice bidiagonale superiore:\nU = \\begin{bmatrix} \\alpha_1 &amp; c_1 &amp; 0 \\\\ 0 &amp; \\alpha_2 &amp; c_2 \\\\ 0 &amp; 0 &amp; \\alpha_3 \\ \\end{bmatrix}, x = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}, y = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{bmatrix}\nRisolvendo il sistema Ux = y, si ottiene:\n\n\\alpha_3 x_3 = y_3 \\Rightarrow x_3 = \\frac{y_3}{\\alpha_3}\n\\alpha_2 x_2 + c_2 x_3 = y_2 \\Rightarrow x_2 = \\frac{1}{\\alpha_2} (y_2 - c_2 x_3)\n\\alpha_1 x_1 + c_1 x_2 = y_1 \\Rightarrow x_1 = \\frac{1}{\\alpha_1} (y_1 - c_1 x_2)\n\nGeneralizzando per una matrice U di ordine n, l’algoritmo è:\n\nx_n = \\frac{y_n}{\\alpha_n}\nx_i = \\frac{1}{\\alpha_i} (y_i - c_i x_{i+1}), per i = n-1, \\dots, 1\n\nQuesto algoritmo ha un costo di 3n - 2.\n1.6. Algoritmo di Thomas\nL’algoritmo di Thomas combina la fattorizzazione LU di una matrice tridiagonale con la risoluzione dei sistemi bidiagonali inferiore e superiore. Il costo totale dell’algoritmo di Thomas è:\n(3n - 1) + (2n - 1) + (3n - 2) = 8n - 4\nQuesto è un risultato notevole, poiché il costo è lineare rispetto alla dimensione del sistema, rendendo l’algoritmo estremamente efficiente per matrici tridiagonali.\n2. Fattorizzazione di Cholesky per Matrici Simmetriche Definite Positive (SDP)\n2.1. Definizione\nUna matrice A è simmetrica definita positiva (SDP) se è simmetrica (A = A^T) e tutti i suoi autovalori sono positivi. Per tali matrici, la fattorizzazione LU esiste ed è unica.\n2.2. Metodo di Cholesky\nLa fattorizzazione di Cholesky decompone una matrice SDP A nella forma:\nA = R^T R\ndove R è una matrice triangolare superiore. Questo significa che è sufficiente calcolare solo un fattore, poiché il fattore triangolare inferiore è semplicemente la trasposta del fattore triangolare superiore.\n2.3. Costo Computazionale\nIl costo computazionale della fattorizzazione di Cholesky è circa la metà della fattorizzazione LU classica, ovvero \\frac{1}{3}n^3.\n2.4. Osservazioni Importanti\nA differenza della fattorizzazione LU standard, i fattori diagonali nella fattorizzazione di Cholesky non sono necessariamente uguali a uno. Tuttavia, le entrate diagonali di R saranno tutte quantità maggiori o uguali a zero.\n3. Matrici Sparse: Strutturate vs. Non Strutturate\n3.1. Definizioni\n\nMatrice sparsa strutturata: è una matrice in cui gli elementi non nulli si dispongono secondo una struttura ben precisa (ad esempio, matrici diagonali o tridiagonali).\nMatrice sparsa non strutturata: è una matrice con pochi elementi non nulli disposti in modo caotico.\n\n3.2. Fattorizzazione LU e Sparsità\n\nSe A è sparsa e strutturata, i fattori L e U ereditano la struttura.\nSe A è sparsa ma non strutturata, i fattori L e U tendono a riempirsi (fill-in).\n\n3.3. Fill-in\nIl fill-in è il fenomeno per cui, durante la fattorizzazione LU di una matrice sparsa, i fattori L e U diventano più densi della matrice originale. Questo aumenta il costo computazionale e la memoria richiesta.\n3.4. Gestione del Fill-in\nPer ridurre il fill-in, si utilizzano algoritmi di riordinamento che permutano le righe e le colonne della matrice per compattare il pattern di sparsità.\n==4. Condizionamento di una Matrice\n4.1. Definizione\nIl numero di condizionamento di una matrice A, indicato con K(A), misura quanto la soluzione di un sistema lineare Ax = b è sensibile a piccole perturbazioni nei dati. È definito come:\nK(A) = |A| |A^{-1}|\ndove | \\cdot | è una norma matriciale.\n4.2. Interpretazione\n\nSe K(A) è piccolo, la matrice è ben condizionata: piccole perturbazioni nei dati portano a piccole perturbazioni nella soluzione.\nSe K(A) è grande, la matrice è mal condizionata: piccole perturbazioni nei dati possono portare a grandi perturbazioni nella soluzione.\n\n4.3. Effetto del Condizionamento\nAnche se la fattorizzazione LU è accurata, una matrice mal condizionata può portare a soluzioni inaccurate a causa degli errori di arrotondamento e delle perturbazioni nei dati.\n4.4. Stima dell’Errore Relativo\nL’errore relativo nella soluzione di un sistema lineare è legato al numero di condizionamento dalla seguente disuguaglianza:\n\\frac{|\\Delta x|}{|x|} \\leq K(A) \\frac{|\\Delta b|}{|b|}\ndove:\n\n\\Delta x è la perturbazione nella soluzione\nx è la soluzione esatta\n\\Delta b è la perturbazione nel termine noto b\n\n4.5. Calcolo del Condizionamento in Matlab\nMatlab fornisce i seguenti comandi per calcolare il numero di condizionamento:\n\ncond(A): calcola il numero di condizionamento usando la norma spettrale (norma 2).\ncond(A, p): calcola il numero di condizionamento usando la norma p.\ncondest(A): stima il numero di condizionamento per matrici sparse usando la norma 1.\n\n4.6. Numero di Condizionamento Spettrale\nIl numero di condizionamento spettrale, K_2(A), è definito come:\nK_2(A) = \\sqrt{\\frac{\\lambda_{max}(A^T A)}{\\lambda_{min}(A^T A)}}\ndove \\lambda_{max} e \\lambda_{min} sono rispettivamente l’autovalore massimo e minimo di A^T A.\nSe A è simmetrica definita positiva, allora:\nK_2(A) = \\frac{\\lambda_{max}(A)}{\\lambda_{min}(A)}\n5. Norme di Vettori e Matrici\n5.1. Norma di un Vettore\n5.1. Norma Euclidea (Norma 2)\nPer un vettore v \\in \\mathbb{R}^n, la norma euclidea è definita come:\n||v||_2 = \\sqrt{\\sum_{i=1}^{n} v_i^2}\n5.2. Norma p\nLa norma p è una generalizzazione della norma euclidea:\n||v||_p = \\left(\\sum_{i=1}^{n} |v_i|^p\\right)^{\\frac{1}{p}}\n5.3. Norma infinito\nLa norma infinito di un vettore v è definita come il massimo valore assoluto delle sue componenti:\n||v||_{\\infty} = \\max_{1 \\leq i \\leq n} |v_i|\n2. Norme Matriciali\nUna norma matriciale è una funzione che assegna una grandezza a una matrice. Esistono diverse norme matriciali, ognuna con proprietà specifiche.\n2.1. Norma Indotta\nUna norma indotta (o norma di оператор) è definita a partire da una norma vettoriale. La norma indotta p di una matrice A è definita come:\n||A||_p = \\sup_{v \\neq 0} \\frac{||Av||_p}{||v||_p}\ndove il \\sup è preso su tutti i vettori non nulli v \\in \\mathbb{R}^n.\n2.2. Norma 1\nLa norma 1 di una matrice è il massimo della somma dei valori assoluti delle colonne:\n||A||_1 = \\max_{1 \\leq j \\leq n} \\sum_{i=1}^{n} |a_{ij}|\n2.3. Norma infinito\nLa norma infinito di una matrice è il massimo della somma dei valori assoluti delle righe:\n||A||_{\\infty} = \\max_{1 \\leq i \\leq n} \\sum_{j=1}^{n} |a_{ij}|\n2.4. Norma 2 (Norma Spettrale)\nLa norma 2 (o norma spettrale) di una matrice A è definita come la radice quadrata dell’autovalore massimo di A^T A:\n||A||_2 = \\sqrt{\\lambda_{\\max}(A^T A)}\nSe A è simmetrica, allora ||A||_2 = \\max_i |\\lambda_i|, dove \\lambda_i sono gli autovalori di A.\n2.5. Norma di Frobenius\nLa norma di Frobenius di una matrice A è definita come la radice quadrata della somma dei quadrati di tutti i suoi elementi:\n||A||_F = \\sqrt{\\sum_{i=1}^{n} \\sum_{j=1}^{n} |a_{ij}|^2}\n3. Compatibilità tra Norme Vettoriali e Matriciali\nUna proprietà importante è la compatibilità tra norme vettoriali e matriciali. Se || \\cdot || è una norma matriciale indotta dalla norma vettoriale || \\cdot ||, allora:\n||Av|| \\leq ||A|| \\cdot ||v||\nper ogni vettore v.\n4. Esempio di Calcolo\nEsempio: Calcolare la norma 1 della matrice:\nA = \\begin{bmatrix} 1 &amp; -2 \\\\ 3 &amp; 4 \\end{bmatrix}\n\nSomma dei valori assoluti per ogni colonna:\n\nColonna 1: |1| + |3| = 4\nColonna 2: |-2| + |4| = 6\n\n\nPrendere il massimo di queste somme:\n\n||A||_1 = \\max(4, 6) = 6\n\n\n\n5. Numero di Condizionamento e Norme\nIl numero di condizionamento di una matrice A dipende dalla norma scelta per calcolarlo:\nK(A) = ||A|| \\cdot ||A^{-1}||\nAd esempio, K_1(A) = ||A||_1 \\cdot ||A^{-1}||_1 e K_2(A) = ||A||_2 \\cdot ||A^{-1}||_2.\n6. Utilizzo in MATLAB\nIn MATLAB, puoi calcolare diverse norme matriciali:\n\nnorm(A, 1): norma 1\nnorm(A, inf): norma infinito\nnorm(A, 2) o norm(A): norma 2 (spettrale)\nnorm(A, &#039;fro&#039;): norma di Frobenius }\n\n\n5.2. Norme di Matrici\nUna norma matriciale è una funzione che assegna un numero reale non negativo a una matrice, soddisfacendo le seguenti proprietà:\n\n|A| \\geq 0 per ogni matrice A\n|A| = 0 se e solo se A = 0\n|\\alpha A| = |\\alpha| |A| per ogni scalare \\alpha\n|A + B| \\leq |A| + |B| per ogni matrice A e B\n\n5.3. Norma Indotta\nLa norma indotta (o norma operatoriale) di una matrice A è definita come:\n|A|_p = \\sup_{v \\neq 0} \\frac{|Av|_p}{|v|_p}\ndove v è un vettore e | \\cdot |_p è una norma vettoriale.\n5.4. Norme Matriciali Comuni\n\nNorma 1: è il massimo della somma dei valori assoluti delle colonne:\n\n|A|_1 = \\max_{1 \\leq j \\leq n} \\sum_{i=1}^{n} |a_{ij}|\n\nNorma infinito: è il massimo della somma dei valori assoluti delle righe:\n\n|A|_{\\infty} = \\max_{1 \\leq i \\leq n} \\sum_{j=1}^{n} |a_{ij}|\n\nNorma 2 (o norma spettrale): è la radice quadrata dell’autovalore massimo di A^T A:\n\n|A|_2 = \\sqrt{\\lambda_{max}(A^T A)}\n\nNorma di Frobenius: è la radice quadrata della somma dei quadrati di tutti gli elementi:\n\n|A|_F = \\sqrt{\\sum_{i=1}^{n} \\sum_{j=1}^{n} |a_{ij}|^2}\n6. Perturbazioni e Condizionamento\n6.1. Sistemi Perturbati\nIn pratica, quando si risolve un sistema lineare Ax = b con metodi numerici, si risolve un sistema perturbato:\n(A + \\Delta A)(x + \\Delta x) = b + \\Delta b\ndove \\Delta A e \\Delta b rappresentano le perturbazioni nella matrice e nel termine noto, rispettivamente, e \\Delta x è la perturbazione nella soluzione.\n6.2. Fonti delle Perturbazioni\nLe perturbazioni sono causate principalmente da:\n\nAritmetica floating-point\nErrori nell’algoritmo\n\n6.3. Obiettivo\nL’obiettivo è capire come le perturbazioni sui dati ( \\Delta A e \\Delta b ) influenzano la soluzione ( \\Delta x ).\n6.4. Matrice di Hilbert\nLa matrice di Hilbert è un esempio classico di matrice mal condizionata. È definita come:\na_{ij} = \\frac{1}{i + j - 1}\nRisolvere un sistema lineare con una matrice di Hilbert può portare a soluzioni molto inaccurate, anche se si utilizza un metodo di fattorizzazione accurato come LU con pivoting.\n6.5. Conclusioni\n\nLa scelta del metodo numerico dipende dalle proprietà della matrice (tridiagonale, SDP, sparsa, ecc.).\nÈ fondamentale valutare il condizionamento della matrice prima di risolvere il sistema.\nMatrici mal condizionate possono portare a soluzioni inaccurate, anche con metodi accurati.\nAlgoritmi di riordinamento possono ridurre il fill-in nelle matrici sparse non strutturate.\n\n\n1. Introduzione al Problema del Condizionamento\nIl condizionamento di una matrice è un concetto cruciale nell’analisi numerica, specialmente quando si risolvono sistemi lineari. Anche se un metodo di fattorizzazione come LU con pivoting produce una fattorizzazione accurata, la soluzione del sistema lineare può essere inaccurata se la matrice è mal condizionata.\n2. Esempio Illustrativo: La Matrice di Hilbert\nPer illustrare questo problema, il professore introduce un esempio specifico: la matrice di Hilbert (o matrice di invert, come menzionato nella trascrizione). Questa matrice è definita come:\na_{ij} = \\frac{1}{i + j - 1}\n\\begin{pmatrix}\n1 &amp; \\frac{1}{2} &amp; \\frac{1}{3} &amp; \\cdots &amp; \\frac{1}{n} \\\\\n\\frac{1}{2} &amp; \\frac{1}{3} &amp; \\frac{1}{4} &amp; \\cdots &amp; \\frac{1}{n+1} \\\\\n\\frac{1}{3} &amp; \\frac{1}{4} &amp; \\frac{1}{5} &amp; \\cdots &amp; \\frac{1}{n+2} \\\\\n\\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n\\frac{1}{n} &amp; \\frac{1}{n+1} &amp; \\frac{1}{n+2} &amp; \\cdots &amp; \\frac{1}{2n-1}\n\\end{pmatrix}\nLa matrice di Hilbert è simmetrica e definita positiva (SDP), il che significa che la fattorizzazione LU esiste ed è unica. Tuttavia, è anche notoriamente mal condizionata.\n2.1. Setup dell’Esperimento Numerico\nPer dimostrare il problema, si imposta un esperimento numerico in MATLAB:\n\nSi sceglie una dimensione n per la matrice A_n e si crea la matrice di Hilbert di dimensione n.\nSi sceglie un termine noto b_n tale che la soluzione esatta x_n sia un vettore di tutti 1. Questo facilita il confronto tra la soluzione calcolata e quella esatta. Il termine noto è scelto come b_n = A_n \\cdot \\mathbb{1}, dove \\mathbb{1} è il vettore con tutte le componenti uguali a 1.\nSi calcola la fattorizzazione LU di A_n con pivoting e si risolve il sistema lineare A_n x = b_n utilizzando MATLAB.\nSi confronta la soluzione ottenuta con la soluzione esatta e si calcola l’errore relativo.\n\n2.2. ==Monitoraggio dell’Accuratezza\nPer monitorare l’accuratezza della fattorizzazione LU, si calcola la matrice residua R_n come:\nR_n = P_n A_n - L_n U_n\ndove P_n è la matrice di permutazione ottenuta dal pivoting. Si verifica che il massimo delle entrate di R_n sia vicino a zero, il che indica che la fattorizzazione LU è accurata.\nSi calcola l’errore relativo \\epsilon_n come:\n\\epsilon_n = \\frac{||x_n - \\tilde{x}_n||}{||x_n||}\ndove \\tilde{x}_n è la soluzione calcolata da MATLAB e || \\cdot || indica la norma euclidea.\n2.3. Risultati dell’Esperimento\nSi osserva che, anche se la fattorizzazione LU è accurata (cioè, ||R_n||_{\\infty} è piccolo), l’errore relativo \\epsilon_n aumenta rapidamente con n. In particolare, per n \\geq 13, l’errore relativo diventa maggiore di 10, il che significa un errore del 1000%.\nQuesto dimostra che, anche con una fattorizzazione accurata, una matrice mal condizionata può portare a risultati disastrosi.\n3. Analisi del Problema: Sistemi Perturbati\nPer capire perché succede questo, il professore spiega che MATLAB non risolve il sistema originale Ax = b, ma un sistema perturbato:\n(A + \\Delta A)(x + \\Delta x) = b + \\Delta b\ndove \\Delta A e \\Delta b sono perturbazioni nei dati dovute all’aritmetica floating-point e agli errori nell’algoritmo.\n3.1. Fonti delle Perturbazioni\nLe perturbazioni \\Delta A e \\Delta b sono causate principalmente da due fattori:\n\nAritmetica floating-point: I calcoli vengono eseguiti con precisione finita, il che introduce errori di arrotondamento.\nAlgoritmo stesso: La scelta dei moltiplicatori e le operazioni eseguite nell’algoritmo possono amplificare gli errori di arrotondamento.\n\n3.2. Obiettivo: Legare Perturbazioni e Risultati\nL’obiettivo è capire come le perturbazioni nei dati influenzano la soluzione. In un mondo ideale, piccole perturbazioni nei dati dovrebbero portare a piccole perturbazioni nella soluzione. Tuttavia, questo non è sempre il caso, specialmente con matrici mal condizionate.\n4. Il Numero di Condizionamento\nIl numero di condizionamento di una matrice A, indicato con K(A), quantifica la sensibilità della soluzione di un sistema lineare alle perturbazioni nei dati. È definito come:\nK(A) = ||A|| \\cdot ||A^{-1}||\ndove || \\cdot || è una norma matriciale.\n4.1. Interpretazione del Numero di Condizionamento\n\nSe K(A) è piccolo, la matrice è ben condizionata: piccole perturbazioni nei dati portano a piccole perturbazioni nella soluzione.\nSe K(A) è grande, la matrice è mal condizionata: piccole perturbazioni nei dati possono portare a grandi perturbazioni nella soluzione.\n\n4.2. Stima dell’Errore Relativo\nL’errore relativo nella soluzione di un sistema lineare è legato al numero di condizionamento dalla seguente disuguaglianza:\n\\frac{||\\Delta x||}{||x||} \\leq K(A) \\frac{||\\Delta b||}{||b||}\ndove:\n\n\\Delta x è la perturbazione nella soluzione\nx è la soluzione esatta\n\\Delta b è la perturbazione nel termine noto b\n\nQuesta disuguaglianza mostra che l’errore relativo nella soluzione può essere amplificato dal numero di condizionamento.\n4.3. Esempio Numerico\nSupponiamo che la perturbazione relativa nei dati sia 10^{-10}. Se K(A) = 1, allora l’errore relativo nella soluzione sarà al più 10^{-10}. Tuttavia, se K(A) = 10^4, allora l’errore relativo nella soluzione potrebbe essere fino a 10^{-6}, che è molto più grande.\n4.4. Calcolo del Condizionamento in MATLAB\nMATLAB fornisce diversi comandi per calcolare il numero di condizionamento:\n\ncond(A): Calcola il numero di condizionamento usando la norma spettrale (norma 2).\ncond(A, p): Calcola il numero di condizionamento usando la norma p.\ncondest(A): Stima il numero di condizionamento per matrici sparse usando la norma 1.\n\n4.5. Numero di Condizionamento Spettrale\nIl numero di condizionamento spettrale, K_2(A), è definito come:\nK_2(A) = \\sqrt{\\frac{\\lambda_{max}(A^T A)}{\\lambda_{min}(A^T A)}}\ndove \\lambda_{max} e \\lambda_{min} sono rispettivamente l’autovalore massimo e minimo di A^T A.\nSe A è simmetrica definita positiva, allora:\nK_2(A) = \\frac{\\lambda_{max}(A)}{\\lambda_{min}(A)}\n5. Dimostrazione della Disuguaglianza Fondamentale\nIl professore fornisce una dimostrazione della disuguaglianza che lega l’errore relativo nella soluzione all’errore relativo nei dati e al numero di condizionamento.\nSi parte dal sistema esatto:\nAx = b\ne dal sistema perturbato:\nA\\tilde{x} = \\tilde{b} = b + \\Delta b\n==Si sottrae membro a membro e si ottiene:\nA(x - \\tilde{x}) = \\Delta b\nDa cui:\nx - \\tilde{x} = A^{-1} \\Delta b\nPrendendo le norme e usando la compatibilità tra norma matriciale e norma vettoriale:\n||x - \\tilde{x}|| \\leq ||A^{-1}|| \\cdot ||\\Delta b||\nSi riparte dal sistema esatto e si prende la norma:\n||b|| = ||Ax|| \\leq ||A|| \\cdot ||x||\nDa cui:\n\\frac{1}{||x||} \\leq \\frac{||A||}{||b||}\nCombinando le due disuguaglianze, si ottiene:\n\\frac{||x - \\tilde{x}||}{||x||} \\leq ||A|| \\cdot ||A^{-1}|| \\frac{||\\Delta b||}{||b||} = K(A) \\frac{||\\Delta b||}{||b||}\nche è la disuguaglianza desiderata.\n6. Conclusioni\nIn sintesi, il condizionamento di una matrice è un fattore cruciale da considerare quando si risolvono sistemi lineari. Anche se un metodo di fattorizzazione è accurato, una matrice mal condizionata può portare a soluzioni molto inaccurate. Pertanto, è sempre consigliabile calcolare il numero di condizionamento prima di risolvere un sistema lineare e, se la matrice è mal condizionata, considerare metodi alternativi o tecniche di regolarizzazione.\nReferences\nAppunti Mate Num- lez04.pdf\n2025-02-26 15:31\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:   sbobine   matematica numerica\nmateNum- Lez05\nPerturbazione dei sistemi lineari e condizionamento\n\n\nProblema: Risolvere accuratamente un sistema lineare Ax = b quando si usa la fattorizzazione LU. Anche se la fattorizzazione LU è accurata, l’output di MATLAB per x può differire significativamente dalla soluzione x.\n\n\nMotivo: MATLAB risolve un sistema perturbato: (A + \\delta A)x = b + \\delta b dove \\delta A è una perturbazione sulla matrice dei coefficienti e \\delta b è una perturbazione sul termine noto. Queste perturbazioni inducono una perturbazione \\delta x sulla soluzione.\n\n\nAnalisi semplificata: Inizialmente, si considera solo la perturbazione sul termine noto, quindi \\delta A = 0.\n\n\nRelazione tra perturbazione sulla soluzione e perturbazione sul termine noto\nSi cerca una relazione tra la perturbazione sulla soluzione (\\delta x) e la perturbazione sul termine noto (\\delta b).\n\n\nNumero di condizionamento: Definito come il prodotto della norma di A per la norma dell’inversa di A, cioè cond(A) = ||A|| \\cdot ||A^{-1}||. Esistono diverse definizioni di norma di matrice e, di conseguenza, diverse definizioni di condizionamento.\n\n\nImportanza del condizionamento:\n\nSe il numero di condizionamento è piccolo, una piccola perturbazione sui dati (\\delta b) porta a una piccola perturbazione sulla soluzione (\\delta x). In questo caso, il sistema è ben condizionato.\nViceversa, un numero di condizionamento grande amplifica anche piccole perturbazioni sui dati, portando a una soluzione molto diversa. Un esempio è la matrice di Hilbert.\n\n\n\n==Caso generale: perturbazioni su A e b\nSi rimuove l’ipotesi semplificativa \\delta A = 0 per considerare il caso reale con perturbazioni sia su A che su b.\n\n\nCondizione: Si assume che || \\delta A || \\cdot || A^{-1} || &lt; 1.\n\n\nRisultato generale: La perturbazione sulla soluzione è controllata dalla seguente relazione: \\frac{||\\delta x||}{||x||} \\leq \\frac{cond(A)}{1 - cond(A) \\frac{||\\delta A||}{||A||}} \\left( \\frac{||\\delta A||}{||A||} + \\frac{||\\delta b||}{||b||} \\right) Questo risultato generalizza il caso semplificato. Se \\delta A = 0, si ritrova la relazione precedente.\n\n\nVerifica della positività del denominatore: La condizione || \\delta A || \\cdot || A^{-1} || &lt; 1 assicura che il denominatore sia strettamente positivo. Dividendo entrambi i membri per ||A|| \\cdot ||A^{-1}||, si ottiene:\n\n\n\n\n\n\\frac{||\\delta A||}{||A||} &lt; \\frac{1}{cond(A)} Moltiplicando per -cond(A), si ha 1 - cond(A) \\frac{||\\delta A||}{||A||} &gt; 0.\n\n\nResiduo\n\n\nDefinizione: Il residuo R è ciò che rimane quando si sostituisce la soluzione approssimata nel problema esatto. R = b - A\\tilde{x} dove \\tilde{x} è la soluzione approssimata. Idealmente, se \\tilde{x} è vicino alla soluzione esatta, R è vicino a zero.\n\n\nRelazione con la perturbazione: Si dimostra che \\delta b = -R quando \\delta A = 0. \\delta b = A(x + \\delta x) - Ax = A \\delta x e R = b - A\\tilde{x} = Ax - A\\tilde{x} = -A \\delta x.\n\n\n\n\n\nStima equivalente: La stima della perturbazione sulla soluzione può essere riscritta usando il residuo normalizzato (immagino con delta A = 0 ):\n\\frac{||\\delta x||}{||x||} \\leq cond(A) \\frac{||R||}{||b||}\n\n\nPrecondizionatore\n\nProblema: Cosa fare se il problema è mal condizionato?\nSoluzione: Utilizzare un precondizionatore P, una matrice invertibile. L’obiettivo è trovare un P tale che il condizionamento della matrice precondizionata P^{-1}A sia molto più piccolo del condizionamento di A: cond(P^{-1}A) &lt;&lt; cond(A)\nRiscrivere il sistema: Moltiplicare il sistema Ax = b per P^{-1}: P^{-1}Ax = P^{-1}b Si risolve quindi A_{new}x = b_{new}, dove A_{new} = P^{-1}A e b_{new} = P^{-1}b.\nPrecondizionatore ideale: Idealmente, P dovrebbe essere A^{-1}, in modo che P^{-1}A = I (matrice identità) e cond(I) = 1. Questo non è sempre possibile, ma fornisce una direzione.\n\nMetodi iterativi\nTerminologia\n\n\nMetodo iterativo: Una “black box” in cui entra un valore iniziale (guess iniziale) x_0 e produce un’approssimazione x_1, che viene reintrodotta nella black box per generare x_2, e così via.\n\n\nGuess iniziale: Un’ipotesi iniziale per la soluzione.\n\n\nApprossimazioni successive: Partendo dal guess iniziale, il metodo genera una collezione di approssimazioni x_k per la soluzione x: \\set{x_k}_{k=0}^{\\infty}, \\quad x_k \\in \\mathbb{R}^n, \\quad x_k \\approx x\n\n\nCriteri di arresto\nPoiché non si può iterare all’infinito, è necessario un criterio di arresto.\n\nNumero massimo di iterazioni (N_{max}): Si fissa un numero massimo di iterazioni. Questo può essere scelto arbitrariamente o in base al tempo massimo consentito per la computazione.\nControllo sull’accuratezza: Si cerca di controllare l’accuratezza della soluzione. Idealmente, si vorrebbe che: ||x - x_k|| &lt; tolleranza dove la tolleranza è un valore fissato dall’utente (es. 10^{-q}). Tuttavia, poiché x è sconosciuta, si controlla uno stimatore dell’errore.\n\nStimatori dell’errore\n\nIncremento: La differenza tra due iterazioni successive: ||x_{k+1} - x_k|| &lt; tolleranza L’idea è che, se il metodo converge, le iterazioni successive saranno sempre più vicine.\nResiduo: Si utilizza il residuo R = b - Ax_k: ||R|| = ||b - Ax_k|| &lt; tolleranza Se x_k fosse la soluzione esatta, il residuo sarebbe zero.\n\n\nAffidabilità degli stimatori: È fondamentale studiare l’affidabilità degli stimatori, perché potrebbe esserci una costante che influenza la stima dell’errore: ||x - x_k|| \\leq C \\cdot ||x_{k+1} - x_k|| Se C è molto grande, lo stimatore potrebbe non essere affidabile.\n\nConvergenza\n\n\nDefinizione: Si desidera che la successione di approssimazioni converga alla soluzione esatta: \\lim_{k \\to \\infty} x_k = x Questo limite va inteso componente per componente.\n\n\nErrore all’iterata k-esima: e_k = x - x_k. La convergenza può essere espressa come: \\lim_{k \\to \\infty} e_k = 0\n\n\nSchema iterativo generico\nSi ipotizza che la black box generi una nuova approssimazione attraverso una combinazione lineare: x_{k+1} = Bx_k + G dove B \\in \\mathbb{R}^{n \\times n} e G \\in \\mathbb{R}^n. B e G definiscono il metodo iterativo. B è legata alla matrice A, mentre G è legata sia ad A che al termine noto b.\nConsistenza\n\n\nDefinizione: Un metodo numerico è consistente con il problema se, sostituendo la soluzione esatta nello schema, l’uguaglianza è soddisfatta: x = Bx + G Questo certifica che il metodo non è “folle” e che è coerente con il problema che si vuole risolvere.\n\n\nLegame tra G, A e b: Dalla consistenza, si può dimostrare che G dipende sia da A che da b.\n\n\nAnalisi di convergenza\n\n\nLa sola consistenza non è sufficiente: Un esempio è B = I (matrice identità) e G = 0. In questo caso, x_{k+1} = x_k, quindi non c’è convergenza a meno che x_0 = x.\n\n\nCondizione sufficiente per la convergenza: Supponendo che il metodo sia consistente, si sottrae lo schema iterativo dalla relazione di consistenza: x_{k+1} - x = Bx_k + G - (Bx + G) = B(x_k - x) Quindi e_{k+1} = Be_k. Prendendo le norme: ||e_{k+1}|| = ||Be_k|| \\leq ||B|| \\cdot ||e_k|| Iterando, si ottiene:\n\n\n||e_{k+1}|| \\leq ||B||^{k+1} \\cdot ||e_0|| Affinché ||e_k|| \\to 0 per k \\to \\infty, è sufficiente che ||B|| &lt; 1.\n\n\nCondizione necessaria e sufficiente per la convergenza: Il teorema fondamentale afferma che, se lo schema è consistente, allora converge per ogni scelta di x_0 se e solo se il raggio spettrale di B è minore di 1: \\rho(B) &lt; 1 dove \\rho(B) = \\max{|\\lambda| : \\lambda \\text{ autovalore di } B}.\n\n\nLemma utile: Per dimostrare il teorema, data una C \\in \\mathbb{R}^{n x n} si usa il fatto che C^k \\to 0 se e solo se \\rho(C) &lt; 1. Inoltre, \\rho(C) \\leq ||C||.\n\n\nVelocità di convergenza: Più piccolo è il raggio spettrale, più rapida è la convergenza.\n\n\nSchema iterativo di Richardson\n\n\nPartenza: Si parte dal sistema Ax = b e si moltiplica per una costante \\alpha_k: \\alpha_k Ax = \\alpha_k b\n\n\nManipolazione algebrica: Si riscrive \\alpha_k A come P - (P - \\alpha_k A), dove P è una matrice invertibile (il precondizionatore): Px - (P - \\alpha_k A)x = \\alpha_k b\n\n\nSchema iterativo: Si decide arbitrariamente di associare il termine a sinistra con la nuova iterata e quello a destra con la vecchia iterata: Px_{k+1} = (P - \\alpha_k A)x_k + \\alpha_k b\n\n\nConsistenza per costruzione: Questo schema è consistente per costruzione, perché si è partiti dall’equazione esatta e si è semplicemente manipolata algebricamente.\n\n\nForma esplicita: Moltiplicando per P^{-1}, si ottiene la forma x_{k+1} = Bx_k + G: x_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b dove B_{\\alpha_k} = I - \\alpha_k P^{-1} A e G_{\\alpha_k} = \\alpha_k P^{-1} b.\n\n\nAlgoritmo:\n\nDato x_0 (guess iniziale).\nPer k \\geq 0, calcola: x_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\n\n\n\nMetodi di Richardson stazionari e dinamici:\n\nStazionario: \\alpha_k = \\alpha per ogni k (parametro costante).\nDinamico: \\alpha_k varia ad ogni iterazione.\n\n\n\n\nMetodi Iterativi per Sistemi di Equazioni Lineari\nIntroduzione ai Metodi Iterativi\nI metodi iterativi rappresentano un blocco fondamentale per la risoluzione di sistemi di equazioni lineari, in alternativa ai metodi diretti.\nTerminologia e Concetti Chiave\nQuando si parla di un metodo iterativo, si può immaginare una “scatola nera” (black box).\n\nGuess Iniziale: All’interno di questa scatola nera entra un valore iniziale, chiamato “guess iniziale” (o ipotesi iniziale). Il guess iniziale viene indicato con x_0. Il verbo “guess” significa “ipotizzare”.\nApprossimazione della Soluzione: In corrispondenza di x_0, la scatola nera produce una quantità x_1, che rappresenta la prima approssimazione della soluzione.\nIterazione: Questa x_1 rientra nella scatola nera, generando x_2, e così via. Quindi, partendo dal guess iniziale, si genera una sequenza di approssimazioni.\n\nNel contesto specifico della risoluzione di sistemi di equazioni lineari (Ax = b), x_0 è un’approssimazione per x, che è un vettore di R^n. Ogni approssimazione successiva (x_k) sarà anch’essa un vettore di R^n.\nIdealmente, la black box genera una collezione infinita di approssimazioni per x. Avremo quindi una collezione di x_k, con k che varia da 0 a infinito, dove ogni x_k appartiene a R^n e approssima x.\nCriterio d’Arresto\nDato che il concetto di infinito non è gestibile da un calcolatore, ogni metodo iterativo deve essere dotato di un criterio d’arresto (stop). Questo criterio indica quando fermare il processo iterativo.\nTipi di Criteri d’Arresto\n\n\nNumero Massimo di Iterazioni: Si fissa un numero massimo di iterazioni (N_{max}). Questo valore può essere scelto arbitrariamente o in base al tempo massimo consentito per l’esecuzione. Tuttavia, questo criterio da solo non garantisce una buona accuratezza.\n\n\nControllo sull’Accuratezza: Si cerca di controllare l’accuratezza, imponendo che la differenza tra la soluzione esatta (x) e l’approssimazione corrente (x_k) sia inferiore a una certa tolleranza (\\epsilon):\n||x - x_k|| &lt; \\epsilon\nLa tolleranza (\\epsilon = 10^{-q}) è definita dall’utente e deve essere coerente con i valori misurati.\n\n\nIdealmente, si utilizzano entrambi i criteri in combinazione:\n\nIl criterio sul numero massimo di iterazioni evita di iterare all’infinito se l’accuratezza desiderata non viene mai raggiunta.\nIl criterio sull’accuratezza permette di fermarsi prima se si raggiunge la tolleranza desiderata.\n\nStima dell’Errore\nDato che la soluzione esatta x non è nota, si utilizzano degli stimatori per controllare l’accuratezza. Due stimatori comuni sono:\n\nIncremento: La differenza tra due approssimazioni successive: ||x_{k+1} - x_k||.\nResiduo: Definito come r_k = b - Ax_k. Il residuo indica quanto la soluzione approssimata soddisfa l’equazione originale.\n\nIdealmente, si vorrebbe che:\n||x - x_k|| \\le S &lt; \\epsilon\nDove S è lo stimatore. Tuttavia, in pratica, esiste una costante che può influenzare l’affidabilità dello stimatore:\n||x - x_k|| \\le C \\cdot S\nSe C è molto grande, lo stimatore potrebbe non essere affidabile.\nConvergenza\nIdealmente, si desidera che la successione di approssimazioni x_k converga alla soluzione esatta x per k che tende a infinito:\n\\lim_{k \\to \\infty} x_k = x\nQuesto significa che ogni componente del vettore x_k deve tendere alla corrispondente componente del vettore x.\nIn modo equivalente, si può definire l’errore all’iterata k-esima come:\ne_k = x - x_k\nE richiedere che:\n\\lim_{k \\to \\infty} e_k = 0\nDove 0 è il vettore nullo.\nForma Generale di uno Schema Iterativo\nSi ipotizza che la black box generi una nuova approssimazione x_{k+1} a partire dalla precedente x_k attraverso una combinazione lineare:\nx_{k+1} = Bx_k + g\nDove:\n\nB è una matrice di iterazione di dimensioni n \\times n.\ng è un vettore.\n\nB e g identificano il metodo iterativo. La matrice B è legata alla matrice A del sistema originale, mentre il vettore g è legato sia ad A che al termine noto b.\nConsistenza\nUn metodo numerico si dice consistente con il problema se, rimpiazzando nel metodo la soluzione esatta, l’uguaglianza è verificata:\nx = Bx + g\nIn altre parole, il metodo è coerente con il problema che si sta cercando di risolvere.\nLegame tra g, A e b\nIl vettore g dipende sia dalla matrice A che dal termine noto b. Possiamo riscrivere l’equazione di consistenza come:\nx = Bx + g \\implies g = x - Bx = (I - B)x\nDato che x = A^{-1}b, possiamo scrivere:\ng = (I - B)A^{-1}b\nQuesto dimostra che g dipende sia da A che da b.\nCondizione Sufficiente per la Convergenza\nLa sola consistenza non è sufficiente a garantire la convergenza.\nEsempio:\nSe si sceglie B = I (matrice identità) e g = 0 (vettore nullo), il metodo è consistente, ma x_{k+1} = x_k, quindi non c’è convergenza a meno che il guess iniziale non sia già la soluzione esatta.\nSupponendo che il metodo sia consistente, sottraiamo la relazione di consistenza dallo schema iterativo:\nx_{k+1} - x = Bx_k + g - (Bx + g) = B(x_k - x)\nDefinendo l’errore come e_k = x - x_k, otteniamo:\ne_{k+1} = Be_k\nPrendendo la norma (ad esempio, la norma 2) di entrambi i membri:\n||e_{k+1}|| = ||Be_k|| \\le ||B|| \\cdot ||e_k||\nIterando, otteniamo:\n||e_{k+1}|| \\le ||B||^{k+1} \\cdot ||e_0||\nAffinché l’errore tenda a zero per k \\to \\infty, è sufficiente che:\n||B|| &lt; 1\nQuindi, se il metodo è consistente e la norma di B è strettamente minore di 1, il metodo è convergente.\nCondizione Necessaria e Sufficiente per la Convergenza\nUn teorema fondamentale stabilisce una condizione necessaria e sufficiente per la convergenza:\nTeorema: Sia lo schema x_{k+1} = Bx_k + g consistente. Allora, il metodo converge per ogni scelta del guess iniziale x_0 se e solo se il raggio spettrale di B è strettamente minore di 1.\nRaggio Spettrale\nIl raggio spettrale di una matrice B, indicato con \\rho(B), è il massimo dei moduli degli autovalori di B:\n\\rho(B) = \\max_i |\\lambda_i|\nDove \\lambda_i sono gli autovalori di B.\nLemma\nPer dimostrare il teorema, abbiamo bisogno di due risultati preliminari:\n\nSia C una matrice a entrate reali. Allora, C^k \\to 0 (componente per componente) se e solo se \\rho(C) &lt; 1.\nEsiste una relazione tra il raggio spettrale e la norma 2 di una matrice: \\rho(B) \\le ||B||_2.\n\nDimostrazione del Teorema\nPartiamo dalla relazione:\ne_{k+1} = Be_k\nIterando:\ne_{k+1} = B^{k+1}e_0\nL’errore e_{k+1} tende a zero indipendentemente da e_0 se e solo se B^{k+1} tende alla matrice nulla. Grazie al lemma (punto 1), questo accade se e solo se \\rho(B) &lt; 1.\nOsservazione\nSe ||B||_2 &lt; 1, allora, grazie al lemma (punto 2), anche \\rho(B) &lt; 1, e quindi il metodo converge. Tuttavia, può succedere che \\rho(B) &lt; 1 ma ||B||_2 &gt; 1, quindi la condizione sulla norma è solo sufficiente.\nVelocità di Convergenza\nLa grandezza del raggio spettrale determina anche la velocità di convergenza: più piccolo è \\rho(B), più rapida è la convergenza. Se abbiamo due metodi con matrici di iterazione B_1 e B_2 e \\rho(B_1) = 0.9 e \\rho(B_2) = 0.1, allora il secondo metodo converge più rapidamente.\nCostruzione di uno Schema Iterativo Generico: Metodo di Richardson\nPartiamo dal sistema lineare:\nAx = b\nMoltiplichiamo entrambi i membri per una costante \\alpha_k:\n\\alpha_k Ax = \\alpha_k b\nIntroduciamo una matrice invertibile P (precondizionatore) e riscriviamo \\alpha_k A come:\n\\alpha_k A = P - (P - \\alpha_k A)\nQuindi, il sistema diventa:\nPx - (P - \\alpha_k A)x = \\alpha_k b\nRisolvendo per Px:\nPx = (P - \\alpha_k A)x + \\alpha_k b\nIn modo arbitrario, associamo il membro di sinistra con la nuova iterata x_{k+1} e il membro di destra con la vecchia iterata x_k:\nPx_{k+1} = (P - \\alpha_k A)x_k + \\alpha_k b\nQuesto schema è consistente per costruzione. Per scriverlo nella forma x_{k+1} = Bx_k + g, moltiplichiamo per P^{-1}:\nx_{k+1} = P^{-1}(P - \\alpha_k A)x_k + \\alpha_k P^{-1}b\nQuindi:\nB_{\\alpha_k} = P^{-1}(P - \\alpha_k A) = I - \\alpha_k P^{-1}A\ng_{\\alpha_k} = \\alpha_k P^{-1}b\nL’algoritmo iterativo è:\n\nDato x_0 (guess iniziale)\nPer k \\ge 0: x_{k+1} = B_{\\alpha_k}x_k + g_{\\alpha_k}\n\nQuesto schema è noto come metodo di Richardson.\nMetodo di Richardson Stazionario e Dinamico\n\nStazionario: Se il parametro \\alpha_k è costante (\\alpha_k = \\alpha per ogni k), il metodo è detto stazionario.\nDinamico: Se il parametro \\alpha_k varia ad ogni iterazione, il metodo è detto dinamico.\n\nIn generale, un metodo dinamico può adattarsi meglio al problema, ma richiede un costo computazionale maggiore per la determinazione di \\alpha_k ad ogni iterazione.\n\nTeorema Fondamentale per i Metodi Iterativi\nIl teorema cardine per i metodi iterativi stabilisce una condizione necessaria e sufficiente per la convergenza di uno schema iterativo.\nIpotesi:\n\nSi considera uno schema iterativo nella forma: x_{k+1} = Bx_k + g\nLo schema è consistente, ovvero x = Bx + g\n\nTesi:\nEsiste equivalenza tra le seguenti affermazioni:\n\nIl raggio spettrale di B, indicato con \\rho(B), è strettamente minore di 1, cioè \\rho(B) &lt; 1\nLo schema converge, indipendentemente dalla scelta del guess iniziale x_0 \\in \\mathbb{R}^n\n\nDefinizione di Raggio Spettrale\nIl raggio spettrale \\rho(B) è definito come il massimo dei moduli degli autovalori della matrice B. Formalmente:\n\\rho(B) = \\max_i |\\lambda_i| dove \\lambda_i sono gli autovalori di B.\nIn MATLAB, il raggio spettrale può essere calcolato con la seguente sequenza di comandi:\neig(B); % Calcola gli autovalori di B\nabs();   % Calcola il valore assoluto (modulo) degli autovalori\nmax();   % Trova il massimo tra i moduli degli autovalori\n\nLemmi Utili per la Dimostrazione\nPer dimostrare il teorema, sono necessari due lemmi:\nLemma 1:\nSe C è una matrice a elementi reali, allora C^k \\rightarrow 0 (la potenza k-esima di C tende a zero) se e solo se \\rho(C) &lt; 1.\nLemma 2:\nEsiste una relazione tra il raggio spettrale di una matrice e la sua norma 2, ma solo in una direzione: \\rho(B) \\le ||B||_2. Non vale il viceversa.\nDimostrazione del Teorema\n\n\nPunto di partenza: Si sottrae lo schema iterativo dalla relazione di consistenza:\ne_{k+1} = x_{k+1} - x = Bx_k + g - (Bx + g) = B(x_k - x) = Be_k\ndove e_k rappresenta l’errore al passo k.\n\n\nIterazione: Iterando la relazione, si ottiene:\ne_{k+1} = B e_k = B^2 e_{k-1} = \\dots = B^{k+1} e_0\n\n\nConvergenza: L’errore e_{k+1} tende a zero indipendentemente da x_0 se e solo se B^{k+1} \\rightarrow 0.\n\n\nApplicazione del Lemma 1: Per il Lemma 1, B^{k+1} \\rightarrow 0 se e solo se \\rho(B) &lt; 1.\n\n\nPertanto, la convergenza dello schema è equivalente alla condizione \\rho(B) &lt; 1.\nOsservazioni aggiuntive\n\n\nImportanza della libertà di scelta del guess iniziale: La possibilità di scegliere liberamente il guess iniziale è fondamentale, specialmente in contesti come i metodi per equazioni non lineari, dove una scelta errata può compromettere la convergenza.\n\n\nLegame tra norma 2 e raggio spettrale: Se ||B||_2 &lt; 1, allora, grazie al Lemma 2, \\rho(B) &lt; 1, e quindi il metodo converge. Tuttavia, la convergenza può verificarsi anche se ||B||_2 &gt; 1, purché \\rho(B) &lt; 1.\n\n\nVelocità di convergenza: La grandezza del raggio spettrale determina la velocità di convergenza: più piccolo è \\rho(B), più rapida è la convergenza.\nEsempio: Dati due metodi, M1 con \\rho(B_1) = 0.9 e M2 con \\rho(B_2) = 0.1, si preferirà M2 perché converge più rapidamente.\n\n\nCostruzione di uno Schema Iterativo Generico: Il Metodo di Richardson\nIl professore introduce un metodo iterativo generico, noto come metodo di Richardson, partendo dal sistema lineare Ax = b e manipolandolo algebricamente per ottenere uno schema iterativo nella forma x_{k+1} = Bx_k + g.\nPassaggi Chiave\n\n\nMoltiplicazione per una costante: Si moltiplica il sistema per una costante \\alpha_k:\n\\alpha_k Ax = \\alpha_k b\n\n\nIntroduzione della matrice P: Si riscrive \\alpha_k A introducendo una matrice invertibile P (il precondizionatore):\n\\alpha_k A = P - (P - \\alpha_k A)\n\n\nRiscrittura del sistema: Si sostituisce questa espressione nel sistema originale:\nPx - (P - \\alpha_k A)x = \\alpha_k b\n\n\nDefinizione dello schema iterativo: Si associa il termine Px con la nuova iterata x_{k+1} e il resto con l’iterata precedente x_k:\nPx_{k+1} = (P - \\alpha_k A)x_k + \\alpha_k b\n\n\nForma Finale dello Schema di Richardson\nPer ottenere la forma canonica x_{k+1} = Bx_k + g, si moltiplica per P^{-1}:\nx_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\nDove:\n\nB_{\\alpha_k} = I - \\alpha_k P^{-1} A è la matrice di iterazione\ng_{\\alpha_k} = \\alpha_k P^{-1} b è il termine noto\n\nL’algoritmo risultante è:\n\nDato x^{(0)} (guess iniziale)\nPer k \\ge 0: x_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\n\nMetodi di Richardson Stazionari e Dinamici\n\nStazionario: \\alpha_k = \\alpha (costante per ogni k)\nDinamico: \\alpha_k varia ad ogni iterazione\n\nLa scelta tra stazionario e dinamico dipende dal problema specifico e dagli obiettivi di convergenza.\nGli schemi di Richardson sono consistenti per costruzione, il che significa che non è necessario verificare esplicitamente la condizione di consistenza quando si studia la convergenza. È sufficiente dimostrare che il raggio spettrale della matrice di iterazione è minore di 1.\nReferences\nAppunti Mate Num-lez05.pdf\n2025-03-03 18:01\n_Status: flashcard_finite  riscritto_zero  revisione_zero\n_Tags:sbobine matematica numerica\nmateNum- Lez06\nMetodi Iterativi per Sistemi di Equazioni Lineari\nI metodi iterativi sono utilizzati per risolvere sistemi di equazioni lineari attraverso una successione di approssimazioni. L’idea fondamentale è di partire da una stima iniziale della soluzione e di raffinare iterativamente questa stima fino a raggiungere un livello di accuratezza desiderato.\nSchema Generale\nUn metodo iterativo genera una successione di iterate regolata dalla legge:\nx_{k+1} = Bx_k + g\ndove:\n\nx_{k+1} è la nuova iterazione\nx_k è l’iterazione precedente\nB è la matrice di iterazione\ng è un vettore\n\nConvergenza e Consistenza\n\nConvergenza: Si desidera che la successione delle iterate converga alla soluzione del sistema lineare.\nConsistenza: Il metodo deve essere consistente, ovvero la soluzione del sistema deve essere un punto fisso dell’iterazione.\n\nCondizione Necessaria e Sufficiente per la Convergenza\nLa condizione necessaria e sufficiente per la convergenza è che il raggio spettrale della matrice di iterazione B sia strettamente minore di 1.\nMetodo di Richardson\nIl metodo di Richardson è una famiglia di metodi iterativi che parte dalla riscrittura del sistema lineare originale.\nSplitting\nSi introduce una matrice di precondizionamento P e un parametro \\alpha_k. Il sistema viene riscritto come:\n\\alpha_k A = P - (P - \\alpha_k A)\nSchema Iterativo\nLo schema iterativo di Richardson è dato da:\nx_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\ndove:\n\nI è la matrice identità\nP è la matrice di precondizionamento\n\\alpha_k è un parametro di accelerazione\n\nMetodo di Richardson Stazionario e Dinamico\n\nStazionario: Se \\alpha_k è uguale ad ogni iterazione (\\alpha_k = \\alpha).\nDinamico: Se \\alpha_k varia ad ogni iterazione.\n\nRiscrittura del Metodo di Richardson\n\nUn modo computazionalmente utile per riscrivere il metodo di Richardson è:\nx_{k+1} = x_k + \\alpha_k P^{-1} (b - Ax_k)\ndove r_k = b - Ax_k è il residuo.\nResiduo Precondizionato\nLa correzione z_k = P^{-1} r_k è chiamata residuo precondizionato. In pratica, per calcolare z_k, si risolve il sistema lineare Pz_k = r_k.\nScelta del Precondizionatore\nLa scelta del precondizionatore P è cruciale. Idealmente, P dovrebbe essere:\n\nInvertibile\nFacile da invertire (ad esempio, una matrice diagonale o tridiagonale)\nIn grado di migliorare il condizionamento del sistema\n\nTuttavia, non esiste un criterio univoco per scegliere P, e la scelta è spesso dipendente dal problema.\nMetodo di Jacobi\nIl metodo di Jacobi è un metodo iterativo in cui si usa la prima equazione per trovare la prima incognita, la seconda equazione per trovare la seconda incognita, e così via.\nDerivazione\nPartendo da un sistema di tre equazioni in tre incognite:\na_{11}x_1 + a_{12}x_2 + a_{13}x_3 = b_1\na_{21}x_1 + a_{22}x_2 + a_{23}x_3 = b_2\na_{31}x_1 + a_{32}x_2 + a_{33}x_3 = b_3\nSi ricavano le incognite:\nx_1 = \\frac{1}{a_{11}}(b_1 - a_{12}x_2 - a_{13}x_3)\nx_2 = \\frac{1}{a_{22}}(b_2 - a_{21}x_1 - a_{23}x_3)\nx_3 = \\frac{1}{a_{33}}(b_3 - a_{31}x_1 - a_{32}x_2)\nSchema Iterativo per Componenti\nSi associa la nuova iterazione alle quantità a sinistra e l’iterazione precedente a quelle a destra:\nx_1^{k+1} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^k - a_{13}x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^k - a_{23}x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}}(b_3 - a_{31}x_1^k - a_{32}x_2^k)\nGeneralizzazione per Componenti\nIn generale, per un sistema di n equazioni:\nx_i^{k+1} = \\frac{1}{a_{ii}}(b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k)\nper i = 1, \\dots, n e k \\geq 0 e a_{ii}\\neq 0.\nImplementazione Parallela\nL’algoritmo di Jacobi è ben parallelizzabile, poiché ogni componente della nuova iterazione può essere calcolata indipendentemente dalle altre.\nRiscrittura Matriciale\n\nSia D la matrice diagonale formata dalle entrate diagonali di A:\nD = \\begin{bmatrix} a_{11} &amp; 0 &amp; 0 \\\\ 0 &amp; \\ddots &amp; 0 \\\\ 0 &amp; 0 &amp; a_{nn} \\end{bmatrix}\nLo schema iterativo può essere riscritto in forma matriciale come:\nx^{k+1} = D^{-1}(b - (A - D)x^k)\nIdentificazione di B e G\nDalla forma matriciale, si identifica:\n\nB_J = D^{-1}(A - D)\ng_J = D^{-1}b\n\nRiscrittura come Metodo di Richardson\nLo schema di Jacobi può essere visto come un metodo di Richardson con:\n\nP = D (matrice diagonale)\n\\alpha_k = 1 (stazionario)\n\nQuindi:\nx^{k+1} = x^k + D^{-1}r^k\ndove r^k = b - Ax^k è il residuo.\n\nMetodo di Gauss-Seidel\nIl metodo di Gauss-Seidel è una variante del metodo di Jacobi in cui, nel calcolo di una componente, si utilizzano le componenti già aggiornate nella stessa iterazione.\nSchema Iterativo per Componenti (3x3)\nx_1^{k+1} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^k - a_{13}x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^{k+1} - a_{23}x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}}(b_3 - a_{31}x_1^{k+1} - a_{32}x_2^{k+1})\nGeneralizzazione per Componenti\nx_i^{k+1} = \\frac{1}{a_{ii}}(b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij}x_j^k)\nper i = 1, \\dots, n e k \\geq 0 e a_{ii} \\neq o.\nImplementazione Seriale\nA differenza di Jacobi, Gauss-Seidel è intrinsicamente seriale, poiché ogni componente dipende dalle precedenti già aggiornate.\nRiscrittura Matriciale\nSi decompone la matrice A come:\nA = D - E - F\ndove:\n\n\nD è la matrice diagonale\n-E è la parte strettamente triangolare inferiore di A\nA-D-(-E) è la parte strettamente triangolare superiore di A\n\nSchema Iterativo Matriciale\n\n(D - E)x^{k+1} = b + (D-E-A)x^k\nIdentificazione di B e G\nB_{GS} = (D - E)^{-1}(D-E-A)\ng_{GS} = (D - E)^{-1}b\nRiscrittura come Metodo di Richardson\nx^{k+1} = x^k + (D - E)^{-1}r^k\ndove r^k = b - Ax^k è il residuo. Quindi:\n\nP = D - E\n\\alpha_k = 1\n\nMetodo di Rilassamento di Jacobi (JOR)\nIl metodo JOR (Jacobi Over-Relaxation) introduce un parametro di rilassamento \\omega per accelerare la convergenza.\nSchema Iterativo per Componenti\nx_i^{k+1} = \\frac{\\omega}{a_{ii}}(b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k) + (1 - \\omega)x_i^k\nParametro di Rilassamento \\omega\n\n0 &lt; \\omega &lt; 1: Sottorilassamento\n\\omega &gt; 1: Sovrarilassamento\n\\omega = 1: Metodo di Jacobi\n\nRiscrittura Matriciale\n\nDx^{k+1} = \\omega(b - (A - D)x^k) + (1 - \\omega)Dx^k\nIdentificazione di B e G\nB_{JOR} = \\omega D^{-1}(A - D) + (1 - \\omega)I\ng_{JOR} = \\omega D^{-1}b\nRiscrittura come Metodo di Richardson\n\nx^{k+1} = x^k + \\omega D^{-1}r^k\nQuindi:\n\nP = D\n\\alpha_k = \\omega\n\nMetodo di Rilassamento di Gauss-Seidel (SOR)\nIl metodo SOR (Successive Over-Relaxation) combina le idee di Gauss-Seidel e del rilassamento.\nSchema Iterativo per Componenti\nx_i^{k+1} = \\frac{\\omega}{a_{ii}}(b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij}x_j^k) + (1 - \\omega)x_i^k\nRiscrittura Matriciale\n\n(D - \\omega E)x^{k+1} = \\omega b + (\\omega F + (1 - \\omega)D)x^k\nIdentificazione di B e G\nB_{SOR} = (D - \\omega E)^{-1}(\\omega F + (1 - \\omega)D)\ng_{SOR} = (D - \\omega E)^{-1}\\omega b\nRiscrittura come Metodo di Richardson\nx^{k+1} = x^k + (D - \\omega E)^{-1}r^k\nQuindi:\n\nP = (D - \\omega E)\n\\alpha_k = \\omega\n\nConvergenza di Jacobi e Gauss-Seidel\nCondizioni Sufficienti\n\nSe A è a dominanza diagonale stretta per righe o per colonne, allora sia Jacobi che Gauss-Seidel convergono.\nUlteriore Condizione per Gauss-Seidel\nSe A è simmetrica definita positiva (SPD), allora Gauss-Seidel converge.\nOsservazione\nLe condizioni sufficienti per la convergenza di Jacobi e Gauss-Seidel si basano sulle proprietà della matrice A, non sulle matrici di iterazione B_J e B_{GS}.\n\nEcco una spiegazione dettagliata e formattata dei metodi iterativi di Jacobi e Gauss-Seidel, includendo i passaggi matematici, esempi ed esercizi forniti, basata sulle fonti fornite.\nMetodi Iterativi per la Risoluzione di Sistemi di Equazioni Lineari\nL’obiettivo è risolvere sistemi di equazioni lineari utilizzando metodi iterativi. Questi metodi generano una successione di approssimazioni che, idealmente, convergono alla soluzione esatta.\nSchema Generale di Iterazione\n\nSi parte da una legge di ricorrenza: la nuova iterazione è una modifica della precedente.\nMatematicamente: x_{k+1} = B x_k + g, dove:\n\nx_{k+1} è la nuova iterazione.\nB è la matrice di iterazione.\nx_k è l’iterazione precedente.\ng è un vettore.\n\n\nObiettivi:\n\nConvergenza: la successione di iterazioni deve convergere alla soluzione esatta.\nConsistenza: ogni iterazione deve essere “sensata” rispetto al sistema originale.\n\n\nCondizione Sufficiente per la Convergenza: |B| &lt; 1 per qualche norma matriciale.\nCondizione Necessaria e Sufficiente per la Convergenza: il raggio spettrale di B deve essere minore di 1.\n\nSchemi di Richardson\n\nSono una famiglia di metodi iterativi.\nSi parte dal sistema Ax = b.\nSi moltiplica il sistema per una quantità reale \\alpha_k: \\alpha_k Ax = \\alpha_k b.\nSi introduce uno splitting della matrice A: \\alpha_k A = P - (P - \\alpha_k A), dove P è il precondizionatore.\nSi riscrive il problema come: Px = (P - \\alpha_k A)x + \\alpha_k b.\nSi identifica il termine a sinistra con la nuova iterazione e quello a destra con la vecchia:\n\nx_{k+1} = (I - \\alpha_k P^{-1} A)x_k + \\alpha_k P^{-1} b\n\n\nMatrice di Iterazione: B(\\alpha_k) = I - \\alpha_k P^{-1} A\nVettore: g(\\alpha_k) = \\alpha_k P^{-1} b\nTipi di Schemi di Richardson:\n\nStazionario: \\alpha_k = \\alpha (costante per ogni iterazione).\nDinamico: \\alpha_k varia ad ogni iterazione.\n\n\n\nRiscrittura dello Schema di Richardson\n\nPartendo da x_{k+1} = x_k - \\alpha_k P^{-1} A x_k + \\alpha_k P^{-1} b\nSi espande il prodotto: x_{k+1} = x_k + \\alpha_k P^{-1} (b - A x_k)\nSi definisce il residuo r_k = b - A x_k.\nLo schema diventa: x_{k+1} = x_k + \\alpha_k P^{-1} r_k\nSi introduce la correzione z_k = P^{-1} r_k, detta residuo precondizionato.\n\nPer calcolare z_k, si risolve il sistema lineare P z_k = r_k.\n\n\nConsiderazioni Implementative:\n\nCalcolare l’inversa di una matrice è computazionalmente costoso.\nSi risolve il sistema lineare Pz_k = r_k invece di calcolare P^{-1}.\nSe si risolve un sistema con la stessa matrice P ad ogni iterazione, si può calcolare la fattorizzazione LU di P una sola volta.\nSi può scegliere P diagonale, tridiagonale o triangolare per semplificare la risoluzione del sistema.\n\n\nScelta del Precondizionatore:\n\nP deve essere invertibile.\nLa risoluzione del sistema Pz_k = r_k deve essere semplice.\nP deve migliorare il condizionamento del sistema originale.\nLa scelta di P è problem-dependent.\n\n\n\nMetodo di Jacobi\nDerivazione\n\nPartiamo da un sistema di 3 equazioni in 3 incognite:\n\na_{11}x_1 + a_{12}x_2 + a_{13}x_3 = b_1\na_{21}x_1 + a_{22}x_2 + a_{23}x_3 = b_2\na_{31}x_1 + a_{32}x_2 + a_{33}x_3 = b_3\n\n\nRicaviamo ogni incognita dalla corrispondente equazione:\n\nx_1 = \\frac{1}{a_{11}}(b_1 - a_{12}x_2 - a_{13}x_3)\nx_2 = \\frac{1}{a_{22}}(b_2 - a_{21}x_1 - a_{23}x_3)\nx_3 = \\frac{1}{a_{33}}(b_3 - a_{31}x_1 - a_{32}x_2)\n\n\nAssociamo le quantità a sinistra con la nuova iterazione (k+1) e quelle a destra con l’iterazione precedente (k):\n\nx_1^{k+1} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^k - a_{13}x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^k - a_{23}x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}}(b_3 - a_{31}x_1^k - a_{32}x_2^k)\n\n\n\nGeneralizzazione del Metodo di Jacobi\nPer un sistema di n equazioni in n incognite, la componente i-esima del vettore all’iterazione k+1 è data da:\nx_i^{k+1} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k \\right)\ndove:\n\nx_i^{k+1} è la componente i-esima del vettore x all’iterazione k+1.\na_{ii} è l’elemento diagonale della matrice A (deve essere diverso da zero).\nb_i è la componente i-esima del vettore b.\na_{ij} sono gli elementi della matrice A.\nx_j^k è la componente j-esima del vettore x all’iterazione k.\nLa sommatoria calcola la somma di tutti i termini tranne quello sulla diagonale.\n\nImplementazione\n\nImplementabile in parallelo: ogni processore può calcolare una componente del vettore x^{k+1} indipendentemente dagli altri.\n\nRiscrittura Matriciale\n\nIntroduzione della matrice diagonale D: matrice che contiene solo gli elementi diagonali di A.\nIntroduzione dei vettori x^k e x^{k+1}: vettori colonna contenenti le componenti delle iterazioni k e k+1.\nMoltiplicando entrambi i membri per a_{ii}: a_{ii} x_i^{k+1} = b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k\nRiscrivendo in forma matriciale: Dx^{k+1} = b - (A-D)x^k\nMoltiplicando per D^{-1}: x^{k+1} = D^{-1}b - D^{-1}(A-D)x^k\nSemplificando: x^{k+1} = D^{-1}b + (I - D^{-1}A)x^k\n\nForma A e B\n\nForma A: x^{k+1} = B_J x^k + g_J, dove:\n\nB_J = I - D^{-1}A (matrice di iterazione di Jacobi).\ng_J = D^{-1}b (vettore di Jacobi).\n\n\n\nRiscrittura alla Richardson\n\nx^{k+1} = x^k + D^{-1}(b - Ax^k)\nx^{k+1} = x^k + D^{-1}r^k, dove r^k è il residuo.\n\nIdentificazione con lo Schema di Richardson\n\nIl metodo di Jacobi è uno schema di Richardson stazionario.\nP_J = D (precondizionatore è la matrice diagonale).\n\\alpha_k = 1 (parametro di accelerazione è costante e uguale a 1).\n\n==Metodo di Gauss-Seidel\nModifica al Metodo di Jacobi\n\nSi utilizzano le componenti già aggiornate della nuova iterazione (k+1) non appena sono disponibili.\nQuesto dovrebbe accelerare la convergenza (ma non è sempre vero).\n\nImplementazione\n\nImplementazione seriale: a differenza di Jacobi, Gauss-Seidel non è parallelizzabile perché ogni componente dipende dalle precedenti già aggiornate.\n\nFormulazione per Componenti\n\nx_1^{k+1} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^k - a_{13}x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^{k+1} - a_{23}x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}}(b_3 - a_{31}x_1^{k+1} - a_{32}x_2^{k+1})\n\nGeneralizzazione\nx_i^{k+1} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij}x_j^k \\right)\nRiscrittura con Sommatorie\nLa sommatoria di Jacobi viene divisa in due somme: una per le componenti “nuove” (k+1) e una per le componenti “vecchie” (k).\nNotazione Matriciale\n\nDecomposizione della matrice A: A = D - E + (A - D + E), dove:\n\nD è la matrice diagonale.\n-E è la parte strettamente triangolare inferiore di A.\nA - D + E è la parte strettamente triangolare superiore di A.\n\n\n\nRiscrittura Matriciale\n\nPartendo dall’equazione: Dx^{k+1} = b + E x^{k+1} - (A - D + E)x^k\nRiorganizzando: (D - E)x^{k+1} = b - (A - D + E)x^k\n\nForma A e B\n\nForma A: x^{k+1} = B_{GS} x^k + g_{GS}, dove:\n\nB_{GS} = (D - E)^{-1}(D - E - A)\ng_{GS} = (D - E)^{-1}b\n\n\n\nRiscrittura alla Richardson\n\nx^{k+1} = x^k + (D - E)^{-1}(b - Ax^k)\nP_{GS} = D - E (precondizionatore è la matrice triangolare inferiore).\n\\alpha_k = 1 (parametro di accelerazione è costante e uguale a 1).\n\nMetodo di Rilassamento di Jacobi (JOR)\n\nÈ una combinazione lineare del sistema classico e di x_i^k.\nx_i^{k+1} = \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j=1, j\\neq i}^{n} a_{ij}x_j^k \\right) + (1-\\omega)x_i^k\n\\omega è il parametro di rilassamento:\n\n0 &lt; \\omega &lt; 1: sottorilassamento.\n\\omega &gt; 1: sovrarilassamento.\n\\omega = 1: metodo di Jacobi.\n\n\n\nRiscrittura\nx_i^{k+1} = \\omega D^{-1}(b - (A-D)x^k)+(1-\\omega)x^k\nForma A e B\n\nB_{JOR} = \\omega(I - D^{-1}A) + (1-\\omega)I = \\omega B_J + (1-\\omega)I\n\nRiscrittura alla Richardson\nx^{k+1} = x^k + \\omega D^{-1} r^k\nP_{JOR} = D precondizionatore come Jacobi \\alpha_k = \\omega parametro di accelerazione\nMetodo di Rilassamento di Gauss-Seidel (SOR)\n\nSuccessive Over-Relaxation.\nx_i^{k+1} = \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij}x_j^k \\right) + (1-\\omega)x_i^k\nSe \\omega = 1, si ottiene Gauss-Seidel.\n\nForma matriciale\nD x^{k+1} = \\omega b + \\omega E x^{k+1} - \\omega (A-D+E) x^k + (1-\\omega) D x^k\nForma A e B\n\nB_{SOR} = (I - \\omega D^{-1} E)^{-1}((1-\\omega)I + \\omega D^{-1} (D-E-A))\ng_{SOR} = (I - \\omega D^{-1} E)^{-1} \\omega D^{-1}b\n\nRiscrittura alla Richardson\nx^{k+1} = x^k + \\omega (D - \\omega E)^{-1} r^k\nP_{SOR} = (D - \\omega E) \\alpha_k = \\omega\nConvergenza\n\nCondizione Necessaria e Sufficiente: il raggio spettrale della matrice di iterazione (BJ, BGS, BJSR, BSOR) deve essere minore di 1.\nCondizioni Sufficienti per Jacobi e Gauss-Seidel: se la matrice A è a dominanza diagonale stretta per righe o per colonne, allora Jacobi e Gauss-Seidel convergono.\nCondizione Sufficiente Aggiuntiva per Gauss-Seidel: se A è definita positiva, allora Gauss-Seidel converge.\n\n\nEcco la spiegazione del professore riguardo alle flashcard, integrata con i passaggi matematici, gli esempi e gli esercizi, formattata in modo chiaro e leggibile.\n==Metodo di Gauss-Seidel: spiegazione dettagliata\nIdea di base\nL’idea alla base del metodo di Gauss-Seidel è di utilizzare le componenti già aggiornate durante il calcolo delle nuove iterate. Invece di aspettare di completare un’intera iterazione per aggiornare tutte le componenti del vettore soluzione, Gauss-Seidel sfrutta immediatamente i nuovi valori non appena sono disponibili.\nIterazione\n\nNel metodo di Jacobi, la componente i-esima della nuova iterazione dipende solo dalle componenti dell’iterata precedente.\nNel metodo di Gauss-Seidel, la componente i-esima della nuova iterazione dipende dalle componenti dell’iterata precedente, ma anche dalle componenti già aggiornate nella stessa iterazione.\n\nEsempio 3x3\nConsideriamo un sistema 3x3:\nx_1^{k+1} = \\frac{1}{a_{11}} (b_1 - a_{12} x_2^k - a_{13} x_3^k)\nx_2^{k+1} = \\frac{1}{a_{22}} (b_2 - a_{21} x_1^{\\color{red}{k+1}} - a_{23} x_3^k)\nx_3^{k+1} = \\frac{1}{a_{33}} (b_3 - a_{31} x_1^{\\color{red}{k+1}} - a_{32} x_2^{\\color{red}{k+1}})\nSi noti come, nel calcolo di x_2^{k+1} e x_3^{k+1}, si utilizzino i valori di x_1^{k+1} e x_2^{k+1} già calcolati nella stessa iterazione (indicati in rosso).\nImplementazione\nL’implementazione del metodo di Gauss-Seidel è seriale, poiché ogni componente dipende dalle precedenti già aggiornate. Questo significa che non è possibile parallelizzare facilmente l’algoritmo come nel caso di Jacobi.\nFormulazione generale\nLa formula generale per il metodo di Gauss-Seidel è:\nx_i^{k+1} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{k+1} - \\sum_{j=i+1}^{n} a_{ij} x_j^k \\right)\ndove:\n\nx_i^{k+1} è la i-esima componente del vettore soluzione all’iterazione k+1.\na_{ii} è l’elemento diagonale della matrice dei coefficienti.\nb_i è la i-esima componente del vettore dei termini noti.\nLa prima sommatoria considera le componenti già aggiornate (x_j^{k+1}).\nLa seconda sommatoria considera le componenti dell’iterata precedente (x_j^k).\n\nRiscrittura in forma matriciale\nPer riscrivere il metodo di Gauss-Seidel in forma matriciale, è utile decomporre la matrice A come segue:\nA = D - E - F\ndove:\n\nD è la matrice diagonale contenente gli elementi diagonali di A.\n-E è la matrice triangolare inferiore stretta (elementi sotto la diagonale).\nA-D-(-E) è la matrice triangolare superiore stretta (elementi sopra la diagonale). Quindi F = A - D + E.\n\nNotazione\nÈ importante prestare attenzione al segno di E, poiché viene definita come -E la parte triangolare inferiore.\nQuindi -E è la matrice triangolare inferiore della matrice A:\nE = \\begin{bmatrix} 0 &amp; 0 &amp; 0 \\\\ -a_{21} &amp; 0 &amp; 0 \\\\ -a_{31} &amp; -a_{32} &amp; 0 \\end{bmatrix}\nForma matriciale del metodo di Gauss-Seidel\nUsando questa decomposizione, il metodo di Gauss-Seidel può essere scritto in forma matriciale come:\nDx^{k+1} = b - Ex^{k+1} - F x^k\nRiordinando i termini:\n(D - E) x^{k+1} = b - F x^k\nIterazione\nx^{k+1} = (D - E)^{-1} (b - F x^k)\nQuesta è la forma matriciale del metodo di Gauss-Seidel.\nUlteriori passaggi\nPer arrivare alle forme A e B, si possono seguire questi passaggi:\nx^{k+1} = (D - E)^{-1} b - (D - E)^{-1} F x^k\nx^{k+1} = (D - E)^{-1} b + (I - (D - E)^{-1} A )x^k\n\nMatrice di iterazione: B_{GS} = -(D-E)^{-1}F = I - (D - E)^{-1} A\nVettore G: G_{GS} = (D - E)^{-1} b\n\nRiscrittura alla Richardson\nPartendo dalla forma matriciale:\nx^{k+1} = (D - E)^{-1} b - (D - E)^{-1} F x^k\nSi aggiunge e sottrae x^k:\nx^{k+1} = x^k + (D - E)^{-1} b - (D - E)^{-1} F x^k - x^k\nx^{k+1} = x^k + (D - E)^{-1} (b - F x^k - (D - E)x^k)\nx^{k+1} = x^k + (D - E)^{-1} (b - (F + D - E)x^k)\nx^{k+1} = x^k + (D - E)^{-1} (b - A x^k)\nQuindi:\nx^{k+1} = x^k + (D - E)^{-1} r^k\ndove r^k = b - A x^k è il residuo all’iterazione k.\nParametri di Richardson\nDa questa forma, si identifica:\n\nPrecondizionatore: P_{GS} = (D - E)\nParametro di accelerazione: \\alpha_k = 1 (stazionario)\n\nMetodo di Jacobi\nIterazione\nx_i^{k+1} = \\frac{1}{a_{ii}} (b_i - \\sum_{j\\ne i} a_{ij} x_j^k)\nRiscrittura alla Richardson\nx^{k+1} = x^k + D^{-1} r^k\nParametri di Richardson\nDa questa forma, si identifica:\n\nPrecondizionatore: P_{J} = D\nParametro di accelerazione: \\alpha_k = 1 (stazionario)\n\nMetodo di Rilassamento (SOR)\nSOR\nIl metodo SOR (Successive Over-Relaxation) è una variante del metodo di Gauss-Seidel che introduce un parametro di rilassamento \\omega per accelerare la convergenza.\nIterazione\nx_i^{k+1} = (1-\\omega)x_i^k + \\frac{\\omega}{a_{ii}} \\left(b_i - \\sum_{j&lt;i} a_{ij}x_j^{k+1} - \\sum_{j&gt;i} a_{ij}x_j^k\\right)\nImplementazione\nCome Gauss-Seidel, SOR è un algoritmo seriale.\nConvergenza\nCondizione necessaria e sufficiente\nPer tutti gli schemi iterativi nella forma x^{k+1} = Bx^k + G, la condizione necessaria e sufficiente per la convergenza è che il raggio spettrale della matrice di iterazione B sia minore di 1:\n\\rho(B) &lt; 1\ndove \\rho(B) è il massimo degli autovalori in modulo della matrice B.\nConsistenza\nPer gli schemi di Richardson, la consistenza è garantita per costruzione.\nCondizioni sufficienti per Jacobi e Gauss-Seidel\nSe la matrice A è a dominanza diagonale stretta per righe o per colonne, allora sia il metodo di Jacobi che il metodo di Gauss-Seidel convergono.\nPer Gauss-Seidel, se A è simmetrica definita positiva, allora il metodo converge.\nReferences\nAppunti Mate Num- Lez06.pdf\n2025-03-04 16:47\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:  sbobine   matematica numerica\nmateNum- Lez07\nConvergenza dei Metodi Iterativi di Richardson\nCondizione Necessaria e Sufficiente\nPer tutti gli schemi iterativi della forma x^{k+1} = Bx^k + G, si può utilizzare la condizione necessaria e sufficiente che richiede la consistenza più il fatto che il raggio spettrale della corrispondente matrice B sia strettamente minore di 1.\nCondizioni Sufficienti per Jacobi e Gauss-Seidel\nEsistono condizioni sufficienti che riguardano la matrice A che permettono di stabilire la convergenza di Jacobi e Gauss-Seidel:\n\nJacobi: Se A è una matrice a dominanza diagonale stretta per righe o per colonne, allora Jacobi è convergente.\nGauss-Seidel: Valgono le stesse affermazioni di Jacobi, e in più, se A è una matrice simmetrica definita positiva, allora Gauss-Seidel è convergente.\n\nConfronto tra Jacobi e Gauss-Seidel\nIn generale, si potrebbe pensare che Gauss-Seidel converga meglio di Jacobi perché utilizza in corso le componenti già aggiornate. Tuttavia, ci sono casi in cui Jacobi converge e Gauss-Seidel diverge, o Jacobi performa meglio di Gauss-Seidel.\nProposizione\nSe A è una matrice di ordine n a elementi reali tridiagonale e non singolare, con tutte le entrate diagonali a_{ii} diverse da 0 per i da 1 a n, allora:\n\nGauss-Seidel e Jacobi convergono entrambi o divergono entrambi.\nSe entrambi convergono, il raggio spettrale della matrice B associata a Gauss-Seidel è uguale al quadrato del raggio spettrale della matrice di Jacobi: \\rho(B_{GS}) = \\rho(B_{Jac})^2.\n\nEsempio\nSupponiamo che il raggio spettrale della matrice di iterazione associata a Jacobi sia \\rho(B_{Jac}) = \\frac{1}{4}. Fissiamo una tolleranza TOL e cerchiamo il numero minimo di iterazioni k \\in \\mathbb{N} tale che \\rho(B_{Jac})^k \\le TOL.\n\\left(\\frac{1}{4}\\right)^k \\le TOL\n\\frac{1}{TOL} \\le 4^k\n\\log_4\\left(\\frac{1}{TOL}\\right) \\le k\nQuindi, k \\ge \\lceil\\log_4\\left(\\frac{1}{TOL}\\right)\\rceil.\nPer Gauss-Seidel, \\rho(B_{GS}) = \\left(\\frac{1}{4}\\right)^2 = \\frac{1}{16}. Quindi:\n\\left(\\frac{1}{16}\\right)^k \\le TOL\n\\frac{1}{TOL} \\le 16^k = (4^2)^k = 4^{2k}\n\\log_4\\left(\\frac{1}{TOL}\\right) \\le 2k\nk \\ge \\lceil{\\frac{1}{2}\\log_4\\left(\\frac{1}{TOL}\\right)}\\rceil\nQuesto esempio mostra che il numero di iterazioni richieste da Gauss-Seidel è circa la metà di quelle richieste da Jacobi per raggiungere la stessa accuratezza.\nEsempio numerico: Risolvendo un sistema Ax = b con A tridiagonale \\begin{bmatrix}\n  3 &amp; -1 &amp; 0 &amp; \\cdots &amp; 0 \\\\\n  -2 &amp; 3 &amp; -1 &amp; \\cdots &amp; 0 \\\\\n  0 &amp; -2 &amp; 3 &amp; \\cdots &amp; 0 \\\\\n  \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n  0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 3\n\\end{bmatrix}, e b = \\begin{bmatrix} 1,\\cdots, 1 \\end{bmatrix} si trova che Jacobi richiede  it_j= 277 iterazioni mentre Gauss-Seidel ne richiede it_{GS}= 143 per x^{(0)}=0 una tolleranza di 10^{-12}.\nConvergenza di JOR e SOR\nJOR\nSe A è una matrice simmetrica definita positiva, allora lo schema di JOR converge se 0 &lt; \\omega &lt; \\frac{2}{\\rho(D^{-1}A)}, dove D è la diagonale di A (il precondizionatore di Jacobi e JOR).\nSOR\n\nSe A è simmetrica definita positiva, allora SOR converge se e solo se 0 &lt; \\omega &lt; 2.\nSe A è simmetrica definita positiva e tridiagonale, allora SOR converge per 0 &lt; \\omega &lt; 2 e esiste un valore ottimale per il parametro di rilassamento \\omega.\n\n\\omega_{opt} = \\frac{2}{1 + \\sqrt{1 - \\rho(B_{Jac})^2}}\nQuesto valore ottimale massimizza la velocità di convergenza.\nCriteri di Arresto nelle Iterazioni\nIntroduzione\nQuando si implementano metodi iterativi per approssimare la soluzione di un sistema lineare, è fondamentale stabilire dei criteri di arresto per interrompere il processo iterativo. Questi criteri servono a bilanciare l’accuratezza della soluzione con il costo computazionale.\nCriteri di Arresto Principali\n\nNumero Massimo di Iterazioni:\n\nÈ cautelativo fissare un numero massimo di iterazioni (N_{\\text{max}}).\nLa scelta di N_{\\text{max}} è arbitraria e dipende dall’utente.\nServe a garantire che l’algoritmo termini anche se la convergenza è lenta.\n\n\nControllo sull’Errore (Tolleranza):\n\nSi cerca un indice k tale che l’errore (la differenza tra la soluzione esatta x e l’approssimazione x^k) sia minore di una tolleranza fissata (\\text{tol}).\nMatematicamente: |x - x^k| &lt; \\text{tol}.\nIn pratica, non si conosce x, quindi si utilizza uno stimatore S.\nSi arresta il loop quando S &lt; \\text{tol}, combinando questo criterio con il numero massimo di iterazioni.\n\n\n\nStimatore S e Affidabilità\n\n\nL’obiettivo è trovare una quantità S che surroghi l’errore, ovvero che lo approssimi.\n\n\nIdealmente, S dovrebbe essere molto vicino all’errore reale.\n\n\nSi introduce una costante C tale che \\text{Errore} \\approx C \\cdot S.\n\nSe C è piccola (dell’ordine di 10^0 o 10^1), lo stimatore è affidabile.\nSe C è grande (es. 3 \\times 10^6), lo stimatore non è affidabile.\n\n\n\nSi utilizzano due stimatori (S_1 e S_2) per avere alternative nel caso uno non sia affidabile.\n\n\nStimatore 1: Residuo Relativo\nDefinizione del Residuo\n\n\nIl residuo r^k è definito come r^k = b - Ax^k, dove x^k è l’approssimazione della soluzione al passo k.\n\n\nIl razionale è che, se x^k fosse la soluzione esatta x, allora r^k sarebbe zero.\n\n\nSi utilizza il residuo relativo come stimatore S_1:\nS_1 = \\frac{|r^k|}{|b|}\n\n\nSi cerca il minimo k tale che \\frac{|r^k|}{|b|} \\leq \\text{tol}.\n\n\nLegame con l’Errore Relativo\n\n\nSi vuole trovare una relazione tra l’errore relativo e il residuo relativo:\n\\frac{|x - x^k|}{|x|} \\leq C \\cdot \\frac{|r^k|}{|b|}\n\n\nLa costante C in questo caso è il numero di condizionamento K(A) della matrice A.\n\n\nNumero di Condizionamento\n\nSe la matrice A è ben condizionata (K(A) piccolo), allora S_1 è uno stimatore affidabile.\nSe la matrice A è mal condizionata (K(A) grande), allora S_1 non è affidabile.\nIl numero di condizionamento è legato alla sensibilità della soluzione del sistema lineare alle perturbazioni nei dati.\n\nDerivazione della Relazione\n\n\nSi parte dalla relazione nota (vista durante lo studio del condizionamento):\n\\frac{|\\delta x|}{|x|} \\leq K(A) \\frac{|\\delta b|}{|b|}\n\n\nDove \\delta x è la perturbazione sulla soluzione e \\delta b è la perturbazione sul dato.\n\n\nSi identifica \\delta b con -r^k, ottenendo:\n\\frac{|x - x^k|}{|x|} \\leq K(A) \\frac{|r^k|}{|b|}\n\n\nStimatore 2: Incremento\nDefinizione dell’Incremento\n\nL’incremento \\delta^k è definito come la differenza tra due iterate successive: \\delta^k = x_{k+1} - x^k.\nQuesto stimatore è usato per controllare l’errore assoluto.\n\nRelazione con l’Errore Assoluto\n\n\nSi cerca una relazione tra l’errore assoluto e l’incremento:\n|x - x^k| \\leq C \\cdot |\\delta^k|\n\n\nSi aggiunge e sottrae x_{k+1} all’errore:\n|x - x^k| = |x - x_{k+1} + x_{k+1} - x^k|\n\n\nSi ottiene:\n|x - x^k| = |(x - x_{k+1}) + (x_{k+1} - x^k)| = |e_{k+1} + \\delta^k|\n\n\nUsando la disuguaglianza triangolare:\n|e_{k+1} + \\delta^k| \\leq |e_{k+1}| + |\\delta^k|\n\n\nUlteriori Passaggi (con B Simmetrica Definitiva Positiva)\n\n\nSi assume che la matrice di precondizionamento B sia simmetrica definita positiva per semplificare i calcoli.\n\n\nSi usa la relazione e_{k+1} = B e^k, quindi |e_{k+1}| = |B e^k|.\n\n\nUsando la compatibilità tra norma matriciale e vettoriale:\n|B e^k| \\leq |B| |e^k|\n\n\nSi ha:\n|x - x^k| \\leq |B| |e^k| + |\\delta^k|\n\n\nDa cui:\n|e^k| \\leq |B| |e^k| + |\\delta^k|\n\n\nSe B è simmetrica definita positiva, allora |B|_2 = \\rho(B), il raggio spettrale di B.\n\n\nRiarrangiando:\n|e^k|(1 - \\rho(B)) \\leq |\\delta^k|\n\n\nInfine:\n|x - x^k| \\leq \\frac{1}{1 - \\rho(B)} |\\delta^k|\n\n\nAffidabilità dello Stimatore\n\nLa costante C è \\frac{1}{1 - \\rho(B)}.\nAffinché S_2 sia affidabile, \\rho(B) deve essere il più vicino possibile a zero.\nQuesto significa che il metodo deve convergere velocemente.\n\nConclusioni\n\nSe la matrice A è ben condizionata, si può usare il residuo relativo S_1.\nSe il metodo converge velocemente, si può usare l’incremento S_2.\nIn caso contrario, è necessario utilizzare altri metodi.\n\nConvergenza del Metodo di Richardson Stazionario\nTeorema di convergenza: Per un generico schema di Richardson stazionario, con precondizionatore invertibile P, la convergenza è garantita indipendentemente dalla scelta del guess iniziale \\forall x_0 \\in \\mathbb{R}^n se e solo se il parametro di accelerazione \\alpha soddisfa una specifica relazione.\nCondizione necessaria e sufficiente: La condizione è definita in termini degli autovalori \\lambda_i della matrice precondizionata P^{-1}A. In particolare, \\alpha deve soddisfare la seguente disuguaglianza:\n2 \\frac{Re(\\lambda_i)}{\\alpha |\\lambda_i|^2} &gt; 1 \\quad \\forall i\ndove:\n\nRe(\\lambda_i) è la parte reale dell’autovalore \\lambda_i\n|\\lambda_i|^2 è il modulo quadrato dell’autovalore \\lambda_i\n\nOsservazioni:\n\nAnche se la matrice A ha coefficienti reali, gli autovalori \\lambda_i di P^{-1}A possono essere complessi.\nSe gli autovalori sono reali, la condizione si semplifica.\n\nRaggio Spettrale e Matrice di Iterazione\nLa condizione di convergenza è strettamente legata al raggio spettrale della matrice di iterazione.\nMatrice di iterazione: Per il metodo di Richardson stazionario, la matrice di iterazione B_\\alpha è data da:\nB_\\alpha = I - \\alpha P^{-1}A\ndove I è la matrice identità.\nAutovalori di B_\\alpha: Se \\lambda_i sono gli autovalori di P^{-1}A, allora gli autovalori corrispondenti di B_\\alpha sono:\n1 - \\alpha \\lambda_i\nCondizione di convergenza basata sul raggio spettrale: La convergenza è assicurata se il modulo di questi autovalori è minore di 1 per ogni i:\n|1 - \\alpha \\lambda_i| &lt; 1 \\quad \\forall i\nAnalisi del Modulo e Derivazione della Condizione\nPer analizzare la condizione |1 - \\alpha \\lambda_i| &lt; 1, è necessario considerare la parte reale e immaginaria del numero complesso 1 - \\alpha \\lambda_i.\nCalcolo del modulo: Il modulo al quadrato è dato da:\n|1 - \\alpha \\lambda_i|^2 = Re(1 - \\alpha \\lambda_i)^2 + Im(1 - \\alpha \\lambda_i)^2\ndove:\n\nRe(1 - \\alpha \\lambda_i) = 1 - \\alpha Re(\\lambda_i)\nIm(1 - \\alpha \\lambda_i) = -\\alpha Im(\\lambda_i)\n\nSviluppo della disuguaglianza: Sostituendo e sviluppando, si ottiene:\n[1 - \\alpha Re(\\lambda_i)]^2 + [-\\alpha Im(\\lambda_i)]^2 &lt; 1\n1 - 2\\alpha Re(\\lambda_i) + \\alpha^2 Re(\\lambda_i)^2 + \\alpha^2 Im(\\lambda_i)^2 &lt; 1\nSemplificazione: Dopo alcune semplificazioni algebriche, si arriva a:\n\\alpha^2 |\\lambda_i|^2 - 2\\alpha Re(\\lambda_i) &lt; 0\nCondizione finale: Dividendo per \\alpha^2 |\\lambda_i|^2 (e notando che la quantità 2\\alpha Re(\\lambda_i) deve essere positiva), si ottiene:\n2 \\frac{Re(\\lambda_i)}{\\alpha |\\lambda_i|^2} &gt; 1\nche è la condizione di convergenza iniziale.\nScelta Ottimale di \\alpha\nIn condizioni più restrittive, si può determinare un valore ottimale per \\alpha che massimizza la velocità di convergenza.\nIpotesi aggiuntive:\n\nP^{-1}A ha tutti gli autovalori reali e positivi\nGli autovalori sono ordinati in modo decrescente: \\lambda_1 &gt; \\lambda_2 &gt; ... &gt; \\lambda_n &gt; 0\n\nIntervallo di convergenza per \\alpha: In queste condizioni, il metodo di Richardson stazionario converge se \\alpha appartiene all’intervallo:\n0 &lt; \\alpha &lt; \\frac{2}{\\lambda_1}\ndove \\lambda_1 è l’autovalore massimo di P^{-1}A.\nValore ottimale di \\alpha: Il raggio spettrale della matrice di iterazione B_\\alpha è minimizzato quando \\alpha è scelto come:\n\\alpha_{ott} = \\frac{2}{\\lambda_1 + \\lambda_n}\ndove \\lambda_n è l’autovalore minimo di P^{-1}A.\nDimostrazione Grafica del Valore Ottimale di \\alpha\nLa determinazione del valore ottimale di \\alpha può essere compresa graficamente analizzando come varia il modulo degli autovalori di B_\\alpha in funzione di \\alpha.\nSetup del grafico:\n\nSi considerano tre autovalori \\lambda_1 &gt; \\lambda_2 &gt; \\lambda_3 &gt; 0 di P^{-1}A.\nSi tracciano i grafici delle funzioni |1 - \\alpha \\lambda_i| per i = 1, 2, 3 in funzione di \\alpha.\n\n\nAndamento dei grafici:\n\nOgni grafico ha una forma a “V” e interseca l’asse \\alpha in \\frac{1}{\\lambda_i}.\nTutti i grafici partono dal punto (0, 1).\n\nDeterminazione grafica di \\alpha_{ott}:\n\nPer ogni valore di \\alpha, si identificano i tre valori |1 - \\alpha \\lambda_i|.\nSi considera il massimo di questi tre valori, che corrisponde al raggio spettrale.\nSi cerca il valore di \\alpha che minimizza questo massimo.\n\nPunto di minimo: Il minimo del massimo si trova nel punto di intersezione tra il ramo decrescente della funzione associata a \\lambda_1 e il ramo crescente della funzione associata a \\lambda_3\n\nCalcolo geometrico: Si impone l’uguaglianza tra le due rette:\n1 - \\alpha \\lambda_3 = \\alpha \\lambda_1 - 1\nDa cui si ricava:\n\\alpha_{ott} = \\frac{2}{\\lambda_1 + \\lambda_3}\nChe generalizzato al caso di n autovalori diventa:\n\\alpha_{ott} = \\frac{2}{\\lambda_1 + \\lambda_n}\nConsiderazioni Finali\nLa scelta di \\alpha è cruciale per la convergenza e l’efficienza del metodo di Richardson stazionario. Mentre le condizioni teoriche forniscono un quadro generale, la determinazione del valore ottimale richiede ulteriori ipotesi sugli autovalori della matrice precondizionata P^{-1}A.\nInoltre, mentre ci sono delle indicazioni su come scegliere \\alpha in modo ottimale, non ci sono altrettante indicazioni su come scegliere P.\nReferences\nAppunti Mate Num- Lez07.pdf\n2025-03-06 15:28\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine   matematica numerica\nmateNum- Lez08\nMetodo di Richardson Stazionario Precondizionato\nRichiamo sulla Lezione Precedente\nNella lezione precedente, abbiamo introdotto il metodo di Richardson stazionario precondizionato e iniziato a esplorare il ruolo del parametro di accelerazione \\alpha. L’obiettivo era di comprendere come questo parametro potesse influenzare la convergenza del metodo, in analogia a quanto osservato con i metodi di Jacobi e Gauss-Seidel, dove un parametro \\omega (simile ad \\alpha) veniva utilizzato per accelerare la convergenza. Ricordiamo che in Jacobi e Gauss-Seidel, il parametro era fissato a uno, mentre con il metodo di Richardson stazionario precondizionato, abbiamo la libertà di scegliere \\alpha in modo più strategico.\nRicerca del Parametro Ottimale \\alpha_{opt}\nAbbiamo derivato un teorema che, sotto l’ipotesi che la matrice di precondizionamento P sia non singolare e che la matrice P^{-1}A abbia tutti gli autovalori reali e positivi, ci permette di definire un intervallo di valori ammissibili per \\alpha e di calcolare un valore ottimale \\alpha_{opt} per questo parametro. Questo valore ottimale è dato da:\n\\qquad \\alpha_{opt} = \\frac{2}{\\lambda_1 + \\lambda_n}\ndove \\lambda_1 e \\lambda_n rappresentano rispettivamente l’autovalore massimo e l’autovalore minimo della matrice P^{-1}A.\nVelocità di Convergenza con \\alpha_{opt}\nSuccessivamente, abbiamo analizzato la velocità di convergenza raggiungibile quando il parametro \\alpha è scelto uguale al suo valore ottimale \\alpha_{opt}. La velocità di convergenza è determinata dal raggio spettrale \\rho(B(\\alpha)) della matrice di iterazione B(\\alpha) = I - \\alpha P^{-1}A. Gli autovalori di B(\\alpha) sono dati da 1 - \\alpha \\lambda_i, dove \\lambda_i sono gli autovalori di P^{-1}A. Pertanto, quando \\alpha = \\alpha_{opt}, il raggio spettrale \\rho(B(\\alpha_{opt})) è il massimo modulo degli autovalori 1 - \\alpha_{opt} \\lambda_i.\nConsiderando che gli autovalori \\lambda_i sono reali e positivi, il valore massimo di |1 - \\alpha_{opt} \\lambda_i| si ottiene per l’autovalore più piccolo \\lambda_n (poiché \\alpha_{opt} è positivo). Quindi, la velocità di convergenza è data da:\n\\qquad \\rho(B(\\alpha_{opt})) = |1 - \\alpha_{opt} \\lambda_n| = \\left|1 - \\frac{2}{\\lambda_1 + \\lambda_n} \\lambda_n\\right|\nSemplificando l’espressione:\n\\qquad \\rho(B(\\alpha_{opt})) = \\left|\\frac{\\lambda_1 + \\lambda_n - 2\\lambda_n}{\\lambda_1 + \\lambda_n}\\right| = \\left|\\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n}\\right|\nPoiché \\lambda_1 \\ge \\lambda_n &gt; 0, l’espressione è sempre non negativa, quindi:\n\\qquad \\rho(B(\\alpha_{opt})) = \\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n}\nQuesto risultato è importante perché ci permette di quantificare teoricamente la velocità di convergenza del metodo di Richardson stazionario precondizionato quando si utilizza il parametro ottimale \\alpha_{opt}, una volta che conosciamo gli autovalori estremi di P^{-1}A.\nCaso Particolare: P^{-1}A Simmetrica Definita Positiva (SDP)\nFacciamo ora un’osservazione importante: se la matrice P^{-1}A è simmetrica definita positiva (SDP), questo rappresenta un sottocaso particolare del teorema precedentemente enunciato, in quanto una matrice SDP ha tutti gli autovalori reali e positivi.\nIn questo caso, possiamo introdurre il concetto di numero di condizionamento rispetto alla norma spettrale 2, denotato come K_2(M) per una generica matrice M. Per una matrice SDP come P^{-1}A, il numero di condizionamento K_2(P^{-1}A) è dato dal rapporto tra l’autovalore massimo e l’autovalore minimo:\n\\qquad K_2(P^{-1}A) = \\frac{\\lambda_1}{\\lambda_n}\nUtilizzando questa definizione, possiamo riscrivere la velocità di convergenza \\rho(B(\\alpha_{opt})) in termini del numero di condizionamento di P^{-1}A:\n\\qquad \\rho(B(\\alpha_{opt})) = \\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n} = \\frac{\\frac{\\lambda_1}{\\lambda_n} - 1}{\\frac{\\lambda_1}{\\lambda_n} + 1} = \\frac{K_2(P^{-1}A) - 1}{K_2(P^{-1}A) + 1}\nQuesto risultato evidenzia un ruolo cruciale della matrice di precondizionamento P: oltre a dover essere invertibile e “facile” da usare, il suo compito principale è quello di migliorare il condizionamento della matrice A, ovvero rendere il numero di condizionamento K_2(P^{-1}A) il più piccolo possibile. Un valore di K_2(P^{-1}A) vicino a 1 implica una velocità di convergenza \\rho(B(\\alpha_{opt})) vicina a 0, che è desiderabile per una rapida convergenza.\nIl professore sottolinea che, a differenza della scelta del parametro \\alpha per cui esistono delle “ricette” anche in modalità dinamica, non esiste una ricetta ottimale universale per il precondizionatore P. La scelta del precondizionatore è spesso dipendente dal problema specifico.\nCaso di Richardson Stazionario Non Precondizionato\nConsideriamo ora il caso in cui non si utilizzi un precondizionatore, ovvero P = I. In questo scenario, il metodo di Richardson stazionario non precondizionato si applica direttamente alla matrice A.\nSupponiamo che la matrice A sia simmetrica definita positiva (SDP) e abbia autovalori reali e positivi 0 &lt; \\lambda_n \\le \\dots \\le \\lambda_1. In questo caso, il metodo di Richardson stazionario non precondizionato con un parametro \\alpha scelto opportunamente, ad esempio nell’intervallo (0, \\frac{2}{\\lambda_1}), converge.\nInoltre, si può derivare una stima per l’errore all’iterata k-esima, misurato nella norma A (o norma in energia) definita per un vettore z \\in \\mathbb{R}^n come |z|_A^2 = z^T A z. La stima è data da:\n\\qquad |e^{(k)}|_A \\le \\rho(B(\\alpha)) |e^{(k-1)}|_A\ndove e^{(k)} = x^* - x^{(k)} è l’errore all’iterata k-esima e B(\\alpha) = I - \\alpha A è la matrice di iterazione. Iterando questa relazione, si ottiene:\n\\qquad |e^{(k)}|_A \\le \\rho(B(\\alpha))^k |e^{(0)}|_A\nSe si sceglie il parametro ottimale per il caso non precondizionato, che è \\alpha_{opt} = \\frac{2}{\\lambda_1 + \\lambda_n} (analogamente al caso precondizionato ma applicato ad A invece di P^{-1}A), il raggio spettrale diventa:\n\\qquad \\rho(B(\\alpha_{opt})) = \\frac{\\lambda_1 - \\lambda_n}{\\lambda_1 + \\lambda_n} = \\frac{K_2(A) - 1}{K_2(A) + 1}\ndove K_2(A) = \\frac{\\lambda_1}{\\lambda_n} è il numero di condizionamento di A rispetto alla norma 2.\nLa norma A è una norma dipendente dal problema (dalla matrice A) e rappresenta una sorta di “cambio di metrica” in cui la valutazione degli errori è adattata specificamente al sistema che stiamo risolvendo. Questa norma è anche detta norma in energia e trova applicazioni, ad esempio, nell’analisi di sistemi fisici come le strutture elastiche, dove è legata all’energia associata all’equilibrio del sistema.\nAlgoritmo di Richardson Stazionario Precondizionato\nIl professore ha quindi descritto i passaggi fondamentali dell’algoritmo di Richardson stazionario precondizionato:\nInput:\n\nGuess iniziale x_0.\nParametro di accelerazione \\alpha (idealmente \\alpha_{opt}).\nMatrice di precondizionamento P.\n\nPassaggi:\n\nCalcolare il residuo iniziale r_0 = b - Ax_0.\nIniziare un ciclo iterativo (ad esempio, un ciclo while basato su un criterio di convergenza).\nAd ogni iterazione k (partendo da k=0):\n\nRisolvere il sistema precondizionato Pz_k = r_k per ottenere il residuo precondizionato z_k.\nAggiornare la soluzione corrente: x_{k+1} = x_k + \\alpha z_k.\nAggiornare il residuo: r_{k+1} = b - Ax_{k+1}.\n\n\n\nPer l’aggiornamento del residuo, esiste una formula ricorsiva più efficiente dal punto di vista computazionale:\n\\qquad r_{k+1} = b - A(x_k + \\alpha z_k) = (b - Ax_k) - \\alpha Az_k = r_k - \\alpha Az_k\nQuindi, ad ogni iterazione, invece di ricalcolare b - Ax_{k+1} da zero, si aggiorna il residuo utilizzando il residuo precedente e il residuo precondizionato z_k moltiplicato per A e per -\\alpha.\nCosto Computazionale e Scelta tra Metodo Stazionario e Dinamico\nInfine, il professore ha discusso brevemente il costo computazionale associato alla scelta del parametro \\alpha ottimale nel metodo stazionario e ha introdotto una riflessione sul confronto con i metodi dinamici.\nMentre in un metodo stazionario il parametro \\alpha viene calcolato una sola volta, il calcolo di \\alpha_{opt} = \\frac{2}{\\lambda_1 + \\lambda_n} richiede la conoscenza (o l’approssimazione) degli autovalori massimo \\lambda_1 e minimo \\lambda_n della matrice P^{-1}A (o di A nel caso non precondizionato). Se la matrice A è di grandi dimensioni (ad esempio, 10000 \\times 10000), calcolare tutti gli autovalori sarebbe proibitivo.\nTuttavia, esistono metodi numerici specializzati per approssimare solo l’autovalore massimo e il corrispondente autovettore, o solo l’autovalore minimo e il corrispondente autovettore, senza dover calcolare l’intero spettro della matrice. Questo rende il calcolo (o l’approssimazione) di \\alpha_{opt} potenzialmente fattibile anche per problemi di grandi dimensioni.\nIl professore ha anticipato che nei metodi di Richardson dinamici, il parametro di accelerazione \\alpha (o \\alpha_k per indicare la sua dipendenza dall’iterazione k) viene aggiornato ad ogni iterazione. Sebbene questo approccio possa offrire una maggiore flessibilità nell’adattare il parametro all’evoluzione della soluzione, è necessario considerare il costo computazionale di questo aggiornamento ad ogni passo. Al momento, non sappiamo ancora quanto costerà calcolare \\alpha_k nel caso dinamico, ma è un aspetto importante da tenere in considerazione nel confronto tra i due approcci (stazionario e dinamico). La scelta tra un metodo stazionario con un \\alpha_{opt} calcolato una volta e un metodo dinamico con \\alpha_k variabile dipende quindi da diversi fattori, tra cui l’efficacia del metodo dinamico nel migliorare la convergenza e il costo computazionale associato all’aggiornamento del parametro.\n\nCertamente, ecco la spiegazione del professore riguardo alle flashcard, integrata con i passaggi matematici, gli esempi e i commenti, formattata come richiesto:\nMetodi Iterativi per la Risoluzione di Sistemi Lineari\nAlgoritmo di Richardson Stazionario Precondizionato\nIl professore inizia accennando all’algoritmo di Richardson stazionario precondizionato. L’aggiornamento del residuo avviene in un modo specifico, indicato nel testo con un “così”, la cui forma esatta non è riportata nell’estratto fornito.\nViene poi suggerita una possibile ottimizzazione: eseguire una volta per tutte la fattorizzazione LUD della matrice di precondizionamento P. In questo modo, il passaggio di risoluzione con P^{-1} si trasformerebbe in due schemi di sostituzioni in avanti e all’indietro, che sono computazionalmente più efficienti. Tuttavia, il professore specifica che questi sono dettagli più approfonditi e che per una comprensione di base è sufficiente considerare che ad ogni iterazione è presente un’operazione di risoluzione con la matrice di precondizionamento P.\nMetodo di Richardson Dinamico (Non Precondizionato)\nIl professore introduce quindi il metodo di Richardson dinamico partendo dal caso non precondizionato.\nSchema Iterativo\nLo schema iterativo generico per il metodo di Richardson dinamico non precondizionato è dato da:\nx_{k+1} = x_k + \\alpha_k z_k\ndove in questo caso, poiché non c’è precondizionamento (P = I, la matrice identità), si ha z_k = r_k, con r_k che rappresenta il residuo alla k-esima iterazione. Quindi lo schema diventa:\nx_{k+1} = x_k + \\alpha_k r_k\nQui, \\alpha_k è un parametro di accelerazione che può variare ad ogni iterazione (da cui “dinamico”).\nScelta Ottimale del Parametro \\alpha_k\nIl professore afferma che esiste una ricetta ottimale per il parametro \\alpha_k, che viene fornita come:\n\\alpha_k = \\frac{r_k^T r_k}{r_k^T A r_k}\ndove:\n\nr_k^T è il trasposto del residuo alla k-esima iterazione.\nr_k è il residuo alla k-esima iterazione (un vettore di dimensione n \\times 1).\nA è la matrice dei coefficienti del sistema lineare.\n\nIl numeratore r_k^T r_k è il prodotto scalare del residuo con se stesso (la norma euclidea al quadrato del residuo), che risulta essere un numero (dimensione 1 \\times n \\cdot n \\times 1 = 1 \\times 1).\nIl denominatore r_k^T A r_k è anch’esso un numero (dimensione 1 \\times n \\cdot n \\times n \\cdot n \\times 1 = 1 \\times 1).\nRelazione con il Metodo del Gradiente\nIl professore sottolinea che per questa scelta ottimale di \\alpha_k e in assenza di precondizionatore, il metodo di Richardson dinamico si identifica con un metodo molto noto in letteratura: il metodo del gradiente.\nIl metodo del gradiente è caratterizzato dall’avere come unica “carta da giocare” la scelta ottimale del parametro \\alpha. Questa scelta di \\alpha_k è quella che massimizza la velocità di convergenza del metodo.\nCosto Computazionale di \\alpha_k\nViene poi discussa la costosità del calcolo di \\alpha_k ad ogni iterazione. Il professore fa notare che, a differenza dell’\\alpha stazionario che richiedeva la stima di autovalori (come \\lambda_1 e \\lambda_n che potrebbero non essere facilmente accessibili), l’\\alpha_k ottimale dipende dal residuo r_k, che è una quantità già calcolata all’interno dell’algoritmo per definire l’aggiornamento x_{k+1}. Pertanto, il calcolo di \\alpha_k non introduce un costo computazionale aggiuntivo significativo, poiché le quantità necessarie sono già disponibili.\nInterpretazione Geometrica e Derivazione dell’\\alpha_k Ottimale: Connessione con l’Ottimizzazione\nPer fornire un’interpretazione geometrica del metodo del gradiente e per derivare l’espressione ottimale di \\alpha_k, il professore introduce un lemma di equivalenza.\nLemma di Equivalenza\nIl lemma si basa sull’ipotesi che la matrice dei coefficienti A sia simmetrica definita positiva (SDP). Questa è un’ipotesi fondamentale per la validità del metodo del gradiente nella sua forma standard.\nSotto questa ipotesi, il lemma afferma che risolvere il sistema lineare Ax = b è equivalente a risolvere un problema di minimo:\n\\min_{y \\in \\mathbb{R}^n} \\phi(y)\ndove \\phi(y) è la funzione energia del sistema, definita come una forma quadratica:\n\\phi(y) = \\frac{1}{2} y^T A y - y^T b\nLa soluzione x del sistema lineare è l’argomento che realizza il minimo di questa funzione, ovvero x = \\text{argmin}_{y} \\phi(y). In altre parole, il vettore x che risolve Ax = b è lo stesso vettore x che rende minima la funzione \\phi(y).\nInterpretazione Geometrica della Funzione Energia\n\nIn due dimensioni (se y = [y_1, y_2]^T), la funzione energia \\phi(y) rappresenta geometricamente un paraboloide, una superficie a forma di “scodella”. La soluzione x = [x_1, x_2]^T del sistema lineare corrisponde al punto di minimo di questa scodella.\nPer dimensioni superiori, la funzione energia è una generalizzazione di questo paraboloide in più dimensioni.\nGradiente della Funzione Energia\nIl professore calcola il gradiente della funzione energia \\phi(y):\n\\nabla \\phi(y) = \\frac{1}{2} (A + A^T) y - b\nSfruttando l’ipotesi che A è simmetrica (A^T = A), l’espressione si semplifica a:\n\\nabla \\phi(y) = A y - b\nIl professore fa notare che questa espressione è strettamente legata al residuo r = b - Ay. Infatti, \\nabla \\phi(y) = -(b - Ay) = -r.\nDimostrazione dell’Equivalenza\nViene dimostrata l’equivalenza tra la risoluzione del sistema lineare e la minimizzazione della funzione energia in entrambe le direzioni.\nDa Minimo a Soluzione (argmin \\implies Ax = b)\nSe x realizza il minimo di \\phi(y), allora il gradiente di f valutato in x deve essere nullo:\n\\nabla \\phi(x) = 0\nSostituendo l’espressione del gradiente, si ottiene:\nA x - b = 0\nDa cui:\nA x = b\nQuesto dimostra che se x minimizza \\phi(y), allora x è una soluzione del sistema lineare.\nDa Soluzione a Minimo (Ax = b \\implies argmin)\nPer dimostrare l’implicazione opposta, si considera l’espansione di Taylor di \\phi(x + y) intorno a x:\n\\phi(x + y) = \\phi(x) + \\nabla \\phi(x)^T y + \\frac{1}{2} y^T H_\\phi(x) y + \\text{termini di ordine superiore}\ndove H_\\phi(x) è la matrice Hessiana di f valutata in x. Per la funzione quadratica \\phi(y) = \\frac{1}{2} y^T A y - y^T b, la matrice Hessiana è semplicemente A. Quindi l’espansione si riduce a:\n\\phi(x + y) = \\phi(x) + \\nabla \\phi(x)^T y + \\frac{1}{2} y^T A y\nSe x è la soluzione del sistema Ax = b, allora \\nabla \\phi(x) = Ax - b = 0. Sostituendo questo nell’espansione di Taylor, si ottiene:\n\\phi(x + y) = \\phi(x) + 0^T y + \\frac{1}{2} y^T A y = \\phi(x) + \\frac{1}{2} y^T A y\nPoiché A è definita positiva, per ogni y \\neq 0, si ha y^T A y &gt; 0. Pertanto:\n\\phi(x + y) &gt; \\phi(x) \\quad \\text{per ogni } y \\neq 0\nQuesto dimostra che se x è la soluzione di Ax = b, allora x è il punto in cui la funzione energia \\phi(y) assume il suo valore minimo.\nInterpretazione Geometrica come Metodo di Discesa Ripida (Steepest Descent)\n\nIl professore utilizza l’analogia di una persona in montagna (la cui altitudine è rappresentata dalla funzione energia) con una fitta nebbia che vuole tornare alla macchina in fondo alla valle (il minimo della funzione energia, la soluzione del sistema). La posizione attuale è x_k, e si vuole determinare la prossima posizione x_{k+1}.\nLa strategia è di muoversi nella direzione di massima pendenza negativa (la discesa più ripida). La direzione di massima pendenza è data dal gradiente \\nabla \\phi(x_k), che punta nella direzione di aumento più rapido della funzione . Pertanto, la direzione di discesa più ripida è -\\nabla \\phi(x_k) .\nRicordando che \\nabla \\phi(x_k) = Ax_k - b = -r_k, la direzione di discesa \\delta(x_k) è data da :\n\\delta(x_k) = -\\nabla \\phi(x_k) = - (Ax_k - b) = b - Ax_k = r_k\nQuindi, nel metodo del gradiente, la direzione di movimento ad ogni iterazione è proprio il residuo .\nLa nuova posizione x_{k+1} sarà data da :\nx_{k+1} = x_k + \\gamma_k \\delta(x_k) = x_k + \\gamma_k r_k\ndove \\gamma_k è la lunghezza del passo da compiere lungo la direzione r_k . Questo \\gamma_k corrisponde al nostro \\alpha_k.\nScelta Ottimale della Lunghezza del Passo \\gamma_k\nPer trovare la lunghezza del passo ottimale \\gamma_k, si vuole minimizzare la funzione energia lungo la direzione di discesa . Si considera quindi la funzione g(\\gamma_k) = \\phi(x_k + \\gamma_k r_k), che rappresenta il valore della funzione energia spostandosi di un passo \\gamma_k nella direzione r_k a partire da x_k .\nUtilizzando l’espansione di Taylor di \\phi(x + y) con x = x_k e y = \\gamma_k r_k, si ottiene :\n\\phi(x_k + \\gamma_k r_k) = \\phi(x_k) + \\nabla \\phi(x_k)^T (\\gamma_k r_k) + \\frac{1}{2} (\\gamma_k r_k)^T A (\\gamma_k r_k)\ng(\\gamma_k) = \\phi(x_k) - r_k^T (\\gamma_k r_k) + \\frac{1}{2} \\gamma_k^2 r_k^T A r_k\ng(\\gamma_k) = \\phi(x_k) - \\gamma_k (r_k^T r_k) + \\frac{1}{2} \\gamma_k^2 (r_k^T A r_k)\nPer trovare il valore di \\gamma_k che minimizza g(\\gamma_k), si calcola la derivata di g rispetto a \\gamma_k e si pone uguale a zero :\ng&#039;(\\gamma_k) = -\\frac{d}{d\\gamma_k} (\\gamma_k (r_k^T r_k)) + \\frac{d}{d\\gamma_k} (\\frac{1}{2} \\gamma_k^2 (r_k^T A r_k))\ng&#039;(\\gamma_k) = -(r_k^T r_k) + \\gamma_k (r_k^T A r_k)\nImponendo g&#039;(\\gamma_k) = 0 per trovare il \\gamma_k ottimale (\\gamma_k^{opt}):\n-(r_k^T r_k) + \\gamma_k^{opt} (r_k^T A r_k) = 0\n\\gamma_k^{opt} (r_k^T A r_k) = r_k^T r_k\n\\gamma_k^{opt} = \\frac{r_k^T r_k}{r_k^T A r_k}\nQuesto \\gamma_k^{opt} è esattamente l’\\alpha_k ottimale derivato precedentemente per il metodo di Richardson dinamico . Questo conferma che il metodo del gradiente utilizza ad ogni passo la lunghezza del passo ottimale lungo la direzione del residuo (che è la direzione di discesa più ripida della funzione energia).\n\nConvergenza del Metodo del Gradiente Non Precondizionato\nIl professore introduce lo studio della convergenza del metodo del gradiente non precondizionato, sottolineando l’importanza dell’ipotesi che la matrice A sia simmetrica definita positiva (SDP). Applicare il metodo del gradiente a una matrice non SDP non è consentito.\nConfronto con Metodi Iterativi Classici (Jacobi e Gauss-Seidel)\nViene proposto un confronto tra il metodo del gradiente non precondizionato e i metodi di Jacobi e Gauss-Seidel su un sistema lineare piccolo:\n2x_1 + x_2 = 1 x_1 + 3x_2 = 0\nLa cui matrice è A = \\begin{pmatrix} 2 &amp; 1 \\\\ 1 &amp; 3 \\end{pmatrix}, che è SDP. La soluzione esatta è x = \\begin{pmatrix} 3/5 \\\\ -1/5 \\end{pmatrix}.\nSi discute l’andamento dell’errore  in scala logaritmica rispetto al numero di iterazioni per i tre metodi. L’obiettivo è confrontare la velocità di convergenza.\nVelocità di Convergenza Empirica\n\nSi prevede che, per questo sistema, il gradiente converga più rapidamente di Gauss-Seidel, che a sua volta converga più rapidamente di Jacobi. Questo si visualizza concettualmente con grafici dell’accuratezza (es. 10^{-qualcosa}) in funzione del numero di iterazioni. Curve più ripide indicano una convergenza più rapida.\n\nJacobi: Convergenza più lenta (retta meno inclinata nel grafico concettuale).\nGauss-Seidel: Convergenza intermedia (retta con inclinazione maggiore di Jacobi).\nGradiente: Convergenza più rapida (retta con inclinazione maggiore di Gauss-Seidel).\n\nQuesti grafici possono essere usati per:\n\nFissare un’accuratezza e determinare il numero di iterazioni richieste da ciascun metodo.\nFissare un numero di iterazioni e confrontare l’accuratezza ottenuta da ciascun metodo.\n\nIl professore menziona che il grafico corretto è disponibile sul libro e sottolinea l’importanza di usare una scala logaritmica per visualizzare l’ordine di convergenza come l’inclinazione della retta.\nVerifica della Convergenza\nPer verificare formalmente la convergenza, si confronta il valore della funzione obiettivo \\phi(x) all’iterata k+1 con quella all’iterata k. Si desidera che \\phi(x_{k+1}) &lt; \\phi(x_k), indicando che ci si sta muovendo verso il minimo.\nPartendo da x_{k+1} = x_k + \\alpha_k r_k (notare il segno positivo qui, il professore usa + \\alpha_k r_k nel derivare, considerando r_k = b - Ax_k, quindi la direzione di ricerca è r_k), e sostituendo l’espressione per \\alpha_k ottimo, si ottiene:\n\\phi(x_{k+1}) = \\phi(x_k) - \\alpha_k |r_k|_2^2 + \\frac{1}{2} \\alpha_k^2 r_k^T A r_k\nSostituendo \\alpha_k = \\frac{r_k^T r_k}{r_k^T A r_k} = \\frac{|r_k|_2^2}{r_k^T A r_k}:\n\\phi(x_{k+1}) = \\phi(x_k) - \\frac{|r_k|_2^4}{r_k^T A r_k} + \\frac{1}{2} \\left(\\frac{|r_k|_2^2}{r_k^T A r_k}\\right)^2 r_k^T A r_k\n\\phi(x_{k+1}) = \\phi(x_k) - \\frac{|r_k|_2^4}{r_k^T A r_k} + \\frac{1}{2} \\frac{|r_k|_2^4}{(r_k^T A r_k)^2} r_k^T A r_k\n\\phi(x_{k+1}) = \\phi(x_k) - \\frac{|r_k|_2^4}{r_k^T A r_k} + \\frac{1}{2} \\frac{|r_k|_2^4}{r_k^T A r_k}\n\\phi(x_{k+1}) = \\phi(x_k) - \\frac{1}{2} \\frac{|r_k|_2^4}{r_k^T A r_k}\nPoiché A è SDP, r_k^T A r_k &gt; 0 per r_k \\neq 0, e |r_k|_2^4 \\ge 0. Pertanto, \\phi(x_{k+1}) \\le \\phi(x_k), e se r_k \\neq 0, allora \\phi(x_{k+1}) &lt; \\phi(x_k), dimostrando che il valore della funzione obiettivo diminuisce ad ogni iterazione, indicando la convergenza verso il minimo.\nTasso di Convergenza\nIl teorema sulla convergenza del gradiente non precondizionato stabilisce una relazione tra l’errore all’iterata k+1 e l’errore all’iterata k, misurati nella norma in energia |e|_A = \\sqrt{e^T A e}, dove e = x - x^k è l’errore e x^k è la soluzione esatta:\n|e_{k+1}|_A^2 \\le \\left( \\frac{\\kappa(A) - 1}{\\kappa(A) + 1} \\right)^2 |e_k|_A^2\ndove \\kappa(A) = \\frac{\\lambda_{max}(A)}{\\lambda_{min}(A)} è il numero di condizionamento della matrice A. Un numero di condizionamento elevato può portare a una convergenza lenta, e in questo caso, non ci sono gradi di libertà per migliorare la situazione nel metodo del gradiente non precondizionato, poiché il passo \\alpha_k è scelto in modo ottimale.\nIl Metodo del Gradiente Precondizionato\nPer accelerare la convergenza, specialmente quando la matrice A ha un elevato numero di condizionamento, si introduce il precondizionamento. L’idea è di trasformare il sistema originale Ax = b in un sistema equivalente con una matrice il cui numero di condizionamento sia più piccolo.\nAlgoritmo del Gradiente Precondizionato\nL’algoritmo del gradiente precondizionato, con un precondizionatore P (simmetrico e definito positivo), procede come segue:\n\nScegli un punto iniziale x_0.\nCalcola il residuo iniziale r_0 = b - Ax_0.\nPer k = 0, 1, 2, \\dots fino a convergenza: a. Risolvi il sistema precondizionato P z_k = r_k per z_k. b. Calcola il passo ottimale \\alpha_k^{pre} (diverso dall’\\alpha_k non precondizionato): \\alpha_k^{pre} = \\frac{z_k^T r_k}{z_k^T A z_k} c. Aggiorna la soluzione: x_{k+1} = x_k + \\alpha_k^{pre} z_k d. Aggiorna il residuo: r_{k+1} = r_k - \\alpha_k^{pre} A z_k\n\nIl professore sottolinea che se il precondizionatore P fosse la matrice identità I, l’algoritmo si ridurrebbe al metodo del gradiente non precondizionato. Inoltre, questo algoritmo generalizza anche il metodo di Richardson stazionario, precondizionato e non precondizionato, a seconda di come viene scelto e utilizzato \\alpha (se costante o variabile) e se P è l’identità o un altro precondizionatore.\nTasso di Convergenza del Gradiente Precondizionato\nIl teorema sulla convergenza del gradiente precondizionato afferma che:\n|e_{k+1}|_{A}^2 \\le \\left( \\frac{\\kappa(P^{-1}A) - 1}{\\kappa(P^{-1}A) + 1} \\right)^2 |e_k|_{A}^2\ndove \\kappa(P^{-1}A) è il numero di condizionamento della matrice precondizionata P^{-1}A. La scelta di un buon precondizionatore P mira a ridurre \\kappa(P^{-1}A), migliorando così il tasso di convergenza.\nOsservazioni Finali\nIl professore conclude suggerendo di utilizzare sempre valori ottimali per i parametri (come \\alpha_k) e di attivare un precondizionatore quando possibile per migliorare l’efficienza dei metodi iterativi.\nReferences\nAppunti Mate Num- lez08.pdf\n2025-03-11 12:46\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine matematica numerica\nmateNum- Lez10\nSpiegazione del Metodo del Gradiente e Introduzione al Gradiente Coniugato\nRicapitolo della Lezione Precedente: Metodo del Gradiente\nIl professore inizia la lezione riprendendo i concetti fondamentali del metodo del gradiente, distinguendo tra la versione non precondizionata e quella precondizionata. L’obiettivo odierno è concludere la discussione sui metodi iterativi, in particolare introducendo il metodo del gradiente coniugato. Viene sottolineata l’importanza dei due “mattoni” del corso: i sistemi (già in discussione) e le questioni di differenza nominale (come ultimo argomento). Il prossimo argomento sarà più “soft”.\nMetodo del Gradiente Non Precondizionato\nIl professore riassume l’algoritmo del metodo del gradiente non precondizionato:\nInput: Guess iniziale x_0.\nInizializzazione: Calcolo del residuo iniziale R_0 = b - A x_0.\nIterazione (ciclo): Per k = 0, 1, 2, \\dots:\n\nCalcolo del parametro di discesa \\alpha_k: \\qquad \\alpha_k = \\frac{R_k^T R_k}{R_k^T A R_k} = \\frac{||R_k||_2^2}{R_k^T A R_k} Viene spiegato che \\alpha_k viene aggiornato ad ogni iterazione poiché il gradiente è un esempio di .\nAggiornamento dell’iterata: \\qquad x_{k+1} = x_k + \\alpha_k R_k La nuova iterata è ottenuta correggendo quella precedente nella direzione del residuo.\nAggiornamento del residuo: \\qquad R_{k+1} = R_k - \\alpha_k A R_k Si nota che anche il residuo viene aggiornato ad ogni iterazione.\n\nViene sottolineato che la richiesta fondamentale per l’applicazione di questo metodo è che la matrice A sia simmetrica e definita positiva. Si accenna alla possibilità che questo algoritmo venga implementato in laboratorio.\nMetodo del Gradiente Precondizionato\nIl professore introduce poi la versione precondizionata del metodo del gradiente:\nInput: Guess iniziale x_0, precondizionatore P (opportunamente scelto).\nInizializzazione: Calcolo del residuo iniziale R_0 = b - A x_0.\nIterazione (ciclo): Per k = 0, 1, 2, \\dots:\n\nCalcolo del residuo precondizionato Z_k: \\qquad P Z_k = R_k Questo passaggio implica la risoluzione di un sistema lineare con il precondizionatore P.\nCalcolo del parametro di discesa \\alpha_k: \\qquad \\alpha_k = \\frac{Z_k^T R_k}{Z_k^T A Z_k} In questo caso, il peso \\alpha_k dipende anche dal residuo precondizionato Z_k.\nAggiornamento dell’iterata: \\qquad x_{k+1} = x_k + \\alpha_k Z_k La correzione all’iterata precedente avviene nella direzione del residuo precondizionato Z_k.\nAggiornamento del residuo: \\qquad R_{k+1} = R_k - \\alpha_k A Z_k\n\nLa vera novità del metodo precondizionato è il calcolo del residuo precondizionato Z_k, che introduce uno step aggiuntivo rispetto alla versione non precondizionata.\nOsservazioni sul Metodo del Gradiente Non Precondizionato\nIl professore si concentra ora sulla versione non precondizionata del gradiente, evidenziando due osservazioni fondamentali che motiveranno l’introduzione del metodo del gradiente coniugato.\nOrtogonalità dei Residui Consecutivi\nAffermazione: Due residui relativi consecutivi, R_k e R_{k+1}, sono tra loro ortogonali. Questo significa che il loro prodotto scalare è zero: \\qquad R_{k+1}^T R_k = 0\nVerifica: Il professore procede con la dimostrazione di questa proprietà:\nPartiamo dalla definizione del residuo al passo k+1: \\qquad R_{k+1} = b - A x_{k+1}\nSostituiamo l’espressione per x_{k+1}: \\qquad R_{k+1} = b - A (x_k + \\alpha_k R_k) \\qquad R_{k+1} = (b - A x_k) - \\alpha_k A R_k\nRiconosciamo che b - A x_k è il residuo R_k: \\qquad R_{k+1} = R_k - \\alpha_k A R_k\nOra calcoliamo il prodotto scalare di R_{k+1} con R_k: \\qquad R_k^T R_{k+1} = R_k^T (R_k - \\alpha_k A R_k) \\qquad R_k^T R_{k+1} = R_k^T R_k - \\alpha_k R_k^T A R_k\nSostituiamo l’espressione di \\alpha_k che abbiamo precedentemente derivato: \\qquad R_k^T R_{k+1} = R_k^T R_k - \\left( \\frac{R_k^T R_k}{R_k^T A R_k} \\right) R_k^T A R_k\nOsservando che R_k^T A R_k è uno scalare (così come R_k^T R_k), possiamo semplificare: \\qquad R_k^T R_{k+1} = R_k^T R_k - R_k^T R_k = 0\nQuesto dimostra che R_k e R_{k+1} sono ortogonali.\nImplicazioni: Questa proprietà vale solo tra due residui consecutivi. In generale, R_{k+1} non è ortogonale a R_{k-1}, R_{k-2}, ecc.. Tuttavia, se consideriamo l’intera sequenza dei residui, si formano due famiglie di vettori ortogonali tra loro: tutti i residui con indice pari sono ortogonali tra loro, e tutti i residui con indice dispari sono ortogonali tra loro. All’interno di ciascuna famiglia (pari o dispari), i vettori risultano essere paralleli. Il professore precisa che questa osservazione è valida in un contesto ideale senza errori di floating point.\nInterpretazione Geometrica\n\nIl professore fornisce un’interpretazione geometrica del metodo del gradiente non precondizionato. La funzione obiettivo \\phi(x) = \\frac{1}{2}x^T A x - b^T x (il cui minimo è la soluzione di Ax=b) ha superfici di livello che sono ellissoidi concentrici in \\mathbb{R}^n (paraboloidi se visualizzati in \\mathbb{R}^{n+1}).\nIl segmento che unisce due approssimazioni consecutive, x_k e x_{k+1}, è tangente all’ellissoide che passa per il punto x_{k+1} e definito dall’insieme dei punti x tali che \\phi(x) = \\phi(x_{k+1}).\nIl gradiente, R_k = b - A x_k = -\\nabla \\phi(x_k), è sempre perpendicolare alle curve di livello nel punto x_k. Quindi, il metodo del gradiente si muove lungo direzioni ortogonali (i residui consecutivi) nel tentativo di raggiungere il centro del paraboloide, che rappresenta il minimo della funzione e quindi la soluzione del sistema lineare.\nIl professore illustra ulteriormente questo concetto considerando un caso semplice con una matrice A diagonale 2 \\times 2, A = \\begin{pmatrix} \\lambda_1 &amp; 0 \\\\ 0 &amp; \\lambda_2 \\end{pmatrix}. In questo caso, la funzione \\phi(x) definisce un ellissoide le cui lunghezze dei semiassi sono inversamente proporzionali a \\lambda_1 e \\lambda_2.\nSe l’ellissoide è molto “schiacciato” (alta eccentricità), il percorso a zig-zag compiuto dal metodo del gradiente per raggiungere il centro diventa più lungo, richiedendo un maggior numero di iterazioni. Al contrario, se l’ellissoide è simile a un cerchio, il metodo del gradiente converge più rapidamente, idealmente in una sola iterazione se fosse un cerchio perfetto partendo dal centro.\nQuesta osservazione è il punto di partenza per l’introduzione del metodo del gradiente coniugato.\nIntroduzione al Metodo del Gradiente Coniugato\nMotivazione\nIl metodo del gradiente classico utilizza come direzione di discesa il residuo R_k, che corrisponde alla direzione di massima discesa locale. Il professore si chiede se sia possibile migliorare la velocità di convergenza sostituendo questa direzione di discesa con una nuova direzione, che viene battezzata P_k. L’obiettivo è trovare una sequenza di direzioni di discesa {P_k} che permettano di raggiungere la soluzione in un numero finito di iterazioni (al massimo n, la dimensione del sistema) in assenza di errori di arrotondamento.\nDefinizione di Direzioni A-Coniugate\nPrima di presentare l’algoritmo del gradiente coniugato, è necessario definire il concetto di direzioni A-coniugate.\nUn insieme di l+1 vettori \\set{P_0, P_1, \\dots, P_l} in \\mathbb{R}^n definiscono direzioni A-coniugate rispetto alla matrice A (simmetrica e definita positiva) se soddisfano la seguente proprietà: \\qquad P_i^T A P_j = 0 \\quad \\text{per } i \\neq j\nSi osserva che se A fosse la matrice identità I, la definizione di A-coniugate si ridurrebbe alla definizione classica di ortogonalità (P_i^T P_j = 0 per i \\neq j). Quindi, la coniugatezza rispetto ad A introduce la struttura del problema nel concetto di ortogonalità.\nQuesto concetto è strettamente legato alla definizione di norma A, ||x||_A = \\sqrt{x^T A x}, e al prodotto scalare indotto da A, \\langle x, y \\rangle_A = x^T A y. Dire che due vettori sono A-coniugati significa che sono ortogonali rispetto a questo nuovo prodotto scalare. Questo può essere interpretato come un cambio di metrica.\nIl professore accenna a una domanda riguardante la consistenza del metodo quando si sostituisce R_k con P_k, rimandando la discussione a un momento successivo.\nProprietà delle Direzioni A-Coniugate\nSe si ha un insieme di n direzioni A-coniugate \\set{P_0, P_1, \\dots, P_{n-1}} in \\mathbb{R}^n, allora questo insieme forma una base per \\mathbb{R}^n.\nPer dimostrare che formano una base, è sufficiente dimostrare che questi vettori sono linearmente indipendenti. Il professore inizia la dimostrazione considerando una combinazione lineare di questi vettori uguale al vettore nullo: \\qquad a_0 P_0 + a_1 P_1 + \\dots + a_{n-1} P_{n-1} = 0\nL’obiettivo è dimostrare che tutti i coefficienti a_i devono essere nulli.\n\nMetodo del Gradiente Coniugato\n1. Definizione e Indipendenza Lineare delle Direzioni Accumulate\nDimostrazione della Loro Indipendenza Lineare:\nPer dimostrare che queste n direzioni accumulate formano una base di \\mathbb{R}^n, è necessario dimostrare la loro indipendenza lineare. Si imposta una combinazione lineare di queste direzioni uguale al vettore nullo:\na_0 p_0 + a_1 p_1 + ... + a_{n-1} p_{n-1} = 0\nL’obiettivo è dimostrare che tutti i coefficienti a_i devono essere necessariamente nulli.\nPasso 1: Moltiplicazione per p_0^T A\nSi moltiplica l’intera combinazione lineare a sinistra per p_0^T A:\np_0^T A (a_0 p_0 + a_1 p_1 + ... + a_{n-1} p_{n-1}) = p_0^T A \\cdot 0\nDistribuendo p_0^T A all’interno della parentesi, si ottiene:\na_0 (p_0^T A p_0) + a_1 (p_0^T A p_1) + ... + a_{n-1} (p_0^T A p_{n-1}) = 0\nSecondo la definizione di direzioni accumulate, per i \\neq 0, si ha p_0^T A p_i = 0. Pertanto, tutti i termini successivi al primo si annullano:\na_0 (p_0^T A p_0) = 0\nLa quantità p_0^T A p_0 è strettamente positiva poiché A è definita positiva. Affinché il prodotto a_0 (p_0^T A p_0) sia zero, l’unica possibilità è che a_0 = 0.\nPasso 2: Generalizzazione per gli Altri Coefficienti\nPer dimostrare che anche a_1 = 0, si moltiplica la combinazione lineare iniziale per p_1^T A:\np_1^T A (a_0 p_0 + a_1 p_1 + ... + a_{n-1} p_{n-1}) = p_1^T A \\cdot 0\nDistribuendo, si ha:\na_0 (p_1^T A p_0) + a_1 (p_1^T A p_1) + ... + a_{n-1} (p_1^T A p_{n-1}) = 0\nPer la proprietà delle direzioni accumulate, p_1^T A p_i = 0 per i \\neq 1. Quindi tutti i termini tranne quello con a_1 si annullano:\na_1 (p_1^T A p_1) = 0\nAnche in questo caso, p_1^T A p_1 &gt; 0 (perché A è definita positiva), il che implica che a_1 = 0.\nQuesto processo si ripete per tutti i coefficienti a_i. Moltiplicando la combinazione lineare per p_i^T A, si dimostra che a_i = 0 per ogni i = 0, 1, ..., n-1. Poiché tutti i coefficienti della combinazione lineare sono nulli, le direzioni accumulate p_0, p_1, ..., p_{n-1} sono linearmente indipendenti e formano quindi una base di \\mathbb{R}^n.\n2. Algoritmo del Gradiente Coniugato\nL’algoritmo del gradiente coniugato viene introdotto definendo i suoi passi fondamentali.\nInizializzazione:\n\nSi sceglie un punto iniziale x_0.\nSi calcola il residuo iniziale r_0 = b - A x_0.\nSi inizializza la prima direzione di discesa p_0 uguale al residuo iniziale: p_0 = r_0.\nSi imposta il contatore dell’iterazione k = 0.\n\nIterazione (fino a convergenza):\n\n\nCalcolo del parametro di accelerazione \\alpha_k: \\alpha_k = \\frac{p_k^T r_k}{p_k^T A p_k}\n\n\nAggiornamento della soluzione: x_{k+1} = x_k + \\alpha_k p_k\n\n\nAggiornamento del residuo: r_{k+1} = r_k - \\alpha_k A p_k\n\n\nCalcolo del coefficiente \\beta_k: \\beta_k = \\frac{p_k^T A r_{k+1}}{p_k^T A p_k} oppure \\beta_k = \\frac{r_{k+1}^T A p_k}{p_k^T A p_k} (essendo A simmetrica)\n\n\nAggiornamento della direzione di discesa: p_{k+1} = r_{k+1} - \\beta_k p_k\n\n\nSi incrementa il contatore: k = k + 1.\n\n\nL’algoritmo continua fino a quando un criterio di convergenza (ad esempio, la norma del residuo è sufficientemente piccola) viene soddisfatto.\n3. Giustificazione delle Formule\n4. Proprietà del Metodo del Gradiente Coniugato*\nMANCAA\n\n4.1 Proprietà 1: Ortogonalità dei Residui rispetto alle Direzioni Precedenti\nSi può dimostrare che il nuovo residuo r_{k+1} è ortogonale alla precedente direzione di discesa p_k:\np_k^T r_{k+1} = 0\nVerifica per p_k^T r_{k+1} = 0:\nSi parte dalla definizione di r_{k+1}:\nr_{k+1} = r_k - \\alpha_k A p_k\nSi moltiplica a sinistra per p_k^T:\np_k^T r_{k+1} = p_k^T r_k - \\alpha_k p_k^T A p_k\nSi sostituisce l’espressione di \\alpha_k:\np_k^T r_{k+1} = p_k^T r_k - \\left( \\frac{p_k^T r_k}{p_k^T A p_k} \\right) p_k^T A p_k p_k^T r_{k+1} = p_k^T r_k - p_k^T r_k = 0\nProcedendo per induzione, si può verificare che il residuo r_{k+1} non è solo ortogonale a p_k, ma a tutte le direzioni precedenti p_i per i = 0, 1, ..., k:\np_i^T r_{k+1} = 0, per i = 0, ..., k\n4.2 Proprietà 2: A-Ortogonalità delle Direzioni di Discesa\nPer costruzione (attraverso la scelta di \\beta_k), la nuova direzione di discesa p_{k+1} è A-ortogonale alla precedente direzione p_k:\np_k^T A p_{k+1} = 0\nCome accennato nella giustificazione di \\beta_k, questa condizione è imposta per derivare il valore di \\beta_k. Procedendo per induzione, si può dimostrare che tutte le direzioni di discesa sono mutuamente A-ortogonali:\np_j^T A p_{k+1} = 0, per j = 0, ..., k\nQuesta proprietà di A-ortogonalità delle direzioni di discesa è fondamentale per la convergenza efficiente del metodo del gradiente coniugato.\n3.1 Giustificazione di \\alpha_k\nLa formula per \\alpha_k è derivata minimizzando la funzione obiettivo quadratica lungo la direzione di ricerca p_k a partire dal punto x_k. La funzione obiettivo ha la forma di un paraboloide.\nSi definisce una funzione G(\\alpha) = \\phi(x_k + \\alpha p_k), dove \\phi(x) = \\frac{1}{2} x^T A x - b^T x è la funzione da minimizzare. Utilizzando l’espansione di Taylor di \\phi intorno a x_k, si ottiene:\nG(\\alpha) = \\phi(x_k) + \\nabla \\phi(x_k)^T (\\alpha p_k) + \\frac{1}{2} (\\alpha p_k)^T H\\phi(x_k) (\\alpha p_k) + ...\nDove \\nabla \\phi(x) = Ax - b = -r(x) e H\\phi(x) = A. Quindi:\nG(\\alpha) = \\phi(x_k) + (-r_k)^T (\\alpha p_k) + \\frac{1}{2} (\\alpha p_k)^T A (\\alpha p_k) G(\\alpha) = \\phi(x_k) - \\alpha r_k^T p_k + \\frac{1}{2} \\alpha^2 p_k^T A p_k\nPer trovare il valore di \\alpha = \\alpha_k che minimizza G(\\alpha), si calcola la derivata prima rispetto ad \\alpha e si impone che sia uguale a zero:\nG&#039;(\\alpha) = -r_k^T p_k + \\alpha p_k^T A p_k = 0\nRisolvendo per \\alpha, si ottiene la formula per \\alpha_k:\n\\alpha_k = \\frac{r_k^T p_k}{p_k^T A p_k} = \\frac{p_k^T r_k}{p_k^T A p_k}\nQuesta scelta di \\alpha_k garantisce che ci si muova lungo la direzione p_k fino al punto in cui la funzione obiettivo è minimizzata in quella direzione.\nMANCAAAAA\n\n3.2 Giustificazione di \\beta_k (no)\nIl coefficiente \\beta_k è scelto in modo da garantire che la nuova direzione di discesa p_{k+1} sia A-ortogonale a tutte le direzioni di discesa precedenti p_0, p_1, ..., p_k. In particolare, si impone la condizione di A-ortogonalità tra p_{k+1} e p_k:\np_k^T A p_{k+1} = 0\nSi assume che la nuova direzione p_{k+1} sia una combinazione lineare del nuovo residuo r_{k+1} e della vecchia direzione p_k:\np_{k+1} = r_{k+1} - \\beta_k p_k (seguendo il testo)\nSostituendo questa espressione nella condizione di A-ortogonalità:\np_k^T A (r_{k+1} - \\beta_k p_k) = 0 p_k^T A r_{k+1} - \\beta_k p_k^T A p_k = 0\nRisolvendo per \\beta_k, si ottiene:\n\\beta_k = \\frac{p_k^T A r_{k+1}}{p_k^T A p_k}\n\nMetodo del Gradiente Coniugato\nTeorema di Convergenza del Gradiente Coniugato\nIl professore introduce un teorema fondamentale che sottolinea la potenza del metodo del gradiente coniugato.\nIl teorema afferma che il gradiente coniugato converge alla soluzione esatta in al più n iterazioni, dove n è l’ordine del sistema lineare da risolvere.\nQuesto risultato è notevole perché trasforma un metodo iterativo in qualcosa che assomiglia a un metodo diretto, in quanto il numero massimo di iterazioni necessarie per la convergenza è finito e noto a priori. Non è necessario implementare criteri di stopping basati su una tolleranza, poiché la convergenza è garantita entro n passi. Tuttavia, il professore anticipa che su spazi di Hilbert si osserverà una convergenza ancora più rapida, richiedendo molte meno di n iterazioni.\nStima dell’Errore e Fattore di Convergenza (Non Precondizionato)\nViene presentata una stima non rigorosa ma intuitiva per l’errore associato all’iterata k-esima. L’errore nella norma A, indicata come ||e_k||_A, può essere controllato rispetto alla norma A dell’errore iniziale ||e_0||_A con un fattore che guida la velocità di convergenza.\nPer il metodo del gradiente semplice, il fattore di convergenza che lega due iterazioni consecutive, quando iterato k volte, porta a controllare l’errore come:\n||e_k||_A \\le \\left( \\frac{\\kappa_2(A) - 1}{\\kappa_2(A) + 1} \\right)^k ||e_0||_A\n\ndove \\kappa_2(A) è il condizionamento della matrice A in norma 2. Il professore sottolinea che se il condizionamento \\kappa_2(A) è grande, la convergenza del gradiente semplice può essere molto lenta.\nPer il gradiente coniugato non precondizionato, il fattore di convergenza è diverso e migliora la situazione:\n\\frac{||e_k||_A}{||e_0||_A} \\le 2 \\left( \\frac{\\sqrt{\\kappa_2(A)} - 1}{\\sqrt{\\kappa_2(A)} + 1} \\right)^k = 2 \\left( \\frac{c}{1 + c} \\right)^{2k}, dove c = \\frac{\\sqrt{\\kappa_2(A)} - 1}{\\sqrt{\\kappa_2(A)} + 1}.\nIl professore evidenzia come la radice quadrata del numero di condizionamento nel fattore di convergenza del gradiente coniugato (non precondizionato) rappresenti un miglioramento significativo rispetto al gradiente semplice. Ad esempio, se \\kappa_2(A) = 10^4, la radice diventa 10^2, riducendo notevolmente l’impatto del malcondizionamento.\nGiustificazione delle n Iterazioni\nIl professore fornisce una spiegazione intuitiva del perché il gradiente coniugato converge in al più n iterazioni, basandosi sulle proprietà delle direzioni di discesa e dei residui.\nOrtogonalità delle Direzioni di Discesa\nLe prime n direzioni di discesa p_0, p_1, ..., p_{n-1} generate dal metodo del gradiente coniugato sono A-ortogonali (o coniugate). Questa proprietà (proprietà 2 menzionata dal professore) implica che queste n direzioni formano una base per \\mathbb{R}^n.\nOrtogonalità del Residuo\nIl residuo all’iterazione l, r_l, è ortogonale a tutte le direzioni di discesa precedenti, p_0, p_1, ..., p_{l-1} (proprietà 1 menzionata dal professore).\nConvergenza in n Passi\nConsiderando il residuo all’iterazione n, r_n, per la proprietà 1, esso deve essere ortogonale a tutte le n direzioni di discesa p_0, p_1, ..., p_{n-1}. Poiché queste direzioni formano una base per \\mathbb{R}^n, l’unico vettore ortogonale a tutti i vettori di una base è il vettore nullo.\nPertanto, r_n = 0, il che implica che x_n è la soluzione esatta (x) del sistema lineare Ax = b. Il professore precisa che potrebbe accadere che il residuo diventi nullo anche prima di n iterazioni, quindi n rappresenta uno scenario “peggiore”.\nDimostrazione Alternativa\nSe non si è convinti, si può esprimere r_n come combinazione lineare delle direzioni di discesa:\nr_n = c_0 p_0 + c_1 p_1 + ... + c_{n-1} p_{n-1}\nAndando a calcolare il prodotto scalare di r_n con ciascuna direzione p_i e sfruttando la proprietà di ortogonalità tra il residuo r_i e le direzioni precedenti, si dimostra che tutti i coefficienti c_i devono essere zero, confermando che r_n è il vettore nullo.\nMetodo del Gradiente Coniugato Precondizionato\nIl professore introduce la variante precondizionata del metodo del gradiente coniugato, utile per accelerare la convergenza, specialmente in caso di sistemi mal condizionati. Si assume che la matrice A sia simmetrica e definita positiva.\nAlgoritmo\n\nCalcolo del residuo iniziale: r_0 = b - Ax_0.\nCalcolo del residuo precondizionato iniziale: Risolvere Mz_0 = r_0 per z_0, dove M è la matrice di precondizionamento.\nScelta della prima direzione di discesa: p_0 = z_0 (anziché r_0).\nIterazioni per k = 0, 1, ...:\n\nCalcolo del passo \\alpha_k: \\alpha_k = \\frac{r_k^T z_k}{p_k^T A p_k}.\nAggiornamento della soluzione: x_{k+1} = x_k + \\alpha_k p_k.\nAggiornamento del residuo: r_{k+1} = r_k - \\alpha_k A p_k.\nCalcolo del nuovo residuo precondizionato: Risolvere Mz_{k+1} = r_{k+1} per z_{k+1}.\nCalcolo del coefficiente \\beta_k: \\beta_k = \\frac{p_k^T A z_{k+1}}{p_k^T A p_k} (formula modificata rispetto al non precondizionato).\nAggiornamento della direzione di discesa: p_{k+1} = z_{k+1} - \\beta_k p_k (formula modificata rispetto al non precondizionato, utilizza z_{k+1} invece di r_{k+1}).\n\n\n\nStima dell’Errore e Fattore di Convergenza (Precondizionato)\nSISTEMARE\n\nAnche per il metodo precondizionato, l’errore associato all’iterata k-esima in norma A può essere confrontato con l’errore iniziale tramite un fattore di convergenza:\n\\frac{||e_k||_A}{||e_0||_A} \\le 2 \\left( \\frac{\\sqrt{\\kappa_2(M^{-1}A)} - 1}{\\sqrt{\\kappa_2(M^{-1}A)} + 1} \\right)^k = 2 \\left( \\frac{\\tilde{c}}{1 + \\tilde{c}} \\right)^{2k}, dove \\tilde{c} = \\frac{\\sqrt{\\kappa_2(M^{-1}A)} - 1}{\\sqrt{\\kappa_2(M^{-1}A)} + 1}.\nIl professore sottolinea come il numero di condizionamento della matrice precondizionata M^{-1}A, \\kappa_2(M^{-1}A), influenzi la velocità di convergenza. Una buona scelta della matrice di precondizionamento M può significativamente ridurre questo numero di condizionamento, accelerando la convergenza.\nApplicazione alla Matrice di Hilbert (Inverta)\nIl professore passa a considerare la risoluzione di un sistema lineare Ax = b dove A è la matrice di Hilbert, nota per essere simmetrica definita positiva e mal condizionata. La matrice di Hilbert H_n ha elementi H_{ij} = \\frac{1}{i+j-1}.\nCondizionamento della Matrice di Hilbert\nViene mostrato come il numero di condizionamento della matrice di Hilbert cresca rapidamente con la dimensione n del sistema:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimensione nNumero di Condizionamento \\kappa_2(A)4\\mathcal{O}(10^4)6\\mathcal{O}(10^6)8\\mathcal{O}(10^8)10\\mathcal{O}(10^{11})12\\mathcal{O}(10^{14})14\\mathcal{O}(10^{17})\nQuesta rapida crescita del condizionamento suggerisce che la risoluzione di sistemi con la matrice di Hilbert può essere problematica, specialmente per metodi diretti.\nRisultati con il Metodo Diretto (Slash in Matlab)\nUtilizzando un metodo diretto (rappresentato dal comando “slash” in Matlab), si osservano i seguenti errori nella soluzione:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimensione nErrore Metodo Diretto4\\mathcal{O}(10^{-13})6\\mathcal{O}(10^{-10})14\\mathcal{O}(10^{1})\nI risultati mostrano una rapida perdita di precisione con l’aumentare della dimensione n, confermando le difficoltà nel risolvere sistemi di Hilbert con metodi diretti a causa del suo elevato condizionamento. Per n=14, l’errore è addirittura dell’ordine di 10^1, rendendo la soluzione inaffidabile.\nRisultati con Metodi Iterativi Precondizionati\nVengono considerati il Gradiente Precondizionato (PG) e il Gradiente Coniugato Precondizionato (PCG), entrambi precondizionati con la matrice diagonale D = diag(A) contenente gli elementi diagonali della matrice di Hilbert. Si parte da una guess iniziale nulla e si fissa una tolleranza di 10^{-6} per la convergenza.\nGradiente Precondizionato (GP)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimensione nErrore GP PrecondizionatoNumero Iterazioni GP Precondizionato4\\mathcal{O}(10^{-3})9956\\mathcal{O}(10^{-3})181314\\mathcal{O}(10^{-3})3779\nSi osserva che l’errore rimane costante all’incirca a \\mathcal{O}(10^{-3}) al variare di n, il che è un risultato positivo considerando il malcondizionamento crescente. Tuttavia, l’errore non raggiunge la tolleranza desiderata di 10^{-6}, e il numero di iterazioni cresce con la dimensione del sistema.\nGradiente Coniugato Precondizionato (GCP)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDimensione nErrore GCP PrecondizionatoNumero Iterazioni GCP Precondizionato4\\mathcal{O}(10^{-2})36\\mathcal{O}(10^{-3})48\\mathcal{O}(10^{-3})414\\mathcal{O}(10^{-3})5\nIl gradiente coniugato precondizionato mostra un comportamento notevolmente migliore. L’errore si stabilizza anch’esso intorno a \\mathcal{O}(10^{-3}), simile al gradiente precondizionato, ma il numero di iterazioni necessarie per la convergenza rimane estremamente basso e quasi indipendente dalla dimensione del sistema n. Questo dimostra l’efficacia del gradiente coniugato precondizionato nel gestire sistemi mal condizionati come quelli con la matrice di Hilbert, raggiungendo una precisione simile al gradiente precondizionato con un costo computazionale drasticamente inferiore in termini di numero di iterazioni.\nIl professore conclude sottolineando come il gradiente coniugato precondizionato sia vincente nel caso della matrice di Hilbert, riuscendo a controllare l’errore con un numero molto ridotto di iterazioni, a differenza del metodo diretto che fallisce e del gradiente precondizionato che richiede molte più iterazioni.\nReferences\nAppunti Mate Num 1- lez10.pdf\n2025-03-11 12:15\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine matematica numerica\nMatenum- lez11\nApprossimazione di Funzioni e Dati\nIntroduzione all’Approssimazione\nIl corso inizia con l’introduzione al concetto di approssimazione di funzioni e dati. Si parte dall’ipotesi di avere una funzione f definita su un intervallo [a, b] della retta reale. Nel caso dei dati, si considera una collezione di misurazioni, rappresentate come coppie di istanti temporali (o più in generale, ascisse x_i) e valori misurati y_i.\nMotivazioni per l’Approssimazione\nSi esplorano le ragioni per cui potrebbe essere utile o necessario approssimare funzioni e dati. L’idea fondamentale è di rimpiazzare un oggetto potenzialmente complesso o difficile da manipolare con qualcosa di più gestibile.\nApprossimazione di Funzioni\nUn contesto significativo in cui l’approssimazione di funzioni si rivela utile è nel calcolo di integrali. Se si ha un integrale definito di una funzione f(x) tra a e b, \\int_a^b f(x) dx, e la funzione integranda è particolarmente complessa, potrebbe non essere calcolabile in forma esplicita o potrebbe essere espressa come una serie non facilmente valutabile. In questi casi, si può rimpiazzare f(x) con una sua approssimazione \\tilde{f}(x) che sia più facile da integrare. La scelta di \\tilde{f}(x) deve essere tale che l’integrale \\int_a^b \\tilde{f}(x) dx sia facilmente calcolabile. Una scelta suggerita è quella di approssimare f(x) con un polinomio, poiché i polinomi sono facilmente integrabili. L’integrale di f(x) (\\text{IDF}) viene approssimato dall’integrale di \\tilde{f}(x) (\\text{ID}\\tilde{f}): \\text{IDF} = \\int_a^b f(x) dx \\approx \\int_a^b \\tilde{f}(x) dx = \\text{ID}\\tilde{f}\nUn altro contesto menzionato è la soluzione di equazioni non lineari, dove una funzione complessa potrebbe essere sostituita con un polinomio per semplificare la ricerca delle soluzioni.\nApprossimazione di Dati\nQuando si ha a che fare con una collezione di dati, come misurazioni di temperatura nel tempo, l’approssimazione può servire a trovare una tendenza o una legge sottostante i dati. Se da una serie di misurazioni si riesce a dedurre un andamento, questo può essere utilizzato per stimare il valore della grandezza misurata in istanti o luoghi in cui non sono state effettuate misurazioni.\nLa natura dei dati influenza il tipo di approssimazione più appropriato.\n\nPochi dati ben distribuiti: In questo caso, si può cercare di costruire una curva che replica i valori misurati nei punti in cui sono stati acquisiti.\nMolti dati distribuiti in modo caotico (nuvola di dati): In questa situazione, cercare una curva che passi per tutti i punti risulterebbe in un andamento molto irregolare e poco significativo. È più sensato cercare una curva più semplice, come una retta o una parabola, che colga l’andamento generale dei dati senza necessariamente passare per ogni singolo punto.\n\nTipi di Approssimazione: Interpolazione e Minimi Quadrati\nVengono distinti due tipi principali di approssimazione:\n\nInterpolazione: Questo tipo di approssimazione mira a costruire una curva che passa esattamente per i punti dati. È adatta quando si hanno pochi dati ben distribuiti o quando si vuole replicare esattamente i valori di una funzione in specifici punti. Un esempio menzionato è l’interpolazione lineare a tratti, dove si uniscono punti consecutivi con segmenti di retta.\nApprossimazione ai Minimi Quadrati: Questo metodo è più adatto a dati distribuiti in modo caotico e cerca di trovare una curva che minimizza la somma dei quadrati delle differenze tra i valori misurati e i valori sulla curva approssimante. L’obiettivo non è replicare esattamente i singoli valori, ma catturare l’andamento generale. Questo approccio è strettamente legato all’ambito statistico.\n\nApprossimazione di Funzioni e l’Analisi: La Serie di Taylor\nQuando si considera l’approssimazione di funzioni, lo strumento principale offerto dall’analisi è lo sviluppo di Taylor. La serie di Taylor di una funzione f(x) centrata in un punto x_0 è data da: f(x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(x_0)}{k!} (x - x_0)^k = f(x_0) + f&#039;(x_0)(x-x_0) + \\frac{f&#039;&#039;(x_0)}{2!}(x-x_0)^2 + ...\nLo sviluppo di Taylor fornisce un’approssimazione della funzione in un intorno del punto x_0. Tuttavia, presenta due principali limiti:\n\nLocalità: Lo sviluppo di Taylor è una buona approssimazione solo in un intorno ristretto del punto in cui viene centrato. L’esempio della funzione f(x) = \\frac{1}{x} centrata in x_0 = 1 illustra come l’approssimazione di Taylor possa divergere rapidamente al di fuori di un piccolo intervallo intorno a 1. Sebbene in alcuni casi, come l’esponenziale centrato in zero, l’approssimazione possa essere valida su un intervallo più ampio, la località rimane un problema generale.\nRegolarità: Per poter scrivere l’espansione di Taylor fino a un certo ordine (e quindi ottenere una buona approssimazione troncando la serie), è necessario che la funzione f(x) sia sufficientemente derivabile e che le sue derivate siano continue. In molti fenomeni realistici, la regolarità richiesta per lo sviluppo di Taylor potrebbe non essere soddisfatta.\n\nA causa di questi limiti, si rende necessario esplorare metodi di approssimazione alternativi, come l’interpolazione.\nInterpolazione: Definizione e Obiettivo\nL’interpolazione consiste nel trovare un oggetto (nel nostro caso, una funzione \\tilde{f}(x)) che passa esattamente per un insieme di n+1 coppie di dati (x_i, y_i), dove i va da 0 a n. Le x_i sono chiamate nodi di interpolazione e devono essere distinte tra loro (x_i \\neq x_j per i \\neq j). Le y_i rappresentano i valori da interpolare, che possono essere i valori di una funzione f(x) nei nodi (y_i = f(x_i)) o direttamente dei dati misurati.\nL’obiettivo dell’interpolazione è trovare una funzione \\tilde{f}(x) tale che: \\tilde{f}(x_i) = y_i \\quad \\text{per } i = 0, 1, ..., n Queste condizioni sono chiamate condizioni di interpolazione.\nScelta della Funzione Interpolante\nLa funzione \\tilde{f}(x) può essere scelta tra diverse classi di funzioni:\n\n\nInterpolazione Polinomiale: In questo caso, la funzione interpolante \\tilde{f}(x) è un polinomio. L’insieme dei polinomi di grado al più Q con coefficienti reali è denotato con \\mathbb{P}_Q, e un generico polinomio P_Q(x) \\in \\mathbb{P}_Q ha la forma: P_Q(x) = a_0 + a_1 x + a_2 x^2 + ... + a_Q x^Q, dove a_i \\in \\mathbb{R} per i = 0, ..., Q. Ci focalizzeremo principalmente su questo tipo di interpolazione.\n\n\nInterpolazione Trigonometrica: In questo caso, la funzione interpolante è una combinazione di funzioni trigonometriche, come seni e coseni, o equivalentemente, esponenziali complessi. Questo tipo di interpolazione è strettamente legato alle serie di Fourier e viene spesso utilizzato per approssimare segnali e onde. La forma generale può essere espressa come una somma: \\tilde{f}(x) = \\sum_{k} A_k e^{ikx}, dove A_k \\in \\mathbb{R} sono i coefficienti.\n\n\nInterpolazione Razionale: In questo caso, la funzione interpolante \\tilde{f}(x) è un quoziente di due polinomi: \\tilde{f}(x) = \\frac{P(x)}{S(x)} = \\frac{a_0 + a_1 x + ... + a_k x^k}{b_0 + b_1 x + ... + b_s x^s}, dove a_i, b_i \\in \\mathbb{R}.\n\n\nInterpolazione Polinomiale: Esistenza e Unicità\nSi introduce una proposizione fondamentale riguardante l’interpolazione polinomiale:\nProposizione: Si considerino n+1 coppie di dati (x_i, y_i) per i = 0, ..., n, con i nodi di interpolazione x_i distinti tra loro. Allora, esiste ed è unico un polinomio \\pi_n(x) di grado minore o uguale a n tale che \\pi_n(x_i) = y_i per i = 0, ..., n.\nIl simbolo \\pi_n viene utilizzato per denotare il polinomio interpolante di grado al più n. È importante notare lo stretto legame tra il numero di dati (n+1) e il grado massimo del polinomio interpolante (n). Questo è una caratteristica distintiva dell’interpolazione polinomiale rispetto ad altri metodi di approssimazione come i minimi quadrati, dove il grado del polinomio approssimante può essere scelto indipendentemente dal numero di dati.\nIl polinomio di interpolazione \\pi_n(x) viene definito come un’approssimazione globale, in quanto utilizza tutti i dati contemporaneamente per la sua costruzione.\nDimostrazione dell’Unicità\nPer dimostrare l’unicità del polinomio interpolante, si procede per assurdo. Si suppone che esistano due polinomi, \\pi_n(x) e \\pi_n^*(x), entrambi di grado al più n, tali che interpolino gli stessi n+1 punti (x_i, y_i): \\pi_n(x_i) = y_i \\quad \\text{per } i = 0, ..., n \\pi_n^*(x_i) = y_i \\quad \\text{per } i = 0, ..., n\nSi considera la differenza tra i due polinomi: d(x) = \\pi_n(x) - \\pi_n^*(x)\nPoiché sia \\pi_n(x) che \\pi_n^*(x) hanno grado al più n, anche la loro differenza d(x) avrà grado al più n. Valutando d(x) nei nodi di interpolazione x_i, si ottiene: d(x_i) = \\pi_n(x_i) - \\pi_n^*(x_i) = y_i - y_i = 0 \\quad \\text{per } i = 0, ..., n\nQuesto significa che il polinomio d(x) ha n+1 radici distinte (i nodi di interpolazione x_0, x_1, ..., x_n). Tuttavia, un polinomio non nullo di grado al più n può avere al massimo n radici distinte. Affinché un polinomio di grado al più n abbia n+1 radici distinte, esso deve essere identicamente nullo: d(x) = 0 \\quad \\forall x\nQuesto implica che: \\pi_n(x) - \\pi_n^*(x) = 0 \\implies \\pi_n(x) = \\pi_n^*(x)\nPertanto, il polinomio interpolante di grado al più n che passa per n+1 punti distinti è unico. La dimostrazione dell’esistenza verrà affrontata successivamente attraverso la costruzione esplicita del polinomio interpolante.\n\nPolinomio Interpolatore\nUnicità del Polinomio Interpolatore\nIl professore inizia dimostrando per assurdo l’unicità del polinomio di grado n che interpola n+1 punti. Suppone che esistano due polinomi distinti, \\pi_n(x) e \\pi_n^*(x), entrambi di grado n, che replicano gli stessi valori y_i in corrispondenza dei nodi x_i per i che va da 0 a n. Questo significa che:\n\\pi_n(x_i) = y_i \\pi_n^*(x_i) = y_i\nper i = 0, 1, ..., n.\nSuccessivamente, introduce un polinomio differenza G_n(x) definito come:\nG_n(x) = \\pi_n(x) - \\pi_n^*(x).\nQuesto polinomio G_n(x) è anch’esso di grado al più n, essendo la differenza di due polinomi di grado n. Valutando G_n(x) nei nodi di interpolazione x_i, si ottiene:\nG_n(x_i) = \\pi_n(x_i) - \\pi_n^*(x_i) = y_i - y_i = 0.\nQuesto implica che il polinomio G_n(x) di grado n si annulla in n+1 punti distinti (x_0, x_1, ..., x_n). Un polinomio di grado n può avere al massimo n radici (o zeri), a meno che non sia il polinomio identicamente nullo.\nL’unica possibilità affinché un polinomio di grado n abbia n+1 zeri è che sia il polinomio che associa 0 ad ogni valore di x:\nG_n(x) = 0 per ogni x.\nSostituendo la definizione di G_n(x), si ha:\n\\pi_n(x) - \\pi_n^*(x) = 0 per ogni x.\nDa cui si conclude che:\n\\pi_n(x) = \\pi_n^*(x) per ogni x.\nQuesto contraddice l’ipotesi iniziale che i due polinomi fossero distinti, dimostrando quindi l’unicità del polinomio interpolatore di grado n.\nCostruzione del Polinomio Interpolatore\nDopo aver dimostrato l’unicità, il professore passa alla costruzione del polinomio interpolatore \\pi_n(x). Inizia considerando un caso particolare per poi generalizzare.\nCaso Particolare: Interpolazione con Tre Nodi e Valori Specifici\nSi considerano tre nodi di interpolazione: x_0 = 0, x_1 = 0.5, x_2 = 1, e i corrispondenti valori da interpolare: y_0 = 0, y_1 = 1, y_2 = 0. L’obiettivo è costruire un polinomio di grado 2 (una parabola) che passi per i punti (0, 0), (0.5, 1), e (1, 0).\nInvece di chiamare subito il polinomio \\pi_2(x), il professore lo battezza f_1(x). L’indice ‘1’ nel pedice indica il nodo in corrispondenza del quale il valore interpolato non è zero (in questo caso, y_1 = 1 al nodo x_1 = 0.5).\nSi cerca un polinomio di grado 2 che si annulli in x_0 = 0 e x_2 = 1. Un modo semplice per costruire un tale polinomio è il prodotto di monomi:\n(x - x_0)(x - x_2) = (x - 0)(x - 1) = x(x - 1) = x^2 - x.\nQuesto polinomio si annulla in x = 0 e x = 1, soddisfacendo le condizioni in x_0 e x_2. Tuttavia, valutandolo in x_1 = 0.5, si ottiene:\n(0.5)^2 - 0.5 = 0.25 - 0.5 = -0.25.\nPer fare in modo che il polinomio valga 1 in x_1 = 0.5, è necessario dividere per il valore che il polinomio assume in quel punto:\nf_1(x) = \\frac{(x - x_0)(x - x_2)}{(x_1 - x_0)(x_1 - x_2)} = \\frac{(x - 0)(x - 1)}{(0.5 - 0)(0.5 - 1)} = \\frac{x(x - 1)}{0.5 \\times (-0.5)} = \\frac{x^2 - x}{-0.25} = -4(x^2 - x) = 4x - 4x^2.\nQuindi, il polinomio interpolatore f_1(x) = 4x - 4x^2 è una parabola che passa per i punti (0, 0), (0.5, 1), e (1, 0).\nGeneralizzazione: Costruzione dei Polinomi Caratteristici di Lagrange\nIl professore generalizza ora la costruzione al caso di n+1 nodi di interpolazione generici x_0, x_1, ..., x_n e suppone che l’unico valore da interpolare diverso da zero (e uguale a 1) sia in corrispondenza del k-esimo nodo x_k, cioè y_k = 1 e y_i = 0 per i \\neq k. Si vuole costruire il polinomio f_k(x) di grado n tale che:\nf_k(x_j) = \\delta_{jk} = \\begin{cases} 1 &amp; \\text{se } j = k \\\\ 0 &amp; \\text{se } j \\neq k \\end{cases}\ndove \\delta_{jk} è il delta di Kronecker.\nAnalogamente al caso particolare, f_k(x) deve annullarsi in tutti i nodi x_j con j \\neq k. Questo si ottiene considerando il prodotto di monomi che includono tutti i fattori (x - x_j) eccetto quello con j = k:\n\\prod_{j=0, j \\neq k}^{n} (x - x_j) = (x - x_0)(x - x_1)...(x - x_{k-1})(x - x_{k+1})...(x - x_n).\nQuesto prodotto è un polinomio di grado n. Per fare in modo che f_k(x_k) = 1, si divide questo prodotto per il valore che assume in x = x_k:\nf_k(x) = \\frac{\\prod_{j=0, j \\neq k}^{n} (x - x_j)}{\\prod_{j=0, j \\neq k}^{n} (x_k - x_j)}.\nIl polinomio f_k(x) così definito è chiamato polinomio caratteristico di Lagrange associato al nodo x_k.\nIl denominatore è una costante data da:\n(x_k - x_0)(x_k - x_1)...(x_k - x_{k-1})(x_k - x_{k+1})...(x_k - x_n).\nQuando si valuta f_k(x) in un nodo x_i:\n\nSe i = k, il numeratore contiene tutti i fattori del denominatore (con l’ordine dei termini possibilmente diverso), quindi f_k(x_k) = 1.\nSe i \\neq k, uno dei fattori nel numeratore sarà (x_i - x_i) = 0, rendendo l’intero prodotto nullo, quindi f_k(x_i) = 0.\n\nAnalogie con la Funzione Caratteristica\nIl professore fa un’analogia tra il polinomio caratteristico di Lagrange e la funzione caratteristica (o funzione indicatrice) di un insieme \\Omega in \\mathbb{R}^d, spesso indicata con \\mathbb{1}_{\\Omega}(x) o \\chi_{\\Omega}(x). Questa funzione vale:\n\\chi_{\\Omega}(x) = \\begin{cases} 1 &amp; \\text{se } x \\in \\omega \\\\ 0 &amp; \\text{se } x \\notin \\omega \\end{cases}.\nL’analogia risiede nel fatto che f_k(x) “si accende” (vale 1) solo nel nodo x_k e “si spegne” (vale 0) in tutti gli altri nodi di interpolazione. Questa proprietà permette di localizzare il contributo di ciascun nodo all’interpolazione.\nCaso Generale: Polinomio Interpolatore di Lagrange\nInfine, il professore considera il caso generale in cui si vogliono interpolare i valori y_0, y_1, ..., y_n in corrispondenza dei nodi x_0, x_1, ..., x_n . Il polinomio interpolatore di Lagrange \\pi_n(x) si può esprimere come una combinazione lineare dei polinomi caratteristici di Lagrange :\n\\pi_n(x) = \\sum_{k=0}^{n} y_k f_k(x) = \\sum_{k=0}^{n} y_k \\prod_{j=0, j \\neq k}^{n} \\frac{(x - x_j)}{(x_k - x_j)} .\nDove y_k sono i valori da interpolare nei nodi x_k.\nPer verificare che questo polinomio interpola correttamente i dati, valutiamolo in un nodo x_i:\n\\pi_n(x_i) = \\sum_{k=0}^{n} y_k f_k(x_i)\nSappiamo che f_k(x_i) = \\delta_{ik}, quindi f_k(x_i) è 1 se k = i e 0 se k \\neq i. Pertanto, nella somma, l’unico termine non nullo è quello in cui k = i:\n\\pi_n(x_i) = y_i f_i(x_i) = y_i \\times 1 = y_i.\nQuesto dimostra che il polinomio di Lagrange \\pi_n(x) passa per tutti i punti (x_i, y_i) per i = 0, 1, ..., n. Essendo una combinazione lineare di polinomi di grado n, anche \\pi_n(x) è un polinomio di grado al più n. Per l’unicità dimostrata in precedenza, questo è l’unico polinomio di grado n che interpola i dati.\n\nCostruzione del Polinomio di Interpolazione\nPrimo Metodo: Utilizzo dei Polinomi Caratteristici (Forma di Lagrange)\nL’obiettivo è costruire un polinomio \\pi_2(x) di grado 2 che soddisfi tre condizioni di interpolazione date da tre nodi (x_0, y_0), (x_1, y_1), (x_2, y_2).\nSi decide di esprimere \\pi_2(x) come una combinazione lineare di tre polinomi caratteristici f_0(x), f_1(x), f_2(x) associati rispettivamente ai nodi x_0, x_1, x_2:\n\\pi_2(x) = a f_0(x) + b f_1(x) + c f_2(x)\ndove a, b, c sono i coefficienti da determinare.\nQuesti polinomi caratteristici hanno la seguente proprietà fondamentale:\nf_i(x_j) = \\delta_{ij} = \\begin{cases} 1 &amp; \\text{se } i = j \\\\ 0 &amp; \\text{se } i \\neq j \\end{cases}\nEsplicitamente:\nf_0(x_0) = 1, f_0(x_1) = 0, f_0(x_2) = 0 f_1(x_0) = 0, f_1(x_1) = 1, f_1(x_2) = 0 f_2(x_0) = 0, f_2(x_1) = 0, f_2(x_2) = 1\nOra si impongono le condizioni di interpolazione:\n\n\n\\pi_2(x_0) = y_0: a f_0(x_0) + b f_1(x_0) + c f_2(x_0) = y_0 a \\cdot 1 + b \\cdot 0 + c \\cdot 0 = y_0 \\implies \\mathbf{a = y_0}\n\n\n\\pi_2(x_1) = y_1: a f_0(x_1) + b f_1(x_1) + c f_2(x_1) = y_1 a \\cdot 0 + b \\cdot 1 + c \\cdot 0 = y_1 \\implies \\mathbf{b = y_1}\n\n\n\\pi_2(x_2) = y_2: a f_0(x_2) + b f_1(x_2) + c f_2(x_2) = y_2 a \\cdot 0 + b \\cdot 0 + c \\cdot 1 = y_2 \\implies \\mathbf{c = y_2}\n\n\nSostituendo i valori di a, b, c nell’espressione di \\pi_2(x), si ottiene la forma del polinomio interpolatore di grado 2:\n\\mathbf{\\pi_2(x) = y_0 f_0(x) + y_1 f_1(x) + y_2 f_2(x)}\nGeneralizzando questo risultato per n+1 punti di interpolazione (x_i, y_i) con i = 0, 1, \\dots, n, il polinomio interpolatore \\pi_n(x) di grado n è dato da:\n\\mathbf{\\pi_n(x) = \\sum_{k=0}^{n} y_k f_k(x)}\ndove f_k(x) è il polinomio caratteristico associato al nodo x_k e ha la forma:\n\\mathbf{f_k(x) = \\prod_{j=0, j\\neq k}^{n} \\frac{x - x_j}{x_k - x_j}}\nSostituendo l’espressione di f_k(x) nella formula per \\pi_n(x), si ottiene la forma di Lagrange del polinomio interpolatore:\n\\mathbf{\\pi_n(x) = \\sum_{k=0}^{n} y_k \\prod_{j=0, j\\neq k}^{n} \\frac{x - x_j}{x_k - x_j}}\nSecondo Metodo: Risoluzione di un Sistema Lineare\nUn altro modo per costruire il polinomio interpolatore \\pi_n(x) è di esprimerlo nella sua forma generale come un polinomio di grado n:\n\\mathbf{\\pi_n(x) = a_0 + a_1 x + a_2 x^2 + \\dots + a_n x^n = \\sum_{i=0}^{n} a_i x^i}\ndove a_0, a_1, \\dots, a_n sono i coefficienti incogniti (in numero di n+1) che devono essere determinati.\nUtilizzando le n+1 condizioni di interpolazione \\pi_n(x_i) = y_i per i = 0, 1, \\dots, n, si ottiene un sistema di n+1 equazioni lineari nelle n+1 incognite a_0, a_1, \\dots, a_n:\n\\begin{cases} a_0 + a_1 x_0 + a_2 x_0^2 + \\dots + a_n x_0^n = y_0 \\\\ a_0 + a_1 x_1 + a_2 x_1^2 + \\dots + a_n x_1^n = y_1 \\\\ \\vdots \\ a_0 + a_1 x_n + a_2 x_n^2 + \\dots + a_n x_n^n = y_n \\end{cases}\nQuesto sistema può essere scritto in forma matriciale come:\n\\mathbf{B A = Y}\ndove:\n\n\n\\mathbf{B} è la matrice di Vandermonde di dimensione (n+1) \\times (n+1):\n\\mathbf{B} = \\begin{pmatrix} 1 &amp; x_0 &amp; x_0^2 &amp; \\dots &amp; x_0^n \\\\ 1 &amp; x_1 &amp; x_1^2 &amp; \\dots &amp; x_1^n \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; x_n &amp; x_n^2 &amp; \\dots &amp; x_n^n \\end{pmatrix}\n\n\n\\mathbf{A} è il vettore delle incognite (i coefficienti del polinomio):\n\\mathbf{A} = \\begin{pmatrix} a_0 \\\\ a_1 \\\\ \\vdots \\\\ a_n \\end{pmatrix}\n\n\n\\mathbf{Y} è il vettore dei valori da interpolare:\n\\mathbf{Y} = \\begin{pmatrix} y_0 \\ y_1 \\ \\vdots \\ y_n \\end{pmatrix}\n\n\nLa matrice di Vandermonde \\mathbf{B} è non singolare (e quindi il sistema ammette un’unica soluzione) se e solo se tutti i nodi x_i sono distinti. Questa è l’ipotesi fondamentale sotto cui si formalizza il problema di interpolazione.\nTuttavia, la matrice di Vandermonde è fortemente mal condizionata, simile alla matrice di Hilbert. Questo significa che la risoluzione diretta di questo sistema può portare a coefficienti numericamente inaffidabili, specialmente per valori di n elevati. Pertanto, questo secondo metodo, pur essendo concettualmente semplice, è spesso evitato nella pratica numerica. I metodi iterativi possono migliorare la situazione, ma rimangono comunque rischiosi. Nonostante ciò, questo approccio è spesso presentato a livelli didattici inferiori come introduzione al problema.\nComandi MATLAB per l’Interpolazione Polinomiale\nMATLAB fornisce due comandi principali per lavorare con l’interpolazione polinomiale:\n\n\nPolifit(x, y, n): Questo comando costruisce il polinomio interpolatore.\n\nInput:\n\nx: un vettore contenente i nodi di interpolazione.\ny: un vettore contenente i valori da interpolare nei rispettivi nodi.\nn: il grado del polinomio interpolatore desiderato. È importante notare che, se si hanno n+1 dati e si desidera interpolarli esattamente, il grado del polinomio sarà n. La funzione Polifit è in realtà progettata anche per il fitting ai minimi quadrati, dove il grado del polinomio può essere inferiore al numero di dati. Nel caso di interpolazione esatta con n+1 dati, specificare il grado n corrisponde a trovare il polinomio che passa esattamente per tutti i punti.\n\n\nOutput:\n\nC: un vettore contenente i coefficienti del polinomio interpolatore di grado n. I coefficienti sono ordinati in modo decrescente rispetto al grado, ovvero C = [c_n, c_{n-1}, \\dots, c_1, c_0], dove il polinomio è p(x) = c_n x^n + c_{n-1} x^{n-1} + \\dots + c_1 x + c_0. È fondamentale ricordare questo ordine per interpretare correttamente i risultati.\n\n\n\n\n\nPolival(C, D): Questo comando valuta un polinomio in uno o più punti.\n\nInput:\n\nC: il vettore dei coefficienti del polinomio (ottenuto da Polifit o definito manualmente).\nD: uno scalare o un vettore contenente i punti in cui si desidera valutare il polinomio.\n\n\nOutput:\n\nQ: uno scalare o un vettore contenente i valori del polinomio valutato nei punti specificati in D. Se D è un numero reale, Q sarà un numero reale, \\pi_n(D) = Q. Se D è un vettore di punti, Q sarà un vettore contenente i valori del polinomio in corrispondenza di ciascun punto in D.\n\n\n\n\n\nL’utilità di Polival si manifesta, ad esempio, quando si vuole valutare l’errore dell’interpolazione. Anche se il polinomio interpolatore coincide con la funzione nei nodi di interpolazione, in altri punti potrebbe esserci una discrepanza. Valutando il polinomio in punti intermedi (non inclusi nel set di nodi) e confrontando il valore ottenuto con il valore effettivo della funzione (se conosciuta), è possibile stimare l’errore commesso dall’approssimazione polinomiale.\nErrore del Polinomio di Interpolazione\nQuando si interpola una funzione f(x) utilizzando un polinomio \\pi_n(x) costruito sui nodi x_0, x_1, \\dots, x_n, è importante analizzare l’errore di interpolazione, definito come la differenza tra la funzione e il polinomio:\n\\mathbf{e_n(f(x)) = f(x) - \\pi_n(f(x))}\nSe la funzione f(x) è sufficientemente regolare, ovvero se f è continua insieme alle sue derivate fino all’ordine n+1 nell’intervallo I = [\\min(x_0, \\dots, x_n), \\max(x_0, \\dots, x_n)], allora per ogni x \\in I, esiste un punto \\alpha(x) \\in I (che dipende da x) tale che l’errore è dato da:\n\\mathbf{e_n(f(x)) = \\frac{1}{(n+1)!} f^{(n+1)}(\\alpha(x)) w_{n+1}(x)}\ndove f^{(n+1)}(\\alpha(x)) è la derivata di ordine n+1 di f valutata nel punto \\alpha(x), e w_{n+1}(x) è il polinomio nodale:\n\\mathbf{w_{n+1}(x) = \\prod_{k=0}^{n} (x - x_k) = (x - x_0)(x - x_1)\\dots(x - x_n)}\nQuesto risultato è notevole perché fornisce un’espressione esatta per l’errore di interpolazione. Tuttavia, il punto \\alpha(x) è generalmente sconosciuto. Questo implica che, per rendere operativa questa formula, spesso si passa a una maggiorazione dell’errore, utilizzando il massimo valore assoluto della derivata (n+1)-esima nell’intervallo I.\nÈ importante notare che, se x coincide con uno dei nodi di interpolazione x_i, allora w_{n+1}(x_i) = 0, e di conseguenza l’errore e_n(f(x_i)) = 0. Questo conferma che il polinomio interpolatore passa esattamente per i punti dati.\nReferences\nAppunti Mate Num-lez11.pdf\n2025-03-20 10:39\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nmateNum- Lez12\nErrore del Polinomio di Interpolazione di Lagrange\nIntroduzione\nIl professore ha ripreso la lezione precedente, spostando l’attenzione dall’approssimazione della soluzione di sistemi di equazioni lineari all’approssimazione di una funzione continua f o di un insieme di dati. In particolare, la discussione è iniziata con la distinzione tra interpolazione e minimi quadrati, focalizzandosi inizialmente sull’interpolazione.\nÈ stata ricordata l’esistenza e l’unicità del polinomio di interpolazione di Lagrange. Successivamente, l’attenzione si è spostata sull’analisi dell’errore di interpolazione, introducendo un teorema a riguardo.\nTeorema sull’Errore di Interpolazione\nTeorema: Sia f \\in C^{n+1}([x_0, x_n]) e sia p_n(x) il polinomio di interpolazione di Lagrange di grado al più n che interpola f nei nodi x_0, x_1, \\dots, x_n. Allora, per ogni x \\in [x_0, x_n], esiste un punto \\alpha(x) \\in (x_0, x_n) tale che l’errore di interpolazione è dato da: f(x) - p_n(x) = \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} \\omega_{n+1}(x) dove \\omega_{n+1}(x) è il polinomio di grado n+1 definito come: \\omega_{n+1}(x) = \\prod_{k=0}^{n} (x - x_k) Questa stima dell’errore è valida quando si interpola una funzione f e non un semplice insieme di dati. L’ipotesi fondamentale per questo risultato è la regolarità della funzione f, che deve essere C^{n+1}.\nÈ importante notare che, per definizione di interpolazione, l’errore calcolato in corrispondenza dei nodi x_i è zero, poiché \\omega_{n+1}(x_i) = 0 per i = 0, \\dots, n.\nDimostrazione del Teorema\nPer dimostrare il teorema, è stata introdotta una funzione ausiliaria della variabile indipendente t, chiamata g(t): g(t) = f(t) - p_n(t) - W \\omega_{n+1}(t) dove W è una costante definita in modo tale che g(x) = 0 per un fissato x \\neq x_i con i = 0, \\dots, n. Esplicitamente, scegliendo W come: W = \\frac{f(x) - p_n(x)}{\\omega_{n+1}(x)} si ottiene g(x) = f(x) - p_n(x) - \\frac{f(x) - p_n(x)}{\\omega_{n+1}(x)} \\omega_{n+1}(x) = 0.\nRegolarità della Funzione Ausiliaria g(t)\nLa funzione g(t) è definita sull’intervallo I_x = [\\min(x_0, \\dots, x_n, x), \\max(x_0, \\dots, x_n, x)]. La regolarità di g(t) dipende dalla regolarità di f(t) e di p_n(t) e \\omega_{n+1}(t). Sappiamo che f \\in C^{n+1}(I_x), p_n(t) è un polinomio di grado al più n (quindi C^\\infty), e \\omega_{n+1}(t) è un polinomio di grado n+1 (anch’esso C^\\infty)?. Pertanto, g(t) \\in C^{n+1}(I_x).\nZeri della Funzione Ausiliaria g(t)\nLa funzione g(t) si annulla nei nodi di interpolazione x_0, x_1, \\dots, x_n perché f(x_i) - p_n(x_i) = 0 (per definizione di interpolazione) e \\omega_{n+1}(x_i) = 0. Inoltre, per come è stata definita la costante W, abbiamo anche g(x) = 0. Quindi, g(t) ha almeno n+2 zeri distinti in I_x.?\nApplicazione del Teorema di Rolle?\nApplicando ripetutamente il Teorema di Rolle, possiamo dedurre che:\n\ng&#039;(t) ha almeno n+1 zeri distinti in I_x.\ng&#039;&#039;(t) ha almeno n zeri distinti in I_x.\n…\ng^{(n+1)}(t) ha almeno 1 zero in I_x. Sia questo zero \\alpha(x).\n\nCalcolo della Derivata (n+1)-esima di g(t)\nCalcoliamo la derivata (n+1)-esima di g(t): g^{(n+1)}(t) = \\frac{d^{n+1}}{dt^{n+1}} (f(t) - p_n(t) - W \\omega_{n+1}(t)) Poiché p_n(t) è un polinomio di grado al più n, la sua derivata (n+1)-esima è zero: \\frac{d^{n+1}}{dt^{n+1}} p_n(t) = 0. La derivata (n+1)-esima di \\omega_{n+1}(t) = (t - x_0)(t - x_1)\\cdots(t - x_n) è (n+1)!. Questo risultato può essere dimostrato per induzione, osservando che la derivata prima è una somma di prodotti di n termini (t-x_i), la derivata seconda sarà una somma di prodotti di n-1 termini, e così via. La derivata n-esima sarà una somma di termini costanti, e la derivata (n+1)-esima sarà una costante data da (n+1)!.\nQuindi, la derivata (n+1)-esima di g(t) è: g^{(n+1)}(t) = f^{(n+1)}(t) - 0 - W (n+1)! = f^{(n+1)}(t) - W (n+1)!\nDerivazione della Formula dell’Errore?\nSappiamo che esiste un punto \\alpha(x) \\in (x_0, x_n) tale che g^{(n+1)}(\\alpha(x)) = 0. Quindi: f^{(n+1)}(\\alpha(x)) - W (n+1)! = 0 Da cui ricaviamo la costante W: W = \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} Sostituendo questa espressione di W nella definizione di W data in precedenza: \\frac{f(x) - p_n(x)}{\\omega_{n+1}(x)} = \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} otteniamo la formula per l’errore di interpolazione: f(x) - p_n(x) = \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} \\omega_{n+1}(x) Questo completa la dimostrazione.\nOsservazione sulla Struttura dell’Errore e Relazione con Taylor\nIl professore ha sottolineato come la struttura dell’errore di interpolazione sia simile alla struttura del termine di resto della formula di Taylor. Infatti, entrambe presentano una derivata di ordine (n+1), il fattoriale (n+1)! a denominatore e un termine che dipende dalla distanza dal punto di espansione (nel caso di Taylor) o dai nodi di interpolazione (nel nostro caso, \\omega_{n+1}(x) è un polinomio di grado n+1 con radici nei nodi). Esiste una dimostrazione di questo risultato che utilizza proprio il teorema di Taylor, anche se quella presentata si basa sul teorema di Rolle.\nStima dell’Errore: Passaggio alla Norma Infinito\nLa formula esatta per l’errore contiene \\alpha(x), un punto la cui esatta posizione nell’intervallo [x_0, x_n] è generalmente sconosciuta. Per ottenere una stima dell’errore che sia computabile, si passa spesso a considerare una maggiorazione utilizzando la norma infinito.\nLa norma infinito di una funzione h(x) su un intervallo I è definita come: ||h||_{\\infty, I} = \\max_{x \\in I} |h(x)| Applicando la norma infinito all’errore di interpolazione sull’intervallo I_x = [\\min(x_0, \\dots, x_n), \\max(x_0, \\dots, x_n)], otteniamo: ||f - p_n||_{\\infty, I_x} = \\max_{x \\in I_x} |f(x) - p_n(x)| = \\max_{x \\in I_x} \\left| \\frac{f^{(n+1)}(\\alpha(x))}{(n+1)!} \\omega_{n+1}(x) \\right| Poiché \\alpha(x) \\in (x_0, x_n) \\subseteq I_x, possiamo maggiorare il termine contenente la derivata (n+1)-esima: ||f - p_n||_{\\infty, I_x} \\leq \\frac{1}{(n+1)!} \\max_{x \\in I_x} |f^{(n+1)}(\\alpha(x))| \\cdot \\max_{x \\in I_x} |\\omega_{n+1}(x)| \\Rightarrow ||f - p_n||_{\\infty, I_x} \\leq \\frac{1}{(n+1)!} ||f^{(n+1)}||_{\\infty, I_x} \\cdot ||\\omega_{n+1}||_{\\infty, I_x} Questa stima fornisce un controllo dall’alto sull’errore di interpolazione e dipende sia dalla funzione f (attraverso la norma infinito della sua derivata (n+1)-esima) che dalla scelta dei nodi di interpolazione (attraverso la norma infinito di \\omega_{n+1}(x)).\nCaso di Nodi di Interpolazione Uniformi\nConsideriamo ora il caso in cui i nodi di interpolazione x_0, x_1, \\dots, x_n sono distribuiti uniformemente nell’intervallo [x_0, x_n].\nDefinizione di Nodi Uniformi e Passo Costante\nSe la distribuzione dei nodi è uniforme, la distanza tra due nodi consecutivi è costante. Definiamo il passo di discretizzazione h come: h = \\frac{x_n - x_0}{n} Il passo h rappresenta l’ampiezza di ciascuno degli n sottointervalli in cui [x_0, x_n] è diviso dai nodi.\nEspressioni per i Nodi Uniformi\nCi sono due modi equivalenti per esprimere i nodi uniformi:\n\nRicorsivamente: x_{k+1} = x_k + h, \\quad \\text{per } k = 0, 1, \\dots, n-1 dove x_0 è il primo nodo.\nDirettamente: x_{k} = x_0 + k h, \\quad \\text{per } k = 0, 1, \\dots, n\n\nMaggiorazione di ||\\omega_{n+1}||_{\\infty, I_x} per Nodi Uniformi\nNel caso di nodi uniformi, si può dimostrare (anche se la dimostrazione non è fornita nel testo) che il massimo del valore assoluto di \\omega_{n+1}(x) sull’intervallo [x_0, x_n] può essere maggiorato come: ||\\omega_{n+1}||_{\\infty, [x_0, x_n]} \\leq \\frac{h^{n+1} n!}{4} È importante notare che questa stima non dipende da x grazie all’uniformità del passo.\nStima dell’Errore con Nodi Uniformi\nUtilizzando la maggiorazione di ||\\omega_{n+1}||_{\\infty, [x_0, x_n]}, possiamo riscrivere la stima per la norma infinito dell’errore nel caso di nodi uniformi: ||f - p_n||_{\\infty, [x_0, x_n]} \\leq \\frac{1}{(n+1)!} ||f^{(n+1)}||_{\\infty, [x_0, x_n]} \\cdot \\frac{h^{n+1} n!}{4} Semplificando il termine con i fattoriali ((n+1)! = (n+1) \\cdot n!), otteniamo: ||f - p_n||_{\\infty, [x_0, x_n]} \\leq \\frac{h^{n+1}}{4 (n+1)} ||f^{(n+1)}||_{\\infty, [x_0, x_n]} Questa stima sarà utilizzata in seguito.\nComportamento dell’Errore al Crescere di n\nConsideriamo ora cosa succede all’errore quando aumentiamo il numero di nodi di interpolazione n, mantenendo fisso l’intervallo [x_0, x_n]. In questo caso, il passo h = \\frac{x_n - x_0}{n} tende a zero quando n \\rightarrow \\infty.\nLa stima dell’errore con nodi uniformi può essere vista come il prodotto di due “blocchi”:\n\nBlocco A: \\frac{h^{n+1}}{4 (n+1)} che dipende dalla scelta dei nodi (in particolare dal numero di nodi n). Poiché h \\rightarrow 0 al crescere di n, questo blocco tende a zero per n \\rightarrow \\infty.\nBlocco B: ||f^{(n+1)}||_{\\infty, [x_0, x_n]} che dipende dalla funzione f e dalle sue derivate di ordine elevato. Il comportamento di questo blocco al crescere di n dipende fortemente dalla natura della funzione f.\n\nIdealmente, ci si aspetterebbe che l’errore tenda a zero quando n \\rightarrow \\infty, poiché un numero maggiore di informazioni sulla funzione dovrebbe portare a un’approssimazione migliore. Tuttavia, questo non è sempre garantito.\nPossono verificarsi diversi scenari per il blocco B al tendere di n all’infinito:\n\n||f^{(n+1)}||_{\\infty, [x_0, x_n]} converge a una costante. In questo caso, l’errore complessivo tende a zero perché il blocco A tende a zero.\n||f^{(n+1)}||_{\\infty, [x_0, x_n]} tende a zero. Anche in questo caso, l’errore complessivo tende a zero.\n||f^{(n+1)}||_{\\infty, [x_0, x_n]} tende a più infinito. In questo caso, il comportamento dell’errore complessivo dipende dalla velocità con cui il blocco A tende a zero rispetto alla velocità con cui il blocco B tende a infinito. Se il blocco A converge a zero più rapidamente di quanto il blocco B diverga, l’errore può ancora tendere a zero. Altrimenti, l’errore può divergere.\n\nFenomeno di Runge\nEsistono casi in cui, nonostante l’aumento del numero di nodi, l’errore di interpolazione non diminuisce e, anzi, può addirittura aumentare, specialmente agli estremi dell’intervallo. Questo fenomeno è noto come Fenomeno di Runge.\nUn esempio classico in cui si manifesta il Fenomeno di Runge è la funzione: f(x) = \\frac{1}{1 + x^2} sull’intervallo [-5, 5]. Questa funzione è analitica e apparentemente “ben comportata”.\nTuttavia, se si utilizzano nodi di interpolazione uniformi e si aumenta il numero di nodi, il polinomio interpolante p_n(x) converge bene verso f(x) nella parte centrale dell’intervallo [-5, 5], ma agli estremi si sviluppano oscillazioni spurie sempre più ampie. Queste oscillazioni non rappresentano il comportamento della funzione originale e peggiorano all’aumentare di n, portando a un aumento dell’errore agli estremi.\n\nAnalisi dei Blocchi A e B per la Funzione di Runge\nConsiderando la funzione di Runge, si osserva il seguente comportamento qualitativo per piccoli valori di n:\n\nBlocco A (\\frac{h^{n+1}}{4 (n+1)}): Diminuisce rapidamente all’aumentare di n. Ad esempio, si è visto che l’ordine di grandezza passa da O(10^1) per n=3 a O(10^{-10}) per n=21.\nBlocco B (||f^{(n+1)}||_{\\infty, [-5, 5]}): Aumenta molto rapidamente all’aumentare di n. Ad esempio, si è visto che l’ordine di grandezza passa da O(10^0) per n=3 a O(10^{19}) per n=21.\n\n\nIl prodotto di questi due blocchi determina il comportamento dell’errore. Nel caso della funzione di Runge con nodi uniformi, la crescita del blocco B prevale sulla diminuzione del blocco A per valori di x vicini agli estremi dell’intervallo, causando il fenomeno delle oscillazioni spurie e la mancata convergenza (anzi, la divergenza) del polinomio interpolante verso la funzione f(x) in quelle regioni.\nDefinizione del Fenomeno di Runge\nIl Fenomeno di Runge è la manifestazione di oscillazioni spurie agli estremi del dominio di interpolazione al crescere del numero dei nodi di interpolazione, specialmente quando si utilizzano nodi uniformi.\n\nNodi di Chebyshev-Gauss-Lobatto e il Fenomeno di Runge\nIl Problema: Oscillazioni nell’Interpolazione con Nodi Equispaziati (Fenomeno di Runge)\nIl problema discusso riguarda le oscillazioni che si verificano quando si approssima una funzione mediante un polinomio interpolante costruito su nodi equispaziati, specialmente verso i bordi dell’intervallo di interpolazione. Questo fenomeno è noto come fenomeno di Runge. Il professore introduce questo problema come motivazione per esplorare strategie di scelta dei nodi di interpolazione più efficaci.\nUna Possibile Soluzione: Nodi Non Uniformi\nUna strategia per mitigare il fenomeno di Runge consiste nell’utilizzare nodi di interpolazione non uniformemente distribuiti sull’intervallo. L’idea è di addensare i nodi nelle regioni dove la funzione presenta maggiori variazioni o dove le oscillazioni tendono a essere più pronunciate.\nIntroduzione ai Nodi di Chebyshev-Gauss-Lobatto (CGL)\nIl professore introduce una famiglia di nodi specifici, noti come nodi di Chebyshev-Gauss-Lobatto (CGL). Questi nodi prendono il nome dalle tre persone che hanno contribuito alla loro definizione: Chebyshev, Gauss e Lobatto. Vengono anche chiamati nodi CGL.\nDefinizione dei Nodi CGL sull’Intervallo di Riferimento [-1, 1]\nI nodi di Chebyshev-Gauss-Lobatto vengono definiti inizialmente sull’intervallo di riferimento [-1, 1]. Questi nodi, indicati con \\tilde x_i, per i che va da 0 a n, sono dati dalla seguente formula:\n\\tilde x_i = -\\cos\\left(\\frac{\\pi i}{n}\\right), \\quad i = 0, 1, \\ldots, n\nDefinizione: La formula sopra definisce gli n+1 nodi di Chebyshev-Gauss-Lobatto sull’intervallo [-1, 1].\nInterpretazione Geometrica dei Nodi CGL\n\nLa costruzione di questi nodi può essere visualizzata considerando la semicirconferenza unitaria di raggio 1 centrata nell’origine.\n\nSi divide la mezza circonferenza in n porzioni uguali.\nSi considerano i punti di divisione sulla semicirconferenza.\nI nodi di Chebyshev-Gauss-Lobatto sull’asse x (l’intervallo [-1, 1]) sono le proiezioni di questi punti sull’asse delle ascisse.\n\nEsempio: Per n = 8, la semicirconferenza viene divisa in otto parti uguali. Le proiezioni dei punti di divisione sull’asse x forniscono i nove nodi CGL (per i = 0, \\ldots, 8).\n\nPer i = 0: \\tilde x_0 = -\\cos(0) = -1.\nPer i = 1: \\tilde x_1 = -\\cos(\\frac{\\pi}{8}).\n…\nPer i = 8: \\tilde x_8 = -\\cos(\\pi) = -(-1) = 1.\n\nCome si può notare, i nodi sono più densi agli estremi dell’intervallo [-1, 1] e meno densi nella parte centrale. Questo è dovuto alla natura non lineare della proiezione tramite la funzione coseno.\nMappatura dei Nodi CGL su un Intervallo Generico [a, b] NO\nPoiché l’intervallo di interpolazione di interesse può essere un qualunque intervallo [a, b] della retta reale, è necessario mappare i nodi CGL definiti su [-1, 1] all’intervallo fisico [a, b]. Questa mappatura viene effettuata utilizzando una trasformazione lineare:\nx_i = \\frac{b + a}{2} + \\frac{b - a}{2} \\tilde x_i, \\quad i = 0, 1, \\ldots, n\nDimostrazione della Mappatura: Verifichiamo che questa mappa trasformi correttamente gli estremi e il punto medio dell’intervallo [-1, 1] negli estremi e nel punto medio dell’intervallo [a, b].\n\nSe \\tilde x_i = -1: x_i = \\frac{b + a}{2} + \\frac{b - a}{2} (-1) = \\frac{b + a - b + a}{2} = \\frac{2a}{2} = a Quindi, -1 viene mappato in a.\nSe \\tilde x_i = 1: x_i = \\frac{b + a}{2} + \\frac{b - a}{2} (1) = \\frac{b + a + b - a}{2} = \\frac{2b}{2} = b Quindi, 1 viene mappato in b.\nSe \\tilde x_i = 0: x_i = \\frac{b + a}{2} + \\frac{b - a}{2} (0) = \\frac{b + a}{2} Quindi, 0 (il punto medio di [-1, 1]) viene mappato in \\frac{b + a}{2} (il punto medio di [a, b]).\n\nQuesta mappatura trasferisce la distribuzione non uniforme dei nodi dall’intervallo di riferimento [-1, 1] all’intervallo fisico [a, b], mantenendo la proprietà di maggiore densità agli estremi.\nEffetto dei Nodi CGL sul Fenomeno di Runge\n\nQuando si utilizza lo stesso numero di nodi, ma distribuiti secondo la formula dei nodi CGL, per interpolare la funzione f(x) = \\frac{1}{1 + x^2}, si osserva un comportamento significativamente diverso rispetto all’utilizzo di nodi equispaziati.\n\nLa funzione approssimata inizia ancora ad oscillare, ma le oscillazioni sono più contenute.\nLe oscillazioni più grandi si trovano nella parte centrale dell’intervallo, mentre diminuiscono man mano che ci si avvicina agli estremi.\n\nTeorema (Convergenza con Nodi CGL): Per n \\to \\infty, l’errore di interpolazione E_n(f) = |f - p_n|_\\infty, dove p_n è il polinomio interpolante di grado n costruito sui nodi CGL, tende a 0 anche per funzioni meno regolari rispetto a quanto richiesto per la convergenza con nodi uniformi. In particolare, la convergenza si verifica anche se la funzione f è solamente di classe C^1. Questo è un risultato notevole, in quanto con nodi uniformi si richiederebbe una regolarità C^{n+1} per garantire la convergenza al crescere di n.\nIntroduzione ai Nodi di Chebyshev-Gauss (CG)\nIl professore introduce anche un’altra famiglia di nodi strettamente legata ai nodi CGL, chiamati nodi di Chebyshev-Gauss (CG). La principale differenza è che i nodi CG non includono gli estremi dell’intervallo, ma sono tutti nodi interni.\nDefinizione dei Nodi CG sull’Intervallo di Riferimento [-1, 1]\nI nodi di Chebyshev-Gauss, indicati con x_i^*, per i che va da 0 a n, sull’intervallo [-1, 1] sono definiti come:\nx_i^* = -\\cos\\left(\\frac{(2i + 1)\\pi}{2(n + 1)}\\right), \\quad i = 0, 1, \\ldots, n\nDefinizione: La formula sopra definisce gli n+1 nodi di Chebyshev-Gauss sull’intervallo [-1, 1].\nEsempio: Per n = 8, i nodi CG saranno:\n\nx_0^* = -\\cos\\left(\\frac{\\pi}{18}\\right)\nx_1^* = -\\cos\\left(\\frac{3\\pi}{18}\\right)\n…\nx_8^* = -\\cos\\left(\\frac{17\\pi}{18}\\right)\n\nCome si può osservare, per i = 0, l’argomento del coseno è \\frac{\\pi}{2(n+1)} \\neq 0, e per i = n, l’argomento è \\frac{(2n+1)\\pi}{2(n+1)} = \\pi - \\frac{\\pi}{2(n+1)} \\neq \\pi. Di conseguenza, i nodi x_0 e x_n non coincidono con -1 e 1 rispettivamente, ma sono interni all’intervallo [-1, 1].\nAnche i nodi CG possono essere mappati su un intervallo generico [a, b] utilizzando la stessa trasformazione lineare.\nProprietà dei Nodi CG: Anche i nodi CG godono di simili proprietà di convergenza ai nodi CGL. L’errore di interpolazione tende a zero al crescere di n, anche per funzioni con una regolarità minima.\nMotivazione per l’Uso dei Nodi CG\nIn alcune applicazioni, può essere inutile o indesiderabile includere i bordi dell’intervallo nei punti di interpolazione. Utilizzando i nodi CG, si ottiene un campionamento più fitto all’interno del dominio, il che può essere vantaggioso in certi contesti.\nLimiti dei Nodi di Chebyshev (CGL e CG)\nUn limite di questi approcci basati sui nodi di Chebyshev è che i punti di interpolazione sono predeterminati e non possono essere scelti arbitrariamente. Questo può rappresentare un problema quando si ha a che fare con l’approssimazione di dati sperimentali, dove i punti di misurazione sono fissati e non necessariamente coincidono con i nodi di Chebyshev. In questi casi, potrebbe essere necessario ricorrere a tecniche di approssimazione diverse dall’interpolazione polinomiale su nodi fissi. Il professore accenna al fatto che questa limitazione motiva la ricerca di approcci differenti per l’approssimazione, specialmente nel contesto dell’approssimazione di dati.\n\nInterpolazione Lineare a Tratti\nProblemi con l’Interpolazione Globale e Nodi Uniformi\nInizialmente, si era partiti con un approccio ottimistico all’interpolazione. Tuttavia, sorgono delle problematiche quando si considerano i dati ottenuti, specialmente se questi non corrispondono esattamente agli istanti desiderati per la misurazione. Se i dati sono già raccolti, è necessario avere la fortuna che questi siano stati campionati esattamente nei nodi scelti, altrimenti non possono essere direttamente utilizzati. Questo vincola la scelta dei nodi, che non possono più essere scelti liberamente.\nUtilizzare nodi uniformemente distribuiti si è rivelato problematico. Anche l’intervallo considerato inizialmente piccolo non risolve il problema per intervalli più ampi.\nUn altro fattore critico è il grado del polinomio interpolante. Con un numero elevato di nodi nell’interpolazione globale, si è portati inevitabilmente a utilizzare polinomi di alto grado. I polinomi di alto grado tendono ad avere un andamento oscillatorio, intersecando l’asse delle ascisse più volte.\nPassaggio all’Interpolazione Polinomiale Locale: L’Interpolazione a Tratti\n\nPer superare i limiti dell’interpolazione globale con molti nodi e grado elevato, si introduce l’idea di interpolazione polinomiale locale. Invece di considerare tutti i nodi contemporaneamente, li si considera a piccoli gruppi.\nLa forma più semplice di interpolazione locale consiste nel prendere i nodi a coppie consecutive e interpolare i dati corrispondenti con una retta. Questo porta alla creazione di una spezzata, formata da segmenti di retta che connettono i punti dati. Questa tecnica è nota come interpolazione lineare a tratti.\nDefinizione (Interpolazione Lineare a Tratti): L’interpolazione lineare a tratti consiste nell’approssimare una funzione f(x) su un intervallo [x_0, x_n] mediante una funzione continua formata da segmenti di retta che interpolano i dati (x_i, f(x_i)) in nodi consecutivi x_i e x_{i+1} per i = 0, 1, \\ldots, n-1.\nRappresentazione Grafica: Consideriamo una funzione con alcuni nodi x_0, x_1, x_2, x_3.\n\nApprossimazione Globale: Un polinomio di grado 3 che interpola tutti e quattro i nodi potrebbe avere un andamento oscillatorio tra i nodi.\nApprossimazione a Tratti (Lineare): Si congiungono i punti (x_0, f(x_0)) e (x_1, f(x_1)) con una retta, poi (x_1, f(x_1)) e (x_2, f(x_2)) con un’altra retta, e così via. Questo produce una spezzata che segue l’andamento dei dati in modo più locale.\n\nVantaggi dell’Interpolazione a Tratti:\n\nSe si infittiscono i dati (si aggiungono più nodi), l’approssimazione migliora. La spezzata si avvicina sempre più alla funzione originale.\nNon si introducono oscillazioni indesiderate tra i nodi, a differenza dei polinomi di alto grado.\n\nOltre all’interpolazione lineare a tratti, si possono utilizzare anche interpolazioni quadratiche a tratti e cubiche a tratti, unendo segmenti di parabole o cubiche tra gruppi di nodi. Tuttavia, raramente si utilizzano gradi superiori a 3 per evitare problemi simili al fenomeno di Runge su intervalli più piccoli.\nFormalizzazione dell’Interpolazione Lineare a Tratti\nSia dato un insieme di n+1 nodi x_0 &lt; x_1 &lt; \\ldots &lt; x_n nell’intervallo [a, b] (dove a = x_0 e b = x_n). I nodi non devono necessariamente essere uniformemente distribuiti.\nSi definisce l’intervallino i-esimo come I_i = [x_i, x_{i+1}] per i = 0, 1, \\ldots, n-1.\nL’ampiezza dell’intervallino i-esimo è h_i = x_{i+1} - x_i.\nL’ampiezza massima dei sottointervalli è h = \\max_{i} {h_i}.\nIl polinomio lineare a tratti che interpola la funzione f(x) nei nodi x_i è denotato come \\pi_{1}^hf(x).\nProprietà di \\pi_{1}^hf(x):\n\n\\pi_{1}^hf(x) è una funzione continua sull’intervallo [x_0, x_n].\nLa restrizione di \\pi_{1}^hf(x) al generico intervallo I_i = [x_i, x_{i+1}] è un polinomio di grado 1.\n\\pi_{1}^hf(x) soddisfa le condizioni di interpolazione: P_{1,h}f(x_i) = f(x_i) per i = 0, 1, \\ldots, n.\n\nEspressione del Polinomio Lineare a Tratti su un Intervallo:\nLa restrizione di \\pi_{1}^hf(x) all’intervallo I_i = [x_i, x_{i+1}] è la retta che interpola i punti (x_i, f(x_i)) e (x_{i+1}, f(x_{i+1})). La sua espressione è data da:\n\\pi_{1}^hf(x)|_{I_i} = f(x_i) + \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i} (x - x_i)\nVerifica dell’Interpolazione:\n\n?Se x = x_i: P_{1,h}f(x_i)|_{I_i} = f(x_i) + \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i} (x_i - x_i) = f(x_i) + 0 = f(x_i)\nSe x = x_{i+1}: P_{1,h}f(x_{i+1})|_{I_i} = f(x_i) + \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i} (x_{i+1} - x_i) = f(x_i) + f(x_{i+1}) - f(x_i) = f(x_{i+1}) L’interpolazione è quindi verificata.\n\nErrore dell’Interpolazione Lineare a Tratti\nSi vuole verificare che, aumentando il numero di nodi (e quindi facendo tendere a zero l’ampiezza massima h), l’errore dell’interpolazione lineare a tratti tende a zero.\nConsideriamo l’errore sull’intervallino I_i: |f(x) - \\pi_{1}^hf(x)| per x \\in I_i. Poiché sull’intervallo I_i si utilizzano solo due nodi (gli estremi), si può riciclare la stima dell’errore per l’interpolazione con due nodi uniformi. In questo caso, n+1 = 2, quindi n=1. La formula dell’errore per nodi uniformi (non esplicitata nel testo ma richiamata) suggerisce una dipendenza da h^{n+1} = h^2 e dalla derivata di ordine n+1 = 2 della funzione.\nStima dell’Errore Locale:\nAssumendo che f \\in C^2([x_0, x_n]), l’errore sull’intervallino I_i può essere maggiorato come:\n\\max_{x \\in I_i} |f(x) - \\pi_{1}^hf(x)| \\le \\frac{h_i^2}{8} \\max_{x \\in I_i} |f&#039;&#039;(x)| Questa stima si basa sull’errore di interpolazione di Lagrange per due punti.\nStima dell’Errore Globale:\nPer ottenere una stima dell’errore su tutto l’intervallo [x_0, x_n], si considera il massimo dell’errore locale su tutti gli intervallini:\n\\max_{x \\in [x_0, x_n]} |f(x) - \\pi_{1}^hf(x)| = \\max_{i} \\left( \\max_{x \\in I_i} |f(x) - \\pi_{1}^hf(x)| \\right)\nUtilizzando la stima locale e maggiorando h_i con h = \\max_{i} {h_i} e \\max_{x \\in I_i} |f&#039;&#039;(x)| con \\max_{x \\in [x_0, x_n]} |f&#039;&#039;(x)|, si ottiene:\n\\max_{x \\in [x_0, x_n]} |f(x) - \\pi_{1}^hf(x)| \\le \\frac{h^2}{8} \\max_{x \\in [x_0, x_n]} |f&#039;&#039;(x)|\nAnalisi della Convergenza:\nIn questa stima dell’errore globale, il termine \\max_{x \\in [x_0, x_n]} |f&#039;&#039;(x)| è una costante (blocco B) che dipende dalla funzione f e dall’intervallo [x_0, x_n]. Il termine h^2 (blocco A) dipende dall’ampiezza massima degli intervallini.\nAl contrario dell’interpolazione globale dove, aumentando il grado del polinomio (e quindi potenzialmente il numero di nodi), il comportamento del termine analogo a B poteva portare a divergenza (fenomeno di Runge), qui il termine \\max |f&#039;&#039;(x)| rimane costante.\nQuando si infittiscono i nodi, l’ampiezza massima h tende a zero. Di conseguenza, anche h^2 tende a zero. Pertanto, l’errore dell’interpolazione lineare a tratti:\n\\lim_{h \\to 0} \\max_{x \\in [x_0, x_n]} |f(x) - \\pi_{1}^hf(x)| = 0\nQuesto dimostra che l’interpolazione lineare a tratti converge alla funzione f(x) quando il numero di nodi aumenta (ovvero, quando h diminuisce), a condizione che la funzione f sia sufficientemente regolare (f \\in C^2). Questo approccio risolve il problema del fenomeno di Runge riscontrato con l’interpolazione globale.\nSi può quindi affermare che l’interpolazione lineare a tratti è una soluzione al fenomeno di Runge.\nSi accenna infine che per approssimazioni più accurate, si possono utilizzare interpolazioni a tratti di grado superiore (quadratiche, cubiche) con nodi scelti in modo intelligente (non necessariamente uniformi), come fa ad esempio MATLAB.\nReferences\nAppunti Mate Num-lez12.pdf\n2025-03-18 11:08\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine. matematica numerica\nmateNum- Lez13\nApprossimazione di Dati e Funzioni: Interpolazione a Tratti\nInterpolazione Lineare a Tratti\nLa professoressa ha introdotto l’interpolazione a tratti come una delle possibili soluzioni al fenomeno di Runge. Nello specifico, si è inizialmente concentrata sull’interpolazione lineare a tratti.\nDefinizione\nL’interpolazione lineare a tratti consiste nel congiungere coppie di punti (x_i, y_i) con segmenti di retta. Invece di utilizzare un unico polinomio di alto grado per interpolare tutti i punti, si utilizzano polinomi di grado uno (rette) su ciascun intervallo [x_i, x_{i+1}] definito dai nodi di interpolazione.\nStima dell’Errore\nLa professoressa ha ricordato che era stata ricavata una stima dell’errore per l’interpolazione lineare a tratti. Questa stima presentava una struttura simile a quella con nodi uniformi, con un blocco A e un blocco B.\n\nBlocco A: Era legato alla distanza tra i nodi, tipicamente rappresentata da H (o h per la massima ampiezza degli intervalli), e continuava a tendere a zero all’aumentare del campionamento.\nBlocco B: La novità principale rispetto al caso con nodi uniformi era che il blocco B, invece di avere un andamento asintotico, diventava una costante.\n\nQuesta caratteristica garantiva che il prodotto dei due blocchi (e quindi l’errore) convergesse a zero all’aumentare del campionamento, indipendentemente dal valore della costante nel blocco B.\nComando MATLAB interp1\nLa professoressa ha introdotto il comando MATLAB interp1 come strumento builtin per realizzare l’interpolazione lineare a tratti, in vista del laboratorio.\nSintassi Minimale\nLa sintassi base del comando interp1 prevede tre parametri di input:\ninterp1(X, Y, Z)\n\nDove:\n\nX: è il vettore che raccoglie i nodi di interpolazione x_i.\nY: è il vettore che raccoglie i dati da interpolare, ovvero i valori della funzione nei nodi f(x_i) o i dati misurati.\nZ: è un numero reale o un insieme di numeri reali (un vettore di dimensione S) in corrispondenza dei quali si vuole valutare il polinomio di interpolazione lineare a tratti.\n\nFunzionalità\nLa professoressa ha spiegato che interp1 può essere visto come un “merging” dei comandi polyfit e polyval utilizzati per il polinomio di Lagrange.\n\nMentre polyfit costruiva il polinomio e polyval lo valutava, interp1 costruisce e valuta direttamente l’interpolante lineare a tratti, che è concettualmente semplice essendo un’unione continua di segmenti di retta. Per questo motivo, non è necessario ottenere un’espressione esplicita del polinomio.\n\nOutput\nL’output del comando interp1 è un oggetto (che la professoressa aveva forse chiamato pif) che avrà la stessa dimensionalità di Z. Se Z è un punto, l’output sarà il valore di pif in quel punto; se Z è un vettore, l’output sarà un vettore dei valori di pif nei punti di Z.\nMiglioramento dell’Approssimazione e Scelta Adattativa dei Nodi\nLa professoressa ha sottolineato come l’interpolazione lineare a tratti, pur essendo un’approssimazione “grezza”, funzioni estremamente bene. L’aggiunta di punti nelle zone del dominio dove mancano informazioni porta a un miglioramento dell’approssimazione, come ci si aspetta.\nComando plot in MATLAB e Nodi Adattativi\nÈ stato evidenziato che il comando plot in MATLAB, quando viene utilizzato per disegnare il grafico di una funzione, in realtà si appoggia a un polinomio di interpolazione lineare a tratti. Il campionamento utilizzato è così fitto che la natura “spezzata” della curva non è percepibile a occhio nudo, ma diventa visibile soloZoomando ripetutamente.\nMATLAB utilizza una scelta adattativa dei nodi per il comando plot.\nScelta Adattativa\nUna scelta adattativa dei nodi significa che i nodi di interpolazione vengono posizionati in modo da adattarsi alla funzione.\n\nNelle regioni del dominio in cui la funzione è piatta (con variazioni contenute), viene utilizzato un campionamento lasco (pochi nodi).\nNelle regioni in cui la funzione presenta gradienti più significativi e una maggiore dinamica (come nel caso di uno shock in propagazione), il campionamento viene intensificato (più nodi).\n\nQuesto approccio è ottimale per gestire le informazioni, concentrando i punti dove la funzione ha un comportamento più complesso da descrivere (variazioni rapide, derivate elevate). La scelta adattativa dei nodi si basa sull’analisi dell’andamento della funzione, considerando le derivate prime e seconde (e in più dimensioni l’Hessiana). Dove queste assumono valori elevati, vengono inseriti più nodi.\nGeneralizzazione a Griglie di Calcolo Adattate\n\nLa professoressa ha menzionato come la scelta adattativa dei nodi sia la base per la costruzione di griglie di calcolo adattate in dimensioni superiori (2D e 3D), un argomento di cui si occupa nella sua ricerca.\n\nIn 2D, anziché dividere un intervallo in sottointervalli, si “tassella” il dominio con quadrati o triangoli (questi ultimi più avanzati, tipici del metodo degli elementi finiti).\nIn 3D, le tessere diventano cubi o piramidi.\n\nL’obiettivo delle griglie adattate è sempre lo stesso: ottenere calcoli accurati a basso costo, concentrando la risoluzione (elementi più piccoli) nelle zone di maggiore interesse o dove la soluzione presenta maggiori variazioni.\nInterpolazione Quadratica a Tratti\nSuccessivamente, la professoressa ha considerato l’ipotesi di unire non più tratti di retta, ma tratti di parabola.\nDefinizione\n\nIn questo caso, i nodi iniziali vengono raggruppati a tre a tre. Su ogni tripletta di nodi (x_i, x_{i+1}, x_{i+2}) viene costruito un polinomio di grado due (parabola) che interpola la funzione in quei tre punti. Questo processo viene ripetuto per le triple successive di nodi.\nVantaggi Potenziali\nUnire pezzi di parabola anziché pezzi di retta può potenzialmente portare a una maggiore accuratezza. Aumentando localmente il numero di informazioni (tre punti per intervallo anziché due), ci si aspetta un’approssimazione migliore.\nStima dell’Errore Locale\nSupponendo, per semplicità, che i nodi siano equispaziati all’interno di ogni intervallo, la stima dell’errore locale per l’interpolazione quadratica a tratti presenta la seguente forma:\n\\frac{H_i^{n+1}}{4(n+1)!} \\max_{x \\in [x_i, x_{i+n}]} |f^{(n+1)}(x)|\nDove n è il grado del polinomio (in questo caso n=2), e H_i è l’ampiezza dell’intervallo considerato. Quindi, per l’interpolazione quadratica a tratti (n=2), la stima locale dell’errore diventa:\n\\frac{H_i^{3}}{4 \\cdot 3!} \\max_{x \\in [x_i, x_{i+2}]} |f^{(3)}(x)| = \\frac{H_i^{3}}{24} \\max_{x \\in [x_i, x_{i+2}]} |f^{(3)}(x)|\nPassando alla stima globale, si ottiene una dipendenza da h^3 e dalla derivata terza della funzione:\n\\frac{h^3}{12} \\max_{x \\in [a, b]} |f^{(3)}(x)|\nQuesto indica che l’accuratezza dovrebbe migliorare rispetto all’interpolazione lineare a tratti, dove l’errore dipendeva da h^2 e dalla derivata seconda.\nSvantaggi e Limitazioni\nNonostante la maggiore accuratezza potenziale, l’interpolazione quadratica a tratti presenta degli svantaggi:\n\nMaggiore Regolarità Richiesta: La stima dell’errore coinvolge la derivata terza della funzione, il che significa che la funzione deve essere più regolare (almeno tre volte differenziabile) rispetto al caso lineare (due volte differenziabile). Non tutte le funzioni posseggono questa regolarità.\nPossibili Oscillazioni Spurie: Aumentare localmente il grado del polinomio può portare a oscillazioni spurie, simili a quelle osservate nell’interpolazione globale con polinomi di alto grado (fenomeno di Runge). È consigliabile non esagerare troppo con l’aumento locale del grado.\nRegolarità Globale: Anche se si utilizzano parabole, l’interpolazione quadratica a tratti continua a essere generalmente solo C^0 (continua), proprio come l’interpolazione lineare a tratti. I punti di raccordo tra le parabole potrebbero avere derivate prime diverse, rendendo la funzione globalmente non differenziabile.\n\nLa professoressa ha chiarito che l’interpolazione quadratica a tratti è una scelta alternativa all’interpolazione lineare a tratti, con una diversa gestione delle informazioni, e non un suo sostituto diretto.\nSpline Cubiche Interpolatorie\nPer ottenere approssimazioni più regolari globalmente, la professoressa ha introdotto il concetto di spline.\nDefinizione\nUna spline cubica interpolatoria (S_3) è una funzione definita a tratti, ottenuta unendo tratti di cubiche (polinomi di grado 3). Esistono anche spline di grado inferiore, come le spline quadratiche, ma le spline cubiche sono molto utilizzate, ad esempio, nella computer grafica e nel CAD.\nProprietà Fondamentali\n\nInterpolazione: S_3(x_i) = y_i per tutti i nodi x_i.\nRegolarità Globale Elevata: A differenza dell’interpolazione lineare o quadratica a tratti, le spline cubiche interpolatorie sono tipicamente di classe C^2. Questo significa che non solo la funzione è continua, ma lo sono anche la sua derivata prima e la sua derivata seconda. Questa elevata regolarità le rende adatte ad applicazioni dove è richiesta una “morbidezza” (smoothness) nelle curve e nelle superfici, come nel design automobilistico, computer grafica e CAD.\n\nCostruzione e Gradi di Libertà\nSu ogni sottointervallo [x_i, x_{i+1}], la spline cubica è un polinomio di grado 3, che ha bisogno di quattro coefficienti per essere definito. Con n sottointervalli, si hanno 4n incognite in totale. Le condizioni di interpolazione nei nodi (2n condizioni), la continuità della funzione nei nodi interni (n-1 condizioni), la continuità della derivata prima nei nodi interni (n-1 condizioni) e la continuità della derivata seconda nei nodi interni (n-1 condizioni) portano a un totale di 4n - 2 condizioni. Per definire la spline in modo univoco, mancano due condizioni aggiuntive, che possono essere scelte in diversi modi (ad esempio, condizioni sui valori della derivata prima o seconda agli estremi dell’intervallo).\nComando MATLAB spline\nMATLAB ha un comando dedicato per la realizzazione delle spline, chiamato spline. La sintassi è esattamente la stessa del comando interp1:\nspline(X, Y, Z)\n\nDove X, Y, e Z hanno lo stesso significato descritto per interp1. Per default, spline implementa la spline cubica, ma potrebbe essere possibile scegliere anche spline di grado diverso.\nApprossimazione delle Derivate con le Spline Cubiche\nUn aspetto interessante delle spline cubiche è che, grazie alla loro elevata regolarità, possono essere utilizzate non solo per approssimare la funzione f(x), ma anche le sue derivate.\n\nLa derivata prima di S_3 (S&#039;_3) può essere utilizzata per approssimare la derivata prima di f (f&#039;(x)).\nLa derivata seconda di S_3 (S&#039;&#039;_3) può essere utilizzata per approssimare la derivata seconda di f (f&#039;&#039;(x)).\n\nL’accuratezza di queste approssimazioni delle derivate è generalmente buona, proprio perché S_3 è un’approssimazione accurata di f.\nStima dell’Errore per le Derivate\nLa professoressa ha fornito una stima dell’errore per l’approssimazione sia della funzione che delle sue derivate tramite la spline cubica e le sue derivate:\n\\max_{x} |f^{(q)}(x) - S_3^{(q)}(x)| \\leq C_q h^{4-q} \\max_{x} |f^{(4)}(x)|\nDove:\n\nq = 0 indica l’approssimazione della funzione stessa (f(x) \\approx S_3(x)). In questo caso, l’ordine di convergenza è h^4.\nq = 1 indica l’approssimazione della derivata prima (f&#039;(x) \\approx S&#039;_3(x)). In questo caso, l’ordine di convergenza è h^3.\nq = 2 indica l’approssimazione della derivata seconda (f&#039;&#039;(x) \\approx S&#039;&#039;_3(x)). In questo caso, l’ordine di convergenza è h^2.\nC_q è una costante che dipende da q.\nh è la massima ampiezza degli intervalli tra i nodi.\n\\max_{x} |f^{(4)}(x)| rappresenta il massimo valore assoluto della derivata quarta di f(x) sull’intervallo considerato.\n\nQuesta stima evidenzia che l’accuratezza dell’approssimazione diminuisce man mano che si considerano derivate di ordine superiore. La spline cubica è “nata” per approssimare f, e derivandola si “spreme” l’approssimazione, ottenendo risultati meno accurati per le derivate successive, ma comunque con un ordine di convergenza che tende a zero con h. La potenza di h (4) è legata al grado locale dell’approssimazione (cubica, n=3), e l’ordine si riduce di uno per ogni derivata considerata.\nStabilità dell’Interpolazione di Lagrange\nIntroduzione al Problema della Stabilità\nQuando si approssimano dati o funzioni, è fondamentale considerare la stabilità dell’approssimazione rispetto a piccole variazioni nei dati. Questo problema è analogo a quanto visto per i sistemi di equazioni lineari, dove il numero di condizionamento indicava come gli errori sui dati si propagavano ai risultati. Anche nell’interpolazione, specialmente quando si tratta di dati misurati e quindi soggetti a errori, è importante capire come le perturbazioni nei dati influenzino l’approssimazione.\nDati Originali e Perturbati\nConsideriamo un insieme di dati originali (x_i, f(x_i)) per i che va da 0 a n, con tutti gli x_i distinti. A questi dati è associato il polinomio di interpolazione di Lagrange P_n f(x).\nSupponiamo ora di avere dei dati perturbati (x_i, \\tilde{f}(x_i)) per gli stessi nodi x_i, dove \\tilde{f}(x_i) rappresenta una perturbazione di f(x_i). Questa perturbazione può essere dovuta all’aritmetica floating point o a errori di misurazione. A questi dati perturbati associamo un altro polinomio di interpolazione, \\tilde{P}_n f(x), che rappresenta una perturbazione del polinomio originale.\nRelazione tra la Perturbazione sui Dati e sul Risultato\nL’obiettivo è comprendere come la perturbazione sui dati, |f(x_i) - \\tilde{f}(x_i)|, sia legata alla perturbazione sul risultato, |P_n f(x) - \\tilde{P}_n f(x)|.\nSi cerca una relazione tra la massima perturbazione sulla soluzione e la massima perturbazione sul dato: \\max_{x \\in I} |P_n f(x) - \\tilde{P}_n f(x)| \\leq C \\cdot \\max_{0 \\leq i \\leq n} |f(x_i) - \\tilde{f}(x_i)| dove C è una costante che quantifica l’amplificazione della perturbazione.\nLa Costante di Lebesgue (\\Lambda_n)\nIl ruolo della costante C è svolto dalla costante di Lebesgue, denotata con \\Lambda_n. Questa costante è definita come: \\Lambda_n = \\max_{x \\in I} \\sum_{i=0}^{n} |l_i(x)| dove l_i(x) sono i polinomi caratteristici di Lagrange (o polinomi elementari di Lagrange). Ricordiamo che l_i(x) è un polinomio di grado n che vale 1 nel nodo x_i e 0 in tutti gli altri nodi x_j per j \\neq i. Il polinomio di interpolazione di Lagrange può essere espresso come: P_n f(x) = \\sum_{i=0}^{n} f(x_i) l_i(x)\nDimostrazione della Relazione\nPartiamo dalle espressioni dei polinomi di interpolazione per i dati originali e perturbati: P_n f(x) = \\sum_{i=0}^{n} f(x_i) l_i(x) \\tilde{P}_n f(x) = \\sum_{i=0}^{n} \\tilde{f}(x_i) l_i(x)\nConsideriamo la differenza tra i due polinomi: P_n f(x) - \\tilde{P}_n f(x) = \\sum_{i=0}^{n} f(x_i) l_i(x) - \\sum_{i=0}^{n} \\tilde{f}(x_i) l_i(x) = \\sum_{i=0}^{n} (f(x_i) - \\tilde{f}(x_i)) l_i(x)\nPassando al valore assoluto: |P_n f(x) - \\tilde{P}_n f(x)| = \\left| \\sum_{i=0}^{n} (f(x_i) - \\tilde{f}(x_i)) l_i(x) \\right|\nUtilizzando la disuguaglianza triangolare: |P_n f(x) - \\tilde{P}_n f(x)| \\leq \\sum_{i=0}^{n} |f(x_i) - \\tilde{f}(x_i)| |l_i(x)|\nPer portare fuori dalla sommatoria la massima perturbazione sui dati, prendiamo il massimo di |f(x_i) - \\tilde{f}(x_i)| per i che va da 0 a n: |P_n f(x) - \\tilde{P}_n f(x)| \\leq \\left( \\max_{0 \\leq i \\leq n} |f(x_i) - \\tilde{f}(x_i)| \\right) \\sum_{i=0}^{n} |l_i(x)|\nInfine, per considerare la massima perturbazione sulla soluzione, prendiamo il massimo su x nell’intervallo di interesse I: \\max_{x \\in I} |P_n f(x) - \\tilde{P}_n f(x)| \\leq \\left( \\max_{0 \\leq i \\leq n} |f(x_i) - \\tilde{f}(x_i)| \\right) \\max_{x \\in I} \\sum_{i=0}^{n} |l_i(x)| \\max_{x \\in I} |P_n f(x) - \\tilde{P}_n f(x)| \\leq \\Lambda_n \\cdot \\max_{0 \\leq i \\leq n} |f(x_i) - \\tilde{f}(x_i)|\nQuesta relazione mostra come la costante di Lebesgue \\Lambda_n amplifichi o controlli la perturbazione sui dati nella soluzione interpolante. Una costante di Lebesgue elevata indica una maggiore sensibilità dell’interpolazione a piccole variazioni nei dati, quindi una minore stabilità.\nComportamento della Costante di Lebesgue al Crescere di n\nPer un numero crescente di nodi (n \\rightarrow \\infty), la costante di Lebesgue generalmente tende all’infinito: \\lim_{n \\to \\infty} \\Lambda_n = \\infty Questo significa che, aumentando il grado del polinomio interpolante globale, la stabilità rispetto alle perturbazioni sui dati peggiora.\nTuttavia, la velocità con cui \\Lambda_n diverge dipende dalla scelta dei nodi di interpolazione.\nNodi Equispaziati\nSe si utilizzano nodi equispaziati, la costante di Lebesgue ha un andamento asintotico di tipo esponenziale con n: \\Lambda_n \\sim 2^n Questo comportamento è legato al fenomeno di Runge, dove per nodi equispaziati un polinomio di grado elevato può presentare forti oscillazioni tra i punti di interpolazione, soprattutto vicino agli estremi dell’intervallo. Questa scelta di nodi, sebbene semplice, porta a problemi sia di convergenza (richiedendo funzioni con elevata regolarità) che di stabilità.\nNodi di Chebyshev-Gauss(-Lobatto)\nSe si utilizzano nodi di Chebyshev-Gauss o Chebyshev-Gauss-Lobatto, la costante di Lebesgue ha un andamento logaritmico con n: \\Lambda_n \\sim \\ln(n) Un andamento logaritmico è significativamente migliore di uno esponenziale in termini di stabilità. L’utilizzo di questi nodi mitiga il fenomeno di Runge e garantisce una migliore stabilità dell’interpolazione, richiedendo anche condizioni di regolarità meno stringenti sulla funzione da interpolare (ad esempio, C^1 invece di C^{n+1}).\nConclusioni sulla Scelta dei Nodi\nLa scelta dei nodi di interpolazione ha un impatto cruciale sia sulla convergenza che sulla stabilità dell’interpolazione polinomiale. I nodi equispaziati, pur essendo intuitivi, possono portare al fenomeno di Runge e a una scarsa stabilità per gradi elevati. I nodi di Chebyshev rappresentano una scelta più intelligente, in quanto migliorano sia la convergenza che la stabilità dell’interpolazione globale.\nIl professore ha menzionato anche i nodi adattativi, che sono considerati la scelta migliore perché permettono di concentrare i nodi nelle regioni dove la funzione presenta maggiore variabilità, ottimizzando i risultati in termini di accuratezza e potenzialmente anche di stabilità, sebbene questo non sia stato dettagliato nei passaggi precedenti.\nInfine, il professore ha concluso la discussione sull’interpolazione, preparando il terreno per l’argomento successivo: i minimi quadrati.\nApprossimazione ai Minimi Quadrati\nDistinzione tra Approssimazione e Interpolazione\nL’approssimazione si distingue dall’interpolazione. Quest’ultima si occupa di trovare una funzione che passi esattamente per tutti i punti dati. Invece, l’approssimazione, in particolare quella ai minimi quadrati, è più adatta quando si hanno dati caoticamente disposti, la cosiddetta “nuvola di dati”. In questo scenario, cercare una funzione interpolante che passi per ogni singolo punto risulterebbe in un percorso tortuoso e poco significativo. È più sensato, in questi casi, considerare l’andamento generale dei dati, ad esempio, se tendono a seguire una parabola.\nMotivazioni per l’Approssimazione ai Minimi Quadrati\nDati Caoticamente Disposti\n\nCome accennato, se i dati sono distribuiti in modo irregolare, una funzione che tentasse di interpolarli sarebbe eccessivamente complessa e poco informativa sull’andamento sottostante. L’approssimazione permette di trovare una funzione più semplice che catturi la tendenza generale dei dati.\nEstrapolazione\nUn’altra importante motivazione per l’uso dell’approssimazione ai minimi quadrati è l’estrapolazione. Il termine “extra” di estrapolazione deriva dal latino e significa “fuori”, in contrapposizione a “inter” che significa “dentro”. Estrapolare significa ricostruire l’andamento di una funzione al di fuori dell’intervallo su cui si hanno dati. Questo può essere utile per cercare di prevedere valori futuri o valori non misurati.\n\nConsideriamo l’esempio dell’andamento di un titolo borsistico. I grafici che mostrano l’evoluzione del prezzo di un’azione o di un bond nel tempo sono spesso interpolazioni lineari a tratti dei prezzi misurati a intervalli (ad esempio, a fine giornata). Se volessimo prevedere il valore del titolo il giorno successivo, basarci unicamente sull’interpolazione lineare a tratti tra l’ultimo giorno e il giorno precedente potrebbe essere fuorviante. Infatti, un titolo che globalmente tende a scendere potrebbe aver avuto un rialzo improvviso nell’ultimo periodo a causa di eventi specifici. In questo contesto, un’approssimazione ai minimi quadrati, che tiene conto di tutta la “storia” dei dati, sarebbe uno strumento più utile per l’estrapolazione, in quanto riflette l’andamento medio del grafico. L’approssimazione ai minimi quadrati considera l’intera sequenza di dati, non solo l’ultima variazione, fornendo una stima più robusta della tendenza generale.\nFormalizzazione Matematica dell’Approssimazione ai Minimi Quadrati\nNell’approssimazione ai minimi quadrati, si cerca un surrogato \\tilde f(x) per una funzione o per un insieme di dati (x_i, y_i), dove i = 0, 1, ..., n. Per semplicità, questo surrogato viene spesso scelto come un polinomio di grado m, indicato come \\tilde f(x).\nUna differenza fondamentale rispetto all’interpolazione è che il grado m del polinomio approssimante è indipendente dal numero di dati n+1. Mentre nell’interpolazione di Lagrange, un set di n+1 dati determina un polinomio di grado al più n, nell’approssimazione ai minimi quadrati si può scegliere un grado m qualsiasi, che tipicamente è molto minore di n (m \\ll n).\nIl polinomio \\tilde f(x) di grado m che realizza l’approssimazione ai minimi quadrati è definito come quel polinomio che minimizza la somma dei quadrati degli scarti tra i valori dei dati y_i e i valori del polinomio approssimante \\tilde f(x_i) nei punti x_i. Matematicamente, \\tilde f(x) è tale che:\n\\qquad \\sum_{i=0}^{n} (y_i - f \\tilde(x_i))^2 \\le \\sum_{i=0}^{n} (y_i - p_m(x_i))^2\nper ogni polinomio p_m(x) di grado m.\nIn altre parole, tra tutti i possibili polinomi di grado m, \\tilde f(x) è quello che rende minima la somma dei quadrati delle differenze verticali tra i punti dati e la curva del polinomio. Questo approccio è ampiamente utilizzato in statistica.\nÈ importante notare che la scelta di un polinomio come funzione approssimante è fatta per semplicità e praticità; si potrebbero utilizzare anche combinazioni lineari di altre funzioni, come funzioni sinusoidali o esponenziali. Inoltre, nell’approssimazione, in generale, non si ha più l’esatta corrispondenza tra y_i e \\tilde f (x_i).\nCaso Particolare: m = n (Relazione con l’Interpolazione)\nConsideriamo ora cosa succede quando il grado m del polinomio ai minimi quadrati viene scelto uguale a n, il numero di dati meno uno. In questo caso, la somma degli scarti quadratici, \\sum_{i=0}^{n} (y_i - \\tilde f(x_i))^2, è una somma di termini non negativi (essendo quadrati). Il suo valore minimo possibile è zero.\nQuesta somma è zero se e solo se ogni singolo termine è zero, cioè se y_i - \\tilde f(x_i) = 0 per tutti gli i = 0, 1, ..., n. Ciò significa che \\tilde f(x_i) = y_i per tutti i punti dati, che è esattamente la definizione di interpolazione.\nQuindi, l’interpolazione è un caso particolare dell’approssimazione ai minimi quadrati quando il grado del polinomio approssimante è uguale al grado del polinomio interpolante (per n+1 dati, grado n).\nQuesto giustifica la sintassi della funzione polyfit (presumibilmente in un software come MATLAB o Python), che accetta come argomenti le coordinate x, le coordinate y, e il grado n del polinomio. Specificando il grado n (o la lunghezza di x o y meno 1), si esegue di fatto un’interpolazione polinomiale. Il nome “fit” (adattamento) suggerisce l’idea generale di approssimazione, ma includendo il grado massimo possibile, si ricade nel caso dell’interpolazione.\nIl Caso m = 1: La Retta di Regressione\nUn caso particolarmente importante di approssimazione ai minimi quadrati è quando il grado del polinomio è m = 1. In questo caso, si cerca una retta che meglio approssimi i dati, ed è nota come retta di regressione. Questo è un concetto fondamentale in statistica.\nFormulazione del Problema di Minimizazione\nIl problema di trovare l’approssimazione ai minimi quadrati si traduce in un problema di minimizzazione. Si desidera trovare i coefficienti a_0, a_1, ..., a_m del polinomio \\tilde f(x) = a_0 + a_1 x + ... + a_m x^m che minimizzano la funzione f(b_0, b_1, ..., b_m) definita come la somma dei quadrati degli scarti:\n\\qquad f(b_0, b_1, ..., b_m) = \\sum_{i=0}^{n} (y_i - p_m(x_i))^2 = \\sum_{i=0}^{n} (y_i - (b_0 + b_1 x_i + ... + b_m x_i^m))^2\ndove b_0, b_1, ..., b_m sono i coefficienti di un generico polinomio p_m(x) di grado m. L’obiettivo è trovare i valori dei coefficienti a_0, a_1, ..., a_m che rendono minima questa funzione.\nPer trovare il minimo di una funzione di più variabili, si calcolano le derivate parziali rispetto a ciascuna variabile (in questo caso, i coefficienti b_0, b_1, ..., b_m) e si impone che queste derivate siano uguali a zero. Le soluzioni di questo sistema di equazioni daranno i valori a_0, a_1, ..., a_m che definiscono il polinomio ai minimi quadrati \\tilde f(x).\nCalcolo della Retta di Regressione (m = 1)\nConsideriamo il caso della retta di regressione, dove m = 1. Il polinomio approssimante è \\tilde f(x) = a_0 + a_1 x, e il generico polinomio di grado 1 è p_1(x) = b_0 + b_1 x. La funzione da minimizzare è:\n\\qquad f(b_0, b_1) = \\sum_{i=0}^{n} (y_i - b_0 - b_1 x_i)^2\nEspandendo il quadrato, otteniamo:\n\\qquad f(b_0, b_1) = \\sum_{i=0}^{n} (y_i^2 + b_0^2 + b_1^2 x_i^2 - 2 y_i b_0 - 2 y_i b_1 x_i + 2 b_0 b_1 x_i)\nOra calcoliamo le derivate parziali di f rispetto a b_0 e b_1:\n\\qquad \\frac{\\partial f}{\\partial b_0} = \\sum_{i=0}^{n} (2 b_0 - 2 y_i + 2 b_1 x_i)\n\\qquad \\frac{\\partial f}{\\partial b_1} = \\sum_{i=0}^{n} (2 b_1 x_i^2 - 2 y_i x_i + 2 b_0 x_i)\nImponendo che queste derivate parziali valutate in a_0 e a_1 siano uguali a zero:\n\\qquad \\sum_{i=0}^{n} (2 a_0 - 2 y_i + 2 a_1 x_i) = 0\n\\qquad \\sum_{i=0}^{n} (2 a_1 x_i^2 - 2 y_i x_i + 2 a_0 x_i) = 0\nDividendo per 2 e riorganizzando le somme, otteniamo un sistema di due equazioni lineari nelle due incognite a_0 e a_1:\n\\qquad \\sum_{i=0}^{n} a_0 - \\sum_{i=0}^{n} y_i + \\sum_{i=0}^{n} a_1 x_i = 0 \\implies a_0 \\sum_{i=0}^{n} 1 + a_1 \\sum_{i=0}^{n} x_i = \\sum_{i=0}^{n} y_i\n\\qquad \\sum_{i=0}^{n} a_1 x_i^2 - \\sum_{i=0}^{n} y_i x_i + \\sum_{i=0}^{n} a_0 x_i = 0 \\implies a_0 \\sum_{i=0}^{n} x_i + a_1 \\sum_{i=0}^{n} x_i^2 = \\sum_{i=0}^{n} y_i x_i\nQuesto sistema può essere scritto in forma matriciale come B \\mathbf{a} = \\mathbf{f}, dove \\mathbf{a} = \\begin{pmatrix} a_0 \\ a_1 \\end{pmatrix} è il vettore delle incognite, e:\n\\qquad B = \\begin{pmatrix} \\sum_{i=0}^{n} 1 &amp; \\sum_{i=0}^{n} x_i \\\\ \\sum_{i=0}^{n} x_i &amp; \\sum_{i=0}^{n} x_i^2 \\end{pmatrix} = \\begin{pmatrix} n+1 &amp; \\sum_{i=0}^{n} x_i \\\\ \\sum_{i=0}^{n} x_i &amp; \\sum_{i=0}^{n} x_i^2 \\end{pmatrix}\n\\qquad \\mathbf{f} = \\begin{pmatrix} \\sum_{i=0}^{n} y_i \\ \\sum_{i=0}^{n} y_i x_i \\end{pmatrix}\nLa matrice B è simmetrica. Risolvendo questo sistema lineare, si ottengono i coefficienti a_0 (l’intercetta) e a_1 (la pendenza) della retta di regressione.\nGeneralizzazione al Caso di Grado m\n\nPer un polinomio approssimante di grado m, \\tilde f(x) = a_0 + a_1 x + ... + a_m x^m, il vettore delle incognite è \\mathbf{a} = \\begin{pmatrix} a_0 \\ a_1 \\ \\vdots \\ a_m \\end{pmatrix}. Il sistema di equazioni normali che si ottiene imponendo le derivate parziali a zero è dato da B \\mathbf{a} = \\mathbf{f}, dove la matrice B di dimensione (m+1) \\times (m+1) ha elementi:\n\\qquad B_{jk} = \\sum_{i=0}^{n} x_i^{j+k}\nper j, k = 0, 1, ..., m. Il vettore del termine noto \\mathbf{f} di dimensione (m+1) \\times 1 ha elementi:\n\\qquad f_j = \\sum_{i=0}^{n} y_i x_i^j\nper j = 0, 1, ..., m.\nAd esempio, per una parabola di regressione (m=2), il sistema sarebbe:\n\\qquad \\begin{pmatrix} \\sum_{i=0}^{n} x_i^0 &amp; \\sum_{i=0}^{n} x_i^1 &amp; \\sum_{i=0}^{n} x_i^2 \\\\ \\sum_{i=0}^{n} x_i^1 &amp; \\sum_{i=0}^{n} x_i^2 &amp; \\sum_{i=0}^{n} x_i^3 \\\\ \\sum_{i=0}^{n} x_i^2 &amp; \\sum_{i=0}^{n} x_i^3 &amp; \\sum_{i=0}^{n} x_i^4 \\end{pmatrix} \\begin{pmatrix} a_0 \\\\ a_1 \\\\ a_2 \\end{pmatrix} = \\begin{pmatrix} \\sum_{i=0}^{n} y_i \\\\ \\sum_{i=0}^{n} y_i x_i \\\\ \\sum_{i=0}^{n} y_i x_i^2 \\end{pmatrix}\nQuesto sistema di equazioni lineari è noto come il sistema delle equazioni normali. La matrice B è simmetrica e definita positiva. La risoluzione di questo sistema permette di trovare i coefficienti del polinomio ai minimi quadrati di grado m che meglio approssima i dati.\nConclusione\nL’approssimazione ai minimi quadrati è uno strumento fondamentale per analizzare dati, specialmente quando questi sono rumorosi o si desidera estrapolare tendenze. Essa generalizza il concetto di interpolazione e porta alla risoluzione di un sistema di equazioni lineari noto come sistema delle equazioni normali. Questo argomento conclude la parte relativa all’approssimazione di dati e funzioni per il primo parziale.\nReferences\nAppunti Mate Num-lez13.pdf\n2025-03-19 15:08\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:"},"6--full-note/matenum-lab01":{"slug":"6--full-note/matenum-lab01","filePath":"6- full note/matenum-lab01.md","title":"matenum-lab01","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-17 10:17\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nmatenum-lab01\nPerfetto, ecco la trascrizione con le formule in formato MathJax utilizzando sia $$ per le equazioni centrate che $ per le equazioni inline:\n\nSistemi di Equazioni Lineari\nIntroduzione\n\nObiettivo: Risolvere sistemi di equazioni lineari del tipo\n\nA \\mathbf{x} = \\mathbf{b}\ndove A è una matrice n \\times n e \\mathbf{b} è un vettore colonna dei termini noti.\n\nScopo: Trovare il vettore incognita \\mathbf{x}.\n\nMetodi di Risoluzione\n\nMetodi diretti: Utilizzati in questa lezione.\nMetodi iterativi: Non trattati in questa lezione.\n\nFattorizzazione LU\n\nDefinizione: Trasformare la matrice A nel prodotto LU, dove L è una matrice triangolare inferiore e U è una matrice triangolare superiore.\nUtilità: Permette di risolvere il sistema A \\mathbf{x} = \\mathbf{b} trasformandolo in due sistemi più semplici:\n\nL \\mathbf{y} = \\mathbf{b}\nU \\mathbf{x} = \\mathbf{y}\n\n\n\nCondizioni per l’Esistenza Unica della Fattorizzazione LU\n\nCondizione necessaria e sufficiente: I determinanti delle sottomatrici principali di A devono essere non nulli per ogni i da 1 a n-1.\nCondizioni sufficienti:\n\nA è a dominanza diagonale stretta per righe o colonne.\nA è simmetrica definita positiva (tutti gli autovalori sono strettamente maggiori di 0).\n\n\n\nAlgoritmi di Sostituzione\nSostituzione in Avanti\n\n\nUtilizzo: Risolvere sistemi del tipo L \\mathbf{y} = \\mathbf{b}.\n\n\nProcedura:\n\nCalcolare y_1 come\n\ny_1 = \\frac{b_1}{l_{11}}\n\nPer i da 2 a n, calcolare y_i come:\n\ny_i = \\frac{1}{l_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} l_{ij} y_j \\right)\n\n\nSostituzione all’Indietro\n\n\nUtilizzo: Risolvere sistemi del tipo U \\mathbf{x} = \\mathbf{y}.\n\n\nProcedura:\n\nCalcolare x_n come\n\nx_n = \\frac{y_n}{u_{nn}}\n\nPer i da n-1 a 1, calcolare x_i come:\n\nx_i = \\frac{1}{u_{ii}} \\left( y_i - \\sum_{j=i+1}^{n} u_{ij} x_j \\right)\n\n\nImplementazione in MATLAB\nComandi Iniziali\n\nInizializzazione: Utilizzare clear all, close all, clc per pulire l’ambiente di lavoro.\n\nEsempio di Matrice\n\nclose all\n \nclc\n \nclear all\n \nA = [50, 1, 3;\n \n\t1, 6, 0;\n \n\t3, 0, 1];\n \n[L,U,P] = lu(A)\n\nDefinizione: Creare una matrice A simmetrica e diagonalmente dominante.\nFattorizzazione LU: Utilizzare il comando [L, U, P] = lu(A) per ottenere le matrici L, U e la matrice di permutazione P.\n\n\nVisualizzazione delle Matrici\n\nComando spy: Visualizzare lo sparsity pattern delle matrici per verificare la struttura triangolare.\n\n%per vedere se è il pattern di sparsità\n \nspy (L)\n\nPivoting\n\nNecessità: Se la fattorizzazione LU richiede pivoting, utilizzare la matrice P per risolvere il sistema PA \\mathbf{x} = P \\mathbf{b}.\n\nclose all\n \nclc\n \nclear all\n \n%adesso mettiamo 0 nella prima colonna (rendendo la fattorizzazione non unica)\n \n% e non mettiamo P nella fattorizzazione\n \nA = [0, 1, 3;\n \n\t1, 6, 0;\n \n\t3, 0, 1];\n \n[L,U] = lu(A);\n \n%per vedere se è il pattern di sparsità\n \nspy (L);\n\n\nstiamo visualizzando PL quindi male male\n\nCodice MATLAB per Sostituzione in Avanti e all’Indietro\nSostituzione in Avanti\n\nFunzione: Implementare la sostituzione in avanti in una funzione MATLAB.\nPassaggi:\n\nInizializzare il vettore soluzione \\mathbf{x} come un vettore di zeri.\nImplementare il ciclo per calcolare y_i utilizzando la formula della sostituzione in avanti.\n\n\n\nfunction x=fwsub(A,b)\n \n% function [x] = fwsub(A,b)\n \n% Algoritmo di sostituzione in avanti\n \n% A: matrice quadrata triangolare inferiore\n \n% b: termine noto\n \n% x: soluzione del sistema Ax=b\n \nn=length(b);\n \nif (size(A,1)~=n) || (size(A,2)~=n)\n \nerror(&#039;ERRORE: dimensioni incompatibili&#039;)\n \nend\n \nif ~isequal(A,tril(A))\n \nerror(&#039;ERRORE: matrice non triangolare inferiore&#039;)\n \nend\n \nif prod(diag(A)) == 0\n \n% almeno un elemento diagonale nullo\n \nerror(&#039;ERRORE: matrice singolare&#039;)\n \nend\n \n%una dichiarazione delle variabili, che ci permette di avere controllo\n \n%sulla dimensione\n \nx = zeros(n,1);\n \nx(1) = b(1)/A(1,1);\n \nfor i= 2:1:n\n \nx(i) = (b(i)- A(i,1:1:i-1)* x(1:1:i-1))/A(i,i);\n \nend\nSostituzione all’Indietro\n\n\nFunzione: Implementare la sostituzione all’indietro in una funzione MATLAB.\n\n\nPassaggi:\n\nImplementare il ciclo per calcolare x_i utilizzando la formula della sostituzione all’indietro.\n\n\n\n1. d)  Supponiamo ora di voler risolvere il sistema Ax = b con A de\u001cnita in (1). Si utilizzi come termine noto b un vettore tale che la soluzione esatta del sistema sia xex = [1, 1, 1]^T . Si calcoli la soluzione del sistema Ax = b, utilizzando le funzioni bksub.m e fwsub.m.\n\n\nclose all\n \nclc\n \nclear all\n \n%adesso mettiamo 0 nella prima colonna (rendendo la fattorizzazione non unica)\n \n% e non mettiamo P nella fattorizzazione\n \nA = [50, 1, 3;\n \n1, 6, 0;\n \n3, 0, 1];\n \nx_ex = ones (3,1);\n \nb= A*x_ex;\n \n[L,U,P]=lu(A);\n \ny=fwsub(L,b);\n \nx_a= bksub(U,y);\n \nx_a\n\nConclusione\n\nEsercizi: Completare gli esercizi forniti utilizzando i concetti e i codici discussi durante la lezione.\nSuggerimenti: Prestare attenzione agli indici e alla numerazione delle matrici in MATLAB, che parte da 1.\n\nReferences"},"6--full-note/matenum-lab02":{"slug":"6--full-note/matenum-lab02","filePath":"6- full note/matenum-lab02.md","title":"matenum-lab02","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-17 10:16\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nmatenum-lab02\nAnalisi dei Metodi Numerici e Sensibilità alle Perturbazioni\nRipasso dell’Esercizio Precedente: Matrice di Bucky e Decomposizione LU\nL’esercitazione odierna riprende l’ultimo esercizio del laboratorio precedente, focalizzato sull’analisi della matrice di Bucky. L’obiettivo era importare questa matrice da una gallery di Matlab, visualizzarne lo sparsity pattern e calcolare la sua decomposizione LU per osservare lo sparsity pattern delle matrici L e U risultanti.\n\n\nImportazione e Visualizzazione della Matrice di Bucky\n\nLa matrice di Bucky viene importata in Matlab utilizzando il comando B = Bucky.\nLo sparsity pattern viene visualizzato tramite il comando spy(B), che genera un grafico dove i punti indicano la posizione degli elementi non nulli nella matrice. La matrice di Bucky è risultata essere sparsa, ovvero con un numero elevato di elementi nulli.\n\n\n\n\nDecomposizione LU della Matrice di Bucky\n\n\nÈ stata calcolata la decomposizione LU della matrice Bucky utilizzando il comando [L, U, P] = lu(B). La matrice P rappresenta la matrice di permutazione dovuta al pivoting.\nSuccessivamente, sono stati visualizzati gli sparsity pattern delle matrici L, U e P utilizzando il comando subplot per mostrarli in un’unica finestra grafica. Il comando subplot(2, 2, 1) crea una matrice di grafici 2x2 e posiziona il primo grafico nella prima posizione. Similmente, subplot(2, 2, 2) posiziona il secondo grafico.\nUn’osservazione fondamentale è che, nonostante la matrice originale B fosse sparsa, le matrici L e U ottenute dalla decomposizione LU risultavano essere molto più dense, con un numero significativamente maggiore di elementi non nulli. In particolare, il numero di non zeri per B era 180, mentre per L era 451 e per U era 419.\nQuesto fenomeno, per cui le matrici L e U diventano meno sparse della matrice originale A durante la decomposizione LU, è noto come problema del filling.\n\n\n\nImplicazioni Computazionali della Densità\n\nTrattare matrici L e U dense comporta un aumento dei costi computazionali per la risoluzione del sistema lineare associato. Un maggior numero di elementi non nulli implica un maggior numero di operazioni aritmetiche.\nQuesto può anche portare a un aumento degli errori di arrotondamento e influenzare il condizionamento della matrice.\n\n\n\nConclusione sulla Sparsità e Decomposizione LU\n\nQuando si risolve un sistema lineare, è importante considerare la sparsità della matrice.\nNon è garantito che la decomposizione LU di una matrice sparsa produca matrici L e U altrettanto sparse.\n\n\n\nLaboratorio 1 Addendum: Sistemi Lineari con Matrici Tridiagonali\nIl laboratorio prosegue con l’analisi di un sistema lineare Ax = b, dove A è una matrice tridiagonale di dimensione 1000 \\times 1000. Questa matrice ha elementi non nulli solo sulla diagonale principale (tutti uguali a 2), sulla sovradiagonale (tutti uguali a -1) e sulla sottodiagonale (tutti uguali a -1). Il vettore b è tale che la soluzione esatta x sia un vettore di tutti 1. L’obiettivo è comparare diversi metodi risolutivi.\n\n\nMetodi Risolutivi Considerati\n\nBackslash operator () di Matlab.\nDecomposizione LU con pivoting e successiva risoluzione dei sistemi triangolari con gli algoritmi di forward substitution e backward substitution. Il costo computazionale di questa operazione è dominato dalla decomposizione LU, che ha un costo di O(n^3). La sostituzione in avanti e all’indietro hanno un costo di O(n^2) ciascuna.\nFattorizzazione di Cholesky (applicabile a matrici simmetriche definite positive) e successiva risoluzione con forward e backward substitution. La decomposizione di Cholesky di una matrice A produce una matrice triangolare inferiore L tale che A = LL^T. Il costo della decomposizione di Cholesky è circa la metà di quello della decomposizione LU, ovvero O(n^3/3).\nAlgoritmo di Thomas (specifico per matrici tridiagonali). Questo algoritmo esegue una decomposizione LU specializzata che sfrutta la struttura tridiagonale. Il costo computazionale dell’algoritmo di Thomas è lineare, O(n), precisamente 8n - 7 operazioni.\n\n\n\nCosti Computazionali Sintetici\n\nDecomposizione LU con pivoting: O(n^3)\nFattorizzazione di Cholesky: O(n^3/3) (richiede matrice simmetrica definita positiva)\nAlgoritmo di Thomas: O(n) (specifico per matrici tridiagonali)\n\n\n\nImplementazione in Matlab\n\nDefinizione della matrice tridiagonale A: Viene creata sommando tre matrici diagonali: una con 2 sulla diagonale principale (2*eye(n)), una con -1 sulla sovradiagonale (diag(ones(n-1, 1)*-1, 1)), e una con -1 sulla sottodiagonale (diag(ones(n-1, 1)*-1, -1)).\n\n clear all\n \nclose all\n \nclc\n \n%definiamoo la matrice diagonale come la somma di più matrici\n \nn= 10;\n \nA= 2*eye (n)- diag( ones(n-1,1) ,1) - diag( ones(n-1, 1), -1)\n\n\nDefinizione del vettore b: Calcolato come b = A \\times x_{esatta}, dove x_{esatta} è un vettore colonna di tutti 1 (ones(n, 1)).\nRisoluzione con backslash: X1 = A \\ b.\nclear all\n\n\n\nclose all\n \nclc\n \n%definiamoo la matrice diagonale come la somma di più matrici\n \nn= 1e3;\n \nA= 2*eye (n)- diag( ones(n-1,1) ,1) - diag( ones(n-1, 1), -1);\n \nx_ex = ones (n,1);\n \nb = A * x_ex;\n \n%backslash\n \ndisplay(&quot;backlash&quot;);\n \nx1= A\\b\n \n%LU\n \ndisplay(&quot;LU fw bw&quot;);\n \n[L,U,P]= lu(A);\n \ny = fwsub(L,P*b);\n \nx2= bksub (U,y)\n \n%chol\n \ndisplay(&quot;cholesky&quot;);\n \nL= chol(A);\n \ny = fwsub(L,b);\n \nx3= bwsub (L&#039;,y)\n \n%thomas\n \ndisplay(&quot;thomas&quot;);\n \n[Lt,Ut,x4]= thomas(A,b);\n \nx4\n\nRisoluzione con LU:\n- [L, U, P] = lu(A).\n- y = forward_sub(L, P*b). (Correzione: il termine noto deve essere moltiplicato per la matrice di permutazione P)\n- X2 = backward_sub(U, y).\n\nRisoluzione con Cholesky:\n\nLC = chol(A, &#039;lower&#039;). (È importante specificare &#039;lower&#039; per ottenere una matrice triangolare inferiore L tale che A = LL^T, coerentemente con la notazione usata a lezione).\ny = forward_sub(LC, b).\nX3 = LC&#039; \\ y. (Equivalente a risolvere L^T x = y).\n\n\nRisoluzione con Thomas: Viene richiamata una funzione thas (implementata precedentemente) che esegue l’algoritmo di Thomas.\nMisurazione del tempo: I comandi tic e toc vengono utilizzati per misurare il tempo di esecuzione di ciascun metodo risolutivo.\nVerifica della definita positività: Gli autovalori della matrice A vengono calcolati con eig(A) e verificati essere tutti positivi per poter applicare il metodo di Cholesky.\nSparsity pattern di L (da LU): Viene visualizzato lo sparsity pattern della matrice L ottenuta dalla decomposizione LU (spy(L)) e si osserva che in questo caso specifico rimane sparsa, a differenza dell’esempio della matrice di Bucky.\n\n\n\nLaboratorio 2: Sensibilità della Soluzione alle Perturbazioni\nQuesto laboratorio introduce il concetto di sensibilità della soluzione di un sistema lineare rispetto a perturbazioni nei dati (matrice A e termine noto b). Anche con metodi risolutivi accurati, piccole perturbazioni nei dati di input possono portare a grandi variazioni nella soluzione x.\n\n\nIl Problema delle Perturbazioni\n\nIdealmente, si vorrebbe risolvere Ax = b.\nNella pratica, a causa di errori di misurazione o di arrotondamento, si lavora con una matrice perturbata A + \\delta A e un termine noto perturbato b + \\delta b, ottenendo una soluzione perturbata x + \\delta x. Si risolve quindi (A + \\delta A)(x + \\delta x) = b + \\delta b.\nL’obiettivo è capire come le perturbazioni sui dati (\\delta A, \\delta b) si propagano e influenzano la perturbazione sulla soluzione (\\delta x).\n\n\n\nAnalisi della Perturbazione sul Termine Noto\n\nConsiderando inizialmente solo una perturbazione sul termine noto (\\delta A = 0), si ha A(x + \\delta x) = b + \\delta b.\nSottraendo Ax = b, si ottiene A \\delta x = \\delta b, quindi \\delta x = A^{-1} \\delta b.\nUtilizzando le norme vettoriali e matriciali, si può derivare una relazione tra la perturbazione relativa sulla soluzione (\\frac{||\\delta x||}{||x||}) e la perturbazione relativa sul termine noto (\\frac{||\\delta b||}{||b||}).\n\n\n\nNumero di Condizionamento\n\nLa relazione derivata è: \\frac{||\\delta x||_p}{||x||_p} \\le \\kappa_P(A) \\frac{||\\delta b||_p}{||b||_p}, dove \\kappa_P(A) = ||A||_P ||A^{-1}||_P è il numero di condizionamento della matrice A in norma P.\nIl numero di condizionamento \\kappa_P(A) amplifica la perturbazione relativa sul termine noto per dare un limite superiore alla perturbazione relativa sulla soluzione.\nUn numero di condizionamento vicino a 1 indica una matrice ben condizionata, dove piccole perturbazioni nei dati portano a piccole perturbazioni nella soluzione.\nUn numero di condizionamento molto grande indica una matrice mal condizionata, dove piccole perturbazioni nei dati possono portare a grandi perturbazioni nella soluzione, rendendo il problema sensibile alle fluttuazioni.\nIl numero di condizionamento è una proprietà intrinseca della matrice A e non dipende dal metodo risolutivo utilizzato.\n\n\n\nRelazione con il Residuo\n\nUn’altra stima per l’errore relativo è data in termini del residuo normalizzato (\\frac{||b - A\\hat{x}||}{||b||}, dove \\hat{x} è la soluzione calcolata): \\frac{||x - \\hat{x}||}{||x||} \\le \\kappa_P(A) \\frac{||b - A\\hat{x}||}{||b||}.\nQuesta relazione mostra che anche se il residuo è piccolo, l’errore relativo può essere grande se il numero di condizionamento è elevato. Un piccolo residuo non implica necessariamente una soluzione accurata per matrici mal condizionate.\n\n\n\ncomandi matlab\n\ninvece della definizione usiamo cond (A,p) con p la norma p\ncondest(A)\n\n\n\nEsercizio sulla Matrice di Hilbert\n\nL’esercizio consiste nello studiare il condizionamento della matrice di Hilbert di diverse dimensioni (da 1 a 10). La matrice di Hilbert di dimensione n ha elementi H_{ij} = \\frac{1}{i+j-1}.\nPer ogni dimensione n, viene calcolato il numero di condizionamento utilizzando il comando cond(H) in Matlab (che calcola il condizionamento in norma 2).\nViene risolto il sistema lineare Hx = b (dove b è tale che la soluzione esatta x sia un vettore di tutti 1) utilizzando il backslash operator.\nVengono calcolati l’errore relativo della soluzione e il residuo normalizzato.\nI risultati (numero di condizionamento, errore relativo, residuo normalizzato) vengono visualizzati in un grafico semilogaritmico (scala logaritmica sull’asse y) in funzione della dimensione della matrice.\n\n\n\nOsservazioni sull’Esercizio della Matrice di Hilbert\n\nIl grafico del numero di condizionamento in scala semilogaritmica appare come una retta, suggerendo che il condizionamento della matrice di Hilbert cresce esponenzialmente con la dimensione n. Se y = e^{\\alpha n}, allora \\log(y) = \\alpha n, che è l’equazione di una retta in funzione di n.\nIl residuo normalizzato rimane molto piccolo (intorno a 10^{-15}), suggerendo apparentemente una buona soluzione.\nTuttavia, l’errore relativo cresce rapidamente con la dimensione della matrice, raggiungendo valori significativi. Questo dimostra che un piccolo residuo non garantisce una piccola errore per matrici mal condizionate.\nLa stima dell’errore basata sul numero di condizionamento e sul residuo normalizzato (\\kappa(A) \\frac{||r||}{||b||}) fornisce un limite superiore all’errore relativo e segue l’andamento del numero di condizionamento, rimanendo sempre maggiore o uguale all’errore effettivo (a meno di problemi con il calcolo del logaritmo di valori vicini a zero).\n\n\n\nIn conclusione, il numero di condizionamento è un indicatore cruciale della stabilità della soluzione di un sistema lineare rispetto a perturbazioni nei dati. Matrici con un elevato numero di condizionamento (mal condizionate) possono portare a soluzioni inaccurate anche con piccoli errori nei dati o residui piccoli. La matrice di Hilbert è un classico esempio di matrice mal condizionata.\nReferences"},"6--full-note/matenum-lab04":{"slug":"6--full-note/matenum-lab04","filePath":"6- full note/matenum-lab04.md","title":"matenum-lab04","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-18 19:39\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nmatenum-lab04\nlaboratorio 4\nCertamente, ecco una spiegazione dettagliata dei metodi iterativi, con particolare attenzione al metodo di Richardson e alle sue varianti, basata sulla trascrizione fornita. Cercherò di includere tutti i passaggi matematici, esempi e concetti chiave menzionati dal professore, formattando il tutto in modo chiaro e leggibile con l’uso di LaTeX per le formule matematiche.\nMetodi Iterativi per la Risoluzione di Sistemi Lineari\nConsistenza di un Metodo Iterativo\nUn aspetto fondamentale di un metodo iterativo è la sua consistenza. Se consideriamo un generico schema iterativo, possiamo rappresentarlo come:\nx_{k+1} = G(x_k, b)\ndove G è una funzione che dipende dalla soluzione precedente x_k e dal termine noto b del sistema lineare Ax = b. Un metodo iterativo è consistente se, quando la sequenza x_k converge a una soluzione x, quest’ultima è effettivamente la soluzione del sistema lineare.\nIl professore ha menzionato un esercizio tipico per valutare la consistenza: se ci viene chiesto di determinare G affinché il metodo sia consistente, dobbiamo fare in modo che se la sequenza x_k converge a x, allora x deve soddisfare l’equazione originale. Questo si verifica spesso analizzando il punto fisso dell’iterazione, ovvero quando x = G(x, b) implica Ax = b.\nUn modo per verificare la consistenza è partire da un’iterazione del tipo x_{k+1} = Bx_k + c. Se il metodo converge a x, allora x = Bx + c, che possiamo riscrivere come (I - B)x = c. Per la consistenza con il sistema Ax = b, dovremmo avere una relazione tra (I - B) e A, e tra c e b.\nConvergenza dei Metodi Iterativi\nLa convergenza di un metodo iterativo è determinata dalla matrice di iterazione B. In particolare, il raggio spettrale di B, denotato come \\rho(B), gioca un ruolo cruciale. Il raggio spettrale è definito come il massimo modulo degli autovalori di B:\n\\rho(B) = \\max_i |\\lambda_i(B)|\nDove \\lambda_i(B) sono gli autovalori della matrice B.\nLa condizione di convergenza è la seguente:\n\nSe \\rho(B) &lt; 1, allora il metodo iterativo converge per ogni scelta del vettore iniziale x_0.\nSe \\rho(B) &gt; 1, allora il metodo iterativo non converge in generale.\n\nInoltre, il valore del raggio spettrale fornisce informazioni sulla velocità di convergenza: minore è \\rho(B), più veloce è la convergenza.\nMetodo di Richardson\nIl metodo di Richardson è una famiglia di metodi iterativi con diverse varianti. Distinguiamo principalmente tra:\n\nMetodo di Richardson stazionario\nMetodo di Richardson dinamico\nMetodo di Richardson precondizionato stazionario\nMetodo di Richardson precondizionato dinamico\n\nPer chiarezza, ci concentreremo sul metodo di Richardson precondizionato stazionario, accennando alla differenza con la versione dinamica.\nMetodo di Richardson Precondizionato Stazionario\nNel metodo di Richardson precondizionato stazionario, la matrice di iterazione B ha la seguente forma:\nB = (I - \\alpha P^{-1} A)\ndove:\n\n\\alpha è il parametro di accelerazione del metodo.\nP è la matrice di precondizionamento.\nA è la matrice del sistema lineare Ax = b.\nI è la matrice identità.\n\nL’aggiornamento della soluzione al passo successivo x_{k+1} è dato da:\nx_{k+1} = x_k + \\alpha P^{-1} r_k\ndove r_k è il residuo al passo k, definito come:\nr_k = b - Ax_k\nEsiste anche un modo alternativo per aggiornare il residuo:\nr_{k+1} = r_k - \\alpha A z_k\ndove z_k è la soluzione del sistema lineare con la matrice di precondizionamento e il residuo corrente:\nP z_k = r_k \\implies z_k = P^{-1} r_k\nMetodo di Richardson Precondizionato Dinamico\nLa differenza principale con il metodo di Richardson precondizionato dinamico è che il parametro di accelerazione non è costante, ma dipende dal numero di iterazione k, diventando \\alpha_k. Di conseguenza, anche la matrice di iterazione B_k = (I - \\alpha_k P^{-1} A) varia ad ogni passo. Calcolare il raggio spettrale in questo caso diventa più complesso.\nL’aggiornamento della soluzione nel metodo dinamico è analogo, ma con \\alpha_k:\nx_{k+1} = x_k + \\alpha_k P^{-1} r_k\ne l’aggiornamento del residuo diventa:\nr_{k+1} = r_k - \\alpha_k A z_k\nRelazione con i Metodi di Jacobi e Gauss-Seidel\nI metodi di Jacobi e Gauss-Seidel sono casi particolari del metodo di Richardson:\n\nMetodo di Jacobi: Corrisponde a un metodo di Richardson dove la matrice di precondizionamento P è la matrice diagonale D di A, e il parametro di accelerazione \\alpha è 1.\nMetodo di Gauss-Seidel: Corrisponde a un metodo di Richardson dove la matrice di precondizionamento P è data da D - E, con D la parte diagonale e -E la parte strettamente triangolare inferiore di A, e il parametro di accelerazione \\alpha è 1. Per la definizione precisa di D e E, si rimanda al laboratorio precedente. In sintesi, se scomponiamo la matrice A come A = D - E - F, dove D è la diagonale, -E è la parte strettamente triangolare inferiore e -F è la parte strettamente triangolare superiore, allora:\n\nJacobi: P = D, \\alpha = 1\nGauss-Seidel: P = D - E, \\alpha = 1\n\n\n\nCondizione di Convergenza Ottimale per il Metodo di Richardson Stazionario\nSe la matrice di precondizionamento P è non singolare e gli autovalori di P^{-1} A, denotati come \\lambda_i per i = 1, \\dots, n, sono reali, positivi e ordinati in modo decrescente (\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_n &gt; 0), allora il metodo di Richardson stazionario precondizionato converge se e solo se il parametro di accelerazione \\alpha soddisfa la seguente condizione:\n0 &lt; \\alpha &lt; \\frac{2}{\\lambda_1}\nInoltre, esiste un valore ottimale di \\alpha, denotato come \\alpha_{opt}, che massimizza la velocità di convergenza. Questo valore è dato da:\n\\alpha_{opt} = \\frac{2}{\\lambda_1 + \\lambda_n}\nCalcolare gli autovalori \\lambda_1 e \\lambda_n può essere computazionalmente oneroso. In pratica, si possono utilizzare stime o si procede per tentativi per scegliere un valore di \\alpha che garantisca una buona convergenza.\nAlgoritmo del Metodo di Richardson Precondizionato (Dinamico e Stazionario)\nL’algoritmo generale per il metodo di Richardson precondizionato (che può essere sia dinamico che stazionario) segue questi passi all’interno di un ciclo iterativo (ad esempio, un ciclo while con una condizione di arresto basata sul residuo, sul numero massimo di iterazioni o sulla differenza tra iterate successive):\n\n\nRisolvere il sistema lineare con la matrice di precondizionamento: P z_k = r_k da cui si ottiene z_k = P^{-1} r_k.\nIn codice MATLAB questo si tradurrebbe in:\nzk = P \\ rk;\n\noppure, se P^{-1} è nota:\nzk = inv(P) * rk;\n\n\n\nCalcolare il parametro di accelerazione \\alpha_k:\n\nSe il metodo è stazionario, \\alpha_k è una costante \\alpha fornita come parametro di input.\nSe il metodo è dinamico, \\alpha_k viene calcolato in base a una specifica regola che dipende dall’iterazione corrente k.\n\n\n\nAggiornare la soluzione: x_{k+1} = x_k + \\alpha_k z_k\nIn MATLAB:\nxk_plus_1 = xk + alpha_k * zk;\n\n\n\nAggiornare il residuo: r_{k+1} = r_k - \\alpha_k A z_k\nIn MATLAB:\nrk_plus_1 = rk - alpha_k * A * zk;\n\n\n\nSe il metodo di Richardson non è precondizionato, la matrice di precondizionamento P è semplicemente la matrice identità I. In questo caso, risolvere P z_k = r_k si riduce a z_k = r_k.\nMetodo del Gradiente come Caso Particolare del Metodo di Richardson Dinamico\nIl metodo del gradiente (sia precondizionato che non precondizionato) è un caso speciale del metodo di Richardson dinamico.\nMetodo del Gradiente Precondizionato\nNel metodo del gradiente precondizionato, il parametro di accelerazione \\alpha_k ad ogni iterazione viene calcolato in modo specifico come:\n\\alpha_k = \\frac{r_k^T z_k}{z_k^T A z_k}\ndove, come in precedenza, z_k è la soluzione di P z_k = r_k.\nIn MATLAB, questo calcolo si traduce in:\nalpha_k = (rk&#039; * zk) / (zk&#039; * A * zk);\n\nMetodo del Gradiente Non Precondizionato\nSe il metodo del gradiente non è precondizionato, allora P = I, e quindi z_k = r_k. In questo caso, la formula per \\alpha_k si semplifica a:\n\\alpha_k = \\frac{r_k^T r_k}{r_k^T A r_k} = \\frac{|r_k|^2}{r_k^T A r_k}\nIn MATLAB:\nalpha_k = (rk&#039; * rk) / (rk&#039; * A * rk);\nUna proprietà importante del metodo del gradiente non precondizionato è che le direzioni dei residui successivi sono ortogonali tra loro.\nIl professore ha menzionato che la lezione successiva sarà dedicata ad approfondire il metodo del gradiente, inclusi i dettagli sulla discesa, l’ortogonalità delle direzioni, i casi patologici e le differenze con il metodo del gradiente coniugato.\nSpero che questa spiegazione dettagliata e ben formattata ti sia utile. Fammi sapere se hai altre domande.\nReferences"},"6--full-note/matenum-lab05":{"slug":"6--full-note/matenum-lab05","filePath":"6- full note/matenum-lab05.md","title":"matenum-lab05","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-24 09:12\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nmatenum-lab05\nLaboratorio sui Metodi Iterativi e Visualizzazione di Convergenza\nScopo del Laboratorio\nL’obiettivo principale di questo laboratorio è visualizzare concettualmente ciò che è stato appreso riguardo alla risoluzione di sistemi lineari del tipo Ax = b attraverso metodi iterativi. In particolare, si vuole mostrare la connessione tra la risoluzione del sistema lineare e la minimizzazione di una forma quadratica associata.\nEquivalenza tra Sistemi Lineari e Minimizzazione di una Forma Quadratica\nData una matrice A simmetrica e definita positiva, la risoluzione del sistema lineare Ax = b è equivalente alla ricerca del minimo della forma quadratica f(x) definita come:\n\\phi(x) = \\frac{1}{2} x^T A x - x^T b\nDove x è un vettore colonna. Lo scopo del laboratorio è visualizzare questo concetto, immaginando di costruire il paraboloide rappresentato da questa funzione quadratica nello spazio. Il punto di minimo di questo paraboloide corrisponde alla soluzione del sistema lineare Ax = b. I metodi iterativi, partendo da un punto iniziale X_0, cercano di trovare la “strada ottimale” per raggiungere questo punto di minimo.\nPassaggi per la Visualizzazione del Paraboloide\nPer visualizzare questo paraboloide, è necessario seguire alcuni passaggi:\n\n1. Discretizzazione del Dominio\nPoiché non è possibile lavorare con un dominio continuo in \\mathbb{R}^2 (assumendo x = [x, y]^T), è necessario discretizzare le coordinate x e y all’interno di un intervallo specificato (ad esempio, da -10 a 10 per entrambe le variabili). Questo significa selezionare un insieme finito di punti x_i e y_j all’interno di questi intervalli con un certo passo.\n2. Creazione della Griglia (Prodotto Cartesiano)\n\nUna volta definiti i vettori contenenti i punti discreti per x (x_h) e y (y_h), è necessario creare il prodotto cartesiano tra questi due insiemi per ottenere tutte le coppie (x_i, y_j) che definiscono i punti sul piano xy dove verrà disegnato il paraboloide. In MATLAB, questo si realizza con il comando meshgrid:\n[X, Y] = meshgrid(xh, yh);\n\nQuesto comando prende in input i vettori x_h e y_h e restituisce due matrici X e Y che rappresentano le coordinate x e y di una griglia nel piano.\n3. Calcolo della Quota Z\nPer ogni punto (x, y) della griglia creata, è necessario calcolare il valore corrispondente sulla “quota” z, che in questo caso è dato dal valore della funzione quadratica f(x, y). Utilizzando la notazione del professore, se X e Y sono le matrici generate da meshgrid, la matrice Z dei valori della funzione può essere calcolata (element-wise) in base alla forma quadratica:\n\nZ = \\frac{1}{2} X^T A X - X^T B\nAttenzione: Come specificato dal professore, se x = \\begin{bmatrix} x \\ y \\end{bmatrix}, allora X e Y rappresentano le coordinate sulla griglia. La formula va interpretata tenendo conto che per ogni punto della griglia (X_{ij}, Y_{ij}), si calcola il valore di \\phi(\\begin{bmatrix} X_{ij} \\ Y_{ij} \\end{bmatrix}). In termini di componenti, se A = \\begin{bmatrix} A_{11} &amp; A_{12} \\ A_{21} &amp; A_{22} \\end{bmatrix}, X rappresenta la coordinata x, Y la coordinata y, e B = \\begin{bmatrix} b_1 \\ b_2 \\end{bmatrix}, allora per ogni punto (x, y) della griglia:\n\\phi(x, y) = \\frac{1}{2} \\begin{bmatrix} x &amp; y \\end{bmatrix} \\begin{bmatrix} A_{11} &amp; A_{12} \\ A_{21} &amp; A_{22} \\end{bmatrix} \\begin{bmatrix} x \\ y \\end{bmatrix} - \\begin{bmatrix} x &amp; y \\end{bmatrix} \\begin{bmatrix} b_1 \\ b_2 \\end{bmatrix}\n\\phi(x, y) = \\frac{1}{2} (A_{11}x^2 + A_{12}xy + A_{21}yx + A_{22}y^2) - (xb_1 + yb_2)\nPoiché A è simmetrica (A_{12} = A_{21}), si ha:\n\\phi(x, y) = \\frac{1}{2} (A_{11}x^2 + 2A_{12}xy + A_{22}y^2) - (xb_1 + yb_2)\nIn MATLAB, questo calcolo va effettuato element-wise sulle matrici X e Y generate da meshgrid. È importante definire correttamente la matrice A e il vettore B per il sistema lineare che si vuole studiare.\n4. Visualizzazione\nUna volta ottenute le matrici X, Y, e Z, si possono utilizzare i comandi MATLAB per la visualizzazione:\n\nsurf(X, Y, Z): per disegnare la superficie del paraboloide nello spazio 3D.\ncontour(X, Y, Z): per disegnare le linee di livello (proiezioni sul piano xy delle curve di intersezione del paraboloide con piani orizzontali z = costante).\ncontour3(X, Y, Z): per disegnare le linee di livello direttamente nello spazio 3D (menzionato ma non approfondito).\n\nVisualizzazione delle Iterazioni dei Metodi\nOltre a visualizzare il paraboloide, l’obiettivo è anche mostrare come i metodi iterativi si muovono sulla superficie o sulle linee di livello durante il processo di convergenza alla soluzione. A questo scopo, sono disponibili su WIVIP delle funzioni che, oltre alla soluzione finale, restituiscono la storia di tutte le iterazioni (la sequenza dei punti X_0, X_1, X_2, ..., X_k ). Queste funzioni includono:\n\ngradiente coniugato\ngradiente classico\nRichardson iterate\n\nPer visualizzare le iterazioni su un grafico esistente (ad esempio, le linee di livello), è necessario plottare la sequenza dei punti ottenuti da queste funzioni. Se la storia delle iterazioni restituita è una matrice dove ogni colonna rappresenta un’iterazione e le righe rappresentano le componenti (ad esempio, x e y), si può plottare la prima riga (le coordinate x delle iterazioni) contro la seconda riga (le coordinate y delle iterazioni).\nCorrezione del Primo Esercizio\nDurante la correzione del primo esercizio, il professore ha sottolineato l’importanza di alcune nozioni grafiche in MATLAB:\n\n\nsubplot(m, n, p): Questo comando permette di dividere la finestra corrente in una griglia di m righe e n colonne di sottofigure e di rendere attiva la sottofigura numero p (che si conta per righe, da sinistra a destra e dall’alto in basso). È fondamentale consultare l’help di MATLAB per comprenderne appieno il funzionamento.\n\n\nAccesso alle componenti delle iterazioni: Le funzioni che restituiscono la storia delle iterazioni (come Richardson iterate) forniscono tipicamente una matrice dove le colonne rappresentano le iterazioni e le righe le componenti del vettore soluzione. Per plottare la traiettoria delle iterazioni, è necessario selezionare correttamente le righe corrispondenti alle coordinate desiderate (ad esempio, la prima e la seconda riga per un problema in 2D) e tutte le colonne (tutte le iterazioni). Ad esempio, se XKR1 contiene la storia delle iterazioni, XKR1(1, :) rappresenta la prima componente (x) di tutte le iterazioni, e XKR1(2, :) rappresenta la seconda componente (y). Per plottare la traiettoria su un grafico 2D:\nplot(XKR1(1, :), XKR1(2, :), &#039;-o&#039;);\n\ndove &#039;-o&#039; specifica il tipo di linea e un marcatore per ogni punto.\n\n\nControllo dei limiti degli assi: Per visualizzare correttamente la convergenza o la divergenza dei metodi, può essere necessario fissare i limiti degli assi del grafico utilizzando il comando axis per evitare che la scala si adatti ad ogni iterazione in modo fuorviante.\n\n\nOsservazioni sulle visualizzazioni:\n\nIl metodo di Richardson con un parametro \\alpha appropriato mostra una convergenza verso il minimo del funzionale (soluzione del sistema), mentre con un \\alpha non appropriato può divergere.\nIl metodo del gradiente non precondizionato mostra una convergenza lenta con direzioni ortogonali tra un passo e l’altro, caratterizzata da un andamento a “zig-zag” verso il minimo.\nIl metodo del gradiente precondizionato può mostrare una convergenza più rapida (anche se non sempre visivamente evidente dalla perpendicolarità delle direzioni a causa della precondizionamento).\nIl metodo del gradiente coniugato è concettualmente un metodo diretto che, in aritmetica esatta, converge in un numero finito di iterazioni (al massimo la dimensione del sistema). Le visualizzazioni mostrano una convergenza rapida, spesso in pochi passi.\n\n\n\nSecondo Esercizio: Utilizzo di PCG e Precondizionamento\nIl secondo esercizio introduce l’uso della funzione PCG di MATLAB (Preconditioned Conjugate Gradient) e il concetto di precondizionamento.\n1. Importazione della Matrice e Definizione del Vettore b\nViene chiesto di importare una matrice A dalla gallery di MATLAB utilizzando un comando specifico (non riportato esattamente nel testo, ma si intuisce che sia un comando per caricare una matrice predefinita) e di definire un vettore b composto da tutti 1 di dimensione compatibile con A.\n2. Calcolo del Condizionamento con condest\nViene introdotto il comando condest(A) per stimare il numero di condizionamento della matrice A. condest è una funzione più efficiente (meno onerosa computazionalmente) rispetto a cond(A) per matrici di grandi dimensioni, fornendo un’approssimazione del numero di condizionamento. Il numero di condizionamento fornisce una misura della “sensibilità” della soluzione del sistema lineare rispetto a perturbazioni nei dati. Un numero di condizionamento elevato indica un problema mal condizionato, dove piccoli errori nei dati possono portare a grandi errori nella soluzione, e la convergenza dei metodi iterativi può essere lenta.\n3. Utilizzo della Funzione PCG\nLa funzione PCG è l’implementazione MATLAB del metodo del gradiente coniugato precondizionato. Per comprenderne l’utilizzo, è fondamentale consultare la documentazione tramite il comando help PCG nella finestra di comando di MATLAB. La sintassi base è:\nx = pcg(A, b)\n\nche risolve il sistema Ax = b utilizzando il gradiente coniugato precondizionato con parametri di default.\nPCG accetta anche opzioni aggiuntive come la tolleranza sulla norma del residuo, il numero massimo di iterazioni, e la matrice di precondizionamento M (tale che M^{-1} \\approx A^{-1}). La sintassi estesa può essere:\n[x, flag, relres, iter, resvec] = pcg(A, b, tol, maxiter, M1, M2, x0)\n\nDove:\n\nx: è la soluzione approssimata trovata da PCG.\nflag: è un indicatore di convergenza (0 se converge, diverso da 0 altrimenti).\nrelres: è la norma relativa del residuo finale |b - Ax|_2 / |b|_2.\niter: è il numero di iterazioni eseguite.\nresvec: è un vettore contenente la storia delle norme del residuo ad ogni iterazione.\ntol: è la tolleranza desiderata per la norma relativa del residuo (criterio di arresto).\nmaxiter: è il numero massimo di iterazioni consentite. Se non specificato, il valore di default in MATLAB è 20.\nM1, M2: sono matrici di precondizionamento tali che il precondizionatore effettivo è M^{-1} = M_1 \\times M_2. Spesso si usa solo una matrice M tale che M_1 = M e M_2 = I (matrice identità). Se non viene fornito alcun precondizionatore, PCG esegue il metodo del gradiente coniugato non precondizionato.\nx0: è un guess iniziale per la soluzione.\n\nIl professore ha evidenziato che se non si specifica il numero massimo di iterazioni (maxiter), PCG utilizza un valore di default di 20, che potrebbe non essere sufficiente per la convergenza in alcuni casi. È quindi importante scegliere un valore appropriato basandosi sulla dimensione del problema e sul condizionamento della matrice.\nPer sopprimere l’output di alcuni argomenti di ritorno di PCG che non sono di interesse, si utilizza la tilde (~). Ad esempio, se si è interessati solo alla soluzione x e al numero di iterazioni iter, si può scrivere:\n[x, ~, ~, iter] = pcg(A, b, tol, maxiter);\n\n4. Precondizionamento con la Matrice Tridiagonale di A\nNell’esercizio, viene chiesto di utilizzare come precondizionatore P la matrice tridiagonale inferiore (corretto in “tridiagonale”) della matrice A. Per estrarre la parte tridiagonale di A in MATLAB, si possono utilizzare i comandi diag con offset opportuni per ottenere le diagonali principali, superiore e inferiore, e poi ricostruire la matrice tridiagonale:\nd0 = diag(A);      % Diagonale principale\nd1 = diag(A, 1);   % Diagonale superiore\ndm1 = diag(A, -1); % Diagonale inferiore\nP = diag(d0) + diag(dm1, -1) + diag(d1, 1); % Ricostruzione della matrice tridiagonale\n\nSuccessivamente, si risolve il sistema precondizionato utilizzando PCG fornendo P come precondizionatore (nella posizione di M1 o come unico precondizionatore se non si usa M2):\n[x_prec, ~, ~, iter_prec] = pcg(A, b, tol, maxiter, P);\n\n5. Effetto del Precondizionamento\nIl precondizionamento ha lo scopo di migliorare il condizionamento del sistema lineare, rendendo la convergenza dei metodi iterativi più rapida. Come osservato dal professore nell’esempio, l’utilizzo di un precondizionatore (la matrice tridiagonale di A) ha ridotto il numero di iterazioni necessarie per la convergenza rispetto al caso non precondizionato. Questo è correlato alla diminuzione del numero di condizionamento della matrice precondizionata P^{-1}A (anche se non calcolato esplicitamente nell’esempio).\n6. Interpretazione Visiva del Precondizionamento\nIl professore fornisce un’analogia visiva per spiegare l’effetto del precondizionamento. Ricordando le linee di livello del funzionale quadratico visualizzate nel primo esercizio, nel caso di un sistema mal condizionato, queste linee di livello sono ellissi molto schiacciate. Il metodo del gradiente (e di conseguenza il gradiente coniugato non precondizionato) tende a muoversi con un andamento a “zig-zag” perché le direzioni di massima discesa cambiano bruscamente a causa della forma allungata delle ellissi.\nL’azione di un precondizionatore può essere vista, in modo euristico, come una trasformazione del sistema tale che le linee di livello del nuovo funzionale quadratico associato diventano più simili a dei cerchi. In questo modo, non ci sono direzioni “privilegiate” o sfavorevoli per la discesa, e il metodo iterativo può convergere più direttamente verso il minimo (la soluzione). In pratica, è come se il precondizionatore “dilatasse” le ellissi schiacciate rendendole più “rotonde”.\nIn sintesi, il precondizionamento mira a risolvere un sistema “più ben condizionato”, dove la geometria del problema è più favorevole alla rapida convergenza dei metodi iterativi.\nReferences"},"6--full-note/meccanica---programma":{"slug":"6--full-note/meccanica---programma","filePath":"6- full note/meccanica - programma.md","title":"meccanica - programma","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/meccanica-razionale","3--tag/materiale-di-studio"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-26 18:22\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: meccanica razionale  materiale di studio\nmeccanica - programma\n\n\nCorpo rigido : definizione1 , gradi di libertà. Moto del corpo rigido. Esempi.\n\n\nEsistenza ed unicità  della velocità angolare di un corpo rigido: il teorema di Poisson.\n\n\nEnunciare e dimostrare la legge di distribuzione delle velocita .\n\n\nMoto di un corpo rigido. Moto traslatorio, rototraslatorio, e sottocasi interessanti 1 2 4 5\n\n\nAtto di moto di un corpo rigido 1 2 3.\nEnunciare e dimostrare il teorema di Mozzi.\n\n\nAtto di moto rotatorio. Condizione necessaria e sufficiente. Caso piano: teorema di Eulero e teorema di Chasles.\n\n\nVincoli: definizioni ed esempi.\n\n\nVincoli di mobilità. Discutere il caso del puro rotolamento.\n\n\nCinematica relativa. Enunciare e dimostrare il teorema di Galileo ed il teorema di Coriolis.\n\n\nCentro di massa, definizione e proprieta . Dimostrare la propriet a distributiva. Simmetrie materiali. Esempi.\n\n\nSistemi equivalenti di forze e loro riduzione. Enunciare e di- mostrare il teorema di riduzione.\n\n\nDiscutere il problema del’equilibrio di un punto materiale e di un sistema di punti materiali.\n\n\nLe equazioni cardinali della statica e il problema dell’equilibrio di un sistema meccanico.\n\n\nCondizioni necessarie e sufficienti per l’equilibrio di un corpo rigido e di un sistema di corpi rigidi.\n\n\nSpostamenti virtuali e atti di moto virtuali. Vincoli unilateri e bilateri. Esempi.\n\n\nDefinizione di vincoli ideali. Il principio dei lavori virtuali.\n\n\nPLV. Discutere il caso di sistemi con vincoli olonomi bilateri.\n\n\nPLV. Il caso di sollecitazione attiva conservativa.\n-seconda parte-\n\n\nQuantit a di moto per un sistema. Deduzione della prima equazione cardinale e teorema del moto del baricentro.\n\n\nMomenti di inerzia. Definizione. Enunciare e dimostrare il teo- rema di Huygens-Steiner.\n\n\nTensore di inerzia. Assi principali di inerzia e momenti principali di inerzia.\n\n\nMomento delle quantita  di moto per un sistema di punti materiali, definizione e proprieta  sotto cambiamento del polo. Caso del corpo rigido. Sottocasi interessanti.\n\n\nSeconda equazione cardinale: deduzione ed esempi.\n\n\nEnergia cinetica. Definizione. Teorema di Ko ̈nig. Caso del corpo rigido. Sottocasi interessanti.\n\n\nEnunciare e dimostrare il teorema dell’energia cinetica. Discutere il caso in cui si ottiene un’equazione di moto pura per sistemi vincolati. Dedurre la conservazione dell’energia meccanica nel caso di forze conservative.\n\n\nRelazione simbolica della dinamica ed equazione simbolica della dinamica. Equazioni di Lagrange. Formalismo non conservativo e formalismo conservativo.\n\n\nMoti centrali. Caratteristiche generali.\n\n\nMoti centrali: il caso gravitazionale e il vettore di Runge-Lenz.\n\n\nDinamica relativa. Pseudoforze. Esempi.\n\n\nStabilit a dell’equilibrio. Il teorema di stabilita  di Ljapunov.\n\n\nStabilit a dell’equilibrio. Il teorema di Dirichlet. Enunciare il cri- terio instabilit a di Ljapunov.\n\n\nPiccole oscillazioni. Equazione caratteristica e modi normali.\n\n\nEquazioni di Eulero-Lagrange e principio di minima azione di Hamilton.\n\n\nSimmetrie ed integrali primi del moto. Il teorema di Noether.\n\n\nMeccanica Hamiltoniana. Parentesi di Poisson.\n\n\nMeccanica Hamiltoniana e trasformazioni canoniche.\n\n\nCinematica dei continui. Tensore di deformazione e tensore di Cauchy-Green.\n\n\nMoto di un continuo. Descrizione lagrangiana e descrizione eule- riana.\n\n\nMoti di un continuo. Campi materiali e campi spaziali e loro derivate temporali. Derivata sostanziale.\n\n\nI teoremi della media e di localizzazione. Esempi di utilizzo.\n\n\nConservazione della massa ed equazione di continuit a.\n\n\nForze di volume e forze di superficie. Sforzi.\n\n\nIl teorema di Cauchy e il tensore degli sforzi.\n\n\nEquazione di bilancio per la quantita  di moto di un continuo.\n\n\nEquazione di bilancio per il momento delle quantita  di moto di un continuo e simmetria del tensore degli sforzi.\n\n\nFluidi perfetti e relazioni costitutive.\n\n\nReferences"},"6--full-note/meccanica-lez01":{"slug":"6--full-note/meccanica-lez01","filePath":"6- full note/meccanica-lez01.md","title":"meccanica-lez01","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/meccanica-razionale","3--tag/sbobine"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-02-27 20:37\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:   meccanica razionale   sbobine\nmeccanica-lez01\nVincoli e Reazioni Vincolari\nDefinizione di Vincoli\nI vincoli sono oggetti che limitano i gradi di libertà di un sistema. Essi impongono restrizioni al movimento o alla configurazione del sistema in esame.\nReazioni Vincolari\nLe reazioni vincolari sono forze associate ai vincoli che rappresentano incognite a priori nei problemi di meccanica. La presenza di vincoli e reazioni vincolari complica la determinazione dell’equilibrio o del moto di un sistema.\nProblemi Fondamentali della Meccanica\nStatica\nNella statica, il problema principale consiste nel determinare la configurazione di equilibrio di un sistema soggetta a forze attive. Le forze attive includono la forza gravitazionale, la forza peso, la forza elettrica e la forza elastica, escludendo le reazioni vincolari.\nDinamica\nNella dinamica, l’obiettivo è determinare il moto del sistema a partire dalle condizioni iniziali e dalle forze agenti, tenendo conto delle reazioni vincolari se presenti.\nMeccanica Analitica: Principi Variazionali\nPrincipi Variazionali\nLa meccanica analitica introduce principi variazionali che permettono di determinare le configurazioni di equilibrio (in statica) e il moto (in dinamica) senza dover esplicitamente calcolare le reazioni vincolari.\nPrincipio dei Lavori Virtuali\nIn statica, si utilizza il principio dei lavori virtuali per determinare le configurazioni di equilibrio.\nEquazioni di Eulero-Lagrange\nIn dinamica, si utilizzano le equazioni di Eulero-Lagrange per determinare il moto del sistema.\nPrincipio di Minima Azione\nLa meccanica analitica conduce al principio di minima azione, un concetto fondamentale nella fisica moderna.\nFormalismo della Meccanica Analitica\nPotenza del Formalismo\nLa meccanica analitica sviluppa un formalismo potente che consente di risolvere problemi complessi e che trova applicazioni in diversi settori della fisica.\nRelazione tra Simmetrie e Conservazioni\nUn aspetto importante è la relazione tra le simmetrie della Lagrangiana (o dell’azione) e le leggi di conservazione.\nMeccanica dei Continui\nIntroduzione alla Meccanica dei Continui\nIl corso introduce anche la meccanica dei continui, concentrandosi sui fluidi ideali. Nei continui, si ha a che fare con infiniti gradi di libertà, il che rappresenta un salto rispetto ai sistemi con un numero finito di gradi di libertà.\nTeoria di Campo\nLa meccanica dei continui può essere vista come una teoria di campo, simile al campo elettromagnetico studiato in fisica.\nApproccio Fisico-Matematico\nTeoremi e Dimostrazioni\nLa meccanica razionale, essendo un approfondimento fisico-matematico, utilizza teoremi e dimostrazioni, in modo simile a un corso di analisi matematica.\nAssiomatizzazione\nLa meccanica razionale presenta un’assiomatizzazione dello strumento della meccanica, con ipotesi, teoremi e dimostrazioni.\nAspetti Logistici del Corso\nOrario e Ricevimento\nLe lezioni avranno una durata di un’ora e mezza continuata, senza intervallo. L’orario di ricevimento sarà fissato in seguito.\nBibliografia\nNon esiste un testo di riferimento unico per tutto il corso, ma sono consigliati diversi testi, tra cui il Landau (difficile), il Fasano Marmi (completo ma con lacune), il Cercignani (difficile) e i due volumi dell’Ostrowski (scaricabili gratuitamente).\nEsercitazioni\nLe esercitazioni sono fondamentali e saranno tenute da Stefano Finazzi. Sono strutturate per preparare gli studenti all’esame scritto.\nEsame\nProve in Itinere\nCi saranno due prove in itinere:\n\nLa prima prova in itinere sarà concentrata sugli argomenti di cinematica e statica e consisterà in domande di teoria (con dimostrazioni) ed esercizi.\nLa seconda prova in itinere avrà la stessa struttura, ma sarà focalizzata sulla parte restante del corso (dinamica e continui).\n\nStruttura dell’Esame Standard\nL’esame scritto è composto da una parte teorica (con domande che richiedono dimostrazioni) e da esercizi. La durata complessiva è di circa 2 ore e mezza.\nPunteggio\nI due esercizi valgono 10 punti ciascuno, e la teoria vale 13 punti, per un totale di 33.\nOrale\nL’orale è facoltativo per chi ha superato lo scritto, ma il docente si riserva la possibilità di chiamare all’orale chi è vicino alla sufficienza. Il voto può migliorare o rimanere invariato.\nAppelli\nChi non supera le prove in itinere può recuperare agli appelli successivi.\nMateriale Consentito all’Esame\nAll’esame è consentito portare solo penna e carta. Non sono ammessi formulari o calcolatrici.\nComunicazioni\nEventuali variazioni su esercitazioni o lezioni saranno comunicate via WEB.\nCinematica del Punto Materiale\nDefinizione\nLa cinematica è lo studio del moto a prescindere dalle cause.\nMoto del Punto Materiale\nPer descrivere il moto di un punto materiale, è necessario specificare la sua posizione in funzione del tempo rispetto a un osservatore.\nGradi di Libertà\nI gradi di libertà (GDL) sono le coordinate necessarie per descrivere completamente il moto del sistema. Per un punto materiale nello spazio, ci sono tre gradi di libertà.\nTraiettoria\nLa traiettoria è la curva descritta dal punto materiale nel suo moto.\nVelocità e Accelerazione\nLa velocità è la derivata della posizione rispetto al tempo, e l’accelerazione è la derivata della velocità rispetto al tempo.\nSistemi di N Punti Materiali\nUn sistema di n punti materiali ha 3n gradi di libertà, a meno che non siano presenti vincoli.\nVincoli di Posizione\nI vincoli di posizione limitano le configurazioni accessibili al sistema e riducono i gradi di libertà.\n\nEsempio: Un anellino su una sbarra ha un solo grado di libertà.\n\nCorpo Rigido\nDefinizione\nUn corpo rigido è un oggetto indeformabile in cui le mutue distanze tra i punti rimangono costanti nel tempo.\nModello Matematico\nIl corpo rigido è descritto come un sistema di n punti materiali soggetti al vincolo di rigidità.\nVincolo di Rigidità\nIl vincolo di rigidità impone che la distanza tra due punti qualsiasi del corpo rigido rimanga costante:\n|P_i - P_j| = \\text{costante} per ogni i, j con i \\neq j\nGradi di Libertà del Corpo Rigido\nUn corpo rigido nello spazio ha sei gradi di libertà.\nTerna Solidale\nPer descrivere il moto di un corpo rigido, si associa ad esso una terna d’assi solidale.\n\nSi scelgono tre punti non allineati A, B, e C del corpo rigido.\nA è l’origine degli assi.\nB individua il primo asse X.\nC individua il piano XY, e l’asse Y è ortogonale a X nel semipiano contenente C.\nL’asse Z è determinato dalla regola della mano destra.\n\nDescrizione del Moto\nLa posizione di un punto generico P del corpo rigido è descritta dal vettore P - O, dove O è l’origine del sistema di riferimento fisso. Questo vettore può essere scomposto come:\nP - O = P - A + A - O\nAssegnare l’origine A costa 3 gradi di libertà traslazionali, dati da x_A(t), y_A(t), e z_A(t).\nSpero che questa rielaborazione dettagliata ti sia utile!\n\nCertamente, ecco una rielaborazione dettagliata della spiegazione del professore, integrando i concetti chiave, le formule matematiche e gli esempi forniti nel flashcard, riscritta in LaTeX.\nLimiti delle Teorie Fisiche\nLimiti Considerati\nIn fisica, si considerano solitamente tre limiti fondamentali nello sviluppo delle teorie:\n\nVelocità piccole rispetto alla velocità della luce (v &lt;&lt; c).\nEffetti quantistici trascurabili (h \\to 0, dove h è la costante di Planck).\nCampi gravitazionali deboli.\n\nMeccanica Analitica Classica\nNella meccanica analitica classica, tutti e tre i limiti devono essere soddisfatti:\n\nVelocità basse per evitare la relatività speciale.\nAssenza di effetti quantistici.\nCampi gravitazionali deboli per usare la legge di gravitazione universale di Newton.\n\nAltre Teorie\n\nMeccanica Relativistica: Rilassa il vincolo sulle velocità, mantenendo gli altri due.\nRelatività Generale: Rilassa il vincolo sui campi gravitazionali.\nMeccanica Quantistica Non Relativistica: Mantiene i limiti su velocità e campi gravitazionali deboli.\nTeoria Quantistica dei Campi: Rilassa solo il vincolo sulle velocità.\n\nTeoria del Tutto\nLa teoria che rilassa tutti i vincoli è oggetto di ricerca e discussione, ma non è ancora generalmente accettata o verificata sperimentalmente.\nEredità della Meccanica Analitica\nI concetti di Lagrangiana e Hamiltoniana sono ereditati e reinterpretati in tutte queste teorie, sebbene con formalismi differenti.\nCinematica del Punto Materiale\nDefinizione\nLa cinematica è lo studio del moto a prescindere dalle cause.\nMoto del Punto Materiale\nPer descrivere il moto di un punto materiale, è necessario specificare la sua posizione in funzione del tempo rispetto a un osservatore. L’osservatore è definito da un orologio e una terna di assi.\nRappresentazioni del Vettore Posizione\nIl vettore posizione può essere indicato in vari modi:\n\n\\vec{P}(t) (notazione tradizionale, meno utilizzata nel corso)\nP(t) (con P sottolineato)\nP - O(t) (dove P è la punta e O è la coda del vettore)\nP(t) (con P maiuscola e sottolineata, per indicare il vettore)\n\nCoordinate e Versori\nIl vettore posizione può essere espresso come:\nP(t) = x(t) \\hat{i} + y(t) \\hat{j} + z(t) \\hat{k}\ndove x(t), y(t), z(t) sono le coordinate del punto in funzione del tempo, e \\hat{i}, \\hat{j}, \\hat{k} sono i versori degli assi cartesiani.\nGradi di Libertà\nI gradi di libertà (GDL) sono le coordinate necessarie per descrivere completamente il moto del sistema. Per un punto materiale nello spazio, ci sono tre gradi di libertà.\nTraiettoria\nLa traiettoria è la curva descritta dal punto materiale nel suo moto.\nVelocità e Accelerazione\nLa velocità è la derivata della posizione rispetto al tempo, e l’accelerazione è la derivata della velocità rispetto al tempo:\n\nVelocità: v(t) = \\frac{dP(t)}{dt}\nAccelerazione: a(t) = \\frac{d^2P(t)}{dt^2}\n\nSistemi di N Punti Materiali\nUn sistema di n punti materiali ha 3n gradi di libertà, a meno che non siano presenti vincoli.\nVincoli di Posizione\nI vincoli di posizione limitano le configurazioni accessibili al sistema e riducono i gradi di libertà.\nEsempio: Un anellino su una sbarra:\n\nHa un solo grado di libertà.\nPuò traslare solo lungo l’asse della sbarra.\n\nEsempio: Punto materiale vincolato a un piano:\n\nHa due gradi di libertà.\nPuò muoversi solo nel piano.\n\nCorpo Rigido\nDefinizione\nUn corpo rigido è un oggetto indeformabile in cui le mutue distanze tra i punti rimangono costanti nel tempo.\nModello Matematico\nIl corpo rigido è descritto come un sistema di n punti materiali soggetti al vincolo di rigidità.\nVincolo di Rigidità\nIl vincolo di rigidità impone che la distanza tra due punti qualsiasi del corpo rigido rimanga costante:\n|P_i - P_j| = R = \\text{costante} \\quad \\forall i, j \\text{ con } i \\neq j\ndove P_i e P_j sono punti del corpo rigido, e R è una costante.\nGradi di Libertà del Corpo Rigido\nUn corpo rigido nello spazio ha sei gradi di libertà. Nel piano, ne ha tre.\nTerna Solidale\nPer descrivere il moto di un corpo rigido, si associa ad esso una terna di assi solidale.\nProcedimento per definire la terna solidale:\n\nSi scelgono tre punti non allineati A, B, e C del corpo rigido.\nA è l’origine degli assi.\nB individua il primo asse X.\nC individua il piano XY, e l’asse Y è ortogonale a X nel semipiano contenente C.\nL’asse Z è determinato dalla regola della mano destra.\n\nDescrizione del Moto\nLa posizione di un punto generico P del corpo rigido è descritta dal vettore P - O, dove O è l’origine del sistema di riferimento fisso. Questo vettore può essere scomposto come:\nP - O = P - A + A - O\nAssegnare l’origine A costa 3 gradi di libertà traslazionali, dati da x_A(t), y_A(t), e z_A(t).\nReferences"},"6--full-note/meccanica-lez02":{"slug":"6--full-note/meccanica-lez02","filePath":"6- full note/meccanica-lez02.md","title":"meccanica-lez02","links":["tags/flashcard_finite","tags/riscritto_finito","tags/revisione_finita","3--tag/sbobine","3--tag/meccanica-razionale"],"tags":["flashcard_finite","riscritto_finito","revisione_finita"],"content":"2025-02-27 20:47\n_Status: flashcard_finite   riscritto_finito   revisione_finita\n_Tags:   sbobine   meccanica razionale]\nmeccanica-lez02\nGradi di Libertà di un Corpo Rigido\nUn corpo rigido, nello spazio, possiede sei gradi di libertà: tre traslazionali e tre rotazionali.\n\nGradi di libertà traslazionali: sono legati al vettore \\underline{OA}, che individua l’origine degli assi solidali rispetto agli assi fissi. Per descrivere \\underline{OA}, servono tre coordinate, che rappresentano i gradi di libertà traslazionali.\nGradi di libertà rotazionali: sono legati all’orientamento del corpo rigido nello spazio. Per descrivere l’orientamento, si utilizzano i versori solidali, che si muovono rispetto alla terna fissa. \n\nVettore Solidale\n\nIl vettore \\underline{P-A} è un vettore solidale, ovvero le sue componenti (x_p, y_p, z_p) sono costanti rispetto alla terna mobile. In termini matematici, si scrive come:\n(P - O) = (P - A) + (A - O)\n\\underline{P-A} = x_p \\hat{i} + y_p \\hat{j} + z_p \\hat{k}\ndove \\hat{i}, \\hat{j}, \\hat{k} sono i versori degli assi solidali.\nComponenti dei Versori Solidali e Coseni Direttori\nPer descrivere l’orientamento dei versori solidali rispetto a quelli fissi, si cercano le componenti dei versori solidali rispetto a quelli fissi. Queste componenti sono i coseni direttori. Si ottengono nove coseni direttori, ma non sono tutti indipendenti.\n\\begin{cases} \\hat{i} \\cdot \\hat{I},\\\\ \\hat{i} \\cdot \\hat{J},\\\\ \\hat{i} \\cdot \\hat{K},\\\\ \\hat{j} \\cdot \\hat{I},\\\\ \\hat{j} \\cdot \\hat{J},\\\\ \\hat{k} \\cdot \\hat{j},\\\\ \\hat{k} \\cdot \\hat{I},\\\\ \\hat{k} \\cdot \\hat{J},\\\\ \\hat{k} \\cdot \\hat{K} \\end{cases}\nCi sono sei relazioni tra di loro dovute alle condizioni di ortogonalità e normalizzazione dei versori:\n\nCondizioni di ortonormalità:\n\n\\hat{i} \\cdot \\hat{i} = 1\n\\hat{j} \\cdot \\hat{j} = 1\n\\hat{k} \\cdot \\hat{k} = 1\n\\hat{i} \\cdot \\hat{j} = 0\n\\hat{i} \\cdot \\hat{k} = 0\n\\hat{j} \\cdot \\hat{k} = 0\n\n\n\nQueste sei relazioni riducono i gradi di libertà rotazionali a tre.\nAngoli di Eulero: Descrizione e Rotazioni\nGli angoli di Eulero forniscono un metodo per descrivere l’orientamento di un corpo rigido nello spazio attraverso tre rotazioni successive. Questi angoli sono particolarmente utili per definire l’orientamento di una terna mobile rispetto a una terna fissa.\nDefinizione degli Angoli\n\n\n\\phi (angolo di precessione): rappresenta la rotazione attorno all’asse Z. \\phi \\in [0, 2\\pi].\n\\theta (angolo di nutazione o co-latitudine): rappresenta l’angolo tra l’asse Z e l’asse z. \\theta \\in [0, \\pi].\n\\psi (angolo di rotazione propria): rappresenta la rotazione attorno all’asse z. \\psi \\in [0, 2\\pi].\n\nNota: L’ordine degli angoli \\phi e \\psi può variare a seconda della convenzione utilizzata.\nAsse dei Nodi\nL’asse dei nodi (N) è la linea di intersezione tra il piano XY (della terna fissa) e il piano xy (della terna mobile). Matematicamente, il versore \\hat{n} dell’asse dei nodi è definito come:\n\\qquad \\hat{n} = \\frac{\\underline{K} \\wedge \\underline{k}}{|\\underline{K} \\wedge \\underline{k}|}\ndove \\underline{K} e \\underline{k} sono i versori degli assi Z e z, rispettivamente.\nRotazioni di Eulero: Procedura\nLe tre rotazioni di Eulero, eseguite in un ordine specifico, permettono di far coincidere gli assi della terna mobile con quelli della terna fissa.\n\nPrima rotazione: Ruotare attorno all’asse Z di un angolo \\phi in modo che l’asse X coincida con l’asse dei nodi N.\nSeconda rotazione: Ruotare attorno all’asse dei nodi N di un angolo \\theta in modo che l’asse Z coincida con l’asse z.\nTerza rotazione: Ruotare attorno all’asse z di un angolo \\psi.\n\nDopo queste tre rotazioni, le due terne di riferimento (fissa e mobile) sono allineate.\nImportante: L’ordine delle rotazioni è fondamentale, poiché le matrici di rotazione non commutano. Se si cambia l’ordine delle rotazioni, il risultato finale sarà diverso.\nSingolarità\nSi verifica una singolarità quando i piani XY e xy coincidono, rendendo indefinita l’intersezione e quindi l’asse dei nodi. Questa singolarità è analoga a quella che si incontra nel passaggio da coordinate cartesiane a coordinate polari quando l’origine è descritta in coordinate polari. Tuttavia, questa singolarità non invalida la descrizione del moto con gli angoli di Eulero. Inoltre, questa problematica non si presenta nel caso di corpi rigidi piani, dove i piani XY e xy coincidono sempre.\nOrigine dei Nomi\nI nomi degli angoli di Eulero (precessione, nutazione, rotazione propria) derivano dalla descrizione del moto della Terra.\n\nLa rotazione propria è la rotazione della Terra attorno al suo asse.\nLa precessione è il moto conico dell’asse terrestre rispetto alle stelle fisse. L’asse terrestre compie una precessione completa in circa 26.000 anni.\nLa nutazione è una piccola oscillazione dell’asse terrestre attorno al suo valore medio, causata dalle forze di marea del Sole e della Luna. Questo moto rende il cono di precessione irregolare.\n\nTeorema di Poisson: Velocità Angolare e Derivata dei Versori\nIl teorema di Poisson è un teorema fondamentale nella cinematica del corpo rigido. Esso stabilisce l’esistenza e l’unicità di un vettore velocità angolare \\underline{\\omega}. Questo vettore permette di descrivere come variano nel tempo i versori solidali al corpo rigido.\nEnunciato del Teorema\nSia \\mathcal{B} un corpo rigido e siano \\underline{e_1}, \\underline{e_2}, \\underline{e_3} i versori di una terna solidale a B. Allora, esiste un unico vettore \\underline{\\omega} (velocità angolare) tale che:\n\\qquad \\dot{\\underline{e_i}} = \\underline{\\omega} \\wedge \\underline{e_i}\nper i = 1, 2, 3.\nNota: \\dot{\\underline{e_i}} rappresenta la derivata temporale del versore \\underline{e_i}.\nInoltre, \\underline{\\omega} non dipende dalla scelta della terna solidale. Per ogni vettore \\underline{w} solidale al corpo rigido, vale:\n\\qquad \\dot{\\underline{w}} = \\underline{\\omega} \\wedge \\underline{w}\ne vale\nSi definisce il vettore \\underline{\\omega} come:\n\\qquad \\underline{\\omega} = \\frac{1}{2}\\sum_{i=1}^{3} \\underline{e_i} \\wedge \\dot{\\underline{e_i}}\nDimostrazione dell&#039;Esistenza\nPer dimostrare che questo \\underline{\\omega} soddisfa le formule di Poisson, si considera \\underline{\\omega} \\wedge \\underline{e_1} e si dimostra che è uguale a \\dot{\\underline{e_1}}.\n\\qquad \\frac {1}{2} \\Bigr[\\sum_{i=1}^{3} (\\underline{e_i} \\wedge \\dot{\\underline{e_i}})\\Bigl] \\wedge \\underline{e_1}= \nper proprietà distributiva:\n\\qquad =\\frac {1}{2} \\sum_{i=1}^{3} (\\underline{e_i} \\wedge \\dot{\\underline{e_i}}) \\wedge \\underline{e_1}= \nallora effettuiamo un doppio scambio:\n=\\frac{1}{2} \\sum_{i=1}^{3} \\underline e_1 \\wedge (\\dot{\\underline {e_i}} \\wedge \\underline {e_i}) =\n\n\nUtilizzando le proprietà del prodotto scalare e vettoriale \\underline a \\wedge (\\underline b \\wedge \\underline c) = (\\underline a \\cdot \\underline c) \\underline b - (\\underline a \\cdot \\underline b) \\underline c\nsi ha:\n= \\sum_{i=1}^{3} \\Bigr[( \\underline{e_1} \\cdot {\\underline{e_i}} )\\dot{\\underline{e_i}}  -  ( \\underline{e_1} \\cdot \\dot{\\underline{e_i}} )\\underline{e_i}]=\n\nvale la relazione \\frac{d}{dt}(\\underline{e}_i \\cdot \\underline{e}_j) = \\dot{\\underline{e}}_i \\cdot \\underline{e}_j + \\underline{e}_i \\cdot \\dot{\\underline{e}}_j = 0 \\Rightarrow \\dot{\\underline{e}}_i \\cdot \\underline{e}_j = - \\underline{e}_i \\cdot \\dot{\\underline{e}}_j\nallora l’equazione continua:\n= \\frac{1}{2} \\sum_{i=1}^{3} \\left[ (\\underline{e_1} \\cdot \\underline{e_i})\\ \\ \\dot{\\underline{e_i}} + \\underline{(\\underline e_i \\cdot \\dot{\\underline{e_1}})} \\ \\ \\underline e_i \\right]=\ndi = \\frac{1}{2} \\sum_{i=1}^{3} (\\underline{e_1} \\cdot \\underline{e_i}) ci rimane solo il contributo  e_1 , quindi complessivamente ci rimane \\underline{\\dot e_1}\n\n\n\nricordando che si può scrivere un vettore come somma dei suoi componenti\n\n\\underline{a} = (\\underline{a} \\cdot \\underline{e}_1) \\underline{e}_1 + (\\underline{a} \\cdot \\underline{e}_2) \\underline{e}_2 + (\\underline{a} \\cdot \\underline{e}_3) \\underline{e}_3 = \\sum_{i=1}^{3} a_i \\underline{e}_i \\\\\\underline{a} = a_i \\underline{e}_i\ndove a_i = a\\cdot e_i\nsi può descrivere \\dot{\\underline{e_1}} come: \\frac{1}{2} \\sum_{i=1}^{3} \\left[ (\\underline e_i \\cdot \\dot{\\underline{e_1}}) \\ \\ \\underline e_i \\right]= \\dot{\\underline{e_1}}\nallora si ottiene\n= \\frac{1}{2}  (\\dot {\\underline{e_1}}+ \\dot{\\underline{e_1}})= \\dot{\\underline{e_1}}\nallora si ottiene\n\n\n\n\\qquad \\underline{\\omega} \\wedge \\underline{e_1} = \\dot{\\underline{e_1}}\nper \\omega \\wedge e_2 o con tre è analogo\nUnicità\nSi assume che esistano due vettori velocità angolari, \\underline{\\omega} e \\underline{\\omega^*}, che soddisfano le formule di Poisson. Si ha quindi:\n\\qquad \\dot{\\underline{e_i}} = \\underline{\\omega} \\wedge \\underline{e_i} = \\underline{\\omega^*} \\wedge \\underline{e_i}\nSottraendo membro a membro, si ottiene:\n\\qquad \\underline{0} = (\\underline{\\omega} - \\underline{\\omega^*}) \\wedge \\underline{e_i} per i=1,2,3\nQuesto implica che \\underline{\\omega} - \\underline{\\omega^*} deve essere parallelo a tutti e tre i versori \\underline{e_i} IMPOSSIBILE, il che è possibile solo se \\underline{\\omega} = \\underline{\\omega^*}. Quindi, la velocità angolare è unica.\nDimostrazione Algebrica dell’Unicità\nSia \\underline{\\Omega} = \\underline{\\omega} - \\underline{\\omega^*}. Possiamo scrivere \\underline{\\Omega} usando la terna mobile dei versori:\n\\qquad \\underline{\\Omega} = \\sum_{i=1}^{3} \\Omega_i \\underline{e_i}\nConsiderando \\underline{\\Omega} \\wedge \\underline{e_1} = 0:\n\\qquad \\underline{\\Omega} \\wedge \\underline{e_1} = \\Omega_2 (\\underline{e_2} \\wedge \\underline{e_1}) + \\Omega_3 (\\underline{e_3} \\wedge \\underline{e_1}) = -\\Omega_2 \\underline{e_3} + \\Omega_3 \\underline{e_2} = 0\nQuesto implica che \\Omega_2 = 0 e \\Omega_3 = 0.\nSimilmente facendo \\underline{\\Omega} \\wedge \\underline{e_2}, si dimostra che anche u_1 = 0. Pertanto, \\underline{\\Omega} = 0, e quindi \\underline{\\omega} = \\underline{\\omega^*}. \nVettore Solidale e Derivata Temporale\nConsideriamo un vettore solidale \\omega. Le componenti di un vettore solidale sono costanti. Quando calcoliamo la derivata temporale di \\omega, otteniamo \\omega.\nSe usiamo una terna mobile, la derivata sarebbe la derivata delle componenti per il versore, più il versore per la derivata delle componenti, e così via. Tuttavia, poiché le componenti sono costanti, ci rimane:\n\\qquad \\dot{\\omega} = w_1 \\dot{e}_1 + w_2 \\dot{e}_2 + w_3 \\dot{e}_3\nUsando la relazione \\dot{e}_i = \\omega \\wedge e_i (derivata dei versori della terna solidale aka Poisson) possiamo scrivere:\n\\qquad \\dot{\\omega} = w_1 (\\omega \\wedge e_1) + w_2 (\\omega \\wedge e_2) + w_3 (\\omega \\wedge e_3)\nPoiché le componenti w_i sono scalari, possiamo portarle davanti al prodotto vettoriale:\n\\qquad \\dot{\\omega} = \\omega \\wedge (w_1 e_1 + w_2 e_2 + w_3 e_3)\nIl termine tra parentesi è il vettore \\omega stesso, quindi:\n\\qquad \\dot{\\omega} = \\omega \\wedge \\omega\nQuindi, se hai un vettore solidale, soddisferà \\dot{\\omega} = \\omega \\wedge \\omega.\nIndipendenza dalla Terna\nL’indipendenza dalla terna si dimostra notando che i versori e_i sono solidali e quindi \\dot{e&#039;}_i = \\omega \\wedge {e&#039;}_i.\nd\nLa legge di distribuzione delle velocità è un altro teorema fondamentale nella cinematica del corpo rigido. Essa fornisce una caratterizzazione del moto rigido.\nEnunciato: Condizione necessaria e sufficiente affinché un sistema di n punti materiali sia in moto rigido è che valga:\n\\qquad \\underline{v_P}(t) = \\underline{v_Q}(t) + \\underline{\\omega}(t) \\wedge (\\underline{P} - \\underline{Q})(t)\nper ogni P e Q appartenenti al sistema di punti materiali. \nSignificato: La velocità di un punto P è uguale alla velocità di un altro punto Q più un termine che dipende dalla velocità angolare e dalla posizione relativa dei due punti.\nReferences"},"6--full-note/meccanica-lez03":{"slug":"6--full-note/meccanica-lez03","filePath":"6- full note/meccanica-lez03.md","title":"meccanica-lez03","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_finita","3--tag/sbobine","3--tag/meccanica-razionale"],"tags":["flashcard_zero","riscritto_zero","revisione_finita"],"content":"2025-02-28 13:08\n_Status: flashcard_zero  riscritto_zero  revisione_finita\n_Tags:   sbobine   meccanica razionale\nmeccanica-lez03\nLegge di Distribuzione delle Velocità\nLa legge di distribuzione delle velocità è un teorema fondamentale nella cinematica del corpo rigido. Essa fornisce una condizione necessaria e sufficiente affinché un sistema generico di n punti materiali sia in moto rigido. Essere in moto rigido significa che il vincolo di rigidità è rispettato. La condizione è espressa come segue:\nV_P = V_Q + \\omega \\times (P - Q)\ndove:\n\nV_P è la velocità del punto P\nV_Q è la velocità del punto Q\n\\omega è la velocità angolare\nP e Q sono punti appartenenti al sistema rigido\n\nQuesta condizione deve valere per ogni coppia di punti P e Q nel sistema.\nDimostrazione\nLa dimostrazione si articola in due parti: condizione necessaria e condizione sufficiente. \nCondizione Necessaria\nSi considera il corpo rigido S, e si assume che il vincolo di rigidità sia soddisfatto per ipotesi. Si considera il vettore P - Q e la sua derivata rispetto al tempo:\n\\frac{d}{dt}(P - Q) = V_P - V_Q\nPoiché P - Q è un vettore solidale al corpo rigido, la sua derivata rispetto al tempo è data da:\n\\frac{d}{dt}(P - Q) = \\omega \\times (P - Q)\nQuindi, la condizione necessaria è:\nV_P - V_Q = \\omega \\times (P - Q)\nCondizione Sufficiente\nSi assume che valga la legge di distribuzione delle velocità (LDV ) e si vuole dimostrare che il vincolo di rigidità è soddisfatto. Questo significa che la distanza tra due punti qualsiasi P e Q del sistema deve rimanere costante nel tempo:\n|P - Q| = \\text{costante}\nUn modo equivalente per esprimere questa condizione è che la derivata rispetto al tempo del modulo di P - Q sia uguale a zero:\n\\frac{d}{dt}|P - Q| = 0\nPer semplificare la dimostrazione, si considera la derivata rispetto al tempo del modulo quadro di P - Q:\n\\frac{d}{dt}|P - Q|^2 = 2 |P - Q| \\frac{d}{dt}|P - Q|\nPer P \\neq Q, la derivata rispetto al tempo di |P - Q|^2 è uguale a zero se e solo se la derivata del modulo |P - Q|è zero.\nSi utilizza la relazione:\n|P - Q|^2 = (P - Q) \\cdot {(P - Q) = (P - Q)}^2\n\n(ricalco che non è uguale il modulo di un vettore al vettore stesso)\n\nQuindi, si calcola la derivata rispetto al tempo di (P - Q) \\cdot (P - Q):\n\\frac{d}{dt}[(P - Q) \\cdot (P - Q)] = 2 (P - Q) \\cdot \\frac{d}{dt}(P - Q)\n= 2 (P - Q) \\cdot (V_P - V_Q)\n\nNON SI PUO USARE POISSON (ancora), non sappiamo se è un corpo rigido.\n\nUtilizzando la legge di distribuzione delle velocità (valida per ipotesi), si sostituisce V_P - V_Q con \\omega \\times (P - Q):\n= 2 (P - Q) \\cdot [\\omega \\times (P - Q)]\nIl prodotto scalare tra P - Q e un vettore \\omega \\times (P - Q) che è, per definizione del prodotto vettoriale, ortogonale a P - Q è zero. Quindi:\n2 (P - Q) \\cdot [\\omega \\times (P - Q)] = 0\nQuesto dimostra che la derivata rispetto al tempo di |P - Q|^2 è zero, e quindi il vincolo di rigidità è soddisfatto. \nLegge di Distribuzione delle Accelerazioni\nLa legge di distribuzione delle accelerazioni si ricava derivando rispetto al tempo la legge di distribuzione delle velocità:\na_P = a_Q + \\dot{\\omega} \\times (P - Q) + \\omega \\times [\\omega \\times (P - Q)]\n\\forall P,Q \\in \\mathcal{B} \\ \\ \\text{e} \\ \\forall t\ndove:\n\na_P è l’accelerazione del punto P\na_Q è l’accelerazione del punto Q\n\\dot{\\omega} è la derivata temporale della velocità angolare \\omega\n\nDerivazione\nSi parte dalla legge di distribuzione delle velocità:\nV_P = V_Q + \\Omega \\times (P - Q)\nSi deriva rispetto al tempo:\na_P = \\frac{d}{dt}V_P = \\frac{d}{dt}[V_Q + \\omega \\times (P - Q)]\na_P = a_Q + \\dot{\\omega} \\times (P - Q) + \\omega \\times \\frac{d}{dt}(P - Q)\nessendo P - Q un vettore solidale \\frac{d}{dt}(P - Q) = \\omega \\times (P - Q), si ottiene:\na_P = a_Q + \\dot{\\omega} \\times (P - Q) + \\omega \\times [\\omega \\times (P - Q)]\nSpostamento\nLo spostamento infinitesimo dP è dato da:\ndP = dQ + \\gamma \\times (P - Q)\ndove \\gamma = \\omega dt.\ninfatti\n\\frac{dP}{dt} = \\frac{dP}{dt} + \\underline{\\omega} \\wedge (P - Q) e &quot;&quot;&quot;&quot;moltiplichiamo per dt&quot;&quot;&quot;&quot;&quot;\nMoto di un Corpo Rigido: Descrizione Generale\nAssegnare il moto di un corpo rigido T, visto come un sistema di n punti materiali con vincolo di rigidità, è univocamente determinato se sono note le posizioni dei punti P_i(t) appartenenti al corpo in funzione del tempo per i = 1, \\dots, n.\nPer definire completamente il moto di un corpo rigido nello spazio tridimensionale, sono necessari sei gradi di libertà (GDL):\n\n3 GDL traslazionali, legati all’origine: X_A(t), Y_A(t), Z_A(t).\n3 GDL rotazionali, rappresentati dagli angoli di Eulero: \\theta(t), \\psi(t), \\varphi(t).\n\n\n==Moto Traslatorio\nDefinizione\nNel moto traslatorio, ogni direzione solidale al corpo mantiene un’orientazione invariante rispetto agli assi fissi. In altre parole, qualsiasi retta “conficcata” nel corpo rigido non cambia la sua orientazione rispetto al sistema di riferimento fisso mentre il corpo si muove.\n\n“moto di B tale se ogni direzione solidale a \\mathcal{B} mantiene orientazione invariante rispetto agli assi fissi ⇒ gli assi solidali hanno orientazione invariante”\n\nCondizione Necessaria e Sufficiente\nUn corpo è in moto traslatorio se e solo se la sua velocità angolare (\\omega) è uguale a zero. \\omega = 0 Questo implica che gli angoli di Eulero rimangono costanti.\nTeorema\nDati \\underline{\\dot{e_i}} versori invarianti, allora \\underline{\\dot{e_i}} = 0 per ogni i da 1 a 3, dove e_i sono i versori degli assi solidali allora \\qquad \\underline{\\omega} = \\frac{1}{2}\\sum_{i=1}^{3} \\underline{e_i} \\times \\dot{\\underline{e_i}}=0\nViceversa, \\omega=0 implica \\dot{\\underline{e_i}}= \\omega \\wedge \\underline{e_i}=0.\nGradi di Libertà\nIl moto roto-traslatorio ha 3 gradi di libertà: tre traslazionali e uno rotazionale\ni 3 GDL traslazionali X_A(t), Y_A(t), Z_A(t)\nAspettativa ingenua vs. Realtà\nL’aspettativa più comune è che il moto traslatorio sia rettilineo, ovvero lungo una linea retta. Tuttavia, la definizione rigorosa permette anche moti traslatori non rettilinei.\nEsempi\n\nMoto traslatorio rettilineo: Una lamina rettangolare vincolata a traslare lungo una direzione X. In questo caso, gli assi solidali alla lamina non cambiano orientazione mentre la lamina si sposta.\n\n\n\n\nMoto traslatorio non rettilineo: Un’asta (AB) in un sistema di tre aste collegate tramite cerniere. L’asta AB trasla, ma il suo moto non è rettilineo. Gli assi solidali all’asta rimangono sempre orizzontali, mantenendo l’orientazione invariante rispetto agli assi fissi.\n\n\n\n\nRuota panoramica: Il seggiolino di una ruota panoramica, se ben costruito, si muove di moto traslatorio. Gli assi solidali al seggiolino mantengono un’orientazione invariante mentre la ruota gira (trascurando il vasculamento). ^ssqjiw\n\n\n\n\n\nMoto Roto-Traslatorio\nDefinizione\nUn corpo \\mathcal{B} è in moto roto-traslatorio se esiste una direzione privilegiata solidale al corpo che mantiene un’orientazione invariante rispetto agli assi fissi.\nQuesta è una condizione meno restrittiva rispetto al moto traslatorio.\nDirezione Privilegiata\nLa direzione privilegiata è una retta “conficcata” nel corpo rigido che mantiene la sua orientazione rispetto al sistema di riferimento fisso.\nteorema\nUn corpo è in moto rotatorio se e solo se la velocità angolare (\\omega) ha direzione costante. In questo caso, la direzione di \\omega coincide con la direzione privilegiata.\ndimostrazione\nSia \\underline k un versore solidale alla direzione invariante\nAllora \\underline {\\dot k}=0\nvale Poisson: \\underline {\\dot k}= \\underline\\omega \\wedge \\underline k = 0, il che implica che \\omega è parallelo a k.\nse viceversa \\underline\\omega=\\omega \\wedge \\underline k ha direzione invariante\nallora \\underline {\\dot k}= \\underline\\omega \\wedge \\underline k = 0\nDescrizione Matematica\n\nAssumiamo che \\underline\\omega = \\omega k, dove k è la direzione privilegiata, e scegliamo \\underline k =\\underline K (cioè, allineiamo gli assi z). Le coordinate X_A(t), Y_A(t) e Z_A(t) descrivono i gradi di libertà traslazionali.\n\nL’angolo \\theta descrive il grado di libertà rotazionale. I versori i e j possono essere scritti in funzione dei versori I e J come: \\underline i = \\cos(\\theta){\\underline I} + \\sin(\\theta){\\underline J} \\underline j = -\\sin(\\theta){\\underline I} + \\cos(\\theta){\\underline J}\n\nNOTA BENE: un buon angolo di rotazione va dalla direzione invariante X a quella solidale x\n\\frac{d\\underline{i}}{dt} = -\\dot{\\theta} \\sin\\theta \\underline{I} + \\dot{\\theta} \\cos\\theta \\underline{J} = \\dot{\\theta} \\underline{j}\n\n\\frac{d\\underline{j}}{dt} = -\\dot{\\theta} \\cos\\theta \\underline{I} - \\dot{\\theta} \\sin\\theta \\underline{J} = -\\dot{\\theta} \\underline{i}\nLa velocità angolare \\omega è data da: \\omega = \\dot{\\theta} k\ninfatti perché vale\n\\dot{\\underline{i}} = \\underline{\\omega} \\wedge \\underline{i} = \\dot{\\theta} \\underline{k} \\wedge \\underline{i} = \\dot{\\theta} \\underline{j}\n\\dot{\\underline{j}} = \\underline{\\omega} \\wedge \\underline{j} = \\dot{\\theta} \\underline{k} \\wedge \\underline{j} = - \\dot{\\theta} \\underline{i}\nGradi di Libertà\nIl moto roto-traslatorio ha quattro gradi di libertà: tre traslazionali e uno rotazionale.\n\n3 GDL traslazionali X_A(t), Y_A(t), Z_A(t).\n1 GDL rotazionale \\theta(t) \n\nMoto Rigido Piano\nDefinizione\nIl moto rigido piano si verifica quando esiste un piano solidale \\pi al corpo rigido \\mathcal{B} che si mantiene sempre parallelo e a distanza costante da un piano invariante fisso \\pi^* è chiamato piano direttore.\nCaratteristiche\n\n\nDirezione Invariante: L’asse perpendicolare al piano solidale è una direzione invariante. Quindi \\hat{k} piccolo coincide con \\hat{K} grande.\nGradi di Libertà: In questo caso, ci sono solo tre gradi di libertà: x_A, y_A e \\theta, dove \\theta è l’angolo di rotazione attorno all’asse z. La coordinata z_A è costante e non rappresenta un grado di libertà.\nCorpo Rigido Piano: Un corpo rigido pianoa \\mathcal{B}_{\\pi} è un corpo rigido i cui punti sono tutti contenuti in un piano e si muovono in quel piano stesso. Esempi includono aste, aste curve, lamine di varia forma, purché contenute nel piano.\n\n\n\n\n\nDescrizione Matematica\nNel moto rigido piano, l’asse z è perpendicolare al piano del moto e coincide con la direzione invariante. La velocità angolare \\omega è data da:\n\\qquad \\underline\\omega = \\dot{\\theta} \\hat{\\underline k}\ndove \\theta è l’angolo di rotazione nel piano.\nRegole per la Costruzione di \\omega\nA seconda dell’orientazione dell’asse z, si possono avere diverse convenzioni per il segno di \\omega:\n\nAsse z uscente (antiorario): \\omega = \\dot{\\theta} , \\hat{k}\nAsse z entrante (orario): \\omega = -\\dot{\\theta} , \\hat{k}\n\nQueste convenzioni derivano dalla relazione tra l’angolo \\theta e un altro angolo \\phi, dove \\phi = \\frac{\\pi}{2} - \\theta, quindi \\dot{\\phi} = -\\dot{\\theta}. \nReferences"},"6--full-note/meccanica-lez04":{"slug":"6--full-note/meccanica-lez04","filePath":"6- full note/meccanica-lez04.md","title":"meccanica-lez04","links":["tags/flashcard_zero","tags/riscritto_finito","tags/revisione_finita","3--tag/sbobine","3--tag/meccanica-razionale"],"tags":["flashcard_zero","riscritto_finito","revisione_finita"],"content":"2025-03-01 21:03\n_Status: flashcard_zero  riscritto_finito   revisione_finita\n_Tags: sbobine   meccanica razionale\nmeccanica-lez04\nCatalogo dei Moti\nMoto Elicoidale\n\nDefinizione: Il moto di un corpo rigido B è elicoidale se esiste una direzione solidale di orientazione invariante rispetto agli assi fissi tale che due punti qualsiasi del corpo hanno velocità parallela a tale direzione.\nFormalmente: Esiste una direzione r invariante tale che \\underline v_P \\parallel r    \\forall P \\in r.\nCaratteristiche:\n\n\nÈ un sotto-caso del moto rototraslatorio.\nPossiede due gradi di libertà: l’angolo di rotazione e la traslazione lungo l’asse.\nk \\parallel {r} e k \\parallel {K}, dove k è il versore dell’asse z solidale al corpo e K è il versore dell’asse fisso.\n\n\nEsempio: Il moto di una vite che si avvita. \n\nMoto Rotatorio\n\nDefinizione: Il moto di un punto P è tale se esiste una direzione {r} invariante rispetto agli assi fissi, tale che i punti su questa direzione hanno velocità nulla.\nFormalmente: Esiste una direzione {R} invariante tale che {v}_t = 0 per ogni t \\in {R}, dove {R} è l’asse di rotazione.\nCaratteristiche:\n\nPossiede un solo grado di libertà.\nÈ un sotto-caso sia del moto rototraslatorio che del moto elicoidale.\n\n\nEsempio: Un cilindro che ruota attorno al suo asse Z. In questo caso, i punti sull’asse di rotazione sono fissi e hanno velocità nulla.\n\n \n\n\n\nEsempio Complesso: Elicottero\nUn esempio che combina diversi tipi di moto è quello di un elicottero.\n\nComponenti:\n\nCarlinga (corpo principale)\nRotore principale\nRotore anti-coppia\n\n\n\nMoti:\n\nCarlinga: moto traslatorio In fase di decollo verticale, trasla senza cambiare orientazione rispetto agli assi fissi.\nRotore principale: Compie un moto elicoidale. I punti sull’asse del rotore hanno velocità verticale parallela all’asse.\nRotore anti-coppia: Esegue un moto rotatorio. L’asse del rotore anti-coppia è la direzione privilegiata. Il rotore anti-coppia serve per stabilizzare il volo della carlinga.\n\n\n\nMoto Polare\n\nDefinizione: Esiste un punto \\underline P fisso, tale che {v}_P = 0 e P appartiene al corpo rigido.\nCaratteristiche:\n\nPossiede tre gradi di libertà, rappresentati dagli angoli di Eulero.\nFissa i gradi di libertà traslazionali, lasciando solo quelli rotazionali.\n\n\nEsempio: Una trottola con un punto fisso. \n\n\nTeorema Fondamentale sulla Rigidità di un Sistema\nEnunciato: Un sistema di n punti materiali è rigido se e solo se la variazione della distanza tra due punti qualsiasi a e b del sistema rimane costante nel tempo.\n\\forall A, B \\in S \\quad \\forall t$$\nla proiezione della velocità sulla congiungente di due punti devono essere uguali in modulo e in verso. \n![[Pasted image 20250228141209.png]]\n\n#### Dimostrazione\n\n1. **Punto di partenza:** La distanza al quadrato tra due punti _B_ e _A_ è costante se il corpo è rigido:\n    \n    $\\frac{d}{dt} (B - A)^2 = \\frac{d}{dt} |B - A|^2= 0$\n    \n2. **Espansione:** $(b - a)^2$ può essere scritto come il prodotto scalare di $(b - a)$ con se stesso:\n    \n    $(b - a)^2 = (b - a) \\cdot (b - a)$\n    \n3. **Derivazione:** Derivando rispetto al tempo, si ottiene:\n    \n    $\\frac{d}{dt} [(b - a) \\cdot (b - a)] = 2 (b - a) \\cdot \\frac{d}{dt} (b - a) = 2 (b - a) \\cdot (\\dot{b} - \\dot{a})$\n    \n4. **Conclusione:** Se la derivata è zero, allora:  \n    \n    $(b - a) \\cdot (\\dot{b} - \\dot{a}) = 0$\n    \n    Questo implica che la proiezione della velocità relativa $(\\dot{b} - \\dot{a})$ lungo la congiungente $(b - a)$ è zero. In altre parole, le proiezioni delle velocità dei due punti lungo la congiungente devono essere uguali in modulo e verso.\n    \n5. **Reciproco:** Se vale la relazione $(b - a) \\cdot (\\dot{b} - \\dot{a}) = 0$ per ogni _a_, _b_ e per ogni tempo _t_, allora $\\frac {1}{2}\\frac{d}{dt} (B - A)^2$\n\t-  il sistema _S_ è rigido o in moto rigido.\n    \n\n**Significato Fisico:** Questo teorema implica che, per  un corpo rigido, le variazioni delle velocità dei punti devono essere tali da non alterare le distanze relative tra i punti stessi.\n\n#### Esempio Esplicativo\n\n- **Caso Rigido:** Consideriamo due punti _A_ e _B_ su un corpo rigido. Se le proiezioni delle loro velocità lungo la congiungente _AB_ sono uguali (sia in modulo che in verso), allora il corpo è rigido.\n- **Caso Non Rigido:** Se le proiezioni sono uguali in modulo ma opposte in verso, il corpo non è rigido. Ad esempio, se i due punti avessero velocità tali da allontanarsi o avvicinarsi lungo la linea che li congiunge, il corpo non manterrebbe la sua rigidità. ^whru5m\n\n### Atto di Moto (ADM)\n\n#### Definizione\n\nL&#039;atto di moto (ADM) di $\\mathcal{B}$ è l&#039;insieme delle velocità di tutti i punti $p_i \\quad di \\quad \\mathcal{B}$ di un corpo rigido in un istante fissato $t_0$.\nFormalmente, è il campo di velocità dei punti del corpo in quell&#039;istante:\n\n${ v_P(t_0)  \\quad P \\in B \\quad \\forall i=1,\\cdots,N}$\n\ndove $B$ rappresenta il corpo rigido.\n\n- **Terminologia:** La definizione di &quot;atto di moto&quot; è attribuita a Maraldi. Nei testi in inglese, questa definizione potrebbe non essere presente.\n- **Stato Cinetico:** L&#039;atto di moto può essere interpretato come lo stato cinetico del corpo rigido all&#039;istante $t_0$, ovvero la conoscenza delle velocità di tutti i suoi punti in quell&#039;istante. ^gmy9yu\n\n#### Distinzione tra Atto di Moto e Moto\n\nÈ fondamentale distinguere tra &quot;atto di moto&quot; e &quot;moto&quot;:\n\n- **Atto di Moto:** Fornisce un&#039;istantanea delle velocità. Non permette di determinare il moto completo del corpo.\n- **Moto:** Descrive l&#039;evoluzione temporale della posizione e dell&#039;orientamento del corpo, fornendo una conoscenza completa del suo movimento.\n\n**Analogia:** Per un punto materiale, l&#039;atto di moto è analogo alla velocità istantanea, mentre il moto è analogo alla traiettoria completa del punto. Conoscere la velocità istantanea in un dato momento non permette di ricostruire l&#039;intera traiettoria.\n\n#### Utilità dell&#039;Atto di Moto\n\nLa conoscenza dell&#039;atto di moto in un intervallo di tempo, combinata con le condizioni iniziali, permette di ricostruire il moto del corpo. ^qh7oz3\n### Tipi di Atto di Moto\n\nFondamentalmente, ci sono quattro tipi di atto di moto, ma nel caso del corpo rigido piano, si riducono a due:\n\n1. **Atto di Moto Traslatorio**: In questo caso, tutti i punti del corpo hanno la stessa velocità in un dato istante. Ciò implica che la velocità angolare $\\omega$ è uguale a zero.\n    \n    - Formalmente, $v_P= v_Q$ per ogni coppia di punti $P$ e $Q$ appartenenti al corpo.\n    - Questo è possibile solo se $\\omega = 0$.\n    - Se un corpo ha un moto traslatorio, il suo atto di moto ha $\\omega = 0$ in ogni istante.\n\n\n2. **Atto di Moto Roto-Traslatorio**: È caratterizzato dalla legge di distribuzione delle velocità. l&#039;atto di moto di B è tale se Esiste una direzione privilegiata $R_{\\underline P}$ tale che ogni direzione $R$ parallela a $R_{\\underline P}$ è luogo di punti con la stessa velocità.\n    \n    - Vale la legge di distribuzione delle velocità: $v_P = v_Q + \\omega \\wedge {P-Q}$, dove $\\omega$ è la velocità angolare e ${P-Q}$ è il vettore che congiunge i punti $P$ e $Q$.\n    - $\\omega$ è parallela a $R_P$.\n    - Se $P$ e $Q$ appartengono a una retta $R$ parallela a $R_P$, allora $v_P = v_Q + \\omega \\wedge {P-Q}$, allora con  ${P-Q} \\in R$  si ha ${P-Q} // \\omega$ e quindi $(\\omega \\wedge {P-Q}=0)$.\n      \n    - Quando si scrive $v_P = v_Q + \\omega \\wedge {P-Q}$, si dice che l&#039;atto di moto è riferito al punto $Q$.\n    - Per definire completamente l&#039;atto di moto, è sufficiente conoscere $P-Q$ e $\\omega$.\n\t    ##### teorema\n\t    un sistema S di N punti materiali (o anche un continuo) è in moto rigido se e solo se l&#039;adm di S è rototraslatorio in ogni istante\n\t    - non c&#039;è bisogno di dimostrarlo visto che si tratta della legge della distribuzione delle velocità\n\n\n3. **Atto di Moto Elicoidale:** L&#039;**atto di moto rototraslatorio** è tale se esiste una direzione $r_M$, detta **asse di Mozzi**, con $r_M$ parallela a $r_P$ (direzione privilegiata), i punti di questo asse hanno velocità parallela alla direzione preferenziale \n    $v_P$ // $r_P$  $\\forall P \\in r_M$.\n\n    \n4. **Atto di Moto Rotatorio**: È un caso particolare dell&#039;atto di moto roto-traslatorio. Si riduce al rotatorio se esiste un asse di istantanea rotazione $R_I // R_p$ tale che i punti su $R_I$ hanno velocità nulla.\n    \n    - $v_P = 0$ per ogni punto $P$ appartenente a $R_I$.\n    - L&#039;asse di moto rotatorio è istantaneo e può cambiare nel tempo. Non è un asse di rotazione fisso per tutta l&#039;eternità.\n    - Avere un atto di moto rotatorio non implica che il moto sia rotatorio. Ad esempio, nel moto polare della trottola, esiste un asse di istantanea rotazione, ma non è fisso.\n    - Se si prende come riferimento un punto sull&#039;asse di istantanea rotazione, l&#039;espressione della velocità si semplifica.\n    - Se $P$ appartiene a $R$, allora $v_Q = \\omega \\times {P-Q}$. ^cykoq0\n\n\n### Corpo Rigido Piano: Centro di Istantanea Rotazione\n\nNel caso di un corpo rigido piano $\\mathcal{B}$, se l&#039;atto di moto è rotatorio, esiste un punto $C$ chiamato **centro di istantanea rotazione**.\n\n- $\\omega$ è perpendicolare al piano e le velocità sono tutte contenute nel piano.\n- Se si trova un punto con velocità nulla, l&#039;atto di moto è rotatorio.\n- L&#039;asse di istantanea rotazione interseca il piano nel punto $C$, che è il centro di istantanea rotazione. Questo punto è anche detto &quot;CIR&quot;.\n\t- $r_I \\cap \\pi = C$ con $r_I \\perp \\pi$ ($r_I // \\underline{\\omega}$)\n- Se si conoscono le velocità di due punti diversi, l&#039;atto di moto è rotatorio.\n- È utile riferirsi al centro di istantanea rotazione quando si studia l&#039;atto di moto, ma non è obbligatorio.\n\n### Invariante Scalare Cinematico\n\n- **Definizione:** L&#039;invariante scalare cinematico è definito come il prodotto scalare tra la velocità di un punto $P$ del corpo rigido e la velocità angolare $\\omega$:\n    \n    $$I = \\underline v_P \\cdot \\underline\\omega$$\n    \n- **Invarianza:** Questo valore è invariante rispetto alla scelta del punto $P$ sul corpo rigido:\n    \n    $v_P \\cdot  = v_Q + \\omega \\times {Q-P}  \\quad \\forall \\ P, Q \\ \\in B$\n    \n- **Dimostrazione:** Utilizzando la legge di distribuzione delle velocità, si ha:\n    \n    $v_P \\cdot \\omega = (v_Q + \\omega \\times {Q-P}) \\cdot \\omega = v_Q \\cdot \\omega + (\\omega \\times {Q-P}) \\cdot \\omega = v_Q \\cdot \\omega$\n    \n    Poiché il prodotto vettoriale $(\\omega \\times {Q-P})$ è perpendicolare a $\\omega$, il loro prodotto scalare è zero.\n     ^e1iu8n\n**Teorema di Mozzi**: L&#039;invariante scalare è utile per formulare il teorema di Mozzi, che afferma che l&#039;atto di moto più generale per un corpo rigido è elicoidale, con asse coincidente con l&#039;asse di Mozzi.\n\n### Lemma di Calcolo Vettoriale\n\nPer dimostrare il teorema di Mozzi, è utile un lemma di calcolo vettoriale.\n\n**Enunciato**: Siano _$\\underline a$_ e $\\underline b$ vettori fissati non nulli, e sia _O_ l&#039;origine. Si consideri l&#039;equazione vettoriale:\n\n$P-O \\times a = b$\n\nL&#039;equazione ammette soluzione se e solo se $a \\cdot b = 0$.\n\nSe $a \\cdot b = 0$, la soluzione ha la forma:\n\n$P_{\\lambda}-O = \\lambda a + \\frac{a \\times b}{a^2}$\n\ndove $\\lambda \\in {R}$ è arbitrario, e $a^2 = ||a||^2$ è il modulo quadro di _a_. I punti $P_{\\lambda}$ descrivono una retta parallela al vettore _a_.\n\n**Dimostrazione**:\n\n1. **Necessità della condizione $a \\cdot b = 0$**:\n    \n    Se esiste una soluzione _x_ = $P-O$ incognito tale che $x \\times a = b$, allora facendo il prodotto scalare con _a_:\n    \n    $(P-O \\wedge a) \\cdot a = b \\Longleftrightarrow(x \\wedge a) \\cdot a = b \\cdot a$\n    \n    Ma $(x \\times a) \\cdot a = 0$ perché il prodotto vettoriale è ortogonale ad _a_. Quindi $a \\cdot b = 0$.\n    Soluzioni Quando $a \\cdot b = 0$\n    Si dimostra che se $a \\cdot b = 0$, allora esistono soluzioni e si trova la loro forma generale.\n2. \n\t- Siano $P_1$ e $P_2$ due soluzioni dell&#039;equazione, tali che $P_1 \\wedge a = b$ e $p_2 \\wedge a = b$.\n\t- Si sottraggano membro a membro le due equazioni: $(P_1 - P_2) \\wedge a = 0$.\n\t- Questo implica che $P_1 - P_2$ è parallelo ad $a$, ovvero $P_1 - P_2 = \\lambda a$ per qualche scalare $\\lambda$.\n\t- Quindi, tutte le soluzioni differiscono per un multiplo di $a$, ovvero giacciono su una retta parallela ad $a$.\n3. definiamo $P_0$   tale che $(P_0 - O) \\perp \\underline{a}$\n\t- consideriamo $$\\underline{a} \\wedge [(P_0 - O) \\wedge \\underline{a}]= \\underline{a}^2 (P_0 - O) - (\\underline{a} \\cdot (P_0 - O)) \\underline{a}$$\n\t- con $(\\underline{a} \\cdot (P_0 - O)) \\underline{a}=0$\n\n\t- sia $(P_0 - O)$  una soluzione tale che $(P_0 - O) \\wedge \\underline{a} = \\underline{b}$\n\t\t- allora vale vale $\\underline{a}^2 (P_0 - O) = \\underline{a} \\wedge \\underline{b}$\n\n\n\t- allora $$(P_0 - O) = \\frac{\\underline{a} \\wedge \\underline{b}}{a^2}$$\n\t- che è soluzione esplicita e lo si dimostra prchè vale (ricordando che $a \\cdot b = 0$ per ipotesi )  $$\\left( \\frac{\\underline{a} \\wedge \\underline{b}}{a^2} \\right) \\wedge \\underline{a} = \\frac{\\underline{a} \\wedge (\\underline{b} \\wedge \\underline{a})}{a^2} = \\frac{a^2 \\underline{b} - (\\underline{a} \\cdot \\underline{b}) \\underline{a}}{a^2} = b$$\n4. **Sufficienza e costruzione della soluzione**:\n    \n    Supponiamo che $a \\cdot b = 0$. Cerchiamo una soluzione nella forma $P_{\\lambda}-O = \\lambda a + \\frac{a \\wedge b}{a^2}$.\n    \n    Verifichiamo che questa sia una soluzione:\n    \n    $$P_{\\lambda}-O \\wedge a = \\left(\\frac{a \\wedge b} {a^2}\\right) \\wedge a = b$$ ^sdajn8\n### 5. Interpretazione Geometrica\n![[Pasted image 20250301204739.png]]\nSi fornisce un&#039;interpretazione geometrica delle soluzioni.\n\n- Si consideri l&#039;origine $O$, il vettore $a$, e la retta dei punti $p_\\lambda = \\lambda a + \\frac{a \\times b}{a^2}$.\n- La retta è parallela ad $a$ e passa per il punto $P_o = \\frac{a \\times b}{a^2}$, che è il punto di minima distanza dall&#039;origine sulla retta delle soluzioni.\n- Ogni punto su questa retta rappresenta una soluzione dell&#039;equazione originale.\n\nIn conclusione, il lemma è dimostrato mostrando che la condizione $a \\cdot b = 0$ è necessaria e sufficiente per l&#039;esistenza di soluzioni, e che la forma generale delle soluzioni è $x = \\lambda a + \\frac{a \\times b}{a^2}$, dove $\\lambda$ è un parametro reale arbitrario. \n\n#### References\n[[meccanica-lez04_trascrizione]]"},"6--full-note/meccanica-lez05":{"slug":"6--full-note/meccanica-lez05","filePath":"6- full note/meccanica-lez05.md","title":"meccanica-lez05","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/meccanica-razionale","3--tag/sbobine","6--full-note/meccanica-lez06_trascrizione"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-25 12:09\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: meccanica razionale  sbobine\nmeccanica-lez05\nEnunciato del Teorema di Mozzi\nIl teorema di Mozzi afferma che: Se la velocità angolare \\Omega è diversa da zero (\\Omega \\neq 0) per un corpo rigido, l’atto di moto più generale è elicoidale con asse di moto (o asse di Mozzi).\nEquazione dell’Asse di Mozzi\nL’asse di moto ha equazione: P(\\lambda) - O = \\lambda \\Omega + \\frac{\\Omega \\times V_O}{\\Omega^2} dove P(\\lambda) è un punto sull’asse di Mozzi, O è un punto di riferimento (da cui si calcola V_O), \\Omega è il vettore velocità angolare, V_O è la velocità del punto O, \\Omega^2 è il modulo della velocità angolare al quadrato, e \\lambda è un parametro reale.\n\nLa velocità V_P di un punto P sull’asse di Mozzi è data da: V_{P(\\lambda)} = \\frac{I}{\\Omega^2} \\Omega dove I è l’invariante scalare dell’atto di moto.\nL’Invariante Scalare\nL’invariante scalare I è definito come il prodotto scalare tra la velocità angolare \\Omega e la velocità di un punto qualsiasi V_P, cioè I = V_P \\cdot \\Omega. Questo valore è lo stesso per tutti i punti del corpo rigido.\nCasi Particolari dell’Atto di Moto (se \\Omega \\neq 0)\n\nAtto di Moto Rotatorio: Se e solo se l’invariante scalare I è uguale a zero (I=0), l’atto di moto si riduce a un moto rotatorio. In questo caso, l’asse di Mozzi coincide con l’asse istantaneo di rotazione.\n\nAtto di Moto Traslatorio: Se la velocità angolare \\Omega è uguale a zero (\\Omega = 0), l’atto di moto è traslatorio. Questo caso è noto e non richiede il teorema di Mozzi. Il teorema si applica quando \\Omega \\neq 0 per descrivere l’atto di moto più generale.\n\n\nDimostrazione del Teorema di Mozzi\nIl professore accenna che la dimostrazione presentata in aula è diversa da una dimostrazione costruttiva disponibile altrove (es. online), e che se ne potrà vedere anche una più sintetica. La dimostrazione in aula utilizza il metodo basato su un lemma visto il giorno precedente.\nLa dimostrazione procede come segue:\n1. Decomposizione della Velocità V_P\nPer ogni punto P appartenente al corpo rigido, la velocità V_P può essere scomposta in due componenti: una parallela a \\Omega e una perpendicolare a \\Omega. V_P = V_P^\\parallel + V_P^\\perp dove V_P^\\parallel è parallelo a \\Omega e V_P^\\perp è perpendicolare a \\Omega.\n\nCalcolo della Componente Parallela\nPer eseguire questa decomposizione, si introduce il versore \\hat{n}_\\Omega parallelo a \\Omega, ben definito poiché per ipotesi \\Omega \\neq 0. \\hat{n}_\\Omega = \\frac{\\Omega}{|\\Omega|} = \\frac{\\Omega}{\\Omega_{modulo}} La componente parallela V_P^\\parallel si ottiene proiettando V_P sulla direzione di \\Omega e moltiplicando per il versore della direzione: V_P^\\parallel = (V_P \\cdot \\hat{n}_\\Omega) \\hat{n}_\\Omega Sostituendo la definizione di \\hat{n}_\\Omega: V_P^\\parallel = \\left(V_P \\cdot \\frac{\\Omega}{|\\Omega|}\\right) \\frac{\\Omega}{|\\Omega|} = \\frac{(V_P \\cdot \\Omega)}{|\\Omega|^2} \\Omega Il termine (V_P \\cdot \\Omega) è l’invariante scalare I. Quindi, la componente parallela è data da: V_P^\\parallel = \\frac{I}{\\Omega^2} \\Omega Osservazione Importante: Poiché l’invariante scalare I è lo stesso per tutti i punti del corpo rigido, e \\Omega è la velocità angolare del corpo (unica), tutti i punti del corpo rigido hanno la stessa componente di velocità parallela a \\Omega. Questa quantità non può essere ridotta a zero se I \\neq 0; se un punto ha V_P^\\parallel \\neq 0, tutti i punti avranno la stessa componente non nulla. Se un punto ha V_P^\\parallel = 0, allora l’invariante scalare I deve essere zero, e quindi tutti i punti avranno V_P^\\parallel = 0.\n\nCalcolo della Componente Perpendicolare\nLa componente perpendicolare V_P^\\perp si ottiene per definizione sottraendo la componente parallela dalla velocità totale: V_P^\\perp = V_P - V_P^\\parallel\n2. Definizione dell’Asse di Mozzi\nL’asse di Mozzi è definito come il luogo dei punti P per i quali la componente di velocità perpendicolare a \\Omega è nulla (V_P^\\perp = 0). Questo perché, parlando del moto elicoidale, i punti sull’asse hanno velocità solo parallela all’asse stesso (e quindi a \\Omega).\n3. Ricerca dei Punti dell’Asse di Mozzi\nConsideriamo la legge di distribuzione delle velocità nel corpo rigido, riferita a un punto O: V_P = V_O + \\Omega \\times (P - O) \nScomponiamo le velocità V_P e V_O nelle loro componenti parallele e perpendicolari rispetto a \\Omega: V_P^\\parallel + V_P^\\perp = V_O^\\parallel + V_O^\\perp + \\Omega \\times (P - O) Abbiamo osservato che le componenti parallele sono uguali per tutti i punti (V_P^\\parallel = V_O^\\parallel = \\frac{I}{\\Omega^2} \\Omega). Quindi, possiamo semplificarle dall’equazione: V_P^\\perp = V_O^\\perp + \\Omega \\times (P - O) Imponiamo la condizione che V_P^\\perp = 0 per i punti sull’asse di Mozzi: 0 = V_O^\\perp + \\Omega \\times (P - O) Riorganizzando i termini per isolare il vettore posizione relativa (P - O): V_O^\\perp = - \\Omega \\times (P - O) Utilizzando la proprietà anti-commutativa del prodotto vettoriale (\\Omega \\times (P-O) = - (P-O) \\times \\Omega), l’equazione diventa: V_O^\\perp = (P - O) \\times \\Omega\n4. Applicazione del Lemma del Giorno Precedente\nQuesta equazione (P-O) \\times \\Omega = V_O^\\perp ha la forma di un’equazione vettoriale lineare già studiata nel lemma precedente: x \\times a = b, dove x = P-O, a = \\Omega, e b = V_O^\\perp. La soluzione di x \\times a = b con a \\neq 0 e a \\cdot b = 0 è x = \\lambda a + \\frac{a \\times b}{a^2}, dove \\lambda è un parametro reale. Nel nostro caso, a = \\Omega e b = V_O^\\perp. Per costruzione, V_O^\\perp è perpendicolare a \\Omega, quindi il prodotto scalare \\Omega \\cdot V_O^\\perp = 0 è soddisfatto. Applicando la formula del lemma, la soluzione per P-O è:\n\nP - O = \\lambda \\Omega + \\frac{\\Omega \\times V_O^\\perp}{\\Omega^2} Questa è l’equazione dell’asse di Mozzi.\nRiconciliazione delle Forme dell’Equazione dell’Asse\nIl professore nota che l’equazione ricavata (P - O = \\lambda \\Omega + \\frac{\\Omega \\times V_O^\\perp}{\\Omega^2}) è formalmente diversa da quella enunciata all’inizio del teorema (P - O = \\lambda \\Omega + \\frac{\\Omega \\times V_O}{\\Omega^2}), ma descrivono la stessa retta. Questo perché nel prodotto vettoriale \\Omega \\times V_O, la componente parallela di V_O non contribuisce.\n\\Omega \\times V_O = \\Omega \\times (V_O^\\parallel + V_O^\\perp) = \\Omega \\times V_O^\\parallel + \\Omega \\times V_O^\\perp\nDato che V_O^\\parallel è parallelo a \\Omega, il loro prodotto vettoriale è zero (\\Omega \\times V_O^\\parallel = 0). \\Omega \\times V_O = \\Omega \\times V_O^\\perp Quindi, l’equazione può essere scritta indifferentemente usando V_O o V_O^\\perp: P - O = \\lambda \\Omega + \\frac{\\Omega \\times V_O}{\\Omega^2} oppure P - O = \\lambda \\Omega + \\frac{\\Omega \\times V_O^\\perp}{\\Omega^2} Entrambe le forme descrivono la stessa retta tangente a \\Omega (cioè, con direzione parallela a \\Omega). La forma con V_O è spesso più comoda, specialmente nel caso di rotazione pura, dove V_O^\\parallel = 0 per ogni punto O scelto sull’asse.\n\n5. Verifica della Velocità dei Punti sull’Asse di Mozzi\nSi verifica che i punti che soddisfano l’equazione dell’asse di Mozzi hanno effettivamente solo la componente di velocità parallela a \\Omega. La velocità di un punto P è data dalla legge di distribuzione delle velocità V_P = V_O + \\Omega \\times (P - O). Sostituiamo l’espressione per P-O sull’asse di Mozzi: V_P = V_O + \\Omega \\times \\left(\\lambda \\Omega + \\frac{\\Omega \\times V_O^\\perp}{\\Omega^2}\\right) Utilizziamo la linearità del prodotto vettoriale: V_P = V_O + \\Omega \\times (\\lambda \\Omega) + \\Omega \\times \\left(\\frac{\\Omega \\times V_O^\\perp}{\\Omega^2}\\right) Il primo termine del prodotto vettoriale è zero perché \\Omega \\times (\\lambda \\Omega) = \\lambda (\\Omega \\times \\Omega) = 0. V_P = V_O + \\frac{1}{\\Omega^2} \\Omega \\times (\\Omega \\times V_O^\\perp) Applichiamo l’identità del doppio prodotto vettoriale \\vec{a} \\times (\\vec{b} \\times \\vec{c}) = (\\vec{a} \\cdot \\vec{c})\\vec{b} - (\\vec{a} \\cdot \\vec{b})\\vec{c} con \\vec{a} = \\Omega, \\vec{b} = \\Omega, \\vec{c} = V_O^\\perp: \\Omega \\times (\\Omega \\times V_O^\\perp) = (\\Omega \\cdot V_O^\\perp)\\Omega - (\\Omega \\cdot \\Omega)V_O^\\perp Poiché V_O^\\perp è perpendicolare a \\Omega, \\Omega \\cdot V_O^\\perp = 0. \\Omega \\times (\\Omega \\times V_O^\\perp) = (0)\\Omega - (\\Omega^2)V_O^\\perp = - \\Omega^2 V_O^\\perp Sostituiamo questo risultato nell’espressione per V_P: V_P = V_O + \\frac{1}{\\Omega^2} (-\\Omega^2 V_O^\\perp) = V_O - V_O^\\perp Infine, ricordando che V_O = V_O^\\parallel + V_O^\\perp: V_P = (V_O^\\parallel + V_O^\\perp) - V_O^\\perp = V_O^\\parallel Abbiamo dimostrato che la velocità di un punto sull’asse di Mozzi è uguale alla componente parallela della velocità di un punto qualsiasi O. Poiché la componente parallela è la stessa per tutti i punti, la velocità di ogni punto sull’asse di Mozzi è: V_P = V_O^\\parallel = \\frac{I}{\\Omega^2} \\Omega Questa velocità è parallela a \\Omega, come atteso per i punti sull’asse di un moto elicoidale.\n\n6. Relazione con l’Asse Istantaneo di Rotazione\nLa seconda parte del teorema riguarda il caso in cui l’atto di moto è rotatorio, ovvero quando l’invariante scalare I = 0. Se I = 0, la velocità dei punti sull’asse di Mozzi diventa: V_P = \\frac{0}{\\Omega^2} \\Omega = 0 Questo significa che se l’invariante scalare è zero, tutti i punti sull’asse di Mozzi hanno velocità nulla. L’asse di Mozzi diventa quindi l’asse istantaneo di rotazione, definito come il luogo dei punti con velocità nulla.\nViceversa: Se esiste un punto Q con velocità nulla (V_Q = 0), allora Q appartiene all’asse istantaneo di rotazione (se esiste). Applicando lo stesso ragionamento usato per l’asse di Mozzi, se V_Q = 0, allora la componente parallela di V_Q deve essere zero: V_Q^\\parallel = \\frac{I}{\\Omega^2} \\Omega = 0 Poiché \\Omega \\neq 0, questo implica che l’invariante scalare I deve essere zero. Se I=0, abbiamo visto che tutte le componenti parallele della velocità sono nulle per ogni punto del corpo rigido (V_P^\\parallel = 0 per ogni P). In questo caso, tutte le velocità sono ortogonali a \\Omega. L’equazione dell’asse istantaneo di rotazione (luogo dei punti con V_P=0) si ottiene dalla legge di distribuzione delle velocità ponendo V_P=0: 0 = V_O + \\Omega \\times (P - O) Riorganizzando: \\Omega \\times (P - O) = - V_O (P - O) \\times \\Omega = V_O\n Questa è la stessa forma dell’equazione per l’asse di Mozzi, (P-O) \\times \\Omega = V_O^\\perp, con la differenza che, essendo I=0, la velocità V_O è essa stessa perpendicolare a \\Omega (V_O = V_O^\\perp). La soluzione è data dal lemma: P - O = \\lambda \\Omega + \\frac{\\Omega \\times V_O}{\\Omega^2} Questa è l’equazione dell’asse istantaneo di rotazione quando esiste (cioè quando I=0).\nQuesto conclude la spiegazione basata sugli estratti forniti. \n\nCertamente. Di seguito troverai la spiegazione tratta dalla fonte “flashcard”, strutturata secondo le tue indicazioni. Ti informo che la mia risposta si basa esclusivamente sul testo fornito nella fonte “flashcard”, poiché non sono stati forniti altri PDF a cui fare riferimento.\nEcco la trascrizione e l’organizzazione delle spiegazioni del professore:\nIntroduzione al Moto dei Corpi Rigidi\n\nL’Asse Istantaneo di Rotazione (R) esiste e svolge il suo compito. È possibile ricavarlo.\n\nL’Asse Istantaneo di Rotazione (R)\n\nPer individuare l’Asse Istantaneo di Rotazione, è sufficiente trovare un punto del corpo rigido che abbia velocità nulla.\nSe si trova un punto con velocità nulla, si scopre che l’Invariante Scalare (I) è uguale a zero.\nL’invariante scalare I è definito come il prodotto scalare tra il vettore velocità angolare \\boldsymbol{\\omega} e il vettore velocità di un punto P qualsiasi (\\mathbf{v}_P), ovvero I = \\boldsymbol{\\omega} \\cdot \\mathbf{v}_P.\nDato che I è un invariante (ha lo stesso valore per qualsiasi punto P del corpo rigido), se I=0 per un punto, è zero per tutti i punti.\nUn invariante scalare uguale a 0 significa che le velocità di tutti i punti del corpo rigido sono ortogonali al vettore \\boldsymbol{\\omega}.\nI punti che sono fermi (con velocità nulla) appartengono all’asse istantaneo di rotazione.\nL’asse istantaneo di rotazione esiste in quanto esiste l’Asse di Mozzi (dimostrato nella parte precedente non inclusa nella fonte fornita). L’Asse di Mozzi, per I=0, è costituito da punti con velocità (di modulo) 1 (probabilmente un lapsus, dovrebbe essere velocità di modulo minimo, e nel caso I=0 la velocità minima è 0).\n\nL’Asse di Mozzi: Luogo dei Punti con Velocità di Modulo Minimo\n\nProposizione: L’Asse di Mozzi è il luogo geometrico dei punti con velocità di modulo minimo.\nLa dimostrazione di questa proposizione, dopo aver compreso il Teorema di Mozzi, è “banale” o una “semplice banale conseguenza”.\nDimostrazione:\n\nSi considera la velocità di un punto P qualsiasi, \\mathbf{v}_P, e la si decompone in una componente parallela e una perpendicolare alla direzione di \\boldsymbol{\\omega} (che definisce la direzione dell’Asse di Mozzi): \\mathbf{v}_P = \\mathbf{v}_{P\\parallel} + \\mathbf{v}_{P\\perp}\nSi calcola il modulo quadrato della velocità di P: |\\mathbf{v}_P|^2 = |\\mathbf{v}_{P\\parallel}|^2 + |\\mathbf{v}_{P\\perp}|^2\nSpiegazione del passaggio precedente: Quando si calcola il prodotto scalare di \\mathbf{v}_P con se stesso, i prodotti scalari delle componenti parallela e perpendicolare (\\mathbf{v}_{P\\parallel} \\cdot \\mathbf{v}_{P\\perp}) sono nulli perché le due componenti sono ortogonali.\nDall’espressione |\\mathbf{v}_P|^2 = |\\mathbf{v}_{P\\parallel}|^2 + |\\mathbf{v}_{P\\perp}|^2, si osserva che il modulo quadrato della velocità di P è evidentemente maggiore o uguale al modulo quadrato della sola componente parallela: |\\mathbf{v}_P|^2 \\ge |\\mathbf{v}_{P\\parallel}|^2\nLa componente parallela \\mathbf{v}_{P\\parallel} (la velocità “di trascinamento” lungo l’asse di Mozzi) ha modulo costante per tutti i punti del corpo rigido e pari a I/|\\boldsymbol{\\omega}|. Il professore la indica con ”I \\omega su \\omega^2 al quadrato” che interpreta come (I/|\\boldsymbol{\\omega}|)^2.\nI punti che appartengono all’Asse di Mozzi hanno solamente la velocità parallela (\\mathbf{v}_{P\\perp} = \\mathbf{0} per punti sull’asse).\nQualsiasi altro punto del corpo rigido che non appartenga all’Asse di Mozzi ha anche una componente di velocità perpendicolare non nulla (\\mathbf{v}_{P\\perp} \\ne \\mathbf{0}).\nPertanto, per i punti non sull’asse, |\\mathbf{v}_P|^2 = |\\mathbf{v}_{P\\parallel}|^2 + |\\mathbf{v}_{P\\perp}|^2 sarà strettamente maggiore di |\\mathbf{v}_{P\\parallel}|^2 (la velocità sull’asse).\nQuesto dimostra che i punti dell’Asse di Mozzi hanno la velocità di modulo minimo.\n\n\n\n\nIl Caso Piano (Corpo Rigido Piano)\n\n\nIl caso del corpo rigido piano è particolarmente interessante per gli esercizi.\n\n\nIn questo caso, gli atti di moto possibili si riducono a due: traslatorio o rotatorio.\n\n\nTeorema 1: Teorema di Eulero (per il caso piano)\n\nProposizione: L’atto di moto di un corpo rigido piano, se non è traslatorio, è rotatorio.\nIn caso di moto rotatorio, esiste il Centro di Istantanea Rotazione (C).\nDimostrazione (come corollario di Mozzi):\n\nPer un corpo rigido piano, il vettore velocità angolare \\boldsymbol{\\omega} è perpendicolare al piano (\\pi) in cui giace il corpo.\nLa velocità \\mathbf{v}_P di qualsiasi punto P appartenente al corpo rigido piano è contenuta nel piano (\\pi).\nSi calcola l’Invariante Scalare I = \\boldsymbol{\\omega} \\cdot \\mathbf{v}_P. Poiché \\boldsymbol{\\omega} è perpendicolare al piano e \\mathbf{v}_P è nel piano, il loro prodotto scalare è sempre zero: I = \\boldsymbol{\\omega} \\cdot \\mathbf{v}_P = 0 per ogni punto P.\nSe \\boldsymbol{\\omega} \\ne \\mathbf{0} e I=0, il Teorema di Mozzi implica che l’Asse Istantaneo di Rotazione R esiste.\n\nPoiché R è parallelo a \\boldsymbol{\\omega}, R è perpendicolare al piano.\nL’intersezione di questo asse R con il piano è un punto unico. Questo punto è il Centro di Istantanea Rotazione (C).\nPertanto, se \\boldsymbol{\\omega} \\ne \\mathbf{0}, l’atto di moto è rotatorio attorno a C.\nSe \\boldsymbol{\\omega} = \\mathbf{0}, l’atto di moto è banalmente traslatorio.\n\n\nQuesta dimostrazione è una “banalità” o un “teoremino utile” dopo aver visto il Teorema di Mozzi, semplicemente osservando la perpendicolarità di \\boldsymbol{\\omega} al piano e la giacenza di \\mathbf{v}_P nel piano.\n\n\n\n\nTeorema 2: Teorema di Chasles\n\nQuesto teorema è molto semplice e molto utile per individuare graficamente il Centro di Istantanea Rotazione per il corpo piano. (Nota sulla pronuncia: “Scialle”, le due ‘s’ non si sentono).\nProposizione: Siano A e B due punti appartenenti a un corpo rigido piano tali che le loro velocità \\mathbf{v}_A e \\mathbf{v}_B non siano parallele.\nAllora, il Centro di Istantanea Rotazione (C) si trova all’intersezione della retta r_A passante per A e perpendicolare a \\mathbf{v}_A, e della retta r_B passante per B e perpendicolare a \\mathbf{v}_B.\n\nQuesto metodo è utile per individuare C, anche se a volte può essere difficile.\nRiferire l’atto di moto al CIR C è conveniente perché la velocità di C è nulla: \\mathbf{v}_P = \\boldsymbol{\\omega} \\times (\\mathbf{P} - \\mathbf{C}) dove \\mathbf{v}_C = \\mathbf{0}.\nDimostrazione:\n\nSi ipotizza che \\mathbf{v}_A non sia parallela a \\mathbf{v}_B.\nCiò implica che \\mathbf{v}_A è diversa da \\mathbf{v}_B.\nL’atto di moto non può essere traslatorio (altrimenti le velocità sarebbero uguali).\nPer il Teorema di Eulero, l’atto di moto è rotatorio, il che significa che \\boldsymbol{\\omega} \\ne \\mathbf{0} e che il Centro di Istantanea Rotazione (C) esiste.\n\nSi scrive l’atto di moto rotatorio riferito al punto C (anche se la posizione di C non è ancora nota), usando la formula fondamentale della cinematica dei corpi rigidi riferita a C: \\mathbf{v}_A = \\mathbf{v}_C + \\boldsymbol{\\omega} \\times (\\mathbf{A} - \\mathbf{C}) \\mathbf{v}_B = \\mathbf{v}_C + \\boldsymbol{\\omega} \\times (\\mathbf{B} - \\mathbf{C})\nPoiché C è il Centro di Istantanea Rotazione, la sua velocità è nulla: \\mathbf{v}_C = \\mathbf{0}\nSostituendo \\mathbf{v}_C = \\mathbf{0} nelle equazioni precedenti: \\mathbf{v}_A = \\boldsymbol{\\omega} \\times (\\mathbf{A} - \\mathbf{C}) \\mathbf{v}_B = \\boldsymbol{\\omega} \\times (\\mathbf{B} - \\mathbf{C})\nSi osservano le proprietà del prodotto vettoriale: il risultato \\boldsymbol{\\omega} \\times \\mathbf{r} è perpendicolare a entrambi i vettori \\boldsymbol{\\omega} e \\mathbf{r}.\nDall’equazione \\mathbf{v}_A = \\boldsymbol{\\omega} \\times (\\mathbf{A} - \\mathbf{C}), si deduce che \\mathbf{v}_A è perpendicolare al vettore (\\mathbf{A} - \\mathbf{C}).\nIl vettore (\\mathbf{A} - \\mathbf{C}) giace sulla retta che passa per A e C.\nQuesto implica che il punto C deve giacere sulla retta che passa per A ed è perpendicolare a \\mathbf{v}_A. Questa è la retta r_A definita nella proposizione del teorema.\nAllo stesso modo, dall’equazione \\mathbf{v}_B = \\boldsymbol{\\omega} \\times (\\mathbf{B} - \\mathbf{C}), si deduce che \\mathbf{v}_B è perpendicolare al vettore (\\mathbf{B} - \\mathbf{C}).\nIl vettore (\\mathbf{B} - \\mathbf{C}) giace sulla retta che passa per B e C.\n\nQuesto implica che il punto C deve giacere sulla retta che passa per B ed è perpendicolare a \\mathbf{v}_B. Questa è la retta r_B definita nella proposizione del teorema.\nPoiché C si trova sia sulla retta r_A che sulla retta r_B, deve essere il loro punto di intersezione. L’intersezione è unica perché, essendo \\mathbf{v}_A e \\mathbf{v}_B non parallele, le rette r_A e r_B (a loro perpendicolari) non sono parallele.\n\n\nQuesto conclude la dimostrazione. \n\n\n\nEsempio Grafico (per il Teorema di Chasles)\n\n\nPer chiarire le idee, si considera un esempio.\n\n\nSi prendono due punti A e B su un corpo rigido piano (immaginato con una certa sagoma).\n\n\nSi disegnano le velocità \\mathbf{v}_A e \\mathbf{v}_B dei punti A e B. È importante che rispettino le condizioni di rigidità (la proiezione di \\mathbf{v}_A e \\mathbf{v}_B sulla retta congiungente A e B deve essere uguale) e che non siano parallele per poter applicare il teorema di Chasles.\n\n\nPassaggi grafici per trovare il CIR (C):\n\nTracciare la retta r_A passante per il punto A e perpendicolare al vettore velocità \\mathbf{v}_A.\nTracciare la retta r_B passante per il punto B e perpendicolare al vettore velocità \\mathbf{v}_B. (Si indica con un angolo retto nel disegno).\nIl punto di intersezione delle rette r_A e r_B è il Centro di Istantanea Rotazione (C).\n\n\n\nSi sottolinea che esempi in cui le velocità \\mathbf{v}_A e \\mathbf{v}_B non rispettano le condizioni di rigidità o parallelismo non sono corretti per trovare il CIR in questo modo.&lt;\n\n\n\n\nIntroduzione ai Vincoli nel Moto dei Corpi Rigidi\nIl discorso sui vincoli segue la trattazione degli atti di moto e si rende necessario per affrontare gli esercizi che, nel caso del corpo rigido piano, implicano spesso la presenza di vincoli. I vincoli sono dispositivi che limitano il movimento accessibile a un sistema di punti materiali o a un corpo rigido. Il professore introduce una prima divisione in due classi principali di vincoli:\n\nVincoli di Posizione\nVincoli di Mobilità \n\n1. Vincoli di Posizione\nI vincoli di posizione sono dispositivi che limitano le configurazioni accessibili al sistema. Sono già stati visti esempi in precedenza. Anche il vincolo di rigidità di un corpo rigido è esso stesso un vincolo di posizione. Un esempio di vincolo di posizione è un anellino vincolato a una sbarra: l’anellino può muoversi solo lungo la sbarra, perdendo gradi di libertà perpendicolari ad essa e mantenendo una sola coordinata libera.\n\n\n\nRappresentazione Matematica dei Vincoli di Posizione\nDato un sistema generico di n punti materiali, i vincoli di posizione possono essere imposti tramite m funzioni F_i che dipendono dalle posizioni dei punti (x_1, \\dots, x_n) e potenzialmente dal tempo (t), e che devono essere nulle. Assumendo che questi m vincoli siano indipendenti, la loro forma generale è: F_1(x_1, x_2, \\dots, x_n, t) = 0 F_2(x_1, x_2, \\dots, x_n, t) = 0 \\vdots F_m(x_1, x_2, \\dots, x_n, t) = 0 o, in forma più compatta: F_i(x_1, \\dots, x_n, t) = 0, \\quad i = 1, \\dots, m dove x_j rappresenta le coordinate del j-esimo punto, che possono essere vettoriali. P_1, \\dots, P_n potrebbe essere usato al posto di x_1, \\dots, x_n.\n\n\n\n2. Vincoli di Mobilità\nI vincoli di mobilità sono dispositivi che limitano le velocità accessibili al sistema. Esempi specifici per il corpo rigido piano, come il puro rotolamento, rientrano in questa categoria e saranno visti più avanti, riducendosi, nel caso del corpo rigido piano visto dal professore, a vincoli positivi.\n\n\n\nRelazione tra Vincoli di Posizione e Vincoli di Mobilità\nLe due classi di vincoli, mobilità e posizione, hanno una intersezione non nulla. Si può ottenere un vincolo di mobilità a partire da un vincolo di posizione.\n\n\nDimostrazione: Derivazione di un Vincolo di Mobilità da un Vincolo di Posizione\nConsideriamo un singolo vincolo di posizione: F(x_1, \\dots, x_n, t) = 0 Poiché questa funzione è identicamente uguale a zero per tutto il tempo in cui il vincolo è attivo, anche la sua derivata totale rispetto al tempo deve essere zero: \\frac{dF}{dt} = 0 Espandendo la derivata totale tramite la regola della catena, ricordando che x_i sono funzioni del tempo t (x_i(t)), si ottiene: \\frac{dF}{dt} = \\sum_{i=1}^n \\frac{\\partial F}{\\partial x_i} \\cdot \\frac{dx_i}{dt} + \\frac{\\partial F}{\\partial t} = 0\n\nIl professore utilizza una notazione in cui \\frac{df}{dx_i} sta per il gradiente di F rispetto alle coordinate del punto i (se x_i è un vettore di coordinate) e x.i sta per la velocità \\dot{x}_i (vettore velocità del punto i). Adattando la notazione del professore per un sistema di n punti, dove \\mathbf{x}_i è la posizione vettoriale del punto i e \\dot{\\mathbf{x}}_i la sua velocità vettoriale: \\sum_{i=1}^n \\nabla_{\\mathbf{x}_i} F \\cdot \\dot{\\mathbf{x}}_i + \\frac{\\partial F}{\\partial t} = 0\n\nCommento sui Passaggi:\n\nPartiamo dalla funzione del vincolo di posizione F che è nulla.\nLa derivata totale \\frac{dF}{dt} è la variazione di F seguendo il moto dei punti e tenendo conto dell’eventuale dipendenza esplicita dal tempo.\nQuesta derivata totale è zero perché F è sempre zero.\nLa regola della catena ci dice come calcolare questa derivata totale: somma dei contributi dovuti al cambiamento di posizione dei punti (termini con \\dot{\\mathbf{x}}_i) più il contributo dovuto all’eventuale cambiamento esplicito nel tempo del vincolo (\\frac{\\partial F}{\\partial t}).\nI termini \\nabla_{\\mathbf{x}_i} F \\cdot \\dot{\\mathbf{x}}_i sono prodotti scalari tra il gradiente della funzione del vincolo rispetto alle coordinate del punto i e la velocità del punto i. Il professore ha scritto \\frac{df}{dx_i} come notazione per il gradiente.\nL’equazione risultante è una relazione che lega le velocità dei punti. Questo è un vincolo di mobilità.\n\n\n\nIl professore commenta che i vincoli di mobilità ottenuti in questo modo sono “farlocchi” (cioè, apparenti), nel senso che si riducono al vincolo di posizione originale. L’unico vincolo effettivo è quello di posizione.\n\n\n\n\nIntegrabilità dei Vincoli di Mobilità\nPosta la domanda opposta: è sempre possibile ridurre un vincolo di mobilità a un vincolo di posizione?. Il professore spiega che per affrontare questa questione adeguatamente servono strumenti matematici che non si possiedono, in particolare il linguaggio delle forme differenziali. La possibilità di ridurre un vincolo di mobilità a uno di posizione dipende dalla sua integrabilità.\n\nSe un vincolo di mobilità è integrabile, esso si riduce a un vincolo di posizione. Questi sono chiamati vincoli di mobilità integrabili.\nSe un vincolo di mobilità non è integrabile, non può essere ridotto a un vincolo di posizione. Questi sono chiamati vincoli di pura mobilità. Dunque, i vincoli di posizione e i vincoli di pura mobilità rappresentano due classi di vincoli che non si intersecano e non sono riducibili l’una all’altra.\n\n\n\n\n\n3. Nomenclatura: Vincoli Olonomi e Anolonomi\n\n\nDefinizione:\n\nI vincoli di posizione sono detti olononomi. Il professore aggiunge che si parlerà anche di olonomia del vincolo.\nI vincoli di pura mobilità sono detti anolonomi. Questi sono considerati difficili da trattare. Il professore accennerà ad essi ma non ne mostrerà esempi all’opera.\n\n\n\n\nOrigine dei Termini:\n\nL’origine è greca.\nOlononomia significa “conoscete per intero la legge che governa il vincolo”.\nAnolonomia, con l’alfa privativa, significa che “non conoscete per intero la legge”.\n\n\n\nEsempi Concreti di Vincoli di Pura Mobilità Gli esempi più comuni di vincoli di pura mobilità (anolonomi) sono quelli di puro rotolamento.\n\nLa ruota della bicicletta che rotola senza strisciare.\nUn disco che rotola senza strisciare sul piano.\nLa palla o il pallone da calcio che rotola senza strisciare. Questo significa che il punto di contatto è istantaneamente fermo e non striscia sul pavimento. Il professore riprenderà questi esempi in seguito.\n\n\n\n4. Ulteriore Classificazione: Vincoli Fissi e Vincoli Mobili\nOltre alla divisione in posizione/mobilità (olononomi/anolonomi), i vincoli possono essere ulteriormente classificati in vincoli fissi e vincoli mobili. (Viene menzionata anche la divisione in unilateri e bilateri, ma verrà trattata dopo aver dato altre opzioni).\n\n\nVincoli Fissi\nSono i vincoli che non hanno una dipendenza esplicita dal tempo nella loro equazione che li definisce. La funzione F dipende solo dalle posizioni: F(x_1, \\dots, x_n) = 0.\n\nEsempio di Vincolo Fisso: Un punto materiale P che deve stare su una circonferenza di raggio R costante. La posizione del punto può essere descritta in coordinate cartesiane (x, y). Il vincolo è che la distanza dall’origine sia R. L’equazione del vincolo è: x^2 + y^2 - R^2 = 0 Questa è una funzione F(x, y) = x^2 + y^2 - R^2 = 0. Non c’è una dipendenza esplicita dal tempo t in questa espressione. Questo è un vincolo fisso. Si può anche descrivere il punto con coordinate parametriche come x(t) = R \\cos(\\theta(t)) e y(t) = R \\sin(\\theta(t)), che mostrano una dipendenza dal tempo attraverso l’angolo \\theta(t), ma la funzione del vincolo F non dipende esplicitamente da t.\n\n\n\n\nVincoli Mobili\nSono i vincoli che presentano una dipendenza esplicita dal tempo nella loro equazione. La funzione F dipende dalle posizioni e dal tempo: F(x_1, \\dots, x_n, t) = 0.\n\nEsempio di Vincolo Mobile: Un punto materiale P che deve stare su una circonferenza il cui raggio varia nel tempo, ad esempio R(t) = vt, dove v è una costante con dimensioni di velocità. L’equazione del vincolo è: x^2 + y^2 - (R(t))^2 = 0 Sostituendo R(t) = vt: x^2 + y^2 - (vt)^2 = 0 Questa è una funzione F(x, y, t) = x^2 + y^2 - (vt)^2 = 0. C’è una dipendenza esplicita da t. Questo è un vincolo mobile.\n\nRiassunto e Importanza \n\n\n\nRiassumendo, la prima divisione principale è tra vincoli di posizione (olononomi), che limitano le configurazioni, e vincoli di mobilità, che limitano le velocità. I vincoli di mobilità possono essere integrabili (e ridursi quindi a vincoli di posizione) o di pura mobilità (anolonomi). Una seconda suddivisione importante, ortogonale alla prima, è tra vincoli fissi (nessuna dipendenza esplicita dal tempo) e vincoli mobili (dipendenza esplicita dal tempo).\nLa distinzione tra vincoli fissi e mobili è particolarmente utile per le discussioni future sulla dinamica, sulle Lagrangiane e sulla conservazione dell’energia. La presenza di vincoli mobili cambia le cose rispetto alla presenza di soli vincoli fissi.\nReferences\nmeccanica-lez06_trascrizione"},"6--full-note/meccanica-lez06":{"slug":"6--full-note/meccanica-lez06","filePath":"6- full note/meccanica-lez06.md","title":"meccanica-lez06","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/meccanica-razionale","6--full-note/meccanica-lez06_trascrizione"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-26 16:28\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine meccanica razionale\nmeccanica-lez06\nIntroduzione ai Concetti di Vincolo\nLe fonti introducono il concetto di vincoli, riprendendo concetti già visti. Si esplorano diverse classi di vincoli, osservando che ne esistono di varie tipologie.\nClassificazione Generale dei Vincoli\nEsistono diverse modalità per classificare i vincoli:\n\nVincoli di Posizione vs. Vincoli di Mobilità: Oltre ai vincoli di posizione, esistono i vincoli di mobilità. La sottoclasse dei vincoli di mobilità che non possono essere ridotti a vincoli di posizione è definita vincoli di pura mobilità.\nVincoli Fissi vs. Vincoli Mobili: Questa divisione si basa sull’eventuale dipendenza esplicita dal tempo nell’espressione del vincolo. Sono definiti fissi quando non c’è dipendenza esplicita dal tempo. Sono definiti mobili altrimenti. Si ritiene che questa distinzione sarà più chiara e utile in seguito, quando avrà un’applicazione specifica.\n\nEsempi di Vincoli per il Corpo Rigido Piano\nGli esempi di vincoli presentati si focalizzano sul corpo rigido piano, poiché sono quelli che tipicamente si incontrano negli esercizi. Un corpo rigido piano possiede inizialmente tre gradi di libertà (Gdl): due traslazionali e uno rotazionale. I vincoli agiscono limitando questi gradi di libertà.\n1. Cerniera Fissa\n\nDescrizione: È il primo vincolo introdotto. Vincola un punto specifico, chiamato A, del corpo rigido (indicato come BP) a rimanere fisso. Il corpo rigido può solo ruotare attorno a questo punto A.\nSimbolo: È rappresentato graficamente da una pallina con dei raggi che escono fuori. Viene mostrato un disegno con gli assi fissi XY e gli assi solidali E1, E2, Y’ con origine nel punto A.\nEffetto sui Gradi di Libertà: Il punto A è fisso, quindi le sue coordinate X_A e Y_A non sono gradi di libertà. Questo elimina i gradi di libertà traslazionali. Rimane un solo grado di libertà, quello di rotazione \\theta attorno ad A. La cerniera fissa toglie due gradi di libertà.\n\n2. Carrello\n\nDescrizione: Questo vincolo costringe un punto A appartenente al corpo rigido piano a scorrere lungo una curva piana, che nella maggioranza dei casi è una retta. Può anche essere un carrello su una circonferenza. Il caso più frequente è quello in cui il carrello scorre lungo una retta, ad esempio l’asse X.\nSimbolo: Si indica con due stanghette e un semicerchietto, o un circolino, per indicare che rimangono gradi di libertà. A volte si trova il simbolo del carrellino con le ruote.\nEffetto sui Gradi di Libertà: Il carrello toglie un grado di libertà. Ne rimangono due. Nel caso di scorrimento lungo l’asse X, il simbolo del carrello indica che non ci si può muovere ortogonalmente a questa direzione. La direzione di scorrimento è data dalle due stanghette. Quindi, la coordinata Y_A (perpendicolare all’asse X) è fissata, Y_A = 0. Le coordinate X_A(t) (scorrimento lungo X) e l’angolo \\theta(t) (rotazione) rimangono gradi di libertà. Il carrello è un vincolo “meno forte” della cerniera fissa perché toglie meno gradi di libertà.\n\n3. Pattino\n\nDescrizione: È un vincolo simile al carrello nel simbolo ma con una differenza cruciale: non c’è il pallino. Questo implica che la direzione solidale associata al pattino non può ruotare; non c’è libertà di rotazione. Il pattino costringe un punto A del corpo rigido a muoversi (per semplicità, lungo una retta) e non consente rotazioni attorno ad A. Anche un pattino vincolato a una circonferenza dovrebbe rimanere tangente ad essa.\nSimbolo: Molto simile al carrello, ma senza il pallino. Mostra una direzione solidale che non può essere piegata.\nEffetto sui Gradi di Libertà: In una situazione con pattino lungo una retta (ad esempio, l’asse X), la direzione solidale E_1 sull’asse X&#039; e E_2 sull’asse Y&#039; rimane fissa in orientamento. L’angolo \\theta non è libero. Si è eliminato un grado di libertà traslazionale (quello perpendicolare alla direzione di scorrimento) e quello rotazionale. Rimane un solo grado di libertà: lo scorrimento traslazionale lungo la direzione consentita, ad esempio X_A(t).\nNote Aggiuntive: Viene definito il “maledetto pattino” perché spesso mette in difficoltà gli studenti. Questo vincolo avrà un momento di reazione vincolare perché impedisce le rotazioni. Dettagli su questo momento verranno spiegati più avanti.\n\n4. Incastro\n\nDescrizione: Il vincolo più “cattivo”. Come suggerisce il nome, non lascia alcun grado di libertà al corpo rigido. Fissa un punto A appartenente al corpo rigido e non consente rotazioni. Può essere visto sia come un rafforzamento della cerniera fissa (che consente rotazioni) che come un rafforzamento del pattino (che non fissa il punto). Un esempio fisico è un’asta piantata nel pavimento o nel muro, che non si muove più.\nSimbolo: Si possono trovare diversi simboli. Uno più frequente è una linea con ombreggiatura e una direzione solidale del corpo rigido che si “conficca” dentro. Un altro simbolo possibile viene anche mostrato. Viene menzionato che in altri corsi potrebbe essere chiamato “manicotto”.\nEffetto sui Gradi di Libertà: L’incastro toglie tre gradi di libertà. Dato che il corpo rigido piano ne ha tre, non ne rimane nessuno. È un vincolo molto forte.\n\n5. Cerniera Mobile\n\nDescrizione: Questo è un vincolo tra due corpi rigidi, non tra un corpo rigido e un vincolo esterno fisso. Vincola due punti, A’ appartenente al primo corpo rigido (BP_1) e A” appartenente al secondo corpo rigido (BP_2), a coincidere in un punto comune chiamato A. Lascia libertà di rotazione attorno a questo punto A, ma a differenza della cerniera fissa, il punto A si può muovere.\nSimbolo: Si indica con un pallino.\nEsempio e Descrizione Processo: Viene mostrato un esempio con due corpi rigidi distinti (BP_1 e BP_2) con i rispettivi assi solidali, che vengono poi uniti in un unico oggetto tramite la cerniera mobile nel punto A, che è la fusione di A’ e A”. Viene fatto l’esempio di due aste unite da una cerniera.\nEffetto sui Gradi di Libertà: La fonte si interrompe prima di completare la spiegazione di quanti gradi di libertà vengono rimossi o rimangono nel sistema di due corpi rigidi uniti da una cerniera mobile.\n\nQuesto conclude la descrizione dei vincoli presentati nelle fonti a disposizione. Come richiesto, ho cercato di riportare fedelmente i concetti e gli esempi forniti dal professore, strutturando l’informazione in modo gerarchico con titoli e sottotitoli e citando le fonti per ogni affermazione.\n\nCertamente. Di seguito riporto la spiegazione del professore sulla base delle informazioni contenute nelle fonti fornite, integrandole con i passaggi matematici e gli esempi presentati.\nGli appunti sono strutturati con titoli e sottotitoli per facilitare la comprensione.\nAnalisi dei Gradi di Libertà e Vincoli\nQuesto argomento tratta come i vincoli meccanici influenzano i gradi di libertà di un sistema, concentrandosi in particolare sulla cerniera mobile e sul puro rotolamento.\nLa Cerniera Mobile (Esempio di Vincolo di Posizione)\n\nIntroduzione: Consideriamo due corpi rigidi. Inizialmente, ognuno ha tre gradi di libertà (GDL) nel piano, per un totale di sei GDL per il sistema di due corpi.\nApplicazione del Vincolo: Mettiamo assieme i due corpi rigidi attraverso una cerniera mobile nel punto A. Questa cerniera mobile unisce i due corpi in un punto, permettendo traslazione del punto A nel piano e rotazioni di entrambi i corpi attorno ad A.\nEffetto sui GDL: Quando uniamo le due origini nel punto A, i gradi di libertà traslazionali di una delle due origini vengono “lavati via” perché le facciamo coincidere. Il vincolo di cerniera mobile toglie due gradi di libertà traslazionali.\nGDL Residui: Rimangono 6 meno 2, quindi 4 gradi di libertà. Questi sono i due gradi di libertà traslazionali del punto A nel piano e la possibilità di rotazione (indicata come \\theta e \\phi) attorno ad A per entrambi i corpi. In sintesi, una cerniera mobile permette al punto vincolato di muoversi nel piano (2 GDL traslazionali) e ai corpi di ruotare liberamente attorno a quel punto (2 GDL rotazionali totali per i due corpi, se non ci sono altri vincoli che li legano).\n\nIl Puro Rotolamento (Vincolo di Mobilità)\n\nIntroduzione: Il puro rotolamento, o rotolamento senza strisciamento, è un vincolo che si applica alla velocità e non alla posizione. Non ha un simbolo grafico standard.\nDefinizione: Nel punto di contatto A tra un corpo rigido (ad esempio, un disco) e una guida (che può essere fissa o mobile), il vincolo di puro rotolamento implica che i due punti di contatto avranno la stessa velocità. Questo significa che il corpo rigido non striscia sulla guida. Matematicamente, questo si esprime come v_A^{\\text{corpo rigido}} = v_A^{\\text{guida}}. Questo è un vincolo di mobilità, ovvero un vincolo sulle velocità.\n\nEsempio: Puro Rotolamento su Guida Fissa\n\n\nSetup: Consideriamo un disco che rotola senza strisciare su una guida fissa, come un piano (detto piano \\pi o piano della lavagna). Il disco si muove rimanendo in questo piano. La guida fissa può essere pensata come un tavolo. Indichiamo il punto di contatto come A, il centro del disco come C e il raggio del disco come R. Usiamo un sistema di coordinate X-Y fissato, con l’asse X lungo la guida fissa.\n\n\nCondizione di Puro Rotolamento: Per definizione, v_A^{\\text{disco}} = v_A^{\\text{guida}}. Poiché la guida è fissa, il suo punto di contatto A ha velocità nulla: v_A^{\\text{guida}} = 0.\n\n\nConseguenza: La condizione di puro rotolamento diventa quindi v_A^{\\text{disco}} = 0. Questo significa che, istante per istante, il punto del disco a contatto con la guida ha velocità nulla.\n\n\nPunto di Contatto come Centro di Istantanea Rotazione (CIR): Se un punto di un corpo rigido ha velocità nulla, quel punto è il Centro di Istantanea Rotazione (CIR) del corpo rigido in quell’istante. Pertanto, per un disco che rotola senza strisciare su una guida fissa, il punto di contatto A è il CIR del disco.\n\n\nAnalisi dei Gradi di Libertà: Un corpo rigido libero di muoversi nel piano ha 3 GDL (ad esempio, le coordinate x_C, y_C del centro e l’angolo di rotazione \\theta). Nel caso del disco che rotola su un piano orizzontale fisso, la sua altezza (l’ordinata y_C del centro C) è costante e uguale al raggio R (y_C = R). Questo fissa un GDL di posizione. Rimangono x_C e \\theta come potenziali GDL, per un totale di 2. L’obiettivo è dimostrare che il vincolo di puro rotolamento lega queste due coordinate, riducendo ulteriormente i GDL indipendenti a uno solo.\n\n\nDimostrazione: Relazione tra x_C e \\theta Il vincolo di puro rotolamento lega la traslazione orizzontale del centro del disco alla sua rotazione. Possiamo dimostrarlo calcolando la velocità del centro C in due modi diversi.\n\nVelocità del Centro C (Coordinate Cartesiane): Il centro C ha coordinate (x_C, y_C). Poiché il disco rotola su un piano orizzontale fisso, l’ordinata y_C è costante e pari al raggio R: y_C = R. La velocità del centro C è data dalla derivata rispetto al tempo del suo vettore posizione: v_C = \\frac{d}{dt}(x_C \\mathbf{i} + y_C \\mathbf{j}) Essendo y_C = R una costante, la sua derivata è zero. Quindi: v_C = \\dot{x}_C \\mathbf{i} dove \\dot{x}_C rappresenta la derivata di x_C rispetto al tempo.\nVelocità del Centro C (usando il CIR): Poiché A è il CIR del disco, la velocità di qualsiasi punto P del disco può essere calcolata usando la legge di distribuzione delle velocità relativa al CIR A: v_P = v_A + \\omega \\times (P-A). Per il centro C, abbiamo: v_C = v_A + \\omega \\times (C-A) Sappiamo che v_A = 0 perché A è il CIR. Il vettore C-A va dal punto A (di contatto) al centro C. In un sistema di riferimento dove X è orizzontale e Y verticale verso l’alto, se A è l’origine momentanea in basso, C si trova R unità sopra A, quindi C-A = R \\mathbf{j}. La velocità angolare \\omega del disco è legata alla velocità di rotazione \\dot{\\theta}. Convenzionalmente, se \\theta aumenta con una rotazione antioraria, \\omega = \\dot{\\theta} \\mathbf{k}, dove \\mathbf{k} è un versore uscente dal piano. La fonte usa una convenzione opposta per \\theta, risultando in \\omega = -\\dot{\\theta} \\mathbf{k}. Calcoliamo il prodotto vettoriale \\omega \\times (C-A): \\omega \\times (C-A) = (-\\dot{\\theta} \\mathbf{k}) \\times (R \\mathbf{j}) = -R\\dot{\\theta} (\\mathbf{k} \\times \\mathbf{j}) Ricordando che \\mathbf{k} \\times \\mathbf{j} = -\\mathbf{i}: = -R\\dot{\\theta} (-\\mathbf{i}) = R\\dot{\\theta} \\mathbf{i} Quindi, v_C = R\\dot{\\theta} \\mathbf{i}.\nConfronto delle Velocità e Relazione Integrata: Le due espressioni per la velocità del centro C devono essere uguali: \\dot{x}_C \\mathbf{i} = R\\dot{\\theta} \\mathbf{i} Questo implica la seguente relazione differenziale tra le velocità lineari e angolari: \\dot{x}_C = R\\dot{\\theta} Integrando questa equazione rispetto al tempo, otteniamo una relazione finita tra la posizione orizzontale del centro del disco e l’angolo di rotazione: x_C = R\\theta + \\text{costante} Questa costante dipende dalle condizioni iniziali (ad esempio, se x_C=0 quando \\theta=0, la costante è zero).\n\n\n\nConclusioni sul Caso Guida Fissa: La relazione x_C = R\\theta + \\text{costante} è un vincolo finito tra le coordinate x_C e \\theta. Ciò significa che delle due coordinate apparentemente libere (x_C e \\theta), solo una è indipendente. Quindi, nel caso del puro rotolamento di un disco su una guida fissa in un piano, rimane un solo grado di libertà. La combinazione del contatto con la guida e del puro rotolamento toglie due gradi di libertà dai tre iniziali del disco come corpo rigido nel piano. Inoltre, in questo caso specifico, il vincolo di mobilità (sulle velocità) si riduce a un vincolo di posizione (sulle coordinate). Un vincolo che può essere espresso come una relazione finita tra le sole coordinate è detto olonomo.\n\n\nEsempio: Puro Rotolamento su Guida Mobile\n\nSetup: Consideriamo ora un disco che rotola senza strisciare su una guida mobile, come un’asta che può traslare (ad esempio, lungo l’asse X). Il punto di contatto tra il disco e l’asta è ancora A.\nCondizione di Puro Rotolamento: La condizione v_A^{\\text{disco}} = v_A^{\\text{guida}} continua a valere.\nDifferenza Fondamentale: A differenza della guida fissa, la guida mobile ha una sua velocità, quindi v_A^{\\text{guida}} è generalmente diversa da zero. Di conseguenza, v_A^{\\text{disco}} sarà generalmente diverso da zero.\nPunto di Contatto NON è il CIR: Poiché il punto di contatto A sul disco ha una velocità diversa da zero (v_A^{\\text{disco}} \\neq 0), il punto A NON è il Centro di Istantanea Rotazione del disco. Il CIR di un corpo rigido è, per definizione, il punto con velocità nulla.\nEffetto sui GDL: Anche nel caso di guida mobile, il vincolo di puro rotolamento toglie due gradi di libertà al moto relativo tra il disco e la guida nel punto di contatto, analogamente al caso della guida fissa. Tuttavia, l’analisi completa dei GDL del sistema composto (disco + guida mobile) richiede di considerare anche i GDL della guida stessa. L’importante distinzione rispetto al caso della guida fissa, dal punto di vista cinematico del singolo disco, è che il punto di contatto non ne è il CIR.\n\nSpero questa riorganizzazione e integrazione della spiegazione sia chiara e completa.\n\nEcco un resoconto dettagliato e commentato, formattato come richiesto:\nSpiegazione sul Concetto di Punto di Contatto e Vincoli (da “flashcard”)\nIl professore inizia introducendo la notazione e un concetto fondamentale legato al punto di contatto nel puro rotolamento: la sua natura molteplice.\n1. La Natura Molteplice del Punto di Contatto nel Puro Rotolamento\n\n\nIntroduzione del Simbolo A\n\nAnche se si usa il simbolo unico A per indicare il punto di contatto, è cruciale capire che questo simbolo, in realtà, racchiude l’idea di tre “personaggi” o punti distinti.\n\n\n\nI Tre Punti nel Puro Rotolamento (Concetti Definitivi)\n\nA’: Questo è il punto materiale che appartiene al disco e si trova a contatto con la guida.\nA”: Questo è il punto materiale che appartiene alla guida e si trova a contatto con il disco.\nA_geom (o A geometrico): Questo è il punto geometrico nello spazio in cui i due punti materiali A&#039; e A&#039;&#039; si trovano a coincidere istante per istante.\n\n\n\nNatura Fisica vs. Geometrica\n\nA&#039; e A&#039;&#039; sono definiti come punti materiali perché appartengono fisicamente a corpi rigidi (il disco e la guida, rispettivamente).\nA_{geom} è un punto geometrico, una posizione nello spazio, dove la coincidenza dei punti materiali avviene in un dato istante.\n\n\n\n2. Velocità dei Punti nel Puro Rotolamento (Condizione di Guida Fissa) (Analisi della Velocità)\nSi considera il caso specifico in cui la guida è fissa.\n\n\nVelocità dei Punti Materiali (A&#039;, A&#039;&#039;)\n\nPer la guida fissa: La velocità del punto A&#039;&#039; (punto della guida a contatto) è necessariamente nulla. v(A&#039;&#039;) = 0.\nPer il puro rotolamento: La condizione fondamentale di puro rotolamento (senza strisciamento) impone che la velocità del punto del disco a contatto (A&#039;) sia uguale alla velocità del punto della guida a contatto (A&#039;&#039;).\nCombinando le due, si ha che la velocità del punto del disco a contatto è anch’essa nulla: v(A&#039;) = v(A&#039;&#039;) = 0.\nSpiegazione: Questa è una condizione istantanea. I punti materiali che si trovano in contatto in quell’istante hanno velocità nulla in quell’istante rispetto alla guida fissa. Il professore sottolinea che “non ci sono santi”, se la guida è fissa e non c’è strisciamento, la velocità istantanea dei punti materiali di contatto è nulla. Se non fosse così, ci sarebbe strisciamento.\n\n\n\nVelocità del Punto Geometrico (A_geom)\n\nA differenza dei punti materiali A&#039; e A&#039;&#039; che hanno velocità nulla nell’istante del contatto, il punto geometrico A_geom in cui questi coincidono si muove se lo si considera in istanti diversi.\nQuesto è un punto chiave: A&#039; e A&#039;&#039; sono sempre i punti attualmente a contatto, che cambiano istante per istante sul bordo dei corpi. A_geom è la posizione dove il contatto avviene in un dato istante.\nVelocità di A_geom: Il punto geometrico in cui i punti di contatto coincidono istante per istante si muove con la velocità del centro del disco.\n\n\n\nEsempio Visivo (Disco che Roto-Trasla)\n\nImmaginate una “foto” del disco al tempo T_1 e una al tempo T_2 &gt; T_1. Il disco si è spostato roto-traslando.\nIl punto di contatto geometrico (la posizione sulla guida dove il contatto avviene) si trova sempre sotto il centro del disco (C).\nDi conseguenza, questo punto geometrico si sposta sulla guida con la stessa velocità orizzontale del centro del disco.\n\n\n\nEsempio della Moneta\n\nSi prende una moneta (idealmente con zigrinatura per identificare punti sul bordo) e la si fa rotolare su una superficie piana fissa (la mano).\nPunto Materiale: Si segna una zigrinatura. Quando quella specifica zigrinatura tocca la superficie (la guida), in quell’istante, quel punto materiale della moneta ha velocità nulla rispetto alla superficie. Subito dopo, mentre la moneta rotola via, quel punto materiale si solleva e acquista velocità diversa da zero.\nPunto Geometrico: Il punto geometrico sulla superficie (mano) dove il contatto avviene in un dato istante è diverso dal punto geometrico di contatto nell’istante successivo. Questo punto geometrico di contatto si sposta sulla superficie con la velocità con cui si muove la moneta nel suo complesso, che è la velocità del suo centro.\nIl professore ribadisce che è fondamentale distinguere tra i punti materiali (istantaneamente fermi nel contatto) e il punto geometrico (che si sposta).\n\n\n\n3. Classificazione del Vincolo di Puro Rotolamento (Proprietà del Vincolo)\nIl professore discute la natura del vincolo imposto dal puro rotolamento in termini di vincoli olonomi e anolonomi.\n\n\nGeneralmente: Vincolo Anolonomo\n\nNonostante in casi molto specifici (come il puro rotolamento 2D che si mantiene sempre nello stesso piano) possa sembrare simile a un vincolo olonomo, in generale il vincolo di puro rotolamento non è olonomo, bensì anolonomo.\nÈ definito come un vincolo di pura mobilità.\n\n\n\nEsempi di Vincoli Anolonomi Legati al Rotolamento\n\nSfera su un Piano Fisso: Una sfera (o palla) che rotola senza strisciare su un pavimento o un piano fisso è l’esempio classico di un vincolo anolonomo. Il professore specifica che questo vincolo di velocità non è integrabile, rendendolo molto difficile da trattare analiticamente.\nRuota della Bicicletta: Anche una ruota di bicicletta che rotola senza strisciare è un vincolo anolonomo. Se la ruota rimane sempre nello stesso piano verticale, il vincolo è anolonomo. Se inizia a cambiare direzione (quindi il piano di rotolamento cambia), diventa subito un vincolo anolonomo.\n\n\n\nImplicazioni dei Vincoli Anolonomi\n\nUtilità Pratica: Nella vita reale, la natura anolonomo del puro rotolamento (come quello delle ruote di un’automobile) è vantaggiosa perché non limita le configurazioni spaziali raggiungibili. Permette di fare manovra e raggiungere posizioni che non sarebbero accessibili con un vincolo olonomo (che limiterebbe i gradi di libertà configurazionali).\nComplessità Analitica: Dal punto di vista della meccanica analitica, i vincoli anolonomi sono “un disastro” da trattare. Richiedono l’uso di equazioni più complesse, come le equazioni di Hafele.\n\n\n\n4. Vincolo Numero 7: Contatto con Strisciamento (Nuovo Vincolo)\nIl professore introduce un diverso tipo di vincolo tra corpi rigidi: il contatto con strisciamento.\n\n\nDefinizione e Contesto\n\nÈ un vincolo che si realizza tra due corpi rigidi, chiamati BP_1 (Body Part 1) e BP_2 (Body Part 2).\nImplica un punto Q appartenente al primo corpo rigido (BP_1) che è a contatto con una superficie \\sigma del secondo corpo rigido (BP_2).\nLa superficie \\sigma ha una normale esterna N_{\\sigma} nel punto Q.\n\n\n\nCondizione del Vincolo (Equazione Fondamentale)\n\nLa condizione imposta dal contatto con strisciamento è meno restrittiva rispetto a quella del puro rotolamento. Il puro rotolamento richiede che l’intero vettore velocità sia uguale nei punti di contatto dei due corpi.\nIl contatto con strisciamento richiede solo che le componenti delle velocità dei punti di contatto, proiettate lungo la normale alla superficie nel punto di contatto Q, siano uguali.\nLa formula che esprime questa condizione è: V_Q^{BP1} \\cdot N_{\\sigma}(Q) = V_Q^{BP2} \\cdot N_{\\sigma}(Q) Dove:\n\nV_Q^{BP1} è la velocità del punto Q considerato come appartenente al corpo rigido BP_1.\nV_Q^{BP2} è la velocità del punto Q considerato come appartenente al corpo rigido BP_2.\nN_{\\sigma}(Q) è il vettore normale esterna alla superficie \\sigma del corpo BP_2 nel punto di contatto Q.\n\\cdot indica il prodotto scalare.\n\n\n\n\n\nSignificato della Condizione\n\nQuesta condizione è “naturale” ed è il modo per mantenere il contatto tra i due corpi.\nRichiedendo l’uguaglianza delle componenti normali delle velocità, si impedisce che i corpi si allontanino l’uno dall’altro o si compenetrino nella direzione perpendicolare alla superficie di contatto.\nLe componenti tangenziali delle velocità dei due punti di contatto possono essere diverse; è questa differenza nella velocità tangenziale che costituisce lo “strisciamento”.\n\n\n\nEsempio del Vincolo con Strisciamento (Applicazione/Esercizio)\n\nSi considera un sistema composto da un’asta rigida OQ (chiamata BP_1) e una lamina rigida (chiamata BP_2).\nL’asta è incernierata in un punto fisso O (l’origine degli assi X e Y nell’esempio), quindi il suo atto di moto è puramente rotatorio attorno a O.\nLa lamina ha un lato rettilineo che funge da superficie \\sigma.\nIl contatto avviene nel punto Q dove l’asta tocca il lato della lamina.\nNell’esempio disegnato, il lato della lamina è verticale, e la normale esterna N_{\\sigma} a questo lato è orizzontale e rivolta verso sinistra. Il professore specifica che in questo caso semplice la normale è sempre la stessa lungo tutto il lato.\nNell’esempio specifico del disegno fornito, la normale N_{\\sigma} è il versore -\\mathbf{i} (assumendo l’asse X rivolto verso destra).\nApplicando la condizione del vincolo V_Q^{BP1} \\cdot N_{\\sigma} = V_Q^{BP2} \\cdot N_{\\sigma}, si sta imponendo che la componente orizzontale della velocità del punto Q (visto come appartenente all’asta) sia uguale alla componente orizzontale della velocità del punto Q (visto come appartenente alla lamina).\nQuesto assicura che l’asta e la lamina rimangano a contatto lungo quel lato, anche se il punto Q sull’asta scivola (striscia) lungo il lato della lamina.\n\n\n\nIl professore conclude la descrizione di questo vincolo, menzionando che gli esempi pratici e un esercizio completo verranno affrontati successivamente.\nReferences\nmeccanica-lez06_trascrizione"},"6--full-note/meccanica-lez06_trascrizione":{"slug":"6--full-note/meccanica-lez06_trascrizione","filePath":"6- full note/meccanica-lez06_trascrizione.md","title":"meccanica-lez06_trascrizione","links":[],"tags":[],"content":"Se per cortesia potete chiudere le porte, capisco che faccia caldo, ma almeno una delle due chiudiamola.\nQuella più vicina se la potete chiudere. Allora però con l’acqua Allora, vi dico anche a voce, avete ricevuto il messaggio che domani ci sarà lezione e invece mercoledì prossimo avrete le esercitazioni. Martedì ci sarà. Questo cambiamento serve in modo da dare all’esercitatore tutto ciò che serve per fare esercizi sul corpo rigido piano. E come non sono sicuro del can sicuramente non riesco a finire oggi tutto ciò che serve, è meglio se faccio lezione. Ok. Allora, oggi l’argomento principale della lezione è teorema di M. Il teorema di Mozzi ci dice la seguente cosa. Se Omega diverso da 0 per corpo D il più generale atto di mo B è liquidale con asse di moto se volete asse di mi. di equazione m lambda - o uso la m per ricordarci che sono punti dell’asse di num lambda omega + omega vettor vo di omega². Questo omega al quadrato è il modulo della velocità angolare. al quadrato con lambda che è un parametro reale, d’accordo? Per i punti dell’asse vale VM lambda uguale al variante scalare per omega vettore/ega² parallelo ovviamente ad Omega dove i lo metto tra parentesi, visto che l’abbiamo visto solo ieri è l’inariante forse è meglio chiudere anche l’altro. che devono fare. Vabbè, c’è una temperatura tropicale, non si possono le finestre. Vabbè, l’in variante scalare è questo qui. Se in solo se In variante scalare uguale a 0, l’atto di moto si riduce a rotatorio. D’accordo? E al caso, ma di mozzi che parte qui si riduce, cioè coincide con l’asse di istantanea rotazione. Ok, questo è se omega è uguale a 0 l’atro di moto è 32. Questo lo sappiamo già e non c’è bisogno di metterlo dentro. Diciamo quando omega è diverso da 0 ci chied ci chiediamo come si è fatto eh come sia fatto. Ecco, quale sia l’atto di moto più generale? Scopriamo che è appunto l’atto di moto e liquidato, non è il rototrafiatorio. È un sotto caso del del rototrafiatore perché possiamo sempre trovare l’asse di mossa. D’accordo. Allora, la dimostrazione la dimostrazione che facciamo qui in aula è una dimostrazione che tutta il lemma che abbiamo visto ieri su web suip potete trovare una dimostrazione costruttiva e come vi ho detto ieri scegliete quella che preferite, potete fare quella che facciamo in aula, potete fare quella che c’è su Vip, quella costruttiva e potete anche fare quella più sintetica che di quest che vi farò sempre col metodo allm. Allora, cominciamo a dire che componiamo per ogni P appartenente al corpo rigido componiamo la velocità di P come segue. Scriviamo VP uguale VP parallelo + VP perpendic perpendicolare dove BP parallelo è parallelo a omega e di P perpendicolare, indovinate un po’, è perpendicolare a Allora, come faccio a fare questa cosa? Eh, introduco, se volete, il versore che è ben definito perché Omega per ipotesi è diverso da 0 m introduciamo un versore parallelo ad omega. N di omega per definizione uguale a omega diviso il suo modulo. Ok. Allora, BP parallelo è uguale a VP scala N omega per N omega. Facciamo il prodotto scalare con la direzione con la direzione di omega attraverso il versore n omega e moltiplichiamo ancora per n omega per un’operazione elementare. Ok? Allora, se esplicitiamo qui ci viene di P scalar omega/ega per omega/ega. Omega vettore lettera adesso raccontata, viene male. Omega intendo il vettore diviso il suo modulo. Qui il vettore diviso il suo modulo. Allora, vedete VP scalar omega, questo è l’invariante scalare. Quindi scopriamo subito che la componente parallela ha proprio l’espressione che troveremo per i punti dell’asse di mol è uguale a i per il vettore omega diviso il suo modulo quadro. Ok? Evidentemente per ogni P e Q appartenenti al nostro corpo rigido. Cosa succede? Le velocità parallele a omega dei punti, le componenti parallele sono tutte uguali perché c’è l’invariante scalare che è lo stesso per tutti. Quindi scopriamo che queste sono quantità irreducibili, cioè se c’è un punto che ha velocità parallela a omega diversa da 0, tutti gli altri punti devono avere la stessa lo stesso vettore, diciamo, la il componente della velocità il vettore componente della velocità parallela uguale Ok? Vedete? C’è l’invariante scalare che è lo stesso per tutti, quindi non c’è non c’è verso. Questa è una quantità che non potete eh ridurre, cioè non riuscite a trovare punti del corpo rigido che abbiano velocità parallela uguale a Z0. Una volta che uno ce l’abbiamo diversa da zero, tutti la devono avere uguale e diversa da Z. Quindi, una volta che avete fissato quello, ecco, può succedere di trovare un punto che ha velocità uguale a Z0 e allora tutte le componenti parallele faranno lo stesso mestiere. Oh! Eh, cosa succede ulteriormente? Beh, dobbiamo dire che cos’è di P perpendicolare. Beh, a questo punto sarà per definizione VP - VP parallela. Ok, ora Sono riuscito a disordinarmi gli appunti. Va bene? Allora, faccio cose. Quanti i fogli sono tanti. A ve la faccia braccio se torcia la eh Ok, allora consideriamo la legge di distribuzione. Allora, vogliamo punti, vogliamo per definizione di assi di mozzi punti che abbiano solo la componente parallela. Perché l’asse di vogliamo trovare il luogo dei punti tali che DT perpendicolare è uguale a 0 che perché l’asse di mo ha tutte ha. Poi alla fine scopriremo che ha appunto per definizioni deve avere punti deve essere fatto di punti con componente solo parallela ad omega. della velocità, per come l’abbiamo definito parlando del moto liquidato. Allora, scriviamo LDB in questo modo. DP uguale DQ la riferiamo a O rispettare poi come abbiamo scritto l’asse nell’enunciato del teorema più Omega vettor t - uguale. Allora, anzi per scrivere uguale qui, adesso la esplicitiamo, diciamo. Over scriviamo dt parallela + d perpendicolare uguale do parallela + perpendicolare + omega vettor - non ho fatto altro che scomporre d e V. Adesso facciamo questa osservazione. Abbiamo detto che tutte le componenti parallele Le possiamo semplificare perché sono uguali. L’abbiamo visto in quella laagna lì, sono tutte i omega su omega qua, quindi posso semplificarlo qui e qua e imponiamo perché vogliamo cercare proprio quel luogo di punti con componenti perpendicolari delle velocità uguali a 0. Vpresi dovuto chiamarle Vabbè, dopo correggiamo. Vp perpendicolare uguale a 0. Riatami VN così ciamo già con col simbolo giusto. Beh, se vi consentite non siete tanto conti e vabbè poi cambiamo cambiamo l’equazione, ma sarà equivalente via. Allora, VP ortogonale uguale a 0. Cosa significa? Guardate, se solo se perché Questa legge deve valere eh se solo se eh avete che portiamo a sinistra dell’uguale questo membro e scambiamolo. No, lo lasciamo. Siccome prende il segno meno scambiamo t- vettor omega uguale a do perpendicolare. Ah, che bella equazione, no? L’abbiamo studiata ieri. È lei. Cosa ho fatto? Ho preso questo, l’ho portato di là, prendo il segno meno, scambio i due fattori e me lo rimarcio e trovo questa equazione qui. Allora, per il Lemma, vedete qui, Omega la consideriamo nota di Ottogonale. la consideriamo nota. No abbiamo riferito l’atto di moto di cui consideriamo notte le componenti. Abbiamo proprio la situazione del lemma. Per il lemma la soluzione è data da P. Lamb - o = lambda omega + omega vettor di ortogonale diviso omega². Perché Cosa vi diceva il lemma? Avevate il lambda - ve lo scrivo qua sotto, ma poi lo cancello subito, uguale lambda a + a vettor b² per l’equazione - o vettor a = b. Soluzione di questa equazione qua con a b = 0. Ora lo scriviamo Qui ovviamente V ortogonale scalar omega fa 0. Quindi questa equazione ammette soluzione la soluzione questa. Adesso se qualcuno non fosse chiaro, perché abbiamo usato quella soluzione? Perché dobbiamo avere a sc ug per costruzione io ho perpendicolare perpendicolare omega, non ci sono problemi. D’accordo. Ah, questo lo cancello, tanto l’abbiamo visto ieri. Se avete dubbi chiedeteli. Ora, ehm, questo è appunto l’equazione dell’asse di mozzi. Ho eh di norma Lass di Mozzi. Ah, diciamola così. Beh, l’asse di Mozzi è ehm scritto possiamo scriverlo anche con la P, tanto sono simboli. m lambda - o = lambda omega + omega vettor vo tutto vo/ omega qu’è una direte beh, ma son diversi di fatto no. Osserviamo che eh le due equazioni descrivono la stessa retta di tangente omega. Mh, se fate la derivata rispetto a lambda che farà trovate omega di tangente omega. in quanto evidentemente di O vettor omega vettor di O coincide con omega vettor di O perpendicolare. La componente parallela non da contributo in quel prodotto vettoriale, quindi è proprio la stessa retta. Adesso vi è più comodo scriverla così nella forma che c’è anche nell’enunciato per il semplice motivo che poi quando il vi riducete all’asse di istantanea rotazione, quando vi riducete all’asse di istantanea rotazione mettere perpendicolare non serve perché tutti punti hanno componenti della velocità parallela uguale a 0 e quindi viene più comodo usare questa notazione qui, ma sono esattamente la stessa retta. Ok? Vale, adesso facciamo la verifica su questa pi lambda uguale O + omega vettor lambda - giusto? Allora, verifichiamo che viene proprio quella velocità. Vabbè, ovviamente, però verifichiamola. Questo è o + omega vettor lambda omega + omega vettor di o perpendicolare fratto omega perpendicolare diviso omega² uguale do più primo pezzo non dà contributo, il secondo pezzo è uguale a 1 su omega² che moltiplica Allora, abbiamo omega vettor omega vettor, abbiamo il primo scalare, il terzo. Omega scalaro di O perpendicolare per omega, ma questo fa 0 - omega il primo scalare il secondo che moltiplica il terzo vettore omega qu VO perpendicolare. Allora, cosa scopriamo? Scopriamo che questo è uguale a B - B perpendicolari perché i 2 omega² numeratore e denominatore si semplificano e poi c’è il segno meno. E questa che cos’è? È di O parallela che questa che cos’è? I omega/ omega. Abbiamo verificato qui È vero che l’asse di mozza che abbiamo trovato soddisella equazione. Ah, va bene. Cosa succede? Dobbiamo dimostrare la seconda parte del del teorema, cioè parlare dell’asse di istantanea rotazione. Ok? Allora, vale poi se I è ugora l’asse di di morsi diventa asse ri istantanea rotazione p lambda è uguale a 0 per ogni pi lambda appartenente a all’asse. Quindi abbiamo trovato unasse punti tutti di velocità nulla, quindi l’asse di scattare rotazione viceversa. Se esiste eh di Q se esiste Q con VQ uguale a 0. Ok? Allora eh Q appartiene a R che esiste. è lo stesso ragionamento che abbiamo usato per trovare l’asse di di mozzi, solo che questa volta vale che eh VP scalar omega uguale a 0 per ogni Parteno rigido. D’accordo? Quindi tutte le componenti parallele sono uguali a 0. Avete solo la velocità e tutte le velocità in sostanza sono ortogonali ad omega. E vi basta trovare il punto dell’asse. Prendete poi la direzione che passa per il punto è parallela a omega e trovate l’asse. O equazione di R. avete lambda - o esattamente uguale lambda omega + omega vettor su omega qu. C’è qualcuno che voleva fare una domanda? Scusate, allora può riec\nR esiste, nel senso che potete ripetere L’asse di istantanea rotazione R esiste. L’asse istantanea rotazione esiste e fa il mestiere giusto. Lo potete ricavare. Ok. Allora Sì. Allora, in realtà vi basta appunto trovare un punto del corpo rigido che abbia velocità nulla, d’accordo? In variante scalare mi viene uguale a zero. Già il teorema di Mozzi, vabbè, chiaramente stiamo facendo un appetizio principio. Questo vi dice, diciamo, sapendo il teorema di Mozzi, sapete che esiste l’asse istantaneo perché è vero, è vero perché ehm comunque se volete esiste l’asse di Mi. E poi sapete che l’invariante scalare è uguale a 0 e quindi quell’asse diventa l’asse di istantanea. Sono stato convincente, vi vedo perplessi, lo ripeto. Allora, trovate un punto che ha velocità nulla. A quel punto scoprite che l’invariente scalare è uguale a 0. Quindi se essendo un invariante Stessa cosa invariante scalare uguale a 0 vuol dire che tutti i punti sono orto hanno velocità ortogonale a omega e dice ma quelli che son fermi appartengono all’asse istantanea rotazione che esiste perché esiste la parte precedente della dimostrazione l’asse di Mozzi che per i uguale a 0 è fatto di punti di velocità 1 e lo Devo scrivere. No, dai, adesso ho spiegato tre volte se dopo la terza volta siete non siete convinti. Ci sono 10 pagine di dimostrazione su internet di bip, andatevele a leggere e se non siete convinti mi venite a chiedere. Ok. Oh, ehm L’asse di Mozzi è luogo di punti di con velocità. di modulo minimo. Ok. Come si fa a capire questa cosa? Beh, la dimostrazione dopo tutto quello che abbiamo visto nel teorema di Morzi è banale. Nel senso ah, non ho messo il quadratino. Il quadratino. Vabbè, mettiamolo qui per dire che la dimostrazione è finita. Dimostrazione di questo corollario vale per ogni P appartenente a corpo rigido VP, abbiamo già detto VP parallelo più VP perpendicolare. Adesso se facciamo Vt modulo quadro penso ci verrà uguale VP parallelo modulo qua. + VT perpendicolare modulo quadro. Naturalmente quando fate il prodotto scalare di VP con se stesso per ottenere questo oggetto i prodotti VP parallelo scalare VP perpendicolare si verranno tutti nuli. D’accordo? Quindi rimane questa roba qui e questa è evidentemente maggiore più uguale a BP parallelo quale che è, se volete i omega su omega² al quadrato e non c’è altro da dire, sono soliti i punti di Mozzi, hanno i punti dell’asse di Mozzi hanno solo la velocità parallela e quindi qualsiasi altro punto del corpo di che non appartenga all’asse di mozi a velocità di mollo quindi è una semplice banale conseguenza del teorema. Ok, adesso vi volevo raccontare il caso piano che è quello che vi interessa per gli esercizi il caso piano come che cosa possiamo dire? Ci sono due teoremi. Il primo teorema è il teorema di Eolero che ci dice che l’atto di moto di un corpo rigido piano se non è traslatorio è rotatorio. D’accordo? Cosa vuol dire? Nel caso del corpo rigido piano ci riduciamo a due possibili atti di moto, cioè quello traslatorio in cui tutti i punti hanno uguale velocità oppure quello rotatorio. Allora, in questo caso diremo che esiste il centro di istantanea ropa. Allora, qui vè la dimostrazione è una societagina un corollario di mozzi. Avete che I è ugale a 0. D’accorda? In quanto omega è perpendicolare. al piano pi greco e bp appartiene al piano pi gre per ogni p appartenente al nostro corpo rigido piano. Quindi ci viene in variante scalare uguale a 0. Quindi se omega diverso da 0 allora esiste R. D’accordo? E quindi esiste il C, il centro di franzeg uguale a 0 chiaramente l’atto di moto sarà È proprio un teoremino. Una volta che uno visto il teorema dei Mozzi, questo è una banalità. Basta osservare che siccome Omega è sempre perpendicolare al piano che contiene i punti del vostro corpo rigido, le velocità di questi punti sono tutte contenute nel piano. Quindi quando fate il prodotto scalaro omega vettor la velocità di qualsiasi punto del corpo rigido vi verrà zero, l’inariante scalare viene zero e quindi se omega è diverso da 0 sappiamo che esiste l’asse di istantanea rotazione. Sappiamo che quindi esiste che è parallelo ad omega, quindi è perpendicolare al piano. Esiste l’intersezione unica di questo asse con il piano è C e l’atto di modo è rotatore. Se omega è invece uguale a 0 e banalmente avete la il teorema però è un teoremino utile e di cui si potrebbe chiedere anche lazione perché peraltro essendo così banale ok? E poi poi invece c’è un altro teorema. Questo è un teorema che questo molto semplice ma molto utile, nel senso che vi aiuta a individuare graficamente il centro di istantanea rotazione per il corpo piano. Questo è il teorema di questo signore. Le sento si dice sciale. Queste due s Non si sentono, eh? Scialle, come se fosse scialle con la e finale troncata. Cosa ci dice questo Torena? Siano a e B appartenenti a un corpo di rigido piano tali che di A diverso da VB. Allora, con salto oggi che sembra molto importante in realtà no, vediamo nella dimostrazione. Allora, eh VA diverso da VB non parallele, anzi l’ho scritto male. cancellate di A non è parallela a + b. Allora, il Cir si trova all’intersezione della retta ra passante per A e perpendicolare A. Ok? E della retta R passante per B e perpendicolare AB. Questa è leon. Vedete? Basta che voi conosciate le velocità di due come sono, diciamo, più che conoscere il valore della della velocità in metro a seconda dicendo. Basta che in realtà sappiate comeè messo il vettore a come messo il vettore B. Se questi non sono paralleli, potete individuare il Cir in questo modo che è appunto interessante per individuare il gir per i corpi rigidi piani. Come vi ho detto alle volte può essere di difficile. Ci sono cinematiche piuttosto complicate in cui individuare il Ciro è difficile. Non siete impiccati a riferire l’atto di moto al CR. Vi è incomodo perché buttatevi un pezzo, cioè vi viene vp = omega vettor n c dove c è CR. Quindi buttate via DC perché è uguale a 0 essendo il C. Va bene? Allora, dimostrazione. Avete pa non parallela a DB. Cosa significa? Segue BA diversa da B. Cos’altro segue? Eh, non può essere atto di moto traslatorio perché sennò queste velocità, le velocità sarebbero tutte uguali. Non è, facciamo proprio tutti i passaggi, non è ADM traslatorio. Allora, per Il teorem di umero di n è rotatorio, quindi omega diverso da 0. Ovviamente queste note velocità diverse non le ottenete. E eh Esiste il Cir, chiamiamolo C. Dove sta? E ce lo dice il teorema. Esiste C. Il Cir non sappiamo ancora dov’è. Mh. Però possiamo scrivere l’atto di moto rotatorio, cioè riferendo l’atto di moto al circo. che è quello rotaslatorio riferito al C. Potete scrivere DA uguale BC, ve lo scrivo, poi lo cancello, più omega vettore a - cb uguale bc + omega vettor b. Lo stiamo riferendo al nostro circ anche se non sappiamo dove stia, lo possiamo fare perché sappiamo che esiste questo uguale a 0 D’accordo? Allora, a questo punto cosa osserviamo? Che A - C è un vettore che sta su retta passante per A. a e a - c è perpendicolare a perché perché per il prodotto vettoriale tre fattori, diciamo, questo oggetto è perpendicolare a ciascuno dei due, quindi perpendicolare in particolare ad amp B - C è un vettore che sta su RB e eh cosa succede? Che B - C è perpendicolare a BP. Stesso motivo. Questo oggetto è perpendicolare a ciascuno dei due fattori del prodotto vettoriale. Ok? Allora, a questo punto il teorema è dimostrato perché perché scopriamo che C sta sia sulla retta RA che sulla rete RB. E qui l’unico modo in cui lo può fare, siccome queste rette non sono, diciamo, non sono parallele, è che eh C sia l’intersezione tra le due, d’accordo? dimostrazione finita. Facciamo per chiarirvi le idee, come esempio. Allora, sia prendiamo un punto A con velocità, d’accordo? Poi prendiamo un punto B corpo rigido che avrà una sagona, quella che lo dite voi. Questo è BP, ok? E prendiamo ci prendiamo una velocità BB fatta così. Naturalmente per avere rigidità questa proiezione, quest’altra La proiezione devono essere uguali, più o meno nel disegno lo sono. La potrei anche fare più lunga questa velocità. Facciamoli, l’allunghiamo un attimino. Questa è B. Rispettiamo le eh richieste di quel teorema che abbiamo visto ieri. Qui ho messo anche a in B come direzione, proprio perché in questo modo posso fare un esempio fatto bene. Allora, cosa succede? Prendete la retta per A perpendicolare a VA. Poi la retta per B perpendicolare a DB. Qui ci mettiamo un bell’angolo retto. Questo è RB. Ed eccolo qui il C. No, la tentazione, come vi ho detto alle volte, dimenticando il teorema di ieri, potete presentarmi questo esempio e che naturalmente sento un esempio sbagliato a qualche punto devo ferro perché questo non va, anche se le due velocità sono diverse o le potreste anche prendere uno dice “Beh, le prendo così, non va bene.” No, perché quell’oggetto non Non è rigido. Bene, attenzione, quando fate il disegnino fatelo. Casomai non lo fate, mettete la dimostrazione bassa. Se siete furbi e non vi ricordate questa cosa, mettete la dimostrazione senza farvi questo es. Va bene? Oh, con gli atti di moto abbiamo finito, siamo contenti. Avete problemi con questa dimostrazione? No. Ok. Poi prima di farvi degli esercizi che servono naturalmente per fare degli esempi concreti, ho bisogno di introdurre dei È vero che guardiamo il corpo rigido però gli esercizi linea di massima implicano la presenza di vincoli per il corpo di piano e quindi è necessario prima parlare un pochino di prima vi faccio il discorso generale senza stare a scendere troppo nel dettaglio. Allora, possiamo introdurre due classi i vincoli di posizione che limitano le configurazioni accessibili. al sistema. Come vi ho detto, sono dispositivi che fanno questo mestiere di impedirvi, per esempio, se avete un anellino vincolato ad una sbarra, questo anellino si potrà muovere solo lungo la sbarra e non avrà gradi libertà perpendicolari alla sbarra, quindi avrà una sola coordinata libera. Questi esempi li abbiamo già fatti, quindi quando abbiamo passato parlato dei vincoli di posizione per capire che anche il vincolo di rigidità del corpo rigido è un vincolo di posizione. E poi ci sono i vincoli di mobilità. I vincoli di mobilità sono dispositivi che limitano B velocità accessibili al sistema. Vedremo gli esempi. Cicamente vedremo il caso importante per gli esercizi di questo lido piano, che è il caso del puro rotolamento. Nel caso del corpo rigido piano, come lo vedremo noi, in realtà poi questo tipo di vincoli si riduce a vincoli positivi. E infatti cosa succede? Allora, se avete eh potreb che la componente Z della velocità sia uguale a 0 per i vostri punti. Potete imporre altri tipi di vincoli, però attenzione. Ehm, allora, vediamo innanzitutto la struttura dei vincoli di posizione. Le due classi, vi dico subito, hanno intersezione, non prima di farvi esempi di vincoli di mobilità, vi dico le intersezioni, le due classe, appunto, vincoli in mobilità e vincoli di posizione hanno intersezione e non nulla. Ehm, vediamo prima, appunto, in generale i vincoli di posizione. Allora, si è dato un sistema di n punti materiali generico, eh imponiamo i piccoli, eh F1 di ehm X1 Xn potrebbe in generale dipendere anche da T uguale a 0. Potevo scrivere anche P1 PN, va bene? Fino ad arrivare a FM t x1 xn e t ug a 0. D’accord? In questo, vedete, abbiamo m vincoli di posizione, cioè diamo m funzioni che devo essere uguali a 0 e possiamo ricavare che alcune posizioni saranno scrivibili in funzione delle altre. Naturalmente facciamo per ipotesi mettiamoli indipendenti. D’accordo? Potrei mettere, che ne so, il quadrato del primo vincolo m volte, ma sarebbe sempre come vincolo. Quindi Prendiamo indipendente. Oh! Eh da un vincolo di posizione. Quello che si può vedere che potrei ricavare un vincolo di velocità facendo la derivata di quella funzione lì. Mettiamo di avere f1 xn e t = 0. Allora posso dire f su tt. Siccome questa f identicamente uguale a è uguale a 0, se faccio la derivata questa sarà uguale a 0. Ma se la scriviamo esplicitamente che cosa sarà? Sarà eh qui sarà questo è un gradiente quello che vi scrivo di fatto d su dx1 scalare x1 1 + df su dx2. Sto facendo una derivata totale scalare x.2 + df dx m scalare x. M la derivata parziale di f. Ho fatto la derivata totale, quindi derivate di di funzione di funzione. Queste sono funzioni del tempo m x1 t xn d t. Quindi io qui dovrei scrivere il gradiente rispetto x1. Eh, mi concedete questa notazione. Quelli però vi avviso son gradienti. Dovreste scrivere, vabbè, facciamolo una volta. Abbiamo che quando scrivo df su d x intendo gradiente rispetto x, ma ci viene comodo una scrittura di questo tipo per per D’accordo? Allora, vedete questo è un vincolo del tipo G X1 X M1 T = 0. Questa è l’espressione e un vincolo di velocità. In generale quelli che si vedono più spesso sono di questo tipo qui, cioè sono lineari nelle velocità, potrebbero anche essere le cose vincolo di mobilità, non di velocità, di mobilità è un vincolo di mobilità. Eh, mamma mia! Come mai non avete protestato? Incro di Vabbè, si capisce di più in realtà diamo una\nM. Ah, dunque, no, scusate, ha ragione, è una N. Grazie. Vabbè, questa vi può mettiamo CN così siamo tutti più tranquilli. Grazie. Ha ragione. Perfettamente. Sì, non c’entrava niente con questa m qua. Va bene? Quindi, dato un vincolo di posizione, uno può ottenere un vincolo di mobilità in cui compaiono le velocità. E allora uno si chiede, vabbè, questi sono vincoli di mobilità farlocchi, nel senso che si riducono al vincolo di posizione. L’unico vincolo che c’è effettivamente è quello di posizione originale. Non è che ci sono altri oggetti in bicolo di mobilità che appunto si riducono per come sono stati ricavati a vincoli di posizione. Ok? Allora, uno si può fare la domanda opposta, cioè dato un vincolo di mobilità, posso ridurlo sempre a vincolo di posizione? Questa è una domanda interessante. Purtroppo non abbiamo gli strumenti matematici adeguati per poter affrontare la questione con abbastanza agio. Quello che vi posso dire è che entra in ballo il problema della cosiddetta integrabilità dei vincoli di mobilità. Se il vincolo, come si dice, è integr a vincolo di posizione, se non lo è si chiama vincolo di pura mobilità. Allora, esistono vincoli di movilità cosiddetti integrali. E lo dico così, servirebbe il linguaggio delle cose differenziali per farlo in maniera onesta. Non ce l’abbiamo, non lo saiamo. Cosidetti vincoli vincoli cosiddetti integrabili che si riducono a vincoli di posizione. Esistono però dei veicoli di mobilità che non sono integrabili e allora li chiameremo, come vi ho detto, il pura mobilità. Quindi non riducibile. Si dicono vincoli di pur mobilità. Allora, adesso se prendiamo i vincoli posizione, i vincoli di pura mobilità, abbiamo due classi di vincoli che non siestano, non sono riduscibili, appunto, questi vincoli non possono essere riportati a vincoli di Ok. Tanto per darvi ancora un po’ di nomenclatura importante, i vincoli di posizione si dicono olonomi, anche si parlerà di olonomia del vincolo che vuol dire che il veincolo è il veicolo di posizione e poi invece vincoli di fora moltibilità si dicono anolonomi e questi sono veramente difficili da trattare. Vi farò un cenno, ma non ne ved Emo all’opera sostanzialmente nessuno. Allora, l’origine di questi di queste parole è greca. Olonomia significa che conoscete per intero la legge che governa il vincolo hanno l’onomia che è l’alfa privativa, quindi vuol dire che non conoscete per intero la legge, ok? Ehm, poiamo l’esempi concreto di vincolo di mobilità, preferisco farvelo direttamente domani quando vi faccio i vincoli per il corpo rigido piano. E cos’altro vi voglio dire? i vincoli si eh dividono anche in vincoli fissi e vincoli mobili. Ad esempio Poi ci saranno anche quelli unilateri e bilateri, ma prima dovrò dare altre opzioni. Ehm, prendiamo un punto P su una circonferenza di raggio rostante. Allora, che cosa avete? Questo è un vincolo di posizione, ovviamente il vostro punto materiale P, qui c’è R, qui ci sarà l’angolo teta. Allora, potete scrivere che x di p del tempo sarà r cosθa d t ed y dt = r sin teta di t. L’avete visto probabilmente esercitazioni, comunque mi torna. Vedete il punto si deve muovere su sulla circonferenza che che vediamo come un anellino su una guida circolare. D’accordo? E qui avete un vincolo fisso. La legge fx y = 0 dipende esplicitamente da tete scriverla f = 0 equivale a x^ + y² - r² = 0. E questa è la circostanza. Ok. vincolo fisso. Potete avere la situazione in cui quelle funzioni delle posizioni, adesso li vediamo solo che incoli in posizione. Per le funzioni della posizione che è eguagliato ug a 0 c’è anche una dipendenza esplicita da f sia, allora ehm sia P su una circonferenza di raggio rt = t vuol dire è che avete fx y t = 0 che scriverete come x² + y² - vt qu = 0. Questo dipende esplicitamente Vedete? C’è questa dipendente striscita del T e questo è un vincolo mobile. Quello che fa la differenza tra i due fatto se tra le due diciamo classi saranno fissi vincoli che non hanno dipendenze esplicite da t E invece saranno mobili quelli che ce l’hanno. Ok? Ho scritto V con V costante sarà dimensioni di velocità da questo scritto, d’accordo? Ho questo come quadro generale, quindi riassumendo Partiamo da prima divisione. La prima divisione è abbiamo i vincoli di posizione, d’accordo? I vincoli posizione che saranno cosiddetti vincoli polonomi. Questi vincoli di posizione eh hanno, diciamo così, quando li li andate a definire, non presentano dipendenze dalla velocità Ok, limiteranno le configurazioni accessibili, capiamo subito. E eh invece poi abbiamo la seconda classe che è quella dei vincoli di mobilità che saranno vincoli che in realtà limitano le velocità più che limitare le configurazioni, limitano le velocità accessibili al vostro sistema, d’accordo? Potete prendere un vincolo posizione, derivarlo e trovate un vincolo di mobilità. Scopriamo che i vincoli di mobilità in realtà possono spesso, ma non certamente sempre essere ridotti a vincoli di posizione. Entra in gioco questo concetto piuttosto complicato di ehm integrabilità. Complicato perché per farlo bene bisogna avere adesso su se prendete belli morosi alberti trovate un esempio di vincoli di posizione, scusate vincolo di mobilità che è un vincolo di pura mobilità perché non è integrabile. Praticamente è la ruota della bicicletta che rotola senza strisciare, un disco che rotola senza strisciare sul piano è un vincolo di pura mobilità, così come la palla, il pallone da calcio che rotola senza strisciare. Questo vuol dire che il punto di contatto è istantaneamente fermo, non striscia sul pavimento, eppure un vincolo in pura. Questo comunque ve lo riprendo domani di sicuro quando parliamo. E poi abbiamo questulteriore suddivisione in vincoli fissi e Ok? E è utile per discorsi che faremo quando parleremo di dinamica e di lagrangiane e conservazioni dell’energia. Allora, se ci saranno vincoli fis mobili in ballo, le cose ci cambiano rispetto alla presenza di sui vincoli fissi. Va bene, direi che per oggi possiamo chiuderla qui. Ci vediamo domani in aula 32."},"6--full-note/prob---programma":{"slug":"6--full-note/prob---programma","filePath":"6- full note/prob - programma.md","title":"prob - programma","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/probabilità","3--tag/materiale-di-studio"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-26 18:51\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: probabilità. materiale di studio\nprob - programma\nI teoremi enunciati senza dimostrazione sono in ==corsivo==. I teoremi con dimostrazione inclusa nel solo programma completo sono indicati in rosso.\n1 Definizione assiomatica di probabilità\n\n﻿﻿Operazioni insiemistiche elementari, leggi di De Morgan, limiti di successioni di insiemi inscatolati.\n﻿﻿Controimmagini e proprietà.\n﻿﻿Operazioni fra funzioni reali di variabile categorica: somma, differenza, moltiplicazione, rapporto, massimo, minimo, limite.\n﻿﻿Spazio campionario, esiti, eventi: definizione, interpretazione modellistica, esempi.\n﻿﻿Operazioni logiche fra eventi.\n﻿﻿o-algebra degli eventi: definizione , interpretazione modellistica, prime proprietà1.\n﻿﻿o-algebra banale, o-algebra delle parti ed altri esempi di o-algebre.\n﻿﻿Spazio misurabile: definizione.\n﻿﻿o-algebra generata da una collezione di eventi. Definizione. La definizione è ben posta. Esempi.\n﻿﻿o-algebra di Borel su R. Definizione. Classi di insiemi che generano la o-algebra di Borel. Le semirette chiuse illimitate a sinistra generano la o-algebra di Borel\n﻿﻿Probabilità: interpretazione modellistica, esempi, definizione1.\n﻿﻿P(0) = 0; ogni probabilità è additiva. Proprietà elementari implicate dalla additività.\n﻿﻿Successioni di eventi crescenti e decrescenti: definizione e probabilità dell’evento limite.\n﻿﻿La probabilità è subadditiva.\n﻿﻿Spazi campionari discreti: la probabilità è caratterizzata dalla densità (discreta); caratterizzazione di una densità (discreta). Esempi. Generalizzazione a o-algebre generate da partizioni discrete. Esempi.\n\n• Eventi impossibili, improbabili, certi e quasi certi.\n2 Probabilità condizionata e indipendenza di eventi\n\n\n﻿﻿Probabilità condizionata: definizione, interpretazione modellistica, casi estremi.\n\n\n﻿﻿La probabilità condizionata è una probabilità nel suo primo argomento.\n\n\n﻿﻿Esempi di utilizzo modellistico della probabilità condizionata.\n\n\n﻿﻿La formula di disintegrazione e delle probabilità totali. Generalizzazioni.\n\n\n﻿﻿La formula di Bayes.\n\n\n﻿﻿Esempi e controesempi.\n\n\n﻿﻿Probabilità di una intersezione e probabilità condizionate.\n\n﻿﻿Coppia di eventi indipendenti: definizione, interpretazione modellistica, casi estremi, esempi.\n\n\n\n﻿﻿Due eventi sono indipendenti se e solo se lo sono i complementari, se e solo se…\n\n\n﻿﻿Famiglia di eventi (mutuamente) indipendenti: definizione, interpretazione modellistica.\n\n\n3 Costruzione di una probabilità su R\n• Criterio di Caratheodory. Controesempio.\n• funzione di ripartizione: definizione.\n\n﻿﻿Condizioni necessarie e sufficienti per essere la funzione di ripartizione di una probabilità sui bore-liani; probabilità di intervalli e di punti; una probabilità sui boreliani è caratterizzata dalla funzione di ripartizione.\n﻿﻿Esempi di probabilità su R: delta di Dirac, probabilità discrete, probabilità con densità Riemann integrabili.\n\n4 Variabili aleatorie\n\n﻿﻿Variabile aleatoria: definizione, interpretazione modellistica, primi esempi.\n﻿﻿La composizione di funzioni misurabili è misurabile.\n﻿﻿Criteri di misurabilità per funzioni a valori in R e R”; somme, prodotti, max, min, sup, inf, limiti di variabili aleatorie reali sono misurabili.\n﻿﻿Le funzioni continue sono misurabili rispetto alle o-algebre di Borel.\n﻿﻿Altri esempi di variabili aleatorie.\n﻿﻿Legge / distribuzione di una variabile aleatoria: definizione, interpretazione e importanza modelli-stica.\n﻿﻿La legge di una variabile aleatoria è una probabilità. Esempi.\n﻿﻿Variabili uguali quasi certamente: definizione e ruolo modellistico. Classi di equivalenza di variabili\nuguali quasi certamente.\n﻿﻿Due variabili uguali quasi certamente hanno la stessa legge. Esempi e controesempi.\n﻿﻿Proprietà valide quasi certamente.\n\n5 Valore atteso / Media / Integrale rispetto ad una probabilità\n\n﻿﻿Variabile aleatoria reale semplice: definizione e caratterizzazione.\n﻿﻿Valore atteso di una variabile aleatoria reale semplice: definizione e interpretazione modellistica.\n﻿﻿Approssimazione di variabili non negative tramite variabili semplici non negative.\n﻿﻿Valore atteso di una variabile aleatoria non negativa: definizione e prime proprietà.\n﻿﻿Variabili non negative con valore atteso infinito e variabili non negative che assumono valore infinito.\n﻿﻿Parte positiva e parte negativa di una variabile aleatoria reale: definizione.\n﻿﻿Variabile aleatoria reale che ammette valore atteso, variabile aleatoria reale integrabile, L’: definizioni\n﻿﻿Valore atteso di una variabile aleatoria reale integrabile e di una variabile aleatoria reale che ammette valore atteso: definizione.\n\n﻿﻿Prime proprietà del valore atteso: {’ è spazio vettoriale, il valore atteso è lineare e positivo, una variabile non negativa a media nulla è nulla q.c., |E[X]| ≤ E[|X|], convergenza monotona,  convergenza dominata.\n\n\n﻿﻿Ulteriori proprietà del valore atteso.\n﻿﻿Primi esempi: il valore atteso su uno spazio campionario discreto, il valore atteso su R con una probabilità discreta.\n﻿﻿Esempi e controesempi per convergenza monotona, convergenza dominata.\n﻿﻿Integrale di una variabile aleatoria reale su un evento rispetto ad una probabilità: definizione.\n﻿﻿Valore atteso di una serie e serie dei valori attesi.\n\n• Disuguaghanza di Markov.\n\n\n﻿﻿Insiemi di variabili aleatorie reali CP e LP, 1 ≤ p &lt; ∞0.\n\n\n﻿﻿Disuguaglianza di Cauchy-Schwarz; L^2 \\subset L^1, E[X]^2 &lt; E[x^2]; L^2 è spazio lineare.\n\n\n﻿﻿Varianza di una variabile aleatoria reale in L*: definizione, interpretazione modellistica, prime proprietà.\n\n\n﻿﻿Disuguaglianza di Chebichev.\n\n\n﻿﻿Regola del valore atteso.\n\n\n6 Variabili aleatorie reali discrete\n\n﻿﻿Variabile aleatoria reale discreta: definizione.\n﻿﻿Regola del valore atteso per variabili aleatorie reali discrete.\n﻿﻿Esempi.\n\n7 Variabili aleatorie reali (assolutamente) continue\n• Misura di Ledesgue su k: dennione, interpretazione, esistenza, unicita.\n• Integrale di una funzione reale di variabile reale rispetto alla misura di Lebesgue. Relazione con l’integrale di Riemann.\n• Densita (continua) di una probabilta su k, probabilta (assolutamente) continua su k, variabile aleatoria reale (assolutamente) continua: definizioni.\n• Condizioni sufficienti affinché una funzione di ripartizione definisca una probabilità (assolutamente) continua\n\n﻿﻿Caratterizzazione di una densità su K e relazione con la relativa probabilità.\n﻿﻿Regola del valore atteso per variabilli aleatorie reali continue.\n\n• Esempi e controesempi.\nReferences"},"6--full-note/prob--Lez04":{"slug":"6--full-note/prob--Lez04","filePath":"6- full note/prob- Lez04.md","title":"prob- Lez04","links":["tags/flashcard_finite","tags/riscritto_finito","tags/revisione_finita","3--tag/probabilità","3--tag/sbobine"],"tags":["flashcard_finite","riscritto_finito","revisione_finita"],"content":"2025-02-23 14:35\n_Status: flashcard_finite     riscritto_finito     revisione_finita\n_Tags:  probabilità   sbobine\nprob- Lez04\nSigma-algebra generata da una famiglia di insiemi\nIl professore spiega un dubbio frequente riguardo alla sigma-algebra generata da una famiglia di insiemi.\nDubbio comune\nMolti studenti si chiedono come la sigma-algebra di Borel (\\mathcal{B}) sia generata dagli aperti (U) o, equivalentemente, dagli intervalli.\nChiarimento del professore\n\n\nConcetto di generazione: Il professore ricorda che generare una sigma-algebra a partire da una classe di insiemi significa che la sigma-algebra risultante conterrà molti più elementi della classe di partenza.\n\nEsempio: Se si parte da un singolo evento A, la sigma-algebra generata conterrà A, il suo complementare A^c, l’insieme vuoto \\emptyset e l’insieme totale \\Omega.\nSe si parte da due eventi A e B, la sigma-algebra conterrà A, B, A \\cup B, A^c, B^c, A \\cup B^c, e così via.\n\n\n\nSigma-algebra dei Boreliani: La sigma-algebra dei Boreliani (\\mathcal{B}) contiene molti più insiemi degli intervalli aperti da cui è generata. Include tutti gli insiemi chiusi, i punti singoli, le semirette, gli intervalli semiaperti, ecc.\n\n\nNon confondere la famiglia con la sigma-algebra generata: È fondamentale non confondere la famiglia di insiemi di partenza con la sigma-algebra che essa genera. La sigma-algebra generata è generalmente più grande della famiglia di partenza, a meno che la famiglia non sia già una sigma-algebra.\n\n\nCome verificare se un insieme appartiene alla sigma-algebra generata: Per capire se un insieme appartiene alla sigma-algebra generata, si deve verificare se può essere ottenuto tramite operazioni di complementazione, unione numerabile e intersezione numerabile a partire dagli insiemi della famiglia generatrice.\n\nPrendere un elemento A nella famiglia, e verificare se anche il suo complementare A^c appartiene alla sigma-algebra.\nPrendere due elementi A e B e verificare se la loro unione A \\cup B e la loro intersezione A \\cap B appartengono alla sigma-algebra. L’appartenenza dell’intersezione discende dalle proprietà di algebra/sigma-algebra.\n\n\n\nMisura di Lebesgue e sue proprietà\nIl professore riprende la lezione precedente introducendo la misura di Lebesgue su \\mathbb{R}^d.\nDefinizione e proprietà\n\n\nMisura di Lebesgue su \\mathbb{R}: Nel caso di \\mathbb{R}, la misura di Lebesgue di un intervallo è esattamente la sua lunghezza. La misura di Lebesgue di tutto \\mathbb{R} è +\\infty. Si ricorda che la misura di Lebesgue è sigma-finita.\n\n\nMisura di Lebesgue di un punto: La misura di Lebesgue di un singolo punto è zero, ovvero \\lambda({x}) = 0 per ogni x \\in \\mathbb{R}. Questo vale anche per misure di probabilità assolutamente continue.\n\n\nProprietà generali:\n\nIn \\mathbb{R}^d, la misura di Lebesgue di un punto è zero.\nIn \\mathbb{R}^3, la misura di Lebesgue di un piano è zero.\nPiù in generale, in \\mathbb{R}^d, la misura di Lebesgue di qualsiasi iperpiano di dimensione strettamente minore di d è zero (Leb_D=0)\n\n\n\nEsempio\nIl professore propone un esempio in \\mathbb{R}^2:\n\nConsideriamo due rette nel piano. Qual è la misura di Lebesgue della loro unione?\n\nSoluzione: Poiché ogni retta ha misura di Lebesgue zero e la misura di Lebesgue è sigma-additiva, la misura dell’unione delle due rette è la somma delle loro misure, che è 0 + 0 = 0. Matematicamente: \\lambda(retta_1 \\cup retta_2) \\le \\lambda(retta_1) + \\lambda(retta_2) = 0 + 0 = 0.\n\nEsempi di Spazi di Probabilità\nIl professore introduce due esempi per illustrare i concetti di spazi di probabilità e misure.\nEsempio 1: Dado a Sei Facce (spazio finito)\n\nSpazio Campionario: \\Omega = {1, 2, 3, 4, 5, 6}, che rappresenta i possibili risultati del lancio di un dado a sei facce.\nProbabilità: Ogni elemento ha la stessa probabilità di verificarsi, ovvero P({i}) = \\frac{1}{6} per i = 1, 2, ..., 6.\nMisura di Probabilità: La funzione di probabilità è definita sull’insieme delle parti di \\Omega, P(\\cdot): \\mathcal{P}(\\Omega) \\to [0,1], e assegna a ogni sottoinsieme di \\Omega la somma delle probabilità dei suoi elementi  P(A)=\\sum_{i \\in A}p_i \\ \\ \\ , p_i=\\frac{1}{6} con \\mathcal{A}\\in \\mathcal{P}(\\Omega)= \\mathcal{F}\nQuesta è una misura.\nModellizzazione: Questo esempio rappresenta il lancio di un dado non truccato, dove ogni faccia ha la stessa probabilità di uscire. Si fanno delle scelte di modellizzazione, come assumere che il dado non venga rubato o distrutto.\n\nEsempio 2: Cerchio Unitario (spazio non numerabile)\n\nSpazio Campionario: \\mathbb{R}^2\\supset\\Omega =\\set{\\omega=(x_1, x_2) : x_1^2 + x_2^2 \\le 1}, che rappresenta l’insieme dei punti all’interno di un cerchio di raggio 1.\n\nMisura di Probabilità: Si vuole definire una misura di probabilità che formalizzi l’idea di scegliere un punto a caso uniformemente all’interno del cerchio.\nSigma-algebra: Si utilizza la sigma-algebra dei Boreliani su \\mathbb{R}^2 (\\mathcal{F}=\\mathcal{B}(\\mathbb{R})), ristretta a \\Omega.\nDefinizione della Misura: (abbiamo bisogno di una misura non discreta) Si parte dalla misura di Lebesgue \\lambda (Leb_2) e si definisce la misura di probabilità P(A) come:  P(A) = \\frac{\\lambda(A \\cap \\Omega)}{\\lambda(\\Omega)} = \\frac{\\lambda(A \\cap \\Omega)}{\\pi} \\ \\ \\ \\ \\ \\ \\ \\  \\forall A \\in \\mathcal{F} dove A è un insieme misurabile e \\lambda(\\Omega) = \\pi è l’area del cerchio unitario.\nUniformità: Questa misura di probabilità è uniforme, nel senso che la probabilità di un piccolo disco attorno a un punto è proporzionale all’area del disco, indipendentemente dalla posizione del punto all’interno del cerchio.\nEventi: Gli eventi sono sottoinsiemi di \\Omega che appartengono alla sigma-algebra.\nEsempio di Evento: Si consideri l’evento A = “il diametro passante per il punto scelto interseca il settore tra le ore 12 e le ore 3”. Per calcolare la probabilità di A, si deve tradurre questo evento in un sottoinsieme misurabile di \\Omega. Questo sottoinsieme è l’unione del primo e terzo quadrante.\n\nProbabilità Condizionata e Indipendenza\nIl professore introduce i concetti di probabilità condizionata e indipendenza.\nSpazio Misurabile e Spazio di Probabilità\n\nUno spazio misurabile è una coppia (\\Omega, \\mathcal{F}), dove \\Omega è lo spazio campionario e \\mathcal{F} è una sigma-algebra su \\Omega.\nUno spazio di probabilità è una terna (\\Omega, \\mathcal{F},\\mathbb{P}), dove (\\Omega, \\mathcal{F}) è uno spazio misurabile e P è una misura di probabilità su \\mathcal{F}.\n\nProbabilità Condizionata\n\n\nSiano E e H due eventi in \\mathcal{F}, con P(H) &gt; 0. La probabilità condizionata di E dato H è definita come: P(E|H) = \\frac{P(E \\cap H)}{P(H)}\nInterpretazione: P(E|H) rappresenta la probabilità che l’evento E si verifichi, dato che l’evento H si è verificato. In altre parole, si restringe l’attenzione all’universo H e si valuta la probabilità di E in questo universo ristretto.\n\n\n\n\n\n\nProprietà della Probabilità Condizionata\n\nP(E|H) è una misura di probabilità: Fissato H\\in \\mathcal{F}, \\ \\ \\mathbb{P}(H)\\geq 0, la funzione P(E|H): \\mathcal{F} \\to è una misura di probabilità su \\mathcal{F}. (la probabilità condizionata è una funzione rispetto a E)\nQuesto significa che soddisfa gli assiomi di una misura di probabilità:\n\nPer dimostrare che questa applicazione è una misura di probabilità su \\mathcal{F}, dobbiamo verificare tre proprietà fondamentali:\n\n\nNon negatività: P(E|H) \\geq 0 Questo è vero perché sia P(E \\cap H) che P(H) sono non negativi, e quindi il loro rapporto è non negativo.\n\n\nNormalizzazione: P(\\Omega|H) = 1 Dimostrazione: P(\\Omega|H) = \\frac{P(\\Omega \\cap H)}{P(H)} = \\frac{P(H)}{P(H)} = 1\n\n\nAdditività completa: Sia {A_n}_{n \\geq 1} una successione di eventi disgiunti. Dobbiamo dimostrare che: P\\left(\\bigcup_{n=1}^{\\infty} A_n \\mid H\\right) = \\sum_{n=1}^{\\infty} P(A_n \\mid H)\n\nIniziamo scrivendo la definizione: P\\left(\\bigcup_{n=1}^{\\infty} A_n \\mid H\\right) = \\frac{P\\left(\\left(\\bigcup_{n=1}^{\\infty} A_n\\right) \\cap H\\right)}{P(H)}\nUsiamo la proprietà distributiva dell’intersezione rispetto all’unione: \\frac{P\\left(\\bigcup_{n=1}^{\\infty} (A_n \\cap H)\\right)}{P(H)}\nPoiché gli A_n sono disgiunti, anche gli (A_n \\cap H) sono disgiunti. Quindi, possiamo usare l’additività completa della probabilità P: \\frac{\\sum_{n=1}^{\\infty} P(A_n \\cap H)}{P(H)}\nRiscriviamo ogni termine usando la definizione di probabilità condizionale: \\sum_{n=1}^{\\infty} \\frac{P(A_n \\cap H)}{P(H)} = \\sum_{n=1}^{\\infty} P(A_n \\mid H)\nQuindi, abbiamo dimostrato l’additività completa: P\\left(\\bigcup_{n=1}^{\\infty} A_n \\mid H\\right) = \\sum_{n=1}^{\\infty} P(A_n \\mid H)\n\n\n\nCorollario\nOgni proprietà che vale per una misura di probabilità vale anche per la probabilità condizionale quando si tiene fisso il condizionante. Ad esempio:\n- P(E|H) \\ge 0 per ogni E \\in \\mathcal{F}.\n- P(\\Omega|H) = \\frac {P(\\Omega \\cap H)}{\\mathbb{P}(H)}= \\frac {P( H)}{\\mathbb{P}(H)} =1.\n- Se E_1, E_2, ... sono eventi disgiunti, allora P(\\bigcup_{i=1}^{\\infty} E_i | H) = \\sum_{i=1}^{\\infty} P(E_i | H).\n- \n- intersezione e unione godono della proprietà distributiva\n- \n- \n\nOGNI probabilità che sappiamo valere per una misura di probabilità vale per la probabilità condizionata quando teniamo fisso il condizionante\n\nesempio:\n\n\n\n\nFormula delle Probabilità Totali\n\n\nSia H_1, H_2, ... una partizione numerabile di \\Omega, ovvero H_i \\cap H_j = \\emptyset per i \\ne j e \\bigcup_{i=1}^{\\infty} H_i = \\Omega, con P(H_i) &gt; 0 per ogni i. Allora, per ogni evento E \\in \\mathcal{F}: P(E) = \\sum_{i=1}^{\\infty} P(E|H_i) P(H_i)\n\nCaso Generale: Partizione Numerabile\n\n\nDefinizione di partizione: Sia {H_i}_{i=1}^{\\infty} una partizione numerabile di \\Omega. Questo significa che:\n\nH_i \\in \\mathcal{F} per ogni i (ogni H_i è un evento misurabile)\n\\bigcup_{i=1}^{\\infty} H_i = \\Omega (l’unione di tutti gli H_i è l’intero spazio campionario)\nH_i \\cap H_j = \\emptyset per i \\neq j (gli H_i sono a due a due disgiunti)\nP(H_i) &gt; 0 per ogni i\n\n\n\nDecomposizione dell’evento E: L’evento E può essere espresso come l’unione delle intersezioni di E con gli elementi della partizione: E = \\bigcup_{i=1}^{\\infty} (E \\cap H_i)\n\n\nAdditività completa: Poiché gli eventi (E \\cap H_i) sono disgiunti, possiamo scrivere: P(E) = \\sum_{i=1}^{\\infty} P(E \\cap H_i)\n\n\nUtilizzo della probabilità condizionale: Usando la definizione di probabilità condizionale: P(E \\cap H_i) = P(E \\mid H_i) \\cdot P(H_i)\n\n\nFormula generale delle probabilità totali: Sostituendo nella formula per P(E): P(E) = \\sum_{i=1}^{\\infty} P(E \\mid H_i) \\cdot P(H_i)\n\n\nQuesta formula esprime la probabilità di E come la somma delle probabilità condizionate di E dato H_i, pesate per le probabilità di H_i.\nCaso Semplice: Partizione in Due Eventi\n\n\nDecomposizione dell’evento E: L’evento E può essere espresso come l’unione di due eventi mutuamente esclusivi: E = (E \\cap H) \\cup (E \\cap H^c) dove H^c rappresenta il complemento di H.\n\n\nAdditività: Siccome (E \\cap H) e (E \\cap H^c) sono disgiunti, possiamo scrivere: P(E) = P(E \\cap H) + P(E \\cap H^c)\n\n\nUtilizzo della probabilità condizionale: Ricordando la definizione di probabilità condizionale: P(E \\mid H) = \\frac{P(E \\cap H)}{P(H)} e quindi P(E \\cap H) = P(E \\mid H) \\cdot P(H) Allo stesso modo: P(E \\cap H^c) = P(E \\mid H^c) \\cdot P(H^c)\n\n\nFormula delle probabilità totali: Sostituendo nella formula per P(E): P(E) = P(E \\mid H) \\cdot P(H) + P(E \\mid H^c) \\cdot P(H^c)\nQuesta formula permette di calcolare la probabilità di E usando le probabilità condizionate e le probabilità degli eventi H e il suo complemento.\n\n\n\nTeorema di Bayes\n\nNelle stesse ipotesi della formula delle probabilità totali, per ogni H_i nella partizione e per ogni evento E con P(E) &gt; 0: P(H_i|E) = \\frac{P(E|H_i) P(H_i)}{\\sum_{j=1}^{\\infty} P(E|H_j) P(H_j)}\n\nEsempio del Test Clinico\n\nSi consideri un test clinico per una malattia. Siano:\n\nE = “il test risulta positivo”.\nH = “il paziente è malato”.\nH^c = “il paziente è sano”.\n\n\nSi conoscono le seguenti probabilità condizionate:\n\nP(E|H) = probabilità che il test sia positivo dato che il paziente è malato (sensibilità del test).\nP(E|H^c) = probabilità che il test sia positivo dato che il paziente è sano (1 - specificità del test).\nP(H) = probabilità a priori che un individuo nella popolazione sia malato (prevalenza della malattia).\n\n\nSi vuole calcolare P(H|E), ovvero la probabilità che il paziente sia effettivamente malato dato che il test è risultato positivo. Utilizzando il teorema di Bayes: P(H|E) = \\frac{P(E|H) P(H)}{P(E|H) P(H) + P(E|H^c) P(H^c)}\ndove P(H^c) = 1 - P(H).\n\nFormulazione del Teorema di Bayes\nDati: P(E|H), P(E|H^c) e P(H), si vuole calcolare P(H|E).\nTeorema:\nSia ({H_i})_{i\\ge 1} una partizione numerabile di \\Omega, tale che P(H_i) &gt; 0 per ogni i. Allora, la probabilità condizionata P(H_i|E) può essere calcolata come:\nP(H_i|E) = \\frac{P(E|H_i)P(H_i)}{\\sum_{j \\ge 1} P(E|H_j)P(H_j)}\nDimostrazione:\nIl denominatore dell’espressione sopra è equivalente a P(E) per il teorema delle probabilità totali. Quindi:\nP(H_i|E) = \\frac{P(E|H_i)P(H_i)}{P(E)}\nA destra dell’equazione, abbiamo solo termini noti.\nOsservazioni Importanti\n\nInversione delle Probabilità: Il teorema permette di “invertire” le probabilità, calcolando P(H_i|E) a partire da P(E|H_j) e P(H_j).\nStatistica Bayesiana: Questo teorema è alla base della statistica Bayesiana.\nTerminologia Statistica:\n\nP(E|H_i) è chiamata verosimiglianza (likelihood).\nP(H_i) è la distribuzione iniziale (prior).\nP(H_i|E) è la distribuzione finale (posterior).\n\n\nMeccanismo di Apprendimento: Il teorema può essere visto come un meccanismo di apprendimento. P(H_i) rappresenta la conoscenza iniziale, P(E|H_i) è il modello, e P(H_i|E) è ciò che si apprende dopo aver osservato l’evento E.\nNecessità di una Struttura Probabilistica: Per fare questi calcoli, è fondamentale avere uno spazio \\Omega, una \\sigma-algebra e una misura di probabilità ben definiti, anche se poi l’enunciato riguarda solo specifici valori numerici.\n\nReferences"},"6--full-note/prob--totale":{"slug":"6--full-note/prob--totale","filePath":"6- full note/prob- totale.md","title":"prob- totale","links":["3--tag/sbobine","3--tag/probabilità","tags/revisione_in_corso","tags/flashcard_finite","tags/riscritto_zero","tags/revisione_finita","tags/riscritto_finito","tags/flashcard_zero","tags/revisione_zero","paste/Appunti-Prob-Lez07.pdf","paste/appunti-prob-lez08.pdf","2--source-materials/Appunti-Prob--lez08'.pdf","2--source-materials/Appunti-Prob---lez09.pdf","2--source-materials/appunti-bussetti-lez09.pdf","2--source-materials/appunti-bussetti--lez10.pdf","2--source-materials/appunti-bussetti--lez11.pdf"],"tags":["revisione_in_corso","flashcard_finite","riscritto_zero","revisione_finita","riscritto_finito","flashcard_zero","revisione_zero"],"content":"2025-02-18 13:22\nStatus: 1-18\nTags: sbobine probabilità\nlez01’- Prob\nIntroduzione alla Probabilità e Teoria della Misura\nIl professore introduce il concetto di probabilità, sottolineando come essa si applichi a fenomeni non descrivibili con leggi deterministiche. La probabilità, in sostanza, misura l’incertezza. L’approccio matematico moderno alla probabilità si basa sulla teoria della misura.\nConcetti Chiave: Algebre, Misure, Misure di Probabilità (o probabilità)\nGli argomenti principali della lezione sono algebre, σ-algebre, misure e misure di probabilità. È importante, secondo il professore, fare tabula rasa delle concezioni elementari di probabilità per poter ricostruire i concetti in modo più rigoroso. L’astrazione è necessaria per inglobare sia il discreto che il continuo in un unico linguaggio matematico.\nMisura: Definizione Intuitiva\nIntuitivamente, una misura associa un valore a un insieme. Questo valore può rappresentare un’area, una lunghezza, un peso o un’incertezza.\n\nProprietà Fondamentale\nSe si misurano due insiemi disgiunti A₁ e A₂ separatamente, la somma delle loro misure deve essere uguale alla misura della loro unione:\nμ(A₁ ∪ A₂) = μ(A₁) + μ(A₂) se A₁ ∩ A₂ = ∅\nSpazio Campionario (Ω)\n\n\nΩ (Omega): Spazio Campionario (o Spazio degli Esiti):\n\nL’insieme di tutti i possibili risultati di un esperimento casuale.\nInsieme astratto, senza struttura particolare.\nPuò essere finito, infinito numerabile, o continuo.\nSpesso non è esplicitamente definito, ma esiste implicitamente.\n\n\n\n**ω (omega minuscola):\n\nEsito Elementare**: Un singolo elemento di Ω, un punto, una particolare realizzazione dell’esperimento.( Parametrizzazione del caso).\n\n\n\nEventi A: Sottoinsiemi di Ω  A⊂Ω.\n\nCollezione di esiti elementari che soddisfano una condizione.\n\n\n\nEvento Certo: L’insieme Ω stesso.\n\n\nEsempi di Spazi Campionari:\n\nInsieme finito di punti: Ω = {1, 2, 3, …, 10}\nNumeri naturali non negativi: Ω = {0, 1, 2, …}\nNumeri reali: Ω = ℝ\nSpazio euclideo: Ω = ℝᵈ (vettori con componenti reali)\nSuccessioni: Ω = {x = (x₁, x₂, …): xᵢ ∈ {1, 2, …, m}}\n\nSottoinsiemi e Operazioni Insiemistiche\nI sottoinsiemi di Ω rappresentano eventi. È fondamentale non confondere un punto (ω ∈ Ω) con un sottoinsieme.\nOperazioni Fondamentali:\n\nComplementare: Aᶜ = {ω ∈ Ω: ω ∉ A} (tutti gli elementi di Ω che non appartengono ad A).\n\nÈ essenziale specificare l’insieme universo (Ω) quando si considera il complementare.\n\n\n\nAlgebre di Insiemi\nUna classe (o famiglia) di sottoinsiemi di Ω \\mathcal{A} si dice algebra se soddisfa le seguenti proprietà:\n\nΩ ∈ \\mathcal{A} (l’insieme totale appartiene all’algebra).\nSe A ∈ \\mathcal{A}, allora Aᶜ ∈ \\mathcal{A} (se un insieme appartiene all’algebra, anche il suo complementare appartiene all’algebra).\nSe A₁, A₂ ∈ \\mathcal{A}, allora A₁ ∪ A₂ ∈ \\mathcal{A} (se due insiemi appartengono all’algebra, anche la loro unione appartiene all’algebra).\n\nProprietà Derivata\nSe A è un’algebra e A₁, …, Aₙ ∈ A, allora ∪ᵢ₌₁ⁿ Aᵢ ∈ \\mathcal{A} (l’unione finita di insiemi appartenenti all’algebra appartiene all’algebra). Questo si dimostra per induzione.\nSigma-Algebre (σ-algebre)\nUna σ-algebra è un’algebra che è anche stabile rispetto a unioni numerabili. Formalmente, una classe di insiemi \\mathcal{F} è una σ-algebra se soddisfa:\n\nΩ ∈ \\mathcal{F}\nSe A ∈ \\mathcal{F}, allora Aᶜ ∈ \\mathcal{f}\nSe Aᵢ ∈ \\mathcal{F} per i = 1, 2, …, allora ∪ᵢ₌₁^∞ Aᵢ ∈ \\mathcal{f} (l’unione numerabile di insiemi appartenenti alla σ-algebra appartiene alla σ-algebra).\n\nConseguenze Importanti:\n\nSe \\mathcal{F} è una σ-algebra, allora ∅ ∈ \\mathcal{F} (l’insieme vuoto appartiene alla σ-algebra).\n\n 1. e 2. implicano che Ω ^c\\in \\mathcal{F} ma con Ω ^c=∅\n\n\nSe \\mathcal{F} è una σ-algebra, allora è anche un’algebra.\nLa stabilità rispetto a unioni numerabili implica la stabilità rispetto a unioni finite, ma non viceversa.\n\n\n\n\n\nOsservazione sulle Notazioni\nIl professore userà la lettera \\mathcal{F} per denotare una σ-algebra. In alcuni testi, si usa la lettera \\mathcal{A} per indicare sia le algebre che le σ-algebre.\nInsieme delle Parti\nL’insieme delle parti \\mathcal{P}(Ω) è l’insieme di tutti i sottoinsiemi di Ω. \\mathcal{P}(Ω) è sempre una σ-algebra.\nCaso Finito\nSe Ω è un insieme finito, allora non c’è differenza tra algebra e σ-algebra. In questo caso, l’insieme delle parti \\mathcal{P}(Ω) è finito, e quindi ogni famiglia di sottoinsiemi è finita.\nMisure\nUna misura è una funzione che associa un valore numerico a un insieme, quantificandone la “dimensione” in un certo senso.\nSpazio Misurabile\nUna coppia (Ω, \\mathcal{A}) o (Ω, \\mathcal{F}), dove Ω è uno spazio campionario e \\mathcal{A} è un’algebra ( \\mathcal{F} è una σ-algebra) su Ω, è chiamata spazio misurabile.\nMisura Finitamente Additiva\nUna funzione μ: \\mathcal{A} → [0, +∞] è una misura finitamente additiva se soddisfa le seguenti proprietà:\n\nμ(∅) = 0\nPer ogni A₁, A₂ ∈ \\mathcal{A} tali che A₁ ∩ A₂ = ∅, si ha μ(A₁ ∪ A₂) = μ(A₁) + μ(A₂)\n\ndefinire un algebra è servito a questo\n\n\n\n\nNOTA: μ non è una misura di un punto μ_d , ma di una famiglia di sottoinsiemi.\n\nMisura (σ-additiva o completamente additiva)\nUna funzione μ: \\mathcal{F} → [0, +∞] è una misura (σ-additiva) se soddisfa le seguenti proprietà:\n\n\nμ(∅) = 0\n\n\nSe Aᵢ ∈ \\mathcal{F} per i = 1, 2, … e Aᵢ ∩ Aⱼ = ∅ per ogni i ≠ j, allora:\nμ(∪ᵢ₌₁^∞ Aᵢ) = ∑ᵢ₌₁^∞ μ(Aᵢ)\n- μ\\left( \\bigcup_{i \\geq 1} A_i \\right) = \\sum_{i \\geq 1} μ(A_i).\n\nse vale più infinito la somma, la misura sarà infinito\n\n\n\nTerminologia\n\nEventi: I sottoinsiemi di Ω sono spesso chiamati eventi.\nEvento certo: Ω (l’evento che si verifica sempre)\nEvento impossibile: ∅ (l’evento che non si verifica mai)\nEvento contrario: Aᶜ (il complementare di A)\n\nMisure di Probabilità\nUna misura di probabilità è una misura che associa a ogni evento un numero compreso tra 0 e 1, rappresentando la probabilità che l’evento si verifichi.\nProbabilità Finitamente Additiva\nUna funzione \\mathbb{P}: A →[0,1] è una probabilità finitamente additiva se soddisfa:\n\nP(∅) = 0 e P(Ω) = 1\nPer ogni A₁, A₂ ∈ \\mathcal{A} tali che A₁ ∩ A₂ = ∅, si ha P(A₁ ∪ A₂) = P(A₁) + P(A₂)\n\nMisura di Probabilità (σ-additiva)\nUna funzione P: \\mathcal{F} → è una misura di probabilità (σ-additiva) se soddisfa:\n\n\nP(∅) = 0 e P(Ω) = 1\n\n\nSe Aᵢ ∈ \\mathcal{F} per i = 1, 2, … e Aᵢ ∩ Aⱼ = ∅ per ogni i ≠ j, allora:\nP\\left( \\bigcup_{n \\geq 1} A_n \\right) = \\sum_{n \\geq 1} P(A_n).\n\n\nRelazione tra Misure e Misure di Probabilità\nUna misura di probabilità è un caso particolare di misura in cui i valori sono normalizzati tra 0 e 1 e la misura dello spazio totale è 1.\n\ndefinizione probabilità: è una misura sigma additiva tale per cui lo spazio totale vale omega\n\nProprietà Elementari delle Misure (e Misure di Probabilità)\nLe seguenti proprietà valgono sia per le misure che per le misure di probabilità (nell’accezione di σ-additiva):\n\nSe A₁ ∩ A₂ = ∅, allora μ(A₁ ∪ A₂) = μ(A₁) + μ(A₂)\n\nquesta proprietà appartiene alle unioni numerabili (σ- finite) si può dedurre valga anche per le σ-additive\n\n\nSe A ⊆ B, allora μ(A) ≤ μ(B) (monotonia)\n\nSe A ⊆ B significa B implica A\n\n\n\nTerminologia Probabilistica Aggiuntiva\n\nSe A ∩ B = ∅, si dice che A e B sono incompatibili.\n\n\nMisure di Probabilità: Proprietà Fondamentali e Dimostrazioni\nse P è una mdp (misura di probabilità) → P è una misura\nle proprietà sulle misure valgono per P.\nIl professore spiega le proprietà fondamentali delle misure di probabilità, sottolineando che queste proprietà sono valide in generale per le misure su sigma-algebre e sono cruciali per la teoria della probabilità.\n1. Additività Completa e Finitamente Additiva (il cambio da P a un mu è colpa del prof…)\n\n\nDefinizione: Una misura di probabilità (P) su uno spazio campionario (\\Omega) è completamente additiva se, per ogni successione di eventi mutuamente disgiunti A_1, A_2, \\dots, vale:\n\\mu\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} \\mu(A_i)\n\n\nAdditività finita: Se la proprietà vale solo per un numero finito di eventi disgiunti, allora la misura è finitamente additiva.\nP\\left(\\bigcup_{i=1}^{n} A_i\\right) = \\sum_{i=1}^{n} P(A_i) \n\n\nDimostrazione che l’additività completa implica quella finita:\n\n\nSiano A_1 e A_2 eventi disgiunti. Possiamo scrivere la loro unione come un’unione infinita, aggiungendo l’insieme vuoto infinite volte:\nA_1 \\cup A_2 = A_1 \\cup A_2 \\cup \\emptyset \\cup \\emptyset \\cup \\dots\n\n\nPer l’additività completa:\n\\mu(A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2) + \\sum_{i=3}^{\\infty} \\mu(\\emptyset) \n\n\nDato che \\mu(\\emptyset) = 0:\n\\mu(A_1 \\cup A_2) = \\mu(A_1) + \\mu(A_2)\n\n\nQuesto dimostra che se una misura è completamente additiva, allora è anche finitamente additiva.\n\n\n\n\n2. Monotonia\n\nDefinizione: Se (A \\subseteq B), allora (P(A) \\leq P(B)).\nDimostrazione:\n\n\nSe A \\subseteq B, possiamo scrivere B come l’unione disgiunta di A e B \\setminus A:\nB = A \\cup (B \\setminus A)\n\n\nA\\cap (B\\setminus A)=\\emptyset\n\n\n\nQuindi, \\mu(B) = \\mu(A) + \\mu(B \\setminus A)\n\n\n\n\nper additività finita.\n\n\n\n\nDato che \\mu(B \\setminus A) \\geq 0 per definizione allora:\n\\mu(B) \\geq \\mu(A)\n\n\n\n\n3. Probabilità del Complementare\n\nDefinizione sia \\mathbb{P}\\in\\cal{F}\n\n: (P(A^c) = 1 - P(A)) \\forall A\\in \\cal{F}\n\ndove (A^c) è il complementare di (A) rispetto a (\\Omega).\n\n\n\n\nDimostrazione:\n\nSappiamo che (A \\cup A^c = \\Omega) e (A \\cap A^c = \\emptyset).\nQuindi, per additività finita\n\n(P(A \\cup A^c) = P(A) + P(A^c) = P(\\Omega) = 1).\n\n\nDa cui: P(A^c) = 1 - P(A)\n\n\n\n4. Probabilità dell’Unione di Due Eventi\n\n\nDefinizione: sia \\mathbb{P}\\in\\cal{F}\n\nPer due eventi (A) e (B), vale: P(A \\cup B) = P(A) + P(B) - P(A \\cap B) \\forall A,B\\in \\cal{F}\n\n\nDimostrazione:\n\n\nSi decompone (A \\cup B) in tre parti disgiunte: (A \\setminus (A \\cap B)), (B \\setminus (A \\cap B)) e (A \\cap B).\n\n\nQuindi per additività finita: P[A \\cup B] = P[A \\setminus (A \\cap B)] + P[B \\setminus (A \\cap B)] + P(A \\cap B)\n\n\nNotiamo che (B\\cap A)\\subseteq A\n\nA = [A \\setminus (A \\cap B)] \\cup (A \\cap B), che sono disgiunti\n\n\n\n\nP(A) = P(A \\setminus (A \\cap B)) + P(A \\cap B)\nP(A \\setminus (A \\cap B)) = P(A) - P(A \\cap B)\n\n\n\nAnalogamente: P(B \\setminus (A \\cap B)) = P(B) - P(A \\cap B)\n\n\nSostituendo: P(A \\cup B) = P(A) - P(A \\cap B) + P(B) - P(A \\cap B) + P(A \\cap B)\n\n\nSemplificando: P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\n\nIl professore sottolinea che sommare (P(A)) e (P(B)) significa contare due volte l’intersezione, quindi la si deve sottrarre.\n\n\n\n\nSigma-algebra Generata da una Famiglia di Insiemi\n\nDefinizione: Data una famiglia di sottoinsiemi (\\mathcal{E}\\subset \\cal{P}(\\Omega)) di (\\Omega),\n\nla sigma-algebra generata da (\\mathcal{E}), indicata con (\\sigma(\\mathcal{E})), è la più piccola sigma-algebra che contiene (\\mathcal{E}).\n\n\nEsempio:\n\nSia (\\Omega = {1, 2, 3}) e (\\mathcal{E} = {{1, 2}, {2, 3}}). (\\mathcal{E}) non è un’algebra perché non contiene (\\Omega) né l’insieme vuoto.\nPer generare la sigma-algebra, dobbiamo aggiungere:\n\n(1, 2) \\cup (2, 3)= \\Omega.\nIl complementare di ({1, 2}), che è ({3}).\nIl complementare di ({2, 3}), che è ({1}).\n{1,3} che è il complementare di {2}\n{2} che è il complementare di {1,3}\nL’insieme vuoto\n\n\nQuindi, (\\sigma(\\mathcal{E}) = {\\emptyset, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, \\Omega}), che è l’insieme delle parti di (\\Omega).\n\n\nEsercizio Proposto\n\nEsercizio: Dato (\\Omega = {1, 2, 3}) e (\\mathcal{E} = {{1, 2}, {3}}), trovare la sigma-algebra generata da (\\mathcal{E}).\nOsservazione: In questo caso, la sigma-algebra generata non sarà l’insieme delle parti, suggerendo che non sempre si è in grado di misurare tutti i sottoinsiemi dello spazio campionario.\nReferences\n\n\n\n2025-02-18 08:16\nStatus: revisione_in_corso flashcard_finite riscritto_zero\nTags:probabilità sbobine\nlez02-Prob\nDefinizione di Probabilità: Approccio Alternativo\nIl professore introduce una definizione di probabilità leggermente diversa da quella standard, ma equivalente. Questa definizione alternativa non richiede esplicitamente che la probabilità dell’insieme vuoto sia zero.\nDefinizione\nSia (Ω, F) uno spazio misurabile, dove Ω è lo spazio campionario e F è una σ-algebra di eventi. Una funzione P: ℱ →|0,1|  è una misura di probabilità se soddisfa le seguenti condizioni:\n\n\nP(Ω) = 1 (la probabilità dell’evento certo è 1)\n\n\nσ-additività (additività completa): Per ogni successione di eventi Aᵢ ∈ F tali che Aᵢ ∩ Aⱼ = ∅ per i ≠ j (eventi incompatibili), vale:\nP(∪ᵢ Aᵢ) = ∑ᵢ P(Aᵢ)\n\n\n\n\n\nEquivalenza tra le Definizioni\nLa definizione standard di misura di probabilità include anche la condizione che P(∅) = 0. Il professore dimostra che la definizione alternativa è equivalente a quella standard, mostrando che la condizione P(∅) = 0 può essere derivata dalle altre proprietà.\nDimostrazione che P(∅) = 0\n\n1→2\n2→1\n\n\nSi esprime l’insieme vuoto come unione numerabile di insiemi vuoti:\n∅ = ∪ᵢ ∅\n\n\nSia p = P(∅). Per la σ-additività, si ha:\np = P(∅) = P(∪ᵢ ∅) = ∑ᵢ P(∅) = ∑ᵢ p\n\n\nQuindi, p = ∑ᵢ p. Questo è possibile solo se p = 0. Se p fosse strettamente positivo, la somma di infiniti valori positivi divergerebbe.\n\n\nPertanto, P(∅) = 0.\n\n\n\n\nCommenti\n\nQuesta dimostrazione mostra che la condizione P(∅) = 0 è ridondante nella definizione alternativa, poiché può essere derivata dalle altre proprietà.\nL’obiettivo del professore è di fornire una caratterizzazione utile per confrontare diverse definizioni di probabilità, ad esempio quella trovata nel libro di Protter.\n\nMisure Finite e σ-Finite\nIl professore introduce le definizioni di misura finita e misura σ-finita.\nMisura Finita\nUna misura μ su una σ-algebra F è detta finita se la misura dell’insieme totale è finita:\nμ(Ω) &lt; ∞\nEsempio: Una misura di probabilità è una misura finita perché P(Ω) = 1.\nMisura σ-Finita\nUna misura μ su una σ-algebra ℱ è detta σ-finita se esiste una famiglia numerabile di insiemi misurabili Bᵢ ∈ F tale che:\n\nGli insiemi Bᵢ sono disgiunti: Bᵢ ∩ Bⱼ = ∅ per i ≠ j\nL’unione degli insiemi Bᵢ è l’intero spazio: ∪ᵢ Bᵢ = Ω\nLa misura di ogni insieme Bᵢ è finita: μ(Bᵢ) &lt; ∞ per ogni i\n\nUna famiglia di insiemi con queste proprietà è chiamata partizione numerabile o partizione misurabile numerabile dello spazio.\n\n\n\nCommenti\n\nLa misura σ-finita è una generalizzazione della misura finita. Permette di lavorare con spazi di misura infinita, purché possano essere suddivisi in una quantità numerabile di sottoinsiemi di misura finita.\nLe misure che verranno utilizzate nel corso avranno spesso questa proprietà. Ad esempio, la misura di Lebesgue su ℝⁿ è σ-finita perché ℝⁿ può essere suddiviso in una quantità numerabile di cubi con lato di lunghezza finita.\n\nrifattorizzo\nEsempi di Misure di Probabilità\nIl professore presenta tre esempi semplici di misure, che servono come base per costruire esempi più complessi.\n1. Delta di Dirac (Massa Puntuale)\nSia Ω uno spazio qualsiasi e ω₀ ∈ Ω un punto fissato. La misura delta di Dirac δω₀ è definita come:\nδω₀(A) = { 1 se ω₀ ∈ A\n{ 0 se ω₀ ∉ A\nδω₀(A) assegna probabilità 1 se l’insieme A contiene il punto ω₀ e probabilità 0 altrimenti.\n\nCommento: La delta di Dirac è una misura di probabilità degenere, perché assegna probabilità 1 a un singolo punto e 0 a tutto il resto. Dal punto di vista probabilistico, rappresenta un evento certo.\n\n2. Misura di Conteggio\nSia Ω un insieme al più numerabile di punti ωᵢ. La misura di conteggio μ è definita come:\nμ(A) = ∑ᵢ δωᵢ(A) = |{ωᵢ ∈ A}|\ndove |{ωᵢ ∈ A}| indica il numero di elementi in A.\n\n\n\nIn altre parole, μ(A) conta il numero di punti ωᵢ che appartengono all’insieme A.\n\n\nEsempio: Sia Ω = ℕ (numeri naturali) e A = {1, 3, 5}. Allora μ(A) = 3.\n\n\nin questo caso μ(Ω) sarebbe infinito → non sarebbe una misura finita\n\n\n3. Misura Discreta Generale\nSia Ω un insieme al più numerabile di punti ωᵢ e siano cᵢ dei numeri reali positivi. La misura discreta μ è definita come:\nμ(A) = ∑{cᵢ : ωᵢ ∈ A}\n\n\n\nIn questo caso, ogni punto ωᵢ ha un peso cᵢ. La misura di un insieme A è la somma dei pesi dei punti che appartengono ad A.\n\nSe ∑ᵢ cᵢ = 1, allora μ è una misura di probabilità.\nSe ∑ᵢ cᵢ &lt; ∞, allora μ è una misura finita.\nSe ∑ᵢ cᵢ = ∞, allora μ non è una misura finita.\n\nCommenti\n\nQuesti esempi mostrano come costruire misure a partire da punti isolati.\nLe misure discrete sono fondamentali in molti contesti probabilistici.\n\nSigma Algebra Generate da Famiglie di Insiemi\nIl professore introduce il concetto di σ-algebra generata da una famiglia di insiemi.\nDefinizione\nData una famiglia di insiemi E, la σ-algebra generata da E, indicata con σ(E), è la più piccola σ-algebra che contiene tutti gli insiemi in E.\nIn altre parole, σ(E) è l’intersezione di tutte le σ-algebre che contengono E.\nσ(E) = ∩{ℱ : ℱ è una σ-algebra e E ⊆ ℱ}\n\n\n\nProprietà\nSe E₁ ⊆ E₂, allora σ(E₁) ⊆ σ(E₂).\nEsempio\nSia Ω = {1, 2, 3} e E = {{1, 2}}. Allora la σ-algebra generata da E è:\nσ(E) = {∅, Ω, {1, 2}, {3}}\nCommenti\n\nLa σ-algebra generata da una famiglia di insiemi è un concetto fondamentale per costruire σ-algebre complesse a partire da insiemi più semplici.\nQuesto concetto è particolarmente importante quando si lavora con spazi non numerabili, come la retta reale.\n\nProbabilità su Spazi Numerabili (o finiti)\nIl professore discute come definire misure di probabilità su spazi numerabili.\nPartizioni Numerabili\nUna partizione numerabile di uno spazio Ω è una famiglia numerabile di insiemi disgiunti H = {Hᵢ} tali che ∪ᵢ Hᵢ = Ω.\nSigma Algebra Generata da una Partizione Numerabile\nLa σ-algebra generata da una partizione numerabile H è l’insieme di tutte le unioni (finite o numerabili) di elementi di H.\n\n\n\nCaratterizzazione delle Misure di Probabilità\nSia F la σ-algebra generata da una partizione numerabile H. Per definire una misura di probabilità P su F, è sufficiente assegnare un peso pᵢ ≥ 0 a ogni elemento Hᵢ della partizione, tale che ∑ᵢ pᵢ = 1.\nLa probabilità di un insieme A ∈ F è data da:\nP(A) = ∑{pᵢ : Hᵢ ⊆ A}\n\n\n\nEsempio\nSia Ω = ℕ e H = {{1}, {2}, {3}, …}. Una misura di probabilità su F = P(ℕ) è completamente determinata dai pesi pᵢ = P({i}), con pᵢ ≥ 0 e ∑ᵢ pᵢ = 1.\n\nProbabilità Uniforme su un Insieme Finito: Se Ω = {ω₁, …, ωₘ}, si pone P(ωᵢ) = 1/m per ogni i.\nDistribuzione Geometrica: Sia Ω = ℕ₀ = {0, 1, 2, …} e sia 0 &lt; θ &lt; 1. Si definisce P(i) = θⁱ (1 - θ) per i ∈ ℕ₀. Questa è la distribuzione geometrica.\n\n\n\nEstensione e Unicità\nIl professore introduce i concetti di estensione* e unicità* delle misure}.\nMotivazione\nSi vuole costruire misure* su spazi non* numerabili*, come la retta* reale*, che soddisfino certe proprietà intuitive. Ad esempio, si vorrebbe una misura μ su ℝ tale che μ([a, b]) = b - a per ogni intervallo* [a, b].\nTeorema di Estensione di Carathéodory\nSia A* un’algebra* su Ω e sia μ una misura* σ-additiva* su A*. Allora esiste un’estensione* μ** di μ a σ(A)* che è una misura σ-additiva*. Se μ è σ-finita*, allora l’estensione è unica*.\n\nformulazione che usiamo noi\n\n\nTeorema di Unicità\nSiano P e Q due misure* di probabilità* su una σ-algebra F. Sia C* una classe* di insiemi* tale che σ(C) = F. Se P(A) = Q(A) per ogni A ∈ C, allora P = Q. In altre parole, se due misure di probabilità coincidono* su una classe* che genera la σ-algebra*, allora coincidono* su tutta* la σ-algebra*.\nP-Classe\nUna classe C di insiemi è detta P-classe se è stabile* per intersezioni* finite*. Ovvero, se A₁, …, Aₙ ∈ C, allora A₁ ∩ … ∩ Aₙ ∈ C.\n\nEsempio di P-Classe: La famiglia di semirette della forma (-∞, x]* con x ∈ ℝ è una P-classe.\n\nReferences\n2025-02-19 10:24\n_Status: revisione_finita  flashcard_finite  riscritto_finito\n_Tags: probabilità sbobine\nlez03- Prob\nMisure di Probabilità su Insiemi Numerabili\nIl professore introduce il concetto di misure di probabilità definite su insiemi numerabili, finiti o, più in generale, su spazi “misurabilmente generali”.\nCaso in cui Ω è un Insieme Finito\n\nProposizione : Se =Ω è un insieme finito* e F è la σ-algebra delle parti di Ω, una misura* di* probabilità* P* su F assegna una probabilità* a ogni sottoinsieme* di Ω* (l’insieme* delle* parti*) .\n\n\n\nSe P è una misura di probabilità su F, e si definisce pᵢ* come la probabilità del singoletto* {ωᵢ},* dove gli ωᵢ sono gli elementi di Ω ordinati* convenzionalmente* (1, 2, 3, …), allora la probabilità di ogni evento* A ⊆ Ω può essere scritta come la somma* delle probabilità* dei singoletti* contenuti* in A*.\n\ncon \\omega \\in \\set{\\omega_1,\\omega_2,\\cdots} numerabile* o finito* e \\mathcal{F}=\\mathcal{P}(\\Omega)\nse \\mathbb{P} è misura* di probabilita* di \\mathcal{F} e p_i:=\\mathbb{\\omega_i}  per i=1,2,3 → \\mathbb{P\\set{A}}=\\sum_{i: \\ \\omega_i \\in A} p_i \\quad \\forall i: \\omega_i \\in A\n\nP(A) = ∑ᵢ pᵢ,  per tutti gli i tali che ωᵢ ∈ A\n\nDove:\n\nP(A) è la probabilità dell’evento A.\npᵢ è la probabilità del singoletto {ωᵢ}.\nLa sommatoria è estesa a tutti gli indici i tali che l’elemento ωᵢ appartiene all’insieme A.\n\n\n\n\nCaratterizzazione completa: Una misura di probabilità sulla σ-algebra* delle parti* è completamente* caratterizzata* dalle probabilità* dei singoletti*. Conoscendo le probabilità di ogni singolo* elemento* di Ω, si può determinare la probabilità* di qualsiasi* evento.\n\n\nCondizione: Data una successione pᵢ ≥ 0 tale che ∑ᵢ pᵢ = 1, si può definire una misura di probabilità P su \\mathcal{F}=\\mathcal{P}(\\Omega) come:\n\nP(A) = \\sum_{i:\\omega_i \\in A} p_i\nÈ fondamentale che questa funzione sia definita su F.\n\n\n\nfatto fino a qua\nTeorema di Unicità per Misure di Probabilità\nIl professore introduce il teorema di unicità per le misure di probabilità.\n\n\nTeorema (caso di misura di probabilità): Se C è una P-classe che genera la σ-algebra F, e P₁ e P₂ sono due misure di probabilità su F, se P₁(A) = P₂(A) per ogni evento A nella P-classe C, allora P₁ = P₂.\n\n\n\nIn termini più formali:\n\nSia C una P-classe tale che σ(C) = F.\nSiano P₁ e P₂ due misure di probabilità su F.\nSe P₁(A) = P₂(A) ∀ A ∈ C, allora P₁ = P₂.\n\n\n\nEstensione a Misure Sigma-Finite: Il teorema si estende a misure sigma-finite con condizioni aggiuntive:\n\nSiano μ₁ e μ₂ due misure sigma-finite su una σ-algebra F.\nSia C una classe tale che la σ-algebra generata da C sia proprio F, cioè σ(C) = F.\nEsista una successione di eventi Eᵢ ∈ C tali che Eᵢ ∩ Eⱼ = ∅ per i ≠ j e ⋃ᵢ Eᵢ = Ω.\nμ₁(Eᵢ) &lt; ∞ per ogni i.\nSe μ₁(A) = μ₂(A) per ogni A ∈ C, allora μ₁ = μ₂.\n\n\n\n\n\nImportante: Per misure che non sono di probabilità, è necessario che le misure siano sigma-finite e che la P-classe contenga una partizione numerabile tale che le misure degli insiemi nella partizione siano finite.\n\n\nEsempio: Famiglia di Intervalli e Misura di Lebesgue\nDiscussione di un esempio riguardante la famiglia di intervalli su \\mathbb{R} e la misura di Lebesgue.\n\nClasse C₀: C₀ è la famiglia di intervalli aperti (a, b). Questa non è una P-classe, perché l’intersezione di due intervalli disgiunti è l’insieme vuoto, che non appartiene a C₀.\n\nClasse C₀ estesa: Aggiungendo l’insieme vuoto a C₀, si ottiene una P-classe.\nMisura di Lebesgue: La misura di Lebesgue non funziona direttamente con C₀, ma con la classe estesa, a causa della condizione di sigma-finità.\n\n\n\n\nContinuità della Misura di Probabilità\n\nMANCA UNA DIMOSTRAZIONE\n\nIl professore introduce il concetto di continuità per le misure di probabilità.\nConvergenza Monotona di Eventi\n\n\nDefinizione: Una successione di eventi Aₙ converge in modo monotono crescente a un evento A se Aₙ ⊆ Aₙ₊₁ per ogni n, e A = ⋃ₙ Aₙ.\nDefinizione: Aₙ converge in modo monotono decrescente a A se Aₙ ⊇ Aₙ₊₁ per ogni n, e A = ⋂ₙ Aₙ.\n\n\n\n\n\nTeorema di Continuità\n\n\nTeorema: Se P è una misura di probabilità su F, allora:\n\n\nPer ogni successione Aₙ di eventi in F che converge in modo monotono crescente ad A, si ha che:\nlim (n→∞) P(Aₙ) = P(A)\n\n\n\nPer ogni successione Aₙ di eventi in F che converge in modo monotono decrescente ad A, si ha che:\nlim (n→∞) P(Aₙ) = P(A)\n\n\n\n\n\n\n\n\n\n\nTeorema di continuità per misure di probabilità\n\n\n\n\nEnunciato: Sia \\mathcal{F} una \\sigma-algebra su \\Omega. Se P è una misura di probabilità su \\mathcal{F}, allora:\n\nP(A_n) \\to P(A) per ogni successione {A_n}_{n \\in \\mathbb{N}} di eventi in \\mathcal{F} che converge ad A monotonicamente (crescente o decrescente).\nSupponiamo che P sia una funzione da \\mathcal{F} a  tale che P(\\Omega) = 1 e P(A_1 \\cup A_2) = P(A_1) + P(A_2) per ogni A_1, A_2 \\in \\mathcal{F} con A_1 \\cap A_2 = \\emptyset. Allora P è \\sigma-additiva se e solo se per ogni successione {B_n}_{n \\in \\mathbb{N}} di eventi in \\mathcal{F} convergente monotonicamente all’insieme vuoto, \\lim_{n \\to \\infty} P(B_n) = 0.\n\n\n\nDimostrazione (parte 1, caso crescente):\n\nSia {A_n}_{n \\in \\mathbb{N}} una successione di eventi in \\mathcal{F} tale che A_n \\subseteq A_{n+1} per ogni n, e sia A = \\bigcup_{n=1}^{\\infty} A_n.\nDefiniamo una nuova successione di eventi {B_n}_{n \\in \\mathbb{N}} tale che B_1 = A_1 e B_{n+1} = A_{n+1} \\setminus A_n per ogni n \\geq 1. Gli eventi B_n sono a due a due incompatibili.\nSi ha che A_n = \\bigcup_{k=1}^{n} B_k, quindi P(A_n) = P(\\bigcup_{k=1}^{n} B_k) = \\sum_{k=1}^{n} P(B_k) (per additività finita).\nInoltre, A = \\bigcup_{n=1}^{\\infty} A_n = \\bigcup_{k=1}^{\\infty} B_k, quindi P(A) = P(\\bigcup_{k=1}^{\\infty} B_k) = \\sum_{k=1}^{\\infty} P(B_k) (per \\sigma-additività).\nPrendendo il limite per n \\to \\infty di P(A_n), si ottiene \\lim_{n \\to \\infty} P(A_n) = \\lim_{n \\to \\infty} \\sum_{k=1}^{n} P(B_k) = \\sum_{k=1}^{\\infty} P(B_k) = P(A).\nQuindi, P(A_n) converge a P(A).\n\n\n\n\n\nEquivalenza con la Sigma-Additività\n\nTeorema: Sia P una funzione da F a tale che P(Ω) = 1 e P(A₁ ∪ A₂) = P(A₁) + P(A₂) per ogni A₁ e A₂ disgiunti. Allora\n\nP è sigma-additiva se e solo se per ogni successione Bₙ convergente all’insieme vuoto, si ha che lim (n→∞) P(Bₙ) = 0.\n\n\n\n\ndimostrazione\n\n\n\nSubadditività Finita e Numerabile\n\n\nMANCA LA DIMOSTRAZIONE\n\n\nTeorema: Sia P una misura di probabilità su F e sia {Aₖ} una successione di eventi in F. Allora:\n\n\nSubadditività finita:\nP(⋃ₖ₌₁ⁿ Aₖ) ≤ ∑ₖ₌₁ⁿ P(Aₖ)\n\n\n\nSubadditività completa:\nP(⋃ₖ₌₁^∞ Aₖ) ≤ ∑ₖ₌₁^∞ P(Aₖ)\n\n\n\n\n\nCaso di eventi disgiunti: Se gli Aₖ sono a due a due disgiunti, vale l’uguaglianza.\n\n\nFormula per due eventi: Per due eventi qualsiasi A e B:\nP(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n\n\n\n\n\n\n\n\nSubadditività finita e numerabile di una misura di probabilità\n\n\n\n\nEnunciato: Sia P una misura di probabilità su \\mathcal{F} e {A_n}_{n \\in \\mathbb{N}} una successione di eventi in \\mathcal{F}. Allora:\n\nP(\\bigcup_{k=1}^{n} A_k) \\leq \\sum_{k=1}^{n} P(A_k) (subadditività finita).\nP(\\bigcup_{k=1}^{\\infty} A_k) \\leq \\sum_{k=1}^{\\infty} P(A_k) (subadditività completa).\n\n\n\nDimostrazione:\n\nLa subadditività finita si dimostra per induzione. Per n=2, P(A \\cup B) = P(A) + P(B) - P(A \\cap B) \\leq P(A) + P(B).\nPer il passo induttivo, supponiamo che valga per n e dimostriamo per n+1:\n\nP(\\bigcup_{k=1}^{n+1} A_k) = P(\\bigcup_{k=1}^{n} A_k \\cup A_{n+1}) \\leq P(\\bigcup_{k=1}^{n} A_k) + P(A_{n+1}) \\leq \\sum_{k=1}^{n} P(A_k) + P(A_{n+1}) = \\sum_{k=1}^{n+1} P(A_k).\n\n\nPer la subadditività completa, sia C_n = \\bigcup_{k=1}^{n} A_k. Allora C_n converge monotonicamente (crescendo) a \\bigcup_{k=1}^{\\infty} A_k.\nPer la continuità della misura di probabilità, P(\\bigcup_{k=1}^{\\infty} A_k) = \\lim_{n \\to \\infty} P(C_n) = \\lim_{n \\to \\infty} P(\\bigcup_{k=1}^{n} A_k).\nDalla subadditività finita, P(\\bigcup_{k=1}^{n} A_k) \\leq \\sum_{k=1}^{n} P(A_k).\nQuindi, \\lim_{n \\to \\infty} P(\\bigcup_{k=1}^{n} A_k) \\leq \\lim_{n \\to \\infty} \\sum_{k=1}^{n} P(A_k) = \\sum_{k=1}^{\\infty} P(A_k).\nPertanto, P(\\bigcup_{k=1}^{\\infty} A_k) \\leq \\sum_{k=1}^{\\infty} P(A_k).\n\n\n\n\n\nSigma-algebra di Borel su \\mathbb{R} e \\mathbb{R^d}\n\n\n\nIntroduzione della sigma-algebra di Borel su R.\n\n\nDefinizione: La sigma-algebra di Borel (B(R)) è la sigma-algebra generata dagli insiemi aperti di R.\n\n\nAperti in R: Un insieme A ⊆ R è aperto se per ogni x ∈ A esiste un intervallo aperto (x - ε, x + ε) ⊆ A.\n\n\n\n\n\nObiettivo: Restringere l’attenzione agli insiemi boreliani, che includono intervalli, semirette e altri insiemi “ragionevoli”.\n\n\nClassi di Insiemi: Definizione di diverse classi di insiemi che generano la sigma-algebra di Borel:\n\nC₀: Intervalli aperti (a, b).\nC₁: Intervalli chiusi [a, b].\nC₂: Semirette (-∞, x].\n\n\n\n\nAlgebra generata da C₁ ∪ C₂ ∪ C₃: Si può costruire un’algebra A a partire da C₁, C₂, e C₃, formata da unioni finite di elementi di queste classi. Gli elementi di A sono unioni di intervallini di vario tipo, eventualmente con semirette.\n\n\n\n\n\nEquivalenza tra generatori: B(R) può essere ottenuta generando la sigma-algebra a partire da C₀ o C₂.\nB(R) = σ(C₀) = σ(C₂) = σ(A)\n\n\n\nMotivazioni: Questo risultato è utile per:\n\nAvere un’idea concreta degli insiemi boreliani.\nSemplificare le dimostrazioni, usando il teorema di Caratheodory per estendere le misure da un’algebra alla sigma-algebra generata.\nIdentificare misure di probabilità, mostrando che coincidono su una P-classe che genera B(R).\n\n\n\nChiusi: Poiché la sigma-algebra di Borel contiene gli aperti, contiene anche i chiusi (complementari degli aperti). Quindi, contiene anche i singoli punti.\n\n\n\n\n\nSemirette: Le semirette del tipo (-∞, x] appartengono a B(R). Questo si può dimostrare approssimando la semiretta con unioni numerabili di intervalli chiusi.\n\n\n\n\nEquivalenza di generatori della \\sigma-algebra di Borel su \\mathbb{R}\n\n\nEnunciato: Sia \\mathcal{B}(\\mathbb{R}) la \\sigma-algebra di Borel su \\mathbb{R}. Allora: \\sigma(\\mathcal{C}_0) = \\sigma(\\mathcal{C}_1) = \\sigma(\\mathcal{C}_2) = \\mathcal{B}(\\mathbb{R}) dove:\n\n\\mathcal{C}_0 è la famiglia degli intervalli aperti (a, b).\n\\mathcal{C}_1 è la famiglia degli intervalli chiusi [a, b].\n\\mathcal{C}_2 è la famiglia delle semirette (-\\infty, x].\n\n\nDimostrazione (solo \\sigma(\\mathcal{C}_0) = \\mathcal{B}(\\mathbb{R}) ):\n\nPer definizione, \\mathcal{B}(\\mathbb{R}) = \\sigma(\\mathcal{A}), dove \\mathcal{A} è la famiglia degli aperti di \\mathbb{R}.\nPasso 1: \\mathcal{C}_0 \\subseteq \\mathcal{A}. Quindi \\sigma(\\mathcal{C}_0) \\subseteq \\sigma(\\mathcal{A}) = \\mathcal{B}(\\mathbb{R}).\nPasso 2: Ogni aperto A \\subseteq \\mathbb{R} si può scrivere come un’unione numerabile di intervalli aperti.\nQuindi, \\mathcal{A} \\subseteq \\sigma(\\mathcal{C}_0) perché \\sigma(\\mathcal{C}_0) è una \\sigma-algebra e contiene tutti gli intervalli aperti, quindi deve contenere anche le loro unioni numerabili.\nApplicando di nuovo la proprietà che se una classe è contenuta nell’altra, quando generate le sigma algebre, le due sigma algebre sono contenute. Quindi \\sigma(\\mathcal{A}) \\subseteq \\sigma(\\mathcal{C}_0).\nConcludiamo che \\mathcal{B}(\\mathbb{R}) = \\sigma(\\mathcal{A}) \\subseteq \\sigma(\\mathcal{C}_0).\nCombinando i due passi, otteniamo \\sigma(\\mathcal{C}_0) = \\mathcal{B}(\\mathbb{R}).\n\n\n\n\n\nSigma-algebra di Borel su Rᵈ\n\n\n\nEstensione del concetto di sigma-algebra di Borel a Rᵈ.\n\n\nDefinizione: La sigma-algebra di Borel su Rᵈ (B(Rᵈ)) è la sigma-algebra generata dagli insiemi aperti di Rᵈ.\n\n\n\n\n\nRettangoli aperti: Generalizzazione degli intervalli aperti tramite rettangoli aperti, prodotti cartesiani di intervalli aperti.\n\n\n\n\n\nClassi di Insiemi:\n\nD₀: Rettangoli aperti in Rᵈ, prodotti cartesiani di intervalli aperti.\n\n\n\n\nC₂: “Quadranti” in Rᵈ, insiemi della forma (-∞, x], dove x ∈ Rᵈ. Sono insiemi di punti y ∈ Rᵈ tali che ogni coordinata di y è minore o uguale della corrispondente coordinata di x.\n\n\n\n\n\n\n\nEquivalenza tra generatori: B(Rᵈ) può essere generata a partire da D₀ o da C₂.\nB(Rᵈ) = σ(C_0) = σ(D₀) = σ(C₂)\n\n\n\nConseguenza: Se due misure di probabilità P e Q su B(Rᵈ) coincidono su tutti i quadranti, allora sono uguali.\n\n\nMANCA UNA DELUCIDAZIONE\n\n\nMisura di Lebesgue\n\n\n\nIntroduzione della misura di Lebesgue, che rappresenta lunghezza, area o volume.\n\n\nTeorema: Esiste un’unica misura sigma-finita μ su B(R) tale che μ((a, b]) = b - a per ogni a, b ∈ R.\n\n\nGeneralizzazione a Rᵈ: Esiste un’unica misura sigma-finita μ su B(Rᵈ) tale che, per ogni rettangolo R = (a₁, b₁] × … × (a𝒹, b𝒹], si ha μ(R) = (b₁ - a₁) * … * (b𝒹 - a𝒹).\n\n\n\n\n\nMisura di Lebesgue: Questa misura si chiama misura di Lebesgue e non è una misura di probabilità.\n\n\nCostruzione: Per costruire la misura di Lebesgue, si definisce una funzione finitamente additiva su un’algebra di insiemi (unioni finite di intervallini) e poi la si estende usando il teorema di Caratheodory.\n\n\n\n\n\nNotazione: La misura di Lebesgue è definita sui boreliani di Rᵈ.\n\n\nReferences\n2025-02-23 14:35\n_Status: flashcard_finite     riscritto_finito     revisione_finita\n_Tags:  probabilità   sbobine\nprob- Lez04\nSigma-algebra generata da una famiglia di insiemi\nIl professore spiega un dubbio frequente riguardo alla sigma-algebra generata da una famiglia di insiemi.\nDubbio comune\nMolti studenti si chiedono come la sigma-algebra di Borel (\\mathcal{B}) sia generata dagli aperti (U) o, equivalentemente, dagli intervalli.\nChiarimento del professore\n\n\nConcetto di generazione: Il professore ricorda che generare una sigma-algebra a partire da una classe di insiemi significa che la sigma-algebra risultante conterrà molti più elementi della classe di partenza.\n\nEsempio: Se si parte da un singolo evento A, la sigma-algebra generata conterrà A, il suo complementare A^c, l’insieme vuoto \\emptyset e l’insieme totale \\Omega.\nSe si parte da due eventi A e B, la sigma-algebra conterrà A, B, A \\cup B, A^c, B^c, A \\cup B^c, e così via.\n\n\n\nSigma-algebra dei Boreliani: La sigma-algebra dei Boreliani (\\mathcal{B}) contiene molti più insiemi degli intervalli aperti da cui è generata. Include tutti gli insiemi chiusi, i punti singoli, le semirette, gli intervalli semiaperti, ecc.\n\n\nNon confondere la famiglia con la sigma-algebra generata: È fondamentale non confondere la famiglia di insiemi di partenza con la sigma-algebra che essa genera. La sigma-algebra generata è generalmente più grande della famiglia di partenza, a meno che la famiglia non sia già una sigma-algebra.\n\n\nCome verificare se un insieme appartiene alla sigma-algebra generata: Per capire se un insieme appartiene alla sigma-algebra generata, si deve verificare se può essere ottenuto tramite operazioni di complementazione, unione numerabile e intersezione numerabile a partire dagli insiemi della famiglia generatrice.\n\nPrendere un elemento A nella famiglia, e verificare se anche il suo complementare A^c appartiene alla sigma-algebra.\nPrendere due elementi A e B e verificare se la loro unione A \\cup B e la loro intersezione A \\cap B appartengono alla sigma-algebra. L’appartenenza dell’intersezione discende dalle proprietà di algebra/sigma-algebra.\n\n\n\nMisura di Lebesgue e sue proprietà\nIl professore riprende la lezione precedente introducendo la misura di Lebesgue su \\mathbb{R}^d.\nDefinizione e proprietà\n\n\nMisura di Lebesgue su \\mathbb{R}: Nel caso di \\mathbb{R}, la misura di Lebesgue di un intervallo è esattamente la sua lunghezza. La misura di Lebesgue di tutto \\mathbb{R} è +\\infty. Si ricorda che la misura di Lebesgue è sigma-finita.\n\n\nMisura di Lebesgue di un punto: La misura di Lebesgue di un singolo punto è zero, ovvero \\lambda({x}) = 0 per ogni x \\in \\mathbb{R}. Questo vale anche per misure di probabilità assolutamente continue.\n\n\nProprietà generali:\n\nIn \\mathbb{R}^d, la misura di Lebesgue di un punto è zero.\nIn \\mathbb{R}^3, la misura di Lebesgue di un piano è zero.\nPiù in generale, in \\mathbb{R}^d, la misura di Lebesgue di qualsiasi iperpiano di dimensione strettamente minore di d è zero (Leb_D=0)\n\n\n\nEsempio\nIl professore propone un esempio in \\mathbb{R}^2:\n\nConsideriamo due rette nel piano. Qual è la misura di Lebesgue della loro unione?\n\nSoluzione: Poiché ogni retta ha misura di Lebesgue zero e la misura di Lebesgue è sigma-additiva, la misura dell’unione delle due rette è la somma delle loro misure, che è 0 + 0 = 0. Matematicamente: \\lambda(retta_1 \\cup retta_2) \\le \\lambda(retta_1) + \\lambda(retta_2) = 0 + 0 = 0.\n\nEsempi di Spazi di Probabilità\nIl professore introduce due esempi per illustrare i concetti di spazi di probabilità e misure.\nEsempio 1: Dado a Sei Facce (spazio finito)\n\nSpazio Campionario: \\Omega = {1, 2, 3, 4, 5, 6}, che rappresenta i possibili risultati del lancio di un dado a sei facce.\nProbabilità: Ogni elemento ha la stessa probabilità di verificarsi, ovvero P({i}) = \\frac{1}{6} per i = 1, 2, ..., 6.\nMisura di Probabilità: La funzione di probabilità è definita sull’insieme delle parti di \\Omega, P(\\cdot): \\mathcal{P}(\\Omega) \\to [0,1], e assegna a ogni sottoinsieme di \\Omega la somma delle probabilità dei suoi elementi  P(A)=\\sum_{i \\in A}p_i \\ \\ \\ , p_i=\\frac{1}{6} con \\mathcal{A}\\in \\mathcal{P}(\\Omega)= \\mathcal{F}\nQuesta è una misura.\nModellizzazione: Questo esempio rappresenta il lancio di un dado non truccato, dove ogni faccia ha la stessa probabilità di uscire. Si fanno delle scelte di modellizzazione, come assumere che il dado non venga rubato o distrutto.\n\nEsempio 2: Cerchio Unitario (spazio non numerabile)\n\nSpazio Campionario: \\mathbb{R}^2\\supset\\Omega =\\set{\\omega=(x_1, x_2) : x_1^2 + x_2^2 \\le 1}, che rappresenta l’insieme dei punti all’interno di un cerchio di raggio 1.\n\nMisura di Probabilità: Si vuole definire una misura di probabilità che formalizzi l’idea di scegliere un punto a caso uniformemente all’interno del cerchio.\nSigma-algebra: Si utilizza la sigma-algebra dei Boreliani su \\mathbb{R}^2 (\\mathcal{F}=\\mathcal{B}(\\mathbb{R})), ristretta a \\Omega.\nDefinizione della Misura: (abbiamo bisogno di una misura non discreta) Si parte dalla misura di Lebesgue \\lambda (Leb_2) e si definisce la misura di probabilità P(A) come:  P(A) = \\frac{\\lambda(A \\cap \\Omega)}{\\lambda(\\Omega)} = \\frac{\\lambda(A \\cap \\Omega)}{\\pi} \\ \\ \\ \\ \\ \\ \\ \\  \\forall A \\in \\mathcal{F} dove A è un insieme misurabile e \\lambda(\\Omega) = \\pi è l’area del cerchio unitario.\nUniformità: Questa misura di probabilità è uniforme, nel senso che la probabilità di un piccolo disco attorno a un punto è proporzionale all’area del disco, indipendentemente dalla posizione del punto all’interno del cerchio.\nEventi: Gli eventi sono sottoinsiemi di \\Omega che appartengono alla sigma-algebra.\nEsempio di Evento: Si consideri l’evento A = “il diametro passante per il punto scelto interseca il settore tra le ore 12 e le ore 3”. Per calcolare la probabilità di A, si deve tradurre questo evento in un sottoinsieme misurabile di \\Omega. Questo sottoinsieme è l’unione del primo e terzo quadrante.\n\nProbabilità Condizionata e Indipendenza\nIl professore introduce i concetti di probabilità condizionata e indipendenza.\nSpazio Misurabile e Spazio di Probabilità\n\nUno spazio misurabile è una coppia (\\Omega, \\mathcal{F}), dove \\Omega è lo spazio campionario e \\mathcal{F} è una sigma-algebra su \\Omega.\nUno spazio di probabilità è una terna (\\Omega, \\mathcal{F},\\mathbb{P}), dove (\\Omega, \\mathcal{F}) è uno spazio misurabile e P è una misura di probabilità su \\mathcal{F}.\n\nProbabilità Condizionata\n\n\nSiano E e H due eventi in \\mathcal{F}, con P(H) &gt; 0. La probabilità condizionata di E dato H è definita come: P(E|H) = \\frac{P(E \\cap H)}{P(H)}\nInterpretazione: P(E|H) rappresenta la probabilità che l’evento E si verifichi, dato che l’evento H si è verificato. In altre parole, si restringe l’attenzione all’universo H e si valuta la probabilità di E in questo universo ristretto.\n\n\n\n\n\n\nProprietà della Probabilità Condizionata\n\nP(E|H) è una misura di probabilità: Fissato H\\in \\mathcal{F}, \\ \\ \\mathbb{P}(H)\\geq 0, la funzione P(E|H): \\mathcal{F} \\to è una misura di probabilità su \\mathcal{F}. (la probabilità condizionata è una funzione rispetto a E)\nQuesto significa che soddisfa gli assiomi di una misura di probabilità:\n\nPer dimostrare che questa applicazione è una misura di probabilità su \\mathcal{F}, dobbiamo verificare tre proprietà fondamentali:\n\n\nNon negatività: P(E|H) \\geq 0 Questo è vero perché sia P(E \\cap H) che P(H) sono non negativi, e quindi il loro rapporto è non negativo.\n\n\nNormalizzazione: P(\\Omega|H) = 1 Dimostrazione: P(\\Omega|H) = \\frac{P(\\Omega \\cap H)}{P(H)} = \\frac{P(H)}{P(H)} = 1\n\n\nAdditività completa: Sia {A_n}_{n \\geq 1} una successione di eventi disgiunti. Dobbiamo dimostrare che: P\\left(\\bigcup_{n=1}^{\\infty} A_n \\mid H\\right) = \\sum_{n=1}^{\\infty} P(A_n \\mid H)\n\nIniziamo scrivendo la definizione: P\\left(\\bigcup_{n=1}^{\\infty} A_n \\mid H\\right) = \\frac{P\\left(\\left(\\bigcup_{n=1}^{\\infty} A_n\\right) \\cap H\\right)}{P(H)}\nUsiamo la proprietà distributiva dell’intersezione rispetto all’unione: \\frac{P\\left(\\bigcup_{n=1}^{\\infty} (A_n \\cap H)\\right)}{P(H)}\nPoiché gli A_n sono disgiunti, anche gli (A_n \\cap H) sono disgiunti. Quindi, possiamo usare l’additività completa della probabilità P: \\frac{\\sum_{n=1}^{\\infty} P(A_n \\cap H)}{P(H)}\nRiscriviamo ogni termine usando la definizione di probabilità condizionale: \\sum_{n=1}^{\\infty} \\frac{P(A_n \\cap H)}{P(H)} = \\sum_{n=1}^{\\infty} P(A_n \\mid H)\nQuindi, abbiamo dimostrato l’additività completa: P\\left(\\bigcup_{n=1}^{\\infty} A_n \\mid H\\right) = \\sum_{n=1}^{\\infty} P(A_n \\mid H)\n\n\n\nCorollario\nOgni proprietà che vale per una misura di probabilità vale anche per la probabilità condizionale quando si tiene fisso il condizionante. Ad esempio:\n- P(E|H) \\ge 0 per ogni E \\in \\mathcal{F}.\n- P(\\Omega|H) = \\frac {P(\\Omega \\cap H)}{\\mathbb{P}(H)}= \\frac {P( H)}{\\mathbb{P}(H)} =1.\n- Se E_1, E_2, ... sono eventi disgiunti, allora P(\\bigcup_{i=1}^{\\infty} E_i | H) = \\sum_{i=1}^{\\infty} P(E_i | H).\n- \n- intersezione e unione godono della proprietà distributiva\n- \n- \n\nOGNI probabilità che sappiamo valere per una misura di probabilità vale per la probabilità condizionata quando teniamo fisso il condizionante\n\nesempio:\n\n\n\n\nFormula delle Probabilità Totali\n\n\nSia H_1, H_2, ... una partizione numerabile di \\Omega, ovvero H_i \\cap H_j = \\emptyset per i \\ne j e \\bigcup_{i=1}^{\\infty} H_i = \\Omega, con P(H_i) &gt; 0 per ogni i. Allora, per ogni evento E \\in \\mathcal{F}: P(E) = \\sum_{i=1}^{\\infty} P(E|H_i) P(H_i)\n\nCaso Generale: Partizione Numerabile\n\n\nDefinizione di partizione: Sia {H_i}_{i=1}^{\\infty} una partizione numerabile di \\Omega. Questo significa che:\n\nH_i \\in \\mathcal{F} per ogni i (ogni H_i è un evento misurabile)\n\\bigcup_{i=1}^{\\infty} H_i = \\Omega (l’unione di tutti gli H_i è l’intero spazio campionario)\nH_i \\cap H_j = \\emptyset per i \\neq j (gli H_i sono a due a due disgiunti)\nP(H_i) &gt; 0 per ogni i\n\n\n\nDecomposizione dell’evento E: L’evento E può essere espresso come l’unione delle intersezioni di E con gli elementi della partizione: E = \\bigcup_{i=1}^{\\infty} (E \\cap H_i)\n\n\nAdditività completa: Poiché gli eventi (E \\cap H_i) sono disgiunti, possiamo scrivere: P(E) = \\sum_{i=1}^{\\infty} P(E \\cap H_i)\n\n\nUtilizzo della probabilità condizionale: Usando la definizione di probabilità condizionale: P(E \\cap H_i) = P(E \\mid H_i) \\cdot P(H_i)\n\n\nFormula generale delle probabilità totali: Sostituendo nella formula per P(E): P(E) = \\sum_{i=1}^{\\infty} P(E \\mid H_i) \\cdot P(H_i)\n\n\nQuesta formula esprime la probabilità di E come la somma delle probabilità condizionate di E dato H_i, pesate per le probabilità di H_i.\nCaso Semplice: Partizione in Due Eventi\n\n\nDecomposizione dell’evento E: L’evento E può essere espresso come l’unione di due eventi mutuamente esclusivi: E = (E \\cap H) \\cup (E \\cap H^c) dove H^c rappresenta il complemento di H.\n\n\nAdditività: Siccome (E \\cap H) e (E \\cap H^c) sono disgiunti, possiamo scrivere: P(E) = P(E \\cap H) + P(E \\cap H^c)\n\n\nUtilizzo della probabilità condizionale: Ricordando la definizione di probabilità condizionale: P(E \\mid H) = \\frac{P(E \\cap H)}{P(H)} e quindi P(E \\cap H) = P(E \\mid H) \\cdot P(H) Allo stesso modo: P(E \\cap H^c) = P(E \\mid H^c) \\cdot P(H^c)\n\n\nFormula delle probabilità totali: Sostituendo nella formula per P(E): P(E) = P(E \\mid H) \\cdot P(H) + P(E \\mid H^c) \\cdot P(H^c)\nQuesta formula permette di calcolare la probabilità di E usando le probabilità condizionate e le probabilità degli eventi H e il suo complemento.\n\n\n\nTeorema di Bayes\n\nNelle stesse ipotesi della formula delle probabilità totali, per ogni H_i nella partizione e per ogni evento E con P(E) &gt; 0: P(H_i|E) = \\frac{P(E|H_i) P(H_i)}{\\sum_{j=1}^{\\infty} P(E|H_j) P(H_j)}\n\nEsempio del Test Clinico\n\nSi consideri un test clinico per una malattia. Siano:\n\nE = “il test risulta positivo”.\nH = “il paziente è malato”.\nH^c = “il paziente è sano”.\n\n\nSi conoscono le seguenti probabilità condizionate:\n\nP(E|H) = probabilità che il test sia positivo dato che il paziente è malato (sensibilità del test).\nP(E|H^c) = probabilità che il test sia positivo dato che il paziente è sano (1 - specificità del test).\nP(H) = probabilità a priori che un individuo nella popolazione sia malato (prevalenza della malattia).\n\n\nSi vuole calcolare P(H|E), ovvero la probabilità che il paziente sia effettivamente malato dato che il test è risultato positivo. Utilizzando il teorema di Bayes: P(H|E) = \\frac{P(E|H) P(H)}{P(E|H) P(H) + P(E|H^c) P(H^c)}\ndove P(H^c) = 1 - P(H).\n\nFormulazione del Teorema di Bayes\nDati: P(E|H), P(E|H^c) e P(H), si vuole calcolare P(H|E).\nTeorema:\nSia ({H_i})_{i\\ge 1} una partizione numerabile di \\Omega, tale che P(H_i) &gt; 0 per ogni i. Allora, la probabilità condizionata P(H_i|E) può essere calcolata come:\nP(H_i|E) = \\frac{P(E|H_i)P(H_i)}{\\sum_{j \\ge 1} P(E|H_j)P(H_j)}\nDimostrazione:\nIl denominatore dell’espressione sopra è equivalente a P(E) per il teorema delle probabilità totali. Quindi:\nP(H_i|E) = \\frac{P(E|H_i)P(H_i)}{P(E)}\nA destra dell’equazione, abbiamo solo termini noti.\nOsservazioni Importanti\n\nInversione delle Probabilità: Il teorema permette di “invertire” le probabilità, calcolando P(H_i|E) a partire da P(E|H_j) e P(H_j).\nStatistica Bayesiana: Questo teorema è alla base della statistica Bayesiana.\nTerminologia Statistica:\n\nP(E|H_i) è chiamata verosimiglianza (likelihood).\nP(H_i) è la distribuzione iniziale (prior).\nP(H_i|E) è la distribuzione finale (posterior).\n\n\nMeccanismo di Apprendimento: Il teorema può essere visto come un meccanismo di apprendimento. P(H_i) rappresenta la conoscenza iniziale, P(E|H_i) è il modello, e P(H_i|E) è ciò che si apprende dopo aver osservato l’evento E.\nNecessità di una Struttura Probabilistica: Per fare questi calcoli, è fondamentale avere uno spazio \\Omega, una \\sigma-algebra e una misura di probabilità ben definiti, anche se poi l’enunciato riguarda solo specifici valori numerici.\n\nReferences\n2025-02-25 13:16\n_Status: flashcard_zero  riscritto_zero  revisione_finita\n_Tags:  probabilità   sbobine\nprob-lez05\nBoreliani e Algebra\n\nQuando si definiscono i Boreliani, è necessario includere esplicitamente l’insieme vuoto per assicurarsi che sia un’algebra.\nSe M va da 1 a M, con B_i appartenente a vari intervallini e semirette, si deve considerare anche il caso in cui m = 0, dove per convenzione l’insieme è vuoto.\nQuesto è importante per la chiarezza e per garantire che la definizione soddisfi le proprietà di un’algebra.\n\nMisura di Lebesgue\n\nLa misura di Lebesgue su \\mathbb{R} e i suoi Boreliani è tale che la misura di un intervallo chiuso [a, b] è uguale a b - a.\nQuesta definizione si estende in modo analogo ai cubotti in dimensioni superiori.\n\nSigma Algebra e Traccia\n\n\nData una sigma algebra \\mathcal{F} definita su un insieme \\Omega, si consideri un insieme \\Delta \\in \\mathcal{F}.\n\n\n\nSi definisce la traccia della sigma algebra \\mathcal{F} su \\Delta come:\n\\qquad \\mathcal{F}_\\Delta = \\set{A \\cap \\Delta : A \\in \\mathcal{F}}\n\n\n\n\n\nIn altre parole, si prendono tutti gli insiemi A in \\mathcal{F} e si fa l’intersezione con \\Delta.\n\n\nAffermazione: \\mathcal{F}_\\Delta è una sigma algebra.\n\n\nEsempi Importanti\n\n**Intervallo **: Sia \\Delta =[0,1] e \\Omega = \\mathbb{R}. Si può prendere \\mathcal{F} come i Boreliani di \\mathbb{R}\noppure la restrizione dei Boreliani a |0,1|, che viene chiamata Boreliani di |0,1|.\n\ncontrolla\nI Boreliani  di  sono ottenuti prendendo un qualunque elemento misurabile rispetto ai Boreliani di \\mathbb{R} e facendo l’intersezione con .\n\n\nNumeri Positivi: Analogamente, si può fare la stessa cosa con i numeri positivi \\mathbb{R}^+ per ottenere i Boreliani di \\mathbb{R}^+.\n\nProbabilità Condizionali\n\n\nSi riprende l’argomento delle probabilità condizionali.\n\n\nIn uno spazio di probabilità (\\Omega, \\mathcal{F}, P), la probabilità condizionale di A dato B, con P(B) &gt; 0, è definita come:\n\\qquad P(A|B) = \\frac{P(A \\cap B)}{P(B)} se P(B)&gt;0\n\n\nImportante: P(A|B) è una funzione di due eventi, non è la probabilità di un evento “A dato B”. Si guarda come varia al variare di A.\n\n\nTeorema delle Probabilità Totali e Teorema di Bayes\n\n\nTeorema delle Probabilità Totali: Supponendo che H_i sia una partizione (famiglia al più numerabile di eventi disgiunti la cui unione è \\Omega) e P(H_i) &gt; 0, allora:\n\\qquad P(A) = \\sum_i P(A|H_i)P(H_i)\n\n\nTeorema di Bayes: Nelle stesse condizioni, per ogni i:\n\\qquad P(H_i|A) = \\frac{P(A|H_i)P(H_i)}{\\sum_j P(A|H_j)P(H_j)}\n\n\nEsempio delle Urne\n\n\nDescrizione: Ci sono due urne. La prima contiene 5 palline nere e 5 rosse, la seconda contiene 2 nere e 8 rosse. Si tira una moneta per scegliere un’urna e poi si estrae una pallina.\n\n\nEventi:\n\nR: Estrarre una pallina rossa.\nT: Uscita “testa” sulla moneta, che implica la scelta della prima urna.\n\n\n\nAssunzioni:\n\nP(T) = \\frac{1}{2} (la moneta è equilibrata).\nP(R|T) = \\frac{5}{10} (probabilità di estrarre una pallina rossa dalla prima urna).\nP(R|T^c) = \\frac{8}{10} (probabilità di estrarre una pallina rossa dalla seconda urna).\n\n\n\nCalcolo: Utilizzando il teorema di Bayes, si può calcolare la probabilità di aver estratto dalla prima urna, dato che è stata estratta una pallina rossa:\n\\qquad P(T|R) = \\frac{P(R|T)P(T)}{P(R|T)P(T) + P(R|T^c)P(T^c)}\n\n\nSostituendo i valori:\n\\qquad P(T|R) = \\frac{\\frac{5}{10} \\cdot \\frac{1}{2}}{\\frac{5}{10} \\cdot \\frac{1}{2} + \\frac{8}{10} \\cdot \\frac{1}{2}} = \\frac{\\frac{5}{20}}{\\frac{5}{20} + \\frac{8}{20}} = \\frac{5}{13}\n\n\nCostruzione dello Spazio di Probabilità\n\nViene fatto notare che manca la definizione esplicita dello spazio di probabilità (\\Omega, \\mathcal{F}, P).\nSi assume che esista uno spazio di probabilità (\\Omega, \\mathcal{F}, P) tale che gli eventi T (testa) ed R (pallina rossa) siano ben definiti e con le probabilità specificate.\n\nPartizioni e Sigma Algebra\n\nSi considerano due partizioni dello spazio \\Omega:\n\n\nH_1 = T e H_2 = T^c (testa o croce).\nE_1 = R e E_2 = R^c (pallina rossa o nera).\n\n\nSi formano le intersezioni: T \\cap R, T \\cap R^c, T^c \\cap R, T^c \\cap R^c.\n\n\n\n\nLa collezione (famiglia) B = \\set{(H_n \\cap E_k) \\ \\ \\ n\\geq1,k\\geq1} forma una partizione di \\Omega.\n\nDefinizione della Sigma Algebra\n\nSi definisce una sigma algebra generata dagli eventi in B  \\mathcal{F}= \\sigma(B).\nNel caso specifico, questa sigma algebra contiene eventi come “testa e pallina nera”, “testa e pallina rossa”, “croce e pallina nera”, “croce e pallina rossa”, ma anche eventi come “esce testa”.\nAd esempio, l’evento “esce testa” (H_1) può essere scritto come H_1 = (H_1 \\cap E_1) \\cup (H_1 \\cap E_2).\n\nProposizione Chiave\n\n\nSia {H_n} una partizione di eventi e {E_k} un’altra famiglia di eventi. La collezione B = {H_n \\cap E_k} è una partizione numerabile.\n\n\nSi assegnano una successione di pesi positivi per ogni n (p_n)_{n\\geq1} tali che \\sum_n p_n = 1,\n\n\ne pesi condizionali positivi per ogni n e k (p_{k|n})_{n\\geq1} tali che \\sum_k p_{k|n} = 1 per ogni n.\n\n\nTesi: Esiste una misura di probabilità P definita sulla sigma algebra generata da B tale che:\n\nP(H_n) = p_n per ogni n\nP(H_n \\cap E_k) = p_{k|n} p_n per ogni k e n\nP(E_k|H_n) = p_{k|n} per ogni k e n\n\n\n\nApplicazione all’Esempio delle Urne\n\n\nB = {T \\cap R, T \\cap R^c, T^c \\cap R, T^c \\cap R^c}.\np_1 = P(T) = 0.5 e p_2 = P(T^c) = 0.5.\np_{1|1} = P(R|T) = \\frac{5}{10} (probabilità di estrarre rosso dato testa).\np_{2|1} = P(R^c|T) = \\frac{5}{10} (probabilità di estrarre nero dato testa).\np_{1|2} = P(R|T^c) = \\frac{8}{10} (probabilità di estrarre rosso dato croce).\np_{2|2} = P(R^c|T^c) = \\frac{2}{10} (probabilità di estrarre nero dato croce).\nCon questi ingredienti, si può costruire una misura di probabilità ben definita.\n\nDimostrazione\n\nLa dimostrazione si basa sul fatto che, avendo una sigma algebra generata da un insieme numerabile B, è sufficiente definire una famiglia di numeri positivi q_{kn} (che dipendono da due indici perché la famiglia è indicizzata da due numeri) tali che la somma su tutti gli indici sia 1.\nSi definisce q_{kn} = p_{k|n} p_n.\nSi verifica che \\sum_{k,n} q_{kn} = \\sum_n p_n \\sum_k p_{k|n} = \\sum_n p_n \\cdot 1 = 1.\nQuindi, esiste una misura di probabilità P sulla sigma algebra generata da B tale che P(H_n \\cap E_k) = p_{k|n} p_n.\n\n\nIndipendenza di Eventi\nL’indipendenza è una proprietà della probabilità, non degli eventi stessi. Per una certa misura di probabilità, due eventi potrebbero essere indipendenti, mentre per un’altra no. Pertanto, si parla di eventi indipendenti rispetto a una specifica probabilità P.\nDefinizione di Indipendenza\nDue eventi A e B, appartenenti a uno spazio di probabilità (\\Omega, \\mathcal{F}, P), sono detti indipendenti se e solo se la probabilità della loro intersezione è uguale al prodotto delle loro probabilità:\nP(A \\cap B) = P(A) \\cdot P(B)\nIntuitivamente, conoscere l’esito di B non altera la valutazione di probabilità su A.\nProbabilità Condizionale e Indipendenza\nPartendo dalla definizione di probabilità condizionale:\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\nsi moltiplica per P(B), ottenendo:\nP(A \\cap B) = P(A \\mid B) \\cdot P(B)\nQuesta formula esprime che la probabilità che A e B si verifichino contemporaneamente è uguale alla probabilità di B moltiplicata per “qualcosa”. L’idea intuitiva è che avere informazioni su B aggiorna la probabilità su A.\nProprietà dell’Indipendenza\nSe due eventi A e B sono indipendenti, allora anche A e il complementare di B (indicato come B^c) sono indipendenti. Di conseguenza, anche le seguenti coppie di eventi sono indipendenti:\n\nA^c e B^c\nA^c e B\n\nQuesto significa che l’indipendenza è stabile rispetto all’operazione di complementazione.\nDimostrazione:\nPer dimostrare che A e B^c sono indipendenti, dobbiamo mostrare che P(A \\cap B^c) = P(A) \\cdot P(B^c).\nConsideriamo il diagramma di Venn. L’area rappresentante A \\cap B^c è contenuta in A. Possiamo scrivere A \\cap B^c come A - (A \\cap B).\nQuindi, P(A \\cap B^c) = P(A) - P(A \\cap B).\nPoiché A e B sono indipendenti, P(A \\cap B) = P(A) \\cdot P(B). Sostituendo:\nP(A \\cap B^c) = P(A) - P(A) \\cdot P(B) = P(A) \\cdot (1 - P(B)) = P(A) \\cdot P(B^c).\nQuesto dimostra che A e B^c sono indipendenti.\nErrore Comune\nÈ importante non confondere l’indipendenza (A e B indipendenti) con l’esclusività (A \\cap B = \\emptyset). L’indipendenza è una proprietà della probabilità, mentre l’esclusività è una relazione tra eventi.\nEsempio: Lancio di Due Dadi\nConsideriamo lo spazio campionario \\Omega formato da coppie di numeri, dove ogni numero rappresenta l’esito di un dado a sei facce:\n\\Omega = {(\\omega_1, \\omega_2) \\mid \\omega_1, \\omega_2 \\in {1, 2, 3, 4, 5, 6}}\nLa cardinalità di \\Omega è |\\Omega| = 6 \\times 6 = 36.\nAssumiamo che ogni coppia abbia la stessa probabilità di verificarsi (misura uniforme). Quindi, la probabilità di ogni singolo evento elementare è \\frac{1}{36}.\nDefiniamo i seguenti eventi:\n\nA: il primo dado mostra la faccia 1\nB: il secondo dado mostra la faccia 3\n\nMatematicamente:\n\nA = {(\\omega_1, \\omega_2) \\in \\Omega \\mid \\omega_1 = 1}\nB = {(\\omega_1, \\omega_2) \\in \\Omega \\mid \\omega_2 = 3}\n\nLa probabilità di A è P(A) = \\frac{6}{36} = \\frac{1}{6}, poiché ci sono sei coppie in cui il primo elemento è 1. Similmente, P(B) = \\frac{6}{36} = \\frac{1}{6}.\nL’intersezione di A e B è l’evento in cui il primo dado mostra 1 e il secondo dado mostra 3:\nA \\cap B = {(1, 3)}\nQuindi, P(A \\cap B) = \\frac{1}{36}.\nVerifichiamo se A e B sono indipendenti:\nP(A) \\cdot P(B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36} = P(A \\cap B)\nPoiché P(A \\cap B) = P(A) \\cdot P(B), gli eventi A e B sono indipendenti.\nIndipendenza di n Eventi\nGli eventi A_1, A_2, ..., A_n sono indipendenti se, per ogni sottoinsieme di k eventi distinti (con 2 \\leq k \\leq n), la probabilità dell’intersezione è uguale al prodotto delle probabilità:\nP(A_{i_1} \\cap A_{i_2} \\cap ... \\cap A_{i_k}) = P(A_{i_1}) \\cdot P(A_{i_2}) \\cdot ... \\cdot P(A_{i_k})\ndove i_1, i_2, ..., i_k sono indici distinti compresi tra 1 e n.\nEsempio con Tre Eventi (n = 3)\nSe n = 3, la definizione di indipendenza richiede che siano soddisfatte le seguenti condizioni:\n\nP(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\cdot P(A_2) \\cdot P(A_3)\nP(A_1 \\cap A_2) = P(A_1) \\cdot P(A_2)\nP(A_1 \\cap A_3) = P(A_1) \\cdot P(A_3)\nP(A_2 \\cap A_3) = P(A_2) \\cdot P(A_3)\n\nÈ importante notare che non è sufficiente che solo la prima condizione sia soddisfatta per concludere che i tre eventi sono indipendenti. Tutte le condizioni devono essere vere.\nConseguenze dell’Indipendenza\nSe A_1, A_2, ..., A_n sono indipendenti, allora anche gli eventi ottenuti complementando alcuni di essi sono indipendenti. Ad esempio, A_1, A_2, A_3^c sono indipendenti.\nIndipendenza di una Successione Numerabile di Eventi\nUna successione numerabile di eventi (A_n)_{n \\in \\mathbb{N}} è detta indipendente se ogni sua sottosuccessione finita è costituita da eventi indipendenti. In altre parole, per ogni m \\in \\mathbb{N}, gli eventi A_1, A_2, ..., A_m devono essere indipendenti.\nRegola della Catena (o Regola delle Probabilità Composte)\nSupponiamo di avere n eventi E_1, E_2, ..., E_n appartenenti a \\mathcal{F}, tali che P(E_1 \\cap E_2 \\cap ... \\cap E_n) &gt; 0. Allora, la probabilità dell’intersezione può essere scritta come: ricontrolla\n\n\n\nP(E_1 \\cap E_2 \\cap ... \\cap E_n) = P(E_1) \\cdot P(E_2 \\mid E_1) \\cdot P(E_3 \\mid E_1 \\cap E_2) \\cdot ... \\cdot P(E_n \\mid E_1 \\cap E_2 \\cap ... \\cap E_{n-1})\nDimostrazione (per n=2):\nP(E_1 \\cap E_2) = P(E_1) \\cdot P(E_2 \\mid E_1)\nQuesta formula deriva direttamente dalla definizione di probabilità condizionale. ricontrolla\n\n\nper n=2 \\mathbb{P}(E_1 \\cap E_2) = \\mathbb{P}(E_1) \\mathbb{P}(E_2 | E_1)\\mathbb{P}(E_1 \\cap E_2) = \\frac{\\mathbb{P}(E_1)\\mathbb{P}(E_2 | E_1)}{\\mathbb{P}(E_1)}\n\n\nIndipendenza Tra Eventi\n\nDue eventi A e B sono indipendenti se e solo se P(A \\cap B) = P(A)P(B).\nL’indipendenza è una proprietà della misura di probabilità, non degli eventi stessi.\n\nProprietà Importanti\n\nSe A e B sono indipendenti, allora anche A e B^c sono indipendenti. Di conseguenza, anche A^c e B^c, e A^c e B sono indipendenti.\nDimostrazione: P(A \\cap B^c) = P(A) - P(A \\cap B) = \\\\ P(A) - P(A)P(B) = \\\\ P(A)(1 - P(B)) = \\\\ P(A)P(B^c).\n\nEsempio con i Dadi\n\n\\Omega è l’insieme delle coppie (i, j) con i, j \\in {1, 2, 3, 4, 5, 6}, quindi |\\Omega| = 36.\n\\mathcal{F} è la sigma algebra delle parti di \\Omega, e P è la misura uniforme su \\Omega.\nA = {(i, j) \\in \\Omega : i = 1} (il primo dado mostra 1).\nB = {(i, j) \\in \\Omega : j = 3} (il secondo dado mostra 3).\nP(A) = \\frac{6}{36} = \\frac{1}{6}, P(B) = \\frac{6}{36} = \\frac{1}{6}.\nA \\cap B = {(1, 3)}, quindi P(A \\cap B) = \\frac{1}{36}.\nP(A)P(B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36} = P(A \\cap B), quindi A e B sono indipendenti.\n\nIndipendenza di n Eventi\n\n\nGli eventi A_1, A_2, \\dots, A_n sono indipendenti se per ogni k tra 2 e n, e per ogni scelta di k indici distinti i_1, i_2, \\dots, i_k, si ha:\n\\qquad P(A_{i_1} \\cap A_{i_2} \\cap \\dots \\cap A_{i_k}) = P(A_{i_1})P(A_{i_2})\\dots P(A_{i_k})\n\n\nEsempio con n = 3\n\nSe n = 3, gli eventi A_1, A_2, A_3 sono indipendenti se:\n\nP(A_1 \\cap A_2 \\cap A_3) = P(A_1)P(A_2)P(A_3)\nP(A_1 \\cap A_2) = P(A_1)P(A_2)\nP(A_1 \\cap A_3) = P(A_1)P(A_3)\nP(A_2 \\cap A_3) = P(A_2)P(A_3)\n\n\n\nConseguenze dell’Indipendenza\n\nSe A_1, \\dots, A_n sono indipendenti, allora anche A_1, \\dots, A_k, A_{k+1}^c, \\dots, A_n^c sono indipendenti.\n\nIndipendenza di una Successione Numerabile di Eventi\n\nUna successione numerabile di eventi {A_n} è indipendente se ogni sua sottosuccessione finita è costituita da eventi indipendenti.\n\n\nIndipendenza tra eventi\nDefinizione intuitiva\nL’idea di base è che conoscere qualcosa su un evento B non cambia la valutazione di probabilità su un evento A.\nDefinizione formale\nDue eventi A e B, appartenenti allo spazio di probabilità (\\Omega, \\mathcal{F}, P), sono indipendenti se e solo se:\nP(A \\cap B) = P(A) \\cdot P(B)\nProbabilità condizionata\nRicordando la definizione di probabilità condizionata:\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\nSe A e B sono (stocasticamente) indipendenti, allora P(A|B) = P(A), ovvero conoscere B non altera la probabilità di A.\nErrore comune\nNon confondere l’indipendenza con l’intersezione vuota:\n\nA e B indipendenti non implica A \\cap B = \\emptyset\nL’indipendenza è una proprietà della misura di probabilità P, non degli eventi A e B. Gli eventi A e B sono indipendenti rispetto a P.\n\nProprietà importante\nSe A e B sono indipendenti, allora anche:\n\nA e B^c sono indipendenti\nA^c e B sono indipendenti\nA^c e B^c sono indipendenti\n\nDove B^c è il complementare di B. In altre parole, l’indipendenza è stabile rispetto al complementare.\nDimostrazione\n\nConsideriamo P(A \\cap B^c). Vogliamo dimostrare che P(A \\cap B^c) = P(A) \\cdot P(B^c).\nP(A \\cap B^c) = P(A) - P(A \\cap B)\nSiccome A e B sono indipendenti, P(A \\cap B) = P(A) \\cdot P(B). Quindi:\nP(A \\cap B^c) = P(A) - P(A) \\cdot P(B) = P(A) \\cdot (1 - P(B)) = P(A) \\cdot P(B^c)\nEsempio: Lancio di due dadi\nConsideriamo il lancio di due dadi.\n\n\\Omega = {(w_1, w_2) : w_1, w_2 \\in {1, 2, 3, 4, 5, 6}}\n|\\Omega| = 36\nAssumiamo che la probabilità sia uniforme, quindi P({\\omega}) = \\frac{1}{36} per ogni \\omega \\in \\Omega.\n\nDefiniamo gli eventi:\n\nA = {\\omega \\in \\Omega : \\text{il primo dado mostra la faccia 1}}\nB = {\\omega \\in \\Omega : \\text{il secondo dado mostra la faccia 3}}\n\nCalcoliamo le probabilità:\n\nP(A) = \\frac{6}{36} = \\frac{1}{6}\nP(B) = \\frac{6}{36} = \\frac{1}{6}\nA \\cap B = \\set{\\omega =(1, 3)}\nP(A \\cap B) = \\frac{1}{36}\n\nVerifichiamo l’indipendenza:\nP(A) \\cdot P(B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36} = P(A \\cap B)\nQuindi, A e B sono indipendenti.\nIndipendenza di N eventi\nGli eventi A_1, A_2, ..., A_n \\in \\mathcal{F} sono indipendenti se per ogni sottoinsieme di indici distinti I_1, I_2, ..., I_k con 2 \\leq k \\leq n, vale:\nP(A_{I_1} \\cap A_{I_2} \\cap ... \\cap A_{I_k}) = P(A_{I_1}) \\cdot P(A_{I_2}) \\cdot ... \\cdot P(A_{I_k})\n\n\\mathbb{P} \\left( \\bigcap_{j=1}^{k} A_{ij} \\right) = \\prod_{j=1}^k \\mathbb{P}(A_{ij}) \\ \\ \\forall i,k \\leq n \\forall \\set{I_1, I_2, ..., I_k} \\subseteq \\set{1,\\cdots, n}\n\n\nIn altre parole, deve valere la fattorizzazione per ogni possibile combinazione di eventi.\nEsempio con N=3\nSe n = 3, allora A_1, A_2, A_3 sono indipendenti se valgono contemporaneamente le seguenti:\n\nP(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\cdot P(A_2) \\cdot P(A_3)\nP(A_1 \\cap A_2) = P(A_1) \\cdot P(A_2)\nP(A_1 \\cap A_3) = P(A_1) \\cdot P(A_3)\nP(A_2 \\cap A_3) = P(A_2) \\cdot P(A_3)\n\nNon è sufficiente che valga solo la prima condizione.\nConseguenze dell’indipendenza\nSe A_1, ..., A_n sono indipendenti, allora anche:\n\nA_1, ..., A_k, A_{k+1}^c, ..., A_n^c sono indipendenti (posso complementare qualsiasi sottoinsieme di eventi)\nSe prendo un sottoinsieme degli eventi, questi sono ancora indipendenti. Per esempio, A_1, A_2 sono indipendenti, A_1, A_3 sono indipendenti, ecc..\nSe A_1^c, A_2, A_3 sono indipendenti, allora A_1, A_2, A_3 sono indipendenti.\n\nIndipendenza di una successione numerabile di eventi\nUna successione numerabile di eventi (A_n)_{n \\in \\mathbb{N}} è indipendente se per ogni m \\in \\mathbb{N}, i primi m eventi sono indipendenti.\n\n\\text{Sono indipendenti se } \\\\ \\forall m \\ge 2 \\quad (A_1, \\dots, A_m) \\text{ sono indipendenti}\nIn altre parole, comunque si “arresti” la successione, si ottiene una famiglia finita di eventi indipendenti.\n\nReferences\n2025-02-26 16:08\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:  sbobine   probabilità\nprob-lez06\nEventi Bernoulli (Eventi Bernoulliani)\n\n\n\nQuesto modello descrive una situazione con n eventi, E_1, E_2, ..., E_n, che sono indipendenti. Ogni evento E_i ha una probabilità associata di verificarsi.\n\nriscrivi\n\nIpotesi\n\nGli eventi E_1, E_2, ..., E_n sono indipendenti.\nLa probabilità di ogni singolo evento E_i è un numero p_i compreso tra 0 e 1: 0 \\le p_i \\le 1.\n\n\nriscrivi\n\nConvenzione di Scrittura\nPer semplificare la notazione, si introduce una convenzione:\n\nE_i^{(e_i)} dove e_i può essere 0 o 1.\n\nSe e_i = 1, allora E_i^{(e_i)} = E_i (l’evento si verifica).\nSe e_i = 0, allora E_i^{(e_i)} = E_i^c (l’evento non si verifica, si verifica il suo complementare).\n\n\n\n\nProbabilità dell’Intersezione\n\n\n\nConsiderando un vettore e = (e_1, e_2, ..., e_n) \\subseteq \\set{0,1}^n , si calcola la probabilità dell’intersezione degli eventi corrispondenti:\nP(\\bigcap_{i=1}^{n} E_i^{(e_i)})\nPoiché gli eventi sono indipendenti, questa probabilità può essere espressa come il prodotto delle probabilità dei singoli eventi o dei loro complementari:\nP(\\bigcap_{i=1}^{n} E_i^{(e_i)}) = \\prod_{i=1}^{n} P(E_i^{(e_i)})\nDove:\nP(E_i^{(e_i)}) = \\begin{cases} p_i, &amp; \\text{se } e_i = 1 \\\\ 1 - p_i, &amp; \\text{se } e_i = 0 \\end{cases}\nEvento A_k\nSi definisce l’evento A_k come l’unione di tutte le intersezioni possibili tali che esattamente k eventi si verifichino:\nA_k = \\bigcup_{\\begin{cases}\\textbf{e} \\in {0,1}^n :\\\\ \\sum_{i=1}^{n} e_i = k\\end{cases}} (\\bigcap_{i=1}^{n} E_i^{(e_i)})\nQuesto significa che A_k è l’evento in cui esattamente k degli n eventi E_i si verificano.\nCalcolo della Probabilità di A_k\nLa probabilità di A_k è la somma delle probabilità di tutte le intersezioni disgiunte che la compongono:\nP(A_k) = \\sum_{\\textbf{e} \\in {0,1}^n : \\sum_{i=1}^{n} e_i = k} P(\\bigcap_{i=1}^{n} E_i^{(e_i)})\nSostituendo con la formula dell’indipendenza:\nP(A_k) = \\sum_{\\textbf{e} \\in {0,1}^n : \\sum_{i=1}^{n} e_i = k} \\prod_{i=1}^{n} P(E_i^{(e_i)})\nUlteriore Semplificazione: Eventi Identicamente Distribuibili (i.i.d.)\n\n\nSe, oltre all’indipendenza, tutti gli eventi hanno la stessa probabilità p di verificarsi (cioè p_i = p per ogni i), allora l’espressione si semplifica ulteriormente. In questo caso, si parla di eventi bernoulliani.\n\nP(A_k) = \\binom{n}{k} p^k (1-p)^{n-k}\nDove \\binom{n}{k} è il coefficiente binomiale, che rappresenta il numero di modi di scegliere k eventi tra n.\nEsempio\nConsideriamo il lancio di n monete, dove ogni moneta ha probabilità p di dare testa. Gli esiti dei lanci sono indipendenti. Qual è la probabilità di osservare esattamente k teste? La risposta è data dalla distribuzione binomiale:\nP(A_k) = \\binom{n}{k} p^k (1-p)^{n-k}\nCostruzione di Eventi Bernoulli\n\n\nÈ possibile costruire uno spazio di probabilità in cui gli eventi E_i sono bernoulliani. Si può prendere \\Omega = {0, 1}^n, con la \\sigma-algebra delle parti e definire una misura di probabilità P tale che:\n\nP(\\omega) = \\prod_{i=1}^{n} p_i^{\\omega_i} (1 - p_i)^{(1 - \\omega_i)}\nDove \\omega = (\\omega_1, ..., \\omega_n) è un elemento di \\Omega.\nVerificare che \\sum_{\\omega \\in \\Omega} P(\\omega) = 1 e che gli eventi E_i = {\\omega \\in \\Omega : \\omega_i = 1} sono bernoulliani con probabilità p_i.\n\nIndipendenza Condizionale\n\n\n\nDefinizione A2:\n\n\n\nDati tre eventi E_1, E_2 e H appartenenti a una \\sigma-algebra \\mathcal{F}, E_1 e E_2 sono condizionatamente indipendenti dato H se:\nP(E_1 \\cap E_2 | H) = P(E_1 | H) \\cdot P(E_2 | H)\nIl professore sottolinea che questa definizione non implica che P(E_1 \\cap E_2) = P(E_1) \\cdot P(E_2), ma riguarda le probabilità condizionali.\nMisura di Probabilità Condizionale\nSe si definisce una funzione che associa a un insieme la probabilità P(E | H), questa è una misura di probabilità.\nDefinizione Equivalente di Indipendenza Condizionale\nUn modo equivalente per definire l’indipendenza condizionale è considerare che E_1 e E_2 sono indipendenti rispetto alla misura condizionale dato H. In altre parole, sono indipendenti rispetto alla misura P(\\cdot | H).\nGeneralizzazione a n Eventi\nLa definizione si estende a n eventi E_1, E_2, ..., E_n. Questi eventi sono indipendenti dato H se sono indipendenti rispetto a P(\\cdot | H).\nPer esempio, per tre eventi E_1, E_2, E_3, si deve verificare che:\n\nP(E_1 \\cap E_2 \\cap E_3 | H) = P(E_1 | H) \\cdot P(E_2 | H) \\cdot P(E_3 | H)\nP(E_1 \\cap E_2 | H) = P(E_1 | H) \\cdot P(E_2 | H)\nP(E_1 \\cap E_3 | H) = P(E_1 | H) \\cdot P(E_3 | H)\nP(E_2 \\cap E_3 | H) = P(E_2 | H) \\cdot P(E_3 | H)\n\nIn generale, la definizione di indipendenza viene riscritta sostituendo P con P(\\cdot | H) ovunque.\nImportante\nIl fatto che E_1 e E_2 siano condizionatamente indipendenti dato H non implica che E_1 e E_2 siano indipendenti.\nIl professore menziona che durante le esercitazioni verranno forniti esempi per chiarire ulteriormente questo concetto e illustrare situazioni in cui l’indipendenza condizionale emerge naturalmente.\n\nVariabili Aleatorie: Introduzione e Definizioni Preliminari\n\n\n\n\nL’argomento delle variabili aleatorie è introdotto come un punto cruciale nello studio della probabilità. Prima di arrivare alla definizione formale di variabile aleatoria, vengono presentati alcuni concetti preliminari fondamentali.\nSpazi di Punti e Sigma Algebre\nSi considerano due spazi, \\Omega e X, che rappresentano spazi di punti generici. Ad esempio:\n\n\\Omega = {1, 2, 3, 4, 5, 6} e X = {0, 1}.\n\\Omega = [0,1] X = \\mathbb{R}^d.\n\nA ciascuno di questi spazi viene assegnata una sigma algebra. Ad esempio, si possono usare:\n\nLa sigma algebra delle parti.\nI Boreliani di $.\nI Boreliani di \\mathbb{R}^d.\n\nEsempio Motivazionale: Lancio di un Dado\nPer chiarire meglio, si considera un esempio concreto: modellizzare l’esperimento del lancio di un dado e osservare se il risultato è pari o dispari.\n\nSpazio di partenza (\\Omega): Rappresenta i possibili esiti del lancio del dado, \\Omega = {1, 2, 3, 4, 5, 6}.\nSpazio di arrivo (X): Indica se il numero uscito è pari o dispari, X = \\set{0, 1}, dove 0 rappresenta “dispari” e 1 rappresenta “pari”.\nFunzione x: Mappa ogni esito del dado al valore corrispondente in X. In questo caso:\n\nx(\\omega) = 0 se \\omega \\in {1, 3, 5}.\nx(\\omega) = 1 se \\omega \\in {2, 4, 6}.\n\n\n\nL’obiettivo è quello di poter rispondere a domande del tipo “Qual è la probabilità che esca un numero pari?“.\nFunzioni Misurabili\n\nNon tutte le funzioni sono adatte per lavorare con probabilità. È necessario restringere l’attenzione a funzioni misurabili.\nDefinizione: Una funzione x \\colon \\Omega \\to X è detta misurabile se x^{-1}(A) \\in \\mathcal{F} per ogni A \\in \\Sigma_X, dove \\mathcal{F} è la sigma algebra su \\Omega e \\Sigma_X è la sigma algebra su X. In altre parole, la controimmagine di ogni insieme misurabile in X deve essere un insieme misurabile in \\Omega.\n\nx^{-1}(A) = \\set{\\omega \\in \\Omega : x(\\omega) \\in A} è la controimmagine di A.\n\nEsempio: Nell’esempio del dado, se A = {1} (cioè l’evento “esce pari”), allora x^{-1}(A) = {2, 4, 6}. Per poter calcolare la probabilità di questo evento, è necessario che {2, 4, 6} sia un insieme misurabile in \\Omega.\nVariabili Aleatorie\nDefinizione: Una variabile aleatoria è una funzione misurabile x \\colon \\Omega \\to X dove (\\Omega, \\mathcal{F}, P) è uno spazio di probabilità. Questo significa che, oltre agli spazi \\Omega e X e alle rispettive sigma algebre, è definita anche una misura di probabilità P su \\Omega.\n\nNumero aleatorio: Variabile aleatoria a valori reali, X = \\mathbb{R}.\nVettore aleatorio: Variabile aleatoria a valori in \\mathbb{R}^d.\n\nImportanza della Misurabilità: La misurabilità garantisce che abbia senso calcolare la probabilità di eventi del tipo {x \\in A}, dove A è un insieme misurabile in X. In altre parole, l’evento {\\omega \\in \\Omega : x(\\omega) \\in A} deve appartenere alla sigma algebra \\mathcal{F} per poter calcolarne la probabilità.\nP(x \\in A) = P({\\omega \\in \\Omega : x(\\omega) \\in A}) = P(x^{-1}(A))\nEsempio: Riprendendo l’esempio del dado, la probabilità di ottenere un numero pari è:\nP(x = 1) = P({\\omega \\in \\Omega : x(\\omega) = 1}) = P({2, 4, 6}) = \\frac{1}{2}\nProprietà delle Funzioni Misurabili\nPer manipolare le variabili aleatorie, è utile conoscere alcune proprietà fondamentali delle funzioni misurabili.\nLemma Fondamentale\nEnunciato: Sia x \\colon \\Omega \\to X una funzione, e sia \\mathcal{C} una famiglia di sottoinsiemi di X tale che \\sigma(\\mathcal{C}) = \\Sigma_X, dove \\sigma(\\mathcal{C}) è la sigma algebra generata da \\mathcal{C}. Allora, x è misurabile se e solo se x^{-1}(C) \\in \\mathcal{F} per ogni C \\in \\mathcal{C}.\nIn altre parole, per verificare che una funzione è misurabile, è sufficiente controllare che la controimmagine di ogni insieme in una famiglia che genera la sigma algebra di arrivo sia misurabile.\nDimostrazione: La dimostrazione di questo lemma coinvolge la definizione di una famiglia di insiemi \\mathcal{S} e la dimostrazione che \\mathcal{S} è una sigma algebra.\nCriteri di Misurabilità\n\n\nFunzioni a valori reali: Sia x \\colon \\Omega \\to \\mathbb{R}. Allora x è misurabile se e solo se x^{-1}((-\\infty, a]) \\in \\mathcal{F} per ogni a \\in \\mathbb{R}.\nQuesto criterio semplifica la verifica della misurabilità per funzioni a valori reali: basta controllare che la controimmagine di ogni semiretta sia misurabile.\n\n\nFunzioni vettoriali: Siano x_1, x_2 \\colon \\Omega \\to \\mathbb{R} misurabili. Allora il vettore (x_1, x_2) \\colon \\Omega \\to \\mathbb{R}^2 è misurabile.\nLa dimostrazione utilizza il lemma fondamentale e la proprietà che i rettangoli con basi misurabili generano la sigma algebra dei Boreliani in \\mathbb{R}^2.\n\n\nComposizione di funzioni misurabili: Siano x_1 \\colon \\Omega_1 \\to \\Omega_2 e x_2 \\colon \\Omega_2 \\to X funzioni misurabili. Allora la composizione x_2 \\circ x_1 \\colon \\Omega_1 \\to X è misurabile.\n\n\nFunzioni continue: Se h \\colon \\mathbb{R}^n \\to \\mathbb{R} è una funzione continua, allora h è misurabile rispetto ai Boreliani. La dimostrazione di questa proprietà richiede un richiamo sulle funzioni continue.\n\n\nConseguenze Importanti\nSiano x_1, x_2 \\colon \\Omega \\to \\mathbb{R} funzioni misurabili. Allora:\n\nx_1 + x_2 è misurabile.\nx_1 - x_2 è misurabile.\nx_1 \\cdot x_2 è misurabile.\n\\max{x_1, 0} (parte positiva di x_1) è misurabile.\n-\\min{x_1, 0} (parte negativa di x_1) è misurabile.\nSe f \\colon \\mathbb{R}^2 \\to \\mathbb{R} è continua, allora f(x_1, x_2) è misurabile.\n\nQueste proprietà permettono di costruire nuove funzioni misurabili a partire da funzioni misurabili note, utilizzando operazioni algebriche e composizioni con funzioni continue.\n\nEcco una spiegazione dettagliata sulle funzioni misurabili e variabili aleatorie, basata sulle lezioni del professore, con particolare attenzione ai passaggi matematici, esempi ed esercizi.\nFunzioni Misurabili e Variabili Aleatorie\n\n\n\n\nSpazi di Misura\nSi considerano due spazi, \\Omega e X, dove \\Omega rappresenta uno spazio di punti e X un altro spazio di punti. Ad esempio:\n\n\\Omega = {1, 2, 3, 4, 5, 6} e X = {0, 1}\n\\Omega = \\mathbb{R} e X = \\mathbb{R}^d\n\\Omega = e X = \\mathbb{R}^d\n\nAd ognuno di questi spazi si associa una \\sigma-algebra. Per esempio:\n\nIn \\Omega, la \\sigma-algebra delle parti \\mathcal{P}(\\Omega)\nIn X, la \\sigma-algebra delle parti \\mathcal{P}(X)\nIn , i Boreliani di \nIn \\mathbb{R}^d, i Boreliani di \\mathbb{R}^d\n\nDefinizione di Funzione Misurabile\nUna funzione \\xi: \\Omega \\rightarrow X si dice misurabile se:\n\\xi^{-1}(A) \\in \\mathcal{F} \\quad \\forall A \\in \\Sigma_X\ndove \\Sigma_X è la \\sigma-algebra su X e \\mathcal{F} è la \\sigma-algebra su \\Omega. In altre parole, la controimmagine di ogni insieme misurabile in X è un insieme misurabile in \\Omega.\nEsempio Motivazionale: Lancio di un Dado\nSi vuole modellizzare l’esperimento del lancio di un dado e osservare se il risultato è pari o dispari.\n\n\\Omega = {1, 2, 3, 4, 5, 6} rappresenta l’esito del lancio del dado\nX = {0, 1} rappresenta “dispari” (0) o “pari” (1)\n\nLa funzione \\xi: \\Omega \\rightarrow X è definita come:\n\n\\xi(\\omega) = 0 se \\omega \\in {1, 3, 5}\n\\xi(\\omega) = 1 se \\omega \\in {2, 4, 6}\n\nProbabilità di un Evento\nPer un probabilista, è fondamentale che, data una funzione, si possa propagare l’informazione sulla probabilità. Nell’esempio del dado, si vuole sapere qual è la probabilità che esca un numero pari.\nDefinizione di Variabile Aleatoria\nUna variabile aleatoria è una funzione misurabile da uno spazio di probabilità (\\Omega, \\mathcal{F}, P) a uno spazio misurabile (X, \\Sigma_X). Quindi, oltre alla misurabilità, si aggiunge la presenza di una misura di probabilità P su \\Omega.\nTipi di Variabili Aleatorie\n\nNumero aleatorio: Variabile aleatoria a valori reali, \\xi: \\Omega \\rightarrow \\mathbb{R}, dove \\mathbb{R} è dotato dei Boreliani.\nVettore aleatorio: Variabile aleatoria a valori in \\mathbb{R}^d, \\xi: \\Omega \\rightarrow \\mathbb{R}^d, dove \\mathbb{R}^d è dotato dei Boreliani.\n\nMisurabilità e Controimmagine\nSe \\xi è una variabile aleatoria, allora ha senso chiedersi qual è la probabilità che \\xi(\\omega) appartenga ad A, dove A è un insieme misurabile in X. Formalmente:\nP(\\xi \\in A) = P({\\omega \\in \\Omega : \\xi(\\omega) \\in A}) = P(\\xi^{-1}(A))\nÈ cruciale che \\xi^{-1}(A) sia un evento appartenente alla \\sigma-algebra \\mathcal{F} su \\Omega, affinché si possa calcolare la sua probabilità.\nEsempio: Probabilità di Pari nel Lancio del Dado\nLa probabilità di ottenere un numero pari è:\nP(\\xi = 1) = P({\\omega \\in \\Omega : \\xi(\\omega) = 1}) = P({2, 4, 6})\nProprietà delle Funzioni Misurabili\nFunzioni tra Spazi\nSi definisce una funzione nel senso matematico più generale, cioè una corrispondenza che associa ad ogni punto di \\Omega un punto in X. È importante notare che queste funzioni non sono necessariamente da \\mathbb{R} in \\mathbb{R} o da \\mathbb{R}^d in \\mathbb{R}, ma possono essere tra insiemi più generali.\nLemma Fondamentale\nSia \\xi: \\Omega \\rightarrow X una funzione, e sia \\mathcal{C} una famiglia di sottoinsiemi di X tale che \\sigma(\\mathcal{C}) = \\Sigma_X (cioè, \\mathcal{C} genera la \\sigma-algebra su X). Allora \\xi è misurabile se e solo se:\n\\xi^{-1}(C) \\in \\mathcal{F} \\quad \\forall C \\in \\mathcal{C}\nIn altre parole, per verificare che una funzione è misurabile, è sufficiente controllare che la controimmagine degli elementi di una famiglia che genera la \\sigma-algebra d’arrivo siano misurabili.\nProprietà Utili delle Controimmagini\nSia f: E \\rightarrow F una funzione. Allora:\n\nf^{-1}(\\emptyset) = \\emptyset\nf^{-1}(F) = E\nf^{-1}(\\bigcup_{i} V_i) = \\bigcup_{i} f^{-1}(V_i), dove V_i \\subseteq F\nf^{-1}(A^c) = (f^{-1}(A))^c\n\nConseguenze del Lemma\n\n\nFunzioni a valori reali: Una funzione \\xi: \\Omega \\rightarrow \\mathbb{R} è misurabile (rispetto alla \\sigma-algebra \\mathcal{F} su \\Omega e ai Boreliani \\mathcal{B}(\\mathbb{R}) su \\mathbb{R}) se e solo se:\n\\xi^{-1}((-\\infty, x]) \\in \\mathcal{F} \\quad \\forall x \\in \\mathbb{R}\nBasta quindi controllare che la controimmagine delle semirette sia misurabile.\n\n\nFunzioni vettoriali: Siano \\xi_1, \\xi_2: \\Omega \\rightarrow \\mathbb{R} due funzioni misurabili. Allora il vettore (\\xi_1, \\xi_2): \\Omega \\rightarrow \\mathbb{R}^2 è misurabile (rispetto alla \\sigma-algebra \\mathcal{F} su \\Omega e ai Boreliani \\mathcal{B}(\\mathbb{R}^2) su \\mathbb{R}^2).\nLa dimostrazione utilizza il lemma e il fatto che i rettangoli con basi misurabili generano i Boreliani di \\mathbb{R}^2. La controimmagine di un rettangolo A_1 \\times A_2 è:\n(\\xi_1, \\xi_2)^{-1}(A_1 \\times A_2) = \\xi_1^{-1}(A_1) \\cap \\xi_2^{-1}(A_2)\nPoiché \\xi_1 e \\xi_2 sono misurabili, \\xi_1^{-1}(A_1) \\in \\mathcal{F} e \\xi_2^{-1}(A_2) \\in \\mathcal{F}, quindi (\\xi_1, \\xi_2)^{-1}(A_1 \\times A_2) \\in \\mathcal{F}.\n\n\nComposizione di funzioni misurabili: Siano \\xi_1: (\\Omega_1, \\mathcal{F}_1) \\rightarrow (\\Omega_2, \\mathcal{F}_2) e \\xi_2: (\\Omega_2, \\mathcal{F}_2) \\rightarrow (X, \\Sigma_X) funzioni misurabili. Allora la funzione composta \\xi_2 \\circ \\xi_1: \\Omega_1 \\rightarrow X, definita come (\\xi_2 \\circ \\xi_1)(\\omega) = \\xi_2(\\xi_1(\\omega)), è misurabile (rispetto a \\mathcal{F}_1 e \\Sigma_X).\n\n\nFunzioni Continue e Misurabilità\nSe h: \\mathbb{R}^n \\rightarrow \\mathbb{R} è una funzione continua, allora h è misurabile (rispetto ai Boreliani).\nOperazioni con Funzioni Misurabili\nSiano \\xi_1, \\xi_2: \\Omega \\rightarrow \\mathbb{R} funzioni misurabili. Allora le seguenti funzioni sono misurabili:\n\n\\xi_1 + \\xi_2\n\\xi_1 - \\xi_2\n\\xi_1 \\cdot \\xi_2\n\\xi^+ = \\max{\\xi, 0} (parte positiva di \\xi)\n\\xi^- = -\\min{\\xi, 0} (parte negativa di \\xi)\n\nIn generale, se \\psi: \\mathbb{R}^2 \\rightarrow \\mathbb{R} è una funzione continua, allora \\psi(\\xi_1, \\xi_2) è misurabile.\nReferences\n2025-03-02 21:55\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine   probabilità\nChiarimenti Preliminari\nIl professore inizia rispondendo ad alcune domande degli studenti per chiarire concetti non del tutto chiari dalla lezione precedente.\nEsempio di eventi Bernoulliani\nCostruzione di uno spazio con eventi Bernoulliani: L’esempio riguarda la costruzione di uno spazio in cui ci sono eventi bernoulliani. Lo spazio \\Omega è definito come le successioni di 0 e 1 di lunghezza n. I p_i sono numeri compresi tra 0 e 1, con i che va da 1 a n. Non è necessario che la loro somma faccia 1.\nDefinizione della misura di probabilità: L’esercizio consiste nel definire una misura di probabilità P su \\Omega. Dato un \\omega \\in \\Omega del tipo \\omega = (\\omega_1, \\omega_2, ..., \\omega_n), la probabilità di questo evento particolare (il singoletto) è definita come: P(\\set{\\omega})= \\prod_{i=1}^{n} p_i^{\\omega_i} (1 - p_i)^{1 - \\omega_i} L’obiettivo è dimostrare che tutti questi numeri sono maggiori o uguali a 0 e che la loro somma su tutti gli \\omega è uguale a 1.\nEsempio con n=2: Per n = 2, bisogna verificare che: \\sum_{\\omega \\in \\set{0,1}^2} \\prod_{i=1}^{2} p_i^{\\omega_i} (1 - p_i)^{1 - \\omega_i} = 1 Questo significa controllare se la somma su \\omega_1 e \\omega_2 appartenenti a {0, 1} di p_1^{\\omega_1} (1 - p_1)^{1 - \\omega_1} \\cdot p_2^{\\omega_2} (1 - p_2)^{1 - \\omega_2} fa 1. Questa somma può essere scritta come il prodotto di somme: \\sum_{\\omega_1 \\in \\set{0,1}} p_1^{\\omega_1} (1 - p_1)^{1 - \\omega_1} \\cdot \\sum_{\\omega_2 \\in \\set{0,1}} p_2^{\\omega_2} (1 - p_2)^{1 - \\omega_2} Ogni blocco della somma fa 1, quindi il risultato è 1 \\cdot 1 = 1.\n\nAttenzione alle notazioni: Non confondere P_i con P(\\omega_i). In questo caso, P_i si riferisce a un parametro per definire la probabilità, non alla probabilità di \\omega stesso. In un teorema precedente, quando si aveva uno spazio numerabile, si assegnavano direttamente le probabilità P_i agli elementi \\omega_i.\n\nFunzioni Misurabili\nIl professore spiega che la misurabilità è una proprietà che dipende non solo dalla funzione ma anche dalle sigma algebre sugli spazi di partenza e di arrivo.\n\nDefinizione: Una funzione \\xi: \\Omega \\rightarrow X è misurabile rispetto alle sigma algebre \\mathcal{F} su \\Omega e \\xi su X se per ogni A \\in \\xi, la controimmagine X^{-1}(A) appartiene a \\mathcal{F}.\nEsempio concreto: Consideriamo uno spazio di partenza \\Omega = \\set{1, 2, 3} e uno spazio di arrivo X = \\set{1, 2, 3}. Definiamo una funzione f(\\omega) = \\omega, cioè f(1) = 1, f(2) = 2, f(3) = 3.\n\n\n\nSe \\mathcal{F} = \\mathcal{P}(\\Omega) (l’algebra delle parti di \\Omega) e \\mathcal{X} = \\mathcal{P}(X), allora f è misurabile.\n\n\nSe \\tilde{\\mathcal{F}} = \\sigma({1, 2}) (la sigma algebra generata dall’insieme {1, 2}) e \\mathcal{X} = \\mathcal{P}(X), allora \\xi non è \\tilde{\\mathcal{F}}/\\mathcal{X} misurabile.\n\nLa sigma algebra \\sigma({1, 2}) è composta da \\set{\\emptyset, {1, 2}, {3}, \\Omega}.\nConsideriamo l’insieme {1} \\in \\xi. La sua controimmagine è f^{-1}({1}) = {1}, che non appartiene a \\mathcal{F}.\n\n\n\n\nLa spiegazione sulla continuità nei sources verte su due aspetti principali:\n\nDefinizione di continuità\nLegame tra continuità e misurabilità\n\nDefinizione di Continuità\nLa fonte presenta due definizioni di continuità e si focalizza su quella che è più utile per dimostrare la misurabilità:\n\nContinuità per successioni: Una funzione H: \\mathbb{R}^D \\rightarrow \\mathbb{R} è continua per successioni se, per ogni x \\in \\mathbb{R}^D e per ogni successione x_n in \\mathbb{R}^D convergente a x, allora H(x_n) converge a H(x).\nContinuità tramite controimmagini di aperti: Una funzione H: \\mathbb{R}^D \\rightarrow \\mathbb{R} è continua se per ogni aperto A di \\mathbb{R}, la controimmagine H^{-1}(A) è un aperto in \\mathbb{R}^D.\n\nIl professore indica di non usare la definizione di continuità per successioni, ma quella tramite controimmagini di aperti, in quanto più utile ai fini della dimostrazione della misurabilità.\n\nLegame tra Continuità e Misurabilità\nIl punto chiave è che se una funzione è continua, allora è anche misurabile rispetto alle sigma algebre dei Boreliani. Più precisamente, se H: \\mathbb{R}^D \\rightarrow \\mathbb{R} è continua, allora è Borel-misurabile . Questo significa che è misurabile rispetto alla sigma algebra dei Boreliani su \\mathbb{R}^D e alla sigma algebra dei Boreliani su \\mathbb{R}.\nDimostrazione\nLa dimostrazione utilizza un lemma che semplifica la verifica della misurabilità. In particolare, si usa il lemma che afferma che se la sigma algebra generata da una classe C è uguale alla sigma algebra di arrivo, basta verificare che la controimmagine di ogni elemento di C appartiene alla sigma algebra di partenza.\n\nI passaggi principali sono:\n\nSi sceglie C come la classe degli aperti di \\mathbb{R}. La sigma algebra generata da C è esattamente la sigma algebra dei Boreliani di \\mathbb{R}.\nSi sfrutta la continuità di H per dimostrare che per ogni aperto A \\in C, la controimmagine H^{-1}(A) è un aperto in \\mathbb{R}^D.\nSi conclude che H^{-1}(A) appartiene ai Boreliani di \\mathbb{R}^D, dato che gli aperti di \\mathbb{R}^D sono contenuti nei Boreliani di \\mathbb{R}^D.\nPer il lemma, si conclude che H è misurabile.\n\ndi, è Borel-misurabile.\nEsempio: Misurabilità della somma di due variabili aleatorie\nObiettivo: Dimostrare che se X_1 e X_2 sono variabili aleatorie misurabili, allora anche la loro somma X_1 + X_2 è misurabile.\n\nPassaggi:\n\n\nDefinizione delle variabili: Si considerano X_1 e X_2 definite su uno spazio \\Omega e a valori nei Boreliani di \\mathbb{R}. Entrambe sono misurabili rispetto alle sigma algebre appropriate.\n\n\nCreazione di una funzione vettoriale: Si crea una funzione \\xi che mappa \\omega \\in \\Omega in un vettore (X_1(\\omega), X_2(\\omega)) \\in \\mathbb{R}^2. Questa funzione è misurabile.\n\n\nDefinizione della funzione somma: Si definisce una funzione S: \\mathbb{R}^2 \\rightarrow \\mathbb{R} tale che S(x, y) = x + y. Questa funzione è la somma delle due componenti ed è continua.\n\n\nComposizione delle funzioni: Si considera la composizione S(X_1(\\omega), X_2(\\omega)) = X_1(\\omega) + X_2(\\omega). Questa è la somma delle due variabili aleatorie.\n\n\nApplicazione dei criteri di misurabilità:\n\nLe funzioni continue sono Borel-misurabili. Quindi S è misurabile.\nSe si hanno due variabili aleatorie misurabili, la funzione che le impacchetta in un vettore è congiuntamente misurabile.\nLa composizione di funzioni misurabili è misurabile.\n\n\n\nConclusione: Mettendo insieme questi tre ingredienti, si conclude che la somma X_1 + X_2 è misurabile.\n\n\nIn sintesi, l’esempio mostra come, sfruttando la continuità della somma e la misurabilità delle variabili aleatorie componenti, si possa dimostrare che la somma di due variabili aleatorie è ancora una variabile aleatoria misurabile.\nUtilità\nQuesto risultato è utile perché permette di stabilire facilmente la misurabilità di molte funzioni, semplicemente verificandone la continuità. Inoltre, la composizione di funzioni misurabili è misurabile. Perciò, combinando funzioni continue e variabili aleatorie misurabili, si possono costruire nuove variabili aleatorie misurabili.\nEcco la spiegazione del professore riguardo alle flashcard, integrata con i dettagli matematici, gli esempi e gli esercizi, formattata per chiarezza e leggibilità:\nFunzione indicatrice\nConsideriamo uno spazio \\Omega, \\mathcal{F} , considero A \\in \\mathcal{F} e introduciamo la seguente funzione:\n\n\nAd ogni \\omega \\in \\Omega associamo:\n\n0 se \\omega \\notin A\n1 se \\omega \\in A, dove A \\in \\mathcal{F}\n\n\n\nQuesta funzione è chiamata indicatrice e si indica con diverse notazioni come I, 1_A o I_A. In termini probabilistici, questa funzione indica se un evento si è verificato (1) o meno (0).\nMisurabilità della funzione indicatrice\nLa funzione indicatrice assume valori in [0, 1], quindi possiamo considerarla a valori reali.\nPer verificare se è misurabile, dobbiamo analizzare la controimmagine di un evento che sta in \\mathbb{R}.\nConsideriamo B \\subseteq \\mathbb{R}. Ci sono quattro casi possibili per la controimmagine di B:\n\nSe B contiene 1 ma non 0, allora I_A^{-1}(B) = A\nSe B contiene 0 ma non 1, allora I_A^{-1}(B) = A^c (complementare di A)\nSe B non contiene né 0 né 1, allora I_A^{-1}(B) = \\emptyset (insieme vuoto)\nSe B contiene sia 0 che 1, allora I_A^{-1}(B) = \\Omega\n\nPoiché A \\in \\mathcal{F}, anche A^c \\in \\mathcal{F}, e \\emptyset, \\Omega \\in \\mathcal{F} (perché \\mathcal{F} è una \\sigma-algebra). Quindi, la controimmagine di qualsiasi insieme B è un evento che sta in \\mathcal{F}, dimostrando che la funzione indicatrice è misurabile.\nLa più piccola \\sigma-algebra su \\Omega per cui questa funzione è misurabile è \\sigma(A), la \\sigma-algebra generata da A.\nFunzioni semplici\nPrendiamo A_1, \\dots, A_n \\in \\mathcal{F} e c_1, \\dots, c_M \\in \\mathbb{R} (numeri fissi). La funzione: \\omega \\rightarrow \\sum_{i=1}^M c_i I_{A_i}(\\omega) è misurabile. Se i c_i sono tutti uguali a 1, discende dal fatto che la somma di funzioni misurabili è misurabile. In generale, c_i \\cdot I_{A_i} è misurabile perché il prodotto di una costante per una funzione misurabile è misurabile (funzione continua di funzioni misurabili è misurabile), e quindi la somma di funzioni misurabili è misurabile.\nQueste funzioni si chiamano funzioni semplici e assumono solo un numero finito di valori su \\Omega, anche se \\Omega non è numerabile.\nLimite di funzioni misurabili\n\nSiano X_n : \\Omega \\to \\mathbb{R} funzioni misurabili. Se esiste il limite: X(\\omega) = \\lim_{n \\to \\infty} X_n(\\omega) \\quad \\forall \\omega \\in \\Omega allora X è misurabile rispetto alla \\sigma-algebra in gioco, \\mathcal{F}. In altre parole, se una funzione può essere approssimata puntualmente da una successione di funzioni misurabili, allora questa funzione è misurabile.\nSe il limite non esiste, si possono usare il limite superiore e il limite inferiore, ma è necessario conoscerne la definizione.\n\nProprietà delle Funzioni e Misurabilità\nIntroduzione alle Sigma Algebre e Spazi di Misura\nIl professore inizia sottolineando l’importanza di separare le sigma algebre dagli insiemi e di come si applichino le sigma algebre per parlare di misurabilità. Introduce la notazione standard:\n\nΩ (Omega): spazio di partenza\n\\mathcal{X}: spazio di arrivo\n\\mathcal{F} (F): sigma algebra su Omega\n\\xi (Xi): sigma algebra su X\nX: funzione da Ω a X\n\nViene ribadito che queste sono convenzioni di notazione e che la lettera \\xi è usata per sottolineare che tutto dipende dalla funzione ξ (xi), da omega, da \\mathcal{X} e dalle sigma algebre.\n\nMisura di Probabilità\nSuccessivamente, viene introdotta una misura di probabilità P sullo spazio Ω:\n\n(Ω, ℱ, P): spazio di probabilità\n\nQuesta notazione indica che \\xi è una funzione definita da Ω in X**, con ℱ su Ω, 𝒳 su \\chi e P su ℱ.\nVariabili Aleatorie\nSi introduce la notazione con la lettera X per indicare una funzione misurabile quando lo spazio di arrivo è ℝ.\n\nVariabili aleatorie: funzioni misurabili con spazio di arrivo in ℝ\nVettori aleatori: funzioni misurabili con spazio di arrivo in ℝ^D, con i boreliani di ℝ^D\n\n\nLa differenza fondamentale è che, parlando di funzioni misurabili, si hanno due spazi, una funzione e due sigma algebre. Invece, per le variabili aleatorie, si hanno due spazi, due sigma algebre e una misura di probabilità sullo spazio di partenza. Nel caso di variabili aleatorie a valori reali o vettori aleatori, lo spazio di arrivo è ℝ o ℝ^D, con le sigma algebre d’arrivo che sono i boreliani di ℝ o ℝ^D, e una misura di probabilità.\nEsempio del Dado\nViene ripreso l’esempio del dado per illustrare i concetti:\n\nΩ = {1, 2, 3, 4, 5, 6}\nX = {0, 1} (0 per dispari, 1 per pari)\nℱ = algebra delle parti di Ω\nP(ω) = 1/6 per ogni ω ∈ Ω\n\n\nLa variabile aleatoria X vale 0 se ω ∈ {1, 3, 5} e 1 se ω ∈ {2, 4, 6}.\n\nLa probabilità che esca pari è P(X = 1) = 1/2, e la probabilità che esca dispari è P(X = 0) = 1/2.\n\nQuesto esempio mostra come si possano dare valutazioni di probabilità a qualcosa che sta nello spazio di arrivo.\nLegge Immagine (o Distribuzione Indotta)\nDefinizione di Legge Immagine Dato uno spazio di probabilità (\\Omega, \\mathcal{F}, P) e una variabile aleatoria X : (\\Omega, \\mathcal{F}) \\to ({\\mathbb{R}}^D, \\mathcal{B}({\\mathbb{R}}^D),\nla legge immagine (o distribuzione immagine) di X, denotata come P_X,\nè una misura di probabilità definita su ({\\mathbb{R}}^D, \\mathcal{B}({\\mathbb{R}}^D) tale che P_X(A) = P(X^{-1}(A)) per ogni A \\in \\mathcal{B}({\\mathbb{R}}^D)&#039;.\nIn altre parole, la probabilità che la variabile aleatoria X assuma un valore in un insieme A è uguale alla probabilità che l’evento X^{-1}(A) si verifichi nello spazio di probabilità originale.\n\n\nLa notazione per la legge immagine è menzionata nella fonte “lezione”:\n\n\nData una variabile aleatoria X, la sua legge immagine è denotata come P_X.\n\n\nP_X(A) = P({\\omega \\in \\Omega : X(\\omega) \\in A}).\n\n\nEquivalentemente, si può scrivere P(X \\in A). Questo significa che la probabilità che X appartenga all’insieme A è la legge immagine di X applicata all’insieme A.\n\n\nFormalizzazione della Legge Immagine: La legge immagine P_X è definita come P_X(A) = P({\\omega \\in \\Omega : X(\\omega) \\in A}) per ogni A \\in \\mathcal{F}&#039;.\n\n\nSomma su insiemi disgiunti: Se A = \\bigcup_{n=1}^{\\infty} A_n, dove gli A_n sono insiemi disgiunti, allora P_X(A) = \\sum_{n=1}^{\\infty} P({\\omega : X(\\omega) \\in A_n}).\n\n\nMisura di Probabilità\n\nNon-negatività: P_X(A) \\geq 0 per ogni A.\nProbabilità dello spazio totale: P_X(\\mathbb{R}^D) = 1.\nAdditività completa: Per ogni successione di insiemi A_n incompatibili (cioè disgiunti), P_X(\\bigcup_{n=1}^{\\infty} A_n) = \\sum_{n=1}^{\\infty} P_X(A_n).\n\nEcco i passaggi della dimostrazione forniti in “lezione”:\n\nPositività: P_X(A) è una probabilità, quindi per definizione è maggiore o uguale a zero.\nProbabilità dello spazio totale: P_X(\\mathbb{R}^D) = 1 perché X assume valori in \\mathbb{R}^D. Ciò significa che la probabilità che X assuma un valore all’interno dello spazio totale è pari a 1.\nAdditività completa:\n\nP_X(\\bigcup_{n=1}^{\\infty} A_n) = P({\\omega : X(\\omega) \\in \\bigcup_{n=1}^{\\infty} A_n})\n= P(\\bigcup_{n=1}^{\\infty} \\set{\\omega : X(\\omega) \\in A_n})\n= \\sum_{n=1}^{\\infty} P(\\set{\\omega : X(\\omega) \\in A_n}) (perché gli A_n sono disgiunti)\n= \\sum_{n=1}^{\\infty} P_X(A_n)\n\n\n\nQuindi, P_X soddisfa tutti gli assiomi di una misura di probabilità.\nPassaggi della Dimostrazione\n\nPositività: P_X(A) è una probabilità, quindi è maggiore o uguale a zero.\nProbabilità dello spazio totale: P_X(ℝ^D) = 1 perché X assume valori in ℝ^D.\nAdditività completa:\n\nP_X(\\bigcup_{n=1}^{\\infty} A_n) = P({\\omega : X(\\omega) \\in \\bigcup_{n=1}^{\\infty} A_n})\n= P(\\bigcup_{n=1}^{\\infty} {\\omega : X(\\omega) \\in A_n})\n= \\sum_{n=1}^{\\infty} P({\\omega : X(\\omega) \\in A_n}) (perché gli A_n sono disgiunti)\n= \\sum_{n=1}^{\\infty} P_X(A_n)\n\n\n\nImportanza Concettuale\nsi sottolinea l’importanza fondamentale della legge immagine nella costruzione di modelli probabilistici. Spesso, nella pratica, si ha un modello probabilistico in mente, ma non si ha accesso diretto allo spazio di partenza \\Omega. Invece, si osserva l’esperimento nello spazio di arrivo, cioè nello spazio dei valori che la variabile aleatoria può assumere.\nLa legge immagine consente di trasportare la probabilità dallo spazio originale \\Omega allo spazio dei valori della variabile aleatoria, rendendo possibile lavorare direttamente con la distribuzione dei risultati osservabili.\nFunzioni di Ripartizione\naleatoria reale**. In questo caso, la variabile aleatoria X è una funzione misurabile da uno spazio di probabilità (\\Omega, \\mathcal{F}, P) all’insieme dei numeri reali (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}),P_x), dove P_x è la legge immagine su \\mathcal{B}(\\mathbb{R}) è la \\sigma-algebra dei Boreliani di \\mathbb{R}.\nDefinizione formale\nIl professore introduce la funzione di ripartizione, denotandola tipicamente con la lettera grande F, come una funzione da \\mathbb{R} a valori in [0,1] . Formalmente:\nF: \\mathbb{R} \\rightarrow [0,1]\nUna funzione di ripartizione deve soddisfare le seguenti proprietà:\n\n\nMonotona non decrescente: F è monotona non decrescente. Questo significa che se x_1 &lt; x_2, allora F(x_1) \\leq F(x_2).\n\n\nLimiti agli estremi:\n\n\\lim_{x \\to -\\infty} F(x) = 0\n\\lim_{x \\to +\\infty} F(x) = 1\n\n\n\nContinuità da destra: F è continua da destra. Questo significa che per ogni x_0 \\in \\mathbb{R}:\n\\lim_{x \\to x_0^+} F(x) = F(x_0)\novvero, per ogni x_0 \\in \\mathbb{R}, per ogni successione x_n \\to x_0 con x_n &gt; x_0, si ha \\lim_{n \\to \\infty} F(x_n) = F(x_0). Il professore sottolinea che, pur potendo avere dei punti di discontinuità, la funzione è continua da destra in ogni punto.\n\n\nLegame tra Misure di Probabilità e Funzioni di Ripartizione\nIl professore introduce un teorema fondamentale che collega le misure di probabilità sui Boreliani di \\mathbb{R} e le funzioni di ripartizione.\n\nTeorema:\n\n\nData una misura di probabilità P sui Boreliani di \\mathbb{R}, è possibile definire una funzione F_P(x) come:\nF_P(x) = P((-\\infty, x])\nQuesta funzione F_P(x) è una funzione di ripartizione nel senso definito in precedenza.\n\n\nViceversa, per ogni  funzione di ripartizione F(x), esiste una unica misura di probabilità P sui Boreliani di \\mathbb{R} tale che:\nP((-\\infty, x]) = F(x)\n\n\n\n\nQuesto teorema stabilisce una corrispondenza biunivoca tra le misure di probabilità sui Boreliani di \\mathbb{R} e le funzioni di ripartizione. In altre parole, ogni funzione di ripartizione definisce univocamente una misura di probabilità e viceversa.\nEsempi di Funzioni di Ripartizione\nIl professore presenta tre esempi specifici di funzioni di ripartizione per illustrare le proprietà sopra descritte:\n\n\nFunzione lineare a tratti:\n\nUna funzione definita come 0 fino a un certo punto, poi sale linearmente come una retta, e infine vale 1. Questa funzione è continua, quindi anche continua da destra, ed è monotona.\n\n\nFunzione esponenziale:\n\nF(x) = \\begin{cases} 0, &amp; \\text{se } x &lt; 0 \\\\ 1 - e^{-\\lambda x}, &amp; \\text{se } x \\geq 0 \\end{cases}\ndove \\lambda &gt; 0. Il professore osserva che questa funzione è continua (e quindi continua da destra) e i limiti agli estremi sono rispettati. Per x \\rightarrow -\\infty si ha che F(x) \\rightarrow 0. Per x \\rightarrow +\\infty si ha che F(x) \\rightarrow 1.\n\n\nFunzione a gradini:\n\nF(x) = \\begin{cases} 0, &amp; \\text{se } x &lt; 0 \\\\ 1/2, &amp; \\text{se } 0 \\leq x &lt; 2 \\ 1, &amp; \\text{se } x \\geq 2 \\end{cases}\nQuesta funzione è un esempio di funzione di ripartizione discontinua. È costante a tratti e ha dei salti in x=0 e x=2. Tuttavia, è continua da destra in ogni punto.\n\n\nEsercizio\nCalcolare la probabilità di intervalli dati gli esempi di funzioni di ripartizione.\nprob-lez07\nReferences\nAppunti Prob-Lez07.pdf\n2025-03-03 15:26\n_Status: flashcard_zero  riscritto_zero  revisione_zero\nTags:sbobine probabilità\nRipasso di Concetti Fondamentali: Sigma Algebra e Funzione di Ripartizione\nProprietà della Sigma Algebra: Unione e Intersezione\nIl professore ha inizialmente chiarito una proprietà fondamentale delle sigma algebre. Se si hanno una sequenza di insiemi A_1, A_2, ..., A_n che appartengono a una data sigma algebra, allora non solo la loro unione (\\bigcup_{i=1}^{n} A_i) appartiene alla sigma algebra, ma anche la loro intersezione (\\bigcap_{i=1}^{n} A_i) appartiene alla sigma algebra.\nQuesta seconda affermazione, relativa all’intersezione, non viene esplicitamente inclusa tra gli assiomi che definiscono una sigma algebra, ma è una conseguenza di tali assiomi. Per dimostrarlo, si può utilizzare il fatto che se un insieme B appartiene alla sigma algebra, allora anche il suo complementare B^c appartiene alla sigma algebra. Inoltre, l’unione di insiemi appartenenti alla sigma algebra è anch’essa un elemento della sigma algebra.\nLa dimostrazione si basa sull’applicazione delle leggi di De Morgan. Consideriamo l’intersezione di una sequenza di insiemi A_i appartenenti alla sigma algebra: \\bigcap_{i=1}^{n} A_i. Possiamo riscrivere questa intersezione come il complementare dell’unione dei complementari:\n\\bigcap_{i=1}^{n} A_i = (\\bigcup_{i=1}^{n} A_i^c)^c\nPoiché ogni A_i appartiene alla sigma algebra, anche il suo complementare A_i^c appartiene alla sigma algebra per definizione di sigma algebra. Di conseguenza, l’unione dei complementari \\bigcup_{i=1}^{n} A_i^c appartiene anch’essa alla sigma algebra. Infine, il complementare di questa unione, (\\bigcup_{i=1}^{n} A_i^c)^c, che è uguale all’intersezione originale, appartiene anch’esso alla sigma algebra. Il professore ha suggerito di svolgere questa dimostrazione come esercizio.\nRipasso di Calcolo Combinatorio nell’Esercitazione\nIl professore ha annunciato che l’esercitazione successiva avrebbe riguardato un ripasso di calcolo combinatorio e del suo utilizzo nei problemi elementari di conteggio legati alla probabilità discreta su insiemi finiti. Ha sottolineato l’importanza di queste esercitazioni, pur precisando che la parte combinatorica del corso sarebbe stata abbastanza minimale.\nFunzione di Ripartizione per Misure di Probabilità su \\mathbb{R}\nDefinizione e Collegamento con la Misura di Probabilità\nIl professore ha ripreso il concetto di funzione di ripartizione per descrivere le misure di probabilità sull’insieme dei numeri reali, \\mathbb{R}. Ha ricordato l’enunciato fondamentale stabilito nella lezione precedente:\n\n\nSe F è una funzione di ripartizione (nel senso definito precedentemente), allora esiste un’unica misura di probabilità P_F sui borelliani di \\mathbb{R} tale che per ogni x \\in \\mathbb{R}: P_F((-\\infty, x]) = F(x).\n\n\nViceversa, data una misura di probabilità P sui borelliani di \\mathbb{R}, la funzione F(x) = P((-\\infty, x]) è una funzione di ripartizione.\n\n\nProprietà della Funzione di Ripartizione: Dimostrazioni\nIl professore ha poi ripreso la dimostrazione di alcune proprietà fondamentali della funzione di ripartizione F(x) = P((-\\infty, x]), dove P è una misura di probabilità sui borelliani di \\mathbb{R}.\n1. Monotonia non decrescente:\nPer x \\le y, l’evento (-\\infty, x] è contenuto nell’evento (-\\infty, y]. Poiché la misura di probabilità P è monotona, si ha:\nP((-\\infty, x]) \\le P((-\\infty, y])\nDalla definizione di F(x), questo implica che F(x) \\le F(y) per x \\le y. Quindi, F è una funzione monotona non decrescente.\n2. Limite a -\\infty:\nConsideriamo la successione di eventi A_n = (-\\infty, -n] per n \\in \\mathbb{N}. Questa è una successione decrescente di insiemi, cioè A_{n+1} \\subseteq A_n per ogni n, e la sua intersezione è l’insieme vuoto: \\bigcap_{n=1}^{\\infty} A_n = \\emptyset.\nPer la proprietà di continuità delle misure di probabilità, abbiamo:\n\\lim_{n \\to \\infty} P(A_n) = P(\\bigcap_{n=1}^{\\infty} A_n) = P(\\emptyset) = 0\nPoiché P(A_n) = P((-\\infty, -n]) = F(-n), si ha:\n\\lim_{n \\to \\infty} F(-n) = 0\nGrazie alla monotonia di F, questo risultato si estende a qualunque successione x_n che tende a -\\infty, quindi:\n\\lim_{x \\to -\\infty} F(x) = 0.\n3. Limite a +\\infty:\nConsideriamo la successione di eventi B_n = (-\\infty, n] per n \\in \\mathbb{N}. Questa è una successione crescente di insiemi, cioè B_n \\subseteq B_{n+1} per ogni n, e la sua unione è l’insieme di tutti i numeri reali: \\bigcup_{n=1}^{\\infty} B_n = \\mathbb{R}.\nPer la proprietà di continuità delle misure di probabilità, abbiamo:\n\\lim_{n \\to \\infty} P(B_n) = P(\\bigcup_{n=1}^{\\infty} B_n) = P(\\mathbb{R}) = 1\nPoiché P(B_n) = P((-\\infty, n]) = F(n), si ha:\n\\lim_{n \\to \\infty} F(n) = 1\nAncora per la monotonia di F, questo risultato si estende a qualunque successione x_n che tende a +\\infty, quindi:\n\\lim_{x \\to +\\infty} F(x) = 1.\n4. Continuità da destra:\nConsideriamo un punto x \\in \\mathbb{R} e la successione di eventi C_n = (-\\infty, x + \\frac{1}{n}] per n \\in \\mathbb{N}. Questa è una successione decrescente di insiemi, cioè C_{n+1} \\subseteq C_n per ogni n, e la sua intersezione è l’insieme (-\\infty, x]: \\bigcap_{n=1}^{\\infty} C_n = (-\\infty, x].\nPer la proprietà di continuità delle misure di probabilità, abbiamo:\n\\lim_{n \\to \\infty} P(C_n) = P(\\bigcap_{n=1}^{\\infty} C_n) = P((-\\infty, x])\nPoiché P(C_n) = P((-\\infty, x + \\frac{1}{n}]) = F(x + \\frac{1}{n}) e P((-\\infty, x]) = F(x), si ha:\n\\lim_{n \\to \\infty} F(x + \\frac{1}{n}) = F(x)\nQuesto dimostra che F è continua da destra in ogni punto x \\in \\mathbb{R}.\nIl professore ha menzionato un’osservazione fatta da uno studente riguardo alla continuità da sinistra, spiegando che l’approccio con x - \\frac{1}{n} non converge in modo monotono all’insieme desiderato, il che impedisce di applicare direttamente la proprietà di continuità della misura.\nFunzione di Ripartizione di una Variabile Aleatoria\nData una variabile aleatoria reale X definita su uno spazio di probabilità (\\Omega, \\mathcal{F}, P), la funzione di ripartizione associata a X, indicata con F_X(x), è definita come la probabilità che la variabile aleatoria X assuma un valore minore o uguale a x:\nF_X(x) = P({ \\omega \\in \\Omega : X(\\omega) \\le x }) = P(X \\le x)\nIl professore ha osservato che questa probabilità può anche essere interpretata come la probabilità che la legge immagine P_X (definita sui borelliani di \\mathbb{R}) associ all’intervallo (-\\infty, x]:\nF_X(x) = P_X((-\\infty, x])\nSecondo la proposizione precedentemente dimostrata, F_X(x) è effettivamente una funzione di ripartizione (monotona non decrescente, con limiti 0 a -\\infty e 1 a +\\infty, e continua da destra). Questo stabilisce un legame fondamentale tra variabili aleatorie e funzioni di ripartizione: ogni variabile aleatoria reale è associata a una specifica funzione di ripartizione che ne descrive la distribuzione di probabilità.\nEstrazione di Informazioni dalla Funzione di Ripartizione\nIl professore ha mostrato come estrarre informazioni probabilistiche su una variabile aleatoria X, con funzione di ripartizione F_X(x), direttamente dalla funzione stessa.\n1. Probabilità che X sia strettamente maggiore di x:\nP(X &gt; x) = 1 - P(X \\le x) = 1 - F_X(x).\n2. Probabilità che X appartenga all’intervallo semiaperto (a, b]:\nP(a &lt; X \\le b) = P(X \\le b) - P(X \\le a) = F_X(b) - F_X(a).\nQuesta formula si ottiene considerando l’evento {X \\le b} come l’unione disgiunta di {X \\le a} e {a &lt; X \\le b} e utilizzando la proprietà di additività delle probabilità.\n3. Probabilità che X sia strettamente minore di x:\nP(X &lt; x) = \\lim_{y \\to x^-} F_X(y) = F_X(x^-).\nQuesta probabilità è data dal limite sinistro della funzione di ripartizione nel punto x. Per dimostrarlo, si considera una successione crescente x_n che converge a x da sinistra. Gli eventi {X \\le x_n} formano una successione crescente di insiemi la cui unione è {X &lt; x}. Per la continuità dal basso delle misure di probabilità, si ha P(X &lt; x) = \\lim_{n \\to \\infty} P(X \\le x_n) = \\lim_{n \\to \\infty} F_X(x_n) = F_X(x^-). Questo punto era lasciato come esercizio.\n4. Probabilità che X sia uguale a x:\nP(X = x) = P(X \\le x) - P(X &lt; x) = F_X(x) - F_X(x^-).\nLa probabilità che X assuma esattamente il valore x è data dalla discontinuità (o salto) della funzione di ripartizione nel punto x. Se F_X è continua in x, allora P(X = x) = 0. In particolare, se la funzione di ripartizione è continua ovunque, la probabilità che la variabile aleatoria assuma un valore specifico è sempre zero. Il professore ha sottolineato che questa è una proprietà importante, sebbene a volte controintuitiva, e che sarebbe stata ripresa in seguito.\nEsempi di Funzioni di Ripartizione e Calcolo di Probabilità\nIl professore ha ripreso alcuni esempi di funzioni di ripartizione per illustrare come calcolare le probabilità .\nPrimo Esempio:\nF_1(x) = \\begin{cases} 0 &amp; x &lt; 0 \\\\ x &amp; 0 \\le x \\le 1 \\\\ 1 &amp; x &gt; 1 \\end{cases}\nQuesta funzione di ripartizione è continua ovunque . Il professore ha chiesto qual è la probabilità che una variabile aleatoria X_1 con questa funzione di ripartizione sia uguale a 3, P(X_1 = 3) . Poiché la funzione è continua in x=3, il salto è zero:\nP(X_1 = 3) = F_1(3) - F_1(3^-) = 1 - 1 = 0 .\nSuccessivamente, ha chiesto la probabilità che X_1 sia minore o uguale a 3, P(X_1 \\le 3) . Dalla definizione della funzione di ripartizione:\nP(X_1 \\le 3) = F_1(3) = 1 .\nInfine, ha chiesto la probabilità che X_1 appartenga all’intervallo, P(0 \\le X_1 \\le 1) . Utilizzando la formula per l’intervallo semiaperto:\nP(0 &lt; X_1 \\le 1) = F_1(1) - F_1(0) = 1 - 0 = 1\nPoiché la funzione è continua in 0, P(X_1 = 0) = F_1(0) - F_1(0^-) = 0 - 0 = 0. Quindi,\nP(0 \\le X_1 \\le 1) = P(X_1 = 0) + P(0 &lt; X_1 \\le 1) = 0 + 1 = 1 .\nQuesto indica che la variabile aleatoria X_1 assume valori nell’intervallo  con probabilità 1 .\nSecondo Esempio:\nF_2(x) = \\begin{cases} 0 &amp; x &lt; 0 \\ 1/2 &amp; 0 \\le x &lt; 2 \\ 1 &amp; x \\ge 2 \\end{cases}\nQuesta funzione di ripartizione ha dei salti in x=0 e x=2 . Il professore ha chiesto qual è la probabilità che una variabile aleatoria X_2 con questa funzione di ripartizione sia uguale a 0, P(X_2 = 0) . Utilizzando la formula per la probabilità di un singolo punto:\nP(X_2 = 0) = F_2(0) - F_2(0^-) = \\frac{1}{2} - 0 = \\frac{1}{2} .\nLa probabilità è data dal salto della funzione nel punto x=0 .\n\nEcco la spiegazione del professore contenuta nel flashcard, presentata in maniera dettagliata e formattata come richiesto:\nFunzione di Ripartizione di una Variabile Aleatoria\nDefinizione e Proprietà Fondamentali\nIl professore introduce la funzione di ripartizione (o funzione cumulativa di distribuzione), definendola come un oggetto ben definito per qualunque variabile aleatoria. Non è detto che debba necessariamente essere continua né la funzione cumulata di qualche densità, e quindi non necessariamente scrivibile come un integrale.\nVerifica delle Proprietà: Prima di considerare una funzione come una funzione di ripartizione, è fondamentale controllarne le proprietà. Se una funzione soddisfa tali proprietà, allora descrive completamente la variabile aleatoria o la misura di probabilità indotta.\nProbabilità Puntuale e Discontinuità\nIn presenza di discontinuità nella funzione di ripartizione, possiamo calcolare la probabilità che la variabile aleatoria assuma un valore specifico.\nEsempio: Consideriamo una variabile aleatoria X_2 la cui funzione di ripartizione ha un salto in x=0. Dal disegno (non fornito, ma descritto a parole), la funzione di ripartizione valutata in 0 è 1/2, mentre il limite da sinistra è 0. Il salto in 0 misura quindi 1/2.\nLa probabilità che X_2 sia uguale a 0 è data dalla differenza tra il valore della funzione di ripartizione in 0 e il suo limite da sinistra: P(X_2 = 0) = F_{X_2}(0) - \\lim_{x \\to 0^-} F_{X_2}(x) = \\frac{1}{2} - 0 = \\frac{1}{2}.\nQuesto esempio illustra come le discontinuità nella funzione di ripartizione corrispondano a probabilità puntuali non nulle.\nProbabilità di un Intervallo in Termini di Funzione di Ripartizione\nIl professore introduce un esercizio per esprimere la probabilità che una variabile aleatoria appartenga a un intervallo in termini della sua funzione di ripartizione. Vengono menzionati sia l’intervallo aperto che l’intervallo chiuso.\nPer risolvere questo tipo di esercizio, si devono utilizzare le proprietà della funzione di ripartizione e la definizione di probabilità degli eventi, inclusa la continuità lungo successioni monotone di eventi.\nEsempio di Variabile Aleatoria Uniforme sull’Intervallo\nViene presentato un esempio di una variabile aleatoria X con **distribuzione uniforme sull’intervallo **. La sua funzione di ripartizione F_X(x) è definita come segue:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\ x &amp; \\text{se } 0 &lt; x &lt; 1 \\ 1 &amp; \\text{se } x \\ge 1 \\end{cases}\nPer questa variabile aleatoria, la probabilità che X appartenga a un intervallo [a, b] con 0 \\le a \\le b \\le 1 è data dalla lunghezza dell’intervallo: P(a \\le X \\le b) = F_X(b) - F_X(a) = b - a.\nIl professore sottolinea che in questo caso particolare, poiché la funzione di ripartizione è continua, la probabilità che X assuma un singolo valore è 0. Questo implica che per l’intervallo [a, b] all’interno di : P(a \\le X \\le b) = P(a &lt; X \\le b) = P(a \\le X &lt; b) = P(a &lt; X &lt; b) = b - a.\nImportante: Il professore avverte che se la funzione di ripartizione non è continua, è cruciale prestare attenzione all’uso di minore o uguale (\\le) e minore stretto (&lt;) negli intervalli, poiché ciò può fare la differenza nel calcolo della probabilità.\nMisura di Lebesgue: Viene osservato che la misura di probabilità associata alla variabile uniforme su  coincide con la misura di Lebesgue ristretta all’intervallo .\nEsercizio: Si chiede come dimostrare che la probabilità che X appartenga a un insieme boreliano A tale che la sua intersezione con  sia l’insieme vuoto (A \\cap = \\emptyset) è zero.\nSoluzione dell’Esercizio: Se A \\cap = \\emptyset, allora A è contenuto nel complementare di (0, 1), ovvero A \\subseteq (-\\infty, 0] \\cup [1, +\\infty). Quindi, la probabilità che X appartenga ad A è minore o uguale alla probabilità che X appartenga a (-\\infty, 0] \\cup [1, +\\infty).\nP(X \\in (-\\infty, 0] \\cup [1, +\\infty)) = P(X \\le 0) + P(X \\ge 1) = F_X(0) + (1 - F_X(1)).\nDalla definizione di F_X(x), abbiamo F_X(0) = 0 e F_X(1) = 1. Quindi: P(X \\in (-\\infty, 0] \\cup [1, +\\infty)) = 0 + (1 - 1) = 0.\nPoiché P(X \\in A) \\le 0 e la probabilità è non negativa, ne consegue che P(X \\in A) = 0.\nCostruzione di Nuove Variabili Aleatorie tramite Trasformazioni\nIl professore introduce l’idea di costruire una nuova variabile aleatoria applicando una trasformazione a una variabile aleatoria esistente. Questo è utile sia dal punto di vista modellistico che teorico.\nEsempio 2: Si parte da una variabile aleatoria X_1 distribuita uniformemente su (0, 1), denotato come X_1 \\sim U(0, 1). La sua funzione di ripartizione è F_{X_1}(x) = x per x \\in, 0 per x &lt; 0 e 1 per x &gt; 1 (anche se nel testo viene definita in modo leggermente diverso con \\le 0 e \\ge 1, l’essenza è la stessa per la continuità).\nSi definisce una nuova variabile aleatoria X_2 = -\\log(X_1).\nConsiderazioni sul Dominio del Logaritmo: Il logaritmo è definito solo per numeri positivi. Poiché X_1 è uniforme su (0, 1), assume valori positivi con probabilità 1. Più precisamente, P(X_1 \\in (0, 1)) = 1.\nProprietà di X_2: Se X_1(\\omega) \\in (0, 1), allora -\\log(X_1(\\omega)) &gt; 0. Questo accade con probabilità 1, quindi P(X_2 &gt; 0) = 1.\nCalcolo della Funzione di Ripartizione di X_2: Si vuole calcolare F_{X_2}(x) = P(X_2 \\le x).\nF_{X_2}(x) = P(-\\log(X_1) \\le x)\nPer risolvere questa probabilità, si considera il caso in cui x \\le 0 e il caso in cui x &gt; 0.\nCaso 1: x \\le 0 Abbiamo dimostrato che P(X_2 &gt; 0) = 1. Quindi, la probabilità che X_2 sia minore o uguale a un numero non positivo è 0: F_{X_2}(x) = P(X_2 \\le x) = 0 per x \\le 0 .\nCaso 2: x &gt; 0 P(-\\log(X_1) \\le x) = P(\\log(X_1) \\ge -x) Esponenziando entrambi i lati (e ricordando che la funzione esponenziale è crescente): P(X_1 \\ge e^{-x})\nPoiché X_1 è uniforme su (0, 1), e stiamo considerando x &gt; 0, allora 0 &lt; e^{-x} &lt; 1. La probabilità che X_1 sia maggiore o uguale a e^{-x} è data da: P(X_1 \\ge e^{-x}) = 1 - P(X_1 &lt; e^{-x}) = 1 - F_{X_1}(e^{-x})\nDato che per 0 &lt; y &lt; 1, F_{X_1}(y) = y, abbiamo: 1 - F_{X_1}(e^{-x}) = 1 - e^{-x}\nQuindi, la funzione di ripartizione di X_2 è: F_{X_2}(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\ 1 - e^{-x} &amp; \\text{se } x &gt; 0 \\end{cases}\nQuesta è la funzione di ripartizione di una variabile aleatoria esponenziale con parametro \\lambda = 1.\nIl professore conclude sottolineando l’importanza di guardare “in faccia” la variabile aleatoria e la trasformazione prima di eseguire i calcoli, per capire le sue proprietà fondamentali.\n\nTrasformazione di Variabili Aleatorie e Funzione di Ripartizione\nIntroduzione: Calcolo della Probabilità di X^2 \\le X per X &gt; 0\nIl professore inizia concentrandosi sul calcolo della probabilità che X^2 sia minore o uguale a X, dato che una variabile aleatoria X_1 è strettamente maggiore di 0. Viene specificato che si restringe l’attenzione al caso X &gt; 0 perché la probabilità che X_1 appartenga all’intervallo (0, 1) è 1, semplificando l’analisi iniziale.\nSi definisce una nuova variabile aleatoria X_2 = -\\log(X_1), dove X_1 \\in (0, 1). L’obiettivo è calcolare la funzione di ripartizione di X_2, F_{X_2}(x) = P(X_2 \\le x), conoscendo la funzione di ripartizione di X_1, F_{X_1}(x).\nCalcolo della Funzione di Ripartizione di X_2 per x &gt; 0\nPer x &gt; 0, si ha: F_{X_2}(x) = P(X_2 \\le x) = P(-\\log(X_1) \\le x).\nManipolando la disuguaglianza: -\\log(X_1) \\le x \\iff \\log(X_1) \\ge -x X_1 \\ge e^{-x}.\nQuindi, P(-\\log(X_1) \\le x) = P(X_1 \\ge e^{-x}).\nIl professore sottolinea che l’evento {-\\log(X_1) \\le x} è esattamente uguale all’evento {X_1 \\ge e^{-x}} come sottoinsiemi dello spazio campionario \\Omega.\nLa probabilità P(X_1 \\ge e^{-x}) può essere espressa in termini della funzione di ripartizione di X_1: P(X_1 \\ge e^{-x}) = 1 - P(X_1 &lt; e^{-x}).\nPoiché X_1 è assunta avere una funzione di ripartizione assolutamente continua, la probabilità che X_1 sia uguale a un singolo valore è zero, quindi P(X_1 &lt; e^{-x}) = P(X_1 \\le e^{-x}) = F_{X_1}(e^{-x}).\nPertanto, per x &gt; 0: F_{X_2}(x) = 1 - F_{X_1}(e^{-x}).\nCaso Specifico: X_1 Distribuita Uniformemente in (0, 1)\nIl professore considera il caso in cui X_1 è distribuita uniformemente nell’intervallo (0, 1). In questo caso, la funzione di ripartizione di X_1 è: F_{X_1}(y) = \\begin{cases} 0 &amp; \\text{se } y &lt; 0 \\ y &amp; \\text{se } 0 \\le y \\le 1 \\ 1 &amp; \\text{se } y &gt; 1 \\end{cases}.\nPoiché stiamo considerando x &gt; 0, l’argomento di F_{X_1}, che è e^{-x}, sarà sempre compreso tra 0 e 1 (in quanto x &gt; 0 \\implies e^{-x} \\in (0, 1)).\nQuindi, per x &gt; 0, F_{X_1}(e^{-x}) = e^{-x}.\nSostituendo nell’espressione per F_{X_2}(x), otteniamo per x &gt; 0: F_{X_2}(x) = 1 - e^{-x}.\nFunzione di Ripartizione Completa di X_2\nPer completare la definizione della funzione di ripartizione di X_2, si considera anche il caso x \\le 0. F_{X_2}(x) = P(X_2 \\le x) = P(-\\log(X_1) \\le x).\nSe x \\le 0, allora -\\log(X_1) \\le x implica \\log(X_1) \\ge -x \\ge 0, quindi X_1 \\ge e^{-x} \\ge 1. Tuttavia, sappiamo che X_1 \\in (0, 1) con probabilità 1. Pertanto, per x \\le 0, l’evento {-\\log(X_1) \\le x} ha probabilità 0.\nQuindi, la funzione di ripartizione di X_2 è: F_{X_2}(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\ 1 - e^{-x} &amp; \\text{se } x &gt; 0 \\end{cases}.\nVerifica delle Proprietà della Funzione di Ripartizione\nIl professore verifica che la funzione F_{X_2}(x) ottenuta soddisfa le proprietà di una funzione di ripartizione:\n\nContinuità da destra: La funzione è continua per x &lt; 0 e per x &gt; 0. In x = 0, \\lim_{h \\to 0^+} F_{X_2}(0 + h) = 1 - e^0 = 1 - 1 = 0 = F_{X_2}(0). Quindi è continua da destra.\nMonotona non decrescente: Per x \\le 0, la funzione è costante a 0. Per x &gt; 0, la derivata è \\frac{d}{dx}(1 - e^{-x}) = e^{-x} &gt; 0, quindi è strettamente crescente.\nLimiti agli estremi:\n\n\\lim_{x \\to -\\infty} F_{X_2}(x) = \\lim_{x \\to -\\infty} 0 = 0.\n\\lim_{x \\to +\\infty} F_{X_2}(x) = \\lim_{x \\to +\\infty} (1 - e^{-x}) = 1 - 0 = 1.\n\n\n\nQueste verifiche confermano che F_{X_2}(x) è una funzione di ripartizione valida.\nErrore Tipico da Evitare\nIl professore avverte di un errore comune: dimenticare la parte della funzione di ripartizione per x \\le 0 e scrivere semplicemente F_{X_2}(x) = 1 - e^{-x} per ogni x. Questo porterebbe a risultati errati nel calcolo delle probabilità, specialmente per valori negativi di x.\nDefinizione di Variabile Aleatoria con Legge Esponenziale\nLa variabile aleatoria X_2 la cui funzione di ripartizione è F_{X_2}(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\\\ 1 - e^{-x} &amp; \\text{se } x &gt; 0 \\end{cases} è detta avere una legge esponenziale (o esponenziale negativa).\nQuesto esempio illustra la trasformazione di una variabile aleatoria: a partire dalla legge di X_1, si è derivata la legge della variabile trasformata X_2 = -\\log(X_1). Questo tipo di trasformazioni è frequente in probabilità.\nCorollario sull’Unicità delle Misure di Probabilità\nIl professore introduce un corollario basato sul criterio di unicità delle misure di probabilità:\nSe due variabili aleatorie X_1 e X_2 definite sullo stesso spazio di probabilità (\\Omega, \\mathcal{F}, P) hanno la stessa funzione di ripartizione, cioè F_{X_1}(x) = F_{X_2}(x) per ogni x \\in \\mathbb{R}, allora le loro leggi (misure immagine) sono uguali: P(X_1 \\in A) = P(X_2 \\in A) per ogni insieme boreliano A.\nQuesto deriva dal fatto che gli intervalli (-\\infty, x] formano una \\pi-classe che genera la \\sigma-algebra dei boreliani. Due misure di probabilità che coincidono su una \\pi-classe che genera la \\sigma-algebra, coincidono su tutta la \\sigma-algebra.\nImportanza del Concetto di Legge di una Variabile Aleatoria\nAvere la stessa legge non implica che due variabili aleatorie siano uguali con probabilità 1, anche se definite sullo stesso spazio di probabilità.\nEsempio: Sia \\Omega = {0, 1} con la \\sigma-algebra di tutte le parti e una misura di probabilità P({0}) = 1/2, P({1}) = 1/2. Definiamo due variabili aleatorie: X_1(\\omega) = \\omega X_2(\\omega) = 1 - \\omega\nLa probabilità che X_1 = X_2 è P({\\omega \\in {0, 1} \\mid \\omega = 1 - \\omega}) = P(\\emptyset) = 0. Quindi X_1 e X_2 sono diverse con probabilità 1.\nTuttavia, calcoliamo le loro funzioni di ripartizione:\nPer F_{X_1}(x):\n\nSe x &lt; 0, P(X_1 \\le x) = P(\\emptyset) = 0.\nSe 0 \\le x &lt; 1, P(X_1 \\le x) = P({0}) = 1/2.\nSe x \\ge 1, P(X_1 \\le x) = P({0, 1}) = 1.\n\nPer F_{X_2}(x):\n\nSe x &lt; 0, P(X_2 \\le x) = P(\\emptyset) = 0.\nSe 0 \\le x &lt; 1, P(X_2 \\le x) = P({1}) = 1/2.\nSe x \\ge 1, P(X_2 \\le x) = P({0, 1}) = 1.\n\nQuindi, F_{X_1}(x) = F_{X_2}(x) per ogni x \\in \\mathbb{R}, il che significa che X_1 e X_2 hanno la stessa legge, anche se non sono uguali con probabilità 1.\nCostruzione di una Variabile Aleatoria Data una Funzione di Ripartizione\nSe F è una funzione di ripartizione, esiste uno spazio di probabilità (\\Omega, \\mathcal{F}, P) e una variabile aleatoria X: \\Omega \\to \\mathbb{R} tale che la funzione di ripartizione di X, F_X(x) = P(X \\le x), è uguale a F(x) per ogni x \\in \\mathbb{R}.\nIl professore sottolinea che lo spazio di probabilità e la variabile aleatoria non sono unici. L’esempio di X_1 e X_2 sopra mostra due variabili aleatorie diverse definite sullo stesso spazio di probabilità che hanno la stessa funzione di ripartizione (e quindi la stessa legge).\nQuesto teorema garantisce che per ogni funzione che soddisfa le proprietà di una funzione di ripartizione, possiamo sempre immaginare che essa descriva la distribuzione di probabilità di qualche variabile aleatoria. Ad esempio, la funzione di ripartizione esponenziale trovata in precedenza corrisponde alla legge di una variabile aleatoria esponenziale.\nReferences\nappunti prob-lez08.pdf\nAppunti Prob- lez08’.pdf\n2025-03-06 15:06\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine probabilità\nprob-lez09\n\nprob-lez09\nSpiegazione del Professore su Argomenti di Probabilità\nChiarimento sulla Dimostrazione del Teorema di Bayes\nIl professore inizia la lezione rispondendo a domande di studenti riguardo alla dimostrazione del Teorema di Bayes. Viene chiarito che la dimostrazione è stata effettivamente presentata durante la lezione precedente, quando si è discusso del teorema di Bayes per eventi.\nDimostrazione per Eventi e Forma Ridotta\nLa dimostrazione si basa sulla scrittura del teorema di Bayes nella sua forma ridotta per due eventi, H e E. Questa dimostrazione consiste nello scrivere la formula stessa del teorema.\nApplicazione della Proprietà delle Probabilità Totali\nIl secondo passaggio della dimostrazione implica l’applicazione di quella che è stata definita la proprietà delle probabilità totali o di disintegrazione al denominatore della formula di Bayes.\nSe H_i costituisce una partizione dello spazio campionario, allora la probabilità di un evento E può essere scritta come la somma delle probabilità condizionate di E dato H_i, moltiplicate per le probabilità di H_i:\nP(E) = \\sum_{i} P(E|H_i) P(H_i)\nIl professore sottolinea che la dimostrazione del teorema di Bayes è intrinsecamente legata alla forma delle probabilità totali.\nFunzione di Ripartizione\nSuccessivamente, l’argomento si sposta sulla funzione di ripartizione, associata a una variabile aleatoria. La funzione di ripartizione svolge un ruolo cruciale nella descrizione di tutte le misure di probabilità su \\mathbb{R} e delle leggi di qualunque variabile aleatoria a valori reali.\nCorrispondenza Biunivoca con le Misure di Probabilità\n\nEsiste una corrispondenza biunivoca tra le funzioni di ripartizione e le misure di probabilità sui boreliani di \\mathbb{R}. Data una funzione di ripartizione, è possibile costruire uno spazio di probabilità e una variabile aleatoria tale che la funzione di ripartizione di questa variabile aleatoria coincida con la funzione di ripartizione data.\nDimostrazione dell’Esistenza di una Variabile Aleatoria con Data Funzione di Ripartizione (Dimostrazione Facoltativa)\nIl professore presenta una dimostrazione facoltativa di questo fatto, sottolineando che mette in luce un aspetto importante, anche se a prima vista può sembrare tautologico.\nCostruzione Canonica\nLa costruzione canonica proposta è la seguente:\n\nSi prende lo spazio di partenza \\Omega uguale allo spazio d’arrivo \\mathbb{R}.\nSi definisce la variabile aleatoria X come la funzione identità su \\mathbb{R}, ovvero X(\\omega) = \\omega per ogni \\omega \\in \\mathbb{R}. Questa funzione è (chiaramente) misurabile.\nSi sceglie una misura di probabilità P su \\Omega = \\mathbb{R} (sui boreliani di \\mathbb{R}).\n\nScelta della Misura di Probabilità P_F\nSi assume l’esistenza di una misura P_F tale che le probabilità delle semirette (-\\infty, x] coincidano con la funzione di ripartizione F(x) data. Questo fatto è basato su una proposizione vista precedentemente.\nP_F((-\\infty, x]) = F(x)\nVerifica della Funzione di Ripartizione di X\nLa funzione di ripartizione della variabile aleatoria X (l’identità) è data da:\nF_X(x) = P\\set{ \\omega : X \\le x} = P\\set{\\omega \\in \\mathbb{R} : \\omega \\le x}\nPoiché P è scelta come P_F, si ha:\nF_X(x) = P_F((-\\infty, x]) = F(x)\nQuesto dimostra che esiste una variabile aleatoria (in questo caso l’identità su \\mathbb{R} con la misura P_F) la cui funzione di ripartizione è la funzione F data. Il professore ribadisce che questa non è l’unica possibile costruzione.\nFunzione Quantile (Inversa Generalizzata)\nIl professore introduce la funzione quantile, o inversa generalizzata, di una funzione di ripartizione F. Questa funzione, indicata come F^{-}(u), è definita come:\nF^{-}(u) = \\inf \\set{x \\in \\mathbb{R} : F(x) \\ge u }, \\quad u \\in (0, 1)\nCaso di Funzione di Ripartizione Invertibile\nIn particolare, se la funzione di ripartizione F è strettamente monotona (e quindi invertibile), l’inversa generalizzata coincide con la funzione inversa usuale F^{-1}(u).\nF^{-}(u) = F^{-1}(u)\nInterpretazione Intuitiva\n\nLa funzione quantile F^{-1}(u) (nel caso invertibile) rappresenta quel valore x tale per cui la probabilità che la variabile aleatoria sia minore o uguale a x è uguale a u:\nP(X \\le F^{-1}(u)) = F(F^{-1}(u)) = u\nIn termini statistici, F^{-1}(1/2) corrisponde alla mediana, ovvero quel valore che divide la distribuzione di probabilità in due parti uguali. Per un quantile di ordine p, F^{-1}(p) è il valore al di sotto del quale cade una proporzione p dei dati.\nGeneralizzazione per Funzioni Non Invertibili\n\n\nLa definizione con l’infimum serve a generalizzare il concetto di inversa anche a funzioni di ripartizione che non sono strettamente monotone, ovvero che presentano tratti piatti o salti. In questi casi, per un dato valore di u, potrebbe non esistere un unico x tale che F(x) = u. La definizione tramite l’infimum seleziona il più piccolo di tali x (o il punto iniziale del tratto in cui F(x) \\ge u).\nCostruzione di una Variabile Aleatoria con Legge Arbitraria a Partire da una Variabile Uniforme\nIl professore presenta un metodo per costruire una variabile aleatoria con una legge di probabilità arbitraria, purché si sappia costruire una variabile aleatoria con legge uniforme sull’intervallo (0, 1).\nTeorema di Trasformazione Inversa ?\nSia F una funzione di ripartizione e sia U una variabile aleatoria con legge uniforme su (0, 1) definita su uno spazio di probabilità (\\Omega, \\mathcal{F}, P). Si definisce una nuova variabile aleatoria X come:\nX = F^{-}(U)\n\n\ndove F^{-} è la funzione quantile (inversa generalizzata) di F.\nProprietà Fondamentale\nLa proprietà fondamentale di questa costruzione è che la variabile aleatoria X così definita ha proprio F come sua funzione di ripartizione:\nP(X \\le x) = F(x)\nDimostrazione nel Caso di F Invertibile\n\nIl professore fornisce la dimostrazione di questa proprietà nel caso in cui la funzione di ripartizione F sia strettamente monotona e quindi invertibile. In questo caso, F^{-}(u) = F^{-1}(u).\nP(X \\le x) = P(F^{-1}(U) \\le x)\nPoiché F è strettamente monotona crescente, anche la sua inversa F^{-1} è strettamente monotona crescente. Quindi l’ineguaglianza F^{-1}(U) \\le x è equivalente a U \\le F(x):\nP(F^{-1}(U) \\le x) = P(U \\le F(x))\nDato che U ha una distribuzione uniforme su (0, 1), la sua funzione di ripartizione F_U(u) è data da:\n\nF_U(u) = P(U \\le u) = \\begin{cases} 0 &amp; \\text{se } u &lt; 0 \\\\ u &amp; \\text{se } 0 \\le u \\le 1 \\\\ 1 &amp; \\text{se } u &gt; 1 \\end{cases}\nPoiché F(x) è sempre un valore compreso tra 0 e 1, si ha:\nP(U \\le F(x)) = F_U(F(x)) = F(x)\nQuindi, P(X \\le x) = F(x), dimostrando che la variabile aleatoria X = F^{-1}(U) ha funzione di ripartizione F.\nCollegamento con la Derivazione della Legge Esponenziale\nIl professore fa notare che il procedimento utilizzato per derivare la legge esponenziale a partire da una uniforme è un caso particolare di questa trasformazione inversa.\nEsercizio menzionato: Verificare che l’esercizio fatto per introdurre la legge esponenziale a partire dall’uniforme è esattamente questo conto nel caso particolare di una specifica F.\n\nVariabili Aleatorie Discrete\nDefinizione di Funzione di Ripartizione (Caso Generale)\nSi consideri una variabile aleatoria U. La funzione di ripartizione di U, calcolata in un punto f(x) (dove f(x) è un numero), è definita come la probabilità che la variabile aleatoria U assuma un valore minore o uguale a f(x). Formalmente:\nP(U \\le f(x)) = F_U(f(x))\nDove F_U è la funzione di ripartizione di U. Il valore f(x) è sempre compreso tra 0 e 1, poiché è il valore di una funzione di ripartizione.\nNel caso di una variabile aleatoria U con distribuzione uniforme sull’intervallo (0, 1), la sua funzione di ripartizione F_U(x) in un punto x compreso tra 0 e 1 è semplicemente x stesso.\nDefinizione di Funzione di Ripartizione per Vettori Aleatori\nSi può estendere la definizione di funzione di ripartizione a un vettore aleatorio X = (X_1, ..., X_d) a valori in \\mathbb{R}^d. La funzione di ripartizione del vettore aleatorio F_X(x_1, ..., x_d) è definita come la probabilità che ciascuna componente X_i sia minore o uguale al corrispondente valore x_i per ogni vettore x = (x_1, ..., x_d) \\in \\mathbb{R}^d:\nF_X(x_1, ..., x_d) = P(X_1 \\le x_1, X_2 \\le x_2, ..., X_d \\le x_d)\nDove la notazione con la virgola indica l’intersezione degli eventi.\nTuttavia, lo studio della teoria equivalente per le funzioni di ripartizione in più dimensioni è più complesso rispetto al caso unidimensionale. Pertanto, ci si concentra principalmente sui risultati ottenuti per variabili aleatorie a valori in \\mathbb{R}.\nVariabili Aleatorie Discrete: Definizione e Supporto\nUna variabile aleatoria X a valori in \\mathbb{R}^d è detta discreta se esiste un insieme numerabile C \\subseteq \\mathbb{R}^d (che è anche un insieme boreliano in quanto unione di punti) tale che la probabilità che X appartenga a C sia uguale a 1:\nP\\set{X \\in C} = 1\nL’insieme C è anche detto supporto della variabile aleatoria o insieme dei valori ammissibili. Questo significa che la variabile aleatoria X assume i suoi valori solo all’interno dell’insieme C, e la probabilità di assumere valori al di fuori di C è zero. È importante distinguere tra un evento impossibile (probabilità zero) e un evento che non si osserva mai nella realizzazione della variabile aleatoria.\nNel caso d=1, l’insieme C è un sottoinsieme numerabile di \\mathbb{R} e può essere rappresentato come una sequenza di punti \\set{x_1, x_2, ...}.\n\nProbabilità per Variabili Aleatorie Discrete\n\nPer una variabile aleatoria discreta X con supporto C, la probabilità che X appartenga a un qualsiasi sottoinsieme A \\subseteq \\mathbb{R}^d può essere calcolata considerando solo l’intersezione di A con il supporto C:\nP(X \\in A) = P(X \\in C \\cap A)\nQuesto perché la probabilità che X assuma valori al di fuori di C è zero.\nFunzione di Massa di Probabilità (PMF) o Densità Discreta\nPer una variabile aleatoria discreta X con supporto C = \\set{x_1, x_2, ...}, si definisce la funzione di massa di probabilità (PMF) p_i come la probabilità che X assuma il valore x_i:\np_i = P(X = x_i)\nLa PMF soddisfa le seguenti proprietà:\n\np_i \\ge 0 per ogni i\n\\sum_{i} p_i = 1\n\nLa collezione di questi valori {p_i} descrive completamente la legge o distribuzione della variabile aleatoria discreta X. La legge immagine di X è una misura discreta.\nA volte si usa la notazione p(x_i) o p_X(x_i) per indicare la probabilità che la variabile aleatoria X assuma il valore x_i.\nFunzione di Ripartizione di una Variabile Aleatoria Discreta\nLa funzione di ripartizione F_X(x) di una variabile aleatoria discreta X a valori in \\mathbb{R} è data dalla somma delle probabilità di tutti i valori x_i nel supporto C che sono minori o uguali a x:\nF_X(x) = P(X \\le x) = \\sum_{x_i \\in C: \\ \\ x_i \\le x} p_i\nLa funzione di ripartizione di una variabile aleatoria discreta è una funzione a gradini, costante a tratti e continua da destra, con salti in corrispondenza dei punti del supporto C. L’altezza del salto in un punto x_i \\in C è pari alla probabilità p_i = P(X = x_i).\n\nVettori Aleatori Discreti e Funzione di Ripartizione\nLa definizione di variabile aleatoria discreta si estende ai vettori aleatori X = (X_1, ..., X_d) a valori in \\mathbb{R}^d. Se esiste un insieme numerabile C \\subseteq \\mathbb{R}^d tale che P(X \\in C) = 1, allora X è un vettore aleatorio discreto.\nLa funzione di ripartizione di un vettore aleatorio discreto X è ancora definita come:\n\\begin{aligned}F_X(x_1, ..., x_d) = \\\\ \\\\ P(X_1 \\le x_1, ..., X_d \\le x_d) \\\\ \\\\ \\sum_{\\begin{aligned}x = (x_1&#039;, ..., x_d&#039;) \\in C:\\\\ x_1&#039; \\le x_1, ..., x_d&#039; \\le x_d \\end{aligned}} p(x_1&#039;, ..., x_d&#039;)\\end{aligned}\nDove p(x_1&#039;, ..., x_d&#039;) = P(X_1 = x_1&#039;, ..., X_d = x_d&#039;) è la funzione di massa di probabilità congiunta del vettore aleatorio discreto.\nA volte, per comodità, si può considerare che il supporto C sia un prodotto cartesiano di insiemi numerabili C_1 \\times ... \\times C_d, anche se alcuni punti nel prodotto cartesiano potrebbero avere probabilità zero.\nDistribuzioni Marginali di Vettori Aleatori Discreti\n\nSe X = (X_1, ..., X_d) è un vettore aleatorio discreto con supporto C \\subseteq \\mathbb{R}^d e funzione di massa di probabilità congiunta p(x_1, ..., x_d), allora ogni componente X_i è anch’essa una variabile aleatoria discreta.\nLa funzione di massa di probabilità marginale di X_i, p_{X_i}(x_i), si ottiene marginalizzando (sommando) la funzione di massa di probabilità congiunta su tutti i possibili valori delle altre componenti:\np_{X_i}(x_i) = P(X_i = x_i) = \\sum_{(x_1, ..., x_{i-1}, x_{i+1}, ..., x_d) \\in C_{-i}} p(x_1, ..., x_{i-1}, x_i, x_{i+1}, ..., x_d)\nDove C_{-i} rappresenta l’insieme dei possibili valori delle componenti diverse da X_i nel supporto C.\nEsempio in due dimensioni (d=2): Sia X = (X_1, X_2) un vettore aleatorio discreto con supporto C = {(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3)} e una distribuzione uniforme su questi quattro punti (correzione dell’esempio del professore), quindi P(X = (x_1, x_2)) = 1/4 per (x_1, x_2) \\in {(1, 1), (1, 2), (2, 1), (2, 2)} e 0 altrove.\nLa funzione di massa di probabilità marginale di X_1 è:\np_{X_1}(1) = P(X_1 = 1) = P(X_1 = 1, X_2 = 1) + P(X_1 = 1, X_2 = 2) + P(X_1 = 1, X_2 = 3) = p(1, 1) + p(1, 2) + p(1, 3) = 1/4 + 1/4 + 0 = 1/2\np_{X_1}(2) = P(X_1 = 2) = P(X_1 = 2, X_2 = 1) + P(X_1 = 2, X_2 = 2) + P(X_1 = 2, X_2 = 3) = p(2, 1) + p(2, 2) + p(2, 3) = 1/4 + 1/4 + 0 = 1/2\np_{X_1}(x_1) = 0 per x_1 \\notin {1, 2}\nLa funzione di massa di probabilità marginale di X_2 è:\np_{X_2}(1) = P(X_2 = 1) = P(X_1 = 1, X_2 = 1) + P(X_1 = 2, X_2 = 1) = p(1, 1) + p(2, 1) = 1/4 + 1/4 = 1/2\np_{X_2}(2) = P(X_2 = 2) = P(X_1 = 1, X_2 = 2) + P(X_1 = 2, X_2 = 2) = p(1, 2) + p(2, 2) = 1/4 + 1/4 = 1/2\np_{X_2}(3) = P(X_2 = 3) = P(X_1 = 1, X_2 = 3) + P(X_1 = 2, X_2 = 3) = p(1, 3) + p(2, 3) = 0 + 0 = 0\np_{X_2}(x_2) = 0 per x_2 \\notin {1, 2, 3}\nIl professore introduce la notazione con la virgola per indicare l’intersezione di eventi, ad esempio P(X_1 = 1, X_2 = 1) invece di P(X_1 = 1 \\cap X_2 = 1).\nConclusioni\nSe si ha un vettore aleatorio discreto, allora tutti i suoi sottovettori, incluse le singole componenti, sono anch’essi variabili aleatorie discrete. La legge (distribuzione) di un vettore aleatorio discreto determina completamente la legge di tutte le sue distribuzioni marginali.\n\nVariabili Aleatorie Discrete e Valore Atteso\nDensità di Probabilità Congiunta per Vettori Discreti\nConsideriamo un vettore aleatorio (X_1, X_2) dove X_1 assume valori in un insieme finito C_1 e X_2 assume valori in un insieme finito C_2. La densità di probabilità congiunta del vettore (X_1, X_2) è una funzione P(x_1, x_2) che rappresenta la probabilità che X_1 = x_1 e X_2 = x_2, dove x_1 \\in C_1 e x_2 \\in C_2. Questa densità può essere rappresentata tramite una tabella di contingenza.\nAd esempio, se C_1 = {1, 3, 4} e C_2 = {1, 2, 3}, la tabella di contingenza conterrà le probabilità P(x_1, x_2) per ogni coppia (x_1, x_2).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX_2 \\setminus X_113411/400201/41/4301/40\nDa questa tabella, possiamo leggere diverse informazioni, come il supporto di X_1 e X_2 e la probabilità di ogni combinazione di valori. Ad esempio, la probabilità che X_1 = 3 e X_2 = 2 è P(3, 2) = 1/4. La probabilità che X_1 = 2 e X_2 = 1 è P(2, 1) = 0.\nDensità di Probabilità Marginale\nA partire dalla densità di probabilità congiunta, è possibile ricavare le densità di probabilità marginali delle singole componenti. La densità marginale di X_1, P_{X_1}(x_1), si ottiene sommando la densità congiunta su tutti i possibili valori di X_2:\nP_{X_1}(x_1) = \\sum_{x_2 \\in C_2} P(x_1, x_2)\nAnalogamente, la densità marginale di X_2, P_{X_2}(x_2), si ottiene sommando la densità congiunta su tutti i possibili valori di X_1:\nP_{X_2}(x_2) = \\sum_{x_1 \\in C_1} P(x_1, x_2)\nNell’esempio precedente, la densità marginale di X_1 è: P_{X_1}(1) = P(1, 1) + P(1, 2) + P(1, 3) = 1/4 + 0 + 0 = 1/4 P_{X_1}(3) = P(3, 1) + P(3, 2) + P(3, 3) = 0 + 1/4 + 1/4 = 1/2 P_{X_1}(4) = P(4, 1) + P(4, 2) + P(4, 3) = 0 + 1/4 + 0 = 1/4\nE la densità marginale di X_2 è: P_{X_2}(1) = P(1, 1) + P(3, 1) + P(4, 1) = 1/4 + 0 + 0 = 1/4 P_{X_2}(2) = P(1, 2) + P(3, 2) + P(4, 2) = 0 + 1/4 + 1/4 = 1/2 P_{X_2}(3) = P(1, 3) + P(3, 3) + P(4, 3) = 0 + 1/4 + 0 = 1/4\nQueste marginali possono essere aggiunte alla tabella di contingenza.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX_2 \\setminus X_1134P_{X_2}(x_2)11/4001/4201/41/41/2301/401/4P_{X_1}(x_1)1/41/21/41\nQuesto processo di ricavare le densità marginali dalla densità congiunta è chiamato marginalizzazione.\nRelazione tra Densità Congiunta e Marginali\nImportante: La densità congiunta determina univocamente le densità marginali, ma il viceversa non è vero. Date le densità marginali di X_1 e X_2, non è possibile ricostruire un’unica densità congiunta. Possono esistere diverse densità congiunte che producono le stesse marginali.\nAd esempio, कंसीडर la seguente tabella con la stessa marginali dell’esempio precedente:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX_2 \\setminus X_113411/161/81/1623/162/8 = 4/163/16302/8 = 4/160\n(Nota: il professore ha ammesso un errore nei suoi calcoli nell’esempio a lezione).\nQuesta tabella ha le stesse marginali dell’esempio precedente (verificabile sommando righe e colonne), ma la densità congiunta è diversa. Questo dimostra che la conoscenza delle sole marginali non è sufficiente per determinare la densità congiunta.\nValore Atteso di una Variabile Aleatoria Discreta\nSia X una variabile aleatoria discreta che assume valori in un insieme finito o numerabile C, con densità di probabilità discreta (o funzione di massa di probabilità) p_X(x) = P(X = x) per x \\in C.\nIl valore atteso (o speranza matematica, valor medio, media) di X, denotato con E[X] o \\mu, è definito come la somma (o serie):\nE[X] = \\sum_{x \\in C} x \\cdot p_X(x)\nCondizione di Esistenza: Il valore atteso è definito solo se la seguente somma converge assolutamente:\n\\sum_{x \\in C} |x| \\cdot p_X(x) &lt; \\infty\nSe questa condizione non è soddisfatta (ovvero la somma diverge a +\\infty), allora il valore atteso non è ben definito. Nel caso in cui C sia un insieme finito, questa somma è sempre convergente. Se C è infinito, è necessario verificare la convergenza assoluta. Questa condizione garantisce che la somma che definisce il valore atteso non dipenda dall’ordine in cui i termini vengono sommati.\nInterpretazione del Valore Atteso: Il valore atteso può essere interpretato come una sorta di baricentro dei valori che la variabile aleatoria può assumere, pesati dalle rispettive probabilità. In una dimensione, immagina dei punti sulla retta reale con delle masse corrispondenti alle loro probabilità; il valore atteso è la posizione del centro di massa.\nIl Valore Atteso Dipende dalla Legge Immagine: Tecnicamente, il valore atteso è definito a partire dalla variabile aleatoria X e dallo spazio di probabilità (\\Omega, \\mathcal{F}, P) su cui è definita. Tuttavia, il suo valore dipende esclusivamente dalla legge immagine (o distribuzione di probabilità) di X sullo spazio di arrivo (in questo caso, \\mathbb{R}).\nSe due variabili aleatorie discrete, definite anche su spazi di probabilità diversi, hanno la stessa legge immagine (cioè la stessa densità di probabilità discreta), allora avranno lo stesso valore atteso.\nEsempio 1: Distribuzione di Poisson\nSi consideri una variabile aleatoria X che assume valori negli interi non negativi N = {0, 1, 2, ...}. La probabilità che X = k è data dalla distribuzione di Poisson con parametro \\lambda &gt; 0:\nP(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}, per k \\in N\nVerifica che sia una densità di probabilità: La somma delle probabilità su tutti i possibili valori di k deve essere uguale a 1:\n\\sum_{k=0}^{\\infty} P(X = k) = \\sum_{k=0}^{\\infty} \\frac{\\lambda^k e^{-\\lambda}}{k!} = e^{-\\lambda} \\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!}\nRicordando l’espansione in serie di Taylor della funzione esponenziale e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!}, abbiamo:\n\\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!} = e^{\\lambda}\nQuindi, \\sum_{k=0}^{\\infty} P(X = k) = e^{-\\lambda} \\cdot e^{\\lambda} = 1. Inoltre, P(X = k) \\ge 0 per ogni k \\in N e \\lambda &gt; 0.\nEsercizi:\n\n\nCalcolare la probabilità che X sia maggiore stretto di 1, i.e., P(X &gt; 1). P(X &gt; 1) = 1 - P(X \\le 1) = 1 - [P(X = 0) + P(X = 1)] P(X = 0) = \\frac{\\lambda^0 e^{-\\lambda}}{0!} = e^{-\\lambda} P(X = 1) = \\frac{\\lambda^1 e^{-\\lambda}}{1!} = \\lambda e^{-\\lambda} Pertanto, P(X &gt; 1) = 1 - (e^{-\\lambda} + \\lambda e^{-\\lambda}) = 1 - e^{-\\lambda}(1 + \\lambda).\n\n\nCalcolare il valore atteso di X, E[X], usando la definizione. E[X] = \\sum_{k=0}^{\\infty} k \\cdot P(X = k) = \\sum_{k=0}^{\\infty} k \\cdot \\frac{\\lambda^k e^{-\\lambda}}{k!} Notiamo che per k = 0, il termine è 0 \\cdot \\frac{\\lambda^0 e^{-\\lambda}}{0!} = 0. Possiamo quindi iniziare la somma da k = 1: E[X] = \\sum_{k=1}^{\\infty} k \\cdot \\frac{\\lambda^k e^{-\\lambda}}{k!} = \\sum_{k=1}^{\\infty} \\frac{k}{k!} \\lambda^k e^{-\\lambda} = \\sum_{k=1}^{\\infty} \\frac{1}{(k-1)!} \\lambda^k e^{-\\lambda} Facciamo un cambio di indice, ponendo j = k - 1, quindi k = j + 1. Quando k = 1, j = 0. La somma diventa: E[X] = \\sum_{j=0}^{\\infty} \\frac{1}{j!} \\lambda^{j+1} e^{-\\lambda} = \\lambda e^{-\\lambda} \\sum_{j=0}^{\\infty} \\frac{\\lambda^j}{j!} = \\lambda e^{-\\lambda} \\cdot e^{\\lambda} = \\lambda Quindi, il valore atteso di una variabile aleatoria di Poisson con parametro \\lambda è \\lambda.\n\n\nEsempio 2: Variabili Aleatorie con la Stessa Legge Immagine\nConsideriamo due spazi di probabilità diversi:\n\n\n(\\Omega_1, \\mathcal{F}_1, P_1) dove \\Omega_1 = {1, 2, 3, 4, 5, 6}, \\mathcal{F}_1 è la famiglia di tutti i sottoinsiemi di \\Omega_1, e P_1({\\omega}) = 1/6 per ogni \\omega \\in \\Omega_1 (modello di un dado equilibrato). Definiamo una variabile aleatoria X_1: \\Omega_1 \\rightarrow {0, 1} come l’indicatore dell’evento {\\omega \\in \\Omega_1 : \\omega \\le 3}: X_1(\\omega) = 1 se \\omega \\in {1, 2, 3} X_1(\\omega) = 0 se \\omega \\in {4, 5, 6} La legge di probabilità di X_1 è: P(X_1 = 1) = P_1({1, 2, 3}) = P_1({1}) + P_1({2}) + P_1({3}) = 1/6 + 1/6 + 1/6 = 3/6 = 1/2 P(X_1 = 0) = P_1({4, 5, 6}) = P_1({4}) + P_1({5}) + P_1({6}) = 1/6 + 1/6 + 1/6 = 3/6 = 1/2\n\n\n(\\Omega_2, \\mathcal{F}_2, P_2) dove \\Omega_2 =, \\mathcal{F}_2 è la \\sigma-algebra dei Boreliani di , e P_2 è la misura di Lebesgue ristretta a . Definiamo una variabile aleatoria X_2: \\Omega_2 \\rightarrow {0, 1} come: X_2(\\omega) = 1 se \\omega \\in [0, 1/2) X_2(\\omega) = 0 se \\omega \\in [1/2, 1] La legge di probabilità di X_2 è: P(X_2 = 1) = P_2([0, 1/2)) = 1/2 - 0 = 1/2 P(X_2 = 0) = P_2([1/2, 1]) = 1 - 1/2 = 1/2\n\n\nEntrambe le variabili aleatorie X_1 e X_2 assumono gli stessi valori {0, 1} con le stesse probabilità (legge immagine identica), anche se sono definite su spazi di probabilità (\\Omega, \\mathcal{F}, P) diversi.\nCalcolo del Valore Atteso:\nE[X_1] = \\sum_{x \\in {0, 1}} x \\cdot P(X_1 = x) = 0 \\cdot P(X_1 = 0) + 1 \\cdot P(X_1 = 1) = 0 \\cdot (1/2) + 1 \\cdot (1/2) = 1/2\nE[X_2] = \\sum_{x \\in {0, 1}} x \\cdot P(X_2 = x) = 0 \\cdot P(X_2 = 0) + 1 \\cdot P(X_2 = 1) = 0 \\cdot (1/2) + 1 \\cdot (1/2) = 1/2\nCome si vede, E[X_1] = E[X_2], il che dimostra che il valore atteso dipende unicamente dalla legge immagine della variabile aleatoria e non dallo specifico spazio di probabilità su cui è definita.\n\nReferences\nAppunti Prob - lez09.pdf\nappunti bussetti-lez09.pdf\n2025-03-20 16:17\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nprob-lez10\nVariabili Aleatorie Discrete e Valore Atteso\nIntroduzione alle Variabili Aleatorie Discrete\nIl professore introduce l’argomento delle variabili aleatorie discrete, spiegando che spesso si userà una notazione come X \\sim qualche nome per indicare che la variabile aleatoria X è distribuita secondo una certa legge.\nVariabile Aleatoria di Poisson\nUn primo esempio è la variabile aleatoria di Poisson.\n\nNotazione: X \\sim Pois(\\lambda), dove \\lambda &gt; 0 è un parametro fissato.\nDefinizione: Una variabile aleatoria X è di Poisson , siccome è discreta sapppiamo che  la possiamo completamente caratterizzare con la sua densità (o funzione di probabilità) data da: P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}, per k = 0, 1, 2, \\dots\nSpazio di Probabilità: Il professore sottolinea che per essere rigorosi, si dovrebbe definire X su uno spazio di probabilità (\\Omega, \\mathcal{F}, P) a valori in \\mathbb{R} discreto (\\Omega, \\mathcal{F}, P) \\to (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}). La densità data rappresenta la legge immagine di P tramite X. Nella maggior parte dei casi, ci si concentrerà sullo spazio di arrivo della variabile aleatoria.\nSupporto: La densità è positiva per valori interi maggiori o uguali a zero e implicitamente vale zero al di fuori di questi valori.\n\nEsercizio sul Valore Atteso della Poisson\nIl professore propone di calcolare il valore atteso di una variabile aleatoria di Poisson. La definizione del valore atteso per una variabile aleatoria discreta X è E[X] = \\sum_{x} x P(X=x), dove la somma è estesa a tutti i possibili valori di X, purché \\sum_{x} |x| P(X=x) &lt; \\infty (convergenza assoluta).\nNel caso della Poisson, i valori possibili sono k \\ge 0, quindi il valore atteso è: E[X] = \\sum_{k=0}^{\\infty} k \\frac{\\lambda^k e^{-\\lambda}}{k!}\nOsservando che per k=0 il termine è zero, la somma può iniziare da k=1: E[X] = \\sum_{k=1}^{\\infty} k \\frac{\\lambda^k e^{-\\lambda}}{k!} = \\sum_{k=1}^{\\infty} \\frac{\\lambda^k e^{-\\lambda}}{(k-1)!}\nSi può riscrivere \\lambda^k come \\lambda \\cdot \\lambda^{k-1}: E[X] = \\sum_{k=1}^{\\infty} \\lambda \\frac{\\lambda^{k-1} e^{-\\lambda}}{(k-1)!} = \\lambda \\sum_{k=1}^{\\infty} \\frac{\\lambda^{k-1} e^{-\\lambda}}{(k-1)!}\nEffettuando un cambio di variabile, ponendo j = k-1, quando k=1 si ha j=0, e la somma diventa: E[X] = \\lambda \\sum_{j=0}^{\\infty} \\frac{\\lambda^{j} e^{-\\lambda}}{j!}\nSi riconosce che la somma \\sum_{j=0}^{\\infty} \\frac{\\lambda^{j} e^{-\\lambda}}{j!} è la somma delle probabilità di tutti i possibili valori di una variabile aleatoria di Poisson con parametro \\lambda, che è uguale a 1. Pertanto, il valore atteso di una variabile aleatoria di Poisson è: E[X] = \\lambda \\cdot 1 = \\lambda\nIl professore conclude che la media di una variabile aleatoria di Poisson è \\lambda.\nVariabile Aleatoria Binomiale\nUn altro esempio di variabile aleatoria discreta è la variabile aleatoria binomiale con parametri n \\in \\mathbb{N} e p \\in [0,1]\n\nNotazione: X \\sim Bin(n, p).\nDefinizione: La variabile aleatoria X può assumere valori k \\in {0, 1, 2, \\dots, n} con probabilità: P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}\nInterpretazione: Una variabile binomiale può essere pensata come il numero di successi in n prove di Bernoulli indipendenti, ognuna con probabilità di successo p.\nEsercizio: Il professore propone come esercizio il calcolo del valore atteso di una variabile binomiale, anticipando che risulterà essere np, e che questo risultato verrà ripreso in seguito come esempio di una proprietà del valore atteso.\n\nVariabile Aleatoria Geometrica\nIl terzo esempio è la legge geometrica. Questa viene introdotta partendo da un modello probabilistico.\n\nModello: Si consideri una successione infinita di eventi indipendenti E_1, E_2, \\dots tutti con la stessa probabilità P(E_i) = p di verificarsi.\nDefinizione della Variabile Aleatoria: Sia X la variabile aleatoria che rappresenta il più piccolo indice K tale che i primi K-1 eventi non si sono verificati e l’evento K-esimo si è verificato. In termini di “guasti”, X=K significa che il primo guasto avviene al tempo K.\nSupporto: La variabile aleatoria X assume valori in {1, 2, 3, \\dots} (è discreta)\nProbabilità: La probabilità che X sia uguale a K è data da: P(X=k) = P(E_1^c \\cap E_2^c \\cap \\dots \\cap E_{k-1}^c \\cap E_k) A causa dell’indipendenza degli eventi, questa probabilità si fattorizza come: P(X=k) = P(E_1^c) P(E_2^c) \\dots P(E_{k-1}^c) P(E_k) = (1-p)^{k-1} p\nDefinizione Formale: Una variabile aleatoria discreta con questa densità di probabilità è detta geometrica di parametro p.\n\nLa Funzione Indicatrice e il suo Valore Atteso\nIl professore introduce la funzione indicatrice di un insieme A, definita come: I_A(\\omega) = \\begin{cases} 1 &amp; \\text{se } \\omega \\in A \\\\ 0 &amp; \\text{se } \\omega \\notin A \\end{cases}\nA volte, per comodità, soprattutto quando l’insieme A è definito da una condizione che coinvolge una variabile aleatoria, si userà una notazione del tipo I_{\\set{X \\in B}} o semplicemente I(X \\in B).\nValore Atteso di una Funzione Indicatrice\nConsiderando una variabile aleatoria X = I_A, che può assumere solo i valori 0 e 1, il suo valore atteso è: E[X] = \\sum_{x} x P(X=x) = 0 \\cdot P(X=0) + 1 \\cdot P(X=1)\n\nSi ha che P(X=1) = P({\\omega : I_A(\\omega) = 1}) = P(A) e P(X=0) = P({\\omega : I_A(\\omega) = 0}) = P(A^c). Pertanto, il valore atteso di una funzione indicatrice è la probabilità dell’evento che essa indica: E[I_A] = P(A)\nIn particolare, se si considera una variabile aleatoria Z (invece di X per evitare confusione) definita su uno spazio di probabilità e un insieme B nello spazio di arrivo di Z, la variabile aleatoria Y = I_{{Z \\in B}} è una funzione indicatrice. Il suo valore atteso è la probabilità dell’evento {Z \\in B}: E[I_{{Z \\in B}}] = P(Z \\in B)\nQuesta proprietà verrà utilizzata frequentemente.\nTrasformazione di Variabili Aleatorie e Valore Atteso di g(X)\nCaso Semplice Iniziale e Motivazione\nIl professore inizia con un riferimento a un caso precedente, accennando alla differenza tra “sopra” e “sotto” e alla probabilità di un evento Z \\in B che può assumere solo valori 0 o 1.\nPoi introduce l’idea di trasformare una variabile aleatoria Z attraverso una funzione e calcolare il valore atteso della nuova variabile aleatoria ottenuta. Per generalizzare, introduce una variabile aleatoria X (discreta) con il suo supporto C_X e la sua funzione di probabilità p_X. Considera una funzione borelliana misurabile g: \\mathbb{R} \\rightarrow \\mathbb{R}.\n\nSi definisce una nuova variabile aleatoria Y = g(X). L’obiettivo è calcolare il valore atteso di Y, ovvero E[Y] = E[g(X)].\nDefinizione del Valore Atteso di Y = g(X)\nLa definizione del valore atteso di Y viene data come la somma sui possibili valori di Y, moltiplicati per la loro probabilità:\nE[Y] = \\sum_{y \\in C_Y} y \\cdot P(Y = y)\n\ndove C_Y è l’insieme dei valori che Y può assumere.\nOsservazione Importante: l’immagine di un insieme numerabile è al più un insieme numerabile tramite una funzione.\nIl professore sottolinea che se X è discreta, anche Y = g(X) è discreta. L’insieme dei valori che Y assume C_y è dato da {y \\in \\mathbb{R} \\mid \\exists x \\in C_X \\text{ tale che } y = g(x) }, e questo insieme ha probabilità 1.\n\nCostruzione di un’Espressione Alternativa per E[g(X)] (Proprietà Fondamentale)\nIl professore presenta un’espressione alternativa per calcolare E[g(X)] che è spesso più utile nella pratica:\nE[g(X)] = \\sum_{x \\in C_X} g(x) \\cdot P(X = x)\n\nImportante: Il professore insiste che questa non è la definizione di valore atteso di g(X), ma una proprietà. La definizione è quella basata sulla legge di probabilità di Y = g(X).\nDimostrazione della Proprietà (per g \\ge 0)\nPer semplificare la dimostrazione, si assume inizialmente che g(x) \\ge 0. Il valore atteso di Y = g(X) per definizione è:\nE[Y] = \\sum_{y \\in C_Y} y \\cdot P(Y = y)\nSi sostituisce Y = g(X):\nE[g(X)] = \\sum_{y \\in C_Y} y \\cdot P(g(X) = y)\nLa probabilità P(g(X) = y) è la probabilità dell’unione di tutti gli eventi {X = x} tali che g(x) = y:\nP(g(X) = y) = P\\left( \\bigcup_{x \\in C_X: g(x) = y} {X = x} \\right)\nPoiché gli eventi {X = x} per diversi valori di x sono disgiunti, la probabilità dell’unione è la somma delle probabilità:\nP(g(X) = y) = \\sum_{x \\in C_X: g(x) = y} P(X = x)\nSostituendo questa espressione nella formula per il valore atteso:\nE[g(X)] = \\sum_{y \\in C_Y} y \\cdot \\left( \\sum_{x \\in C_X: g(x) = y} P(X = x) \\right)\nOra si inverte l’ordine delle somme:\nE[g(X)] = \\sum_{x \\in C_X} \\left( \\sum_{y \\in C_Y: y = g(x)} y \\cdot P(X = x) \\right)\nDato che per ogni x fissato, y = g(x) è un valore unico perché g è una funzione, la somma interna si riduce a:\nE[g(X)] = \\sum_{x \\in C_X} g(x) \\cdot P(X = x)\n\nQuesta dimostrazione, inizialmente fatta per g(x) \\ge 0, può essere estesa al caso generale considerando g(x) = g^+(x) - g^-(x), dove g^+ e g^- sono le parti positiva e negativa di g, e richiedendo che E[|g(X)|] &lt; \\infty (cioè che la somma \\sum_{x \\in C_X} |g(x)| P(X = x) converge).\nProprietà del Valore Atteso\nIl professore introduce alcune proprietà importanti del valore atteso per variabili aleatorie discrete:\nLinearità\nSe a, b \\in \\mathbb{R} e X_1, X_2 sono variabili aleatorie discrete tali che E[|X_1|] &lt; \\infty e E[|X_2|] &lt; \\infty (ovvero le rispettive serie convergono assolutamente),\n \nallora il valore atteso della combinazione lineare aX_1 + bX_2 è ben definito e vale:\nE[aX_1 + bX_2] = aE[X_1] + bE[X_2]\nMonotonia\nSe una variabile aleatoria discreta X è tale che P(X \\le a) = 1, allora il suo valore atteso è minore o uguale ad a:\nSe P(X \\le a) = 1 \\implies E[X] \\le a\nCome conseguenza, se due variabili aleatorie discrete X_1 e X_2 soddisfano P(X_1 \\le X_2) = 1 e i loro valori attesi sono finiti, allora:\nE[X_1] \\le E[X_2]\nDisuguaglianza del Valore Assoluto\nIl modulo del valore atteso di una variabile aleatoria discreta X è minore o uguale al valore atteso del suo modulo:\n|E[X]| \\le E[|X|]\nQuesta è una conseguenza della proprietà di monotonia.\nSe una serie dei moduli è assolutamente convergente, cioè se \\sum_{n} |a_n| converge, allora il modulo della serie è minore o uguale alla serie dei moduli:\n|\\sum_{n} a_n| \\le \\sum_{n} |a_n|\nIl professore conclude sottolineando l’importanza di comprendere la distinzione tra la definizione del valore atteso di g(X) e la proprietà che permette di calcolarlo direttamente sulla distribuzione di X.\nesempio specifico nel contesto di variabili aleatorie discrete non negative.\nLinearità del Valore Atteso per Variabili Discrete Non Negative\nL’obiettivo è mostrare che, date due variabili aleatorie discrete x_1 e x_2 tali che x_1 \\ge 0 e x_2 \\ge 0, il valore atteso della loro somma è uguale alla somma dei loro valori attesi:\nE[x_1 + x_2] = E[x_1] + E[x_2]\nPer dimostrarlo, si parte dalla definizione del valore atteso di una funzione di un vettore aleatorio discreto. Se abbiamo un vettore aleatorio discreto (X_1, X_2) con densità congiunta P(x_1, x_2), il valore atteso di una funzione g(X_1, X_2) è dato da:\nE[g(X_1, X_2)] = \\sum_{x_1, x_2} g(x_1, x_2) P(x_1, x_2)\nNel nostro caso, g(x_1, x_2) = x_1 + x_2, quindi:\nE[x_1 + x_2] = \\sum_{x_1, x_2} (x_1 + x_2) P(x_1, x_2)\nAssumendo che la serie \\sum_{x_1, x_2} |(x_1 + x_2) P(x_1, x_2)| sia convergente (il professore menziona l’assoluta convergenza), possiamo separare la somma:\n\nE[x_1 + x_2] = \\sum_{x_1, x_2} x_1 P(x_1, x_2) + \\sum_{x_1, x_2} x_2 P(x_1, x_2)\nRiscrivendo le somme, portando fuori i termini che non dipendono dall’indice di sommazione interno:\nE[x_1 + x_2] = \\sum_{x_1} x_1 \\left( \\sum_{x_2} P(x_1, x_2) \\right) + \\sum_{x_2} x_2 \\left( \\sum_{x_1} P(x_1, x_2) \\right)\nLe somme interne rappresentano le densità marginali di x_1 e x_2 rispettivamente:\nP_{X_1}(x_1) = \\sum_{x_2} P(x_1, x_2)\nP_{X_2}(x_2) = \\sum_{x_1} P(x_1, x_2)\nSostituendo le densità marginali nell’espressione per il valore atteso:\nE[x_1 + x_2] = \\sum_{x_1} x_1 P_{X_1}(x_1) + \\sum_{x_2} x_2 P_{X_2}(x_2)\nQueste due somme sono per definizione il valore atteso di x_1 e il valore atteso di x_2:\nE[x_1 + x_2] = E[x_1] + E[x_2]\n\nIl professore sottolinea che questa dimostrazione è stata fornita in un caso particolare (x_1 \\ge 0, x_2 \\ge 0) per illustrare come la linearità del valore atteso discende dalla formula generale per il valore atteso di una funzione di un vettore aleatorio discreto. Le proprietà fondamentali introdotte sono la linearità e la monotonia del valore atteso.\nEstensione a Variabili Aleatorie Generali\nIl professore introduce la questione di come definire il valore atteso per variabili aleatorie non discrete. Egli anticipa che l’approccio in questo caso è più complesso e si basa sulla teoria della misura.\nSpazio Reale Esteso \\overline{\\mathbb{R}}\nViene anche menzionata la possibilità di considerare variabili aleatorie che possono assumere valori in \\overline{\\mathbb{R}} = \\mathbb{R} \\cup \\set{-\\infty, +\\infty}. Per fare ciò, è necessario definire una sigma algebra su questo spazio. La sigma algebra considerata è la più piccola sigma algebra che contiene sia la sigma algebra di Borel su \\mathbb{R} (\\mathcal{B}(\\mathbb{R})) che gli insiemi {-\\infty} e {+\\infty}. Questa viene chiamata la sigma algebra di Borel sulla retta estesa, \\mathcal{B}(\\overline{\\mathbb{R}}).\nUn insieme A \\in \\mathcal{B}(\\overline{\\mathbb{R}}) può essere scritto nella forma A = \\tilde{A} \\cup \\Delta, dove \\tilde{A} \\in \\mathcal{B}(\\mathbb{R}) e \\Delta è uno dei seguenti insiemi: \\set{\\emptyset}, \\set{-\\infty}, \\set{+\\infty}, \\set{-\\infty, +\\infty}.\nIl professore avverte che le proprietà della funzione di ripartizione (CDF) definite precedentemente valgono solo per variabili aleatorie a valori reali e non si estendono direttamente al caso di variabili aleatorie a valori nella retta estesa. Ad esempio, \\lim_{x \\to -\\infty} F_X(x) = 0 si basa sul fatto che P(X = -\\infty) = 0 per variabili reali.\n\nIntroduzione all’Integrale Rispetto a una Misura\nIl professore inizia a introdurre il concetto di integrale di una funzione misurabile rispetto a una misura. Consideriamo uno spazio misurabile (E, \\mathcal{E}) e una misura \\mu su di esso. Sia \\xi: E \\to \\overline{\\mathbb{R}} una funzione misurabile. L’integrale di \\xi rispetto a \\mu viene indicato con la notazione:\n\\int_E \\xi d\\mu \\quad \\text{oppure} \\quad \\int X d\\mu\nIl professore spiega che questa definizione astratta sarà applicata in tre contesti principali:\n\nIntegrale di Lebesgue: E = \\mathbb{R}^d, \\mathcal{E} = \\mathcal{B}(\\mathbb{R}^d), e \\mu è la misura di Lebesgue su \\mathbb{R}^d.\nValore Atteso: E = \\Omega (spazio di probabilità), \\mathcal{E} = \\mathcal{F} (sigma algebra degli eventi), e \\mu = P (misura di probabilità). In questo caso, se \\xi è una variabile aleatoria, l’integrale \\int_\\Omega \\xi dP rappresenta il valore atteso di \\xi, E[X].\nCambio di Variabili: E = \\mathbb{R}^d, \\mathcal{E} = \\mathcal{B}(\\mathbb{R}^d), e \\mu è la misura immagine di un vettore aleatorio \\xi. L’integrale di una funzione di \\xi, f(\\xi), potrà essere espresso come un integrale rispetto alla misura immagine.\n\n\nDefinizione dell’Integrale per Funzioni Semplici Positive\nPer iniziare a costruire la definizione generale dell’integrale, il professore introduce le funzioni semplici positive in forma canonica.\nFunzioni Semplici Positive in Forma Canonica\nUna funzione S: E \\to [0, +\\infty) è detta semplice positiva in forma canonica se esistono un numero finito m \\in \\mathbb{N}, costanti c_i \\ge 0 per i = 1, \\dots, m, e insiemi misurabili A_i \\in \\mathcal{E} tali che:\n\nA_i \\cap A_j = \\emptyset per i \\neq j (gli insiemi formano una partizione).\n\\bigcup_{i=1}^m A_i = E (gli insiemi coprono tutto lo spazio).\nS(x) = \\sum_{i=1}^m c_i \\mathbb{1}_{A_i}(x), dove \\mathbb{1}_{A_i}(x) è la funzione indicatrice dell’insieme A_i (vale 1 se x \\in A_i e 0 altrimenti).\n\nUna funzione semplice è misurabile perché è una combinazione lineare di funzioni indicatrici di insiemi misurabili.\n\nDefinizione dell’Integrale per Funzioni Semplici Positive\nPer una funzione semplice positiva S in forma canonica come definita sopra, l’integrale di S rispetto alla misura \\mu  (sigma finita)è definito come la somma:\n\\int_E S (e) \\cdot \\mu (de) = \\sum_{i=1}^m c_i \\mu(E_i) \\in [0, + \\infty]\ndove \\mu(A_i) è la misura dell’insieme A_i. Si noti che questo valore può essere anche +\\infty se \\mu(A_i) = +\\infty per qualche i con c_i &gt; 0.\nIl professore osserva che questa definizione è analoga al valore atteso per variabili discrete, dove si sommano i valori assunti dalla variabile moltiplicati per le loro probabilità. In questo caso, i valori c_i giocano il ruolo dei valori della variabile, e le misure \\mu(A_i) giocano il ruolo dei pesi (o probabilità, nel caso di misure di probabilità).\nIl passo successivo sarà estendere questa definizione di integrale a funzioni misurabili più generali.\nReferences\nappunti bussetti- lez10.pdf\n2025-04-07 12:31\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine  probabilità\nprob-lez11\nDefinizione dell’Integrale di Lebesgue\nIntroduzione al Problema e Funzioni Semplici Positive\nOggi affronteremo il problema di definire l’integrale di una funzione s che va da uno spazio di misura (E, \\mathcal{A}, \\mu) (dove E è uno spazio, \\mathcal{A} una \\sigma-algebra e \\mu una misura \\sigma-finita) a valori nei Boreliani di \\mathbb{R} o \\mathbb{R} esteso (\\overline{\\mathbb{R}} = \\mathbb{R} \\cup {-\\infty, +\\infty}) con i Boreliani di \\overline{\\mathbb{R}}.\nLa prima cosa che facciamo è definire l’integrale per una funzione semplice. Una funzione semplice s è costante a tratti su certi insiemi A_i \\in \\mathcal{A} che formano una partizione di E. Consideriamo inizialmente il caso in cui i valori c_i assunti dalla funzione semplice sono tutti maggiori o uguali di 0 (c_i \\ge 0) e gli insiemi A_i formano una partizione di E (E = \\bigcup_i A_i con A_i \\cap A_j = \\emptyset per i \\neq j). In questo caso, s è detta funzione semplice positiva.\nPer una funzione semplice positiva s(x) = \\sum_i c_i \\mathbb{1}_{A_i}(x) (dove \\mathbb{1}_{A_i}(x) è la funzione indicatrice di A_i), definiamo l’integrale di s rispetto a \\mu su E come:\n\\qquad \\int_E s (e) \\cdot \\mu(de) = \\sum_i c_i \\mu(A_i)\nQuesto è un numero maggiore o uguale di 0, poiché c_i \\ge 0 e \\mu(A_i) \\ge 0. Potrebbe anche essere +\\infty se \\mu(A_i) = +\\infty per qualche i con c_i &gt; 0, anche se la somma ha un numero finito di termini. Ad esempio, se \\mu è la misura di Lebesgue su \\mathbb{R}, e A_1 = (-\\infty, 0], A_2 = (0, +\\infty), allora \\mu(A_1) = +\\infty e \\mu(A_2) = +\\infty, e se la nostra funzione semplice è costante su questi insiemi con valori positivi, l’integrale sarà +\\infty. Nonostante ciò, questa definizione è ben posta.\nEstensione dell’Integrale a Funzioni Misurabili Positive\nPer definire l’integrale per una generica funzione misurabile positiva \\xi: E \\to \\overline {\\mathbb{R}}, utilizziamo un processo di approssimazione tramite funzioni semplici.\nProposizione:\nSia \\xi: E \\to \\overline {\\mathbb{R}} una funzione misurabile positiva\n\nEsiste una successione (s_n)_{n \\in \\mathbb{N}} di funzioni semplici positive tali che (s_n(x)) converge a \\xi(x) in modo monotono crescente per ogni x \\in E.\nQuesto significa che per ogni n e per ogni x \\in E, s_n(x) \\le s_{n+1}(x), e \\lim_{n \\to \\infty} s_n(x) = \\xi(x).\n\nSe (s_n)_{n \\in \\mathbb{N}} e (s&#039;_n)_{n \\in \\mathbb{N}} sono due successioni di funzioni semplici positive che convergono a \\xi in modo monotono crescente,\nallora: \\qquad \\lim_{n \\to \\infty} \\int_E s_n (e) \\cdot \\mu(de) = \\lim_{n \\to \\infty} \\int_E s&#039;_n (e) \\cdot \\mu(de) Questo implica che il limite degli integrali non dipende dalla particolare successione approssimante scelta. Inoltre, si afferma implicitamente che questi limiti esistono.\n\nDefinizione dell’integrale di una funzione misurabile positiva:\nSia \\xi: E \\to \\overline {\\mathbb{R}} una funzione misurabile positiva. Definiamo l’integrale di \\xi rispetto a \\mu su E come:\n\\qquad \\int_E  \\xi (e) \\cdot \\mu (de) = \\lim_{n \\to \\infty} \\int_E s_n(e) \\mu(de)\ndove (s_n)_{n \\in \\mathbb{N}} è una qualsiasi successione di funzioni semplici positive che converge a \\xi in modo monotono crescente (la cui esistenza è garantita dal punto 1 della proposizione precedente). In virtù del punto 2 della stessa proposizione, questo limite è ben definito e non dipende dalla scelta specifica della successione (s_n). Questo valore può essere un numero finito non negativo o +\\infty.\n\nSe \\int_E  \\xi (e) \\cdot \\mu (de)&lt; +\\infty, diciamo che la funzione \\xi è integrabile rispetto a \\mu e si dice che un integrale finito.\nIntuizione della costruzione (facoltativa):\nLa costruzione di Lebesgue differisce dall’integrale di Riemann nel modo in cui viene effettuata la partizione. Nell’integrale di Riemann, si partiziona il dominio (lo spazio di partenza), e si approssima la funzione con valori costanti su questi intervalli.\nNell’integrale di Lebesgue, l’idea è di partizionare il codominio (lo spazio di arrivo) e poi considerare le controimmagini di questi intervalli nel dominio. Per una funzione positiva, si suddivide l’asse reale non negativo in intervalli (ad esempio, [0, 1/2), [1/2, 1), [1, 3/2), \\dots) e si guarda la misura degli insiemi del dominio dove la funzione cade in ciascuno di questi intervalli. Si costruisce così una funzione semplice che approssima la funzione originale dal basso. Raffinando la partizione del codominio, si ottiene una successione di funzioni semplici monotone crescenti che convergono alla funzione originale.\n\nDefinizione dell’Integrale per Funzioni Misurabili Generali\n\n(parte negativa tratteggiata, positiva ricalcata)\nConsideriamo ora una funzione misurabile \\xi: E \\to \\overline{\\mathbb{R}} che può assumere valori sia positivi che negativi. Possiamo sempre scrivere \\xi come la differenza tra la sua parte positiva \\xi^+ = \\max(\\xi, 0) e la sua parte negativa \\xi^- = \\max(-\\xi, 0):\n\\qquad |\\xi| = \\xi^+ - \\xi^-\nSia \\xi^+ (x) = \\begin{cases} \\xi(x) &amp; \\text{se } \\xi(x) \\ge 0 \\\\ 0 &amp; \\text{se } \\xi(x) &lt; 0 \\end{cases} e \\xi^- (x) = \\begin{cases} 0 &amp; \\text{se } \\xi(x) \\ge 0 \\\\ -\\xi(x) &amp; \\text{se } \\xi(x) &lt; 0 \\end{cases}\nSe \\xi è misurabile, allora anche \\xi^+ e \\xi^- sono funzioni misurabili e positive. Possiamo quindi definire i loro integrali \\int_E \\xi^+ (e) \\cdot \\mu(de) e \\int_E \\xi^- (e) \\cdot \\mu(de), che saranno numeri in [0, +\\infty].\nDefinizione dell’integrale di una funzione misurabile generale:\nDefiniamo l’integrale di \\xi rispetto a \\mu su E come:\n\\qquad \\int_E \\xi (e) \\cdot \\mu(de) = \\int_E \\xi^+ (e) \\cdot \\mu(de) - \\int_E \\xi^- (e) \\cdot \\mu(de)\nQuesta definizione ha senso se almeno uno tra \\int_E \\xi^+ (e) \\cdot \\mu(de) e \\int_E \\xi^- (e) \\cdot \\mu(de) è finito.\n\nSe \\int_E \\xi^+ (e) \\cdot \\mu(de) &lt; +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) &lt; +\\infty, allora diciamo che \\xi è integrabile con integrale finito rispetto a \\mu, e il suo integrale è un numero finito.\n\nSe \\int_E \\xi^+ (e) \\cdot \\mu(de) = +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) &lt; +\\infty, allora poniamo \\int_E \\xi (e) \\cdot \\mu(de) = +\\infty.\nSe \\int_E \\xi^+ (e) \\cdot \\mu(de) &lt; +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) = +\\infty, allora poniamo \\int_E \\xi (e) \\cdot \\mu(de) = -\\infty.\nSe \\int_E \\xi^+ (e) \\cdot \\mu(de) = +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) = +\\infty, allora l’integrale di \\xi rispetto a \\mu è indefinito.\n\nOsserviamo anche che il modulo di \\xi può essere scritto come |\\xi| = \\xi^+ + \\xi^-.\nProposizione:\nUna funzione misurabile \\xi è integrabile (con integrale finito) se e solo se \\int_E |\\xi| (e) \\cdot \\mu(de) &lt; +\\infty. In questo caso, \\int_E \\xi^+ (e) \\cdot \\mu(de) &lt; +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) &lt; +\\infty.\n\n(per dire che si ammette integrale basterà allora testare sul valore assoluto della funzione \\xi)\n\nIntegrabilità di una Funzione Misurabile\nPer garantire che l’integrale di una funzione misurabile \\xi sia ben definito (cioè che non si abbia la forma \\infty - \\infty), si richiede che l’integrale del modulo della funzione sia finito: \\int |\\xi| \\mu(de) &lt; \\infty\nSe il valore assoluto di una funzione misurabile \\xi è integrabile (ha integrale finito), allora automaticamente gli integrali della parte positiva (\\int \\xi^+ \\mu(de)) e della parte negativa (\\int \\xi^- \\mu(de)) sono finiti, e quindi la funzione \\xi ammette un integrale finito.\nIntegrale su un Insieme Misurabile\nSe A appartiene alla \\sigma-algebra \\mathcal{E}, si può definire l’integrale di una funzione misurabile \\xi ristretto all’insieme A: \\int_A \\xi(e) \\cdot \\mu(de) = \\int \\xi(e) \\cdot \\mathbb{1}_A \\mu(de)\ndove \\mathbb{1}_A è la funzione indicatrice dell’insieme A, definita come: \\mathbb{1}_A(x) = \\begin{cases} 1 &amp; \\text{se } x \\in A \\\\ 0 &amp; \\text{se } x \\notin A \\end{cases}\nQuesta definizione intuitivamente significa considerare la funzione \\xi che vale zero al di fuori dell’insieme A. La funzione \\xi \\cdot \\mathbb{1}_A è misurabile perché è il prodotto di due funzioni misurabili. Ci si può poi chiedere se questa nuova funzione sia integrabile. Questa operazione di restringere l’integrazione a un sottoinsieme misurabile non sempre funziona con l’integrale di Riemann.\nProprietà dell’Integrale Astratto\nSia (E, \\mathcal{E}, \\mu) uno spazio di misura con \\mu \\sigma-finita, e siano \\xi, \\xi_1, \\xi_2 funzioni misurabili da E a \\mathbb{R} \\cup \\set{-\\infty, +\\infty}.\n1. Monotonia\nSe \\xi \\ge 0 per ogni e \\in E, allora: \\int_E \\xi(e) \\cdot \\mu(de) \\ge 0\nQuesta proprietà segue direttamente dalla definizione dell’integrale per funzioni positive, che si basa su limiti di integrali di funzioni semplici positive.\n2. Linearità\nSe A, B \\in \\mathbb{R} e \\xi_1, \\xi_2 sono integrabili (hanno integrale finito), allora A\\xi_1 + B\\xi_2 è integrabile e: \\int_E (A\\xi_1 + B\\xi_2) \\mu(de) = A \\int_E \\xi_1 \\mu(de) + B \\int_E \\xi_2 \\mu(de)\nQuesta proprietà mostra che l’integrale è un operatore lineare, analogo alla linearità della somma per variabili aleatorie discrete e dell’integrale di Riemann.\n\n3. Insensitività agli Insiemi di Misura Nulla (?)\nSia A \\in \\mathcal{E} tale che \\mu(A) = 0. Se \\xi è integrabile, allora: \\int_A \\xi(e) \\cdot \\mu(de) = 0\nQuindi, l’integrale di una funzione integrabile su un insieme di misura nulla è zero.\nUna conseguenza importante di questa proprietà e della linearità è la seguente: se \\xi_1 e \\xi_2 sono integrabili e l’insieme {e \\in E \\mid \\xi_1(e) \\neq \\xi_2(e)} ha misura zero, allora: \\int_E \\xi_1 \\mu(de) = \\int_E \\xi_2 \\mu(de)\nQuesto significa che se si modifica una funzione integrabile su un insieme di misura nulla, il suo integrale non cambia. Questa è una differenza significativa rispetto all’integrale di Riemann.\n\n4. Teorema di Convergenza Monotona (MCT)\nSia (\\xi_n)_{n \\in \\mathbb{N}} una successione di funzioni misurabili tali che 0 \\le \\xi_n \\le \\xi_{n+1} per ogni n, e sia \\xi(e) = \\lim_{n \\to \\infty} \\xi_n(e) per ogni e \\in E. Allora: \\lim_{n \\to \\infty} \\int_E \\xi_n \\mu(de) = \\int_E \\xi(e) \\cdot \\mu(de)\nEquivalentemente, si può “portare il limite dentro l’integrale” in questo caso: \\lim_{n \\to \\infty} \\int_E \\xi_n(e) \\mu(de) = \\int_E \\left( \\lim_{n \\to \\infty} \\xi_n(e) \\right) \\mu(de)\nLe ipotesi di positività e convergenza monotona sono cruciali per questo teorema. Il limite degli integrali può anche essere +\\infty se l’integrale della funzione limite è +\\infty. Questo teorema non è generalmente valido per l’integrale di Riemann.\n5. Convergenza per Serie\nSia (\\xi_n)_{n \\in \\mathbb{N}} una successione di funzioni misurabili tali che \\xi_n \\ge 0 per ogni n. Allora: \\sum_{n=1}^{\\infty} \\int_E \\xi_n \\mu(de) = \\int_E \\left( \\sum_{n=1}^{\\infty} \\xi_n \\right) \\mu(de)\nAnche in questo caso, si può “scambiare la somma con l’integrale”, a condizione che le funzioni siano non negative. Questa proprietà può essere dimostrata usando il Teorema di Convergenza Monotona. I valori di entrambe le espressioni possono essere finiti o +\\infty.\n\n6. Integrabilità e Valori Finiti Quasi Ovunque\nSe \\xi è una funzione misurabile a valori in \\mathbb{R} \\cup {-\\infty, +\\infty} e \\int_E |\\xi (e)| \\mu(de) &lt; \\infty (cioè \\xi è integrabile), allora la misura dell’insieme \\set{e:|\\xi(e)| = +\\infty} è zero: \\mu\\set{e:|\\xi(e)| = +\\infty} = 0\nQuindi, se una funzione ha integrale finito, essa può assumere valori \\pm \\infty solo su un insieme di misura nulla. Di conseguenza, se si sa che \\int_E |\\xi| \\mu(de) &lt; \\infty, allora la funzione \\xi è finitamente valutata quasi ovunque. Questo implica che nella convergenza per serie, se \\sum_{n=1}^{\\infty} \\int_E \\xi_n \\mu(de) &lt; \\infty, allora la serie \\sum_{n=1}^{\\infty} \\xi_n(e) converge per quasi ogni e \\in E.\n\nEsempi\nEsempio 1: Integrale rispetto a una misura discreta\nSi consideri una misura \\mu definita come: \\mu = \\sum_{n} \\pi_n \\delta_{e_n} (de)\ndove (\\pi_n) è una successione di pesi positivi, (e_n) è una successione di punti in E, e \\delta_{e_n} (de) è la misura di Dirac nel punto e_n. L’integrale di una funzione \\xi rispetto a questa misura è dato da: \\int_E \\xi(e) \\cdot \\mu(de) = \\sum_{n\\ge1} \\xi(e_n) \\pi_n\nLa condizione di integrabilità in questo caso diventa \\sum_{n} |\\xi(e_n)| \\pi_n &lt; \\infty. L’integrale è quindi una serie pesata dei valori della funzione nei punti che supportano la misura. Se tutti i \\pi_n = 1 e E = \\mathbb{N} (o \\mathbb{Z}), allora l’integrale di \\xi su \\mathbb{R} è la serie \\sum_{n} \\xi(n), se questa è ben definita (cioè converge assolutamente).\n\nEsempio 2: Valore atteso di una variabile aleatoria discreta\nSia X una variabile aleatoria discreta a valori in \\mathbb{R}. Il valore atteso di X è definito come: E[X] = \\sum_{x} x P(X=x) = \\sum_{i} x_i P(X=x_i)\ndove (x_i) sono i possibili valori di X e P(X=x_i) sono le rispettive probabilità. Si scopre che questo valore atteso coincide con l’integrale astratto di X su \\Omega rispetto alla misura di probabilità P: E[X] = \\int_{\\Omega} X(\\omega) P(d\\omega)\nInoltre, questo coincide anche con l’integrale astratto della funzione identità x \\mapsto x su \\mathbb{R} rispetto alla misura immagine P_X di P tramite X: E[X] = \\int_{\\mathbb{R}} x P_X(dx)\ndove P_X(A) = P(X \\in A) per A \\subseteq \\mathbb{R} misurabile. Nel caso discreto, la misura immagine P_X è una misura discreta concentrata sui valori assunti da X con pesi dati dalle probabilità.\n\nIntegrale di Lebesgue su \\mathbb{R}^d\nL’integrale di Lebesgue è un caso particolare dell’integrale astratto dove lo spazio di partenza è \\mathbb{R}^d, la \\sigma-algebra è quella dei boreliani \\mathcal{B}(\\mathbb{R}^d), e la misura \\mu è la misura di Lebesgue m su \\mathbb{R}^d. Una funzione h: \\mathbb{R}^d \\to \\mathbb{R} è detta misurabile se è borel-misurabile.\n\nL’integrale di Lebesgue di h(x) su \\mathbb{R}^d si scrive come: \\int_{\\mathbb{R}^d} h(x) Leb_D(dx)\ne più comunemente come: \\int_{\\mathbb{R}^d} h(x) dx oppure \\int_{\\mathbb{R}^d} h(x_1, ..., x_d) dx_1 ... dx_d\nQuesto integrale è ben definito per funzioni misurabili e può valere un numero finito o \\pm \\infty.\nRelazione tra Integrale di Lebesgue e Integrale di Riemann\nSostanzialmente, tutte le funzioni che si dovranno integrare saranno integrabili secondo Lebesgue, e l’integrale di Riemann coinciderà con l’integrale di Lebesgue quando entrambi sono definiti.\nIl problema principale con l’integrale di Riemann sorge quando si vuole integrare una funzione h(x) su un sottoinsieme A \\subseteq \\mathbb{R}^d: \\int_A h(x) dx = \\int_{\\mathbb{R}^d} h(x) \\mathbb{1}_A(x) dx\nSe A è un insieme la cui funzione indicatrice \\mathbb{1}_A non è integrabile secondo Riemann (come ad esempio A = \\mathbb{Q} \\cap [0,1]), allora l’integrale di Riemann non è definito, mentre l’integrale di Lebesgue lo è.\n\nD’altra parte, se il modulo di una funzione h è integrabile secondo Riemann (in senso improprio, se necessario) su \\mathbb{R}, allora h è integrabile secondo Lebesgue e i due integrali coincidono: \\int_{\\mathbb{R}} h(x) dx_{\\text{Lebesgue}} = \\int_{\\mathbb{R}} h(x) dx_{\\text{Riemann}}\nAd esempio, \\int_0^1 x^2 dx calcolato con l’integrale di Riemann darà lo stesso risultato se calcolato con l’integrale di Lebesgue. Analogamente per \\int_0^{2\\pi} \\sin(x) dx.\nEsistono però casi in cui l’integrale di Riemann in senso improprio è definito ma la funzione non è integrabile secondo Lebesgue (cioè l’integrale del modulo è infinito), come ad esempio alcune funzioni oscillanti. Tuttavia, per gli scopi del corso, gli integrali che si dovranno calcolare potranno essere risolti usando le tecniche dell’integrale di Riemann (teorema fondamentale del calcolo, cambio di variabili, integrazione per parti). È fondamentale però riconoscere che l’integrale di Lebesgue offre una teoria più generale, in particolare per l’integrazione su insiemi più complessi e per i teoremi di convergenza.\n\nCostruzione di Misure di Probabilità a Partire da Funzioni\nSia f: \\mathbb{R}^d \\to \\mathbb{R} una funzione tale che:\n\nf(x) \\ge 0 per ogni x \\in \\mathbb{R}^d\nf è misurabile (borel-misurabile)\n\\int_{\\mathbb{R}^d} f(x) dx = 1 (l’integrale è inteso nel senso di Lebesgue)\n\nAllora, la funzione di insieme P definita per ogni insieme boreliano A \\in \\mathcal{B}(\\mathbb{R}^d) come: P(A) = \\int_A f(x) dx = \\int_{\\mathbb{R}^d} \\mathbb{1}_A(x) f(x) dx\n\nè una misura di probabilità sui boreliani di \\mathbb{R}^d.\n\nDimostrazione:\n\nNon negatività: P(A) = \\int_A f(x) dx \\ge 0 per la proprietà di monotonia dell’integrale, poiché f(x) \\ge 0 e \\mathbb{1}_A(x) \\ge 0.\nProbabilità dello spazio totale: P(\\mathbb{R}^d) = \\int_{\\mathbb{R}^d} f(x) dx = 1 per ipotesi.\n\\sigma-additività: Sia (A_n)_{n \\in \\mathbb{N}} una successione di insiemi boreliani a due a due disgiunti. Allora: P\\left( \\bigcup_{n=1}^{\\infty} A_n \\right) = \\int_{\\mathbb{R}^d} \\mathbb{1}_{\\bigcup_{n=1}^{\\infty} A_n}(x) f(x) dx Poiché gli A_n sono disgiunti, \\mathbb{1}_{\\bigcup_{n=1}^{\\infty} A_n}(x) = \\sum_{n=1}^{\\infty} \\mathbb{1}_{A_n}(x). Quindi: P\\left( \\bigcup_{n=1}^{\\infty} A_n \\right) = \\int_{\\mathbb{R}^d} \\left( \\sum_{n=1}^{\\infty} \\mathbb{1}_{A_n}(x) \\right) f(x) dx Per la proprietà di convergenza per serie dell’integrale astratto (che si applica all’integrale di Lebesgue): P\\left( \\bigcup_{n=1}^{\\infty} A_n \\right) = \\sum_{n=1}^{\\infty} \\int_{\\mathbb{R}^d} \\mathbb{1}_{A_n}(x) f(x) dx = \\sum_{n=1}^{\\infty} P(A_n) Quindi, P è \\sigma-additiva.\n\nEsempio: La funzione f(x) = \\mathbb{1}_{[0, +\\infty)}(x) e^{-x} è misurabile e non negativa su \\mathbb{R}. Il suo integrale su \\mathbb{R} è: \\int_{\\mathbb{R}} f(x) dx = \\int_0^{+\\infty} e^{-x} dx = [-e^{-x}]_0^{+\\infty} = 0 - (-1) = 1. Quindi, questa funzione f(x) definisce una misura di probabilità sui boreliani di \\mathbb{R} tramite P(A) = \\int_A e^{-x} \\mathbb{1}_{[0, +\\infty)}(x) dx.\n\nLa possibilità di costruire misure di probabilità in questo modo, integrando su insiemi che potrebbero avere indicatori non Riemann-integrabili, è una delle motivazioni per l’uso dell’integrale di Lebesgue.\nReferences\nappunti bussetti- lez11.pdf\n2025-04-08 11:03\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nprob-lez12\nVettori Assolutamente Continui\nRichiami sull’Integrale Astratto e Misure di Probabilità\nIl professore inizia ricordando un risultato fondamentale collegato all’integrale astratto.\nProposizione: Sia f una funzione tale che f(x) \\ge 0 per ogni x \\in \\mathbb{R}^d e \\int_{\\mathbb{R}^d} f(x) dx = 1, dove l’integrale è inteso nel senso di Lebesgue. Allora, la funzione che associa ad ogni boreliano A \\subseteq \\mathbb{R}^d il valore \\int_A f(x) dx definisce una misura di probabilità sui boreliani di \\mathbb{R}^d.\nCommento: Questo significa che ogni funzione non negativa la cui integrale su tutto lo spazio sia unitario può essere vista come la densità di una misura di probabilità.\nDefinizione di Vettore Assolutamente Continuo\nPartendo da questa osservazione, il professore introduce la definizione di vettore aleatorio assolutamente continuo.\nDefinizione (Prima Forma): Un vettore aleatorio X definito su uno spazio di probabilità a valori in \\mathbb{R}^d (con la \\sigma-algebra dei boreliani) si dice con legge assolutamente continua se la sua funzione di ripartizione F_X(x), per ogni x = (x_1, \\dots, x_d) \\in \\mathbb{R}^d, può essere scritta come l’integrale multiplo di Lebesgue di una funzione f(y) \\ge 0 tale che \\int_{\\mathbb{R}^d} f(y) dy = 1. Nello specifico:\nF_X(x) = P(X_1 \\le x_1, \\dots, X_d \\le x_d) = \\int_{\\set{y \\in \\mathbb{R}^d: y_i \\le x_i, \\forall i=1,\\dots,d}} f_X(y) dy\nLa funzione f(x) è detta densità (o funzione di densità di probabilità, PDF) del vettore X.\nCommento: La funzione di ripartizione rappresenta la probabilità che il vettore aleatorio X cada nel “quadrante” (-\\infty, x_1] \\times \\dots \\times (-\\infty, x_d]. La definizione afferma che questa probabilità può essere calcolata integrando la densità su questo insieme.\n\nDefinizione Equivalente di Vettore Assolutamente Continuo\nIl professore presenta poi una definizione equivalente, più generale e spesso più utile.\nDefinizione (Seconda Forma): Un vettore aleatorio X è assolutamente continuo se esiste una funzione densità f_x(x) \\ge 0 con \\int_{\\mathbb{R}^d} f_x(x) dx = 1 tale che, per ogni insieme boreliano A \\subseteq \\mathbb{R}^d, la probabilità che X appartenga ad A sia data da:\nP(X \\in A) = \\int_A f(x) dx\nLa funzione f(x) è la densità del vettore X.\nDimostrazione dell’Equivalenza (Accennata):\n\nDalla seconda alla prima definizione: Se vale la seconda definizione, prendendo come insieme boreliano A il quadrante \\set{y \\in \\mathbb{R}^d: y_i \\le x_i, \\forall i=1,\\dots,d}, si ottiene direttamente la prima definizione.\nDalla prima alla seconda definizione: Si osserva che l’insieme dei quadranti definisce una classe \\mathcal{P} che genera tutti i boreliani di \\mathbb{R}^d. La funzione P&#039;(A) = \\int_A f(x) dx definisce una misura di probabilità sui boreliani. Per ipotesi (prima definizione), P(X \\in A) = P&#039;(A) per ogni A appartenente alla classe \\mathcal{P} dei quadranti. Poiché due misure di probabilità che coincidono su una classe \\mathcal{P} che genera la \\sigma-algebra devono coincidere su tutta la \\sigma-algebra, si ha che P(X \\in A) = \\int_A f(x) dx per ogni boreliano A \\subseteq \\mathbb{R}^d.\n\nCommento: La seconda definizione è più potente perché permette di calcolare la probabilità che il vettore aleatorio cada in qualsiasi insieme boreliano, non solo in particolari “quadranti”.\n\nRiassunto dei Tipi di Vettori Aleatori\nIl professore riassume i diversi modi per descrivere un vettore aleatorio. Dato un vettore aleatorio X a valori in \\mathbb{R}^d:\n\n\nLegge Immagine (o Misura di Probabilità Indotta): Si può sempre definire la misura di probabilità P_X(A) = P(X \\in A) per ogni boreliano A \\subseteq \\mathbb{R}^d.\n\n\nFunzione di Ripartizione: Si può sempre definire la funzione F_X(x) = P(X_1 \\le x_1, \\dots, X_d \\le x_d) per ogni x \\in \\mathbb{R}^d.\n\nPoi si distinguono due casi particolari:\n\n\nVettore Discreto: In questo caso, esiste un insieme numerabile di punti C \\subseteq \\mathbb{R}^d tale che P(X \\in C) = 1. Si può definire una densità discreta (o funzione di massa di probabilità) f_X(x) = P(X = x) per x \\in C, e f_X(x) = 0 altrimenti. La probabilità che X appartenga a un insieme A si ottiene sommando le probabilità dei punti di C contenuti in A: P(X \\in A) = \\sum_{x \\in A \\cap C} f_X(x).\n\n\nVettore Assolutamente Continuo: Come definito precedentemente, esiste una funzione di densità f_X(x) \\ge 0 con \\int_{\\mathbb{R}^d} f_X(x) dx = 1 tale che P(X \\in A) = \\int_A f_X(x) dx per ogni boreliano A \\subseteq \\mathbb{R}^d.\n\n\nCommento: Non tutte le leggi di probabilità rientrano in questi due casi (puramente discreto o assolutamente continuo), ma essi coprono una parte significativa delle distribuzioni utilizzate. In altri casi, si può ricorrere alla funzione di ripartizione per descrivere la legge di probabilità.\n\nRelazione tra Densità e Funzione di Ripartizione (Caso d=1)\nNel caso unidimensionale (d=1), esiste una relazione importante tra la funzione di ripartizione e la densità per variabili assolutamente continue.\nProposizione (Caso d=1): Se X è una variabile aleatoria assolutamente continua con densità f(x), allora la sua funzione di ripartizione F_X(x) è data da:\nF_X(x) = P(X \\le x) = \\int_{-\\infty}^{x} f(t) dt\nNel caso discreto, la funzione di ripartizione è data da:\nF_X(x) = P(X \\le x) = \\sum_{x_i \\le x} P(X = x_i) = \\sum_{x_i \\le x} f_X(x_i)\ndove la somma è estesa a tutti i valori x_i nel supporto (insieme numerabile di punti con probabilità non nulla) di X che sono minori o uguali a x. La funzione di ripartizione di una variabile discreta è una funzione costante a tratti.\n\nCommento: Nel caso assolutamente continuo, se la densità f(t) è continua in un punto x, allora la funzione di ripartizione F_X(x) è derivabile in quel punto e la sua derivata è uguale alla densità: F_X&#039;(x) = f(x) (Teorema Fondamentale del Calcolo)\nProprietà dei Vettori Assolutamente Continui\nIl professore sottolinea alcune importanti proprietà dei vettori assolutamente continui.\nProposizione: Se X è un vettore assolutamente continuo a valori in \\mathbb{R}^d, allora per ogni x \\in \\mathbb{R}^d, la probabilità che X sia esattamente uguale a x è zero:\nP(X = x) = 0\nDimostrazione: Un singolo punto x in \\mathbb{R}^d ha misura di Lebesgue zero. Quindi:\nP(X = x) = \\int_{{x}} f(y) dy = 0\ndove dx indica la misura di Lebesgue.\nProposizione: Se H \\subseteq \\mathbb{R}^d è un sottoinsieme con misura di Lebesgue nulla (ad esempio, un iperpiano di dimensione strettamente minore di d), allora la probabilità che X appartenga ad H è zero:\nP(X \\in H) = \\int_H f(y) dy = 0\nEsempio (Caso d=2): Se X = (X_1, X_2) è un vettore assolutamente continuo in \\mathbb{R}^2, allora la probabilità che X_1 = X_2 è zero. L’insieme {(x_1, x_2) \\in \\mathbb{R}^2: x_1 = x_2} è una retta (un iperpiano di dimensione 1 in \\mathbb{R}^2), che ha misura di Lebesgue zero.\nCommento: Questa proprietà può sembrare controintuitiva, ma significa che per una variabile assolutamente continua, non possiamo osservare un valore specifico con probabilità non nulla. Le probabilità sono associate a insiemi di misura positiva (intervalli, palle, ecc.) .\n\nDistinzione tra Probabilità Puntuale e Densità\nIl professore evidenzia una differenza cruciale :\nOsservazione: Per un vettore assolutamente continuo X con densità f(x):\n\nP(X = x) = 0 per ogni x \\in \\mathbb{R}^d .\nIl valore della densità f(x) in un punto x non rappresenta la probabilità che X sia uguale a x e non è necessariamente compreso tra 0 e 1 .\n\nCommento: La densità f(x) indica la “concentrazione” di probabilità attorno al punto x. Per ottenere una probabilità, è necessario integrare la densità su un insieme contenente x che abbia misura di Lebesgue positiva (un “volume” attorno a x) .\n\nContinuità della Funzione di Ripartizione (Caso d=1)\nProposizione (Caso d=1): Se X è una variabile aleatoria assolutamente continua, allora la sua funzione di ripartizione F_X(x) è continua ovunque .\nEsercizi, esempi e ulteriori passaggi matematici non sono presenti negli estratti forniti.\n\nVariabili Aleatorie Assolutamente Continue\nProbabilità di un Punto e Funzione di Ripartizione\nNel caso di una variabile aleatoria assolutamente continua, la probabilità di un singolo punto è sempre uguale a zero.\nP(X = x) = 0\nLa funzione di ripartizione (CDF), F_X(x) = P(X \\le x), associata a una variabile assolutamente continua può essere scritta come l’integrale della sua funzione di densità di probabilità (PDF), f_X(t):\nF_X(x) = \\int_{-\\infty}^{x} f_X(t) dt\nPer definizione, questa funzione di ripartizione F_X(x) è continua.\nDimostrazione (Accennata): Questa proprietà deriva dal fatto che F_X(x) = \\int_{-\\infty}^{x} f(t) dt. L’integrale di Lebesgue è continuo rispetto al limite superiore di integrazione\nCommento: La continuità della funzione di ripartizione è una caratteristica delle variabili assolutamente continue e le distingue dalle variabili discrete, la cui funzione di ripartizione presenta dei salti nei punti in cui la variabile assume valori con probabilità positiva. Tuttavia, la continuità della funzione di ripartizione non implica necessariamente che la variabile sia assolutamente continua (esistono distribuzioni singolari continue) . Il viceversa è vero: se una variabile è assolutamente continua, la sua funzione di ripartizione è continua .\nAttenzione: Non è vero il viceversa. Si possono avere funzioni di ripartizione continue che non corrispondono a leggi assolutamente continue. Un esempio è la funzione di Cantor (o scala del diavolo).\n\nMisure Non Atomiche\nIn dimensione d=1, le misure di probabilità che hanno una funzione di ripartizione continua sono dette non atomiche, il che significa che non esiste alcun punto con una massa di probabilità strettamente positiva.\nLa classe delle variabili aleatorie con legge assolutamente continua è un sottinsieme della classe più grande delle variabili aleatorie con funzione di ripartizione continua (non atomiche).\nSpesso si userà l’affermazione: “X ha legge assolutamente continua, quindi la sua funzione di ripartizione è assolutamente continua (e quindi continua)“. È importante non confondere “X assolutamente continua” con ”f_X(x) continua”.\nDefinizione di Legge Assolutamente Continua\nUna variabile aleatoria X ha una legge assolutamente continua se la sua funzione di ripartizione F_X(x) può essere espressa come l’integrale di una funzione f_X(t) positiva e integrabile (la densità):\nF_X(x) = \\int_{-\\infty}^{x} f_X(t) dt\nEsempio: Distribuzione Uniforme su (0, 1)\nConsideriamo una variabile aleatoria X distribuita uniformemente sull’intervallo (0, 1). La sua funzione di ripartizione F_X(x) è data da:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\\\ x &amp; \\text{se } 0 &lt; x &lt; 1 \\\\ 1 &amp; \\text{se } x \\ge 1 \\end{cases}\nPossiamo verificare che questa funzione di ripartizione può essere scritta come l’integrale di una densità f_X(t):\nf_X(t) = \\begin{cases} 1 &amp; \\text{se } 0 &lt; t &lt; 1 \\\\ 0 &amp; \\text{altrimenti} \\end{cases} \nInfatti, per ogni x \\in \\mathbb{R}:\n\\int_{-\\infty}^{x} f_X(t) dt = F_X(x)\nLa funzione f_X(t) è positiva, misurabile e il suo integrale su tutto \\mathbb{R} è uguale a 1:\n\\int_{-\\infty}^{\\infty} f_X(t) dt = \\int_{0}^{1} 1 dt = [t]_{0}^{1} = 1 - 0 = 1\nQuindi, la variabile aleatoria X con distribuzione uniforme su (0, 1) ha una legge assolutamente continua. Notiamo che la funzione di ripartizione F_X(x) è continua, mentre la sua densità f_X(t) non lo è (ha discontinuità nei punti t=0 e t=1). Questo conferma che l’assoluta continuità riguarda la legge (o la funzione di ripartizione), non necessariamente la densità.\n\nNon Unicità della Funzione di Densità\nLa funzione di densità f_X(x) per una variabile aleatoria assolutamente continua non è unica in senso stretto. Se modifichiamo la densità in un numero finito di punti (o più in generale, su un insieme di misura di Lebesgue nulla), la funzione di ripartizione associata non cambia.\nAd esempio, per la distribuzione uniforme su (0, 1), la densità potrebbe anche essere definita come:\nf&#039;_X(t) = \\begin{cases} 2 &amp; \\text{se } t = 0.5 \\\\ 1 &amp; \\text{se } 0 &lt; t &lt; 1, t \\neq 0.5 \\\\ 0 &amp; \\text{altrimenti} \\end{cases} \nQuesta f&#039;_X(t) è ancora una densità per la distribuzione uniforme su (0, 1) perché l’integrale di Lebesgue è insensibile a modifiche su insiemi di misura nulla. Tuttavia, nella pratica, si sceglie una rappresentazione conveniente della densità.\nLa densità contiene informazioni sulla probabilità di un intorno, non sul valore puntuale.\n\nDefinizione di Leggi Assolutamente Continue Tramite la Densità\nSpesso, le variabili aleatorie assolutamente continue vengono definite direttamente specificando la loro funzione di densità. Ad esempio:\n\nX ha una legge uniforme se la sua densità è costante su un intervallo e zero altrove.\nX ha una legge esponenziale se la sua densità ha una specifica forma funzionale (come vedremo in seguito).\nX ha una legge Gamma, ecc..\n\nIn questi casi, si assume che la variabile aleatoria sia assolutamente continua con la densità data.\nVerifica dell’Assoluta Continuità a Partire dalla Funzione di Ripartizione\nPer verificare se una funzione di ripartizione F(x) corrisponde a una variabile aleatoria assolutamente continua, si deve controllare se esiste una funzione positiva e integrabile f(t) tale che per ogni x:\nF(x) = \\int_{-\\infty}^{x} f(t) dt\nSe si riesce a trovare tale funzione f(t), allora essa è la densità della variabile aleatoria.\nIn dimensione uno, un modo pratico per trovare la densità, se esiste, è calcolare la derivata della funzione di ripartizione.\nRelazione tra Funzione di Ripartizione e Densità Tramite la Derivazione\nSe la funzione di ripartizione F_X(x) è derivabile su \\mathbb{R} meno un insieme finito di punti, allora la sua derivata è uguale alla funzione di densità di probabilità f_X(x) nei punti di derivabilità:\nf_X(x) = \\frac{d}{dx} F_X(x)\n\nEsempio: Distribuzione Uniforme (Riconsiderata)\nLa funzione di ripartizione della distribuzione uniforme su (0, 1) è:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\\\ x &amp; \\text{se } 0 &lt; x &lt; 1 \\\\ 1 &amp; \\text{se } x \\ge 1 \\end{cases}\nLa sua derivata è:\n\\frac{d}{dx} F_X(x) = \\begin{cases} 0 &amp; \\text{se } x &lt; 0 \\\\ 1 &amp; \\text{se } 0 &lt; x &lt; 1 \\\\ 0 &amp; \\text{se } x &gt; 1 \\end{cases}\nQuesta derivata coincide con la densità f_X(x) definita in precedenza, eccetto che nei punti x=0 e x=1 dove la derivata non esiste. Tuttavia, poiché questi sono solo due punti (un insieme di misura nulla), ciò non influisce sull’integrale.\n\nControesempio: Variabile Aleatoria Discreta\nConsideriamo una variabile aleatoria X tale che P(X = 0) = 1. La sua funzione di ripartizione è:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x &lt; 0 \\\\ 1 &amp; \\text{se } x \\ge 0 \\end{cases}\nQuesta funzione di ripartizione non è continua in x=0. Pertanto, la variabile aleatoria X non è assolutamente continua. Inoltre, la sua derivata è zero ovunque tranne in x=0 dove non è definita, e una funzione che è zero quasi ovunque non può integrare a 1 (che è la probabilità totale).\nApproccio Operativo per Trovare la Densità\nSe si sa che una variabile aleatoria è assolutamente continua, la sua densità può essere trovata derivando la funzione di ripartizione dove essa è derivabile (tipicamente ovunque tranne un insieme finito di punti).\nEsempio: Distribuzione Esponenziale\nConsideriamo una variabile aleatoria X con distribuzione esponenziale di parametro \\lambda &gt; 0. Si definisce che X è assolutamente continua con funzione di densità:\nf_X(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; \\text{se } x &gt; 0 \\\\ 0 &amp; \\text{se } x \\le 0 \\end{cases} \nVerifichiamo che questa è una densità: è positiva per x &gt; 0. Calcoliamo l’integrale su tutto \\mathbb{R}:\n\\int_{-\\infty}^{\\infty} f_X(x) dx = \\int_{0}^{\\infty} \\lambda e^{-\\lambda x} dx\nLa primitiva di \\lambda e^{-\\lambda x} è -e^{-\\lambda x}. Quindi:\n\\begin{aligned} \\int_{0}^{\\infty} \\lambda e^{-\\lambda x} dx = \\lim_{b \\to \\infty} [-e^{-\\lambda x}]_{0}^{b} = \\\\ \\\\ \\lim_{b \\to \\infty} (-e^{-\\lambda b} - (-e^{0})) = (0 - (-1)) = 1 \\end{aligned}\nQuindi f_X(x) è una funzione di densità. Calcoliamo ora la funzione di ripartizione F_X(x) = P(X \\le x) = \\int_{-\\infty}^{x} f_X(t) dt:\n\nSe x &lt; 0: F_X(x) = \\int_{-\\infty}^{x} 0 dt = 0\nSe x \\ge 0: \\begin{aligned} F_X(x) = \\int_{-\\infty}^{0} 0 dt + \\int_{0}^{x} \\lambda e^{-\\lambda t} dt =\\\\ 0 + [-e^{-\\lambda t}]_{0}^{x} = -e^{-\\lambda x} - (-e^{0}) = 1 - e^{-\\lambda x}\\end{aligned} \n\nQuindi la funzione di ripartizione della distribuzione esponenziale è:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x &lt; 0 \\\\ 1 - e^{-\\lambda x} &amp; \\text{se } x \\ge 0 \\end{cases}\nQuesta funzione F_X(x) è continua. La sua derivata per x &gt; 0 è \\frac{d}{dx} (1 - e^{-\\lambda x}) = -(-\\lambda) e^{-\\lambda x} = \\lambda e^{-\\lambda x}, che coincide con la densità f_X(x) per x &gt; 0.\n\nChiarimento sulla Definizione di Assoluta Continuità e il Ruolo di \\Omega\nEssere assolutamente continua non presuppone necessariamente la conoscenza esplicita della funzione di ripartizione. La definizione formale si basa sull’esistenza di una densità.\nDal punto di vista teorico, una variabile aleatoria X è definita su uno spazio probabilistico (\\Omega, \\mathcal{F}, P). La sua legge (o distribuzione) è una misura di probabilità su \\mathbb{R}. Dire che X è assolutamente continua significa che questa misura di probabilità è assolutamente continua rispetto alla misura di Lebesgue, il che implica l’esistenza di una densità f_X.\nIn pratica, spesso si definisce una variabile aleatoria assolutamente continua specificando la sua densità f_X(x), che è una funzione positiva che integra a 1. Data una tale densità, si può definire una misura di probabilità e quindi (teoricamente) trovare uno spazio (\\Omega, \\mathcal{F}, P) e una variabile aleatoria X: \\Omega \\to \\mathbb{R} che abbia quella densità. Tuttavia, nella maggior parte delle applicazioni, non è necessario costruire esplicitamente \\Omega; è sufficiente lavorare con la densità.\nIn sintesi, quando si dice che X è assolutamente continua con una certa densità, si sta affermando che esiste uno spazio probabilistico sottostante tale che la variabile aleatoria X ha quella specifica densità, e quindi la sua funzione di ripartizione può essere ottenuta integrando tale densità.\nUnicità della Variabile Aleatoria Data una Densità\nAffermazione: Data una funzione di densità, non esiste un’unica variabile aleatoria che la possieda.\nCommento: Questa affermazione è valida anche per le funzioni di ripartizione (CDF), sebbene questo aspetto non sarà centrale per la discussione. L’analogia viene fatta con la distribuzione uniforme, dove, pur avendo una specifica funzione di ripartizione uniforme, è possibile costruire diverse variabili aleatorie che seguono tale distribuzione.\nEsempio: Si possono costruire in diversi modi variabili aleatorie distinte che condividono la stessa legge di probabilità.\nImplicazione: La definizione di una variabile aleatoria attraverso la sua densità o funzione di ripartizione fornisce informazioni sulla legge immagine di X, ovvero sulla distribuzione di probabilità dei valori che X può assumere. Per i calcoli, si può fare riferimento allo spazio campionario \\Omega, ma domande specifiche che dipendono dalla struttura di \\Omega potrebbero non essere risolvibili unicamente conoscendo la legge di X.\nEsempio: Se X è una variabile aleatoria geometrica, la sua legge è definita senza specificare lo spazio campionario \\Omega. È possibile calcolare il valore atteso di X con queste informazioni. Tuttavia, per sapere quali elementi \\omega \\in \\Omega corrispondono a un valore specifico di X, come X=3, è necessario conoscere la struttura di \\Omega.\nConclusione: Molte proprietà di una variabile aleatoria, come il valore atteso, dipendono solo dalla sua legge (e quindi, nel caso assolutamente continuo, dalla sua densità) e non dalla specifica realizzazione sullo spazio campionario \\Omega.\nProprietà della Distribuzione Esponenziale\nIl professore introduce la distribuzione esponenziale come esempio di variabile aleatoria assolutamente continua.\nProbabilità che X sia Maggiore o Uguale a Zero\nProprietà: Per una variabile aleatoria X con legge esponenziale, P(X \\ge 0) = 1.\nDimostrazione 1 (Integrale della Densità): \\begin{align}  P(X \\ge 0) =\\\\ \\int_{0}^{+\\infty} f(x) dx =  \\int_{0}^{+\\infty} \\lambda e^{-\\lambda x} dx = \\\\ [ -e^{-\\lambda x} ]_{0}^{+\\infty} =  -e^{-\\infty} - (-e^{0}) = 0 - (-1) = 1 \\end{align}.\nDimostrazione 2 (Funzione di Ripartizione): La funzione di ripartizione F(x) per una variabile aleatoria esponenziale è data da F(x) = 1 - e^{-\\lambda x} per x \\ge 0 e 0 per x &lt; 0. P(X \\ge 0) = 1 - P(X &lt; 0) = 1 - F(0^-) = 1 - 0 = 1. Oppure, P(X \\ge 0) = 1 - P(X &lt; 0). Poiché per x&lt;0, F(x)=0, allora P(X&lt;0) = \\lim_{x \\to 0^-} F(x) = 0. Quindi P(X \\ge 0) = 1 - 0 = 1.\nAssenza di Memoria della Distribuzione Esponenziale\nProblema: Calcolare la probabilità condizionata P(X &gt; t + s | X &gt; t) per s, t &gt; 0, dove X è una variabile aleatoria esponenziale di parametro \\lambda.\nDefinizione di Probabilità Condizionata: P(A | B) = \\frac{P(A \\cap B)}{P(B)}\nApplicazione al Problema: P(X &gt; t + s | X &gt; t) = \\frac{P(X &gt; t + s \\cap X &gt; t)}{P(X &gt; t)}.\nOsservazione sull’intersezione degli eventi: Se X &gt; t + s, allora necessariamente X &gt; t (poiché s &gt; 0). Quindi, l’evento {X &gt; t + s} è contenuto nell’evento {X &gt; t}, e la loro intersezione è l’evento più “piccolo”: {X &gt; t + s} \\cap {X &gt; t} = {X &gt; t + s}.\nCalcolo di P(X &gt; u): P(X &gt; u) = 1 - P(X \\le u) = 1 - F(u). Per u &gt; 0, F(u) = 1 - e^{-\\lambda u}, quindi P(X &gt; u) = 1 - (1 - e^{-\\lambda u}) = e^{-\\lambda u}.\nCalcolo della Probabilità Condizionata: P(X &gt; t + s | X &gt; t) = \\frac{P(X &gt; t + s)}{P(X &gt; t)} = \\frac{e^{-\\lambda (t + s)}}{e^{-\\lambda t}} = e^{-\\lambda t - \\lambda s + \\lambda t} = e^{-\\lambda s}.\nInterpretazione: Si osserva che e^{-\\lambda s} = P(X &gt; s). Quindi, P(X &gt; t + s | X &gt; t) = P(X &gt; s).\nConclusione (Proprietà di Assenza di Memoria): La probabilità che un guasto (o un evento modellato da una distribuzione esponenziale) non si verifichi per un ulteriore tempo s, dato che non si è verificato fino al tempo t, è uguale alla probabilità che non si verifichi per un tempo s a partire dall’istante iniziale (tempo zero). In altre parole, la “memoria” del processo si azzera.\n\nEsempio Pratico (Affidabilità di una Macchina): Se X rappresenta il tempo di guasto di una macchina, la proprietà di assenza di memoria implica che la probabilità che una macchina che ha funzionato per t unità di tempo continui a funzionare per altre s unità di tempo è la stessa della probabilità che una macchina nuova funzioni per s unità di tempo.\nCritica del Modello Esponenziale per Guasti Reali: Questa proprietà di assenza di memoria potrebbe non essere realistica per modellare il guasto di macchine reali, in cui la probabilità di guasto tende ad aumentare con l’usura.\nEstensione alla Distribuzione Geometrica (Discreta): Il professore menziona che la distribuzione geometrica (nel caso discreto) possiede una proprietà analoga di assenza di memoria.\nUnicità tra le Distribuzioni Continue Positive: Tra le variabili aleatorie assolutamente continue e positive, la distribuzione esponenziale è l’unica a godere della proprietà di assenza di memoria.\nAltri Esempi di Distribuzioni Assolutamente Continue\nDistribuzione Gaussiana (Normale)\nDefinizione: Una variabile aleatoria X si dice assolutamente continua con legge (o distribuzione) gaussiana (o normale) di parametri \\mu \\in \\mathbb{R} (media) e \\sigma^2 &gt; 0 (varianza) se la sua funzione di densità è data da: f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}, per x \\in \\mathbb{R}.\nVerifica che la Densità Integra a 1: \\int_{-\\infty}^{+\\infty} f(x) dx = \\int_{-\\infty}^{+\\infty} \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} dx Utilizzando il cambio di variabili t = \\frac{x - \\mu}{\\sigma}, si ha x = \\mu + \\sigma t e dx = \\sigma dt. Gli estremi di integrazione rimangono (-\\infty, +\\infty). \\int_{-\\infty}^{+\\infty} \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{t^2}{2}} \\sigma dt = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{+\\infty} e^{-\\frac{t^2}{2}} dt L’integrale \\int_{-\\infty}^{+\\infty} e^{-\\frac{t^2}{2}} dt = \\sqrt{2\\pi} (integrale gaussiano). Quindi, l’integrale della densità è \\frac{1}{\\sqrt{2\\pi}} \\sqrt{2\\pi} = 1.\n\nGaussiana Standard (Normale Standard): Un caso particolare è la gaussiana standard, con parametri \\mu = 0 e \\sigma^2 = 1. La sua densità è: \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\nFunzione di Ripartizione della Gaussiana: La funzione di ripartizione F(x) = P(X \\le x) = \\int_{-\\infty}^{x} f(t) dt non ha una forma chiusa esprimibile in termini di funzioni elementari (seno, coseno, esponenziale, ecc.). Può essere espressa in termini della funzione di errore (erf), che è comunque definita come un integrale.\n\nNotazione per la Funzione di Ripartizione della Gaussiana Standard: La funzione di ripartizione della gaussiana standard è spesso indicata con la lettera \\Phi(x).\nProprietà della Densità Gaussiana: La densità gaussiana è una funzione continua e derivabile ovunque.\nImportanza della Distribuzione Gaussiana: La distribuzione gaussiana è fondamentale nel calcolo delle probabilità e nella statistica, in particolare per il Teorema del Limite Centrale.\nDistribuzione di Cauchy\nDefinizione: Una variabile aleatoria X con distribuzione di Cauchy con parametri \\mu \\in \\mathbb{R} e \\sigma &gt; 0 ha una funzione di densità data da: f(x) = \\frac{1}{\\pi \\sigma \\left[ 1 + \\left( \\frac{x - \\mu}{\\sigma} \\right)^2 \\right]}\nSpesso, viene considerata la Cauchy standard con parametri \\mu = 0 e \\sigma = 1, la cui densità è: f(x) = \\frac{1}{\\pi (1 + x^2)}\nLa funzione di ripartizione della Cauchy con parametri \\mu e \\sigma è: F(x) = \\frac{1}{\\pi} \\arctan\\left( \\frac{x - \\mu}{\\sigma} \\right) + \\frac{1}{2}\nSimmetria della Gaussiana e della Cauchy: Sia la gaussiana standard che la Cauchy standard sono distribuzioni simmetriche rispetto allo zero. Una variabile aleatoria X ha la stessa legge di -X (indicato come X \\stackrel{\\mathcal{L}}{=} -X) se e solo se la sua distribuzione è simmetrica rispetto allo zero.\nVerifica della Simmetria: Per dimostrare che X \\stackrel{d}{=} -X, si può verificare che la funzione di ripartizione di X, F_X(x), è tale che F_X(x) = 1 - F_X(-x^-) = 1 - P(X &lt; -x). Alternativamente, si può mostrare che la densità f_X(x) è una funzione pari, ovvero f_X(x) = f_X(-x). Sia la densità gaussiana standard \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}} che la densità Cauchy standard f(x) = \\frac{1}{\\pi (1 + x^2)} soddisfano questa proprietà.\n\nCode Leggere vs. Code Pesanti\nComportamento delle Code: La differenza tra la distribuzione gaussiana e la Cauchy risiede nel comportamento delle loro code, ovvero come la densità si avvicina a zero per |x| \\to \\infty.\n\n\nGaussiana: La densità gaussiana decade esponenzialmente, come e^{-x^2/2}, quindi molto rapidamente. Si dice che la gaussiana ha code leggere. Questo implica che la probabilità di osservare valori molto distanti dalla media è molto bassa.\n\n\nCauchy: La densità di Cauchy decade come un polinomio, specificamente come \\frac{1}{x^2}. Questo decadimento è molto più lento rispetto all’esponenziale. Si dice che la Cauchy ha code pesanti. Ciò significa che la probabilità di osservare valori estremi è significativamente più alta rispetto a una distribuzione gaussiana con parametri simili.\n\n\nImplicazione per il Valore Atteso: La distribuzione di Cauchy è un esempio di variabile aleatoria che non ha un valore atteso finito, a causa del comportamento delle code della sua densità.\nValore Atteso e Varianza per Variabili Aleatorie Discrete (Ricapitolazione e Anticipazione)\nValore Atteso (Caso Discreto)\nPer una variabile aleatoria discreta X con funzione di massa di probabilità P(X = x_i) = p_i, il valore atteso (o media) di X, denotato con E[X], è definito come: E[X] = \\sum_{i} x_i p_i, ammesso che la somma converga assolutamente.\nSe g è una funzione reale, il valore atteso di g(X) è: E[g(X)] = \\sum_{i} g(x_i) p_i, ammesso che la somma converga assolutamente.\nVarianza (Caso Discreto)\nLa varianza di una variabile aleatoria discreta X, denotata con Var(X) o \\sigma^2_X, è definita come il valore atteso del quadrato della deviazione di X dalla sua media: Var(X) = E[(X - E[X])^2]\nLa varianza può anche essere calcolata utilizzando la seguente formula: Var(X) = E[X^2] - (E[X])^2\nSpiegazione: Var(X) = E[(X - \\mu)^2] = E[X^2 - 2\\mu X + \\mu^2] = E[X^2] - 2\\mu E[X] + E[\\mu^2] Dato che \\mu = E[X] è una costante, E[\\mu X] = \\mu E[X] = \\mu^2 e E[\\mu^2] = \\mu^2. Quindi, Var(X) = E[X^2] - 2\\mu^2 + \\mu^2 = E[X^2] - \\mu^2 = E[X^2] - (E[X])^2.\nUtilizzo della Definizione per Esercizi: Negli esercizi, per ora, si richiede di utilizzare la definizione di varianza per il suo calcolo. Le proprietà della varianza saranno studiate più avanti.\nReferences\n2025-03-19 11:06\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine. probabilità\nprob-lez13\nValore Atteso per Variabili Aleatorie Generali\nIntroduzione al Valore Atteso Generale\nL’argomento di oggi è l’estensione del concetto di valore atteso a variabili aleatorie qualunque, superando la definizione data per le sole variabili aleatorie discrete. L’obiettivo è definire il valore atteso in un contesto più generale, utilizzando la teoria dell’integrazione astratta.\nDefinizione Attraverso l’Integrale Astratto\nConsideriamo una variabile aleatoria X definita su uno spazio di probabilità (\\Omega, \\mathcal{F}, P), dove \\Omega è lo spazio campionario, \\mathcal{F} è la sigma-algebra degli eventi e P è la misura di probabilità. La variabile aleatoria X assume valori nei numeri reali Boreliani \\mathbb{R} (o eventualmente in \\mathbb{R} esteso) ed è una funzione misurabile X: \\Omega \\to \\mathbb{R} (o \\mathbb{R} \\cup {-\\infty, +\\infty}).\nL’integrale astratto di una funzione misurabile su uno spazio con una misura sigma-finita è un concetto matematico ben definito, sebbene la sua definizione rigorosa coinvolga l’approssimazione con funzioni semplici e il passaggio al limite.\nNel nostro caso, per definire il valore atteso di una variabile aleatoria X, utilizziamo l’integrale astratto con le seguenti specifiche scelte:\n\nLo spazio di misura è lo spazio di probabilità (\\Omega, \\mathcal{F}, P).\nLa funzione misurabile è la variabile aleatoria X: \\Omega \\to \\mathbb{R}.\n\nFormalmente, il valore atteso di X, denotato con E[X], è definito come l’integrale astratto di X rispetto alla misura di probabilità P su \\Omega:\nE[X] = \\int_\\Omega X(\\omega) dP(\\omega)\nÈ importante notare che questa notazione è, inizialmente, un simbolo che rappresenta un oggetto matematicamente ben definito sotto opportune condizioni. Affinché il valore atteso sia ben definito, in particolare, l’integrale astratto del modulo di X, \\int_\\Omega |X(\\omega)| dP(\\omega), deve essere finito.\nRichiamo al Caso Discreto\nQuando abbiamo introdotto il valore atteso per variabili aleatorie discrete, abbiamo implicitamente utilizzato questo concetto di integrale astratto con la specifica misura di probabilità definita sui punti dello spazio campionario discreto. La notazione \\int_\\Omega X(\\omega) dP(\\omega) nel caso discreto significa semplicemente applicare la definizione di integrale astratto a quella particolare scelta di P (la misura di probabilità discreta), di \\Omega (l’insieme discreto) e della variabile aleatoria X definita su di esso.\nDefinizione Costruttiva del Valore Atteso\nPer dare un senso più concreto al valore atteso, possiamo seguire una costruzione in tre passaggi:\n1. Valore Atteso per Variabili Aleatorie Semplici Positive\nUna variabile aleatoria semplice positiva X può essere espressa come una combinazione lineare finita di funzioni indicatrici di insiemi A_i \\in \\mathcal{F} con coefficienti c_i \\ge 0:\nX(\\omega) = \\sum_{i=1}^n c_i \\mathbf{1}_{A_i}(\\omega)\ndove \\mathbf{1}_{A_i}(\\omega) = 1 se \\omega \\in A_i e 0 altrimenti.\nIl valore atteso di una variabile aleatoria semplice positiva X è definito come:\nE[X] = \\sum_{i=1}^n c_i P(A_i)\n2. Valore Atteso per Variabili Aleatorie Positive Generali\nPer una variabile aleatoria X \\ge 0, non necessariamente semplice, si costruisce una successione di variabili aleatorie semplici positive {X_n}_{n \\ge 1} che converge monotonamente a X, cioè 0 \\le X_n(\\omega) \\le X_{n+1}(\\omega) \\le X(\\omega) per ogni \\omega \\in \\Omega e \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega).\nIl valore atteso di X è quindi definito come il limite dei valori attesi delle variabili semplici approssimanti:\nE[X] = \\lim_{n \\to \\infty} E[X_n]\nQuesto limite esiste (può essere finito o +\\infty) ed è indipendente dalla particolare successione di variabili semplici che converge monotonamente a X.\n3. Valore Atteso per Variabili Aleatorie Generali\nPer una variabile aleatoria X generica (che può assumere valori sia positivi che negativi), si considerano la sua parte positiva X^+ = \\max(X, 0) e la sua parte negativa X^- = \\max(-X, 0). Si ha che X = X^+ - X^- e |X| = X^+ + X^-.\nIl valore atteso di X è definito come:\nE[X] = E[X^+] - E[X^-]\npurché entrambi E[X^+] e E[X^-] siano finiti.\nSe uno solo tra E[X^+] e E[X^-] è infinito, allora E[X] è definito come +\\infty o -\\infty rispettivamente. Se entrambi E[X^+] e E[X^-] sono infiniti, allora il valore atteso di X non è ben definito.\nUna variabile aleatoria X è detta integrabile se il suo valore atteso del modulo è finito, cioè E[|X|] &lt; \\infty. Questa condizione è equivalente a richiedere che sia E[X^+] &lt; \\infty che E[X^-] &lt; \\infty. In questo caso, il valore atteso E[X] è un numero reale finito.\nDefinizione Alternativa del Valore Atteso\nEsiste una definizione alternativa del valore atteso di una variabile aleatoria X (anche non positiva) come l’estremo superiore dei valori attesi di tutte le variabili aleatorie semplici positive S che sono minori o uguali a X puntualmente:\nE[X] = \\sup {E[S] \\mid S \\text{ è semplice, } 0 \\le S(\\omega) \\le X(\\omega) \\text{ per ogni } \\omega \\in \\Omega }\nQuesta definizione è equivalente alla definizione costruttiva basata sul limite di variabili semplici approssimanti.\nNotazioni per il Valore Atteso\nOltre alla notazione E[X], si possono trovare anche le seguenti notazioni per il valore atteso:\n\n\\int_\\Omega X(\\omega) dP(\\omega) (integrale astratto esplicito)\n\\langle X \\rangle (usata spesso nella letteratura fisica)\n\nIl professore indica che userà prevalentemente la notazione E[X].\nProprietà del Valore Atteso\nPoiché il valore atteso è un caso particolare di integrale astratto (rispetto alla misura di probabilità P), esso eredita diverse proprietà. Vediamo alcune delle più importanti:\nLinearità\nSiano X_1 e X_2 due variabili aleatorie con valore atteso finito (integrabili) definite sullo stesso spazio di probabilità (\\Omega, \\mathcal{F}, P), e siano a, b \\in \\mathbb{R}. Allora la variabile aleatoria aX_1 + bX_2 è integrabile e il suo valore atteso è dato da:\nE[aX_1 + bX_2] = aE[X_1] + bE[X_2]\nMonotonia\nSe P(X_1 \\ge X_2) = 1, allora i loro valori attesi soddisfano la stessa disuguaglianza:\nE[X_1] \\ge E[X_2]\nCome caso particolare, se P(X_1 \\ge 0) = 1, allora E[X_1] \\ge 0. Questa proprietà è leggermente più debole rispetto alla proprietà analoga per l’integrale astratto, in quanto la condizione è richiesta solo con probabilità 1, non per ogni \\omega \\in \\Omega.\nDisuguaglianza del Valore Assoluto\nPer una variabile aleatoria X_1 con valore atteso finito, vale la seguente disuguaglianza:\n|E[X_1]| \\le E[|X_1|]\nInsensibilità a Eventi di Probabilità Zero\nSe due variabili aleatorie X_1 e X_2 sono uguali con probabilità 1, cioè P(X_1 = X_2) = 1, allora i loro valori attesi sono uguali:\nE[X_1] = E[X_2]\nIn particolare, se P(X_1 = c) = 1 per una costante c \\in \\mathbb{R}, allora E[X_1] = c.\nCorollario: Se A \\in \\mathcal{F} è un evento con probabilità nulla, P(A) = 0, e X_1 è una variabile aleatoria integrabile, allora:\nE[X_1 \\mathbf{1}_A] = 0\nValore Atteso e Variabili Aleatorie a Valori Estesi\nLe definizioni di valore atteso possono essere estese a variabili aleatorie che possono assumere i valori +\\infty o -\\infty. Tuttavia, se il valore atteso E[X_1] è finito, allora la probabilità che X_1 assuma valori infiniti è zero:\nP(X_1 \\in \\mathbb{R}) = 1\nQuesto può essere utile in situazioni in cui dimostrare direttamente che una variabile aleatoria non assume valori infiniti è complicato, ad esempio nel caso di limiti di successioni di variabili aleatorie. Se si riesce a dimostrare che il valore atteso del limite è finito, allora il limite stesso sarà finito con probabilità 1.\nDipendenza dalla Legge della Variabile Aleatoria\nIl valore atteso di una variabile aleatoria X dipende unicamente dalla sua legge (o distribuzione di probabilità), e non specificamente dallo spazio di probabilità (\\Omega, \\mathcal{F}, P) su cui è definita. Questa è una giustificazione del perché spesso si parla di variabili aleatorie con specifiche distribuzioni (esponenziale, Gamma, Gaussiana) senza menzionare esplicitamente lo spazio di probabilità sottostante.\nNel caso di variabili aleatorie assolutamente continue, la legge è descritta dalla funzione di densità di probabilità f_X(x). In questo caso, il valore atteso può essere calcolato come:\nE[X] = \\int_{-\\infty}^{+\\infty} x f_X(x) dx\nNel caso di variabili aleatorie discrete, la legge è descritta dalla funzione di massa di probabilità p_X(x) = P(X=x). In questo caso, il valore atteso è dato da:\nE[X] = \\sum_x x p_X(x)\ndove la somma è estesa a tutti i possibili valori x che la variabile aleatoria può assumere.\nTeoremi di Convergenza\nUn’altra motivazione fondamentale per l’introduzione del concetto generale di valore atteso attraverso l’integrale astratto è la possibilità di enunciare e dimostrare importanti teoremi di convergenza per successioni di variabili aleatorie. Questi teoremi forniscono condizioni sotto le quali è possibile scambiare il limite con l’operatore di valore atteso.\nConvergenza di Variabili Aleatorie e Teoremi Fondamentali\nIntroduzione alla Convergenza di Variabili Aleatorie\nIl corso approfondirà diversi tipi di convergenza di variabili aleatorie. Questa è la prima volta che si introduce questo argomento, che sarà ripreso in seguito con maggiore dettaglio. È fondamentale ricordare che non esiste un unico tipo di convergenza per variabili aleatorie, pertanto è sempre necessario specificare l’aggettivo che qualifica il tipo di convergenza.\nConvergenza Quasi Certamente\nDefinizione di Convergenza Quasi Certamente\nConsideriamo una successione di variabili aleatorie {X_n}_{n \\ge 1} definite su un comune spazio di probabilità (\\Omega, \\mathcal{F}, P) a valori in \\mathbb{R}, e una variabile aleatoria X definita sullo stesso spazio di probabilità.\nDefinizione: La successione di variabili aleatorie {X_n} converge quasi certamente a X se la probabilità dell’insieme degli \\omega \\in \\Omega tali per cui il limite di X_n(\\omega) è uguale a X(\\omega) è pari a 1.\nIn simboli, scriviamo X_n \\xrightarrow{q.c.} X se $$\nP\\left(\\left{\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega)\\right}\\right) = 1\n\n#### Interpretazione della Convergenza Quasi Certamente\n\nPer ogni $\\omega$ fissato, $X_n(\\omega)$ è una successione di numeri reali. La convergenza quasi certa significa che questa successione converge a $X(\\omega)$ per tutti gli $\\omega$ appartenenti a un sottoinsieme di $\\Omega$ che ha probabilità 1.\n\n**Osservazione:** La convergenza quasi certa è &quot;leggermente meno&quot; stringente della convergenza puntuale. Se $X_n(\\omega)$ converge a $X(\\omega)$ per ogni $\\omega \\in \\Omega$, allora la convergenza quasi certa è automaticamente verificata, poiché l&#039;insieme ${\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega)}$ coincide con $\\Omega$, e $P(\\Omega) = 1$. Tuttavia, è possibile avere convergenza quasi certa anche se la convergenza puntuale non si verifica su un insieme di misura di probabilità nulla.\n\nL&#039;espressione &quot;quasi certamente&quot; indica che un certo evento (in questo caso, la convergenza puntuale di $X_n(\\omega)$ a $X(\\omega)$) si verifica su un insieme $\\Omega&#039; \\subseteq \\Omega$ tale che $P(\\Omega&#039;) = 1$.\n\n**Esempio:** Se $P(X_1 = 0) = 1$, allora si può dire che $X_1$ è quasi certamente uguale a 0. In tal caso, il valore atteso di $X_1$ è $E[X_1] = 0$.\n\n### Teorema di Convergenza Monotona\n\nQuesto teorema stabilisce un importante risultato sul limite del valore atteso di una successione di variabili aleatorie non negative che convergono in modo monotono.\n\n**Teorema di Convergenza Monotona:** Sia ${X_n}_{n \\ge 1}$ una successione di variabili aleatorie definite su uno spazio di probabilità $(\\Omega, \\mathcal{F}, P)$ tali che:\n\n- $X_n \\ge 0$ quasi certamente per ogni $n \\ge 1$. Questo significa che $P(X_n \\ge 0) = 1$ per ogni $n$.\n- $X_n$ converge a $X$ in modo monotono crescente quasi certamente, cioè $X_{n+1} \\ge X_n$ quasi certamente per ogni $n \\ge 1$, e $X_n \\xrightarrow{q.c.} X$. In termini di probabilità, $P(X_{n+1} \\ge X_n) = 1$ per ogni $n$, e $P\\left(\\left{\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega)\\right}\\right) = 1$.\n\nAllora, il limite dei valori attesi di $X_n$ è uguale al valore atteso del limite $X$: $$ \\lim_{n \\to \\infty} E[X_n] = E[X] $$ È importante notare che i valori attesi possono essere finiti o anche $+\\infty$. Se il membro di destra è infinito, allora anche il membro di sinistra deve essere infinito, e viceversa.\n\n**Osservazione:** Le due condizioni del teorema (non negatività e convergenza monotona) sono cruciali e il risultato non vale per una qualunque successione di variabili aleatorie.\n\n### Corollario sulla Convergenza di Serie di Variabili Aleatorie Non Negative\n\nQuesto corollario, derivabile dal teorema di convergenza monotona (e anche dal teorema di convergenza dominata), riguarda la convergenza di serie di variabili aleatorie non negative.\n\n**Corollario:** Sia ${X_n}_{n \\ge 1}$ una successione di variabili aleatorie tali che $X_n \\ge 0$ quasi certamente per ogni $n \\ge 1$. Se la serie dei valori attesi converge, cioè $\\sum_{i=1}^{\\infty} E[X_i] &lt; \\infty$, allora la serie $\\sum_{i=1}^{\\infty} X_i$ converge quasi certamente a una variabile aleatoria finita.\n\n**Dimostrazione (Esercizio):** Si consideri la successione delle somme parziali $S_n = \\sum_{i=1}^{n} X_i$. Poiché $X_i \\ge 0$, la successione ${S_n}_{n \\ge 1}$ è monotona crescente. Si applichi il teorema di convergenza monotona alla successione ${S_n}$. Se $\\sum_{i=1}^{\\infty} E[X_i] = L &lt; \\infty$, allora $\\lim_{n \\to \\infty} E[S_n] = E[\\lim_{n \\to \\infty} S_n] = E\\left[\\sum_{i=1}^{\\infty} X_i\\right] = L &lt; \\infty$. Se il valore atteso della somma è finito, allora la somma stessa deve essere finita quasi certamente (proprietà di finitezza del valore atteso non esplicitata nelle fonti, ma richiamata dal professore).\n\n**Esempio:** Supponiamo di avere una successione di variabili aleatorie $X_i \\ge 0$ tali che $E[X_i] \\le \\frac{1}{i^2}$. Sappiamo che la serie numerica $\\sum_{i=1}^{\\infty} \\frac{1}{i^2}$ converge. Quindi, per il corollario, la serie di variabili aleatorie $\\sum_{i=1}^{\\infty} X_i$ converge quasi certamente.\n\n**Importanza del Corollario:** Questo risultato è utile perché spesso è più semplice calcolare o stimare il valore atteso di singole variabili aleatorie o di una serie di valori attesi, piuttosto che studiare direttamente la convergenza quasi certa di una serie di variabili aleatorie.\n\n### Teorema di Convergenza Dominata\n\nQuesto è un altro teorema fondamentale che fornisce condizioni per scambiare il limite con l&#039;integrale (o il valore atteso) quando si ha convergenza quasi certa.\n\n**Teorema di Convergenza Dominata:** Sia ${X_n}_{n \\ge 1}$ una successione di variabili aleatorie definite su uno spazio di probabilità $(\\Omega, \\mathcal{F}, P)$ tale che:\n\n- $X_n$ converge quasi certamente a una variabile aleatoria $X$, cioè $X_n \\xrightarrow{q.c.} X$.\n- Esiste una variabile aleatoria $Y$ definita sullo stesso spazio di probabilità tale che $|X_n| \\le Y$ quasi certamente per ogni $n \\ge 1$, e il valore atteso di $|Y|$ è finito, cioè $E[|Y|] &lt; \\infty$.\n\nAllora, vale il seguente risultato sul limite dei valori attesi: $$ \\lim_{n \\to \\infty} E[X_n] = E[X] $$ **Osservazione:** A differenza del teorema di convergenza monotona, le variabili aleatorie $X_n$ non devono essere non negative né convergere in modo monotono; è sufficiente la convergenza quasi certa. Tuttavia, è necessario trovare una variabile aleatoria $Y$ &quot;dominante&quot; che sia integrabile (cioè con valore atteso finito) e che limiti in modulo tutte le $X_n$ quasi certamente.\n\n**Domanda del Professore:** Le variabili aleatorie $X_n$ nel teorema di convergenza dominata possono avere valore atteso più infinito?\n\n**Risposta:** No, perché se $|X_n| \\le Y$ quasi certamente e $E[|Y|] &lt; \\infty$, allora per la proprietà di monotonia del valore atteso (non esplicitata nelle fonti, ma richiamata dal professore), anche $E[|X_n|]$ deve essere finito, e quindi anche $E[X_n]$ è ben definito e finito.\n\n**Confronto con il Teorema di Convergenza Monotona:** Nel teorema di convergenza monotona per variabili non negative, era possibile che i valori attesi fossero infiniti. Nel teorema di convergenza dominata, la condizione di dominazione con una variabile integrabile implica che i valori attesi delle $X_n$ (e di $X$) sono sempre finiti.\n\n**Osservazioni aggiuntive sul Teorema di Convergenza Dominata:** Esistono diverse varianti del teorema di convergenza dominata, alcune delle quali prevedono una dominazione non da una singola variabile $Y$ ma da una successione di variabili aleatorie. Esistono anche versioni per misure sigma-finite e per l&#039;integrale astratto, ma non saranno trattate nel corso. La versione presentata è la più semplice e spesso sufficiente per le applicazioni.\n\n# Valore Atteso e Cambiamento di Variabili\n\n## Introduzione al Valore Atteso e al Problema del Calcolo di $E[g(X)]$\n\nIl valore atteso di una variabile aleatoria è un concetto fondamentale nella teoria della probabilità. In termini astratti, dato uno spazio di misura $(\\Omega, \\mathcal{F}, P)$ e una variabile aleatoria $Y: \\Omega \\rightarrow \\mathbb{R}$, il valore atteso di $Y$, denotato con $E[Y]$, è definito come l&#039;integrale di Lebesgue di $Y$ rispetto alla misura di probabilità $P$:\n\n$$E[Y] = \\int_{\\Omega} Y(\\omega) dP(\\omega)$$\n\nSpesso ci troviamo nella situazione in cui vogliamo calcolare il valore atteso di una funzione di una variabile aleatoria, ovvero $E[g(X)]$, dove $X: \\Omega \\rightarrow X$ è una variabile aleatoria a valori in uno spazio $X$, e $g: X \\rightarrow \\mathbb{R}$ è una funzione misurabile. Calcolare direttamente l&#039;integrale su $\\Omega$ può essere complicato, specialmente quando la struttura di $\\Omega$ e la natura di $X$ non sono esplicitamente note.\n\n## Cambiamento di Variabili Astratto\n\n### Schema Generale\n\nConsideriamo il seguente schema:\n\n$\\Omega \\xrightarrow{X} X \\xrightarrow{g} \\mathbb{R}$\n\ndove:\n\n- $(\\Omega, \\mathcal{F}, P)$ è uno spazio di misura.\n- $X: \\Omega \\rightarrow X$ è una funzione misurabile (una variabile aleatoria astratta a valori nello spazio $X$).\n- $g: X \\rightarrow \\mathbb{R}$ è una funzione misurabile.\n\nLa variabile aleatoria $Y = g(X)$ è quindi una funzione misurabile da $\\Omega$ a $\\mathbb{R}$, e il suo valore atteso è dato da:\n\n$$E[g(X)] = \\int_{\\Omega} g(X(\\omega)) dP(\\omega)$$\n\n### Teorema di Cambiamento di Variabili\n\nIl teorema di cambiamento di variabili fornisce un modo alternativo per calcolare questo valore atteso, spesso più semplice.\n\n**Teorema (Cambiamento di Variabili Astratto):** Siano $X: \\Omega \\rightarrow X$ una variabile aleatoria astratta (funzione misurabile) e $g: X \\rightarrow \\mathbb{R}$ una funzione misurabile. Sia $P_X$ la misura immagine di $P$ tramite $X$ su $X$. Se $E[|g(X)|] &lt; \\infty$, allora:\n\n$$E[g(X)] = \\int_{X} g(x) dP_X(x)$$\n\ndove $P_X(B) = P(X^{-1}(B)) = P({ \\omega \\in \\Omega : X(\\omega) \\in B })$ per ogni insieme misurabile $B \\subseteq X$. In altre parole, il valore atteso di $g(X)$ può essere calcolato come l&#039;integrale di $g$ sullo spazio $X$ rispetto alla misura indotta $P_X$.\n\n**Dimostrazione:** (Implicita nel testo, il professore afferma che se uno dei due integrali è ben definito, lo è anche l&#039;altro e sono uguali).\n\n### Esempio Concreto: Vettore Aleatorio in $\\mathbb{R}^D$\n\nConsideriamo un vettore aleatorio $X = (X_1, ..., X_D): \\Omega \\rightarrow \\mathbb{R}^D$. In questo caso, lo spazio $X$ è $\\mathbb{R}^D$ con la sua $\\sigma$-algebra dei boreliani $\\mathcal{B}(\\mathbb{R}^D)$. La misura indotta $P_X$ è la misura immagine su $\\mathbb{R}^D$, che è la legge (o distribuzione) del vettore aleatorio $X$.\n\nSe $g: \\mathbb{R}^D \\rightarrow \\mathbb{R}$ è una funzione misurabile, allora il valore atteso di $g(X)$ è dato da:\n\n$$E[g(X)] = \\int_{\\mathbb{R}^D} g(x_1, ..., x_D) dP_X(x_1, ..., x_D)$$\n\nQuesto integrale è un integrale di Lebesgue su $\\mathbb{R}^D$ rispetto alla misura $P_X$.\n\n**Corollario:** Se $X$ è un vettore aleatorio in $\\mathbb{R}^D$ e $g: \\mathbb{R}^D \\rightarrow \\mathbb{R}$ è misurabile tale che $E[|g(X)|] &lt; \\infty$, allora il valore atteso di $g(X)$ può essere calcolato come l&#039;integrale di $g$ rispetto alla legge (misura immagine) di $X$ su $\\mathbb{R}^D$. Questo è un passo importante perché ci permette di lavorare su uno spazio più concreto come $\\mathbb{R}^D$ invece dell&#039;astratto $\\Omega$.\n\n## Caso Particolare: Variabile Aleatoria Reale\n\nSe $X: \\Omega \\rightarrow \\mathbb{R}$ è una variabile aleatoria reale, allora lo spazio $X$ è $\\mathbb{R}$ con la $\\sigma$-algebra dei boreliani $\\mathcal{B}(\\mathbb{R})$, e $P_X$ è la legge di $X$ su $\\mathbb{R}$. Per una funzione misurabile $g: \\mathbb{R} \\rightarrow \\mathbb{R}$, il valore atteso di $g(X)$ è:\n\n$$E[g(X)] = \\int_{\\mathbb{R}} g(x) dP_X(x)$$\n\n### Caso Assolutamente Continuo\n\nSe la variabile aleatoria reale $X$ è assolutamente continua, allora la sua legge $P_X$ può essere rappresentata da una funzione di densità di probabilità $f_X(x) \\ge 0$ tale che $\\int_{\\mathbb{R}} f_X(x) dx = 1$. In questo caso, l&#039;integrale rispetto alla misura $P_X$ si riduce a un integrale di Riemann (o Lebesgue) rispetto alla misura di Lebesgue $dx$:\n\n$$E[g(X)] = \\int_{\\mathbb{R}} g(x) f_X(x) dx$$\n\nIn particolare, il valore atteso di $X$ stesso (quando $g(x) = x$) è:\n\n$$E[X] = \\int_{\\mathbb{R}} x f_X(x) dx$$\n\na condizione che $\\int_{\\mathbb{R}} |x| f_X(x) dx &lt; \\infty$.\n\n## Proprietà del Valore Atteso\n\nIl professore menziona alcune proprietà importanti del valore atteso, valide sia nel caso astratto che nei casi particolari (discreto e assolutamente continuo):\n\n- **Linearità:** $E[aY + bZ] = aE[Y] + bE[Z]$ per variabili aleatorie $Y, Z$ e costanti $a, b$.\n- **Disuguaglianza del Modulo:** $|E[Y]| \\le E[|Y|]$.\n- **Monotonia:** Se $Y \\le Z$ (puntualmente), allora $E[Y] \\le E[Z]$.\n- **Teoremi di Convergenza:** (Non specificati nel dettaglio, ma importanti per passare al limite sotto il segno di valore atteso).\n\nQueste proprietà sono particolarmente utili perché valgono in generale, indipendentemente dalla natura discreta o continua della variabile aleatoria.\n\n## Calcolo del Valore Atteso nei Casi Specifici\n\n### Caso 1: Variabile Aleatoria Discreta\n\nSe $X$ è un vettore aleatorio discreto a valori in $\\mathbb{R}^D$, allora assume un insieme finito o numerabile di valori ${x_i}_{i \\in I}$ con probabilità $p_i = P(X = x_i) &gt; 0$ tali che $\\sum_{i \\in I} p_i = 1$. La legge di $X$, $P_X$, è una misura discreta concentrata sui punti ${x_i}$. Per una funzione $g: \\mathbb{R}^D \\rightarrow \\mathbb{R}$, il valore atteso di $g(X)$ è dato dalla somma:\n\n$$E[g(X)] = \\sum_{i \\in I} g(x_i) P(X = x_i) = \\sum_{i \\in I} g(x_i) p_i$$\n\nQuesto era già stato visto come la proprietà P0 nel caso discreto.\n\n### Caso 2: Variabile Aleatoria Assolutamente Continua (Unidimensionale)\n\nSe $X$ è una variabile aleatoria reale assolutamente continua con densità $f_X(x)$, allora per una funzione $g: \\mathbb{R} \\rightarrow \\mathbb{R}$ tale che $E[|g(X)|] &lt; \\infty$, il valore atteso di $g(X)$ è dato da:\n\n$$E[g(X)] = \\int_{\\mathbb{R}} g(x) f_X(x) dx$$\n\nIn particolare, il valore atteso di $X$ è:\n\n$$E[X] = \\int_{\\mathbb{R}} x f_X(x) dx$$\n\nse $\\int_{\\mathbb{R}} |x| f_X(x) dx &lt; \\infty$.\n\n## Esempi di Calcolo del Valore Atteso\n\n### Esempio 1: Variabile Aleatoria Uniforme su $$\n\nSia $X$ una variabile aleatoria uniforme sull&#039;intervallo $$. La sua densità di probabilità è:\n\n$$f_X(x) = \\begin{cases} 1 &amp; \\text{se } 0 \\le x \\le 1 \\ 0 &amp; \\text{altrimenti} \\end{cases}$$\n\n**Calcolo di $E[X]$:**\n\n$$E[X] = \\int_{\\mathbb{R}} x f_X(x) dx = \\int_{0}^{1} x \\cdot 1 dx = \\left[ \\frac{1}{2} x^2 \\right]_{0}^{1} = \\frac{1}{2} (1)^2 - \\frac{1}{2} (0)^2 = \\frac{1}{2}$$\n\nQuesto risultato è intuitivo: il valore medio di una variabile uniformemente distribuita tra 0 e 1 è il punto medio dell&#039;intervallo.\n\n**Calcolo di $E[X^2 \\mathbb{1}_{{X &gt; 1/2}}]$:**\n\nSia $g(x) = x^2 \\mathbb{1}_{{x &gt; 1/2}}(x)$. Allora:\n\n$$E[g(X)] = \\int_{\\mathbb{R}} g(x) f_X(x) dx = \\int_{\\mathbb{R}} x^2 \\mathbb{1}_{{x &gt; 1/2}}(x) f_X(x) dx$$\n\nSostituendo la densità di $X$:\n\n$$E[g(X)] = \\int_{0}^{1} x^2 \\mathbb{1}_{{x &gt; 1/2}}(x) \\cdot 1 dx$$\n\nL&#039;indicatrice $\\mathbb{1}_{{x &gt; 1/2}}(x)$ è 1 se $x &gt; 1/2$ e 0 altrimenti. Quindi l&#039;integrale diventa:\n\n$$E[g(X)] = \\int_{1/2}^{1} x^2 dx = \\left[ \\frac{1}{3} x^3 \\right]_{1/2}^{1} = \\frac{1}{3} (1)^3 - \\frac{1}{3} \\left(\\frac{1}{2}\\right)^3 = \\frac{1}{3} - \\frac{1}{3} \\cdot \\frac{1}{8} = \\frac{1}{3} - \\frac{1}{24} = \\frac{8 - 1}{24} = \\frac{7}{24}$$\n\n### Esempio 2: Variabile Aleatoria Esponenziale (Esercizio)\n\nSia $X$ una variabile aleatoria esponenziale di parametro $\\lambda = 3$. La sua densità di probabilità è:\n\n$$f_X(x) = \\begin{cases} 3 e^{-3x} &amp; \\text{se } x \\ge 0 \\ 0 &amp; \\text{se } x &lt; 0 \\end{cases}$$\n\n**Esercizio:** Calcolare il tempo medio di vita, ovvero $E[X]$:\n\n$$E[X] = \\int_{\\mathbb{R}} x f_X(x) dx = \\int_{0}^{+\\infty} x \\cdot 3 e^{-3x} dx$$\n\nQuesto integrale può essere risolto utilizzando l&#039;integrazione per parti.\n\n## Conseguenza Importante: Variabili Aleatorie con la Stessa Legge\n\n**Corollario:** Se due variabili aleatorie $X$ e $Y$ hanno la stessa legge (ovvero $P_X = P_Y$), allora, se i rispettivi valori attesi esistono, si ha $E[X] = E[Y]$ e più in generale, per una funzione misurabile $g$, $E[g(X)] = E[g(Y)]$. Questo è vero anche se $X$ e $Y$ sono definite su spazi di probabilità diversi. Il valore atteso dipende unicamente dalla legge (distribuzione) della variabile aleatoria e non dalla struttura dello spazio di probabilità sottostante.\n\n## Caso Multidimensionale Assolutamente Continuo (Chiarimento)\n\nUn vettore aleatorio $X = (X_1, ..., X_D)$ è assolutamente continuo se esiste una funzione di densità congiunta $f_X(x_1, ..., x_D) \\ge 0$ tale che per ogni insieme boreliano $A \\subseteq \\mathbb{R}^D$:\n\n$$P(X \\in A) = \\int_{A} f_X(x_1, ..., x_D) dx_1 ... dx_D$$\n\nIn questo caso, per una funzione misurabile $g: \\mathbb{R}^D \\rightarrow \\mathbb{R}$ tale che $E[|g(X)|] &lt; \\infty$, il valore atteso di $g(X)$ è dato dall&#039;integrale multiplo:\n\n$$E[g(X)] = \\int_{\\mathbb{R}^D} g(x_1, ..., x_D) f_X(x_1, ..., x_D) dx_1 ... dx_D$$\n\nQuesto estende il concetto del caso unidimensionale a dimensioni superiori.\n\n## Conclusione\n\nIl teorema di cambiamento di variabili è uno strumento fondamentale per il calcolo del valore atteso di funzioni di variabili aleatorie. Permette di passare da un integrale astratto sullo spazio $\\Omega$ a un integrale sullo spazio dei valori della variabile aleatoria (come $\\mathbb{R}$ o $\\mathbb{R}^D$) rispetto alla legge indotta. Nei casi particolari di variabili discrete e assolutamente continue, questo si traduce in somme e integrali (singoli o multipli) che possono essere calcolati utilizzando le rispettive funzioni di massa o densità di probabilità. Gli esempi illustrano come applicare queste formule in pratica.\n#### References\n\n[[Appunti Prob-lez13.pdf]]\n\n\n\n2025-04-08 15:51\n\n_Status: #flashcard_zero  #riscritto_zero  #revisione_zero \n\n_Tags:[[probabilità]]  [[sbobine]]\n\n## prob-lez14\n\n\n# Varianza di una Variabile Aleatoria\n\n## Definizione di Varianza\n\nSia $X$ una variabile aleatoria tale che il valore [[atteso]] di $X^2$, indicato come $E[X^2]$, sia finito.\n\nSi definisce **varianza** di $X$, indicata con $Var(X)$ o $\\sigma_X^2$, il valore atteso di $(X - m)^2$, dove $m$ è il valore atteso di $X$, ovvero $m = E[X]$.\n\nMatematicamente: $$Var(X) = E[(X - E[X])^2]$$\n\nQuesta definizione è valida sia per variabili aleatorie discrete che continue.\n\n**Commento:** La varianza misura la dispersione dei valori di una variabile aleatoria attorno alla sua media. Rappresenta la media dei quadrati delle distanze tra ogni realizzazione della variabile aleatoria e la sua media.\n\n## Momenti di una Variabile Aleatoria\n\n### Momento k-esimo\n\nIl **momento k-esimo** di una variabile aleatoria è definito come $E[X^k]$, se questo valore atteso esiste ed è finito, dove $k$ è un intero.\n\n### Momento k-esimo assoluto\n\nIl **momento k-esimo assoluto** di una variabile aleatoria è definito come $E[|X|^p]$, se questo valore atteso esiste ed è finito, dove $p$ è un numero reale maggiore o uguale a 0 ($p \\ge 0$).\n\n**Commento:** La definizione di varianza richiede l&#039;esistenza del momento secondo finito ($E[X^2] &lt; \\infty$). Se il momento secondo è finito, allora anche la media (momento primo) è finita.\n![[Pasted image 20250408162729.png]]\n## Struttura Tipica degli Esami\n\nGli esami sono generalmente costituiti da:\n\n- Domande a risposta multipla (solitamente due nel compitino).\n- Domande a risposta aperta (una nel compitino, due nei compiti più lunghi).\n- Esercizi.\n\n**Esempio di domanda a risposta aperta da un compito passato:** Enunciare la definizione di varianza e dimostrare alcune sue proprietà.\n\n## Proprietà della Varianza\n\n### Proprietà 1: Non negatività\n\n**Proposizione:** $Var(X) \\ge 0$.\n\n**Dimostrazione:** La varianza è definita come il valore atteso di $(X - m)^2$, dove $(X - m)^2$ è sempre una quantità non negativa (essendo un quadrato). Il valore atteso di una funzione non negativa è sempre non negativo per la proprietà di monotonia del valore atteso.\n\n### Proprietà 2: Formula alternativa per la varianza\n\n**Proposizione:** $Var(X) = E[X^2] - (E[X])^2$.\n\n**Dimostrazione:** Partendo dalla definizione di varianza: $$Var(X) = E[(X - E[X])^2]$$ Svolgendo il quadrato: $$Var(X) = E[X^2 + (E[X])^2 - 2X E[X]]$$ Utilizzando la linearità del valore atteso: $$Var(X) = E[X^2] + E[(E[X])^2] - E[2X E[X]]$$ Poiché $E[X]$ è una costante, $(E[X])^2$ è anch&#039;essa una costante, e $2E[X]$ è una costante. Quindi: $$Var(X) = E[X^2] + (E[X])^2 E - 2E[X] E[X]$$ Ricordando che $E = 1$: $$Var(X) = E[X^2] + (E[X])^2 - 2(E[X])^2$$ $$Var(X) = E[X^2] - (E[X])^2$$\n\n**Commento:** Questa formula è spesso più comoda per calcolare la varianza, in quanto richiede il calcolo del valore atteso di $X^2$ e del quadrato del valore atteso di $X$.\n\n**Errore comune da evitare:** Non scrivere che $Var(X) = E[X^2] - E[X]^2$ (senza le parentesi), in quanto $E[X^2]$ è generalmente diverso da $(E[X])^2$.\n![[Pasted image 20250410120607.png]]\n### Proprietà 3: Varianza di una trasformazione lineare\n\n**Proposizione:** $Var(aX + b) = a^2 Var(X)$, per ogni $a, b \\in \\mathbb{R}$ (costanti).\n\n**Dimostrazione:** Utilizzando la definizione di varianza: $$Var(aX + b) = E[((aX + b) - E[aX + b])^2]$$ Per la linearità del valore atteso, $E[aX + b] = aE[X] + b$. Sostituendo: $$Var(aX + b) = E[((aX + b) - (aE[X] + b))^2]$$ $$Var(aX + b) = E[(aX + b - aE[X] - b)^2]$$ $$Var(aX + b) = E[(aX - aE[X])^2]$$ $$Var(aX + b) = E[(a(X - E[X]))^2]$$ $$Var(aX + b) = E[a^2 (X - E[X])^2]$$ Poiché $a^2$ è una costante, può essere portata fuori dal valore atteso per la linearità: $$Var(aX + b) = a^2 E[(X - E[X])^2]$$ Riconoscendo che $E[(X - E[X])^2]$ è la definizione di $Var(X)$: $$Var(aX + b) = a^2 Var(X)$$\n\n**Commento:** Questa proprietà mostra come la varianza viene scalata per trasformazioni lineari. L&#039;aggiunta di una costante $b$ non influisce sulla varianza, mentre la moltiplicazione per una costante $a$ comporta una moltiplicazione della varianza per $a^2$.\n![[Pasted image 20250410120707.png]]\n### Proprietà 4: Varianza nulla\n\n**Proposizione:** $Var(X) = 0$ se e solo se esiste una costante $c$ tale che $P(X = c) = 1$.\n\n**Dimostrazione:** $(\\Rightarrow)$ Se $Var(X) = 0$, allora $E[(X - E[X])^2] = 0$. Poiché $(X - E[X])^2$ è una variabile aleatoria non negativa, il suo valore atteso è zero se e solo se la variabile è zero con probabilità 1. Quindi, $P((X - E[X])^2 = 0) = 1$, il che implica $P(X - E[X] = 0) = 1$, ovvero $P(X = E[X]) = 1$. In questo caso, $c = E[X]$.\n\n$(\\Leftarrow)$ Se esiste una costante $c$ tale che $P(X = c) = 1$, allora $E[X] = c$. Quindi, $Var(X) = E[(X - c)^2]$. Poiché $X = c$ con probabilità 1, $(X - c)^2 = (c - c)^2 = 0$ con probabilità 1. Pertanto, $E[(X - c)^2] = E = 0$, quindi $Var(X) = 0$.\n\n**Commento:** Una variabile aleatoria ha varianza zero solo se è degenere, cioè assume un singolo valore con probabilità 1.\n![[Pasted image 20250410120022.png]]\n## Finitudine dei Momenti\n\n**Osservazione:** Se il momento $S$-esimo assoluto di $X$ è finito per $S &gt; 0$ ($E[|X|^S] &lt; \\infty$), allora il momento $r$-esimo assoluto di $X$ è finito per ogni $0 &lt; r &lt; S$ ($E[|X|^r] &lt; \\infty$).\n\n**Spiegazione:** Si considera la variabile aleatoria non negativa $|X|^r$. Si ha che $|X|^r \\le 1 + |X|^S$. Applicando la linearità e la **monotonia** del valore atteso per variabili aleatorie positive (se $P(Y \\le Z) = 1$, allora $E[Y] \\le E[Z]$): $$E[|X|^r] \\le E[1 + |X|^S] = E + E[|X|^S] = 1 + E[|X|^S]$$ Poiché $E[|X|^S]$ è finito per ipotesi, anche $1 + E[|X|^S]$ è finito. Pertanto, $E[|X|^r]$ è finito.\n\n**Conseguenza:** Se il momento secondo è finito ($E[X^2] &lt; \\infty$), allora anche il momento primo assoluto (e quindi il momento primo) è finito ($E[|X|] &lt; \\infty$ e $E[X] &lt; \\infty$). Questo giustifica l&#039;assunzione che il valore atteso $m = E[X]$ sia finito nella definizione di varianza.\n\n![[Pasted image 20250410120409.png]]\n\n## Standardizzazione di una Variabile Aleatoria\n\nSia $X$ una variabile aleatoria con valore atteso $m = E[X]$ e varianza finita $Var(X) = \\sigma^2$, dove $\\sigma = \\sqrt{Var(X)}$ è la **deviazione standard** (assumendo $\\sigma &gt; 0$).\n\nSi definisce la **standardizzazione** di $X$ una nuova variabile aleatoria $Y$ data da: $$Y = \\frac{X - m}{\\sigma}$$\n\n### Proprietà della Variabile Aleatoria Standardizzata\n\n#### Media di $Y$\n\n$$E[Y] = E\\left[\\frac{X - m}{\\sigma}\\right] = E\\left[\\frac{1}{\\sigma}X - \\frac{m}{\\sigma}\\right]$$ Utilizzando la linearità del valore atteso: $$E[Y] = \\frac{1}{\\sigma}E[X] - \\frac{m}{\\sigma}E = \\frac{1}{\\sigma}m - \\frac{m}{\\sigma}(1) = \\frac{m}{\\sigma} - \\frac{m}{\\sigma} = 0$$ Quindi, la variabile aleatoria standardizzata $Y$ ha **media 0**.\n\n#### Varianza di $Y$\n\n$$Var(Y) = Var\\left[\\frac{X - m}{\\sigma}\\right] = Var\\left[\\frac{1}{\\sigma}X - \\frac{m}{\\sigma}\\right]$$ Utilizzando la proprietà $Var(aX + b) = a^2 Var(X)$ con $a = \\frac{1}{\\sigma}$ e $b = -\\frac{m}{\\sigma}$: $$Var(Y) = \\left(\\frac{1}{\\sigma}\\right)^2 Var(X) = \\frac{1}{\\sigma^2} \\sigma^2 = 1$$ Quindi, la variabile aleatoria standardizzata $Y$ ha **varianza 1**.\n\n**Commento:** La standardizzazione trasforma una variabile aleatoria in una con media zero e varianza unitaria. Questo è utile per confrontare variabili aleatorie con scale e medie diverse. La standardizzazione non richiede alcuna ipotesi sulla forma della distribuzione di $X$, ma solo che abbia varianza finita.\n![[Pasted image 20250410121329.png]]\n## Trasformazione Lineare di una Variabile Aleatoria (Modello Scala-Posizione)\n\nSia $X_0$ una variabile aleatoria con funzione di ripartizione $F_{X_0}(x_0)$. Definiamo una nuova variabile aleatoria $X$ come una trasformazione lineare di $X_0$: $$X = sX_0 + \\mu$$ dove $\\mu \\in \\mathbb{R}$ e $s &gt; 0$ sono costanti. Questo tipo di modello è chiamato **modello scala-posizione**. $\\mu$ rappresenta la traslazione (posizione), e $s$ rappresenta la dilatazione o contrazione (scala).\n\n### Funzione di Ripartizione di $X$\n\n**Proposizione:** La funzione di ripartizione di $X$, $F_X(x) = P(X \\le x)$, è data da: $$F_X(x) = F_{X_0}\\left(\\frac{x - \\mu}{s}\\right)$$\n\n**Dimostrazione:** $$F_X(x) = P(X \\le x) = P(sX_0 + \\mu \\le x)$$ Sottraendo $\\mu$ da entrambi i lati della disuguaglianza: $$F_X(x) = P(sX_0 \\le x - \\mu)$$ Dividendo per $s$ (ricordando che $s &gt; 0$, quindi la direzione della disuguaglianza non cambia): $$F_X(x) = P\\left(X_0 \\le \\frac{x - \\mu}{s}\\right)$$ Per definizione di funzione di ripartizione di $X_0$: $$F_X(x) = F_{X_0}\\left(\\frac{x - \\mu}{s}\\right)$$\n![[Pasted image 20250410121726.png]]\n### Funzione di Densità di $X$ (se $X_0$ è assolutamente continua)\n\n**Proposizione:** Se $X_0$ è assolutamente continua con funzione di densità $f_{X_0}(x_0)$, allora anche $X$ è assolutamente continua e la sua funzione di densità $f_X(x)$ è data da: $$f_X(x) = \\frac{1}{s} f_{X_0}\\left(\\frac{x - \\mu}{s}\\right)$$\n\n**Dimostrazione (informale):** La funzione di densità è la derivata della funzione di ripartizione (dove esiste). Quindi: $$f_X(x) = \\frac{d}{dx} F_X(x) = \\frac{d}{dx} F_{X_0}\\left(\\frac{x - \\mu}{s}\\right)$$ Utilizzando la regola della catena: $$f_X(x) = f_{X_0}\\left(\\frac{x - \\mu}{s}\\right) \\cdot \\frac{d}{dx}\\left(\\frac{x - \\mu}{s}\\right)$$ $$\\frac{d}{dx}\\left(\\frac{x - \\mu}{s}\\right) = \\frac{1}{s} \\frac{d}{dx}(x - \\mu) = \\frac{1}{s}(1 - 0) = \\frac{1}{s}$$ Quindi: $$f_X(x) = \\frac{1}{s} f_{X_0}\\left(\\frac{x - \\mu}{s}\\right)$$\n\n**Commento:** Questa trasformazione mostra come la funzione di ripartizione e la funzione di densità cambiano sotto una trasformazione lineare. La divisione per $s$ nella funzione di densità assicura che l&#039;integrale della densità di $X$ su tutto $\\mathbb{R}$ sia ancora uguale a 1. La standardizzazione è un caso particolare di questa trasformazione con $s = \\sigma$ e $\\mu = m$.\n![[Pasted image 20250410122100.png]]\n## Esercizi e Materiali Aggiuntivi\n\nIl professore ha caldamente invitato a fare gli esercizi, sia quelli svolti durante le esercitazioni di questa e della prossima settimana, sia quelli indicati nel materiale aggiuntivo fornito.\n\nNel materiale aggiuntivo è presente un riferimento puntuale agli esercizi e alle domande (sia teoriche che a risposta multipla) tratte dai compiti d&#039;esame dell&#039;anno scorso che si possono già svolgere con le conoscenze acquisite fino a questa lezione (inclusa la varianza). Questi esercizi rappresentano un buon esempio di ciò che potrebbe essere chiesto nel compitino.\n\n**Esempio discusso dal professore:** Considerare una variabile aleatoria discreta $X$ che assume valori $k$ con probabilità proporzionale a $\\frac{k}{k^c}$ per $k \\ge 1$ (dove $c$ è una costante tale che la serie $\\sum_{k=1}^\\infty \\frac{k}{k^c}$ converge). In questo caso, la probabilità che $X$ sia finita è 1, ma il valore atteso di $X$ potrebbe essere infinito (ad esempio, se $c \\le 2$). Questo illustra che **avere probabilità 1 che una variabile sia finita non implica che il suo valore atteso sia finito**. La dimostrazione fornita era che $E[X] = \\sum_{k} k \\cdot P(X=k)$, e se $P(X=k) = \\frac{C k}{k^c}$, allora $E[X] = \\sum_{k} k \\cdot \\frac{C k}{k^c} = C \\sum_{k} \\frac{k^2}{k^c} = C \\sum_{k} k^{2-c}$, che diverge se $2-c \\ge -1$ (ovvero $c \\le 3$). L&#039;esempio più preciso fatto dal professore era con $P(X=k) \\propto \\frac{1}{k^c}$, e in quel caso $E[X] = \\sum k \\cdot \\frac{C}{k^c} = C \\sum k^{1-c}$, che diverge se $1-c \\ge -1$ ($c \\le 2$). **Errore nella trascrizione precedente, la proporzionalità era a $K/K^c$ e l&#039;esempio fatto era che $E[X] = \\sum K \\cdot \\frac{C K}{K^c} = C \\sum K^{2-c}$ diverge se $2-c \\ge -1$ ($c \\le 3$)**. Tuttavia, il concetto chiave rimane: probabilità di essere finita uguale a 1 non implica valore atteso finito.\n\nIl professore ha anche menzionato che nei prossimi giorni potrebbe essere fornito ulteriore materiale.\n\n___\n\n\n___\n# Spiegazione dei Concetti Chiave sulle Variabili Aleatorie\n\n## Densità e Funzione di Ripartizione\n\n### Individuare la Densità e la Sua Verifica\n\nIl professore spiega come, data una funzione di ripartizione $F(x)$, si possa ipotizzare la forma della densità $f(x)$. Il metodo suggerito è di &quot;guardare in faccia&quot; la funzione di ripartizione. Se la funzione di ripartizione è concreta, si può controllare se è possibile derivarla.\n\nFormalmente, se si ha una funzione di ripartizione $F_X(x)$, si può tentare di trovare la densità $f_X(x)$ derivandola formalmente: $f_X(x) = \\frac{d}{dx} F_X(x)$.\n\nTuttavia, il professore avverte che la derivata potrebbe non esistere in tutti i punti.\n\nUna volta ottenuta una forma per la densità, è necessario verificarla. La verifica consiste nel calcolare l&#039;integrale della densità così ottenuta tra $-\\infty$ e $x$ e controllare se si ottiene la funzione di ripartizione originale: $F_X(x) = \\int_{-\\infty}^{x} f_X(t) dt$.\n\nQuesto processo di verifica è descritto come un cambio di variabili nell&#039;integrale.\n\n## Modello Scala Posizione\n\n### Definizione e Vantaggi\n\nNel contesto di un modello scala posizione, si ha spesso una funzione di ripartizione o una densità assolutamente continua. La proprietà fondamentale di questo modello è che, a partire da una densità, si può costruire un&#039;intera famiglia di densità tramite una trasformazione di scala e posizione.\n\n### Esempio della Famiglia Gaussiana\n\nUn esempio significativo di modello scala posizione è la famiglia delle distribuzioni Gaussiane (o Normali) al variare dei parametri $\\mu$ (media) e $\\sigma^2$ (varianza).\n\nLa densità di una variabile aleatoria $X$ Gaussiana con media $\\mu$ e varianza $\\sigma^2$ è data da: $$f_X(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}$$\n\nConsiderando una variabile aleatoria $X_0$ Gaussiana standard (con media 0 e varianza 1), la cui densità è: $f_{X_0}(x_0) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x_0^2}{2}}$.\n\nSi può notare che la densità di $X$ può essere espressa in termini della densità di $X_0$: $f_X(x) = f_{X_0}\\left(\\frac{x - \\mu}{\\sigma}\\right) \\cdot \\frac{1}{\\sigma}$.\n\nQuesto dimostra che una variabile aleatoria Gaussiana con parametri $\\mu$ e $\\sigma^2$ può essere vista come un modello scala posizione a partire da una Gaussiana standard. In altre parole, $X$ può essere generata da $X_0$ tramite la trasformazione: $X = \\sigma X_0 + \\mu$.\n\nIl professore sottolinea che questo è un modo comodo di pensare una Gaussiana con parametri $\\mu$ e $\\sigma^2$.\n![[Pasted image 20250410122342.png]]\n## Valore Atteso e Varianza in un Modello Scala Posizione\n\n### Trasformazioni Lineari e Momenti\n\nConsiderando una trasformazione scala posizione di una variabile aleatoria $X_0$ con parametri $s$ (scala) e $\\mu$ (posizione), definita come $X = sX_0 + \\mu$.\n\nSe la varianza di $X_0$ è finita, allora il valore atteso di $X$ è: $E[X] = E[sX_0 + \\mu] = sE[X_0] + \\mu$.\n\nE la varianza di $X$ è: $Var(X) = Var(sX_0 + \\mu) = s^2 Var(X_0)$.\n![[Pasted image 20250410122530.png]]\n### Dipendenza dai Momenti della Variabile Base\n\nIl professore evidenzia che in un modello scala posizione, $\\mu$ non è sempre la media di $X$ e $s$ non è sempre la varianza di $X$. Dipende dai valori della media e della varianza di $X_0$.\n\n- Se $E[X_0] = 0$, allora $E[X] = \\mu$.\n- Se $Var(X_0) = 1$, allora $Var(X) = s^2$.\n\n### Esempio della Gaussiana (Ritorno)\n\nNel caso della Gaussiana, se $X_0 \\sim N(0, 1)$, allora $E[X_0] = 0$ e $Var(X_0) = 1$. Di conseguenza, se $X = \\sigma X_0 + \\mu$, allora $E[X] = \\mu$ e $Var(X) = \\sigma^2$. Questo giustifica perché $\\mu$ e $\\sigma^2$ sono chiamati rispettivamente media e varianza per la distribuzione Gaussiana.\n\n### Modello Scala Posizione Senza Momenti Finiti: L&#039;Esempio della Cauchy\n\nIl professore menziona che si può avere un modello scala posizione anche per variabili aleatorie che non hanno varianza o media finita, come la distribuzione di Cauchy. Nella parametrizzazione del professore (indicata con $S$ e $M$), la distribuzione di Cauchy è un modello scala posizione nonostante non ammetta né media né varianza finita.\n\n## Valore Atteso e Varianza della Gaussiana Standard\n\n### Verifica della Media Nulla\n\nPer verificare che una Gaussiana standard $X_0$ ha media nulla, si calcola il valore atteso: $E[X_0] = \\int_{-\\infty}^{+\\infty} x f_{X_0}(x) dx = \\int_{-\\infty}^{+\\infty} x \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}} dx$.\n\nLa funzione integranda $g(x) = x e^{-\\frac{x^2}{2}}$ è una funzione dispari (simmetrica rispetto all&#039;origine), cioè $g(-x) = -g(x)$. Pertanto, l&#039;integrale su un intervallo simmetrico come $(-\\infty, +\\infty)$ è uguale a 0: $E[X_0] = 0$.\n\n### Verifica della Varianza Unitaria\n\nLa varianza di $X_0$ è data da $Var(X_0) = E[X_0^2] - (E[X_0])^2$. Poiché $E[X_0] = 0$, si ha $Var(X_0) = E[X_0^2]$.\n\n$Var(X_0) = \\int_{-\\infty}^{+\\infty} x^2 f_{X_0}(x) dx = \\int_{-\\infty}^{+\\infty} x^2 \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}} dx$.\n\nIl professore lascia come esercizio verificare che questo integrale è uguale a 1.\n![[Pasted image 20250410122713.png]]\n## Disuguaglianze Basate sul Valore Atteso\n\n### Introduzione\n\nIl professore introduce il concetto di disuguaglianze costruite a partire dai valori attesi, tra cui la varianza, come strumenti per stimare quantità in probabilità.\n\n### Disuguaglianza di Jensen\n\n#### Enunciato\n\nSia $X$ una variabile aleatoria reale tale che $E[X]$ sia finito. Sia $g: \\mathbb{R} \\to \\mathbb{R}$ una funzione convessa e supponiamo che $E[g(X)]$ sia ben definito e finito. Allora vale la disuguaglianza di Jensen: $g(E[X]) \\le E[g(X)]$.\n\n#### Funzioni Convesse\n\nUna funzione $g(x)$ è convessa se, per ogni coppia di punti $x_1, x_2$ e per ogni $\\lambda \\in$, si ha: $g(\\lambda x_1 + (1 - \\lambda) x_2) \\le \\lambda g(x_1) + (1 - \\lambda) g(x_2)$. Geometricamente, il segmento che congiunge due punti sul grafico della funzione sta sopra o sulla funzione stessa.\n\n#### Esempi di Funzioni Convesse\n\nEsempi tipici di funzioni convesse sono il quadrato ($g(x) = x^2$) e il modulo ($g(x) = |x|$).\n\n#### Relazione con la Disuguaglianza del Modulo\n\nNel caso del modulo ($g(x) = |x|$), la disuguaglianza di Jensen diventa: $|E[X]| \\le E[|X|]$. Questa è la disuguaglianza del modulo, che può aiutare a ricordare la direzione della disuguaglianza di Jensen per funzioni convesse.\n![[Pasted image 20250410124841.png]]\n### Disuguaglianza di Markov Generalizzata\n\n#### Enunciato\n\nSia $h: \\mathbb{R} \\to [0, +\\infty)$ una funzione misurabile non negativa tale che $E[h(X)] &lt; +\\infty$. Allora, per ogni $\\epsilon &gt; 0$, si ha: $$P(h(X) \\ge \\epsilon) \\le \\frac{E[h(X)]}{\\epsilon}$$\n\n#### Dimostrazione\n\nSi definisce una variabile aleatoria $Y = h(X) \\mathbb{1}_{{h(X) \\ge \\epsilon}}$, dove $\\mathbb{1}_{{h(X) \\ge \\epsilon}}$ è la funzione indicatrice dell&#039;evento ${h(X) \\ge \\epsilon}$.\n\n- Se $h(X) &lt; \\epsilon$, allora $\\mathbb{1}_{{h(X) \\ge \\epsilon}} = 0$, e $Y = h(X) \\ge 0$.\n- Se $h(X) \\ge \\epsilon$, allora $\\mathbb{1}_{{h(X) \\ge \\epsilon}} = 1$, e $Y = h(X) \\ge \\epsilon$.\n\nQuindi, $Y$ è una variabile aleatoria non negativa ($Y \\ge 0$). Inoltre, $Y \\ge \\epsilon \\mathbb{1}_{{h(X) \\ge \\epsilon}}$.\n\nPrendendo il valore atteso di entrambi i lati e usando la linearità del valore atteso e il fatto che $E[\\mathbb{1}_A] = P(A)$: $E[Y] \\ge E[\\epsilon \\mathbb{1}_{{h(X) \\ge \\epsilon}}] = \\epsilon E[\\mathbb{1}_{{h(X) \\ge \\epsilon}}] = \\epsilon P(h(X) \\ge \\epsilon)$.\n\nD&#039;altra parte, per definizione di $Y$: $E[Y] = E[h(X) \\mathbb{1}_{{h(X) \\ge \\epsilon}}]$.\n\nPoiché $h(X) \\mathbb{1}_{{h(X) \\ge \\epsilon}} \\le h(X)$ (essendo $\\mathbb{1}$ o 0 o 1 e $h(X) \\ge 0$), per la proprietà di monotonia del valore atteso: $E[Y] \\le E[h(X)]$.\n\nCombinando le due disuguaglianze per $E[Y]$: $\\epsilon P(h(X) \\ge \\epsilon) \\le E[Y] \\le E[h(X)]$.\n\nDividendo per $\\epsilon$ (che è positivo): $P(h(X) \\ge \\epsilon) \\le \\frac{E[h(X)]}{\\epsilon}$.\n![[Pasted image 20250410125451.png]]\n### Disuguaglianza di Markov\n\nLa disuguaglianza di Markov è un caso particolare della disuguaglianza di Markov generalizzata. Sia $p &gt; 0$ e supponiamo che $E[|X|^p] &lt; +\\infty$. Scegliendo $h(x) = |x|^p$ e $\\epsilon = a^p$ (per $a &gt; 0$) nella disuguaglianza di Markov generalizzata, si ottiene: $P(|X|^p \\ge a^p) \\le \\frac{E[|X|^p]}{a^p}$.\n\nPoiché $|X|^p \\ge a^p$ è equivalente a $|X| \\ge a$ per $p &gt; 0$ e $a &gt; 0$, la disuguaglianza di Markov è: $P(|X| \\ge a) \\le \\frac{E[|X|^p]}{a^p}$.\n\nSpesso la disuguaglianza di Markov viene usata con $p = 1$: $P(|X| \\ge a) \\le \\frac{E[|X|]}{a}$.\n![[Pasted image 20250410125544.png]]\n### Disuguaglianza di Chebyshev\n\nLa disuguaglianza di Chebyshev è un altro caso particolare della disuguaglianza di Markov generalizzata. Supponiamo che la varianza di $X$, $Var(X) = \\sigma^2$, sia finita. Si sceglie $h(x) = (x - E[X])^2$ e $\\epsilon = \\epsilon^2$ (usando $\\epsilon$ per la distanza dalla media) nella disuguaglianza di Markov generalizzata.\n\n$P((X - E[X])^2 \\ge \\epsilon^2) \\le \\frac{E[(X - E[X])^2]}{\\epsilon^2}$.\n\nL&#039;evento $(X - E[X])^2 \\ge \\epsilon^2$ è equivalente a $|X - E[X]| \\ge \\epsilon$. Inoltre, $E[(X - E[X])^2] = Var(X)$. Quindi la disuguaglianza di Chebyshev è: $P(|X - E[X]| \\ge \\epsilon) \\le \\frac{Var(X)}{\\epsilon^2}$.\n\nQuesta disuguaglianza fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una quantità maggiore o uguale a $\\epsilon$, in termini della sua varianza. Il professore commenta che se $\\epsilon$ è piccolo, il limite potrebbe essere maggiore di 1 e quindi poco significativo, ma se la varianza è piccola, la probabilità di grandi deviazioni dalla media è limitata superiormente da un valore piccolo.\n![[Pasted image 20250410130840.png]]\n### Relazione tra Momenti Finiti\n\nIl professore introduce brevemente la relazione tra momenti finiti di ordini diversi. Se il momento $s$-esimo di $|X|$ è finito ($E[|X|^s] &lt; +\\infty$) e $r \\le s$, allora anche il momento $r$-esimo di $|X|$ è finito ($E[|X|^r] &lt; +\\infty$). Questa proprietà è stata dimostrata in precedenza utilizzando una disuguaglianza.\n\n### Disuguaglianza di Lyapunov\n\nLa disuguaglianza di Lyapunov fornisce una relazione più precisa tra i momenti finiti. Se $E[|X|^s] &lt; +\\infty$ per $s &gt; r \\ge 0$, allora: $(E[|X|^r])^{1/r} \\le (E[|X|^s])^{1/s}$.\n\nQuesta disuguaglianza implica che se il momento $s$-esimo è finito, allora anche tutti i momenti di ordine inferiore $r$ (con $r \\ge 0$) sono finiti. La disuguaglianza di Lyapunov può essere dimostrata come conseguenza della disuguaglianza di Jensen. Il termine $(E[|X|^p])^{1/p}$ è chiamato norma $L^p$ di $X$. La disuguaglianza di Lyapunov afferma che la norma $L^p$ è una funzione crescente di $p$.\n\n# Variabili Aleatorie con Momento $p$-esimo Finito e Spazi $L^p$\n\n## Osservazioni Preliminari sulle Disuguaglianze di Probabilità\n\n## Introduzione agli Spazi $L^p$\n\nSi introduce l&#039;argomento delle **variabili aleatorie con momento $p$-esimo finito**, che sono collegate agli **spazi $L^p$**. Il professore specifica che la trattazione sarà limitata al caso delle variabili aleatorie, senza approfondire la teoria generale degli spazi $L^p$ e della misura.\n\n### Definizione di $L^p$\n\nSi fissa $p &gt; 0$. Dato uno spazio di probabilità $(\\Omega, \\mathcal{F}, P)$, si definisce $L^p = L^p(\\Omega, \\mathcal{F}, P)$ (a volte indicato anche come $L^p(\\Omega)$ o semplicemente $L^p$) come l&#039;insieme di tutte le variabili aleatorie $X$ a valori reali (borelliani) tali che il loro **momento $p$-esimo è finito**, ovvero $E[|X|^p] &lt; \\infty$.\n\n### Proprietà degli Spazi $L^p$\n\nConsideriamo due variabili aleatorie $X$ e $Y$ definite sullo stesso spazio di probabilità, tali che $X \\in L^p$ e $Y \\in L^p$, cioè entrambe hanno momento $p$-esimo finito.\n\n#### Somma di Variabili Aleatorie in $L^p$\n\nUna domanda naturale è cosa si può dire di $X + Y$.\n\n- **Disuguaglianza Elementare per $|X + Y|^p$**: Si ricorda una disuguaglianza elementare:\n    \n    - Se $0 &lt; p \\le 1$, allora $|x + y|^p \\le |x|^p + |y|^p$ per ogni $x, y \\in \\mathbb{R}$.\n    - Se $p &gt; 1$, allora esiste una costante $C_p$ (che dipende da $p$) tale che $|x + y|^p \\le C_p (|x|^p + |y|^p)$ per ogni $x, y \\in \\mathbb{R}$. Questa disuguaglianza può essere dimostrata usando la proprietà di convessità della funzione $x \\mapsto |x|^p$ per $p &gt; 1$.\n      ![[Pasted image 20250410131418.png]]\n- **Chiusura di $L^p$ rispetto alla Somma**: Se $X_1 \\in L^p$ e $X_2 \\in L^p$, allora $X_1 + X_2 \\in L^p$.\n    \n    - Per dimostrarlo, si considera il momento $p$-esimo di $|X_1 + X_2|$:\n        - $E[|X_1 + X_2|^p] \\le E[C_p (|X_1|^p + |X_2|^p)] = C_p E[|X_1|^p] + C_p E[|X_2|^p] &lt; \\infty$, dove $C_p = 1$ se $0 &lt; p \\le 1$ e $C_p = 2^{p-1}$ se $p &gt; 1$ (quest&#039;ultima non è esplicitamente menzionata nel testo, ma è una forma comune della costante).\n    - Poiché $E[|X_1|^p] &lt; \\infty$ e $E[|X_2|^p] &lt; \\infty$, anche $E[|X_1 + X_2|^p]$ è finito, quindi $X_1 + X_2 \\in L^p$.\n- **Chiusura di $L^p$ rispetto alla Moltiplicazione per Scalare**: Se $X_1 \\in L^p$ e $a \\in \\mathbb{R}$, allora $aX_1 \\in L^p$.\n    \n    - $E[|aX_1|^p] = E[|a|^p |X_1|^p] = |a|^p E[|X_1|^p] &lt; \\infty$, dato che $E[|X_1|^p] &lt; \\infty$ e $|a|^p$ è una costante finita.\n      ![[Pasted image 20250410131648.png]]\n\n#### Relazione tra $L^p$ e $L^q$\n\nSe $X \\in L^p$, allora $X \\in L^q$ per ogni $0 &lt; q \\le p$. Questo significa che se il momento di ordine $p$ è finito, allora tutti i momenti di ordine inferiore $q$ (con $q \\le p$) sono anch&#039;essi finiti. Di conseguenza, gli spazi $L^p$ sono &quot;scatolati&quot; uno dentro l&#039;altro: più $p$ cresce, più l&#039;insieme $L^p$ diventa &quot;piccolo&quot; (nel senso dell&#039;inclusione).\n\n#### $L^p$ come Spazio Lineare\n\nLe proprietà di chiusura rispetto alla somma e alla moltiplicazione per scalare implicano che $L^p$ (sia la versione &quot;storta&quot; che quella &quot;dritta&quot;, come verrà spiegato) è uno **spazio vettoriale** (o spazio lineare). Questo significa che combinazioni lineari di elementi in $L^p$ rimangono in $L^p$.\n\n## Distinzione tra $L^p$ &quot;storto&quot; e $L^p$ &quot;dritto&quot;\n\nIl professore introduce una sottigliezza riguardante la definizione precisa degli spazi $L^p$, distinguendo tra una notazione $L^p$ &quot;piccolo&quot; (o &quot;storto&quot;) e una notazione $L^p$ &quot;grande&quot; (o &quot;dritto&quot;).\n\n### Il Problema di $L^p$ &quot;storto&quot;\n\nLo spazio $L^p$ &quot;storto&quot; è definito come l&#039;insieme delle variabili aleatorie (funzioni da $\\Omega$ a $\\mathbb{R}$) con momento $p$-esimo finito. Il problema con questa definizione è che possono esistere due variabili aleatorie $X$ e $X&#039;$ tali che $P(X(\\omega) = X&#039;(\\omega)) = 1$ (sono uguali quasi certamente), ma $X(\\omega) \\neq X&#039;(\\omega)$ per qualche $\\omega \\in \\Omega$. Considerate come funzioni, $X$ e $X&#039;$ sono distinte, ma ai fini probabilistici (calcolo di probabilità e valori attesi) si comportano in modo identico.\n\n### Spazi Vettoriali Normati e la Necessità di $L^p$ &quot;dritto&quot;\n\nUna proprietà fondamentale degli spazi vettoriali normati è che se la norma di un elemento è zero, allora l&#039;elemento deve essere l&#039;elemento nullo. Si introduce l&#039;idea di definire una **norma** sugli spazi $L^p$, chiamata **norma $p$**, definita come $||X||_p = (E[|X|^p])^{1/p}$ (per $p \\ge 1$).\n\nIl problema sorge con $L^p$ &quot;storto&quot; perché se $E[|X|^p] = 0$, ciò implica che $P(X = 0) = 1$, ma non necessariamente che $X(\\omega) = 0$ per ogni $\\omega \\in \\Omega$. Quindi, la norma $p$ potrebbe essere zero per una variabile aleatoria che non è identicamente nulla come funzione.\n\n### Definizione di $L^p$ &quot;dritto&quot; tramite Classi di Equivalenza\n\nPer ovviare a questo problema, si definisce $L^p$ &quot;dritto&quot; ($L^p$) come l&#039;insieme delle **classi di equivalenza** di variabili aleatorie in $L^p$ &quot;storto&quot;. La relazione di equivalenza è definita come: $X \\sim X&#039;$ se $P(X = X&#039;) = 1$ (uguaglianza quasi certa). Un elemento di $L^p$ &quot;dritto&quot; non è una singola funzione, ma un insieme di funzioni che sono tutte uguali quasi certamente. In questo modo, se la norma $p$ di una classe di equivalenza è zero, allora ogni rappresentante della classe è uguale a zero quasi certamente, e la classe di equivalenza è quella della variabile aleatoria identicamente nulla (quasi certamente).\n![[Pasted image 20250410132241.png]]\n### Disuguaglianza di Minkowski\n\nPer $p \\ge 1$, se $X_1 \\in L^p$ e $X_2 \\in L^p$, vale la **disuguaglianza di Minkowski**: $$(E[|X_1 + X_2|^p])^{1/p} \\le (E[|X_1|^p])^{1/p} + (E[|X_2|^p])^{1/p}$$ Questa disuguaglianza implica che $L^p$ &quot;dritto&quot; è uno spazio normato rispetto alla norma $||X||_p = (E[|X|^p])^{1/p}$ per $p \\ge 1$. La disuguaglianza triangolare per la norma deriva proprio dalla disuguaglianza di Minkowski.\n![[Pasted image 20250410132501.png]]\n### Osservazioni sulla Praticità\n\nIl professore rassicura che per la maggior parte delle applicazioni del corso, non sarà necessario preoccuparsi eccessivamente della distinzione tra $L^p$ &quot;storto&quot; e $L^p$ &quot;dritto&quot;. Spesso si continuerà a lavorare con le variabili aleatorie direttamente, tenendo presente che le uguaglianze e i limiti sono da intendersi quasi certamente. L&#039;introduzione di $L^p$ &quot;dritto&quot; serve principalmente a fornire una base matematica rigorosa per definire gli spazi $L^p$ come spazi normati.\n## La Proprietà Fondamentale degli Spazi Normati\n\nIn uno spazio normato, una proprietà essenziale è che la **norma di un elemento è zero se e solo se l&#039;elemento è l&#039;elemento nullo**. Matematicamente, questa proprietà si esprime come:\n\n$|x| = 0 \\iff x = 0$\n\ndove $x$ è un elemento dello spazio normato e $0$ è l&#039;elemento neutro rispetto all&#039;addizione (l&#039;elemento nullo).\n\nIl professore sottolinea che questa affermazione **non può essere fatta direttamente** sullo spazio delle funzioni $L^p$ &quot;storto&quot; (riferendosi allo spazio delle variabili aleatorie con momento $p$-esimo finito) senza l&#039;introduzione delle **classi di equivalenza**.\n\n## Necessità delle Classi di Equivalenza in $L^p$\n\nLa necessità delle classi di equivalenza nasce dal fatto che in $L^p$, una variabile aleatoria può avere **norma zero senza essere la variabile aleatoria nulla** in senso stretto. Questo accade perché la norma in $L^p$ è definita in termini di valore atteso. Ad esempio, se il valore atteso di $|X|^p$ è zero ($E[|X|^p] = 0$), ciò implica che la **probabilità che $X$ sia uguale a zero è uno** ($P(X=0) = 1$). Tuttavia, questo non significa che la variabile aleatoria $X$ sia identicamente zero su tutto lo spazio campionario; potrebbe essere diversa da zero su un insieme di probabilità zero.\n\nPer fare in modo che $L^p$ sia effettivamente uno spazio normato, è necessario considerare le **classi di equivalenza** di variabili aleatorie che sono **uguali quasi certamente**.\n\n### Definizione di Classi di Equivalenza\n\nLe classi di equivalenza sono definite a partire da una **relazione di equivalenza** su un insieme. Quozientare un insieme rispetto a una relazione di equivalenza significa che **un punto dello spazio quozientato rappresenta tutte le funzioni (o variabili aleatorie nel nostro caso) che sono equivalenti** secondo quella relazione.\n\nNel contesto di $L^p$, la relazione di equivalenza è l&#039;uguaglianza **quasi certa**. Due variabili aleatorie $X$ e $Y$ sono equivalenti ($X \\sim Y$) se $P(X = Y) = 1$. Una classe di equivalenza $[X]$ è quindi l&#039;insieme di tutte le variabili aleatorie $Y$ tali che $Y \\sim X$.\n![[Pasted image 20250410133222.png]]\n### Rappresentanti delle Classi di Equivalenza\n\nAll&#039;interno di una classe di equivalenza, si può scegliere un **rappresentante**. Un rappresentante conveniente potrebbe essere la variabile aleatoria identicamente zero, ma la classe contiene anche altre variabili che sono zero quasi certamente ma non ovunque.\n\nIl professore afferma che per la verifica che $L^p$ sia uno spazio vettoriale, non è strettamente necessario introdurre le classi di equivalenza. È sufficiente che la somma di due variabili aleatorie in $L^p$ appartenga ancora a $L^p$, e questo vale per la funzione che è la classe di equivalenza della somma.\n\n## Il Significato di Uguaglianza in $L^p$: &quot;Quasi Certamente&quot;\n\nIn $L^p$, quando si afferma che due variabili aleatorie sono uguali ($X = Y$), spesso questa uguaglianza deve essere interpretata nel senso di **uguaglianza quasi certa** ($P(X = Y) = 1$).\n\nIl professore fa notare che nel corso, spesso si incontreranno affermazioni come $X + Y = 0$, che in un contesto rigoroso di $L^p$ dovrebbero essere intese come $P(X + Y = 0) = 1$. Questa è una sottigliezza che emerge quando si lavora formalmente con gli spazi $L^p$ &quot;dritti&quot; (quozientati rispetto alle classi di equivalenza).\n\nUn altro esempio menzionato è che se il valore atteso di una variabile aleatoria $X$ (in $L^1$) è finito, allora la variabile aleatoria è **quasi certamente finita**.\n\n## Spazio Vettoriale $L^p$\n\nLo spazio $L^p$ è uno **spazio lineare**. Questo significa che se si prendono due variabili aleatorie $X$ e $Y$ appartenenti a $L^p$, e due scalari $a$ e $b$, allora la combinazione lineare $aX + bY$ appartiene ancora a $L^p$.\n\n$X_1, X_2 \\in L^p \\implies aX_1 + bX_2 \\in L^p, \\quad a, b \\in \\mathbb{R}$\n\nIl professore sottolinea che per dimostrare che $L^p$ è uno spazio lineare, **non è necessario introdurre le classi di equivalenza**.\n\n## Spazio Normato $L^p$ e la Norma\n\nPer definire una **norma** su $L^p$, e quindi fare di $L^p$ uno spazio normato, è necessario identificare le variabili aleatorie quasi certamente uguali, il che porta all&#039;introduzione dello spazio $L^p$ &quot;dritto&quot; (delle classi di equivalenza).\n\nLa norma in $L^p$ è definita come:\n\n$|X|_p = (E[|X|^p])^{1/p}$\n\nIl professore specifica che per poter definire una norma in questo modo e avere le proprietà di una norma (in particolare la disuguaglianza triangolare), è necessario che **$p \\ge 1$**. Se $p &lt; 1$, si può ancora definire una metrica, ma lo spazio non sarà uno spazio normato.\n\n## La Notazione $L^p$ &quot;Storto&quot; vs. $L^p$ &quot;Dritto&quot;\n\nIl professore utilizza la notazione $L^p$ &quot;storto&quot; per riferirsi allo spazio delle **variabili aleatorie** con momento $p$-esimo finito, mentre $L^p$ &quot;dritto&quot; si riferisce allo spazio delle **classi di equivalenza** di tali variabili aleatorie, dove l&#039;equivalenza è definita dall&#039;uguaglianza quasi certa.\n\nLa ragione per introdurre $L^p$ &quot;dritto&quot; è principalmente per avere uno spazio che soddisfi rigorosamente la definizione di spazio normato, in particolare la proprietà che norma zero implica l&#039;elemento nullo.\n\nTuttavia, il professore ammette che per la maggior parte delle applicazioni e concetti del corso, si può **ragionare direttamente sulle variabili aleatorie** senza necessariamente focalizzarsi sulle classi di equivalenza. Le affermazioni di uguaglianza dovranno essere interpretate tenendo conto che possono valere &quot;quasi certamente&quot;.\n\n## Esempio di Somma di Variabili Aleatorie con Momenti Infiniti\n![[Pasted image 20250410133507.png]]\nIl professore fornisce un esempio per illustrare che la somma di due variabili aleatorie che individualmente non hanno momento primo finito (e quindi non appartengono a $L^1$), può comunque avere momento primo finito.\n\nConsideriamo due variabili aleatorie:\n\n$X_1 = X_0 + \\mu$ $X_2 = -X_0$\n\ndove $E[|X_0|] = +\\infty$ e $\\mu$ è una costante. In questo caso, $E[|X_1|] = E[|X_0 + \\mu|]$ e $E[|X_2|] = E[|-X_0|] = E[|X_0|]$ potrebbero essere infiniti.\n\nTuttavia, la somma delle due variabili aleatorie è:\n\n$X_1 + X_2 = (X_0 + \\mu) + (-X_0) = \\mu$\n\nSe $\\mu$ è una costante finita, allora il suo valore atteso primo è finito ($E[|\\mu|] = |\\mu| &lt; \\infty$). Questo dimostra che **anche se singolarmente le variabili non appartengono a $L^1$, la loro somma può appartenervi**.\n\nIl professore conclude che se una variabile aleatoria appartiene a $L^p$, la stessa cosa vale per la sua classe di equivalenza. Inoltre, se abbiamo due variabili in $L^p$, la loro somma sarà ancora in $L^p$, ma non è detto che se due variabili non sono in $L^p$, la loro somma non possa esserlo.\n\n## Esercizi sulle Variabili Aleatorie\n\nIl professore raccomanda di esercitarsi su variabili aleatorie di diversi tipi: **discrete, assolutamente continue e miste**. Suggerisce di considerare esercizi elementari che richiedono l&#039;applicazione delle definizioni e il calcolo.\n\nEsempi di esercizi menzionati:\n\n- Massimo tra 0 e $X$ ($\\max(0, X)$): analizzare quando questa variabile è assolutamente continua e quando non lo è.\n- Funzione di ripartizione di $X + 3$, data la funzione di ripartizione di $X$.\n- Funzione di ripartizione di $X^2$ e $|X|$, data la funzione di ripartizione di $X$.\n\nÈ importante anche ripassare i concetti fondamentali di probabilità, come il **teorema di Bayes**, la probabilità elementare, il calcolo combinatorio, i valori attesi, i valori attesi di funzioni e le trasformazioni di variabili aleatorie.\n#### References\n\n\n\n2025-04-14 08:40\n\n_Status: #flashcard_zero  #riscritto_zero  #revisione_zero \n\n_Tags:[[sbobine]]   [[probabilità]]\n\n## prob-lez15\n\n\n# **Indipendenza di Variabili Aleatorie**\n\n## **Ripasso: Disuguaglianza di Cauchy-Schwarz**\n\n**Sottotitolo: Definizione e Proprietà**\n\nIl professore inizia la lezione riprendendo un argomento precedente, la disuguaglianza di Cauchy-Schwarz.\n\nSiano $X_1$ e $X_2$ due variabili aleatorie con valore atteso e momento secondo finito. Ciò significa che $X_1, X_2 \\in L^2$.\n\nVale la seguente disuguaglianza: $$|\\mathbb{E}[X_1 X_2]| \\le \\mathbb{E}[|X_1 X_2|] \\le \\sqrt{\\mathbb{E}[X_1^2] \\mathbb{E}[X_2^2]}$$ La seconda disuguaglianza è la versione della disuguaglianza di Cauchy-Schwarz.\n![[Pasted image 20250414090437.png]]\n**Sottotitolo: Conseguenza Importante**\n\nUna delle conseguenze di questa disuguaglianza è che se $X_1$ e $X_2$ hanno un momento secondo finito, il loro prodotto $X_1 X_2$ ha momento primo finito. In altre parole, se $X_1, X_2 \\in L^2$, allora $X_1 X_2 \\in L^1$.\n\n**Sottotitolo: Anticipazione sulla Covarianza**\n\nIl professore anticipa che questa disuguaglianza sarà ritrovata in una forma riscritta quando si parlerà di covarianza.\n\n**Sottotitolo: Dimostrazione (Cenni)**\n\nLa dimostrazione della disuguaglianza di Cauchy-Schwarz si basa sul considerare una variabile aleatoria positiva e sfruttare la linearità del valore atteso.\n\nSi fissa $A$ e $B$ e si considera il quadrato $(AX_1 + BX_2)^2$. Questa è una variabile aleatoria positiva, quindi il suo valore atteso è maggiore o uguale a zero: $$\\mathbb{E}[(AX_1 + BX_2)^2] \\ge 0$$ Sviluppando il quadrato e usando la linearità del valore atteso si ottiene: $$A^2 \\mathbb{E}[X_1^2] + B^2 \\mathbb{E}[X_2^2] + 2AB \\mathbb{E}[X_1 X_2] \\ge 0$$ Questa espressione è una forma quadratica in $A$ e $B$ che può essere scritta come $\\mathbf{v}^T C \\mathbf{v} \\ge 0$, dove $\\mathbf{v} = \\begin{pmatrix} A \\ B \\end{pmatrix}$ e $C = \\begin{pmatrix} \\mathbb{E}[X_1^2] &amp; \\mathbb{E}[X_1 X_2] \\ \\mathbb{E}[X_1 X_2] &amp; \\mathbb{E}[X_2^2] \\end{pmatrix}$.\n\nPoiché questa forma quadratica è sempre maggiore o uguale a zero, la matrice $C$ è semidefinita positiva, e quindi il suo determinante è maggiore o uguale a zero: $$\\det(C) = \\mathbb{E}[X_1^2] \\mathbb{E}[X_2^2] - (\\mathbb{E}[X_1 X_2])^2 \\ge 0$$ Da cui si ricava: $$(\\mathbb{E}[X_1 X_2])^2 \\le \\mathbb{E}[X_1^2] \\mathbb{E}[X_2^2]$$ Prendendo la radice quadrata di entrambi i membri si ottiene la tesi (in modulo): $$|\\mathbb{E}[X_1 X_2]| \\le \\sqrt{\\mathbb{E}[X_1^2] \\mathbb{E}[X_2^2]}$$\n![[Pasted image 20250414091513.png]]\n## **Introduzione all&#039;Indipendenza di Variabili Aleatorie**\n\n**Sottotitolo: Definizione di Indipendenza per Famiglie di Sigma Algebre**\n\nIl professore introduce il nuovo argomento dell&#039;indipendenza di variabili aleatorie partendo dalla definizione di indipendenza per famiglie di sigma algebre.\n\nConsideriamo una famiglia di sotto sigma algebre ${ \\mathcal{G}_i }_{i \\in I}$ di una sigma algebra madre $\\mathcal{F}$ su cui è definita una misura di probabilità $\\mathbb{P}$.\n\nQueste sigma algebre sono dette **indipendenti** se per ogni successione finita di indici distinti $j_1, j_2, \\dots, j_k$ contenuti in $I$ (cioè, per ogni $k \\ge 1$ e $j_1, \\dots, j_k \\in I$, con $j_r \\neq j_s$ per $r \\neq s$) e per ogni scelta di eventi $B_{j_1} \\in \\mathcal{G}_{j_1}, B_{j_2} \\in \\mathcal{G}_{j_2}, \\dots, B_{j_k} \\in \\mathcal{G}_{j_k}$, si ha: $$\\mathbb{P}\\left( \\bigcap_{r=1}^{k} B_{j_r} \\right) = \\prod_{r=1}^{k} \\mathbb{P}(B_{j_r})$$\n![[Pasted image 20250414092043.png]]\n**Sottotitolo: Confronto con l&#039;Indipendenza di Eventi**\n\nLa differenza con la definizione di indipendenza di eventi è che in quel caso si considera una famiglia di eventi, mentre qui si considera una famiglia di sigma algebre. Per verificare l&#039;indipendenza di sigma algebre, è necessario considerare tutte le possibili scelte di eventi, uno da ciascuna sigma algebra nella sottofamiglia considerata.\n\n**Sottotitolo: Esercizio Mentale**\n\nIl professore propone un esercizio mentale per confrontare le due definizioni.\n\n**Sottotitolo: Caso Particolare: Due Eventi**\n\nConsideriamo il caso in cui l&#039;insieme degli indici $I$ è costituito solo da due elementi, $I = \\set{1, 2}$. Siano $\\mathcal{G}_1 = \\sigma(B_1)$ la sigma algebra generata da un evento $B_1$ e $\\mathcal{G}_2 = \\sigma(B_2)$ la sigma algebra generata da un evento $B_2$.\n\nRicordiamo che $\\sigma(B_1) = \\set{ \\emptyset, B_1, B_1^c, \\Omega }$ e $\\sigma(B_2) = \\set{ \\emptyset, B_2, B_2^c, \\Omega }$.\n\nVerificare che $B_1$ e $B_2$ sono indipendenti (nel senso di $\\mathbb{P}(B_1 \\cap B_2) = \\mathbb{P}(B_1) \\mathbb{P}(B_2)$) è del tutto equivalente a dire che le sigma algebre $\\mathcal{G}_1$ e $\\mathcal{G}_2$ sono indipendenti. Questo si dimostra considerando tutte le possibili coppie di eventi, uno da $\\mathcal{G}_1$ e uno da $\\mathcal{G}_2$, e verificando la condizione di fattorizzazione della probabilità dell&#039;intersezione.\n![[Pasted image 20250414092408.png]]\n**Sottotitolo: Generalizzazione a più di Due Oggetti**\n\nLa definizione più generale di indipendenza per sigma algebre è introdotta per poter trattare l&#039;indipendenza di oggetti più complessi di semplici eventi.\n\n**Sottotitolo: Esercizio di Ripasso sull&#039;Indipendenza di Eventi**\n\nIl professore ricorda un esercizio svolto in precedenza: se $A$ e $B$ sono eventi indipendenti, allora anche $A$ e $B^c$, $A^c$ e $B$, $A^c$ e $B^c$ sono indipendenti. Questo può essere verificato come esercizio utilizzando la definizione di indipendenza di sigma algebre nel caso di due eventi.\n\n## **Indipendenza di Variabili Aleatorie**\n\n**Sottotitolo: Definizione della Sigma Algebra Generata da una Variabile Aleatoria**\n\nSia $X$ una variabile aleatoria definita sullo spazio di probabilità $(\\Omega, \\mathcal{F}, \\mathbb{P})$ a valori in uno spazio misurabile $(E, \\mathcal{E})$. La **sigma algebra generata da $X$**, denotata con $\\sigma(X)$, è la sigma algebra generata dalle controimmagini degli insiemi misurabili di $E$ sotto $X$: $$\\sigma(X) = { X^{-1}(D) : D \\in \\mathcal{E} }$$ $X^{-1}(D) = { \\omega \\in \\Omega : X(\\omega) \\in D }$ è un evento in $\\mathcal{F}$ poiché $X$ è una variabile aleatoria. In generale, $\\sigma(X) \\subseteq \\mathcal{F}$, e può essere strettamente contenuta in $\\mathcal{F}$ (ad esempio, se $X$ è costante, $\\sigma(X)$ è la sigma algebra banale ${ \\emptyset, \\Omega }$).\n\n**Sottotitolo: Definizione di Indipendenza per Variabili Aleatorie**\n\nSiano $X_1, X_2, \\dots, X_n$ variabili aleatorie, dove $X_i$ è definita su $(\\Omega, \\mathcal{F}, \\mathbb{P})$ e a valori in $(E_i, \\mathcal{E}_i)$. Le variabili aleatorie $X_1, X_2, \\dots, X_n$ sono dette **indipendenti** se per ogni scelta di insiemi misurabili $\\forall B_1 \\in \\mathcal{E}_1, B_2 \\in \\mathcal{E}_2, \\dots, B_n \\in \\mathcal{E}_n$, si ha: $$\\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2, \\dots, X_n \\in B_n) = \\mathbb{P}(X_1 \\in B_1) \\mathbb{P}(X_2 \\in B_2) \\dots \\mathbb{P}(X_n \\in B_n)$$ Utilizzando la notazione per le controimmagini, questa condizione può essere riscritta come: $$\\mathbb{P}\\left( \\bigcap_{i=1}^{n} { X_i \\in B_i } \\right) = \\prod_{i=1}^{n} \\mathbb{P}(X_i \\in B_i)$$ o equivalentemente: $$\\mathbb{P}\\left( \\bigcap_{i=1}^{n} X_i^{-1}(B_i) \\right) = \\prod_{i=1}^{n} \\mathbb{P}(X_i^{-1}(B_i))$$\n\n**Sottotitolo: Equivalenza con l&#039;Indipendenza delle Sigma Algebre Generate**\n\nL&#039;indipendenza delle variabili aleatorie $X_1, \\dots, X_n$ (secondo la definizione appena data) è equivalente all&#039;indipendenza delle sigma algebre generate $\\sigma(X_1), \\sigma(X_2), \\dots, \\sigma(X_n)$. Questo perché l&#039;evento ${ X_i \\in B_i }$ è proprio un elemento della sigma algebra generata da $X_i$. Quindi, la definizione di indipendenza per variabili aleatorie è un caso particolare della definizione più generale di indipendenza per sigma algebre.\n![[Pasted image 20250414092657.png]]\n**Sottotitolo: Osservazione sull&#039;Indipendenza di Sottoinsiemi**\n\nSe $X_1, X_2, X_3$ sono variabili aleatorie indipendenti, allora anche $X_1$ e $X_2$ sono indipendenti. Questo può essere visto considerando $B_1 \\in \\mathcal{E}_1$ e $B_2 \\in \\mathcal{E}_2$. Allora: $$\\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2) = \\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2, X_3 \\in \\Omega)$$ Poiché $X_1, X_2, X_3$ sono indipendenti e $X_3 \\in \\Omega$ è un evento con probabilità 1, si ha: $$\\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2, X_3 \\in \\Omega) = \\mathbb{P}(X_1 \\in B_1) \\mathbb{P}(X_2 \\in B_2) \\mathbb{P}(X_3 \\in \\Omega) = \\mathbb{P}(X_1 \\in B_1) \\mathbb{P}(X_2 \\in B_2) \\cdot 1$$ Quindi $X_1$ e $X_2$ sono indipendenti. Questa proprietà si generalizza a un numero arbitrario di variabili indipendenti: ogni sottoinsieme di variabili indipendenti è anch&#039;esso indipendente.\n![[Pasted image 20250414094028.png]]\n**Sottotitolo: Natura degli Spazi di Arrivo**\n\nIl professore sottolinea che gli spazi di arrivo delle variabili aleatorie non devono necessariamente essere $\\mathbb{R}$. Si possono avere variabili a valori in $\\mathbb{R}^n$ (vettori aleatori) o in spazi diversi.\n\n## **Teoremi sull&#039;Indipendenza**\n\n**Sottotitolo: Teorema sulle P-Classi**\n\n**Enunciato (senza dimostrazione)**: Siano ${ \\mathcal{G}_i }_{i \\in I}$ una famiglia di sigma algebre e ${ \\mathcal{C}_i }_{i \\in I}$ una famiglia di P-classi sugli spazi di arrivo corrispondenti, tali che ogni $\\mathcal{C}_i$ contenga lo spazio totale e generi la sigma algebra $\\mathcal{G}_i$ (cioè, $\\sigma(\\mathcal{C}_i) = \\mathcal{G}_i$). Se per ogni successione finita di indici distinti $j_1, \\dots, j_k \\in I$ e per ogni scelta di insiemi $B_{j_1} \\in \\mathcal{C}_{j_1}, \\dots, B_{j_k} \\in \\mathcal{C}_{j_k}$, si ha: $$\\mathbb{P}\\left( \\bigcap_{r=1}^{k} B_{j_r} \\right) = \\prod_{r=1}^{k} \\mathbb{P}(B_{j_r})$$ allora le sigma algebre ${ \\mathcal{G}_i }_{i \\in I}$ sono indipendenti.\n![[Pasted image 20250414094330.png]]\n**Commento:** Questo teorema fornisce un criterio più semplice per verificare l&#039;indipendenza di sigma algebre, in quanto è sufficiente controllare la fattorizzazione della probabilità solo per gli elementi di P-classi che generano le sigma algebre, anziché per tutti gli elementi delle sigma algebre stesse. Questo è particolarmente utile nel caso di variabili aleatorie.\n\n**Sottotitolo: Teorema sul Valore Atteso di Funzioni di Variabili Indipendenti**\n\n**Teorema (senza dimostrazione)**: Siano $X_1, \\dots, X_n$ variabili aleatorie indipendenti, dove $X_i$ è a valori in $(E_i, \\mathcal{E}_i)$. Allora le seguenti proprietà sono equivalenti:\n\n1. Le variabili aleatorie $X_1, \\dots, X_n$ sono indipendenti.\n2. Per ogni scelta di funzioni misurabili e limitate $g_i: (E_i, \\mathcal{E}_i) \\to (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$, si ha: $$\\mathbb{E}[g_1(X_1) g_2(X_2) \\dots g_n(X_n)] = \\mathbb{E}[g_1(X_1)] \\mathbb{E}[g_2(X_2)] \\dots \\mathbb{E}[g_n(X_n)]$$\n3. Esiste una collezione di P-classi $\\mathcal{C}_i$ negli spazi di arrivo $(E_i, \\mathcal{E}_i)$ tali che ogni $\\mathcal{C}_i$ contiene $\\Omega$ (anche se il professore nota in che questa condizione potrebbe non essere strettamente necessaria in generale per la definizione di P-classe, ma è rilevante in questo contesto) e genera la sigma algebra $\\mathcal{E}_i$. In tal caso, le variabili aleatorie $X_1, \\dots, X_n$ sono indipendenti se e solo se per ogni scelta di $B_i \\in \\mathcal{C}_i$, si ha: $$\\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2, \\dots, X_n \\in B_n) = \\mathbb{P}(X_1 \\in B_1) \\mathbb{P}(X_2 \\in B_2) \\dots \\mathbb{P}(X_n \\in B_n)$$ In altre parole, l&#039;indipendenza delle sigma algebre generate dalle variabili aleatorie può essere verificata controllando la fattorizzazione della probabilità solo sugli elementi di queste P-classi generatrici. Questo fornisce un **criterio più comodo per verificare l&#039;indipendenza** poiché le P-cla ssi sono spesso più semplici da controllare rispetto all&#039;intera sigma algebra. Un esempio menzionato è nel caso di variabili aleatorie reali, dove la P-classe delle semirette chiuse $(-\\infty, x]$ (unite eventualmente con $\\mathbb{R}$) genera i boreliani di $\\mathbb{R}$.\n\nQuesto terzo punto è strettamente legato alla verifica pratica dell&#039;indipendenza, specialmente quando gli spazi di arrivo hanno una struttura complessa. Controllare la fattorizzazione per tutti gli insiemi misurabili potrebbe essere difficile, mentre restringerla a una P-classe generatrice può semplificare il compito.\n\n![[Pasted image 20250414095211.png]]\n**Commento:** Questo teorema stabilisce che l&#039;indipendenza implica la fattorizzazione del valore atteso di prodotti di funzioni delle singole variabili. Viceversa, se questa fattorizzazione vale per tutte le funzioni misurabili e limitate, allora le variabili sono indipendenti. Un caso particolare importante si ottiene scegliendo le $g_i$ come funzioni indicatrici di insiemi $B_i \\in \\mathcal{E}_i$, che riconduce alla definizione di indipendenza.\n\n**Sottotitolo: Corollario per Variabili Aleatorie Reali e Funzione di Ripartizione**\n\n**Proposizione (Corollario)**: Siano $X_1, \\dots, X_n$ variabili aleatorie reali (a valori in $\\mathbb{R}$). Esse sono indipendenti se e solo se la funzione di ripartizione congiunta del vettore $(X_1, \\dots, X_n)$ è uguale al prodotto delle funzioni di ripartizione marginali delle singole variabili.\n\nLa funzione di ripartizione congiunta è definita come: $$F_{X_1, \\dots, X_n}(x_1, \\dots, x_n) = \\mathbb{P}(X_1 \\le x_1, \\dots, X_n \\le x_n)$$ dove $x_i \\in \\mathbb{R}$ per $i = 1, \\dots, n$.\n\nLa condizione di indipendenza in termini di funzioni di ripartizione è: $$F_{X_1, \\dots, X_n}(x_1, \\dots, x_n) = F_{X_1}(x_1) F_{X_2}(x_2) \\dots F_{X_n}(x_n)$$ dove $F_{X_i}(x_i) = \\mathbb{P}(X_i \\le x_i)$ è la funzione di ripartizione marginale di $X_i$.\n\n**Dimostrazione (Cenni)**:\n\n- **$(\\Rightarrow)$** Se $X_1, \\dots, X_n$ sono indipendenti, allora per definizione per gli insiemi $B_i = (-\\infty, x_i]$, si ha: $$\\mathbb{P}(X_1 \\in (-\\infty, x_1], \\dots, X_n \\in (-\\infty, x_n]) = \\prod_{i=1}^{n} \\mathbb{P}(X_i \\in (-\\infty, x_i])$$ che è esattamente la condizione sulle funzioni di ripartizione.\n    \n- **$(\\Leftarrow)$** Supponiamo che la funzione di ripartizione congiunta sia il prodotto delle marginali. Per dimostrare l&#039;indipendenza, dobbiamo mostrare che per ogni scelta di insiemi boreliani $B_1, \\dots, B_n$, si ha $\\mathbb{P}(X_1 \\in B_1, \\dots, X_n \\in B_n) = \\prod_{i=1}^{n} \\mathbb{P}(X_i \\in B_i)$. Si utilizza il teorema sulle P-classi enunciato precedentemente. La classe delle semirette $(-\\infty, x]$ (unita a $\\mathbb{R}$) è una P-classe che genera la sigma algebra dei boreliani su $\\mathbb{R}$. Poiché la fattorizzazione vale per intersezioni di insiemi di questa forma (per ipotesi sulla funzione di ripartizione), allora per il teorema sulle P-classi, le sigma algebre generate da $X_1, \\dots, X_n$ (che contengono tutti gli eventi ${ X_i \\in B_i }$ per $B_i$ boreliani) sono indipendenti, e quindi le variabili aleatorie sono indipendenti.\n    ![[Pasted image 20250414095503.png]]\n\n**Commento:** Questa proposizione fornisce un criterio pratico per verificare l&#039;indipendenza di variabili aleatorie reali, basato sulle loro funzioni di ripartizione. Ha il vantaggio di valere sia per variabili assolutamente continue che discrete, e in generale per qualsiasi tipo di variabile aleatoria reale.\n\n___\n\n# Indipendenza di Variabili Aleatorie\n\n## Definizione di P-Classi\n\nPer un motivo tecnico, le $\\mathcal{P}$-classi devono avere misura totale. In generale, per come sono definite le $\\mathcal{P}$-classi, questa condizione non è strettamente necessaria. Tuttavia, per alcuni risultati che si basano sulle $\\mathcal{P}$-classi, come l&#039;esempio trattato, è richiesto un requisito leggermente più forte.\n\n## Indipendenza nel Caso Discreto\n\nSiano $X_1, \\dots, X_n$ variabili aleatorie discrete con codominio finito o numerabile in $\\mathbb{R}$.\n\n**Definizione:** $X_1, \\dots, X_n$ sono **indipendenti** se e solo se la densità discreta del vettore $(X_1, \\dots, X_n)$ fattorizza. Questo significa che per ogni scelta di $x_1, \\dots, x_n \\in \\mathbb{R}$, vale: $P(X_1 = x_1, \\dots, X_n = x_n) = P(X_1 = x_1) \\cdot \\dots \\cdot P(X_n = x_n) = \\prod_{i=1}^{n} P(X_i = x_i)$\n\nQuesta uguaglianza può essere riscritta esplicitamente come la probabilità che $X_1$ sia uguale a $x_1$ (piccolo), ..., $X_n$ sia uguale a $x_n$ (piccolo) è uguale al prodotto per $i$ che va da $1$ a $n$ della probabilità che $X_i$ sia uguale a $x_i$, per ogni $x_1, \\dots, x_n$ opportuni per cui questa espressione abbia senso.\n![[Pasted image 20250414095950.png]]\n**Importante:** Questa scrittura è valida solo nel caso di variabili aleatorie discrete. Se $X_1, \\dots, X_n$ fossero variabili assolutamente continue, si otterrebbe $0 = 0$, sia nel caso di dipendenza che di indipendenza. Per questo motivo, la definizione generale di indipendenza si basa sulla probabilità che il vettore appartenga a un prodotto cartesiano di insiemi, come vedremo in seguito. Nel **caso discreto**, ci si può restringere agli insiemi costituiti da un singolo punto.\n\n## Criterio Generale di Indipendenza per Variabili Reali\n\nPer variabili reali, esiste un criterio di indipendenza che vale in qualunque caso (discreto, continuo, misto). Siano $X_1, \\dots, X_n$ variabili aleatorie reali. Esse sono indipendenti se e solo se per ogni $x_1, \\dots, x_n \\in \\mathbb{R}$, si ha: $P(X_1 \\le x_1, \\dots, X_n \\le x_n) = P(X_1 \\le x_1) \\cdot \\dots \\cdot P(X_n \\le x_n) = \\prod_{i=1}^{n} P(X_i \\le x_i)$ Questa condizione è equivalente all&#039;indipendenza per variabili reali in generale.\n\n## Intuizione dell&#039;Indipendenza\n\nL&#039;indipendenza di variabili aleatorie è una proprietà che generalizza l&#039;indipendenza di eventi. Dire che $X_1$ e $X_2$ sono indipendenti significa che la conoscenza del valore assunto da una variabile non implica alcuna informazione sulla conoscenza del valore assunto dall&#039;altra.\n\n## Esempio 1: Variabili Dipendenti Deterministamente\n\nConsideriamo una variabile aleatoria $X$ a valori reali e definiamo $X_1 = X$ e $X_2 = X^2$. \nNon facciamo ipotesi specifiche sulla natura di $X$ (discreta, continua, ecc.).\n\n**Affermazione:** $X_1$ e $X_2$ sono dipendenti. Intuitivamente, questo è vero perché $X_2$ è una funzione deterministica di $X_1$. Se conosciamo il valore di $X_1$, conosciamo univocamente il valore di $X_2$. Questa è una forma di dipendenza molto forte, detta **dipendenza deterministica**.\n\n**Verifica stocastica della dipendenza:** Per dimostrare che $X_1$ e $X_2$ non sono indipendenti dal punto di vista stocastico, è sufficiente trovare una coppia di eventi per cui la probabilità dell&#039;intersezione non è uguale al prodotto delle probabilità. Consideriamo gli eventi ${X_1 \\le 2}$ e ${X_2 \\le 9}$.\n\nLa probabilità dell&#039;intersezione è: $P(X_1 \\le 2, X_2 \\le 9) = P(X \\le 2, X^2 \\le 9)$ L&#039;evento ${X^2 \\le 9}$ è equivalente a ${ -3 \\le X \\le 3 }$. Quindi: $P(X \\le 2, X^2 \\le 9) = P(X \\le 2, -3 \\le X \\le 3) = P(-3 \\le X \\le 2)$\n\nOra consideriamo il prodotto delle probabilità degli eventi singoli: $P(X_1 \\le 2) P(X_2 \\le 9) = P(X \\le 2) P(X^2 \\le 9) = P(X \\le 2) P(-3 \\le X \\le 3)$\n\nIn generale, $P(-3 \\le X \\le 2)$ è diverso da $P(X \\le 2) P(-3 \\le X \\le 3)$. Scegliendo opportunamente la legge di probabilità di $X$, è possibile trovare casi in cui queste due quantità sono diverse. Pertanto, $X_1$ e $X_2$ non sono indipendenti.\n![[Pasted image 20250414100512.png]]\n## Esempio 2: Variabili Discrete Dipendenti\n\nConsideriamo due variabili aleatorie discrete $X_1$ e $X_2$ con i seguenti possibili valori: $X_1 \\in {1, 2}$ e $X_2 \\in {0, 1}$. Supponiamo che la distribuzione di probabilità congiunta sia data dalla seguente tabella:\n\n| $X_1 \\setminus X_2$ | 0   | 1   |\n| :------------------ | :-- | :-- |\n| 1                   | 1/2 | 1/4 |\n| 2                   | 0   | 1/4 |\n\nPer verificare se $X_1$ e $X_2$ sono indipendenti, controlliamo se $P(X_1 = x_1, X_2 = x_2) = P(X_1 = x_1) P(X_2 = x_2)$ per tutte le coppie $(x_1, x_2)$. Consideriamo il caso $x_1 = 1$ e $x_2 = 0$.\n\nDalla tabella, $P(X_1 = 1, X_2 = 0) = 1/2$.\n\nCalcoliamo le probabilità marginali: $P(X_1 = 1) = P(X_1 = 1, X_2 = 0) + P(X_1 = 1, X_2 = 1) = 1/2 + 1/4 = 3/4$ $P(X_2 = 0) = P(X_1 = 1, X_2 = 0) + P(X_1 = 2, X_2 = 0) = 1/2 + 0 = 1/2$\n\n| $X_1 \\setminus X_2$ | 0     | 1       |           |\n| :------------------ | :---- | :------ | --------- |\n| 1                   | 1/2   | 1/4     | 1/2 + 1/4 |\n| 2                   | 0     | 1/4     | 0+1/4     |\n|                     | 1/2+0 | 1/4+1/4 |           |\n\nOra verifichiamo la condizione di indipendenza: $P(X_1 = 1) P(X_2 = 0) = (3/4) \\cdot (1/2) = 3/8$\n\nPoiché $P(X_1 = 1, X_2 = 0) = 1/2 \\neq 3/8 = P(X_1 = 1) P(X_2 = 0)$, le variabili aleatorie $X_1$ e $X_2$ non sono indipendenti. Abbiamo trovato almeno una coppia di valori per cui la condizione di fattorizzazione non è soddisfatta.\n\n## Esempio 3: Costruzione di Variabili Discrete Indipendenti con le Stesse Marginali\n\nConsideriamo le stesse marginali di $X_1$ e $X_2$ dell&#039;esempio precedente: $P(X_1 = 1) = 3/4$, $P(X_1 = 2) = 1/4$ $P(X_2 = 0) = 1/2$, $P(X_2 = 1) = 1/2$\n\nVogliamo costruire due nuove variabili aleatorie discrete, $\\tilde X_{1}$ e $\\tilde X_{2}$, con queste stesse marginali ma che siano indipendenti. Per l&#039;indipendenza, la probabilità congiunta deve essere il prodotto delle probabilità marginali per ogni coppia di valori:\n\n$P(\\tilde X_{1} = 1, \\tilde X_{2} = 0) = P(\\tilde X_{1} = 1) P(\\tilde X_{2} = 0) = (3/4) \\cdot (1/2) = 3/8$ $P(\\tilde X_{1} = 1, \\tilde X_{2} = 1) = P(\\tilde X_{1} = 1) P(\\tilde X_{2} = 1) = (3/4) \\cdot (1/2) = 3/8$ $P(\\tilde X_{1} = 2, \\tilde X_{2} = 0) = P(\\tilde X_{1} = 2) P(\\tilde X_{2} = 0) = (1/4) \\cdot (1/2) = 1/8$ $P(\\tilde X_{1} = 2, \\tilde X_{2} = 1) = P(\\tilde X_{1} = 2) P(\\tilde X_{2} = 1) = (1/4) \\cdot (1/2) = 1/8$\n\nLa tabella di probabilità congiunta per $\\tilde X_{1}$ e $\\tilde X_{2}$ è quindi:\n\n| $\\tilde X_{1} \\setminus \\tilde X_{2}$ | 0   | 1   |     |\n| :------------------------------------ | :-- | :-- | --- |\n| 1                                     | 3/8 | 3/8 | 1/2 |\n| 2                                     | 1/8 | 1/8 | 1/2 |\n|                                       | 3/4 | 1/4 |     |\n\nVerifichiamo che le marginali siano corrette: $P(\\tilde X_{1} = 1) = 3/8 + 3/8 = 6/8 = 3/4$ $P(\\tilde X_{1} = 2) = 1/8 + 1/8 = 2/8 = 1/4$ $P(\\tilde X_{2} = 0) = 3/8 + 1/8 = 4/8 = 1/2$ $P(\\tilde X_{2} = 1) = 3/8 + 1/8 = 4/8 = 1/2$\n\nLe marginali di $\\tilde X_{1}$ sono uguali alle marginali di $X_1$, e le marginali di $\\tilde X_{2}$ sono uguali alle marginali di $X_2$. Tuttavia, le leggi congiunte $(X_1, X_2)$ e $(\\tilde X_{1}, \\tilde X_{2})$ sono diverse, poiché una coppia di variabili è dipendente e l&#039;altra è indipendente.\n![[Pasted image 20250414101251.png]]\n**Osservazione:** Non si può affermare che $X_1 = \\tilde X_{1}$ con probabilità 1, in quanto non è stato definito lo spazio $\\Omega$ su cui sono definite queste variabili aleatorie. Potrebbero persino essere definite su spazi di probabilità diversi, rendendo priva di significato l&#039;espressione $P(X_1 = \\tilde X_{1})$.\n\n## Indipendenza e Leggi Immagine\n\nConsideriamo due variabili aleatorie $X_1$ e $X_2$ indipendenti. Sia $B_1$ un boreliano nello spazio di arrivo di $X_1$ e $B_2$ un boreliano nello spazio di arrivo di $X_2$. Allora, l&#039;evento ${X_1 \\in B_1 \\text{ e } X_2 \\in B_2}$ corrisponde al fatto che la coppia $(X_1, X_2)$ appartiene al prodotto cartesiano $B_1 \\times B_2$ nello spazio prodotto.\n\nLa probabilità di questo evento è data dalla legge immagine della variabile aleatoria vettoriale $(X_1, X_2)$ calcolata sul boreliano $B_1 \\times B_2$. Per l&#039;indipendenza, questa probabilità è uguale al prodotto delle probabilità marginali: $P(X_1 \\in B_1, X_2 \\in B_2) = P(X_1 \\in B_1) P(X_2 \\in B_2)$\n\nIn termini di leggi immagine, se $\\mu_1$ è la legge immagine di $X_1$ e $\\mu_2$ è la legge immagine di $X_2$, e $\\mu_{12}$ è la legge immagine di $(X_1, X_2)$, allora l&#039;indipendenza implica che per ogni coppia di boreliani $B_1$ e $B_2$, si ha: $\\mu_{12}(B_1 \\times B_2) = \\mu_1(B_1) \\mu_2(B_2)$\n![[Pasted image 20250414101621.png]]\nQuesto suggerisce che la proprietà di indipendenza può essere vista nello spazio immagine, confrontando la legge congiunta con il prodotto delle leggi marginali.\n\n**Attenzione:** Se si conoscono solo le leggi immagine marginali $\\mu_1$ e $\\mu_2$, in generale non è possibile ricostruire univocamente la legge immagine congiunta $\\mu_{12}$ senza l&#039;ulteriore ipotesi di indipendenza. Tuttavia, se si assume l&#039;indipendenza, la legge congiunta è univocamente determinata dal prodotto delle marginali. L&#039;esempio discreto precedente illustra come, a partire dalle leggi marginali, si possa costruire una legge congiunta che soddisfi l&#039;indipendenza.\n\nLa motivazione per questo approccio è che spesso si lavora nello spazio di arrivo e si hanno informazioni sulle marginali, e si vuole costruire o studiare misure di probabilità sul prodotto di spazi.\n\n___\n# Misure Prodotto e Integrazione su Spazi Prodotto\n\n## Introduzione alle Misure Prodotto\n\nIl professore introduce il concetto di misure prodotto come generalizzazione di idee già incontrate, in particolare nel contesto delle misure di probabilità. Si anticipa che questo argomento è fondamentale e si lega al concetto di indipendenza. L&#039;obiettivo è definire una misura su uno spazio prodotto a partire da misure definite sugli spazi componenti. Oltre alle misure di probabilità, si applicherà questo concetto alla misura di Lebesgue.\n\n## Costruzione dello Spazio Prodotto e della Sigma Algebra Prodotto\n\n### Spazio Prodotto\n\nDati due spazi misurabili $(E_1, \\mathcal{E}_1)$ e $(E_2, \\mathcal{E}_2)$, lo **spazio prodotto** è definito come l&#039;insieme delle coppie: $E = E_1 \\times E_2 = {(e_1, e_2) \\mid e_1 \\in E_1, e_2 \\in E_2}$. Tipicamente, $E_1$ e $E_2$ saranno $\\mathbb{R}$ con la sigma algebra dei Boreliani $\\mathcal{B}(\\mathbb{R})$, quindi lo spazio prodotto sarà $\\mathbb{R}^2$.\n\n### Sigma Algebra Prodotto\n\nPer definire una misura sullo spazio prodotto, è necessario dotarlo di una sigma algebra. La **sigma algebra prodotto** $\\mathcal{E}_1 \\otimes \\mathcal{E}_2$ è definita come la più piccola sigma algebra su $E_1 \\times E_2$ che contiene i **rettangoli misurabili** della forma $A_1 \\times A_2$, dove $A_1 \\in \\mathcal{E}_1$ e $A_2 \\in \\mathcal{E}_2$.\n\nIn altre parole: $\\mathcal{E}_1 \\otimes \\mathcal{E}_2 = \\sigma({A_1 \\times A_2 \\mid A_1 \\in \\mathcal{E}_1, A_2 \\in \\mathcal{E}_2})$.\n![[Pasted image 20250414102036.png]]\nQuesta costruzione imita il modo in cui si definiscono i Boreliani di $\\mathbb{R}^2$ a partire dai Boreliani di $\\mathbb{R}$. Infatti, si ha che $\\mathcal{B}(\\mathbb{R}) \\otimes \\mathcal{B}(\\mathbb{R}) = \\mathcal{B}(\\mathbb{R}^2)$. Il professore sottolinea che questa uguaglianza è vera per i Boreliani di $\\mathbb{R}$, ma potrebbe non valere in situazioni più generali.\n![[Pasted image 20250414102105.png]]\n## Costruzione della Misura Prodotto\n\n### Teorema di Esistenza e Unicità della Misura Prodotto\n\n**Teorema:** Siano $(E_1, \\mathcal{E}_1, \\mu_1)$ e $(E_2, \\mathcal{E}_2, \\mu_2)$ due spazi misurabili con misure $\\sigma$-finite $\\mu_1$ e $\\mu_2$. Allora esiste un&#039;unica misura $\\sigma$-finita $\\mu$ sulla sigma algebra prodotto $\\mathcal{E}_1 \\otimes \\mathcal{E}_2$, che indicheremo con $\\mu_1 \\otimes \\mu_2$, tale che per ogni coppia di insiemi misurabili $B_1 \\in \\mathcal{E}_1$ e $B_2 \\in \\mathcal{E}_2$, si abbia:\n\n$\\qquad (\\mu_1 \\otimes \\mu_2)(B_1 \\times B_2) = \\mu_1(B_1) \\cdot \\mu_2(B_2)$.\n\nQuesta misura $\\mu_1 \\otimes \\mu_2$ è chiamata **misura prodotto** di $\\mu_1$ e $\\mu_2$.\n\nIl professore fa un parallelo con la costruzione della misura di Lebesgue, dove si parte dai cuboidi e si estende la misura. La costruzione qui presentata è una versione astratta di quel procedimento.\n![[Pasted image 20250414102326.png]]\n### Osservazioni sulle Misure di Probabilità\n\nSe $\\mu_1$ e $\\mu_2$ sono misure di probabilità, allora anche la misura prodotto $\\mu_1 \\otimes \\mu_2$ è una misura di probabilità, poiché $(\\mu_1 \\otimes \\mu_2)(E_1 \\times E_2) = \\mu_1(E_1) \\cdot \\mu_2(E_2) = 1 \\cdot 1 = 1$.\n\nIl professore accenna al fatto che se si richiedesse solo che una misura sullo spazio prodotto abbia $\\mu_1$ e $\\mu_2$ come **marginali**, allora tale misura non sarebbe necessariamente unica. Tuttavia, se si richiede che la misura si **fattorizzi** sul prodotto di insiemi misurabili (come nella definizione della misura prodotto), allora l&#039;unicità è garantita.\n\n### Applicazione alla Misura di Lebesgue\n\nIl professore menziona che, oltre alle misure di probabilità, la costruzione della misura prodotto è particolarmente importante per la misura di Lebesgue.\n\n## Funzioni Misurabili sullo Spazio Prodotto\n\nConsideriamo una funzione $H: E_1 \\times E_2 \\to \\mathbb{R}$. Dire che $H$ è **misurabile rispetto alla sigma algebra prodotto** $\\mathcal{E}_1 \\otimes \\mathcal{E}_2$ e ai Boreliani di $\\mathbb{R}$ ($\\mathcal{B}(\\mathbb{R})$) significa che per ogni $B \\in \\mathcal{B}(\\mathbb{R})$, l&#039;insieme $H^{-1}(B) = {(e_1, e_2) \\in E_1 \\times E_2 \\mid H(e_1, e_2) \\in B}$ appartiene a $\\mathcal{E}_1 \\otimes \\mathcal{E}_2$.\n\nIl professore usa la notazione $H(e_1, e_2)$ per indicare il valore della funzione in un punto $(e_1, e_2) \\in E_1 \\times E_2$.\n ![[Pasted image 20250414102624.png]]\n## Sezioni di Funzioni Misurabili\n\n### Proposizione 2\n\n**Proposizione:** Sia $H: E_1 \\times E_2 \\to \\mathbb{R}$ una funzione misurabile rispetto alla sigma algebra prodotto $\\mathcal{E}_1 \\otimes \\mathcal{E}_2$ e ai Boreliani di $\\mathbb{R}$. Allora:\n\n1. Per ogni $e_1 \\in E_1$, la funzione $H_{e_1}: E_2 \\to \\mathbb{R}$ definita da $H_{e_1}(e_2) = H(e_1, e_2)$ è $\\mathcal{E}_2$-misurabile.\n2. Per ogni $e_2 \\in E_2$, la funzione $H_{e_2}: E_1 \\to \\mathbb{R}$ definita da $H_{e_2}(e_1) = H(e_1, e_2)$ è $\\mathcal{E}_1$-misurabile.\n\nIl professore spiega che questa proposizione afferma che se una funzione è misurabile sul prodotto, allora fissando una delle due variabili, la funzione risultante nell&#039;altra variabile rimane misurabile. Queste funzioni $H_{e_1}$ e $H_{e_2}$ sono chiamate **sezioni** della funzione $H$.\n\nIl professore risponde a una domanda dello studente, confermando che se si hanno due funzioni misurabili, la loro composizione è misurabile, anche se precisa che qui si sta usando la misurabilità nella direzione indicata dalla proposizione.\n![[Pasted image 20250414102856.png]]\n### Importanza per l&#039;Integrazione\n\nQuesta proprietà è fondamentale perché permette di dare un senso all&#039;integrale parziale. Ad esempio, si considera l&#039;espressione:\n\n$\\qquad \\int_{E_2} H(e_1, e_2) , d\\mu_2(e_2)$\n\nPerché questo integrale sia ben definito (almeno per funzioni positive), è necessario che, per ogni $e_1$ fissato, la funzione $e_2 \\mapsto H(e_1, e_2)$ sia $\\mathcal{E}_2$-misurabile, cosa che è garantita dalla Proposizione 2.\n![[Pasted image 20250414103439.png]]\n## Teorema di Fubini-Tonelli (Caso di Funzioni Positive)\n\n### Teorema\n\n**Teorema:** Siano $(E_1, \\mathcal{E}_1, \\mu_1)$ e $(E_2, \\mathcal{E}_2, \\mu_2)$ spazi misurabili con misure $\\sigma$-finite e sia $H: E_1 \\times E_2 \\to [0, +\\infty]$ una funzione $\\mathcal{E}_1 \\otimes \\mathcal{E}_2$-misurabile e positiva. Allora:\n\n1. Per quasi ogni $e_1 \\in E_1$ (rispetto a $\\mu_1$), la funzione $e_2 \\mapsto H(e_1, e_2)$ è $\\mathcal{E}_2$-integrabile (ovvero $\\int_{E_2} H(e_1, e_2) , d\\mu_2(e_2) &lt; +\\infty$).\n2. La funzione $e_1 \\mapsto \\int_{E_2} H(e_1, e_2) , d\\mu_2(e_2)$ è $\\mathcal{E}_1$-misurabile su $[0, +\\infty]$.\n3. Si ha l&#039;uguaglianza:\n\n$\\qquad \\int_{E_1 \\times E_2} H(e_1, e_2) , d(\\mu_1 \\otimes \\mu_2)(e_1, e_2) = \\int_{E_1} \\left( \\int_{E_2} H(e_1, e_2) , d\\mu_2(e_2) \\right) , d\\mu_1(e_1)$.\n\nAnalogamente, invertendo l&#039;ordine di integrazione:\n\n1. Per quasi ogni $e_2 \\in E_2$ (rispetto a $\\mu_2$), la funzione $e_1 \\mapsto H(e_1, e_2)$ è $\\mathcal{E}_1$-integrabile.\n2. La funzione $e_2 \\mapsto \\int_{E_1} H(e_1, e_2) , d\\mu_1(e_1)$ è $\\mathcal{E}_2$-misurabile su $[0, +\\infty]$.\n3. Si ha l&#039;uguaglianza:\n\n$\\qquad \\int_{E_1 \\times E_2} H(e_1, e_2) , d(\\mu_1 \\otimes \\mu_2)(e_1, e_2) = \\int_{E_2} \\left( \\int_{E_1} H(e_1, e_2) , d\\mu_1(e_1) \\right) , d\\mu_2(e_2)$.\n\nQuindi, per una funzione misurabile e positiva, l&#039;integrale sullo spazio prodotto può essere calcolato come un integrale iterato, integrando prima rispetto a una variabile e poi rispetto all&#039;altra, e l&#039;ordine di integrazione non influisce sul risultato.\n\nIl professore sottolinea che l&#039;ipotesi che $H$ sia positiva è cruciale per garantire che la funzione integranda interna sia misurabile e che gli integrali siano ben definiti (anche se possono essere $+\\infty$). Inoltre, parte dell&#039;enunciato è che se l&#039;integrale doppio è finito, allora anche l&#039;integrale iterato è finito, e viceversa.\n\n### Connessione con l&#039;Integrale Multiplo\n\nIl professore fa un collegamento con l&#039;integrale multiplo visto in Analisi II, dove tipicamente si calcola l&#039;integrale di una funzione su un dominio in $\\mathbb{R}^2$ (o $\\mathbb{R}^n$) tramite integrazione per sezioni. Il teorema di Fubini-Tonelli generalizza questa idea a spazi misurabili astratti e fornisce una giustificazione rigorosa per il calcolo degli integrali multipli come integrali iterati.\n\n### Prossimi Passi\n\nIl professore conclude anticipando che nella lezione successiva si approfondirà il teorema di Fubini-Tonelli per funzioni non necessariamente positive e si esplorerà la connessione con l&#039;indipendenza. Si specifica che gli argomenti trattati fino a questo punto potrebbero rientrare nel programma del prossimo compitino. Le esercitazioni sono considerate fondamentali per la comprensione di questi concetti.\n\n\n\n#### References\n\n\n\n2025-04-14 10:36\n\n_Status: #flashcard_zero  #riscritto_zero  #revisione_zero \n\n_Tags:[[sbobine]]  [[probabilità]]\n\n## prob-lez16\n\n# **Misure Prodotto e Teorema di Tonelli**\n\n## **Spazio Misurabile Prodotto**\n\nDati due spazi di misura $(E_1, \\mathcal{M}_1, \\mu_1)$ e $(E_2, \\mathcal{M}_2, \\mu_2)$, si definisce lo **spazio misurabile prodotto** come il prodotto cartesiano $E = E_1 \\times E_2$ dotato della **$\\sigma$-algebra prodotto**.\n\nLa $\\sigma$-algebra prodotto, indicata con $\\mathcal{M}_1 \\otimes \\mathcal{M}_2$, è la più piccola $\\sigma$-algebra costituita dai **rettangoli misurabili**, ovvero insiemi della forma $N_1 \\times N_2$ dove $N_1 \\in \\mathcal{M}_1$ e $N_2 \\in \\mathcal{M}_2$.\n\n## **Misura Prodotto**\n\nSe le misure $\\mu_1$ e $\\mu_2$ sono **$\\sigma$-finite**, allora esiste un&#039;unica misura $\\mu$ sullo spazio misurabile prodotto $(E_1 \\times E_2, \\mathcal{M}_1 \\otimes \\mathcal{M}_2)$, chiamata **misura prodotto** e indicata con $\\mu_1 \\times \\mu_2$ o semplicemente $\\mu$, tale che per ogni rettangolo misurabile $N_1 \\times N_2$ si abbia:\n\n$\\qquad \\mu(N_1 \\times N_2) = \\mu_1(N_1) \\mu_2(N_2)$\n![[Pasted image 20250414104323.png]]\n## **Teorema di Tonelli**\n\n**Enunciato:** Sia $h: E = E_1 \\times E_2 \\rightarrow [0, +\\infty]$ una funzione **misurabile** rispetto alla $\\sigma$-algebra prodotto $\\mathcal{M}_1 \\otimes \\mathcal{M}_2$. Allora, l&#039;**integrale doppio** $\\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2)$ è sempre ben definito (potendo essere anche $+\\infty$). Inoltre, valgono le seguenti uguaglianze:\n\n$\\qquad \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) = \\int_{E_1} \\left( \\int_{E_2} h(e_1, e_2) d\\mu_2(e_2) \\right) d\\mu_1(e_1)$\n\n$\\qquad \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) = \\int_{E_2} \\left( \\int_{E_1} h(e_1, e_2) d\\mu_1(e_1) \\right) d\\mu_2(e_2)$\n\n**Spiegazione:** Il teorema di Tonelli afferma che per **funzioni positive misurabili**, l&#039;ordine di integrazione non influisce sul risultato dell&#039;integrale. Se uno dei due integrali iterati è finito, allora anche l&#039;altro lo è e coincidono con l&#039;integrale sulla misura prodotto. Se uno dei due è $+\\infty$, anche gli altri sono $+\\infty$.\n\n**Osservazione:** Come sottolineato dal professore, l&#039;integrale interno, ad esempio $\\int_{E_2} h(e_1, e_2) d\\mu_2(e_2)$, risulta essere una funzione di $e_1$, e questa funzione è misurabile.\n![[Pasted image 20250414163603.png]]\n# **Teorema di Fubini**\n\n## **Teorema di Fubini**\n\n**Enunciato:** Sia $h: E = E_1 \\times E_2 \\rightarrow \\mathbb{R}$ (o $\\mathbb{C}$) una funzione **misurabile** rispetto alla $\\sigma$-algebra prodotto $\\mathcal{M}_1 \\otimes \\mathcal{M}_2$. Se l&#039;integrale del **modulo** di $h$ sulla misura prodotto è finito, ovvero:\n\n$\\qquad \\int_{E_1 \\times E_2} |h(e_1, e_2)| d(\\mu_1 \\times \\mu_2)(e_1, e_2) &lt; +\\infty$\n\nallora valgono le seguenti affermazioni:\n\n1. Per $\\mu_1$-quasi ogni $e_1 \\in E_1$, la funzione $h(e_1, \\cdot): E_2 \\rightarrow \\mathbb{R}$ (o $\\mathbb{C}$) è $\\mu_2$-integrabile.\n2. Per $\\mu_2$-quasi ogni $e_2 \\in E_2$, la funzione $h(\\cdot, e_2): E_1 \\rightarrow \\mathbb{R}$ (o $\\mathbb{C}$) è $\\mu_1$-integrabile.\n3. Le funzioni definite da: $\\qquad I_1(e_1) = \\int_{E_2} h(e_1, e_2) d\\mu_2(e_2)$ $\\qquad I_2(e_2) = \\int_{E_1} h(e_1, e_2) d\\mu_1(e_1)$ sono rispettivamente $\\mu_1$-integrabile e $\\mu_2$-integrabile.\n4. Valgono le seguenti uguaglianze: $\\qquad \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) = \\int_{E_1} \\left( \\int_{E_2} h(e_1, e_2) d\\mu_2(e_2) \\right) d\\mu_1(e_1)$ $\\qquad \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) = \\int_{E_2} \\left( \\int_{E_1} h(e_1, e_2) d\\mu_1(e_1) \\right) d\\mu_2(e_2)$\n![[Pasted image 20250414163824.png]]\n**Spiegazione:** Il teorema di Fubini estende la possibilità di scambiare l&#039;ordine di integrazione a funzioni che non sono necessariamente positive, a condizione che l&#039;integrale del loro valore assoluto sia finito. Questa condizione garantisce che le funzioni ottenute integrando rispetto a una variabile siano integrabili rispetto all&#039;altra.\n\n**Interpretazione dell&#039;Uguaglianza:** Come spiegato dal professore, l&#039;uguaglianza degli integrali iterati va interpretata nel senso che la funzione interna potrebbe non essere ben definita su un insieme di misura zero (rispetto alla misura esterna). Tuttavia, questo non influisce sul valore dell&#039;integrale esterno. In pratica, si può definire la funzione interna arbitrariamente (ad esempio, ponendola uguale a zero) su tale insieme di misura nulla senza cambiare il risultato dell&#039;integrale finale.\n\n## **Differenze tra Tonelli e Fubini**\n\nLa differenza fondamentale tra i due teoremi risiede nelle ipotesi sulla funzione $h$:\n\n- **Tonelli:** Si applica a funzioni **positive** e misurabili. L&#039;integrale doppio è sempre ben definito (anche se infinito), e l&#039;ordine di integrazione può essere scambiato senza la necessità di verificare la finitezza dell&#039;integrale.\n- **Fubini:** Si applica a funzioni **non necessariamente positive**, ma **misurabili** e tali che l&#039;integrale del loro **modulo** sia finito. Questa condizione è cruciale per poter scambiare l&#039;ordine di integrazione e garantire che gli integrali iterati siano ben definiti e finiti.\n\n## **Applicazione di Tonelli e Fubini**\n\nPer applicare il teorema di Fubini a una funzione $h$ non positiva, la strategia tipica è la seguente:\n\n1. Considerare il **modulo** della funzione, $|h|$.\n2. Applicare il teorema di **Tonelli** alla funzione $|h|$, poiché è positiva. Si calcola uno degli integrali iterati di $|h|$.\n3. Se l&#039;integrale di $|h|$ (e quindi gli integrali iterati di $|h|$) è **finito**, allora si può applicare il teorema di **Fubini** alla funzione $h$, e l&#039;ordine di integrazione può essere scambiato per l&#039;integrale di $h$ stesso.\n\n# **Applicazione a Misure di Lebesgue e Integrale Doppio**\n\n## **Caso delle Misure di Lebesgue su $\\mathbb{R}^{d_1} \\times \\mathbb{R}^{d_2}$**\n\nUn caso fondamentale in cui si applicano i teoremi di Fubini e Tonelli è quando gli spazi di misura sono $\\mathbb{R}^{d_1}$ e $\\mathbb{R}^{d_2}$ dotati della **misura di Lebesgue** e della $\\sigma$-algebra dei **Boreliani**. In questo caso, la $\\sigma$-algebra prodotto coincide con la $\\sigma$-algebra dei Boreliani di $\\mathbb{R}^{d_1 + d_2}$.\n\nSe abbiamo una funzione $h(x_1, x_2)$ con $x_1 \\in \\mathbb{R}^{d_1}$ e $x_2 \\in \\mathbb{R}^{d_2}$, l&#039;integrale rispetto alla misura prodotto (misura di Lebesgue su $\\mathbb{R}^{d_1 + d_2}$) può essere scritto come:\n\n$\\qquad \\int_{\\mathbb{R}^{d_1 + d_2}} h(x_1, x_2) dx_1 dx_2$\n\nSe l&#039;integrale di $|h|$ è finito, per il teorema di Fubini possiamo scambiare l&#039;ordine di integrazione:\n\n$\\qquad \\int_{\\mathbb{R}^{d_1 + d_2}} h(x_1, x_2) dx_1 dx_2 = \\int_{\\mathbb{R}^{d_1}} \\left( \\int_{\\mathbb{R}^{d_2}} h(x_1, x_2) dx_2 \\right) dx_1 = \\int_{\\mathbb{R}^{d_2}} \\left( \\int_{\\mathbb{R}^{d_1}} h(x_1, x_2) dx_1 \\right) dx_2$\n\n![[Pasted image 20250414164310.png]]\n## **Collegamento con l&#039;Integrale Doppio in Analisi**\n\nIl professore fa notare che questo formalismo generalizza il concetto di **integrale doppio** visto in corsi di analisi su insiemi &quot;normali&quot; o plurirettangoli e per funzioni &quot;integrabili&quot; nel senso usuale. I teoremi di Fubini e Tonelli permettono di estendere questi risultati a **insiemi misurabili Boreliani** qualsiasi e a funzioni che sono **Lebesgue-integrabili**, una classe più ampia di funzioni rispetto a quelle Riemann-integrabili.\n\nIn pratica, per calcolare un integrale doppio, si procede come si è abituati: si integra prima rispetto a una variabile (mantenendo l&#039;altra fissa) e poi si integra il risultato rispetto all&#039;altra variabile. I teoremi di Fubini e Tonelli forniscono le condizioni sotto le quali questo procedimento è valido e il risultato è indipendente dall&#039;ordine di integrazione.\n\n# **Marginali di Legge Assolutamente Continue**\n\n## **Caso Discreto (Richiamo)**\n\nIl professore ricorda che nel caso di **vettori aleatori discreti**, se si ha la distribuzione congiunta (ad esempio, una tabella di contingenza), la **distribuzione marginale** di una singola variabile (o di un sottovettore) si ottiene **sommando** (o &quot;saturando&quot;) sulla(e) variabile(i) non di interesse.\n![[Pasted image 20250414164455.png]]\n## **Caso Assolutamente Continuo (d=2)**\n\nConsideriamo un **vettore aleatorio assolutamente continuo** $(X_1, X_2)$ con **funzione di densità congiunta** $f(x_1, x_2)$. Vogliamo trovare la **funzione di densità marginale** di $X_1$, che denotiamo con $f_{X_1}(x_1)$.\n\n**Calcolo della Funzione di Ripartizione Marginale:** La funzione di ripartizione marginale di $X_1$, $F_{X_1}(x_1)$, è data da:\n\n$\\qquad F_{X_1}(x_1) = P(X_1 \\leq x_1) = P(X_1 \\leq x_1, X_2 \\in \\mathbb{R})$\n\nQuesta probabilità può essere espressa come l&#039;integrale della densità congiunta sull&#039;insieme ${(t_1, t_2) \\in \\mathbb{R}^2 : t_1 \\leq x_1, t_2 \\in \\mathbb{R}}$:\n\n$\\qquad F_{X_1}(x_1) = \\int_{-\\infty}^{x_1} \\int_{-\\infty}^{+\\infty} f(t_1, t_2) dt_2 dt_1$\n![[Pasted image 20250414164646.png]]\n**Derivazione della Densità Marginale:** Applicando il teorema di **Tonelli** (poiché la densità congiunta è non negativa), possiamo scambiare l&#039;ordine di integrazione:\n\n$\\qquad F_{X_1}(x_1) = \\int_{-\\infty}^{x_1} \\left( \\int_{-\\infty}^{+\\infty} f(t_1, t_2) dt_2 \\right) dt_1$\n\nDefiniamo la funzione $f_{X_1}(t_1) = \\int_{-\\infty}^{+\\infty} f(t_1, t_2) dt_2$. Allora possiamo scrivere:\n\n$\\qquad F_{X_1}(x_1) = \\int_{-\\infty}^{x_1} f_{X_1}(t_1) dt_1$\n![[Pasted image 20250414164831.png]]\nPer la definizione di variabile assolutamente continua, questo significa che $X_1$ è assolutamente continua e la sua **funzione di densità marginale** è data da:\n\n$\\qquad f_{X_1}(x_1) = \\int_{-\\infty}^{+\\infty} f(x_1, x_2) dx_2$\n![[Pasted image 20250414164910.png]]\n**Spiegazione del Procedimento Logico:** Il professore sottolinea che non si assume a priori che $X_1$ sia assolutamente continua. Il procedimento consiste nel calcolare la funzione di ripartizione marginale e mostrare che essa può essere espressa come l&#039;integrale di una funzione (la densità marginale). Questo dimostra che $X_1$ è assolutamente continua e identifica la sua densità.\n\n## **Caso Generale (d &gt; 2)**\n\nIl risultato si generalizza a vettori aleatori in $d$ dimensioni. Se $X = (X_1, ..., X_d)$ è assolutamente continuo con densità $f(x_1, ..., x_d)$, allora ogni **sottovettore** è assolutamente continuo.\n\nIn particolare, la **densità marginale** di un sottovettore $(X_{i_1}, ..., X_{i_k})$ (dove $1 \\leq i_1 &lt; ... &lt; i_k \\leq d$) si ottiene **integrando** la densità congiunta rispetto a tutte le altre variabili (cioè le variabili con indici $j \\in {1, ..., d} \\setminus {i_1, ..., i_k}$).\n\nMatematicamente, la densità marginale $f_{X_{i_1}, ..., X_{i_k}}(x_{i_1}, ..., x_{i_k})$ è data da:\n\n$\\qquad f_{X_{i_1}, ..., X_{i_k}}(x_{i_1}, ..., x_{i_k}) = \\int_{\\mathbb{R}^{d-k}} f(x_1, ..., x_d) \\prod_{j \\notin {i_1, ..., i_k}} dx_j$\n![[Pasted image 20250414170805.png]]\n**Esempio (d=3):** Se $d=3$ e vogliamo la densità marginale di $(X_1, X_3)$, cioè $f_{X_1, X_3}(x_1, x_3)$, dobbiamo integrare la densità congiunta $f(x_1, x_2, x_3)$ rispetto alla variabile $x_2$:\n\n$\\qquad f_{X_1, X_3}(x_1, x_3) = \\int_{-\\infty}^{+\\infty} f(x_1, x_2, x_3) dx_2$\n![[Pasted image 20250414170814.png]]\n___\n\n## Spiegazione Sulla Assoluta Continuità, Marginali e Indipendenza\n\n### Assoluta Continuità di Vettori Aleatori e Marginali\n\nIl professore introduce il concetto di **assoluta continuità per vettori aleatori multidimensionali**.\n\n- **Definizione:** Un vettore aleatorio è **assolutamente continuo** rispetto alla misura di Lebesgue se la sua probabilità può essere espressa come l&#039;integrale di una funzione di densità.\n    \n- **Proprietà Fondamentale:** Se un vettore aleatorio $(X_1, X_2, ..., X_d)$ è assolutamente continuo, allora **tutti i suoi sottovettori (incluse le marginali unidimensionali)** sono anch&#039;essi assolutamente continui. Questo significa che se il vettore &quot;più grande&quot; è assolutamente continuo, possiamo &quot;sfilare&quot; qualsiasi sottovettore, e questo manterrà la proprietà di essere assolutamente continuo.\n    \n- **Esempio:** Se abbiamo un vettore $(X_1, X_2, X_3)$ assolutamente continuo, allora $X_1$, $X_2$, $X_3$, $(X_1, X_2)$, $(X_1, X_3)$, e $(X_2, X_3)$ sono tutti assolutamente continui.\n    \n\n### Calcolo delle Marginali nel Caso Assolutamente Continuo\n\nIl calcolo delle densità marginali da una densità congiunta si effettua tramite **integrazione**, analogamente a come si fa con le somme nel caso discreto. Questa operazione è una conseguenza del teorema di Fubini-Tonelli.\n\n- **Marginale Unidimensionale:** Per ottenere la densità marginale di una variabile $X_i$ da una densità congiunta $f(x_1, ..., x_d)$, si integra la densità congiunta rispetto a tutte le altre variabili: $f_{X_i}(x_i) = \\int ... \\int f(x_1, ..., x_d) dx_1 ... dx_{i-1} dx_{i+1} ... dx_d$.\n    \n- **Marginale Multidimensionale:** Per ottenere la densità marginale di un sottovettore, ad esempio $(X_i, X_j)$, si integra la densità congiunta rispetto a tutte le variabili che non compaiono nel sottovettore: $f_{X_i, X_j}(x_i, x_j) = \\int ... \\int f(x_1, ..., x_d) dx_1 ... dx_{i-1} dx_{i+1} ... dx_{j-1} dx_{j+1} ... dx_d$.\n    \n\n### La Non Implicazione Viceversa: Marginali Assolutamente Continue non Implicano Congiunta Assolutamente Continua\n\nUn punto cruciale sottolineato dal professore è che **sebbene un vettore assolutamente continuo implichi marginali assolutamente continue, il contrario non è sempre vero**.\n\n- **Controesempio: $X = (Y, Y)$** Consideriamo un vettore $X = (X_1, X_2)$ dove $X_1 = Y$ e $X_2 = Y$, e $Y$ è una variabile aleatoria assolutamente continua.\n    \n    - **Marginali Assolutamente Continue:** Marginalmente, sia $X_1$ che $X_2$ sono uguali a $Y$, quindi sono assolutamente continue.\n        \n    - **Congiunta Non Assolutamente Continua:** Il vettore $X = (Y, Y)$ non è assolutamente continuo. Per costruzione, la probabilità che $X_1 = X_2$ è sempre 1: $P(X_1 = X_2) = P(Y = Y) = 1$.\n        \n    - **Dimostrazione per Assurdo:** Se $X$ fosse assolutamente continuo, esisterebbe una densità congiunta $f_{X_1, X_2}(x_1, x_2)$ tale che: $P(X_1 = X_2) = \\iint_{{(x_1, x_2) | x_1 = x_2}} f_{X_1, X_2}(x_1, x_2) dx_1 dx_2$.\n        \n        L&#039;insieme ${(x_1, x_2) | x_1 = x_2}$ rappresenta una **retta** nel piano $\\mathbb{R}^2$. La **misura di Lebesgue** di una retta in $\\mathbb{R}^2$ è **zero**.\n        \n        Se $f_{X_1, X_2}$ è integrabile (come dovrebbe essere per una densità), allora l&#039;integrale di Lebesgue di una funzione integrabile su un insieme di misura di Lebesgue nulla è **zero**.\n        \n        Quindi, se $X$ fosse assolutamente continuo, avremmo $P(X_1 = X_2) = 0$, che contraddice il fatto che $P(X_1 = X_2) = 1$. Pertanto, il vettore $X = (Y, Y)$ non può essere assolutamente continuo, anche se le sue marginali lo sono.\n        \n    - **Intuizione Geometrica:** La distribuzione di probabilità del vettore $(Y, Y)$ è concentrata sulla retta $x_1 = x_2$ nel piano $\\mathbb{R}^2$. Una distribuzione assolutamente continua in $\\mathbb{R}^2$ dovrebbe essere &quot;diffusa&quot; su insiemi bidimensionali con misura di Lebesgue non nulla, non concentrata su un insieme di misura nulla come una retta.\n        ![[Pasted image 20250414171059.png]]\n\n### Indipendenza e Misure Prodotto\n\nIl professore introduce l&#039;applicazione del teorema di Fubini-Tonelli nel contesto di **spazi di probabilità** e come questo porta al concetto di **indipendenza**.\n\n- **Misure Prodotto:** Dati due spazi di probabilità $(X_1, \\mathcal{A}_1, \\mu_1)$ e $(X_2, \\mathcal{A}_2, \\mu_2)$, si può definire una **misura prodotto** $P = \\mu_1 \\times \\mu_2$ sullo spazio prodotto $(X_1 \\times X_2, \\mathcal{A}_1 \\otimes \\mathcal{A}_2)$ tale che per ogni $A_1 \\in \\mathcal{A}_1$ e $A_2 \\in \\mathcal{A}_2$: $P(A_1 \\times A_2) = \\mu_1(A_1) \\mu_2(A_2)$.\n    \n- **Variabili Aleatorie e Misure Indotte:** Se $X_1$ e $X_2$ sono variabili aleatorie definite su uno spazio di probabilità comune $(\\Omega, \\mathcal{F}, P)$ a valori in $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$, possiamo considerare le loro **misure indotte** $\\mathbb{P}_{X_1}(A_1) = P(X_1 \\in A_1)$ e $\\mathbb{P}_{X_2}(A_2) = P(X_2 \\in A_2)$.\n    ![[Pasted image 20250414172154.png]]\n- **Misura Immagine e Misura Prodotto delle Marginali:** La **legge congiunta** di $(X_1, X_2)$ è la misura immagine $\\mathbb{P}_{(X_1, X_2)}(A_1 \\times A_2) = P(X_1 \\in A_1, X_2 \\in A_2)$ sullo spazio prodotto $\\mathbb{R}^2$. Possiamo anche considerare la **misura prodotto delle marginali**: $\\mathbb{P}_{X_1} \\times \\mathbb{P}_{X_2}(A_1 \\times A_2) = \\mathbb{P}_{X_1}(A_1) \\mathbb{P}_{X_2}(A_2) = P(X_1 \\in A_1) P(X_2 \\in A_2)$.\n    \n- **Definizione di Indipendenza:** Due variabili aleatorie $X_1$ e $X_2$ sono **indipendenti** se per ogni $A_1, A_2$ misurabili (negli spazi di arrivo): $P(X_1 \\in A_1, X_2 \\in A_2) = P(X_1 \\in A_1) P(X_2 \\in A_2)$.\n    \n- **Proposizione:** Le variabili aleatorie $X_1$ e $X_2$ sono indipendenti **se e solo se** la loro **misura immagine (legge congiunta) è uguale alla misura prodotto delle loro marginali**: $\\mathbb{P}_{(X_1, X_2)} = \\mathbb{P}_{X_1} \\times \\mathbb{P}_{X_2}$.\n    \n    Questa equivalenza deriva dal fatto che due misure di probabilità che coincidono su tutti i rettangoli del prodotto coincidono sull&#039;intera sigma-algebra prodotto.\n    ![[Pasted image 20250414172400.png]]\n\n### Teorema di Fubini per Variabili Aleatorie Indipendenti\n\nUna delle conseguenze fondamentali dell&#039;indipendenza, derivata dal teorema di Fubini-Tonelli, riguarda il calcolo del **valore atteso di funzioni di variabili aleatorie indipendenti**.\n\n- **Teorema:** Siano $X_1, X_2$ variabili aleatorie reali definite su uno spazio di probabilità e **indipendenti**. Sia $h: \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ una funzione misurabile.\n    \n    - **Caso $h \\ge 0$:** Se $h$ è non negativa, allora: $E[h(X_1, X_2)] = \\int_{\\mathbb{R}^2} h(x_1, x_2) d\\mathbb{P}_{(X_1, X_2)}(x_1, x_2) = \\int_{\\mathbb{R}} \\left( \\int_{\\mathbb{R}} h(x_1, x_2) d\\mathbb{P}_{X_2}(x_2) \\right) d\\mathbb{P}_{X_1}(x_1) = \\int_{\\mathbb{R}} \\int_{\\mathbb{R}} h(x_1, x_2) d\\mathbb{P}_{X_1}(x_1) d\\mathbb{P}_{X_2}(x_2)$.\n        \n        Nel caso in cui $X_1$ e $X_2$ abbiano densità $f_{X_1}(x_1)$ e $f_{X_2}(x_2)$ rispettivamente, e quindi la densità congiunta sia $f_{X_1, X_2}(x_1, x_2) = f_{X_1}(x_1) f_{X_2}(x_2)$ (per l&#039;indipendenza), il teorema diventa: $E[h(X_1, X_2)] = \\int_{\\mathbb{R}} \\int_{\\mathbb{R}} h(x_1, x_2) f_{X_1}(x_1) f_{X_2}(x_2) dx_1 dx_2$.\n        \n    - **Caso $E[|h(X_1, X_2)|] &lt; \\infty$:** Se il valore atteso del modulo di $h(X_1, X_2)$ è finito, allora vale la stessa uguaglianza. Questo assicura che gli integrali sono ben definiti.\n        ![[Pasted image 20250414172626.png]]\n\n### Corollario: Valore Atteso del Prodotto di Variabili Aleatorie Indipendenti\n\nUn importante corollario del teorema di Fubini per variabili indipendenti riguarda il valore atteso del loro prodotto.\n\n- **Corollario:** Siano $X_1, ..., X_n$ variabili aleatorie reali **indipendenti** tali che il valore atteso di ognuna di esse sia finito ($E[|X_i|] &lt; \\infty$ per ogni $i$). Allora, il valore atteso del loro prodotto è finito e uguale al prodotto dei loro valori attesi: $E[X_1 ... X_n] = E[X_1] ... E[X_n]$.\n    \n    Questa proprietà è fondamentale e semplifica notevolmente il calcolo dei **momenti misti** per variabili indipendenti. Invece di calcolare integrali multipli, si calcolano prodotti di integrali singoli.\n    \n![[Pasted image 20250414172757.png]]\n### Criteri per Verificare l&#039;Indipendenza\n\nIl professore menziona brevemente i criteri per verificare se due variabili aleatorie sono indipendenti.\n\n- **Definizione Generale:** $X_1$ e $X_2$ sono indipendenti se per ogni coppia di eventi $A_1$ e $A_2$ negli spazi di arrivo, $P(X_1 \\in A_1 \\cap X_2 \\in A_2) = P(X_1 \\in A_1) P(X_2 \\in A_2)$. Verificarlo per tutti gli eventi può essere difficile.\n    \n- **Funzione di Ripartizione:** Per variabili aleatorie reali, $X_1$ e $X_2$ sono indipendenti se e solo se la loro funzione di ripartizione congiunta $F_{X_1, X_2}(x_1, x_2)$ è uguale al prodotto delle loro funzioni di ripartizione marginali $F_{X_1}(x_1)$ e $F_{X_2}(x_2)$: $F_{X_1, X_2}(x_1, x_2) = P(X_1 \\le x_1, X_2 \\le x_2) = P(X_1 \\le x_1) P(X_2 \\le x_2) = F_{X_1}(x_1) F_{X_2}(x_2)$. Questo criterio è generale ma la funzione di ripartizione congiunta potrebbe non essere sempre facile da calcolare.\n    \n- **Densità (se esistono):** Se $X_1$ e $X_2$ hanno densità $f_{X_1}(x_1)$ e $f_{X_2}(x_2)$, allora sono indipendenti se e solo se la loro densità congiunta $f_{X_1, X_2}(x_1, x_2)$ è uguale al prodotto delle loro densità marginali: $f_{X_1, X_2}(x_1, x_2) = f_{X_1}(x_1) f_{X_2}(x_2)$. Questo è un criterio pratico quando le densità sono note.\n\n___\n\n# Indipendenza di Vettori Aleatori Assolutamente Continui\n\n## Proposizione/Teorema: Condizione di Indipendenza Tramite la Fattorizzazione della Densità Congiunta\n\nSia $X = (X_1, ..., X_d)$ un vettore assolutamente continuo con densità $f(x) = f(x_1, ..., x_d)$. Le componenti $X_1, ..., X_d$ sono indipendenti se e solo se la densità congiunta $d_X(x)$ (utilizzando $d$ per coerenza) fattorizza, ovvero se esiste una scelta di funzioni $f_i(x_i)$ (che risulteranno essere le densità marginali) tali che:\n\n$d_X(x_1, ..., x_d) = f_1(x_1) \\cdot f_2(x_2) \\cdot ... \\cdot f_d(x_d)$\n\nper ogni scelta di vettori $x = (x_1, ..., x_d)$ di dimensioni appropriate. È importante ricordare che le densità non sono definite ovunque, quindi questa uguaglianza deve valere laddove le densità sono definite. Questa condizione è analoga a quella del caso discreto, e non deve valere solo per qualche particolare $x$, ma per tutti i possibili $x$.\n\n## Dimostrazione (Supponendo che la Densità Fattorizzi)\n\nSupponiamo che la densità congiunta fattorizzi come $d_X(t_1, ..., t_d) = f_1(t_1) \\cdot f_2(t_2) \\cdot ... \\cdot f_d(t_d)$. Vogliamo calcolare la funzione di ripartizione multivariata $F_X(x) = P(X_1 \\le x_1, ..., X_d \\le x_d)$ in un punto generico $x = (x_1, ..., x_d)$. Per la definizione di funzione di ripartizione, si ha:\n\n$F_X(x_1, ..., x_d) = \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} d_X(t_1, ..., t_d) dt_d ... dt_1$\n\nDato che stiamo assumendo che la densità fattorizza, possiamo sostituire $d_X$ con il prodotto delle funzioni $f_i$:\n\n$F_X(x_1, ..., x_d) = \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} f_1(t_1) \\cdot f_2(t_2) \\cdot ... \\cdot f_d(t_d) dt_d ... dt_1$\n![[Pasted image 20250414173711.png]]\nPer il teorema di Fubini-Tonelli, possiamo scambiare l&#039;ordine di integrazione e, poiché ogni $f_i(t_i)$ dipende solo da $t_i$, possiamo separare gli integrali:\n\n$F_X(x_1, ..., x_d) = \\left( \\int_{-\\infty}^{x_1} f_1(t_1) dt_1 \\right) \\cdot \\left( \\int_{-\\infty}^{x_2} f_2(t_2) dt_2 \\right) \\cdot ... \\cdot \\left( \\int_{-\\infty}^{x_d} f_d(t_d) dt_d \\right)$\n\nOgni termine di questo prodotto è la funzione di ripartizione marginale della corrispondente variabile $X_i$ calcolata in $x_i$:\n\n$F_{X_i}(x_i) = \\int_{-\\infty}^{x_i} f_i(t_i) dt_i$\n\nQuindi, otteniamo:\n\n$F_X(x_1, ..., x_d) = F_{X_1}(x_1) \\cdot F_{X_2}(x_2) \\cdot ... \\cdot F_{X_d}(x_d)$\n\nPoiché la funzione di ripartizione congiunta fattorizza nel prodotto delle funzioni di ripartizione marginali, le variabili $X_1, ..., X_d$ sono indipendenti.\n![[Pasted image 20250414173736.png]]\n## Dimostrazione (Supponendo l&#039;Indipendenza)\n\n\nSupponiamo che le variabili aleatorie $X_1, ..., X_d$ siano indipendenti. Per variabili aleatorie reali, questo significa che la loro funzione di ripartizione congiunta fattorizza nel prodotto delle funzioni di ripartizione marginali: $F_X(x_1, ..., x_d) = \\prod_{i=1}^{d} F_{X_i}(x_i)$.\n\nSappiamo che, per una variabile aleatoria assolutamente continua $X_i$, la sua funzione di ripartizione marginale può essere espressa come l&#039;integrale della sua densità marginale $f_{X_i}(t_i)$: $F_{X_i}(x_i) = \\int_{-\\infty}^{x_i} f_{X_i}(t_i) dt_i$.\n\nSostituendo queste espressioni nella condizione di indipendenza per le funzioni di ripartizione, otteniamo: $\\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} f(t_1, ..., t_d) dt_1 ... dt_d = \\prod_{i=1}^{d} \\left( \\int_{-\\infty}^{x_i} f_{X_i}(t_i) dt_i \\right)$.\n\nIl lato destro di questa equazione può essere riscritto come un integrale multiplo grazie al teorema di Fubini-Tonelli: $\\prod_{i=1}^{d} \\left( \\int_{-\\infty}^{x_i} f_{X_i}(t_i) dt_i \\right) = \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} \\left( \\prod_{i=1}^{d} f_{X_i}(t_i) \\right) dt_1 ... dt_d$.\n\nQuindi, abbiamo: $\\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} f(t_1, ..., t_d) dt_1 ... dt_d = \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} \\left( \\prod_{i=1}^{d} f_{X_i}(t_i) \\right) dt_1 ... dt_d$.\n\nQuesta uguaglianza vale per ogni scelta di $x_1, ..., x_d$. Ciò implica che le funzioni integrande devono essere uguali quasi ovunque (a meno di insiemi di misura di Lebesgue nulla): $f(x_1, ..., x_d) = \\prod_{i=1}^{d} f_{X_i}(x_i)$.\n\nPertanto, se le variabili aleatorie sono indipendenti, la loro densità congiunta fattorizza nel prodotto delle densità marginali.\n![[Pasted image 20250414174422.png]]\nQuesto dimostra che se le variabili sono indipendenti, la densità congiunta fattorizza nel prodotto delle densità marginali. La funzione prodotto $\\prod_{i=1}^{d} f_{X_i}(x_i)$ è una funzione positiva e il suo integrale su $\\mathbb{R}^d$ è uguale a 1 (per il teorema di Fubini, è il prodotto degli integrali di ogni $f_{X_i}$ su $\\mathbb{R}$, che sono tutti uguali a 1). Pertanto, essa è una densità per il vettore $X$. Siccome la densità è unica a meno di insiemi di misura nulla, il prodotto delle densità marginali deve essere uguale alla densità congiunta (quasi ovunque).\n\n## Criterio di Indipendenza Tramite Densità Congiunta e Marginali\n\nUn criterio utile per verificare l&#039;indipendenza di un vettore assolutamente continuo è il seguente: se si ha la densità congiunta $f(x_1, ..., x_d)$, si calcolano le densità marginali $f_{X_i}(x_i)$ (integrando la densità congiunta rispetto a tutte le altre variabili). Se il prodotto delle densità marginali è uguale alla densità congiunta:\n\n$f(x_1, ..., x_d) = f_{X_1}(x_1) \\cdot f_{X_2}(x_2) \\cdot ... \\cdot f_{X_d}(x_d)$\n\nallora le variabili $X_1, ..., X_d$ sono indipendenti. In teoria, si dovrebbe prima conoscere la congiunta, calcolare le marginali e poi verificare la loro relazione. Tuttavia, in alcuni casi, si può arrivare a questa conclusione in modo più sintetico.\n\n## Trasformazioni di Vettori Aleatori e Indipendenza\n\nIn generale, trasformare vettori aleatori senza l&#039;ipotesi di indipendenza può essere complicato. Tuttavia, l&#039;indipendenza spesso semplifica notevolmente il problema. Esempi di trasformazioni già viste includono trasformazioni lineari e modelli scala posizione. È importante saper dedurre la funzione di ripartizione e la funzione di densità delle variabili trasformate. Altri esempi di trasformazioni includono il massimo, il minimo, il modulo e il quadrato di variabili aleatorie.\n\nCertamente, ecco la spiegazione del professore a partire dalla Funzione di Ripartizione del Massimo, integrata con i contenuti forniti e formattata come richiesto:\n\n# Statistiche d&#039;Ordine: Massimo e Minimo di Variabili Aleatorie Indipendenti\n\n## Introduzione alle Statistiche d&#039;Ordine\n\nLe statistiche d&#039;ordine si occupano dello studio di variabili aleatorie ottenute ordinando un campione di variabili aleatorie. Tra le statistiche d&#039;ordine più semplici e importanti troviamo il **massimo** e il **minimo** di un insieme di variabili aleatorie indipendenti.\n\nConsideriamo $n$ variabili aleatorie $X_1, X_2, ..., X_n$ indipendenti. Definiamo il **massimo** $M = \\max(X_1, X_2, ..., X_n)$ e il **minimo** $m = \\min(X_1, X_2, ..., X_n)$. Essendo funzioni continue di variabili aleatorie, anche $M$ e $m$ sono variabili aleatorie.\n\n## Funzione di Ripartizione del Massimo\n\nVogliamo calcolare la funzione di ripartizione del massimo, $F_M(x) = P(M \\le x)$.\n\nL&#039;evento ${M \\le x}$ si verifica se e solo se tutte le variabili aleatorie $X_1, X_2, ..., X_n$ sono minori o uguali a $x$: ${M \\le x} = {\\max(X_1, ..., X_n) \\le x} = {X_1 \\le x, X_2 \\le x, ..., X_n \\le x}$\n\nQuindi, la funzione di ripartizione del massimo è: $F_M(x) = P(X_1 \\le x, X_2 \\le x, ..., X_n \\le x)$\n\nSfruttando l&#039;ipotesi di **indipendenza** delle variabili aleatorie, possiamo scrivere la probabilità congiunta come il prodotto delle probabilità marginali: $F_M(x) = P(X_1 \\le x) P(X_2 \\le x) ... P(X_n \\le x)$\n\nIntroduciamo ora l&#039;ulteriore ipotesi che le variabili aleatorie siano **identicamente distribuite** (i.i.d.), cioè che abbiano tutte la stessa funzione di ripartizione $F_X(x) = P(X_i \\le x)$ per ogni $i = 1, ..., n$: $F_M(x) = [F_X(x)]^n$\n![[Pasted image 20250414175120.png]]\nQuesto risultato ci permette di esprimere la funzione di ripartizione del massimo in termini della funzione di ripartizione della singola variabile aleatoria quando queste sono indipendenti e identicamente distribuite.\n\n## Funzione di Ripartizione del Minimo\n\nConsideriamo ora il minimo $m = \\min(X_1, X_2, ..., X_n)$. Calcolare direttamente $P(m \\le x)$ non è particolarmente agevole. È più conveniente calcolare la **funzione di sopravvivenza** (o **contropartizione**) del minimo, $P(m &gt; x)$, e poi ricavare la funzione di ripartizione.\n\nL&#039;evento ${m &gt; x}$ si verifica se e solo se tutte le variabili aleatorie $X_1, X_2, ..., X_n$ sono maggiori di $x$: ${m &gt; x} = {\\min(X_1, ..., X_n) &gt; x} = {X_1 &gt; x, X_2 &gt; x, ..., X_n &gt; x}$\n\nQuindi, la probabilità che il minimo sia maggiore di $x$ è: $P(m &gt; x) = P(X_1 &gt; x, X_2 &gt; x, ..., X_n &gt; x)$\n\nSfruttando l&#039;indipendenza delle variabili aleatorie: $P(m &gt; x) = P(X_1 &gt; x) P(X_2 &gt; x) ... P(X_n &gt; x)$\n\nSotto l&#039;ipotesi di variabili i.i.d., dove $P(X_i &gt; x) = 1 - F_X(x)$: $P(m &gt; x) = [1 - F_X(x)]^n$\n\nInfine, la funzione di ripartizione del minimo è data da: $F_m(x) = P(m \\le x) = 1 - P(m &gt; x) = 1 - [1 - F_X(x)]^n$\n![[Pasted image 20250414175430.png]]\n## Esempio 1: Minimo di Tempi di Guasto Esponenziali\n\nConsideriamo $n$ tempi di guasto indipendenti, ciascuno distribuito secondo una legge esponenziale negativa con parametro $\\lambda &gt; 0$. La funzione di ripartizione di una variabile esponenziale con parametro $\\lambda$ è $F_X(x) = 1 - e^{-\\lambda x}$ per $x &gt; 0$, e $F_X(x) = 0$ per $x \\le 0$.\n\nVogliamo trovare la legge del minimo di questi tempi di guasto. Usando la formula per la funzione di ripartizione del minimo: $F_m(x) = 1 - [1 - (1 - e^{-\\lambda x})]^n = 1 - [e^{-\\lambda x}]^n = 1 - e^{-n\\lambda x}$ per $x &gt; 0$. Per $x \\le 0$, $F_X(x) = 0$, quindi $F_m(x) = 1 - ^n = 1 - 1 = 0$.\n\nLa funzione di ripartizione $F_m(x) = 1 - e^{-n\\lambda x}$ per $x &gt; 0$ è la funzione di ripartizione di una **variabile aleatoria esponenziale negativa con parametro $n\\lambda$**. Questo significa che il minimo di $n$ variabili esponenziali i.i.d. con parametro $\\lambda$ è ancora una variabile esponenziale, ma con un tasso di guasto $n$ volte maggiore.\n![[Pasted image 20250414175554.png]]\n## Esercizio 1: Massimo di Variabili Uniformi su (0, 1)\n\nSiano $X_1, ..., X_n$ variabili aleatorie indipendenti e identicamente distribuite secondo una legge uniforme sull&#039;intervallo $(0, 1)$. La funzione di ripartizione di una variabile uniforme su $(0, 1)$ è: $F_X(x) = \\begin{cases} 0 &amp; x \\le 0 \\\\ x &amp; 0 &lt; x &lt; 1 \\\\ 1 &amp; x \\ge 1 \\end{cases}$\n\nCalcolare la funzione di ripartizione e la densità del massimo $M = \\max(X_1, ..., X_n)$.\n\nUsando la formula per la funzione di ripartizione del massimo: $F_M(x) = [F_X(x)]^n = \\begin{cases} 0^n = 0 &amp; x \\le 0 \\\\ x^n &amp; 0 &lt; x &lt; 1 \\\\ 1^n = 1 &amp; x \\ge 1 \\end{cases}$\n\nPer trovare la densità $f_M(x)$, deriviamo la funzione di ripartizione rispetto a $x$: \n\n$f_M(x) = \\frac{d}{dx} F_M(x) = \\begin{cases} 0 &amp; x \\le 0 \\\\ nx^{n-1} &amp; 0 &lt; x &lt; 1 \\\\ 0 &amp; x \\ge 1 \\end{cases}$\n___\n*da qui in poi un allucinazione*\n## Trasformazioni di Vettori Aleatori e Indipendenza\n\nQuando si considerano trasformazioni di vettori aleatori, l&#039;indipendenza delle componenti semplifica notevolmente l&#039;analisi. Senza l&#039;ipotesi di indipendenza, determinare la legge della trasformazione può essere molto complesso. L&#039;esempio dei massimi e minimi illustra come l&#039;indipendenza permetta di ricavare le leggi delle statistiche d&#039;ordine in modo relativamente semplice.\n\n## Funzione Caratteristica della Gamma\n\nPer concludere, il professore introduce la funzione caratteristica della distribuzione Gamma, senza fornirne la derivazione.\n\nLa densità della distribuzione Gamma è proporzionale a $x^{\\alpha - 1} e^{-\\beta x}$ per $x &gt; 0$, dove $\\alpha &gt; 0$ è il parametro di forma e $\\beta &gt; 0$ è il parametro di tasso (l&#039;inverso del parametro di scala). La funzione caratteristica della distribuzione Gamma è data da: $\\phi_X(t) = E[e^{itX}] = \\left( \\frac{\\beta}{\\beta - it} \\right)^\\alpha$, per $|t| &lt; \\beta$ .\n\nIl professore fa notare che la parametrizzazione della Gamma può variare a seconda della convenzione utilizzata (scala o tasso) . Nella forma presentata, $\\beta$ è un parametro di tasso.\n\n### Caso Particolare: Esponenziale\n\nCome caso particolare, la distribuzione Esponenziale con parametro $\\lambda$ è una distribuzione Gamma con $\\alpha = 1$ e $\\beta = \\lambda$. La sua funzione caratteristica si ottiene sostituendo questi valori nella formula generale: $\\phi_X(t) = \\left( \\frac{\\lambda}{\\lambda - it} \\right)^1 = \\frac{\\lambda}{\\lambda - it} = \\frac{1}{1 - it/\\lambda}$ .\n\nQuesto risultato può essere verificato direttamente tramite l&#039;integrazione complessa, trattando l&#039;integrale della funzione caratteristica come un integrale di funzioni complesse .\n\n### Esercizio 2: Somma di Variabili Gamma Indipendenti\n\nConsiderare $n$ variabili aleatorie indipendenti $X_1, ..., X_n$, dove ciascuna $X_j$ segue una distribuzione Gamma con parametri $(\\alpha_j, \\beta)$ (notare che hanno lo stesso parametro di tasso $\\beta$). Determinare la legge della somma $S_n = X_1 + ... + X_n$.\n\nSfruttando la proprietà che la funzione caratteristica della somma di variabili indipendenti è il prodotto delle loro funzioni caratteristiche: $\\phi_{S_n}(t) = E[e^{itS_n}] = E[e^{it(X_1 + ... + X_n)}] = E[e^{itX_1} ... e^{itX_n}] = E[e^{itX_1}] ... E[e^{itX_n}]$ $\\phi_{S_n}(t) = \\phi_{X_1}(t) ... \\phi_{X_n}(t) = \\left( \\frac{\\beta}{\\beta - it} \\right)^{\\alpha_1} ... \\left( \\frac{\\beta}{\\beta - it} \\right)^{\\alpha_n} = \\left( \\frac{\\beta}{\\beta - it} \\right)^{\\alpha_1 + ... + \\alpha_n}$\n\nLa funzione caratteristica ottenuta è quella di una distribuzione Gamma con parametri $(\\sum_{j=1}^n \\alpha_j, \\beta)$.\n\n**Caso Particolare: Somma di Esponenziali**\n\nSe consideriamo $n$ variabili aleatorie esponenziali indipendenti con lo stesso parametro $\\lambda$ (quindi $\\alpha_j = 1$ e $\\beta = \\lambda$ per ogni $j$), la loro somma seguirà una distribuzione Gamma con parametri $(n, \\lambda)$.\n\nQuesto conclude la parte della lezione richiesta, evidenziando l&#039;importanza dell&#039;indipendenza nello studio delle trasformazioni di variabili aleatorie e fornendo un&#039;introduzione alla funzione caratteristica della distribuzione Gamma.\n\n#### References\n\n\n\n2025-04-15 13:39\n\n_Status: #flashcard_zero  #riscritto_zero  #revisione_zero \n\n_Tags:\n\n## prob-lez17\n\n## Seconda Parte del Corso: Covarianza\n\n### Complemento sull&#039;Indipendenza\n\n#### Funzioni di Variabili Aleatorie Indipendenti\n\nIl professore inizia la seconda parte del corso con un complemento sulla proprietà dell&#039;indipendenza che spesso si presenta nelle applicazioni.\n\n**Proposizione:** Siano $X_1, X_2, \\dots, X_n$ variabili aleatorie indipendenti. Si considerino delle funzioni misurabili $g_1$ di un sottoinsieme di queste variabili (ad esempio, $X_{i_1}, \\dots, X_{i_k}$) e $g_2$ di un altro sottoinsieme disgiunto (ad esempio, $X_{j_1}, \\dots, X_{j_m}$), dove ${i_1, \\dots, i_k} \\cap {j_1, \\dots, j_m} = \\emptyset$. Allora le variabili aleatorie $Y_1 = g_1(X_{i_1}, \\dots, X_{i_k})$ e $Y_2 = g_2(X_{j_1}, \\dots, X_{j_m})$ sono indipendenti.\n\n**Esempio:** Se $X_1, X_2, X_3$ sono variabili aleatorie indipendenti, allora $Y_1 = g_1(X_1) = X_1^2$ e $Y_2 = g_2(X_2, X_3) = X_2^2 + X_3^2$ sono indipendenti.\n![[Pasted image 20250415151714.png]]\n**Dimostrazione (concettuale):** La dimostrazione si basa sulla definizione di indipendenza tramite le controimmagini. Se $X_i$ sono indipendenti, le sigma-algebre generate da gruppi disgiunti di queste variabili sono indipendenti. Le controimmagini di insiemi misurabili tramite $g_1$ e $g_2$ appartengono a queste sigma-algebre indipendenti, garantendo l&#039;indipendenza di $Y_1$ e $Y_2$.\n\n#### Applicazione Tipica: Calcolo del Valore Atteso\n\nConsideriamo variabili aleatorie $X_1, X_2, X_3$ indipendenti con momento secondo finito, cioè $E[X_i^2] &lt; \\infty$ per $i = 1, 2, 3$. Vogliamo calcolare il valore atteso di un&#039;espressione come:\n\n$Y = (X_1^2 + \\sin(X_1 + X_2)) \\cdot e^{-|X_3|}$\n\nDefiniamo $Y_1 = X_1^2 + \\sin(X_1 + X_2)$ e $Y_2 = e^{-|X_3|}$. Notiamo che $Y_1$ è funzione di $X_1$ e $X_2$, mentre $Y_2$ è funzione solo di $X_3$. Poiché $X_1, X_2, X_3$ sono indipendenti, allora $Y_1$ e $Y_2$ sono indipendenti.\n\nSe $E[|Y_1|] &lt; \\infty$ e $E[|Y_2|] &lt; \\infty$, allora il valore atteso del prodotto è il prodotto dei valori attesi:\n\n$E[Y] = E[Y_1 Y_2] = E[Y_1] E[Y_2] = E[X_1^2 + \\sin(X_1 + X_2)] \\cdot E[e^{-|X_3|}]$\n\nPer verificare che i valori attesi siano finiti:\n\n- $|Y_2| = |e^{-|X_3|}| = e^{-|X_3|} \\leq 1$, quindi $E[|Y_2|] \\leq 1 &lt; \\infty$.\n- $|Y_1| = |X_1^2 + \\sin(X_1 + X_2)| \\leq |X_1^2| + |\\sin(X_1 + X_2)| \\leq X_1^2 + 1$. Poiché $E[X_1^2] &lt; \\infty$, allora $E[|Y_1|] \\leq E[X_1^2] + 1 &lt; \\infty$.\n\nQuesta proprietà è fondamentale quando si analizzano funzioni complesse di variabili aleatorie indipendenti.\n![[Pasted image 20250415152305.png]]\n### Covarianza\n\n#### Definizione\n\nDate due variabili aleatorie $X_1$ e $X_2$ con momento secondo finito (cioè $E[X_1^2] &lt; \\infty$ e $E[X_2^2] &lt; \\infty$), la **covarianza** di $X_1$ e $X_2$ è definita come:\n\n$Cov(X_1, X_2) = E[(X_1 - E[X_1])(X_2 - E[X_2])]$\n\nPerché la covarianza è importante? Consideriamo la **varianza di una combinazione lineare** di due variabili aleatorie:\n\n$Var(aX_1 + bX_2) = E[(aX_1 + bX_2 - E[aX_1 + bX_2])^2]$ $= E[(a(X_1 - E[X_1]) + b(X_2 - E[X_2]))^2]$ $= E[a^2(X_1 - E[X_1])^2 + b^2(X_2 - E[X_2])^2 + 2ab(X_1 - E[X_1])(X_2 - E[X_2])]$ $= a^2 E[(X_1 - E[X_1])^2] + b^2 E[(X_2 - E[X_2])^2] + 2ab E[(X_1 - E[X_1])(X_2 - E[X_2])]$ $= a^2 Var(X_1) + b^2 Var(X_2) + 2ab Cov(X_1, X_2)$\n\nLa covarianza emerge naturalmente quando si studia la variabilità di somme di variabili aleatorie.\n![[Pasted image 20250415153126.png]]\n![[Pasted image 20250415153111.png]]\n![[Pasted image 20250415153552.png]]\n## Proprietà della Covarianza\n![[Pasted image 20250415154122.png]]\n### 1. Covarianza di una variabile con se stessa\n\n**Proprietà:** La covarianza di una variabile aleatoria con se stessa è uguale alla sua varianza.\n\n$Cov(X_1, X_1) = Var(X_1)$\n\n**Commento del professore:** Nessuno vieta di considerare il vettore particolare che ha come componente sempre la stessa variabile aleatoria. In questo caso, applicando la definizione di covarianza, il prodotto $(X_1 - E[X_1])(X_1 - E[X_1])$ diventa $(X_1 - E[X_1])^2$, e il valore atteso di questo è proprio la definizione di varianza.\n\n### 2. Simmetria della Covarianza\n\n**Proprietà:** La covarianza tra due variabili aleatorie è simmetrica.\n\n$Cov(X_1, X_2) = Cov(X_2, X_1)$\n\n**Commento del professore:** Questa proprietà è ovvia direttamente dalla definizione di covarianza, poiché il prodotto $(X_1 - E[X_1])(X_2 - E[X_2])$ è commutativo. Quindi l&#039;ordine delle variabili non influenza il risultato della covarianza. Questa proprietà implica che quando si calcola la varianza di una somma di variabili aleatorie, il termine $Cov(X_i, X_j)$ è lo stesso di $Cov(X_j, X_i)$, il che è importante per le formule generali.\n\n### 3. Relazione con il momento misto\n\n**Proprietà:** La covarianza può essere espressa come il momento misto meno il prodotto dei momenti primi (valori attesi).\n\n$Cov(X_1, X_2) = E[X_1 X_2] - E[X_1]E[X_2]$\n\n**Dimostrazione:** Il professore svolge la dimostrazione nel seguente modo: Partendo dalla definizione: $Cov(X_1, X_2) = E[(X_1 - E[X_1])(X_2 - E[X_2])]$ Si sviluppa il prodotto all&#039;interno del valore atteso: $Cov(X_1, X_2) = E[X_1 X_2 - X_1 E[X_2] - E[X_1] X_2 + E[X_1] E[X_2]]$ Utilizzando la linearità del valore atteso, si ottiene: $Cov(X_1, X_2) = E[X_1 X_2] - E[X_1 E[X_2]] - E[E[X_1] X_2] + E[E[X_1] E[X_2]]$ Poiché $E[X_1]$ e $E[X_2]$ sono costanti, possono essere portate fuori dal valore atteso: $Cov(X_1, X_2) = E[X_1 X_2] - E[X_1] E[X_2] - E[X_1] E[X_2] + E[X_1] E[X_2]$ Combinando gli ultimi due termini, si arriva a: $Cov(X_1, X_2) = E[X_1 X_2] - E[X_1] E[X_2]$\n![[Pasted image 20250415160401.png]]\n**Commento del professore:** Questa è una dimostrazione tipica che può essere richiesta in un compito. Spesso è più comodo calcolare separatamente il momento misto $E[X_1 X_2]$ e i momenti marginali $E[X_1]$ e $E[X_2]$ per poi trovare la covarianza.\n\n### 4. Effetto delle trasformazioni lineari\n\n**Proprietà:** La covarianza è quadratica nei coefficienti e insensibile alle traslazioni. Per costanti $a, b, c, d \\in \\mathbb{R}$:\n\n$Cov(aX_1 + c, bX_2 + d) = ab Cov(X_1, X_2)$\n\n**Dimostrazione:** Il professore esegue la dimostrazione come segue: Partendo dalla definizione di covarianza applicata alle variabili trasformate: $Cov(aX_1 + c, bX_2 + d) = E[((aX_1 + c) - E[aX_1 + c])((bX_2 + d) - E[bX_2 + d])]$ Si calcolano i valori attesi delle variabili trasformate: $E[aX_1 + c] = aE[X_1] + c$ $E[bX_2 + d] = bE[X_2] + d$ Sostituendo nella definizione: $Cov(aX_1 + c, bX_2 + d) = E[(aX_1 + c - (aE[X_1] + c))(bX_2 + d - (bE[X_2] + d))]$ $Cov(aX_1 + c, bX_2 + d) = E[(aX_1 - aE[X_1])(bX_2 - bE[X_2])]$ S Factorizzano le costanti $a$ e $b$: $Cov(aX_1 + c, bX_2 + d) = E[a(X_1 - E[X_1]) b(X_2 - E[X_2])]$ $Cov(aX_1 + c, bX_2 + d) = E[ab(X_1 - E[X_1])(X_2 - E[X_2])]$ Per linearità del valore atteso, le costanti $a$ e $b$ possono essere portate fuori: $Cov(aX_1 + c, bX_2 + d) = ab E[(X_1 - E[X_1])(X_2 - E[X_2])] = ab Cov(X_1, X_2)$\n![[Pasted image 20250415160714.png]]\n**Commento del professore:** Come per la varianza (che ha un solo coefficiente), la covarianza è insensibile alle traslazioni (l&#039;aggiunta delle costanti $c$ e $d$) e i coefficienti moltiplicativi $a$ e $b$ vengono portati fuori, moltiplicandosi tra loro.\n\n### 5. Covarianza di variabili indipendenti\n\n**Proprietà:** Se due variabili aleatorie $X_1$ e $X_2$ sono indipendenti, allora la loro covarianza è zero.\n\n$Se \\ X_1 \\ e \\ X_2 \\ sono \\ indipendenti, \\ allora \\ Cov(X_1, X_2) = 0$\n\n**Dimostrazione:** Il professore spiega la dimostrazione in questo modo: Se $X_1$ e $X_2$ sono indipendenti e hanno momento secondo finito (il che implica che abbiano anche momento primo finito, altrimenti non si potrebbe nemmeno scrivere la covarianza), allora $E[X_1 X_2] = E[X_1] E[X_2]$. Utilizzando la proprietà 3: $Cov(X_1, X_2) = E[X_1 X_2] - E[X_1] E[X_2] = E[X_1] E[X_2] - E[X_1] E[X_2] = 0$\n![[Pasted image 20250415160219.png]]\n**Commento del professore:** Il fatto che siano indipendenti implica che il valore atteso del prodotto si fattorizza nel prodotto dei valori attesi, portando direttamente a una covarianza nulla.\n\n**Attenzione:** Il professore sottolinea che **il viceversa non è sempre vero**. Una covarianza nulla non implica necessariamente che le variabili aleatorie siano indipendenti. Possono esistere situazioni in cui la covarianza è zero ma le variabili sono dipendenti.\n\n### 6. Caso speciale: media nulla\n\n**Proprietà:** Se una delle due variabili aleatorie ha media nulla (e la covarianza è finita), allora la covarianza è uguale al valore atteso del momento misto.\n\n$Se \\ E[X_1] = 0 \\ (e \\ Cov(X_1, X_2) \\ è \\ finita), \\ allora \\ Cov(X_1, X_2) = E[X_1 X_2]$\n\n**Spiegazione:** Se $E[X_1] = 0$, allora dalla proprietà 3: $Cov(X_1, X_2) = E[X_1 X_2] - E[X_1] E[X_2] = E[X_1 X_2] - 0 \\cdot E[X_2] = E[X_1 X_2]$\n![[Pasted image 20250415160850.png]]\n**Commento del professore:** Questa è una proprietà semplice ma utile. Se si sa che una delle due variabili ha media zero, per calcolare la covarianza è sufficiente calcolare il valore atteso del loro prodotto, risparmiando un potenziale calcolo di un integrale.\n\n#### Varianza di una Combinazione Lineare di $n$ Variabili Aleatorie\n\nGeneralizzando al caso di $n$ variabili aleatorie $X_1, \\dots, X_n$ e costanti $a_1, \\dots, a_n$, la varianza della combinazione lineare $\\sum_{i=1}^n a_i X_i$ è data da:\n\n$Var(\\sum_{i=1}^n a_i X_i) = \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j Cov(X_i, X_j)$\n\nQuesta formula può essere riscritta in diverse forme equivalenti:\n\n$Var(\\sum_{i=1}^n a_i X_i) = \\sum_{i=1}^n a_i^2 Var(X_i) + \\sum_{i \\neq j} a_i a_j Cov(X_i, X_j)$\n\nOppure:\n\n$Var(\\sum_{i=1}^n a_i X_i) = \\sum_{j=1}^n a_j^2 Var(X_j) + 2 \\sum_{1 \\leq i &lt; j \\leq n} a_i a_j Cov(X_i, X_j)$\n\nQueste espressioni mostrano come la variabilità di una somma di variabili aleatorie dipenda non solo dalle varianze individuali, ma anche dalle covarianze tra le coppie di variabili.\n![[Pasted image 20250415161729.png]]\n#### Covarianza di Combinazioni Lineari\n\nDate due collezioni di variabili aleatorie ${X_i}_{i=1}^m$ e ${Y_j}_{j=1}^n$ definite sullo stesso spazio di probabilità, e costanti ${a_i}_{i=1}^m$ e ${b_j}_{j=1}^n$, la covarianza delle combinazioni lineari $\\sum_{i=1}^m a_i X_i$ e $\\sum_{j=1}^n b_j Y_j$ è:\n\n$Cov(\\sum_{i=1}^m a_i X_i, \\sum_{j=1}^n b_j Y_j) = \\sum_{i=1}^m \\sum_{j=1}^n a_i b_j Cov(X_i, Y_j)$\n\nQuesta proprietà, detta bilinearità della covarianza, è fondamentale per manipolare espressioni che coinvolgono combinazioni lineari di variabili aleatorie.\n![[Pasted image 20250415161853.png]]\n**Esempio:** $Cov(a_1 X_1 + a_2 X_2, b_1 Y_1 + b_2 Y_2) = a_1 b_1 Cov(X_1, Y_1) + a_1 b_2 Cov(X_1, Y_2) + a_2 b_1 Cov(X_2, Y_1) + a_2 b_2 Cov(X_2, Y_2)$\n\nInoltre, la covarianza è insensibile alle traslazioni: $Cov(X + c, Y) = Cov(X, Y)$ per qualsiasi costante $c$.\n\n#### Esempi di Calcolo di Covarianza\n\n1. $Cov(2X + 1, Y + 3Z) = Cov(2X, Y + 3Z) = 2 Cov(X, Y + 3Z) = 2 (Cov(X, Y) + Cov(X, 3Z)) = 2 Cov(X, Y) + 2 \\cdot 3 Cov(X, Z) = 2 Cov(X, Y) + 6 Cov(X, Z)$.\n    \n2. $Cov(3X + 1, X + Y) = Cov(3X, X + Y) = 3 Cov(X, X + Y) = 3 (Cov(X, X) + Cov(X, Y)) = 3 (Var(X) + Cov(X, Y))$.\n    \n3. $Cov(c, X) = Cov(c + 0, X + 0) = 1 \\cdot 1 \\cdot Cov(\\text{costante nulla}, X) = Cov(0, X) = E[(0 - E)(X - E[X])] = E[0 \\cdot (X - E[X])] = E = 0$. La covarianza tra una costante e una variabile aleatoria è sempre zero.\n![[Pasted image 20250415162426.png]]\n\n**Commento:**\n\n- **Insensibilità alle traslazioni:** La costante $+1$ nel primo argomento e $+3z$ nel secondo argomento non influenzano la covarianza. Questo è dovuto alla proprietà che $Cov(aX_1 + c, bX_2 + d) = ab Cov(X_1, X_2)$. Le costanti additive ($c$ e $d$) vengono eliminate nel calcolo della covarianza perché si annullano quando si considerano le deviazioni dalla media.\n- **Linearità nei coefficienti:** I coefficienti moltiplicativi ($2$ per $x$ e potenzialmente un coefficiente implicito di $1$ per $y$, e $3$ per $z$) vengono estratti dalla covarianza. $Cov(2x, y) = 2 Cov(x, y)$ e $Cov(x, 3z) = 3 Cov(x, z)$. Quando abbiamo una combinazione lineare in entrambi gli argomenti, i coefficienti si moltiplicano, come si vede nel termine $2 \\cdot 3 \\cdot Cov(x, z)$.\n- **Distribuzione della covarianza:** La covarianza si &quot;distribuisce&quot; sulla somma, in modo simile al valore atteso. $Cov(2x + 1, y + 3z) = Cov(2x + 1, y) + Cov(2x + 1, 3z)$. Applicando poi l&#039;insensibilità alle traslazioni e la linearità dei coefficienti, si arriva al risultato.\n\n### Esercizio Difficile sulla Covarianza\n\n**Esercizio:** Siano $X_1, X_2$ e $\\tilde{X}_1, \\tilde{X}_2$ due vettori aleatori indipendenti con la stessa legge (stessa distribuzione congiunta). Dimostrare che:\n\n$Cov(X_1, X_2) = \\frac{1}{2} E[(X_1 - \\tilde{X}_1)(X_2 - \\tilde{X}_2)]$\n![[Pasted image 20250415162457.png]]\n![[Pasted image 20250415162800.png|200]]\n**Spiegazione intuitiva della Covarianza come indice di concordanza:**\n\nLa covarianza misura come due variabili aleatorie variano insieme. Un valore positivo indica che tendono a muoversi nella stessa direzione, mentre un valore negativo indica che tendono a muoversi in direzioni opposte. Un valore vicino a zero suggerisce una relazione lineare debole o assente.\n\nL&#039;esercizio proposto cerca di fornire un&#039;ulteriore interpretazione della covarianza confrontando le realizzazioni di due coppie indipendenti con la stessa distribuzione. L&#039;espressione $E[(X_1 - \\tilde{X}_1)(X_2 - \\tilde{X}_2)]$ considera le differenze tra le prime componenti e le differenze tra le seconde componenti delle due coppie. Il valore atteso di questo prodotto è legato alla tendenza delle variazioni congiunte delle variabili.\n\nQuesto esercizio, pur non essendo direttamente utile per il compitino imminente, è prezioso per approfondire la comprensione delle proprietà delle variabili aleatorie e del concetto di covarianza.\n___\n### Conclusione sull&#039;Argomento Varianza, Covarianza e Correlazione\n\n- **Definizione di Coefficiente di Correlazione Lineare**\n    \n    - Date due variabili aleatorie reali $X_1$ e $X_2$ con momento secondo finito (e quindi con varianza finita), il **coefficiente di correlazione lineare**, spesso indicato con $r$ o $\\rho$, è definito come: $$\\rho = \\frac{Cov(X_1, X_2)}{\\sqrt{Var(X_1)Var(X_2)}}$$\n    - Questa definizione è valida assumendo che le varianze siano diverse da zero.\n    - Il professore specifica che si tratterà solo di questo tipo di coefficiente di correlazione, sottolineando che ne esistono altri (come la $\\tau$ di Kendall, legata a una diversa forma di dipendenza).\n- **Proprietà del Coefficiente di Correlazione Lineare**\n    \n    - **Proposizione 1:** Il coefficiente di correlazione lineare $\\rho$ è un numero compreso tra -1 e 1, inclusi.\n        - **Commento:** La covarianza può assumere qualsiasi valore tra $-\\infty$ e $+\\infty$. La divisione per la radice del prodotto delle varianze (che sono positive) normalizza la covarianza, restringendo l&#039;intervallo dei valori possibili per $\\rho$.\n    - **Proposizione 2:** I casi estremi, $|\\rho| = 1$ (ovvero $\\rho = 1$ o $\\rho = -1$), si verificano **se e solo se** esiste una relazione lineare tra $X_1$ e $X_2$ con probabilità 1. Ciò significa che esistono costanti $a \\neq 0$, $b$, $c \\neq 0$, e $d$ tali che con probabilità 1 il vettore $(X_1, X_2)$ è concentrato su una retta, la cui equazione è $ax_1 + bx_2 = c$. In altre parole, $X_2$ può essere espressa come una funzione lineare di $X_1$ (o viceversa), quasi certamente.\n        - Se $\\rho = 1$, allora $X_2 = \\alpha X_1 + \\beta$ con $\\alpha &gt; 0$ quasi certamente.\n        - Se $\\rho = -1$, allora $X_2 = \\alpha X_1 + \\beta$ con $\\alpha &lt; 0$ quasi certamente.\n        - **Commento:** Un valore di $\\rho$ vicino a 1 o -1 suggerisce una forte tendenza alla dipendenza lineare, ma solo i valori estremi indicano una dipendenza lineare esatta con probabilità 1. È possibile avere dipendenza completa (dove una variabile è funzione deterministica dell&#039;altra) senza che $\\rho$ sia uguale a 1 o -1 se la relazione non è lineare.\n    ![[Pasted image 20250416142809.png]]\n- **Dimostrazione delle Proprietà della Correlazione Lineare**\n    \n    1. Consideriamo la varianza della variabile aleatoria trasformata $\\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2}$: $Var\\left(\\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2}\\right) \\geq 0$ Questo è vero perché la varianza di qualsiasi variabile aleatoria reale è sempre non negativa.\n    \n\t2. Applichiamo la proprietà della varianza della somma di due variabili aleatorie: $Var(A + B) = Var(A) + Var(B) + 2 Cov(A, B)$. Nel nostro caso, $A = \\frac{X_1}{\\sigma_1}$ e $B = \\frac{X_2}{\\sigma_2}$: $Var\\left(\\frac{X_1}{\\sigma_1}\\right) + Var\\left(\\frac{X_2}{\\sigma_2}\\right) + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0$\n\t    \n\t3. Utilizziamo la proprietà della varianza di una variabile moltiplicata per una costante: $Var(aX) = a^2 Var(X)$: $\\frac{1}{\\sigma_1^2} Var(X_1) + \\frac{1}{\\sigma_2^2} Var(X_2) + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0$\n\t    \n\t4. Sappiamo che $Var(X_1) = \\sigma_1^2$ e $Var(X_2) = \\sigma_2^2$, quindi: $\\frac{\\sigma_1^2}{\\sigma_1^2} + \\frac{\\sigma_2^2}{\\sigma_2^2} + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0$ $1 + 1 + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0$ $2 + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0$\n\t    \n\t5. Applichiamo la proprietà della covarianza con costanti: $Cov(aX, bY) = ab Cov(X, Y)$: $2 + 2 \\cdot \\frac{1}{\\sigma_1} \\cdot \\frac{1}{\\sigma_2} Cov(X_1, X_2) \\geq 0$ $2 + 2 \\frac{Cov(X_1, X_2)}{\\sigma_1 \\sigma_2} \\geq 0$\n\t    \n\t6. Riconosciamo nella frazione la definizione del coefficiente di correlazione $\\rho$: $2 + 2 \\rho \\geq 0$ $2 \\rho \\geq -2$ $\\rho \\geq -1$\n\t    \n\t7. Ora consideriamo la varianza della variabile aleatoria trasformata $\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}$: $Var\\left(\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}\\right) \\geq 0$\n\t    \n\t8. Applichiamo la proprietà della varianza della somma (o differenza): $Var(A - B) = Var(A) + Var(B) - 2 Cov(A, B)$: $Var\\left(\\frac{X_1}{\\sigma_1}\\right) + Var\\left(-\\frac{X_2}{\\sigma_2}\\right) - 2 Cov\\left(\\frac{X_1}{\\sigma_1}, -\\frac{X_2}{\\sigma_2}\\right) \\geq 0$\n\t    \n\t9. Utilizzando le proprietà $Var(aX) = a^2 Var(X)$ e $Cov(aX, bY) = ab Cov(X, Y)$: $\\frac{1}{\\sigma_1^2} Var(X_1) + \\left(-\\frac{1}{\\sigma_2}\\right)^2 Var(X_2) - 2 \\cdot \\frac{1}{\\sigma_1} \\cdot \\left(-\\frac{1}{\\sigma_2}\\right) Cov(X_1, X_2) \\geq 0$ $\\frac{\\sigma_1^2}{\\sigma_1^2} + \\frac{\\sigma_2^2}{\\sigma_2^2} + 2 \\frac{Cov(X_1, X_2)}{\\sigma_1 \\sigma_2} \\geq 0$ $1 + 1 + 2 \\rho \\geq 0$\n\t    \n\t10. Attenzione, c&#039;è un errore nel passaggio riportato nella fonte. La covarianza di $\\frac{X_1}{\\sigma_1}$ e $-\\frac{X_2}{\\sigma_2}$ è $-\\frac{1}{\\sigma_1 \\sigma_2} Cov(X_1, X_2) = -\\rho$. Quindi la disuguaglianza corretta è: $1 + 1 - 2 (-\\rho) \\geq 0$ $2 + 2 \\rho \\geq 0$, che ci riporta a $\\rho \\geq -1$.\n\t    \n\t    Ripartiamo dal passo 8 con maggiore attenzione al segno: $Var\\left(\\frac{X_1}{\\sigma_1}\\right) + Var\\left(-\\frac{X_2}{\\sigma_2}\\right) - 2 Cov\\left(\\frac{X_1}{\\sigma_1}, -\\frac{X_2}{\\sigma_2}\\right) \\geq 0$ $\\frac{1}{\\sigma_1^2} Var(X_1) + \\frac{1}{\\sigma_2^2} Var(X_2) - 2 \\left(-\\frac{1}{\\sigma_1 \\sigma_2}\\right) Cov(X_1, X_2) \\geq 0$ $1 + 1 + 2 \\frac{Cov(X_1, X_2)}{\\sigma_1 \\sigma_2} \\geq 0$ $2 + 2 \\rho \\geq 0 \\implies \\rho \\geq -1$.\n\t    \n\t    Ora rifacciamo il caso con il segno meno: $Var\\left(\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}\\right) = Var\\left(\\frac{X_1}{\\sigma_1}\\right) + Var\\left(-\\frac{X_2}{\\sigma_2}\\right) + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, -\\frac{X_2}{\\sigma_2}\\right) \\geq 0$ $1 + 1 + 2 \\left(-\\frac{1}{\\sigma_1 \\sigma_2}\\right) Cov(X_1, X_2) \\geq 0$ $2 - 2 \\rho \\geq 0$ $2 \\geq 2 \\rho$ $1 \\geq \\rho \\implies \\rho \\leq 1$\n\t    ![[Pasted image 20250416143337.png]]\n\t    Quindi, combinando i risultati, otteniamo **$-1 \\leq \\rho \\leq 1$**.\n        \n**Proprietà 2: $|\\rho| = 1$ se e solo se esiste una relazione lineare tra $X_1$ e $X_2$ con probabilità 1**\n\n**Dimostrazione:**\n\n- **Caso $\\rho = 1$:** Dalla dimostrazione precedente, abbiamo visto che $Var\\left(\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}\\right) = 2 - 2\\rho$. Se $\\rho = 1$, allora $Var\\left(\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}\\right) = 2 - 2(1) = 0$. Se la varianza di una variabile aleatoria è zero, significa che la variabile è costante con probabilità 1. Quindi, esiste una costante $c$ tale che: $\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2} = c$ con probabilità 1. $X_1 = \\frac{\\sigma_1}{\\sigma_2} X_2 + c \\sigma_1$ con probabilità 1. Questa è una relazione lineare della forma $X_1 = \\alpha X_2 + \\beta$ dove $\\alpha = \\frac{\\sigma_1}{\\sigma_2} &gt; 0$ e $\\beta = c \\sigma_1$. Il segno positivo di $\\alpha$ corrisponde a una correlazione positiva.\n    \n- **Caso $\\rho = -1$:** Dalla dimostrazione precedente, abbiamo visto che $Var\\left(\\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2}\\right) = 2 + 2\\rho$. Se $\\rho = -1$, allora $Var\\left(\\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2}\\right) = 2 + 2(-1) = 0$. Analogamente, esiste una costante $c&#039;$ tale che: $\\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2} = c&#039;$ con probabilità 1. $X_1 = -\\frac{\\sigma_1}{\\sigma_2} X_2 + c&#039; \\sigma_1$ con probabilità 1. Questa è una relazione lineare della forma $X_1 = \\alpha X_2 + \\beta$ dove $\\alpha = -\\frac{\\sigma_1}{\\sigma_2} &lt; 0$ e $\\beta = c&#039; \\sigma_1$. Il segno negativo di $\\alpha$ corrisponde a una correlazione negativa.\n    ![[Pasted image 20250416143921.png]]\n- **Viceversa:** Se esiste una relazione lineare $X_2 = \\alpha X_1 + \\beta$ con $\\alpha \\neq 0$ (condizione $a \\neq 0$ nella fonte), allora possiamo calcolare la covarianza e le varianze: $Cov(X_1, X_2) = Cov(X_1, \\alpha X_1 + \\beta) = \\alpha Cov(X_1, X_1) = \\alpha Var(X_1) = \\alpha \\sigma_1^2$. $Var(X_2) = Var(\\alpha X_1 + \\beta) = \\alpha^2 Var(X_1) = \\alpha^2 \\sigma_1^2$, quindi $\\sigma_2 = |\\alpha| \\sigma_1$. Sostituendo nella definizione di $\\rho$: $\\rho = \\frac{\\alpha \\sigma_1^2}{\\sigma_1 |\\alpha| \\sigma_1} = \\frac{\\alpha}{|\\alpha|} = \\begin{cases} 1 &amp; \\text{se } \\alpha &gt; 0 \\ -1 &amp; \\text{se } \\alpha &lt; 0 \\end{cases}$ Quindi $|\\rho| = 1$. Lo stesso ragionamento si applica se $X_1$ è una funzione lineare di $X_2$.\n    ![[Pasted image 20250416144112.png]]\n\n**Commento:**\n\nLa dimostrazione si basa sull&#039;importante proprietà che la varianza di una variabile aleatoria è zero se e solo se la variabile è costante con probabilità 1. Normalizzando le variabili $X_1$ e $X_2$ per le loro deviazioni standard, si ottengono variabili con varianza unitaria. La varianza della somma o della differenza di queste variabili normalizzate è poi legata al coefficiente di correlazione. I casi estremi $\\rho = 1$ e $\\rho = -1$ si verificano quando la combinazione lineare delle variabili normalizzate ha varianza zero, il che implica una relazione lineare deterministica tra le variabili originali. Il segno di $\\rho$ indica la direzione di questa relazione lineare.\n\nÈ importante notare che il coefficiente di correlazione lineare misura solo la **dipendenza lineare** tra le variabili. Se le variabili sono dipendenti ma la loro relazione non è lineare, il coefficiente di correlazione lineare potrebbe essere vicino a zero.\n\n### Osservazione Importante sulla Varianza della Somma di Variabili Aleatorie Indipendenti\n\n- Se $X_1, X_2, ..., X_n$ sono variabili aleatorie **indipendenti** con varianza finita, allora la varianza della loro somma è uguale alla somma delle loro varianze: $$Var\\left(\\sum_{i=1}^{n} X_i\\right) = \\sum_{i=1}^{n} Var(X_i)$$\n    - **Giustificazione:** La varianza della somma è data da: $$Var\\left(\\sum_{i=1}^{n} X_i\\right) = \\sum_{i=1}^{n} Var(X_i) + \\sum_{i \\neq j} Cov(X_i, X_j)$$ Se le variabili sono indipendenti, la loro covarianza è zero ($Cov(X_i, X_j) = 0$ per $i \\neq j$). Pertanto, il secondo termine della somma si annulla, lasciando solo la somma delle varianze.\n    ![[Pasted image 20250416144254.png]]\n    - **Attenzione:** Questa proprietà vale solo sotto l&#039;ipotesi di indipendenza (o più generalmente, se le variabili hanno correlazione nulla).\n\n### Esempio: Varianza di una Variabile Aleatoria Binomiale\n\n- Sia $X \\sim Bin(n, p)$ una variabile aleatoria binomiale con parametri $n$ (numero di prove) e $p$ (probabilità di successo).\n- Una variabile binomiale può essere vista come la somma di $n$ variabili aleatorie di Bernoulli indipendenti e identicamente distribuite $I_i \\sim Bern(p)$ per $i = 1, ..., n$: $$X = \\sum_{i=1}^{n} I_i$$\n- **Calcolo del valore atteso (ripasso):** $$E[X] = E\\left[\\sum_{i=1}^{n} I_i\\right] = \\sum_{i=1}^{n} E[I_i]$$ Il valore atteso di una variabile di Bernoulli è $E[I_i] = 0 \\cdot (1-p) + 1 \\cdot p = p$. Quindi, $E[X] = \\sum_{i=1}^{n} p = np$.\n- **Calcolo della varianza:** Poiché le variabili di Bernoulli sono indipendenti, possiamo applicare la proprietà della varianza della somma: $$Var(X) = Var\\left(\\sum_{i=1}^{n} I_i\\right) = \\sum_{i=1}^{n} Var(I_i)$$ La varianza di una variabile di Bernoulli è: $$Var(I_i) = E[I_i^2] - (E[I_i])^2$$ Poiché per una Bernoulli $I_i^2 = I_i$ (0²=0, 1²=1), si ha $E[I_i^2] = E[I_i] = p$. Quindi, $Var(I_i) = p - p^2 = p(1 - p)$. Pertanto, la varianza della binomiale è: $$Var(X) = \\sum_{i=1}^{n} p(1 - p) = n p(1 - p)$$\n![[Pasted image 20250416144332.png]]\n    - **Commento:** Questo esempio mostra come l&#039;utilizzo della proprietà della va rianza della somma per variabili indipendenti semplifica il calcolo della varianza di una binomiale rispetto all&#039;applicazione diretta della definizione alla sua densità discreta.\n\n### Trasformazioni di Variabili Aleatorie\n\n- **Problema generale:** Data una variabile aleatoria $X$ con una certa legge, si vuole studiare la legge di una nuova variabile aleatoria $Y = g(X)$, dove $g$ è una funzione.\n    \n- **Caso discreto:** Se $X$ è una variabile aleatoria discreta, allora anche $Y = g(X)$ sarà discreta. La probabilità che $Y$ assuma un valore $y$ è data dalla somma delle probabilità di tutti i valori $x$ nel dominio di $X$ tali che $g(x) = y$: $$P(Y = y) = P(g(X) = y) = \\sum_{x: g(x) = y} P(X = x) = \\sum_{x: g(x) = y} f_X(x)$$ dove $f_X(x)$ è la densità discreta di $X$.\n    ![[Pasted image 20250416151204.png]]\n- **Caso continuo:** Se $X$ è una variabile aleatoria assolutamente continua, la situazione per $Y = g(X)$ è più complessa. In generale, $Y$ potrebbe essere continua, discreta o mista (come visto in un esercizio del compito, ad esempio per il massimo di variabili aleatorie).\n    \n    - **Esempio menzionato:** $X^2$, se $X$ è assolutamente continua, è anch&#039;essa assolutamente continua.\n    - In generale, non si possono dare condizioni semplici su $g$ per determinare la natura di $Y$&#039;s. Si analizza caso per caso.\n    - La **legge immagine** di $Y$, caratterizzata dalla sua funzione di ripartizione o dalle probabilità di eventi, è data da: $$P(Y \\in A) = P(g(X) \\in A) = P(X \\in g^{-1}(A))$$ dove $g^{-1}(A) = {x: g(x) \\in A}$ è la controimmagine dell&#039;insieme $A$ sotto la funzione $g$. Se $X$ è assolutamente continua con densità $f_X(x)$, allora: $$P(Y \\in A) = \\int_{g^{-1}(A)} f_X(x) dx = \\int_{\\set{x: g(x) \\in A}} f_X(x) dx$$ Questo integrale, a seconda della funzione $g$ e dell&#039;insieme $A$, può essere più o meno facile da calcolare. Per calcolare la funzione di ripartizione di $Y$, si prende $A = (-\\infty, y]$.\n    - **Estensione a variabili vettoriali:** Questi concetti si estendono al caso in cui $X$ è un vettore aleatorio in $\\mathbb{R}^d$ e $g: \\mathbb{R}^d \\rightarrow \\mathbb{R}^k$. L&#039;unica differenza è che l&#039;integrale è ora su un sottoinsieme di $\\mathbb{R}^d$.\n\t![[Pasted image 20250416151309.png]]\n### Somma di Variabili Aleatorie\n\n- La somma di variabili aleatorie è un caso particolare di trasformazione di variabili aleatorie, molto frequente in probabilità e statistica.\n    \n- Si considera il caso in cui $X = (X_1, ..., X_d)$ è un vettore aleatorio e $g(X) = \\sum_{i=1}^{d} X_i$ è la somma delle sue componenti.\n    \n- **Caso discreto (d=2):** Siano $X_1$ e $X_2$ due variabili aleatorie discrete e $Y = X_1 + X_2$. La densità discreta di $Y$ in un punto $y$ è data da: $$P(Y = y) = \\sum_{(x_1, x_2): x_1 + x_2 = y} P(X_1 = x_1, X_2 = x_2)$$ Questa somma doppia può essere riscritta come una somma singola, fissando $x_1$ e determinando $x_2 = y - x_1$: $$P(Y = y) = \\sum_{x_1} P(X_1 = x_1, X_2 = y - x_1)$$\n    \n- **Caso di variabili indipendenti:** Se $X_1$ e $X_2$ sono indipendenti, allora $P(X_1 = x_1, X_2 = x_2) = P(X_1 = x_1) P(X_2 = x_2)$. In questo caso, la densità discreta della somma diventa: $$P(Y = y) = \\sum_{x_1} P(X_1 = x_1) P(X_2 = y - x_1)$$ Questa operazione è nota come **convoluzione discreta** delle densità di probabilità di $X_1$ e $X_2$.\n![[Pasted image 20250416151648.png]]\n    \n- **Esercizio proposto:** Considerare due variabili aleatorie di Poisson $X_1 \\sim Poisson(\\lambda_1)$ e $X_2 \\sim Poisson(\\lambda_2)$, indipendenti. Determinare la legge di densità della loro somma $Y = X_1 + X_2$.\n    \n    - **Commento:** Per risolvere questo esercizio, si applicherebbe la formula della convoluzione discreta, tenendo conto dei possibili valori che $X_1$ e $X_2$ possono assumere (interi non negativi) e dei valori che $Y$ può assumere. La somma sarebbe effettuata sugli $x_1 \\geq 0$ tali che $y - x_1 \\geq 0$.\n\n____\n\n\n\n# Trasformazioni di Variabili Aleatorie\n\n## Caso Discreto: La Somma di Variabili Aleatorie Discrete\n\n- Consideriamo due variabili aleatorie discrete, $x_1$ e $x_2$.\n- La probabilità che la loro somma $y = x_1 + x_2$ assuma un certo valore $y$ è data dalla somma delle probabilità congiunte di tutte le coppie $(x_1, x_2)$ tali che $x_1 + x_2 = y$.\n- Matematicamente, questo si esprime come: $P(y = x_1 + x_2) = \\sum_{x_1} P(x_1, y - x_1)$\n- La sommatoria è intesa per tutte le $x_1$ nel supporto di $x_1$ tali che $y - x_1$ sia nel supporto di $x_2$. Se $y - x_1$ non appartiene al supporto di $x_2$, quel termine semplicemente non compare nella somma.\n- **Esempio:** Il professore suggerisce di considerare il caso della distribuzione di Poisson per farsi un&#039;idea.\n\n## Caso Continuo: La Somma di Variabili Aleatorie Assolutamente Continue\n\n- Consideriamo due variabili aleatorie assolutamente continue, $x_1$ e $x_2$, con densità congiunta $f_X(x_1, x_2)$.\n- La variabile aleatoria $y = x_1 + x_2$ è anch&#039;essa assolutamente continua.\n- La densità di probabilità di $y$, $f_y(y)$, può essere ottenuta calcolando prima la funzione di ripartizione $F_y(y) = P(x_1 + x_2 \\le y)$ e poi derivandola rispetto a $y$.\n- La densità $f_y(y)$ ha la seguente struttura nel caso di due variabili: $f_y(y) = \\int_{-\\infty}^{+\\infty} f(x_1, y - x_1) dx_1$\n- **Osservazione:** Questa è l&#039;analogo continuo della somma che si ha nel caso discreto.\n- **Esercizio (suggerito):** Il professore suggerisce di provare a dimostrare questa formula come esercizio, mostrando come la funzione di ripartizione si può scrivere come un integrale e come si arriva a questa espressione per la densità.\n- **Caso di Indipendenza:** Se $x_1$ e $x_2$ sono indipendenti, la loro densità congiunta si fattorizza $f(x_1, x_2) = f_{x_1}(x_1) f_{x_2}(x_2)$, e la densità della somma diventa la **convoluzione** delle densità marginali: $f_y(y) = \\int_{-\\infty}^{+\\infty} f_{x_1}(x_1) f_{x_2}(y - x_1) dx_1 = (f_{x_1} * f_{x_2})(y)$ A volte la convoluzione è indicata con l&#039;asterisco.\n- **Osservazione:** L&#039;integrazione non è sempre su tutto $\\mathbb{R}$. Ad esempio, se si considerano due variabili aleatorie esponenziali negative, la densità può essere zero per certi valori.\n- **Complicazione per più variabili:** Per la somma di tre variabili aleatorie, si otterrebbe un integrale doppio, per quattro un integrale triplo, e così via, rendendo i calcoli spesso complessi.\n![[Pasted image 20250423145725.png]]\n# Matrice di Varianze e Covarianze\n![[Pasted image 20250423150041.png]]\n## Definizione\n\n- Consideriamo un vettore di variabili aleatorie $Y = \\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_d \\end{pmatrix}$.\n- **Valore Atteso di un Vettore/Matrice:** Il valore atteso di un vettore o di una matrice di variabili aleatorie è definito componente per componente. Il valore atteso di un vettore $Y$ è il vettore delle medie dei suoi componenti: $$ E[Y] = E \\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_D \\end{pmatrix} = \\begin{pmatrix} E[Y_1] \\\\ E[Y_2] \\\\ \\vdots \\\\ E[Y_D] \\end{pmatrix} $$ Questo è ben definito se il valore atteso di ogni componente è finito.\n- **Linearità del Valore Atteso (con Matrici Deterministiche):** Se A, B, C sono matrici deterministiche compatibili e Y è un vettore/matrice aleatorio, allora $E[A Y B + C] = A E[Y] B + C$, mantenendo l&#039;ordine delle moltiplicazioni perché le matrici non commutano.\n\n**2.2 Definizione della Matrice di Varianze e Covarianze** Per un vettore aleatorio $Y$ a valori in $\\mathbb{R}^D$, la **matrice di varianze e covarianze** (a volte indicata come matrice di covarianza o matrice di varianza) è una matrice $D \\times D$ dove l&#039;elemento alla posizione $(i, j)$ è la covarianza tra $Y_i$ e $Y_j$. $$ \\text{Cov}(Y)_{ij} = \\text{Cov}(Y_i, Y_j) = E[(Y_i - E[Y_i])(Y_j - E[Y_j])] $$ Sulla diagonale principale di questa matrice si trovano le varianze delle singole componenti, poiché $\\text{Cov}(Y_i, Y_i) = \\text{Var}(Y_i)$.\n![[Pasted image 20250423150831.png]]\n**2.3 Proprietà della Matrice di Varianze e Covarianze** Si assume che tutte le componenti di $Y$ abbiano varianza finita, altrimenti non si potrebbe definire la matrice.\n\n**2.3.1 Osservazione 1:** La matrice di varianze e covarianze può essere scritta in forma compatta usando il valore atteso di un prodotto esterno: $$ \\text{Cov}(Y) = E[(Y - E[Y])(Y - E[Y])^T] $$ Questo perché la componente $(i, j)$ della matrice $(Y - E[Y])(Y - E[Y])^T$ è $(Y_i - E[Y_i])(Y_j - E[Y_j])$, e il valore atteso di questa quantità è per definizione la covarianza $\\text{Cov}(Y_i, Y_j)$.\n![[Pasted image 20250423151106.png]]\n**2.3.2 Proprietà di Traslazione:** Se $B$ è un vettore deterministico, aggiungere $B$ al vettore aleatorio $Y$ non cambia la sua matrice di varianze e covarianze: $$ \\text{Cov}(Y + B) = \\text{Cov}(Y) $$ Questo deriva dalla definizione: $(Y+B) - E[Y+B] = Y+B - (E[Y] + B) = Y - E[Y]$, quindi la formula $E[(Y - E[Y])(Y - E[Y])^T]$ rimane invariata.\n\n**2.3.3 Proprietà Fondamentali (Proposizione)** Per un vettore aleatorio $Y$ in $\\mathbb{R}^D$ con varianze finite:\n\n1. **Simmetria e Semidefinita Positività:** La matrice $\\text{Cov}(Y)$ è simmetrica e semidefinita positiva. Si usa la notazione $\\text{Cov}(Y) \\ge 0$ per indicare la semidefinita positività. La simmetria è dovuta alla simmetria della covarianza: $\\text{Cov}(Y_i, Y_j) = \\text{Cov}(Y_j, Y_i)$.\n2. **Trasformazione Lineare:** Se $A$ è una matrice deterministica $M \\times D$ e $B$ è un vettore deterministico in $\\mathbb{R}^M$, allora la matrice di varianze e covarianze del vettore aleatorio $AY + B$ (che sta in $\\mathbb{R}^M$) è data da: $$ \\text{Cov}(AY + B) = A \\text{Cov}(Y) A^T $$\n![[Pasted image 20250423151137.png]]\n**2.3.4 Dimostrazione della Proprietà 2 (Trasformazione Lineare) (Dimostrazione)**\n\n- **Passaggio 1:** Usando la proprietà di traslazione (Osservazione 1): $$ \\text{Cov}(AY + B) = \\text{Cov}(AY) $$\n- **Passaggio 2:** Usando la definizione $\\text{Cov}(Z) = E[(Z - E[Z])(Z - E[Z])^T]$ con $Z = AY$: $$ \\text{Cov}(AY) = E[(AY - E[AY])(AY - E[AY])^T] $$\n- **Passaggio 3:** Usando la linearità del valore atteso $E[AY] = AE[Y]$ e la proprietà del trasposto $(MN)^T = N^T M^T$: $$ E[(AY - AE[Y])(AY - AE[Y])^T] = E[A(Y - E[Y]) (A(Y - E[Y]))^T] $$ $$ = E[A(Y - E[Y]) (Y - E[Y])^T A^T] $$\n ![[Pasted image 20250423151925.png]]\n- **Passaggio 4:** Usando la linearità del valore atteso per estrarre le matrici deterministiche $A$ e $A^T$: $$ A E[(Y - E[Y])(Y - E[Y])^T] A^T $$\n- **Risultato:** Riconoscendo che $E[(Y - E[Y])(Y - E[Y])^T]$ è per definizione $\\text{Cov}(Y)$: $$ \\text{Cov}(AY + B) = A \\text{Cov}(Y) A^T $$ Questo conclude la dimostrazione della Proprietà 2.\n\n**2.3.5 Dimostrazione della Proprietà 1 (Semidefinita Positiva) (Dimostrazione)**\n\n- **Passaggio 1:** Ricordare la definizione di matrice semidefinita positiva $S$: $x^T S x \\ge 0$ per ogni vettore $x$. Vogliamo dimostrare che $x^T \\text{Cov}(Y) x \\ge 0$ per ogni $x \\in \\mathbb{R}^D$.\n- **Passaggio 2:** Si consideri un vettore deterministico $x \\in \\mathbb{R}^D$ e si definisca una matrice $A = x^T$. Questa è una matrice $1 \\times D$.\n- **Passaggio 3:** Si consideri la variabile aleatoria scalare $Z = A Y = x^T Y$. Questa è una combinazione lineare delle componenti di $Y$, $Z = \\sum_{i=1}^D x_i Y_i$.\n- **Passaggio 4:** Si applichi la Proprietà 2 (dimostrata al punto 2.3.4) al vettore aleatorio $AY$ con $A=x^T$. Il risultato è una matrice $1 \\times 1$ (uno scalare): $$ \\text{Cov}(x^T Y) = x^T \\text{Cov}(Y) (x^T)^T = x^T \\text{Cov}(Y) x $$\n- **Passaggio 5:** Riconoscere che $\\text{Cov}(x^T Y)$ è semplicemente la varianza della variabile aleatoria scalare $Z = x^T Y$: $$ \\text{Cov}(x^T Y) = \\text{Var}(x^T Y) $$\n- **Passaggio 6:** La varianza di qualunque variabile aleatoria scalare (se esiste finita) è sempre non negativa: $$ \\text{Var}(x^T Y) \\ge 0 $$\n- **Risultato:** Combinando i passaggi 4, 5 e 6: $$ x^T \\text{Cov}(Y) x = \\text{Var}(x^T Y) \\ge 0 $$ Questo vale per ogni vettore $x \\in \\mathbb{R}^D$, dimostrando che $\\text{Cov}(Y)$ è una matrice semidefinita positiva. La simmetria è già stata osservata.\n![[Pasted image 20250423152454.png]]\n**Definizione:** Una matrice $S$ è semidefinita positiva ($S \\ge 0$) se $x^T S x \\ge 0$ per ogni vettore $x$. È definita positiva ($S &gt; 0$) se $x^T S x &gt; 0$ per ogni $x \\ne 0$. Per le matrici simmetriche, questo equivale ad avere tutti gli autovalori reali non negativi (semidefinita positiva) o strettamente positivi (definita positiva).\n\n**3. Funzioni Caratteristiche**\n\nLe funzioni caratteristiche sono un altro strumento per caratterizzare la legge di una variabile aleatoria o di un vettore.\n\n**3.1 Introduzione e Motivazione** Abbiamo già visto diversi oggetti (funzione di ripartizione, densità, densità discreta) che caratterizzano la legge di una variabile aleatoria. Tuttavia, come suggerito dall&#039;esempio della somma, calcolare la densità della somma può essere computazionalmente oneroso (grandi integrali/somme di convoluzione). Avere più strumenti equivalenti per caratterizzare le distribuzioni e semplificare i calcoli è utile. Le funzioni caratteristiche sono uno di questi strumenti.\n\n**3.2 Definizione per Variabile Aleatoria Reale** Per definire le funzioni caratteristiche, si usa l&#039;esponenziale complesso. È utile ricordare che per un numero reale $x$, $e^{ix} = \\cos(x) + i \\sin(x)$.\n\n**Definizione:** Data una variabile aleatoria reale $X$, la sua **funzione caratteristica** $\\phi_X(t)$ è definita per ogni $t \\in \\mathbb{R}$ come il valore atteso dell&#039;esponenziale complesso $e^{itX}$: $$ \\phi_X(t) = E[e^{itX}] $$ $e^{itX}$ è una variabile aleatoria a valori complessi, che si può scrivere come $\\cos(tX) + i \\sin(tX)$. Il valore atteso di una variabile aleatoria complessa si definisce come il valore atteso della parte reale più $i$ volte il valore atteso della parte immaginaria: $$ E[e^{itX}] = E[\\cos(tX) + i \\sin(tX)] = E[\\cos(tX)] + i E[\\sin(tX)] $$ La funzione caratteristica $\\phi_X(t)$ è **sempre ben definita** per ogni $t \\in \\mathbb{R}$. Questo perché le funzioni coseno e seno sono limitate (il modulo di $e^{itX}$ è $| \\cos(tX) + i \\sin(tX) | = \\sqrt{\\cos^2(tX) + \\sin^2(tX)} = 1$). Pertanto, $\\cos(tX)$ e $\\sin(tX)$ sono variabili aleatorie limitate, e il loro valore atteso esiste sempre ed è finito. La funzione caratteristica è una funzione da $\\mathbb{R}$ a $\\mathbb{C}$.\n![[Pasted image 20250423153200.png]]\n**3.3 Definizione per Vettore Aleatorio** La definizione si estende ai vettori aleatori.\n\n**Definizione:** Dato un vettore aleatorio $X$ a valori in $\\mathbb{R}^D$, la sua **funzione caratteristica** $\\phi_X(t)$ è definita per ogni vettore $t \\in \\mathbb{R}^D$ come il valore atteso dell&#039;esponenziale complesso $e^{i t \\cdot X}$, dove $t \\cdot X$ è il prodotto scalare tra $t$ e $X$: $$ \\phi_X(t) = E[e^{i t \\cdot X}] $$ Il prodotto scalare $t \\cdot X$ è $\\sum_{j=1}^D T_j X_j$. Quindi $e^{i t \\cdot X}$ è $e^{i \\sum T_j X_j}$, che è l&#039;esponenziale di uno scalare, e la definizione è l&#039;analoga multidimensionale del caso unidimensionale. La funzione caratteristica di un vettore è una funzione da $\\mathbb{R}^D$ a $\\mathbb{C}$. È anch&#039;essa sempre ben definita.\n![[Pasted image 20250423153253.png]]\n**3.4 Calcolo (Somme/Integrali)** Calcolare la funzione caratteristica richiede il calcolo di un valore atteso.\n\n- Se $X$ è una variabile aleatoria discreta con densità (PMF) $P(x)$, la funzione caratteristica è una somma: $$ \\phi_X(t) = \\sum_x e^{itx} P(x) $$ La somma è su tutti i valori $x$ nel dominio di $X$.\n- Se $X$ è una variabile aleatoria assolutamente continua con densità (PDF) $f(x)$, la funzione caratteristica è un integrale su $\\mathbb{R}$: $$ \\phi_X(t) = \\int_{-\\infty}^{\\infty} e^{itx} f(x) dx $$\n- Se $X$ è un vettore aleatorio assolutamente continuo in $\\mathbb{R}^D$ con densità $f(x)$, la funzione caratteristica è un integrale su $\\mathbb{R}^D$: $$ \\phi_X(t) = \\int_{\\mathbb{R}^D} e^{i t \\cdot x} f(x) dx = \\int_{\\mathbb{R}^D} e^{i \\sum_{j=1}^D T_j X_j} f(x_1, \\dots, x_D) dx_1 \\dots dx_D $$ A seconda dei casi, calcolare questi integrali o somme può essere più o meno semplice.\n![[Pasted image 20250423153356.png]]\n**3.5 Teorema di Unicità (Teorema Fondamentale)** Questo teorema è fondamentale per l&#039;utilità delle funzioni caratteristiche.\n\n**Teorema di Unicità:** Due vettori aleatori $X_1$ e $X_2$ a valori in $\\mathbb{R}^D$ hanno la stessa legge immagine (cioè, la stessa distribuzione di probabilità) **se e solo se** le loro funzioni caratteristiche sono uguali per ogni vettore $t \\in \\mathbb{R}^D$: $$ X_1 \\sim X_2 \\iff \\phi_{X_1}(t) = \\phi_{X_2}(t) \\quad \\forall t \\in \\mathbb{R}^D $$\n![[Pasted image 20250423154409.png]]\nCiò significa che la funzione caratteristica caratterizza univocamente la distribuzione di probabilità. Se si riesce a dimostrare che due variabili o vettori aleatori hanno la stessa funzione caratteristica, si può concludere che hanno la stessa legge, anche se non si conosce esplicitamente la densità o la PMF. Un esempio d&#039;uso è dimostrare che una variabile binomiale è una somma di variabili di Bernoulli calcolando e confrontando le loro funzioni caratteristiche.\n\n**3.6 Esempi di Calcolo (Esercizi)** Vengono mostrati esempi di calcolo della funzione caratteristica per distribuzioni discrete.\n\n**Esempio 1: Variabile di Bernoulli(p)** Sia $X \\sim \\text{Bernoulli}(p)$. La variabile assume valore 1 con probabilità $p$ e 0 con probabilità $1-p$.\n\n- **Passaggio 1:** Applicare la definizione di funzione caratteristica $\\phi_X(t) = E[e^{itX}]$.\n- **Passaggio 2:** Calcolare il valore atteso usando la definizione per variabili discrete (somma sui valori possibili): $$ E[e^{itX}] = e^{it \\cdot 1} P(X=1) + e^{it \\cdot 0} P(X=0) $$\n- **Passaggio 3:** Sostituire le probabilità e semplificare: $$ = e^{it} \\cdot p + e^0 \\cdot (1-p) $$ $$ = p e^{it} + 1 \\cdot (1-p) $$ $$ = p e^{it} + 1 - p $$\n- **Risultato:** La funzione caratteristica di una Bernoulli(p) è: $$ \\phi_X(t) = 1 - p + p e^{it} $$\n![[Pasted image 20250423154700.png]]\n**Esempio 2: Variabile di Poisson($\\lambda$)** Sia $X \\sim \\text{Poisson}(\\lambda)$. La variabile assume valori $k \\in {0, 1, 2, \\dots }$ con probabilità $P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$.\n\n- **Passaggio 1:** Applicare la definizione di funzione caratteristica $\\phi_X(t) = E[e^{itX}]$.\n- **Passaggio 2:** Calcolare il valore atteso usando la definizione per variabili discrete (somma sui valori possibili $k$): $$ E[e^{itX}] = \\sum_{k=0}^\\infty e^{itk} P(X=k) $$\n- **Passaggio 3:** Sostituire la PMF della Poisson: $$ = \\sum_{k=0}^\\infty e^{itk} \\frac{\\lambda^k e^{-\\lambda}}{k!} $$\n- **Passaggio 4:** Estrarre il termine $e^{-\\lambda}$ dalla somma: $$ = e^{-\\lambda} \\sum_{k=0}^\\infty e^{itk} \\frac{\\lambda^k}{k!} $$\n- **Passaggio 5:** Riscrivere il termine generale della somma come $\\frac{(e^{it} \\lambda)^k}{k!}$: $$ = e^{-\\lambda} \\sum_{k=0}^\\infty \\frac{(e^{it} \\lambda)^k}{k!} $$\n- **Passaggio 6:** Riconoscere la serie di Taylor dell&#039;esponenziale per argomento complesso $z = e^{it} \\lambda$. La serie $\\sum_{k=0}^\\infty \\frac{z^k}{k!}$ converge a $e^z$ anche per $z \\in \\mathbb{C}$. $$ = e^{-\\lambda} e^{e^{it} \\lambda} $$\n- **Passaggio 7:** Semplificare l&#039;espressione: $$ = e^{\\lambda e^{it}} e^{-\\lambda} = e^{\\lambda e^{it} - \\lambda} = e^{\\lambda(e^{it} - 1)} $$\n- **Risultato:** La funzione caratteristica di una Poisson($\\lambda$) è: $$ \\phi_X(t) = e^{\\lambda(e^{it} - 1)} $$ Questo risultato è importante perché, grazie al teorema di unicità, se una variabile aleatoria ha questa funzione caratteristica, allora la sua legge deve essere di Poisson con parametro $\\lambda$.\n![[Pasted image 20250423154738.png]]\n\n#### References\n\n\n\n2025-04-23 16:09\n\n_Status: #flashcard_zero  #riscritto_zero  #revisione_zero \n\n_Tags: [[probabilità]]  [[sbobine]]\n\n## prob-lez18\n\n\n**Appunti sulla Funzione Caratteristica**\n\n**Definizione (implicita nel testo)** La funzione caratteristica di un vettore aleatorio $x$ (calcolata in un vettore $t$) è definita come il valore atteso di $e^{i t^T x}$.\n\n**Proprietà Importanti della Funzione Caratteristica**\n\nVengono presentate e dimostrate tre proprietà fondamentali della funzione caratteristica.\n\n**Proposizione 1: Valore nell&#039;Origine** La prima proprietà importante è che la funzione caratteristica del vettore $x$ calcolata nel vettore nullo ($t=0$) è uguale a 1. In simboli: $\\phi_x(\\mathbf{0}) = 1$\n\n- **Dimostrazione della Proposizione 1** Calcolando la funzione caratteristica nel punto $\\mathbf{0}$, si ha: $\\phi_x(\\mathbf{0}) = E[e^{i \\mathbf{0}^T x}]$ Il prodotto scalare $\\mathbf{0}^T x$ è uguale a $0$. Quindi l&#039;espressione diventa: $E[e^{i \\cdot 0}] = E[e^0]$ $e^0 = 1$, quindi il valore atteso è: $E = 1$ Questa proprietà è considerata ovvia data la definizione.\n\n**Proposizione 2: Continuità Uniforme** La seconda proprietà importante afferma che la funzione caratteristica, che mappa $t$ a $\\phi_x(t)$, è uniformemente continua su tutto $\\mathbb{R}^D$, dove $D$ è la dimensione del vettore $x$.\n\n- **Dimostrazione della Proposizione 2** Per dimostrare la continuità (e poi l&#039;uniforme continuità), si considera la differenza tra la funzione caratteristica valutata in due punti vicini, $t+h$ e $t$, dove $t$ e $h$ sono vettori. Si vuole analizzare $\\phi_x(t+h) - \\phi_x(t)$. Per definizione: $\\phi_x(t+h) = E[e^{i (t+h)^T x}]$ $\\phi_x(t) = E[e^{i t^T x}]$ La differenza è: $\\phi_x(t+h) - \\phi_x(t) = E[e^{i (t+h)^T x}] - E[e^{i t^T x}]$ Usando la linearità del valore atteso: $\\phi_x(t+h) - \\phi_x(t) = E[e^{i (t+h)^T x} - e^{i t^T x}]$ Espandendo l&#039;esponente: $(t+h)^T x = t^T x + h^T x$ Quindi: $e^{i (t^T x + h^T x)} - e^{i t^T x} = e^{i t^T x} e^{i h^T x} - e^{i t^T x}$ Si può raccogliere il termine comune $e^{i t^T x}$: $e^{i t^T x} (e^{i h^T x} - 1)$ Quindi la differenza diventa: $\\phi_x(t+h) - \\phi_x(t) = E[e^{i t^T x} (e^{i h^T x} - 1)]$ Si applica la disuguaglianza del modulo per il valore atteso, $|!|E[Y]|!| \\le E[|!|Y|!|]$: $|!|\\phi_x(t+h) - \\phi_x(t)|!| \\le E[|!|e^{i t^T x} (e^{i h^T x} - 1)|!|]$ Usando la proprietà del modulo di un prodotto, $|!|ab|!| = |!|a|!| |!|b|!|$: $E[|!|e^{i t^T x}|!| |!|e^{i h^T x} - 1|!|]$ Il modulo di $e^{i \\theta}$ è sempre 1 per qualsiasi $\\theta \\in \\mathbb{R}$. Quindi $|!|e^{i t^T x}|!| = 1$. La disuguaglianza diventa: $|!|\\phi_x(t+h) - \\phi_x(t)|!| \\le E[|!|e^{i h^T x} - 1|!|]$ Il termine a destra, $E[|!|e^{i h^T x} - 1|!|]$, dipende solo da $h$, non da $t$. Il modulo di un numero complesso della forma $e^{i\\alpha} - 1$ ha modulo sempre minore o uguale a 2 (poiché $e^{i\\alpha}$ è sulla circonferenza unitaria e -1 è il punto opposto). La variabile aleatoria $|!|e^{i h^T x} - 1|!|$ è quindi dominata dalla costante 2. Si applica il teorema della convergenza dominata per valutare il limite di questo termine a destra per $h \\to \\mathbf{0}$. $\\lim_{h \\to \\mathbf{0}} E[|!|e^{i h^T x} - 1|!|] = E[\\lim_{h \\to \\mathbf{0}} |!|e^{i h^T x} - 1|!|]$ Il limite interno è: $\\lim_{h \\to \\mathbf{0}} e^{i h^T x}$ Poiché $h \\to \\mathbf{0}$, $h^T x \\to 0$. Quindi, $e^{i h^T x} \\to e^{i \\cdot 0} = e^0 = 1$. Il limite del modulo è: $\\lim_{h \\to \\mathbf{0}} |!|e^{i h^T x} - 1|!| = |!|1 - 1|!| = |!|0|!| = 0$. Quindi, per il teorema della convergenza dominata, il valore atteso di questo limite è 0. Questo implica che: $\\lim_{h \\to \\mathbf{0}} |!|\\phi_x(t+h) - \\phi_x(t)|!| = 0$ Ciò dimostra che la funzione caratteristica è continua. Poiché il membro di destra della disuguaglianza, $E[|!|e^{i h^T x} - 1|!|]$, dipende solo da $h$ e non da $t$, la convergenza a 0 per $h \\to \\mathbf{0}$ è uniforme rispetto a $t$. Questo significa che la continuità è uniforme su tutto $\\mathbb{R}^D$. Il concetto di uniforme continuità implica che la scelta di $\\delta$ per una data $\\epsilon$ non dipende dal punto $t$ considerato.\n\n**Proposizione 3: Funzione Caratteristica di una Trasformazione Lineare** La terza proprietà, considerata molto utile nelle applicazioni, descrive la funzione caratteristica di un vettore trasformato linearmente. Fissata una matrice $A$ e un vettore $B$, compatibili per l&#039;operazione $A x + B$, la funzione caratteristica del nuovo vettore $y = A x + B$ calcolata in $t$ può essere espressa come: $\\phi_{Ax+B}(t) = E[e^{i t^T (Ax+B)}]$\n\n- **Dimostrazione della Proposizione 3** Si parte dalla definizione: $\\phi_{Ax+B}(t) = E[e^{i t^T (Ax+B)}]$ Si distribuisce il prodotto scalare nell&#039;esponente: $t^T (Ax+B) = t^T (Ax) + t^T B$ Quindi l&#039;espressione diventa: $E[e^{i (t^T (Ax) + t^T B)}]$ Usando la proprietà $e^{a+b} = e^a e^b$: $E[e^{i t^T (Ax)} e^{i t^T B}]$ Il termine $e^{i t^T B}$ è una costante rispetto all&#039;operatore di valore atteso, poiché $B$ e $t$ sono vettori deterministici (non aleatori). Si può quindi portare fuori dal valore atteso per linearità: $e^{i t^T B} E[e^{i t^T (Ax)}]$ Ora si riscrive il prodotto scalare $t^T (Ax)$. Usando la proprietà $(AB)^T = B^T A^T$, si ha che $(Ax)^T t = x^T A^T t$. Poiché il prodotto scalare è commutativo, $t^T (Ax) = (Ax)^T t = x^T A^T t$. In alternativa, si può vedere $t^T A$ come $(A^T t)^T$. Quindi $t^T (Ax) = (A^T t)^T x$. Sostituendo nell&#039;espressione: $e^{i t^T B} E[e^{i (A^T t)^T x}]$ Osservando la forma del termine del valore atteso, $E[e^{i v^T x}]$, dove $v = A^T t$, si riconosce la definizione della funzione caratteristica di $x$ valutata nel vettore $A^T t$: $E[e^{i (A^T t)^T x}] = \\phi_x(A^T t)$ Quindi la funzione caratteristica di $A x + B$ è: $\\phi_{Ax+B}(t) = e^{i t^T B} \\phi_x(A^T t)$ Questa formula è utile per calcolare la funzione caratteristica di trasformazioni affini (scala-posizione) di vettori aleatori, anche in più dimensioni.\n![[Pasted image 20250423162343.png]]\n![[Pasted image 20250423162353.png]]\n![[Pasted image 20250423162406.png]]\n**Caratterizzazione dell&#039;Indipendenza tramite Funzioni Caratteristiche**\n\nUn altro risultato importante lega l&#039;indipendenza delle componenti di un vettore aleatorio alla sua funzione caratteristica.\n\n**Proposizione 4: Caratterizzazione dell&#039;Indipendenza** Sia $x = (X_1, X_2, \\dots, X_D)$ un vettore aleatorio con componenti $X_j$. Le componenti $X_1, X_2, \\dots, X_D$ sono stocasticamente indipendenti se e solo se la funzione caratteristica del vettore $x$ calcolata in un vettore $t = (t_1, t_2, \\dots, t_D)$ è uguale al prodotto delle funzioni caratteristiche marginali di ciascuna componente, calcolata nel proprio $t_j$. Questo deve valere per ogni vettore $t \\in \\mathbb{R}^D$. In simboli: $X_1, \\dots, X_D$ sono indipendenti $\\iff \\phi_x(t_1, \\dots, t_D) = \\prod_{j=1}^D \\phi_{X_j}(t_j)$ per ogni $(t_1, \\dots, t_D) \\in \\mathbb{R}^D$.\n\n- **Importante Distinzione** È cruciale non confondere questo enunciato con l&#039;espressione della funzione caratteristica della somma di variabili aleatorie. La funzione caratteristica della somma $S = X_1 + \\dots + X_D$ (che è una variabile scalare, non un vettore) calcolata in uno scalare $t$ è data da $$\\phi_S(t) = E[e^{i t S}] = E[e^{i t (X_1 + \\dots + X_D)}] = E[e^{i t X_1 + \\dots + i t X_D}] = E[\\prod_{j=1}^D e^{i t X_j}]$$. Se gli $X_j$ sono indipendenti, allora $E[\\prod Y_j] = \\prod E[Y_j]$, quindi $\\phi_S(t) = \\prod_{j=1}^D E[e^{i t X_j}] = \\prod_{j=1}^D \\phi_{X_j}(t)$. Nel caso della somma, il prodotto è delle funzioni caratteristiche marginali **tutte valutate nello stesso scalare** $t$. Nella caratterizzazione dell&#039;indipendenza delle componenti di un vettore, la funzione caratteristica **vettoriale** è valutata nel vettore $(t_1, \\dots, t_D)$ e il prodotto è delle funzioni caratteristiche marginali, ciascuna valutata **nella sua componente** $t_j$. L&#039;espressione della funzione caratteristica di un vettore $x$ calcolata sulla &quot;diagonale&quot; con componenti uguali a uno scalare $t$, cioè $\\phi_x(t, t, \\dots, t)$, è sempre esprimibile come $\\phi_{X_1+\\dots+X_D}(t)$. Questa è una conseguenza della definizione, sempre vera indipendentemente dall&#039;indipendenza.\n![[Pasted image 20250424090406.png]]\n- **Dimostrazione della Proposizione 4** La dimostrazione procede in due direzioni.\n    \n    **Direzione 1: Indipendenza $\\implies$ Fattorizzazione** Supponiamo che le componenti $X_1, \\dots, X_D$ siano indipendenti. Si vuole dimostrare che $$\\phi_x(t) = \\prod_{j=1}^D \\phi_{X_j}(t_j)$$. Si parte dalla definizione della funzione caratteristica del vettore $x$ calcolata in $t=(t_1, \\dots, t_D)$: $$\\phi_x(t_1, \\dots, t_D) = E[e^{i t^T x}]$$ Si scrive esplicitamente il prodotto scalare $t^T x$: $$t^T x = \\sum_{j=1}^D t_j X_j$$ Quindi: $\\phi_x(t_1, \\dots, t_D) = E[e^{i \\sum_{j=1}^D t_j X_j}]$ Usando la proprietà $e^{\\sum a_j} = \\prod e^{a_j}$: $\\phi_x(t_1, \\dots, t_D) = E[\\prod_{j=1}^D e^{i t_j X_j}]$ Poiché le variabili aleatorie $X_1, \\dots, X_D$ sono indipendenti, le variabili $Y_j = e^{i t_j X_j}$ (che sono funzioni misurabili delle $X_j$) sono anch&#039;esse indipendenti. Per variabili indipendenti, il valore atteso del prodotto è uguale al prodotto dei valori attesi: $$E[\\prod_{j=1}^D e^{i t_j X_j}] = \\prod_{j=1}^D E[e^{i t_j X_j}]$$ Per definizione, $E[e^{i t_j X_j}]$ è la funzione caratteristica della variabile scalare $X_j$ calcolata nello scalare $t_j$: $$E[e^{i t_j X_j}] = \\phi_{X_j}(t_j)$$ Quindi, si ottiene la fattorizzazione: $$\\phi_x(t_1, \\dots, t_D) = \\prod_{j=1}^D \\phi_{X_j}(t_j)$$ Questa direzione è considerata più semplice.\n    ![[Pasted image 20250424090453.png]]\n    **Direzione 2: Fattorizzazione $\\implies$ Indipendenza** Supponiamo che la funzione caratteristica del vettore $x$ fattorizzi, cioè $\\phi_x(t_1, \\dots, t_D) = \\prod_{j=1}^D \\phi_{X_j}(t_j)$ per ogni $t \\in \\mathbb{R}^D$. Si vuole dimostrare che le componenti $X_j$ sono indipendenti. Si parte dalla supposta uguaglianza: $\\phi_x(t_1, \\dots, t_D) = \\prod_{j=1}^D \\phi_{X_j}(t_j)$ Il membro di sinistra, $\\phi_x(t)$, è per definizione $E[e^{i t^T x}]$. Questo è l&#039;integrale di $e^{i t^T x}$ rispetto alla legge (misura di probabilità immagine) del vettore $x$, che chiamiamo $P_x$: $\\phi_x(t) = \\int_{\\mathbb{R}^D} e^{i t^T y} dP_x(y)$ Il membro di destra è il prodotto di $D$ integrali. La funzione caratteristica marginale $\\phi_{X_j}(t_j)$ è per definizione $E[e^{i t_j X_j}]$. Questo è l&#039;integrale di $e^{i t_j y_j}$ rispetto alla legge (misura di probabilità immagine) della variabile $X_j$, che chiamiamo $P_{X_j}$: $\\phi_{X_j}(t_j) = \\int_{\\mathbb{R}} e^{i t_j y_j} dP_{X_j}(y_j)$ Quindi la fattorizzazione si scrive come: $\\int_{\\mathbb{R}^D} e^{i t^T y} dP_x(y) = \\prod_{j=1}^D \\int_{\\mathbb{R}} e^{i t_j y_j} dP_{X_j}(y_j)$ Il prodotto di integrali, per il teorema di Fubini (utilizzato nella direzione &quot;inversa&quot;), è uguale all&#039;integrale del prodotto rispetto alla misura prodotto. La misura prodotto delle leggi marginali $P_{X_1}, \\dots, P_{X_D}$ è la misura $P_{X_1} \\otimes \\dots \\otimes P_{X_D}$ sullo spazio prodotto $\\mathbb{R}^D$. L&#039;integrale del prodotto $\\prod_{j=1}^D e^{i t_j y_j} = e^{i t_1 y_1} \\dots e^{i t_D y_D} = e^{i \\sum t_j y_j} = e^{i t^T y}$ rispetto alla misura prodotto $P_{X_1} \\otimes \\dots \\otimes P_{X_D}$ è: $\\prod_{j=1}^D \\int_{\\mathbb{R}} e^{i t_j y_j} dP_{X_j}(y_j) = \\int_{\\mathbb{R}^D} e^{i t^T y} d(P_{X_1} \\otimes \\dots \\otimes P_{X_D})(y)$ (Il professore illustra questo passaggio mostrando il caso $D=2$ in dettaglio, spiegando come l&#039;integrale doppio rispetto alla misura prodotto si scomponga nel prodotto degli integrali singoli, e come il termine $e^{i t^T y}$ sia un prodotto di funzioni ciascuna dipendente solo da una componente $y_j$, permettendo l&#039;applicazione di Fubini in entrambe le direzioni). Quindi, dalla supposta fattorizzazione, si ottiene l&#039;uguaglianza di due funzioni caratteristiche: $\\int_{\\mathbb{R}^D} e^{i t^T y} dP_x(y) = \\int_{\\mathbb{R}^D} e^{i t^T y} d(P_{X_1} \\otimes \\dots \\otimes P_{X_D})(y)$ Questa uguaglianza vale per ogni $t \\in \\mathbb{R}^D$. Per il teorema di unicità per le funzioni caratteristiche, se due funzioni caratteristiche coincidono, allora le corrispondenti misure di probabilità (leggi) devono coincidere. Pertanto, la legge del vettore aleatorio $x$, $P_x$, deve essere uguale alla misura prodotto delle leggi marginali: $P_x = P_{X_1} \\otimes \\dots \\otimes P_{X_D}$ Questa uguaglianza delle leggi è una delle definizioni (o caratterizzazioni equivalenti) dell&#039;indipendenza delle componenti di un vettore aleatorio. Quindi, se la funzione caratteristica fattorizza, le componenti del vettore $x$ sono indipendenti. La dimostrazione di questa direzione ha utilizzato tre risultati importanti: il teorema di Fubini, il teorema di unicità delle funzioni caratteristiche e una caratterizzazione dell&#039;indipendenza tramite la legge prodotto.\n    ![[Pasted image 20250424090625.png]]\n    ![[Pasted image 20250424090803.png]]\n___\n\n\n### La Funzione Caratteristica e i Momenti\n\nQuesta sezione tratta un argomento molto importante: la relazione tra la funzione caratteristica e i momenti di una variabile aleatoria. La funzione caratteristica è uno strumento fondamentale che verrà ripreso più volte, specialmente in relazione ai concetti di convergenza e al teorema del limite centrale.\n\n#### Esistenza della Funzione Caratteristica vs. Esistenza dei Momenti\n\nLa funzione caratteristica di una variabile aleatoria può essere scritta senza bisogno di alcuna ipotesi sui momenti. Questo significa che si può definire la funzione caratteristica anche per variabili aleatorie che non possiedono il primo momento (valor atteso), il secondo momento, o nessun momento.\n\n- **Esempio:** La distribuzione di Cauchy è un esempio di variabile aleatoria assolutamente continua che non ha momenti. Nonostante ciò, la sua funzione caratteristica esiste e può essere scritta in forma chiusa, risultando semplice. Quindi, una funzione caratteristica ben definita non implica necessariamente che la variabile aleatoria associata abbia momenti.\n\n#### Teorema Fondamentale: Momenti Implicano Derivabilità della Funzione Caratteristica e Sviluppo di Taylor\n\nConsideriamo una variabile aleatoria reale (dimensione 1) X con funzione caratteristica $\\phi_X(t)$ (indicata come f nelle fonti).\n\n**Condizione:** Supponiamo che esista il momento assoluto di $X$ di ordine $n + \\delta$, ovvero che $E[|X|^{n+\\delta}] &lt; \\infty$, dove $n$ è un intero non negativo ($n \\ge 0$) e $\\delta$ è un valore compreso tra 0 e 1, inclusi gli estremi ($0 \\le \\delta \\le 1$).\n\n**Conclusioni:** Se la condizione precedente è soddisfatta, allora valgono i seguenti punti:\n\n1. **Derivabilità e Legame con i Momenti (per $n \\ge 1$)**:\n    \n    - La funzione caratteristica $\\phi_X(t)$ ammette derivata di ordine $k$ per ogni $k$ compreso tra 1 e $n$ ($1 \\le k \\le n$).\n    - La derivata $k$-esima della funzione caratteristica valutata nell&#039;origine ($t=0$) è legata al momento $k$-esimo di $X$ dalla seguente formula: $$ \\phi_X^{(k)}(0) = i^k E[X^k] $$ Questo ha senso solo se $n \\ge 1$, in modo che $k$ possa assumere valori maggiori o uguali a 1.\n2. **Sviluppo di Taylor nell&#039;Origine**:\n    \n    - La funzione caratteristica può essere sviluppata in serie di Taylor attorno all&#039;origine ($t=0$) fino all&#039;ordine $n$.\n    - Lo sviluppo di Taylor usuale è: $$ \\phi_X(t) = \\sum_{k=0}^{n} \\frac{\\phi_X^{(k)}(0)}{k!} t^k + R_n(t) $$ Utilizzando la relazione tra le derivate nell&#039;origine e i momenti ($ \\phi_X^{(k)}(0) = i^k E[X^k]$ per $k \\ge 1$), e ricordando che $\\phi_X(0) = E[e^{i \\cdot 0 \\cdot X}] = E = 1$ (momento di ordine 0), lo sviluppo diventa: $$ \\phi_X(t) = 1 + \\sum_{k=1}^{n} \\frac{i^k E[X^k]}{k!} t^k + R_n(t) $$\n    - **Comportamento del Resto ($R_n(t)$)**:\n        - Se esiste almeno il momento $n$-esimo ($E[|X|^n] &lt; \\infty$, corrispondente al caso $\\delta = 0$), allora il resto è un &quot;o piccolo&quot; di $t^n$: $$ R_n(t) = o(t^n) $$ Questo significa che $\\lim_{t \\to 0} \\frac{R_n(t)}{t^n} = 0$.\n        - Se esiste un momento di ordine leggermente superiore a $n$, ovvero $E[|X|^{n+\\delta}] &lt; \\infty$ con $\\delta &gt; 0$, allora si ha un controllo più preciso sul resto. Il resto è un &quot;O grande&quot; di $t^{n+\\delta}$: $$ R_n(t) = O(t^{n+\\delta}) $$ Questo significa che esiste una costante $C$ tale che $|R_n(t)| \\le C |t|^{n+\\delta}$ per t vicino a 0. La costante $C$ dipende solo da $n$ e $\\delta$ e da $E[|X|^{n+\\delta}]$. Nello specifico, la dipendenza da $X$ è interamente contenuta nel fattore $E[|X|^{n+\\delta}]$.\n\nIn sintesi, il teorema dice che **l&#039;esistenza del momento $n$-esimo implica la derivabilità $n$ volte della funzione caratteristica e garantisce che il resto dello sviluppo di Taylor sia $o(t^n)$**. Se esiste un momento di ordine $n+\\delta$ con $\\delta &gt; 0$, si ottiene un controllo ancora più preciso sul resto ($O(t^{n+\\delta})$).\n\n#### Idea della Dimostrazione (Relazione Derivata-Momento)\n\nL&#039;idea alla base della relazione tra le derivate della funzione caratteristica nell&#039;origine e i momenti non è così strana.\n\nConsideriamo la derivata prima della funzione caratteristica: $$ \\phi_X&#039;(t) = \\frac{d}{dt} E[e^{itX}] $$ Supponendo di poter scambiare l&#039;operazione di derivata con l&#039;operazione di valore atteso (questo è uno dei passaggi che richiederebbe una giustificazione formale, ma è l&#039;idea intuitiva): $$ \\phi_X&#039;(t) = E\\left[\\frac{d}{dt} e^{itX}\\right] = E[iX e^{itX}] $$ Ora, valutiamo questa derivata nell&#039;origine ($t=0$): $$ \\phi_X&#039;(0) = E[iX e^{i \\cdot 0 \\cdot X}] = E[iX e^0] = E[iX] = i E[X] $$ Quindi, abbiamo $\\phi_X&#039;(0) = i E[X]$, il che implica $E[X] = \\frac{\\phi_X&#039;(0)}{i}$. Questa è esattamente la formula $\\phi_X^{(k)}(0) = i^k E[X^k]$ per $k=1$.\n\nL&#039;idea è che, iterando questo processo di derivazione e scambio con il valore atteso, si ottengono le formule per le derivate di ordine superiore, legandole ai momenti di ordine superiore. Se si ha &quot;quel tantino in più&quot; (l&#039;esistenza del momento dell&#039;ordine appropriato) si può giustificare lo scambio e procedere. Una volta ottenute queste formule per le derivate nell&#039;origine, si applica semplicemente lo sviluppo di Taylor per ottenere la tesi del teorema riguardante l&#039;espansione.\n![[Pasted image 20250424091005.png]]\n#### Significato e Utilità del Teorema\n\nQuesto teorema è molto importante per diversi motivi.\n\n1. **Legame tra Momenti e Funzione Caratteristica:** Esiste un legame diretto che, in certi casi, può essere comodo. Se si desidera calcolare un momento ma l&#039;integrale per il valor atteso è complicato, mentre la funzione caratteristica è facile da calcolare e derivare (soprattutto da valutare in zero), si può usare la formula $E[X^k] = \\frac{\\phi_X^{(k)}(0)}{i^k}$ per ricavare il valore numerico del momento.\n2. **Regolarità:** La funzione caratteristica è sempre uniformemente continua senza alcuna ipotesi sui momenti. L&#039;aggiunta di ipotesi sui momenti &quot;aggiunge regolarità&quot; alla funzione caratteristica, permettendo di svilupparla in serie di Taylor nell&#039;origine. Questo non è sorprendente se si conosce la parte 1 del teorema e il comportamento dei resti di Taylor. La cosa fondamentale è che il teorema fornisce gratuitamente il resto $o(t^n)$ se esiste il momento $n$-esimo. Se si ha qualcosa di più (momento $n+\\delta$), si ottiene un controllo più preciso del resto ($O(t^{n+\\delta})$). Questo controllo è importante perché si sa esattamente da cosa dipende la costante nell&#039;O grande (dal momento $n+\\delta$ e costanti universali che dipendono da $n$ e $\\delta$).\n\nL&#039;aspetto essenziale da ricordare è che **l&#039;esistenza dei momenti implica la derivabilità della funzione caratteristica e il comportamento $o(t^n)$ del resto di Taylor**.\n\n#### Osservazione Importante: L&#039;Implicazione è Unidirezionale (Generalmente)\n\nÈ fondamentale notare che l&#039;implicazione stabilita dal teorema è quella scritta: **se esiste il momento $n$-esimo, allora la funzione caratteristica è derivabile $n$ volte con continuità e la sua derivata $k$-esima nell&#039;origine è legata al momento $k$-esimo dalla formula**.\n\nIn generale, **non è vero il contrario**. Cioè, il fatto che la funzione caratteristica sia derivabile $n$ volte con continuità **non implica necessariamente** che esista il momento $n$-esimo. Esistono risultati più fini che distinguono tra n pari e dispari, ma non verranno usati nel contesto presentato.\n\n#### Legame tra Comportamento della Funzione Caratteristica vicino allo Zero e Code della Distribuzione\n\nUn altro aspetto importante, collegato al teorema, è che il comportamento della funzione caratteristica nell&#039;origine (per $t$ piccolo) è controllato dai momenti. Poiché i momenti dipendono da come si comporta la distribuzione per valori grandi della variabile aleatoria (le &quot;code&quot; della distribuzione), esiste un legame tra il comportamento della probabilità di $X$ molto grande e il comportamento della funzione caratteristica per $t$ piccolo.\n\nConcetti simili, che mettono in relazione il comportamento di una funzione a infinito con il comportamento di una sua trasformata (duale) nell&#039;origine, sono studiati nei cosiddetti **teoremi tauberiani**.\n\n#### Altre Trasformate Integrali\n\nLa funzione caratteristica è una delle trasformate integrali usate per studiare le variabili aleatorie, strettamente imparentata con la Trasformata di Fourier in analisi. Esistono altre trasformate che possono essere utili in circostanze diverse:\n\n- **Funzione Generatrice dei Momenti (MGF):** Presente negli appunti, ma non trattata nel corso.\n- **Funzione Generatrice di Probabilità (PGF):** Si applica alle variabili aleatorie discrete.\n\n#### Caso Multidimensionale\n\nIl teorema discusso finora si riferisce a variabili aleatorie reali (dimensione 1). Per vettori aleatori, esiste un risultato analogo che coinvolge i momenti misti e uno sviluppo di Taylor multidimensionale. Questo si può fare e l&#039;idea non è molto diversa dal caso unidimensionale, ma è formalmente più complessa a causa dei multi-indici. L&#039;esistenza di questo risultato per vettori è menzionata, ma non discussa nel dettaglio.\n\n### Esempi ed Esercizi\n\nLe fonti presentano esempi di funzioni caratteristiche calcolate per specifiche distribuzioni, in particolare la costruzione della funzione caratteristica della Binomiale a partire da quella della Bernoulli, e un esercizio sul campionamento.\n\n#### Funzione Caratteristica della Distribuzione di Bernoulli\n\nConsideriamo una variabile aleatoria $Y \\sim \\text{Bernoulli}(p)$. La sua funzione di probabilità è $P(Y=1)=p$ e $P(Y=0)=1-p$. La funzione caratteristica è definita come $E[e^{itY}]$: $$ \\phi_Y(t) = E[e^{itY}] = e^{it \\cdot 0} P(Y=0) + e^{it \\cdot 1} P(Y=1) $$ $$ \\phi_Y(t) = e^0 (1-p) + e^{it} p $$ $$ \\phi_Y(t) = 1 \\cdot (1-p) + e^{it} p $$ $$ \\phi_Y(t) = 1 - p + p e^{it} $$ Questa è la funzione caratteristica della distribuzione di Bernoulli(p).\n\n#### Funzione Caratteristica della Distribuzione Binomiale\n\nConsideriamo una variabile aleatoria $X \\sim \\text{Binomiale}(n, p)$. Una variabile Binomiale può essere vista come la somma di $n$ variabili aleatorie di Bernoulli indipendenti e identicamente distribuite (i.i.d.), $Y_1, Y_2, \\dots, Y_n$, dove $Y_i \\sim \\text{Bernoulli}(p)$ per ogni $i$. Quindi, $X = \\sum_{i=1}^n Y_i$.\n\nUna proprietà fondamentale della funzione caratteristica è che la funzione caratteristica di una somma di variabili aleatorie _indipendenti_ è il _prodotto_ delle loro funzioni caratteristiche individuali. Se le variabili sono anche _identicamente distribuite_, il prodotto diventa una potenza.\n\nPoiché $Y_i$ sono i.i.d. Bernoulli(p), la funzione caratteristica di $\\sum_{i=1}^n Y_i$ è il prodotto delle funzioni caratteristiche di ciascun $Y_i$. Dato che sono identiche, è $(\\phi_Y(t))^n$. $$ \\phi_X(t) = \\phi_{\\sum_{i=1}^n Y_i}(t) = \\prod_{i=1}^n \\phi_{Y_i}(t) = (\\phi_Y(t))^n $$ Sostituendo la funzione caratteristica della Bernoulli: $$ \\phi_X(t) = (1 - p + p e^{it})^n $$ Questa è la funzione caratteristica della distribuzione Binomiale(n, p).\n\n#### Esercizio: Funzione Caratteristica della Frequenza Empirica\n\nConsideriamo di nuovo $n$ variabili aleatorie $Y_1, \\dots, Y_n$ i.i.d. $\\sim \\text{Bernoulli}(p)$. Definiamo la variabile aleatoria $S_n$ come la media di queste variabili, che rappresenta la frequenza empirica di successo (o la probabilità empirica di ottenere 1): $$ S_n = \\frac{1}{n} \\sum_{i=1}^n Y_i $$\n\n**Domanda 1: $S_n$ è una variabile aleatoria Binomiale?** **Risposta:** No. La variabile Binomiale(n, p) può assumere valori interi ${0, 1, 2, \\dots, n}$. Invece, $S_n$ può assumere valori ${0/n, 1/n, 2/n, \\dots, n/n = 1}$. Il dominio (supporto) dei valori possibili è diverso, quindi $S_n$ non è una Binomiale.\n\n**Domanda 2: Qual è la funzione caratteristica di $S_n$?** Per calcolare la funzione caratteristica di $S_n = \\frac{1}{n} \\sum_{i=1}^n Y_i$, possiamo usare la proprietà che per costanti scalari $a, b$, la funzione caratteristica di $aX+b$ è $\\phi_{aX+b}(t) = e^{itb} \\phi_X(at)$. Nel nostro caso, $S_n$ è della forma $aX$ con $a = \\frac{1}{n}$ e $X = \\sum_{i=1}^n Y_i$. Non c&#039;è il termine &#039;b&#039;. Quindi, la funzione caratteristica di $S_n$ è: $$ \\phi_{S_n}(t) = \\phi_{\\frac{1}{n} (\\sum_{i=1}^n Y_i)}(t) $$ Applicando la proprietà di scaling con $a = \\frac{1}{n}$ e $X = \\sum_{i=1}^n Y_i$: $$ \\phi_{S_n}(t) = \\phi_{\\sum_{i=1}^n Y_i}\\left(\\frac{t}{n}\\right) $$ Sappiamo che $X = \\sum_{i=1}^n Y_i$ dove $Y_i$ sono i.i.d. Bernoulli(p) è una variabile aleatoria Binomiale(n, p). Abbiamo calcolato la sua funzione caratteristica come $\\phi_X(t) = (1 - p + p e^{it})^n$.\n\nSostituiamo questa espressione, valutandola in $\\frac{t}{n}$ anziché $t$: $$ \\phi_{S_n}(t) = \\left(1 - p + p e^{i \\frac{t}{n}}\\right)^n $$ Questo completa il calcolo della funzione caratteristica della frequenza empirica $S_n$ per variabili di Bernoulli.\n\nSpero questa rielaborazione dettagliata, basata esclusivamente sulle fonti fornite, ti sia utile per comprendere meglio i concetti e i passaggi presentati.\n![[Pasted image 20250424091458.png]]\n___\n### Spiegazione sulle Funzioni Caratteristiche \n\n#### Introduzione al Contesto e agli Esempi\n\nIl professore introduce il concetto di funzione caratteristica riprendendo degli esempi. Viene menzionato un Esempio 1 in cui delle variabili $X_j$ sono $\\text{01}$. Questo può essere immaginato come il lancio di $n$ monetine, contando il numero di successi e dividendolo per $n$ per ottenere la frequenza di successi su $n$ lanci.\n\nSi passa poi all&#039;Esempio 2.\n\n#### Esempio: Somma di Variabili Casuali Poisson Indipendenti\n\n- **Definizione e Obiettivo** Si considerano variabili casuali $X_j$ indipendenti, ognuna con il proprio parametro $\\lambda_j$. L&#039;obiettivo è calcolare la funzione caratteristica della loro somma.\n    \n- **Calcolo della Funzione Caratteristica della Somma (Utilizzo della proprietà del prodotto)** La funzione caratteristica della somma di variabili casuali indipendenti è il prodotto delle funzioni caratteristiche individuali. Viene ricordata (anche se con una potenziale notazione intermedia un po&#039; confusa nella trascrizione della fonte) la forma della funzione caratteristica per una singola variabile Poisson di parametro $\\lambda$: $\\phi_X(t) = e^{\\lambda(e^{it}-1)}$. Questa forma è presentata nella fonte come $e^{-\\lambda(1-e^{it})}$ o $e^{-\\lambda} e^{\\lambda e^{it}}$ o ancora $e^{-\\lambda + \\lambda e^{it}}$.\n    \n- **Formule Matematiche (come presentate nella fonte, con LaTeX)** Considerando la somma, si deve fare il prodotto delle funzioni caratteristiche: $\\phi_{\\sum X_j}(t) = \\prod_j \\phi_{X_j}(t)$. Usando la forma della funzione caratteristica per ogni $X_j \\sim \\text{Poisson}(\\lambda_j)$, che è $\\phi_{X_j}(t) = e^{\\lambda_j(e^{it}-1)}$, il prodotto diventa: $$ \\prod_j e^{\\lambda_j(e^{it}-1)} $$ Per la proprietà dell&#039;esponenziale, il prodotto di esponenziali è l&#039;esponenziale della somma degli esponenti: $$ \\exp\\left(\\sum_j \\lambda_j(e^{it}-1)\\right) $$ Si può raccogliere il termine $(e^{it}-1)$ dalla somma: $$ \\exp\\left(\\left(\\sum_j \\lambda_j\\right)(e^{it}-1)\\right) $$ Il professore introduce $\\lambda_{barra} = \\sum_j \\lambda_j$. La formula ottenuta è: $$ e^{\\lambda_{barra}(e^{it}-1)} $$ (Nella fonte questa viene presentata come $e^{-\\lambda_{barra}(1 - e^{it})}$, che è la stessa formula).\n![[Pasted image 20250424091524.png]]\n- **Conclusione per la Somma di Poisson** Riconoscendo la forma della funzione caratteristica ottenuta, si conclude che essa è esattamente la funzione caratteristica di una variabile casuale Poisson con parametro $\\lambda_{barra} = \\sum_j \\lambda_j$. Pertanto, in una riga (utilizzando il teorema di unicità della funzione caratteristica), si è dimostrato che la somma di variabili casuali Poisson indipendenti è una variabile casuale Poisson il cui parametro è la somma dei parametri individuali.\n    \n- **Confronto con altre Distribuzioni (Uniforme)** Viene sottolineato che questa proprietà di &quot;stabilità&quot; (la somma rimane nella stessa famiglia di distribuzioni) non è generale per tutte le famiglie di distribuzioni. Ad esempio, la somma di due variabili casuali Uniformi tra 0 e 1 non è una variabile casuale Uniforme.\n    \n- **Rilevanza (Processo di Poisson)** Questa proprietà è una delle ragioni per cui la distribuzione di Poisson è importante. Ad esempio, nel processo di Poisson, se si contano eventi indipendenti in diverse zone, la somma totale degli eventi nelle zone, ipotizzando che gli eventi in ogni singola zona seguano una distribuzione di Poisson indipendente, sarà una variabile casuale Poisson.\n    \n\n#### Studio della Funzione Caratteristica della Variabile Casuale Normale (Gaussiana)\n\n- **Importanza** La funzione caratteristica della Gaussiana è presentata come molto importante.\n    \n- **Definizione e Forma della Funzione Caratteristica per $N(\\mu, \\sigma^2)$** Si considera una variabile casuale reale $X$ con legge Normale (o Gaussiana) di media $\\mu$ e varianza $\\sigma^2$. La funzione caratteristica di $X$ calcolata in $t$, denotata $\\phi_X(t)$, è data da: $$ \\phi_X(t) = e^{i \\mu t} e^{-\\frac{\\sigma^2 t^2}{2}} $$ Viene fatto notare che assomiglia un po&#039; alla funzione di densità, ma non bisogna confondere le due, poiché $\\sigma$ e $\\mu$ compaiono in posizioni diverse.\n    \n- **Relazione tra Gaussiana Generale e Gaussiana Standard ($N(0,1)$)** Si osserva che una variabile casuale Gaussiana $X \\sim N(\\mu, \\sigma^2)$ può essere scritta come $X = \\mu + \\sigma X_0$, dove $X_0$ è una Gaussiana standard, $X_0 \\sim N(0, 1)$. Questo deriva dal fatto che la famiglia Gaussiana è una famiglia di scala e posizione. Questo può essere verificato scrivendo la densità e riconoscendo la densità di una Gaussiana standard dopo una trasformazione lineare di scala e posizione.\n    \n- **Utilizzo della Gaussiana Standard per la Dimostrazione** Grazie alla proprietà che la Gaussiana è una famiglia di scala e posizione, se si conosce la funzione caratteristica della Gaussiana standard $N(0, 1)$, è sufficiente per ottenere la funzione caratteristica di qualsiasi Gaussiana generale $N(\\mu, \\sigma^2)$. La funzione caratteristica di $aX+b$ è $\\phi_{aX+b}(t) = e^{ibt} \\phi_X(at)$. Applicando questa a $X = \\mu + \\sigma X_0$ (con $X_0 \\sim N(0,1)$), si ha: $$ \\phi_X(t) = \\phi_{\\mu + \\sigma X_0}(t) = e^{i \\mu t} \\phi_{X_0}(\\sigma t) $$ Se si dimostra che $\\phi_{X_0}(t) = e^{-t^2/2}$ per la Gaussiana standard, allora: $$ \\phi_X(t) = e^{i \\mu t} \\phi_{X_0}(\\sigma t) = e^{i \\mu t} e^{-(\\sigma t)^2/2} = e^{i \\mu t} e^{-\\frac{\\sigma^2 t^2}{2}} $$ Questo è esattamente quanto si voleva dimostrare. Quindi, basta dimostrare l&#039;espressione per una Gaussiana standard. Questa è una strategia comune: dimostrare proprietà per i parametri più comodi quando si ha una famiglia di scala e posizione. Non è applicabile, ad esempio, alla Poisson o alla Binomiale perché i loro parametri non sono di scala o posizione.\n  ![[Pasted image 20250424091726.png]]\n    \n- **(Dimostrazione) Derivazione della Funzione Caratteristica per la Gaussiana Standard $N(0,1)$**\n    \n    - **Obiettivo e Metodologia (ODE)** Questa dimostrazione non è formalmente richiesta, ma usa tecniche di analisi ed equazioni differenziali ordinarie (ODE).\n        \n    - **Impostazione della Derivata della Funzione Caratteristica (Forma Integrale)** La funzione caratteristica di una variabile casuale con densità $f(x)$ è data dall&#039;integrale $\\int_{-\\infty}^{\\infty} e^{itx} f(x) dx$. Per la Gaussiana standard $X_0$, la densità è $f_{X_0}(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}$ (la costante $\\frac{1}{\\sqrt{2\\pi}}$ è menzionata come &quot;mi ero dimenticato $\\sqrt{2\\pi}$&quot; in, suggerendo che sia stata omessa durante la derivazione). La funzione caratteristica è $\\phi_{X_0}(t) = \\int_{-\\infty}^{\\infty} e^{itx} f_{X_0}(x) dx$. Questo è anche il valore atteso di $e^{itX_0}$ dove $X_0 \\sim N(0,1)$. Si calcola la derivata prima rispetto a $t$: $$ \\phi&#039;_{X_0}(t) = \\frac{d}{dt} \\int_{-\\infty}^{\\infty} e^{itx} f_{X_0}(x) dx $$ Assumendo di poter portare la derivata dentro l&#039;integrale (è una quasi dimostrazione): $$ \\phi&#039;_{X_0}(t) = \\int_{-\\infty}^{\\infty} \\frac{d}{dt}(e^{itx}) f_{X_0}(x) dx = \\int_{-\\infty}^{\\infty} i x e^{itx} f_{X_0}(x) dx $$ Sostituendo la densità (e omettendo temporaneamente la costante $\\frac{1}{\\sqrt{2\\pi}}$ come fatto nella fonte per i calcoli espliciti): $$ \\phi&#039;_{X_0}(t) = \\int i x e^{itx} e^{-x^2/2} dx $$\n        \n    - **Passaggi Matematici (Integrazione per Parti)** Si riarrangia l&#039;integrale per applicare l&#039;integrazione per parti $\\int u dv = uv - \\int v du$. Il termine $ix e^{itx} e^{-x^2/2}$ viene visto come $i \\cdot e^{itx} \\cdot x e^{-x^2/2}$. Si sceglie $u = e^{itx}$ e $dv = x e^{-x^2/2} dx$. Allora $du = it e^{itx} dx$. Per trovare $v$, si integra $dv$. Si nota che $x e^{-x^2/2}$ è la derivata di $-e^{-x^2/2}$ rispetto a $x$: $\\frac{d}{dx}(-e^{-x^2/2}) = -(-x)e^{-x^2/2} = x e^{-x^2/2}$. Quindi $v = -e^{-x^2/2}$.\n        \n        L&#039;integrale diventa, includendo l&#039;iniziale fattore $i$ (menzionato come &quot;davanti a tutta la parente&quot; in): $$ \\phi&#039;_{X_0}(t) = i \\left[ (e^{itx})(-e^{-x^2/2}) \\Big|_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} (-e^{-x^2/2}) (it e^{itx}) dx \\right] $$\n        \n    - **Termine di Bordo (valutazione a $\\pm \\infty$)** Il primo termine (termine di bordo $uv \\big|_{-\\infty}^{\\infty}$) si valuta agli estremi. Poiché $e^{-x^2/2} \\to 0$ sia per $x \\to -\\infty$ che per $x \\to +\\infty$, il termine di bordo è 0.\n        \n    - **Termine Integrale Rimanente** Il termine integrale rimanente è: $$ - \\int_{-\\infty}^{\\infty} (-e^{-x^2/2}) (it e^{itx}) dx $$ Si semplificano i segni e si porta fuori la costante $it$: $$ = it \\int_{-\\infty}^{\\infty} e^{itx} e^{-x^2/2} dx $$ Questo integrale, includendo la costante $\\frac{1}{\\sqrt{2\\pi}}$ omessa nei passaggi intermedi, sarebbe $\\int e^{itx} f_{X_0}(x) \\sqrt{2\\pi} dx$. Il professore corregge l&#039;omissione e dice che l&#039;integrale rimanente è la funzione caratteristica stessa.\n        \n    - **Risultato dell&#039;Integrazione per Parti e Semplificazione** Combinando il fattore $i$ iniziale con il risultato dell&#039;integrazione per parti: $$ \\phi&#039;_{X_0}(t) = i \\left[ 0 - \\left( it \\int_{-\\infty}^{\\infty} e^{itx} e^{-x^2/2} dx \\right) \\right] $$ (Attenzione alla gestione dei segni come descritta in, &quot;meno la derivata del primo&quot;, &quot;meno i tivo&quot;). Seguendo la descrizione del risultato finale in: Il termine integrale dà &quot;- t&quot; moltiplicato per la funzione caratteristica. Con il fattore $i$ iniziale e il $it$ dall&#039;integrazione per parti ($i \\cdot it = i^2 t = -t$), si ottiene $-t$. Il professore riassume che il risultato è &quot;- t volte f(x) con 0 calcolata in t&quot;, dove f(x) con 0 calcolata in t è $\\phi_{X_0}(t)$.\n        \n    - **Derivazione dell&#039;Equazione Differenziale Ordinaria (ODE)** Il calcolo della derivata porta alla seguente equazione differenziale ordinaria (ODE): $$ \\phi&#039;_{X_0}(t) = -t \\phi_{X_0}(t) $$\n        \n    - **Condizione Iniziale** La condizione iniziale per questa ODE è data dal valore della funzione caratteristica in $t=0$: $$ \\phi_{X_0}(0) = E[e^{i \\cdot 0 \\cdot X_0}] = E = 1 $$ La funzione caratteristica calcolata in zero vale sempre 1.\n        \n    - **Soluzione dell&#039;ODE** Questa ODE $\\frac{d\\phi}{dt} = -t \\phi$ è di facile soluzione (a variabili separabili): $$ \\frac{d\\phi}{\\phi} = -t , dt $$ Integrando ambo i lati: $$ \\int \\frac{d\\phi}{\\phi} = \\int -t , dt $$ $$ \\ln|\\phi(t)| = -\\frac{t^2}{2} + C $$ $$ \\phi(t) = A e^{-t^2/2} $$ Utilizzando la condizione iniziale $\\phi_{X_0}(0) = 1$: $$ 1 = A e^{-0^2/2} = A e^0 = A $$ Quindi $A=1$. La soluzione unica di questa ODE è: $$ \\phi_{X_0}(t) = e^{-t^2/2} $$\n        \n    - **Formula Finale per $N(0,1)$** La funzione caratteristica della Gaussiana standard $N(0,1)$ è $e^{-t^2/2}$.\n        \n    - **Nota sulla Non Richiesta della Dimostrazione** Questa dimostrazione non è richiesta all&#039;esame, ma è un esempio di applicazione dell&#039;analisi e delle ODE. È fondamentale, invece, conoscere la definizione e la forma della funzione caratteristica di una Gaussiana e non confonderla con la densità.\n        \n- **Ritorno alla Gaussiana Generale (Derivazione dalla Standard)** Come visto in precedenza, conoscendo $\\phi_{X_0}(t) = e^{-t^2/2}$ e usando la relazione $X = \\mu + \\sigma X_0$ e la proprietà $\\phi_{aX+b}(t) = e^{ibt} \\phi_X(at)$, si ottiene la funzione caratteristica della Gaussiana generale $N(\\mu, \\sigma^2)$: $$ \\phi_X(t) = e^{i \\mu t} \\phi_{X_0}(\\sigma t) = e^{i \\mu t} e^{-(\\sigma t)^2/2} = e^{i \\mu t} e^{-\\frac{\\sigma^2 t^2}{2}} $$\n![[Pasted image 20250424091913.png]]\n\n#### (Proposizione) Somma di Variabili Casuali Normali Indipendenti\n\n- **Enunciato della Proposizione** Si prendono $n$ variabili casuali Gaussiane indipendenti, $X_j \\sim N(\\mu_j, \\sigma_j^2)$, ognuna con la propria media $\\mu_j$ e varianza $\\sigma_j^2$. Allora la somma $S_n = \\sum_{j=1}^n X_j$ è anch&#039;essa una variabile casuale Normale.\n    \n- **Risultati &quot;Banali&quot; (Media e Varianza della Somma)** Una parte di questo enunciato è considerata banale. La media della somma di variabili casuali (anche non indipendenti) è la somma delle medie: $E[\\sum X_j] = \\sum E[X_j] = \\sum \\mu_j$. La varianza della somma di variabili casuali _indipendenti_ è la somma delle varianze: $\\text{Var}(\\sum X_j) = \\sum \\text{Var}(X_j) = \\sum \\sigma_j^2$. Quindi, se si sa già che la somma è una Gaussiana, i suoi parametri (media e varianza) devono necessariamente essere la somma delle medie e la somma delle varianze.\n    \n- **Risultato Non Banale (La Somma Resta Gaussiana)** La parte non banale della proposizione è che quando si sommano Gaussiane indipendenti, queste sono &quot;stabili&quot; nel senso che la loro somma rimane una Gaussiana.\n    \n- **Rarità di Questa Proprietà** Viene ribadito che questa stabilità non è una proprietà comune a molte distribuzioni; accade per la Poisson e per la Gaussiana, ma non per tantissimi altri casi.\n    \n\n#### (Dimostrazione) Dimostrazione della Somma di Normali Indipendenti (Uso Funzioni Caratteristiche)\n\n- **Vantaggio dell&#039;Uso delle Funzioni Caratteristiche (vs Convoluzione)** Questa dimostrazione, a differenza del calcolo con la formula di convoluzione (che sarebbe complicato, anche per sole due variabili), è molto facile usando le funzioni caratteristiche.\n    \n- **Impostazione: Funzione Caratteristica della Somma = Prodotto delle Funzioni Caratteristiche** Per variabili casuali indipendenti, la funzione caratteristica della somma è il prodotto delle funzioni caratteristiche individuali: $$ \\phi_{S_n}(t) = \\phi_{\\sum_{j=1}^n X_j}(t) = \\prod_{j=1}^n \\phi_{X_j}(t) $$\n    \n- **Sostituzione delle Funzioni Caratteristiche Individuali** Si sostituisce la forma della funzione caratteristica per ogni Gaussiana $X_j \\sim N(\\mu_j, \\sigma_j^2)$, che è $\\phi_{X_j}(t) = e^{i \\mu_j t} e^{-\\frac{\\sigma_j^2 t^2}{2}}$: $$ \\phi_{S_n}(t) = \\prod_{j=1}^n \\left(e^{i \\mu_j t} e^{-\\frac{\\sigma_j^2 t^2}{2}}\\right) $$\n    \n- **Sviluppo del Prodotto (Somma degli Esponenti)** Usando la proprietà $\\prod e^{a_j} = e^{\\sum a_j}$: $$ \\phi_{S_n}(t) = \\exp\\left(\\sum_{j=1}^n \\left(i \\mu_j t - \\frac{\\sigma_j^2 t^2}{2}\\right)\\right) $$\n    \n- **Riorganizzazione dell&#039;Esponente** Si riorganizza la somma degli esponenti: $$ \\sum_{j=1}^n i \\mu_j t - \\sum_{j=1}^n \\frac{\\sigma_j^2 t^2}{2} $$ Si raccolgono i termini comuni: $$ i t \\left(\\sum_{j=1}^n \\mu_j\\right) - \\frac{t^2}{2} \\left(\\sum_{j=1}^n \\sigma_j^2\\right) $$\n    \n- **Formula Finale della Funzione Caratteristica della Somma** La funzione caratteristica della somma è quindi: $$ \\phi_{S_n}(t) = \\exp\\left( i t \\left(\\sum_{j=1}^n \\mu_j\\right) - \\frac{t^2}{2} \\left(\\sum_{j=1}^n \\sigma_j^2\\right) \\right) $$ $$ \\phi_{S_n}(t) = e^{i \\left(\\sum_{j=1}^n \\mu_j\\right) t} e^{-\\frac{\\left(\\sum_{j=1}^n \\sigma_j^2\\right) t^2}{2}} $$\n    \n- **Riconoscimento della Forma (Funzione Caratteristica di una Gaussiana)** Guardando questa espressione, si riconosce che ha esattamente la forma della funzione caratteristica di una variabile casuale Gaussiana $e^{i \\mu t} e^{-\\frac{\\sigma^2 t^2}{2}}$.\n    \n- **Parametri della Gaussiana Risultante (Media e Varianza)** Confrontando la forma ottenuta con la forma generale della funzione caratteristica Gaussiana, si deduce che la somma $S_n$ è una Gaussiana con:\n    \n    - Media $\\mu = \\sum_{j=1}^n \\mu_j$\n    - Varianza $\\sigma^2 = \\sum_{j=1}^n \\sigma_j^2$\n- **Nota sull&#039;Additività delle Varianze (non degli Scarti Quadratici Medi)** Viene evidenziato che si sommano le varianze ($\\sigma^2$), non gli scarti quadratici medi ($\\sigma$). Viene menzionato che alcuni software statistici, come R, usano la notazione $\\mu, \\sigma$ invece di $\\mu, \\sigma^2$, quindi bisogna fare attenzione.\n    \n![[Pasted image 20250424092006.png]]\n#### Considerazioni Finali sull&#039;Importanza delle Funzioni Caratteristiche\n\n- **Applicazioni alle Somme** La funzione caratteristica è molto utile nello studio delle somme di variabili casuali indipendenti.\n    \n- **Teorema Centrale del Limite (Cenni)** Storicamente, la funzione caratteristica ha avuto grande importanza nello studio del Teorema Centrale del Limite (TCL), che riguarda anch&#039;esso le somme di variabili casuali.\n    \n\n#### Comunicazioni Amministrative\n\n- **Correzione Compiti e Valutazione** Il professore ha quasi finito di correggere i compiti e non li ha trovati terribili, nonostante una valutazione &quot;estremamente larga&quot;. Soluzioni ed esiti verranno pubblicati.\n    \n- **Questione Visione Scritti** Si pone la questione della visione degli scritti.\n    \n- **Proposta di Modalità** In accordo con un collega (Di Primio), viene suggerita una modalità: fissare un giorno, presentare prima una &quot;zoologia&quot; degli errori canonici (per cui magari non è necessario venire individualmente) e poi fare una coda per coloro che hanno bisogno di chiedere informazioni specifiche.\n    \n- **Proposta di Data** Originariamente si pensava a giovedì prossimo (settimana successiva al 16/17, quindi 23/24), ma si ipotizza che molti non siano presenti.\n    \n- **Valutazione di Streaming vs Presenza (Sondaggio informale)** Viene considerato di fare tutto in streaming se la presenza è minima, poiché anche per i professori è più comodo non doversi spostare apposta (il professore è di Milano e sarebbe presente, Di Primio no). Viene quindi proposto un sondaggio informale tra i presenti.\n    \n- **Esito del Sondaggio** Viene chiesto chi sarebbe presente il 23 o 24. L&#039;esito informale indica che non c&#039;è &quot;zero&quot; presenza, sebbene sembra che pochi abbiano alzato la mano. Si decide comunque di procedere con un sondaggio formale a questo punto.\n\n#### References\n[[Appunti Prob - 18.pdf]]\n\n\n\n\n2025-04-24 12:49\n\n_Status: #flashcard_zero  #riscritto_zero  #revisione_zero \n\n_Tags: [[probabilità]]   [[sbobine]]\n\n## prob-lez19\n\n\n**Distribuzione Gaussiana Multivariata: Estensione e Proprietà**\n\nIn questa lezione si estende il concetto di variabile aleatoria Gaussiana, precedentemente visto per il caso unidimensionale, ai vettori aleatori (caso multivariato, con dimensione $n \\ge 2$). Lo strumento principale utilizzato per questa estensione è la funzione caratteristica, data la sua definizione e le sue proprietà viste in precedenza.\n\n**Richiamo sulla Gaussiana Unidimensionale**\n\nUna variabile aleatoria scalare $X_J$ ha legge Gaussiana con media $\\mu_J$ e varianza $\\sigma_J^2$ (indicata con $X_J \\sim \\mathcal{N}(\\mu_J, \\sigma_J^2)$) se:\n\n- È una variabile aleatoria **assolutamente continua** con densità di probabilità: $$f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_J^2}} e^{-\\frac{(x-\\mu_J)^2}{2\\sigma_J^2}}$$. Questo vale se $\\sigma_J^2 &gt; 0$.\n- Ha funzione caratteristica: $$\\phi_{X_J}(t) = E[e^{itX_J}] = e^{i\\mu_J t - \\frac{1}{2}\\sigma_J^2 t^2}$$.\n\nÈ stato notato che la famiglia delle Gaussiane univariate è una famiglia di scala-posizione, ottenuta da una Gaussiana standard $\\mathcal{N}(0, 1)$ tramite $X_J = \\mu_J + \\sigma_J Z_0$, dove $Z_0 \\sim \\mathcal{N}(0, 1)$. Inoltre, una combinazione lineare di Gaussiane indipendenti è ancora una Gaussiana.\n![[Pasted image 20250424132124.png]]\n\n**Il Caso Degenerato ($\\sigma^2 = 0$)**\n\nSi può adottare la convenzione che una variabile aleatoria $X$ con &quot;legge Gaussiana degenere&quot; con varianza zero ($\\sigma^2=0$) e media $\\mu$ sia semplicemente una **costante** uguale a $\\mu$ con probabilità 1. Questa è una convenzione utile ma &quot;pericolosa&quot;, perché una costante non è assolutamente continua e quindi non ha una densità nel senso usuale. Tuttavia, la sua **funzione caratteristica** è ben definita: $\\phi_X(t) = E[e^{itX}] = E[e^{it\\mu}] = e^{it\\mu}$. La convenzione è giustificata dal fatto che la funzione caratteristica della Gaussiana unidimensionale $\\phi_{X_J}(t) = e^{i\\mu_J t - \\frac{1}{2}\\sigma_J^2 t^2}$, se calcolata per $\\sigma_J^2 = 0$, produce esattamente $e^{i\\mu_J t}$, che è la funzione caratteristica di una costante pari a $\\mu_J$. Quindi, a livello di funzione caratteristica, il caso degenere è incluso naturalmente.\n![[Pasted image 20250424132329.png]]\n**Passaggio 1: Obiettivo - Estendere il Concetto a Vettori Aleatori ($n \\ge 2$)**\n\nL&#039;obiettivo è estendere il concetto di variabile Gaussiana ai vettori aleatori n-dimensionali. Questo richiede l&#039;uso delle funzioni caratteristiche per vettori aleatori.\n\n**Passaggio 2: Un Primo Tentativo - Vettore di Componenti Gaussiane Indipendenti**\n\nSi considera un vettore $\\mathbf{z} = (Z_1, ..., Z_n)^T$, dove $Z_j$ sono variabili aleatorie indipendenti, ognuna distribuita come una Gaussiana con media 0 e varianza $\\sigma_j^2$ ($Z_j \\sim \\mathcal{N}(0, \\sigma_j^2)$). Si ammette che alcune $\\sigma_j^2$ possano essere zero (caso degenere, $Z_j=0$ con probabilità 1). Questo vettore è chiamato un &quot;vettore Gaussiano&quot; in prima battuta. Questa definizione iniziale è limitata perché copre solo vettori le cui componenti sono indipendenti. Non è detto che un tale vettore sia assolutamente continuo, specialmente se alcune $\\sigma_j^2 = 0$.\n\nIn questa formulazione iniziale, è fondamentale notare che si tratta sostanzialmente di una **semplice notazione** e non di una generalizzazione profonda del concetto. Questo approccio descrive un caso molto specifico: un vettore aleatorio le cui **componenti marginali sono tutte Gaussiane e sono indipendenti**. L&#039;obiettivo più ambizioso è invece riuscire a definire vettori Gaussiani in cui le **componenti non siano necessariamente indipendenti**.\n\nPer convenzione, anche in questo contesto multidimensionale e per componenti indipendenti, si ammette la possibilità che alcune delle varianze $\\sigma_j^2$ possano essere **uguali a zero**. Come nel caso unidimensionale degenere, una variabile Gaussiana con varianza zero e media nulla ($Z_j \\sim \\mathcal{N}(0, 0)$) intende semplicemente una variabile aleatoria che è una **costante concentrata in zero** con probabilità 1.\n\nQuesto primo tentativo di definizione può essere espresso formalmente usando la notazione $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, D)$, dove $\\mathbf{0}$ è il vettore nullo (rappresentando le medie nulle) e $D$ è una **matrice diagonale**. Sulla diagonale di questa matrice $D$ si trovano le varianze individuali delle componenti $\\sigma_j^2$, mentre tutti gli elementi fuori dalla diagonale sono zero.\n\nLa possibilità che alcune varianze $\\sigma_j^2$ siano zero ha una conseguenza diretta e importante: **il vettore $\\mathbf{z}$, anche se le sue componenti sono indipendenti, non è necessariamente assolutamente continuo**. Questo accade perché una variabile costante (con varianza zero) non è assolutamente continua e non possiede una densità di probabilità nel senso usuale.\n\nQuesto punto evidenzia una limitazione dell&#039;approccio basato sulla densità di probabilità per definire il vettore Gaussiano generale. Se si desidera la massima generalità, includendo i casi degeneri con varianza zero, **non è conveniente partire dalla definizione tramite densità**, poiché questa non coprirebbe adeguatamente tali scenari. Questa limitazione giustifica l&#039;adozione di un altro strumento matematico per la definizione generale del vettore Gaussiano multivariato: l&#039;uso delle **funzioni caratteristiche**, le quali rimangono ben definite anche quando la varianza è zero. La funzione caratteristica per questo vettore di componenti indipendenti con media zero si calcola facilmente come il prodotto delle funzioni caratteristiche individuali e ha la forma $e^{- \\frac{1}{2} \\sum_{j=1}^n \\sigma_j^2 t_j^2}$. Questa si può riscrivere usando la matrice diagonale $D$ come $e^{- \\frac{1}{2} \\mathbf{t}^T D \\mathbf{t}}$.\n![[Pasted image 20250424132543.png]]\n\n**Passaggio 3: Funzione Caratteristica del Vettore di Componenti Indipendenti**\n\nLa funzione caratteristica del vettore $\\mathbf{z}$ calcolata in un vettore $\\mathbf{t} = (t_1, ..., t_n)^T \\in \\mathbb{R}^n$ è data da: $\\phi_{\\mathbf{z}}(\\mathbf{t}) = E[e^{i\\mathbf{t}^T\\mathbf{z}}]$ Poiché $\\mathbf{z}$ ha componenti indipendenti, l&#039;aspettazione del prodotto si fattorizza nel prodotto delle aspettazioni: $E[e^{i\\mathbf{t}^T\\mathbf{z}}] = E[e^{i \\sum_{j=1}^n t_j Z_j}] = E[\\prod_{j=1}^n e^{i t_j Z_j}] = \\prod_{j=1}^n E[e^{i t_j Z_j}]$ Ognuno dei fattori nell&#039;ultimo prodotto è la funzione caratteristica della variabile unidimensionale $Z_j$, valutata in $t_j$. Dato che $Z_j \\sim \\mathcal{N}(0, \\sigma_j^2)$, la sua funzione caratteristica è $e^{-\\frac{1}{2}\\sigma_j^2 t_j^2}$. Quindi, la funzione caratteristica di $\\mathbf{z}$ è: $\\phi_{\\mathbf{z}}(\\mathbf{t}) = \\prod_{j=1}^n e^{-\\frac{1}{2}\\sigma_j^2 t_j^2} = e^{\\sum_{j=1}^n -\\frac{1}{2}\\sigma_j^2 t_j^2} = e^{-\\frac{1}{2} \\sum_{j=1}^n \\sigma_j^2 t_j^2}$ Questa somma nell&#039;esponente può essere scritta in forma matriciale usando la matrice diagonale $\\mathbf{D}$ con $\\sigma_j^2$ sulla diagonale principale e zero altrove. $\\sum_{j=1}^n \\sigma_j^2 t_j^2 = \\mathbf{t}^T \\mathbf{D} \\mathbf{t}$ Quindi, la funzione caratteristica è: $\\phi_{\\mathbf{z}}(\\mathbf{t}) = e^{-\\frac{1}{2} \\mathbf{t}^T \\mathbf{D} \\mathbf{t}}$ Questa forma vale anche quando alcune $\\sigma_j^2 = 0$.\n![[Pasted image 20250424134126.png]]\n**Passaggio 4: Matrici Simmetriche e Semidefinite Positive**\n\nUna matrice $n \\times n$ simmetrica e semidefinita positiva, indicata con $\\boldsymbol{\\Sigma}$, possiede la proprietà fondamentale di essere **diagonalizzabile** tramite una matrice ortonormale $\\mathbf{O}$. Questo significa che esiste una matrice ortonormale $\\mathbf{O}$ tale che: $\\mathbf{O}^T \\boldsymbol{\\Sigma} \\mathbf{O} = \\mathbf{D}$ dove $\\mathbf{D}$ è una matrice diagonale i cui elementi sulla diagonale sono gli **autovalori** di $\\boldsymbol{\\Sigma}$. Poiché $\\boldsymbol{\\Sigma}$ è semidefinita positiva, i suoi autovalori sono maggiori o uguali a zero ($\\lambda_i \\ge 0$). Si possono indicare questi autovalori come $\\lambda_i$ (o $\\sigma_i^2$ nel contesto delle varianze). Dalla relazione di diagonalizzazione si ottiene anche $\\boldsymbol{\\Sigma} = \\mathbf{O} \\mathbf{D} \\mathbf{O}^T$, poiché $\\mathbf{O}^T \\mathbf{O} = \\mathbf{O} \\mathbf{O}^T = \\mathbf{I}$ (matrice identità) per matrici ortonormali.\n![[Pasted image 20250424134348.png]]\n**Passaggio 5: Costruzione di un Vettore Gaussiano Generale**\n\nSi definisce un vettore aleatorio $\\mathbf{x}$ tramite una **trasformazione affine** di un vettore di Gaussiane indipendenti (come in Passaggio 2). Si prende un vettore $\\boldsymbol{\\mu} \\in \\mathbb{R}^n$, una matrice simmetrica e semidefinita positiva $\\boldsymbol{\\Sigma}$, si diagonalizza $\\boldsymbol{\\Sigma}$ per trovare $\\mathbf{O}$ e $\\mathbf{D}$ (con gli autovalori $\\lambda_j$ sulla diagonale di $\\mathbf{D}$). Si costruisce il vettore $\\mathbf{z}$ con componenti $Z_j$ indipendenti, $Z_j \\sim \\mathcal{N}(0, \\lambda_j)$. Si definisce $\\mathbf{x}$ come: $\\mathbf{x} = \\boldsymbol{\\mu} + \\mathbf{O} \\mathbf{z}$ Questo è un vettore aleatorio poiché $\\mathbf{z}$ è aleatorio e $\\boldsymbol{\\mu}$ e $\\mathbf{O}$ sono costanti.\n\n**Passaggio 6: Proposizione - Funzione Caratteristica del Vettore Costruito**\n\n**Proposizione:** La funzione caratteristica del vettore $\\mathbf{x} = \\boldsymbol{\\mu} + \\mathbf{O} \\mathbf{z}$ (costruito come sopra, dove $\\mathbf{z}$ ha componenti $Z_j \\sim \\mathcal{N}(0, \\lambda_j)$ indipendenti e $\\lambda_j$ sono gli autovalori di $\\boldsymbol{\\Sigma}$) è data da: $\\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}$\n![[Pasted image 20250424134406.png]]\n**Dimostrazione (della Proposizione)** Si usa la proprietà della funzione caratteristica per trasformazioni affini: per un vettore aleatorio $\\mathbf{y}$ e costanti matriciali $\\mathbf{A}$ e vettoriali $\\mathbf{b}$, la funzione caratteristica di $\\mathbf{A}\\mathbf{y} + \\mathbf{b}$ è $\\phi_{\\mathbf{A}\\mathbf{y} + \\mathbf{b}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\mathbf{b}} \\phi_{\\mathbf{y}}(\\mathbf{A}^T \\mathbf{t})$. Nel nostro caso, $\\mathbf{x} = \\mathbf{O}\\mathbf{z} + \\boldsymbol{\\mu}$. Quindi $\\mathbf{A} = \\mathbf{O}$ e $\\mathbf{b} = \\boldsymbol{\\mu}$. $\\phi_{\\mathbf{x}}(\\mathbf{t}) = \\phi_{\\mathbf{O}\\mathbf{z} + \\boldsymbol{\\mu}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu}} \\phi_{\\mathbf{z}}(\\mathbf{O}^T \\mathbf{t})$ Si sostituisce la forma della funzione caratteristica di $\\mathbf{z}$ (da Passaggio 3), ricordando che le varianze sulla diagonale di $\\mathbf{D}$ sono $\\lambda_j$: $\\phi_{\\mathbf{z}}(\\mathbf{t}) = e^{-\\frac{1}{2} \\mathbf{t}^T \\mathbf{D} \\mathbf{t}}$ Sostituendo l&#039;argomento $\\mathbf{O}^T \\mathbf{t}$ al posto di $\\mathbf{t}$: $\\phi_{\\mathbf{z}}(\\mathbf{O}^T \\mathbf{t}) = e^{-\\frac{1}{2} (\\mathbf{O}^T \\mathbf{t})^T \\mathbf{D} (\\mathbf{O}^T \\mathbf{t})}$ Si semplifica l&#039;argomento dell&#039;esponenziale: $(\\mathbf{O}^T \\mathbf{t})^T \\mathbf{D} (\\mathbf{O}^T \\mathbf{t}) = \\mathbf{t}^T (\\mathbf{O}^T)^T \\mathbf{D} \\mathbf{O}^T \\mathbf{t} = \\mathbf{t}^T \\mathbf{O} \\mathbf{D} \\mathbf{O}^T \\mathbf{t}$ Richiamando la diagonalizzazione $\\boldsymbol{\\Sigma} = \\mathbf{O} \\mathbf{D} \\mathbf{O}^T$, l&#039;espressione diventa: $\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}$ Quindi, la funzione caratteristica di $\\mathbf{x}$ è: $\\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu}} e^{-\\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}} = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}$ Questo completa la dimostrazione.\n![[Pasted image 20250424144045.png]]\n**Significato della Proposizione** Questo risultato dimostra che la funzione nella forma $e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}$, per un vettore $\\boldsymbol{\\mu}$ e una matrice $\\boldsymbol{\\Sigma}$ simmetrica e semidefinita positiva, **è una funzione caratteristica valida**. Non tutte le funzioni lo sono, anche se soddisfano proprietà minimali.\n\n**Passaggio 7: Definizione Formale di Vettore Gaussiano Multivariato**\n\n**Definizione:** Un vettore aleatorio n-dimensionale $\\mathbf{x}$ ha legge Gaussiana con parametri $\\boldsymbol{\\mu} \\in \\mathbb{R}^n$ (vettore) e $\\boldsymbol{\\Sigma}$ ($n \\times n$ matrice simmetrica e semidefinita positiva) se la sua funzione caratteristica è: $\\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}$\n![[Pasted image 20250424144130.png]]\n**Ben Definizione della Legge Gaussiana Multivariata** Questa definizione è ben posta per due motivi:\n\n1. **Teorema di Unicità:** La legge di una variabile (o vettore) aleatoria è **completamente caratterizzata** dalla sua funzione caratteristica. Se due vettori aleatori hanno la stessa funzione caratteristica, hanno la stessa legge.\n2. **Esistenza:** La proposizione precedente (Passaggio 6) dimostra che **esiste almeno un vettore aleatorio** (quello costruito come $\\boldsymbol{\\mu} + \\mathbf{O}\\mathbf{z}$) che ha esattamente questa funzione caratteristica.\n\n**Interpretazione della Costruzione** La definizione e la costruzione mostrano che un vettore aleatorio Gaussiano è ottenuto a partire da variabili aleatorie scalari indipendenti Gaussiane (con varianze pari agli autovalori di $\\boldsymbol{\\Sigma}$) tramite una opportuna **trasformazione lineare affine** (una &quot;frullata opportunamente&quot;). Questa trasformazione consiste in una **rotazione/scalatura** data dalla matrice $\\mathbf{O}$ (e dalla scelta delle varianze di $\\mathbf{z}$) e una **traslazione** data dal vettore $\\boldsymbol{\\mu}$. Come nel caso unidimensionale degenere, un vettore Gaussiano multivariato non è necessariamente assolutamente continuo; questo accade se la matrice $\\boldsymbol{\\Sigma}$ è singolare (ovvero, se alcuni autovalori sono zero).\n\n**Passaggio 8: Proprietà Fondamentale - Chiusura Rispetto a Trasformazioni Affini**\n\n**Proposizione:** Se $\\mathbf{x}$ è un vettore Gaussiano $n$-dimensionale con parametri $\\boldsymbol{\\mu}$ e $\\boldsymbol{\\Sigma}$, e $\\mathbf{A}$ è una matrice $m \\times n$ e $\\mathbf{b}$ è un vettore $m$-dimensionale, allora il vettore aleatorio $m$-dimensionale $\\mathbf{y} = \\mathbf{A}\\mathbf{x} + \\mathbf{b}$ è ancora un vettore Gaussiano. I suoi parametri sono:\n\n- Vettore medio: $\\boldsymbol{\\mu}&#039; = \\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b}$\n- Matrice di covarianza: $\\boldsymbol{\\Sigma}&#039; = \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^T$\n![[Pasted image 20250424144616.png]]\nQuesta proprietà è molto generale, vale anche per matrici $\\mathbf{A}$ rettangolari (non necessariamente $n \\times n$) e include casi in cui il vettore risultante $\\mathbf{y}$ è degenere (ad esempio, se $m &lt; n$ o se $\\mathbf{A}$ non ha rango pieno).\n\n**Dimostrazione (della Proprietà di Chiusura)** Si calcola la funzione caratteristica di $\\mathbf{y}$: $\\phi_{\\mathbf{y}}(\\mathbf{t}) = E[e^{i \\mathbf{t}^T \\mathbf{y}}] = E[e^{i \\mathbf{t}^T (\\mathbf{A}\\mathbf{x} + \\mathbf{b})}] = E[e^{i \\mathbf{t}^T \\mathbf{b}} e^{i \\mathbf{t}^T \\mathbf{A} \\mathbf{x}}]$ $= e^{i \\mathbf{t}^T \\mathbf{b}} E[e^{i (\\mathbf{A}^T \\mathbf{t})^T \\mathbf{x}}]$ L&#039;aspettazione è la funzione caratteristica di $\\mathbf{x}$ valutata nel vettore $\\mathbf{A}^T \\mathbf{t}$. $\\phi_{\\mathbf{x}}(\\boldsymbol{\\tau}) = e^{i \\boldsymbol{\\tau}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\boldsymbol{\\tau}^T \\boldsymbol{\\Sigma} \\boldsymbol{\\tau}}$ con $\\boldsymbol{\\tau} = \\mathbf{A}^T \\mathbf{t}$. Quindi: $\\phi_{\\mathbf{y}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\mathbf{b}} e^{i (\\mathbf{A}^T \\mathbf{t})^T \\boldsymbol{\\mu} - \\frac{1}{2} (\\mathbf{A}^T \\mathbf{t})^T \\boldsymbol{\\Sigma} (\\mathbf{A}^T \\mathbf{t})}$ Si semplificano gli esponenti: $(\\mathbf{A}^T \\mathbf{t})^T \\boldsymbol{\\mu} = \\mathbf{t}^T (\\mathbf{A}^T)^T \\boldsymbol{\\mu} = \\mathbf{t}^T \\mathbf{A} \\boldsymbol{\\mu}$ $(\\mathbf{A}^T \\mathbf{t})^T \\boldsymbol{\\Sigma} (\\mathbf{A}^T \\mathbf{t}) = \\mathbf{t}^T (\\mathbf{A}^T)^T \\boldsymbol{\\Sigma} \\mathbf{A}^T \\mathbf{t} = \\mathbf{t}^T \\mathbf{A} \\boldsymbol{\\Sigma} \\mathbf{A}^T \\mathbf{t}$ Sostituendo nell&#039;espressione per $\\phi_{\\mathbf{y}}(\\mathbf{t})$: $\\phi_{\\mathbf{y}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\mathbf{b}} e^{i \\mathbf{t}^T \\mathbf{A} \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T (\\mathbf{A} \\boldsymbol{\\Sigma} \\mathbf{A}^T) \\mathbf{t}}$ Raccogliendo i termini nell&#039;esponente: $\\phi_{\\mathbf{y}}(\\mathbf{t}) = e^{i (\\mathbf{t}^T \\mathbf{b} + \\mathbf{t}^T \\mathbf{A} \\boldsymbol{\\mu}) - \\frac{1}{2} \\mathbf{t}^T (\\mathbf{A} \\boldsymbol{\\Sigma} \\mathbf{A}^T) \\mathbf{t}}$ $\\phi_{\\mathbf{y}}(\\mathbf{t}) = e^{i \\mathbf{t}^T (\\mathbf{A} \\boldsymbol{\\mu} + \\mathbf{b}) - \\frac{1}{2} \\mathbf{t}^T (\\mathbf{A} \\boldsymbol{\\Sigma} \\mathbf{A}^T) \\mathbf{t}}$ Questa funzione caratteristica è esattamente nella forma della definizione di Gaussiana multivariata (Passaggio 7), con nuovi parametri $\\boldsymbol{\\mu}&#039; = \\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b}$ e $\\boldsymbol{\\Sigma}&#039; = \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^T$. Questo dimostra che $\\mathbf{y}$ è Gaussiana.\n![[Pasted image 20250424144711.png]]\n**Passaggio 9: Corollario - Combinazioni Lineari di Componenti**\n\n**Corollario:** Se $\\mathbf{x} = (X_1, ..., X_n)^T$ è un vettore Gaussiano $n$-dimensionale con parametri $\\boldsymbol{\\mu}$ e $\\boldsymbol{\\Sigma}$, allora ogni **combinazione lineare** delle sue componenti, $Y = \\sum_{j=1}^n a_j X_j + b$, dove $a_j$ e $b$ sono costanti reali, è una variabile aleatoria \n\n**Gaussiana unidimensionale**.\n\nQuesto corollario è un caso particolare della proprietà di chiusura per trasformazioni affini (Passaggio 8). Si considera il caso in cui la matrice $\\mathbf{A}$ è un vettore riga $1 \\times n$, $\\mathbf{a} = (a_1, ..., a_n)$, e $\\mathbf{b}$ è uno scalare $b$ (visto come un vettore $1 \\times 1$). Allora $\\mathbf{y} = \\mathbf{A}\\mathbf{x} + \\mathbf{b}$ diventa lo scalare $Y = \\mathbf{a}\\mathbf{x} + b = \\sum a_j X_j + b$. I parametri della Gaussiana unidimensionale risultante sono:\n\n- Media: $\\mu_Y = \\mathbf{a}\\boldsymbol{\\mu} + b = \\sum_{j=1}^n a_j \\mu_j + b$. Questo si ottiene da $\\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b}$ con $\\mathbf{A}=\\mathbf{a}$ (vettore riga) e $\\mathbf{b}=b$ (scalare). Il prodotto $\\mathbf{a}\\boldsymbol{\\mu}$ è un prodotto scalare.\n- Varianza: $\\sigma_Y^2 = \\mathbf{a}\\boldsymbol{\\Sigma}\\mathbf{a}^T$. Questo si ottiene da $\\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^T$ con $\\mathbf{A}=\\mathbf{a}$. Il prodotto $\\mathbf{a}\\boldsymbol{\\Sigma}\\mathbf{a}^T$ è una forma quadratica. Se $\\boldsymbol{\\Sigma}$ ha elementi $\\Sigma_{ij}$, questa forma quadratica è $\\sum_{i=1}^n \\sum_{j=1}^n a_i \\Sigma_{ij} a_j$.\n\nQuesto generalizza il risultato sulla somma di Gaussiane indipendenti al caso di componenti non necessariamente indipendenti. Un caso particolare di combinazione lineare è l&#039;estrazione di una singola componente $X_k$ (scegliendo $a_k=1$, $a_j=0$ per $j \\neq k$, $b=0$). Questo implica che le **distribuzioni marginali** di un vettore Gaussiano sono **univariate Gaussiane**.\n![[Pasted image 20250424150303.png]]\n**Interpretazione dei Parametri $\\boldsymbol{\\mu}$ e $\\boldsymbol{\\Sigma}$**\n\nLa proprietà di chiusura rispetto a trasformazioni affini e il corollario sulle combinazioni lineari permettono di interpretare i parametri $\\boldsymbol{\\mu}$ e $\\boldsymbol{\\Sigma}$ nella definizione di Gaussiana multivariata:\n\n- $\\boldsymbol{\\mu}$ è il **vettore delle medie** delle componenti del vettore Gaussiano. La sua $j$-esima componente $\\mu_j$ è la media di $X_j$, $E[X_j] = \\mu_j$. (Si può dimostrare questo prendendo $a_j=1$, $a_i=0$ per $i\\neq j$, $b=0$ nel corollario, e la media è $\\mu_j$).\n- $\\boldsymbol{\\Sigma}$ è la **matrice di covarianza** del vettore Gaussiano. L&#039;elemento $\\Sigma_{ij}$ in posizione $(i, j)$ è la covarianza tra $X_i$ e $X_j$, $\\text{Cov}(X_i, X_j) = E[(X_i - E[X_i])(X_j - E[X_j])] = E[(X_i - \\mu_i)(X_j - \\mu_j)]$. Gli elementi sulla diagonale sono le varianze $\\Sigma_{ii} = \\text{Var}(X_i) = \\sigma_i^2$. (La formula per la varianza della combinazione lineare $\\mathbf{a}\\boldsymbol{\\Sigma}\\mathbf{a}^T$ coincide con la formula generale per la varianza di una combinazione lineare di variabili aleatorie in termini della loro matrice di covarianza).\n\n**Passaggio 10: Importanza della Distribuzione Gaussiana Multivariata**\n\nIl &quot;mondo Gaussiano&quot; è &quot;particolarmente bello&quot; e importante in molte applicazioni di statistica e modellistica. Le ragioni includono:\n\n- La sua **ubiquità**, legata in parte al Teorema Centrale del Limite (che non è stato ancora affrontato in dettaglio in questo estratto, ma viene menzionato).\n- La sua &quot;niceness&quot; e semplicità di molte proprietà, prima fra tutte la **chiusura rispetto a trasformazioni affini**. Se si parte da un vettore Gaussiano e lo si trasforma linearmente (scalatura, rotazione) e lo si trasla, il risultato è ancora Gaussiano. Anche proiezioni o combinazioni lineari delle componenti risultano Gaussiane.\n\nQueste proprietà rendono i modelli basati sulla distribuzione Gaussiana multivariata gestibili e teoricamente trattabili in molti contesti.\n\n___\n\n### Ripasso e Parametri della Gaussiana Multivariata\n\nQuando si definisce una **Gaussiana multivariata**, è necessario specificare **due parametri**. Il primo parametro è **$\\mu$**, che è un **generico vettore**. Il secondo parametro è **$\\Sigma$**, che è una **generica matrice**. Attenzione, questa matrice $\\Sigma$ non è una matrice qualunque, ma deve essere una **matrice simmetrica e semidefinita positiva**. Il professore sottolinea che un tipico errore è dimenticare di controllare queste proprietà per la matrice $\\Sigma$.\n\n### Momenti di una Gaussiana Multivariata\n\nSe un vettore aleatorio $X$ è una **Gaussiana di parametri $\\mu$ e $\\Sigma$**, il **momento** della componente $j$-esima non è altro che $\\mu_j$. La **matrice di varianze e covarianze di $X$** è proprio $\\Sigma$.\n\nCome si può vedere questo? Partiamo da un lemma precedente (non fornito nella fonte completa, ma citato come base) secondo cui si può scrivere $X$ nella forma: $X = \\mu + O Z$ dove $O$ è una matrice ortonormale (tale per cui $O^{-1} = O^T$) e $D$ è una matrice diagonale con gli autovalori di $\\Sigma$, e vale la relazione $O^T \\Sigma O = D$ (o equivalentemente $\\Sigma = O D O^T$). $Z$ è un vettore Gaussiano &quot;particolare&quot;. Questo vettore $Z$ è costruito in modo tale che le sue componenti $Z_j$ sono Gaussiane unidimensionali. In questo caso particolare, le componenti $Z_j$ hanno media 0 e varianza $\\lambda_j^2$, dove $\\lambda_j$ sono gli autovalori di $\\Sigma$ (quindi gli elementi sulla diagonale di $D$). Pertanto, il vettore delle medie di $Z$, $E[Z]$, è un vettore di zeri.\n![[Pasted image 20250424150439.png]]\n#### Calcolo del Vettore delle Medie $E[X]$\n\nUsando la proprietà di linearità del valore atteso per vettori: $E[X] = E[\\mu + O Z]$ $E[X] = E[\\mu] + E[O Z]$ Poiché $\\mu$ è un vettore costante, $E[\\mu] = \\mu$. $E[O Z] = O E[Z]$ Abbiamo detto che $E[Z]$ è il vettore degli zeri. $O E[Z] = O \\mathbf{0} = \\mathbf{0}$ (moltiplicando un vettore di zeri per una matrice si ottiene il vettore di zeri). Quindi: $E[X] = \\mu + \\mathbf{0} = \\mu$ Questo dimostra che il **vettore delle medie di $X$ è $\\mu$**, e componente per componente $E[X_j] = \\mu_j$.\n\n#### Calcolo della Matrice di Varianze e Covarianze $\\Sigma_X$\n\nUsando le proprietà delle matrici di varianze e covarianze: La matrice di varianze e covarianze è invariante per traslazioni. Quindi $\\Sigma_X = \\Sigma_{X-\\mu}$. $\\Sigma_X = \\Sigma_{O Z}$ Una proprietà della matrice di covarianza di una trasformazione lineare $AY$ è $A \\Sigma_Y A^T$. In questo caso $A=O$ e $Y=Z$. $\\Sigma_{O Z} = O \\Sigma_Z O^T$ La matrice di varianze e covarianze di $Z$, $\\Sigma_Z$, è una matrice diagonale perché le componenti $Z_j$ sono indipendenti (costruzione del lemma). Fuori dalla diagonale, la covarianza è zero perché l&#039;indipendenza implica covarianza nulla. Sulla diagonale ci sono le varianze, che sono $\\lambda_j^2$. Quindi $\\Sigma_Z = D$, dove $D$ è la matrice diagonale degli autovalori. $\\Sigma_X = O D O^T$ Sappiamo dalla costruzione che $\\Sigma = O D O^T$. Quindi: $\\Sigma_X = \\Sigma$ Questo dimostra che la **matrice di varianze e covarianze di $X$ è $\\Sigma$**. La matrice $\\Sigma$ non è una qualunque matrice, ma deve essere simmetrica e semidefinita positiva.\n![[Pasted image 20250424150601.png]]\n### Proposizione 1: Sottovettori di una Gaussiana Multivariata\n\n**Enunciato:** Se $X$ è un vettore $n$-dimensionale Gaussiano di parametri $\\mu$ e $\\Sigma$, allora **qualunque sottovettore di $X$ è Gaussiano**. Le distribuzioni marginali di una Gaussiana sono tutte Gaussiane. Questo è vero a vari gradi (quindi anche prendendo più componenti).\n\n#### Parametri del Sottovettore\n\nSe si prende un sottovettore di indici $I = {i_1, i_2, \\dots, i_k}$: Il **vettore delle medie del sottovettore $X_I$**, $\\mu_I$, è semplicemente il **sottovettore** di $\\mu$ che contiene le componenti $\\mu_j$ con $j \\in I$. La **matrice di varianze e covarianze del sottovettore $X_I$**, $\\Sigma_I$, è la matrice che si ottiene **incrociando le righe e le colonne** della matrice $\\Sigma$ con gli indici contenuti in $I$. Prendete la matrice $\\Sigma$ e selezionate solo le righe e le colonne corrispondenti agli indici $i_1, \\dots, i_k$.\n![[Pasted image 20250424152133.png]]\n#### Dimostrazione della Proposizione 1 (Idea generale usando Funzioni Caratteristiche)\n\nLa dimostrazione di questa proposizione si basa sulla **proprietà di unicità della funzione caratteristica**: se due variabili aleatorie (o vettori aleatori) hanno la stessa funzione caratteristica, allora hanno la stessa legge (distribuzione).\n\nLa funzione caratteristica di un vettore Gaussiano $n$-dimensionale $\\mathbf{x}$ con parametri $\\boldsymbol{\\mu}$ e $\\boldsymbol{\\Sigma}$, calcolata in un vettore $\\mathbf{t} = (t_1, ..., t_n)^T \\in \\mathbb{R}^n$, è data da: $\\phi_{\\mathbf{x}}(\\mathbf{t}) = E[e^{i \\mathbf{t}^T \\mathbf{x}}] = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}$.\n\nConsideriamo prima il caso più semplice e fondamentale: la **dimostrazione che una singola componente $X_k$ (una marginale) è Gaussiana**. La funzione caratteristica di una singola componente $X_k$, $\\phi_{X_k}(u)$, dove $u$ è uno scalare, può essere ottenuta dalla funzione caratteristica congiunta del vettore $\\mathbf{x}$. Per definizione, $\\phi_{X_k}(u) = E[e^{i u X_k}]$. Questo è equivalente a valutare la funzione caratteristica congiunta $\\phi_{\\mathbf{x}}(\\mathbf{t})$ nel vettore $\\mathbf{t}$ che ha la componente $k$-esima uguale a $u$ e tutte le altre componenti uguali a zero. Ossia, poniamo $\\mathbf{t} = (0, ..., 0, u_k=u, 0, ..., 0)^T$ (dove $u$ è nella posizione $k$-esima).\n\nSostituendo questo vettore $\\mathbf{t}$ nella formula della funzione caratteristica congiunta: $\\phi_{X_k}(u) = \\phi_{\\mathbf{x}}(0, ..., u_k=u, ..., 0)$ $= e^{i (0, ..., u, ..., 0)^T \\boldsymbol{\\mu} - \\frac{1}{2} (0, ..., u, ..., 0)^T \\boldsymbol{\\Sigma} (0, ..., u, ..., 0)}$.\n\nAnalizziamo i due termini nell&#039;esponente:\n\n1. $i \\mathbf{t}^T \\boldsymbol{\\mu} = i (0, ..., u, ..., 0) \\begin{pmatrix} \\mu_1 \\\\ \\vdots \\\\ \\mu_k \\\\ \\vdots \\\\ \\mu_n \\end{pmatrix}$. Questo prodotto scalare seleziona solo la componente $k$-esima di $\\boldsymbol{\\mu}$ moltiplicata per $u$. Quindi, $i \\mathbf{t}^T \\boldsymbol{\\mu} = i u \\mu_k$.\n2. $\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} = (0, ..., u, ..., 0) \\begin{pmatrix} \\Sigma_{11} &amp; \\dots &amp; \\Sigma_{1k} &amp; \\dots &amp; \\Sigma_{1n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\Sigma_{k1} &amp; \\dots &amp; \\Sigma_{kk} &amp; \\dots &amp; \\Sigma_{kn} \\\\ \\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\Sigma_{n1} &amp; \\dots &amp; \\Sigma_{nk} &amp; \\dots &amp; \\Sigma_{nn} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ \\vdots \\\\ u \\\\ \\vdots \\\\ 0 \\end{pmatrix}$. Quando si esegue questo prodotto, il vettore riga $(0, ..., u, ..., 0)$ seleziona la riga $k$-esima di $\\boldsymbol{\\Sigma}$ moltiplicata per $u$. Il risultato è $u \\cdot (\\Sigma_{k1}, \\dots, \\Sigma_{kk}, \\dots, \\Sigma_{kn})$. Moltiplicando questo vettore riga per il vettore colonna $(0, ..., u, ..., 0)^T$, si seleziona solo la componente $k$-esima del vettore riga, che è $\\Sigma_{kk}$, moltiplicata per $u$. Quindi, $\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} = u \\cdot (\\Sigma_{k1}, \\dots, \\Sigma_{kk}, \\dots, \\Sigma_{kn}) \\begin{pmatrix} 0 \\\\ \\vdots \\ u \\\\ \\vdots \\\\ 0 \\end{pmatrix} = u \\cdot (u \\Sigma_{kk}) = u^2 \\Sigma_{kk}$.\n\nSostituendo questi termini nell&#039;esponente, otteniamo la funzione caratteristica di $X_k$: $\\phi_{X_k}(u) = e^{i u \\mu_k - \\frac{1}{2} u^2 \\Sigma_{kk}}$.\n\nQuesta è esattamente la funzione caratteristica di una **variabile aleatoria Gaussiana unidimensionale** con media $\\mu_k$ e varianza $\\Sigma_{kk}$. Poiché la funzione caratteristica di $X_k$ corrisponde a quella di una Gaussiana unidimensionale, per il teorema di unicità, $X_k$ è una variabile aleatoria Gaussiana unidimensionale.\n\nLa **dimostrazione per un sottovettore $X_I$ di dimensione $k &gt; 1$** segue la stessa logica ed è stata descritta come &quot;un filino più laboriosa&quot; ma concettualmente identica. Per ottenere la funzione caratteristica del sottovettore $X_I = (X_{i_1}, \\dots, X_{i_k})^T$ calcolata in un vettore $\\mathbf{u} = (u_1, \\dots, u_k)^T$, si valuta la funzione caratteristica congiunta del vettore completo $\\mathbf{x}$ in un vettore $\\mathbf{t} \\in \\mathbb{R}^n$ dove le componenti $t_j$ sono nulle se $j \\notin I$, e sono uguali alle corrispondenti componenti di $\\mathbf{u}$ se $j \\in I$. Ossia, se $j = i_m$ per qualche $m \\in {1, \\dots, k}$, allora $t_j = u_m$, altrimenti $t_j = 0$.\n\nLa funzione caratteristica di $X_I$ è $\\phi_{X_I}(\\mathbf{u}) = E[e^{i \\mathbf{u}^T X_I}]$. Questo è uguale a $E[e^{i \\sum_{m=1}^k u_m X_{i_m}}]$, che è la funzione caratteristica di $\\mathbf{x}$ valutata nel vettore $\\mathbf{t}$ descritto sopra. $\\phi_{X_I}(\\mathbf{u}) = \\phi_{\\mathbf{x}}(\\mathbf{t})$.\n\nSostituendo questo vettore $\\mathbf{t}$ (con zeri nelle posizioni fuori da $I$ e componenti di $\\mathbf{u}$ nelle posizioni indicate da $I$) nella formula della funzione caratteristica congiunta $\\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}$, si ottiene:\n\n1. $i \\mathbf{t}^T \\boldsymbol{\\mu}$: Questo prodotto selezionerà solo le componenti di $\\boldsymbol{\\mu}$ corrispondenti agli indici in $I$, moltiplicate per le rispettive componenti di $\\mathbf{u}$. Il risultato è $i \\mathbf{u}^T \\boldsymbol{\\mu}_I$, dove $\\boldsymbol{\\mu}_I$ è il sottovettore di $\\boldsymbol{\\mu}$ con le componenti indicate da $I$.\n2. $\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}$: Questo prodotto seleziona la **forma quadratica** definita dalla **sottomatrice** di $\\boldsymbol{\\Sigma}$ corrispondente agli indici in $I$, applicata al vettore $\\mathbf{u}$. Il risultato è $\\mathbf{u}^T \\boldsymbol{\\Sigma}_I \\mathbf{u}$, dove $\\boldsymbol{\\Sigma}_I$ è la sottomatrice di $\\boldsymbol{\\Sigma}$ ottenuta incrociando righe e colonne con indici in $I$.\n\nQuindi, la funzione caratteristica del sottovettore $X_I$ è: $\\phi_{X_I}(\\mathbf{u}) = e^{i \\mathbf{u}^T \\boldsymbol{\\mu}_I - \\frac{1}{2} \\mathbf{u}^T \\boldsymbol{\\Sigma}_I \\mathbf{u}}$.\n\nQuesta è esattamente la forma della funzione caratteristica di un **vettore Gaussiano $k$-dimensionale** con vettore delle medie $\\boldsymbol{\\mu}_I$ e matrice di varianze e covarianze $\\boldsymbol{\\Sigma}_I$. Per il teorema di unicità, il sottovettore $X_I$ segue una distribuzione Gaussiana con questi parametri.\n\nLe fonti indicano che la dimostrazione dettagliata per il caso generale del sottovettore, sebbene concettualmente simile a quella della singola componente, non è stata formalmente completata nelle lezioni per intero con tutte le notazioni, ma l&#039;idea di &quot;selezionare la sottomatrice&quot; è stata esplicitata. Questo risultato conferma che **tutte le marginali di un vettore Gaussiano (singole componenti o sottovettori) sono esse stesse Gaussiane**.\n![[Pasted image 20250424154542.png]]\n\n\n**Caso generale (più componenti):** Se si considerano $k$ componenti ($k&gt;1$), si fa la stessa cosa ma il vettore $t$ avrà $k$ elementi non nulli. La forma quadratica $t^T \\Sigma t$ seleziona la **sottomatrice** $\\Sigma_I$ corrispondente agli indici $I$ delle componenti scelte, e il prodotto scalare $t^T \\mu$ seleziona il **sottovettore** $\\mu_I$. La conclusione è la stessa: si ottiene la funzione caratteristica di una Gaussiana di dimensione $k$ con parametri $\\mu_I$ e $\\Sigma_I$.\n\nQuesto spiega la Proposizione 1: le marginali (sottovettori) sono Gaussiane.\n\n### Proposizione 2: Indipendenza delle Componenti e Matrice di Covarianza\n\n**Enunciato (Punto 2 come chiamato nella fonte, o Punto 3 come chiamato nella fonte):** Il vettore Gaussiano $X$ ha **componenti indipendenti se e solo se** la sua matrice di varianze e covarianze **$\\Sigma$ è una matrice diagonale**. **Corollario (Punto 2 bis nella fonte, parte del Punto 3 nella fonte):** Due componenti $X_{i_1}$ e $X_{i_2}$ di un vettore Gaussiano $X$ sono **indipendenti se e solo se** l&#039;elemento $\\sigma_{i_1, i_2}$ (cioè la covarianza tra $X_{i_1}$ e $X_{i_2}$) è **uguale a 0**. Il professore sottolinea che questa è un&#039;affermazione **forte**. In generale, la covarianza nulla non implica indipendenza, ma **nel mondo Gaussiano sì**. Se si sa che due componenti Gaussiane hanno covarianza nulla, si può concludere che sono indipendenti.\n![[Pasted image 20250424152124.png]]\n#### Esempio con Matrice 3x3\n\nConsideriamo un vettore Gaussiano $X = (X_1, X_2, X_3)$ con vettore delle medie $\\mu = (0, 0, 0)$ e una matrice di covarianza $\\Sigma$ data da: $\\Sigma = \\begin{pmatrix} \\Sigma_{11} &amp; \\Sigma_{12} &amp; \\Sigma_{13} \\\\ \\Sigma_{21} &amp; \\Sigma_{22} &amp; \\Sigma_{23} \\\\ \\Sigma_{31} &amp; \\Sigma_{32} &amp; \\Sigma_{33} \\end{pmatrix}$ Sappiamo che $\\Sigma$ è simmetrica, quindi $\\Sigma_{ij} = \\Sigma_{ji}$. La covarianza tra $X_i$ e $X_j$ è $\\Sigma_{ij}$.\n\nSupponiamo di avere la seguente matrice $\\Sigma$ (esempio del professore): $\\Sigma = \\begin{pmatrix} \\Sigma_{11} &amp; 0 &amp; \\Sigma_{13} \\\\ 0 &amp; \\Sigma_{22} &amp; \\Sigma_{23} \\\\ \\Sigma_{31} &amp; \\Sigma_{32} &amp; \\Sigma_{33} \\end{pmatrix}$ Guardando gli elementi fuori dalla diagonale (che rappresentano le covarianze tra diverse componenti):\n\n- $\\Sigma_{12} = 0$ (e $\\Sigma_{21}=0$ per simmetria). Questo significa che la covarianza tra $X_1$ e $X_2$ è zero. Poiché $X_1$ e $X_2$ sono componenti di un vettore Gaussiano (quindi marginalmente Gaussiane per la Proposizione 1), la covarianza nulla implica indipendenza. Quindi, **$X_1$ e $X_2$ sono indipendenti**.\n- $\\Sigma_{13} \\ne 0$ (nell&#039;esempio grafico del professore, anche se non è specificato un valore numerico, è rappresentato come non zero). Questo significa che la covarianza tra $X_1$ e $X_3$ non è zero. Quindi, **$X_1$ e $X_3$ non sono indipendenti**.\n- $\\Sigma_{23} \\ne 0$. Questo significa che la covarianza tra $X_2$ e $X_3$ non è zero. Quindi, **$X_2$ e $X_3$ non sono indipendenti**.\n![[Pasted image 20250424152339.png]]\nQuesto esempio mostra come si può determinare l&#039;indipendenza tra le componenti di un vettore Gaussiano semplicemente guardando se gli elementi fuori dalla diagonale della matrice di covarianza $\\Sigma$ sono zero. Questa proprietà è molto utile negli esercizi, specialmente nei quesiti vero/falso.\n\n#### Dimostrazione della Proposizione 2 (Idea generale usando Funzioni Caratteristiche)\n\nLa dimostrazione si basa principalmente sull&#039;uso della **funzione caratteristica** del vettore aleatorio $\\mathbf{x}$ e sul **teorema di unicità** della funzione caratteristica, che afferma che due variabili (o vettori) aleatorie con la stessa funzione caratteristica hanno la stessa distribuzione. Inoltre, si utilizza il criterio che lega l&#039;indipendenza delle componenti di un vettore aleatorio alla fattorizzazione della sua funzione caratteristica congiunta nel prodotto delle funzioni caratteristiche marginali.\n\nProcediamo con la dimostrazione in due parti, date dall&#039;enunciato &quot;se e solo se&quot;:\n\n**Parte 1: Se le componenti $X_1, \\dots, X_n$ sono indipendenti, allora la matrice $\\boldsymbol{\\Sigma}$ è diagonale.**\n\nQuesto è il lato &quot;facile&quot; dell&#039;implicazione, valido per qualsiasi tipo di variabili aleatorie, non solo Gaussiane. La matrice di varianze e covarianze $\\boldsymbol{\\Sigma}$ ha come elementi $\\Sigma_{ij} = \\text{Cov}(X_i, X_j)$. Per definizione di indipendenza, se due variabili aleatorie $X_i$ e $X_j$ (con $i \\neq j$) sono indipendenti, la loro covarianza è nulla: $\\text{Cov}(X_i, X_j) = E[(X_i - E[X_i])(X_j - E[X_j])] = 0$. Dato che stiamo considerando le componenti $X_1, \\dots, X_n$ come indipendenti, questo significa che $\\text{Cov}(X_i, X_j) = \\Sigma_{ij} = 0$ per ogni $i \\neq j$. Gli elementi sulla diagonale della matrice $\\boldsymbol{\\Sigma}$ sono le varianze delle singole componenti: $\\Sigma_{ii} = \\text{Var}(X_i)$. Questi elementi non sono necessariamente zero (a meno di casi degeneri in cui la componente è una costante, ma anche in quel caso la varianza è la parte diagonale corretta). Pertanto, se tutte le covarianze fuori dalla diagonale sono zero, la matrice $\\boldsymbol{\\Sigma}$ è, per definizione, una matrice diagonale. Questo dimostra la prima parte.\n![[Pasted image 20250424155548.png]]\n**Parte 2: Se la matrice $\\boldsymbol{\\Sigma}$ è diagonale, allora le componenti $X_1, \\dots, X_n$ sono indipendenti.**\n\nQuesta è la parte più significativa per i vettori Gaussiani, e la dimostrazione si basa sull&#039;uso della funzione caratteristica. La funzione caratteristica di un vettore Gaussiano $\\mathbf{x}$ con parametri $\\boldsymbol{\\mu}$ e $\\boldsymbol{\\Sigma}$, calcolata in un vettore $\\mathbf{t} = (t_1, \\dots, t_n)^T \\in \\mathbb{R}^n$, è data da: $\\phi_{\\mathbf{x}}(\\mathbf{t}) = E[e^{i \\mathbf{t}^T \\mathbf{x}}] = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}$.\n\nAssumiamo che $\\boldsymbol{\\Sigma}$ sia una matrice diagonale. Questo significa che gli elementi fuori dalla diagonale sono zero ($\\Sigma_{ij} = 0$ per $i \\neq j$), e gli elementi sulla diagonale sono le varianze $\\Sigma_{ii}$. Il primo termine nell&#039;esponente è il prodotto scalare $i \\mathbf{t}^T \\boldsymbol{\\mu}$. Questo è semplicemente $i \\sum_{j=1}^n t_j \\mu_j$. Il secondo termine nell&#039;esponente, $\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}$, è una forma quadratica. Se $\\boldsymbol{\\Sigma}$ è diagonale, con elementi $\\Sigma_{jj}$ sulla diagonale, questo prodotto si semplifica notevolmente. In forma matriciale, $\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} = \\sum_{i=1}^n \\sum_{j=1}^n t_i \\Sigma_{ij} t_j$. Poiché $\\Sigma_{ij} = 0$ per $i \\neq j$, rimangono solo i termini per cui $i = j$: $\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} = \\sum_{j=1}^n t_j \\Sigma_{jj} t_j = \\sum_{j=1}^n \\Sigma_{jj} t_j^2$. (Nota: le fonti usano anche la notazione $\\sigma_j^2$ o $\\sigma_{jj}^2$ per gli elementi diagonali di $\\boldsymbol{\\Sigma}$ in contesti specifici, ma il significato è lo stesso: la varianza della j-esima componente).\n\nSostituendo questi termini nell&#039;esponente della funzione caratteristica congiunta, otteniamo: $\\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\sum_{j=1}^n t_j \\mu_j - \\frac{1}{2} \\sum_{j=1}^n \\Sigma_{jj} t_j^2}$.\n\nOra, possiamo riscrivere l&#039;esponente come una somma e quindi l&#039;intera espressione come un prodotto di esponenziali: $\\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{\\sum_{j=1}^n (i t_j \\mu_j - \\frac{1}{2} \\Sigma_{jj} t_j^2)} = \\prod_{j=1}^n e^{i t_j \\mu_j - \\frac{1}{2} \\Sigma_{jj} t_j^2}$.\n\nOgni fattore nel prodotto, $e^{i t_j \\mu_j - \\frac{1}{2} \\Sigma_{jj} t_j^2}$, è esattamente la **funzione caratteristica di una variabile aleatoria Gaussiana unidimensionale** con media $\\mu_j$ e varianza $\\Sigma_{jj}$. Queste sono le funzioni caratteristiche marginali $\\phi_{X_j}(t_j)$ delle singole componenti $X_j$. Quindi, abbiamo dimostrato che se $\\boldsymbol{\\Sigma}$ è diagonale, la funzione caratteristica congiunta del vettore $\\mathbf{x}$ è uguale al prodotto delle funzioni caratteristiche marginali delle sue componenti: $\\phi_{\\mathbf{x}}(\\mathbf{t}) = \\prod_{j=1}^n \\phi_{X_j}(t_j)$ per ogni $\\mathbf{t} \\in \\mathbb{R}^n$.\n\nPer il criterio che lega l&#039;indipendenza alla funzione caratteristica, questa fattorizzazione implica che le componenti $X_1, \\dots, X_n$ sono indipendenti.\n\nQuesto completa la dimostrazione della Proposizione 2, confermando che per un vettore Gaussiano, l&#039;indipendenza delle componenti è _equivalente_ alla matrice di varianze e covarianze essere diagonale. Questa è una delle &quot;cose belle&quot; e semplificanti del &quot;mondo Gaussiano&quot;.\n\n**Corollario correlato (Punto 3 o 2 bis):** Se si prendono due singole componenti $X_i$ e $X_j$ da un vettore Gaussiano (che formano un sottovettore Gaussiano di dimensione 2 per la Proposizione 1, non dimostrata formalmente ma discussa nelle fonti), esse sono indipendenti se e solo se la loro covarianza $\\Sigma_{ij}$ è zero. Questo discende direttamente dalla Proposizione 2 applicata al sottovettore $(X_i, X_j)^T$, la cui matrice di covarianza è una sottomatrice $2 \\times 2$ di $\\boldsymbol{\\Sigma}$ contenente $\\Sigma_{ii}, \\Sigma_{ij}, \\Sigma_{ji}, \\Sigma_{jj}$. Se questa sottomatrice è diagonale (cioè $\\Sigma_{ij} = \\Sigma_{ji} = 0$), le due componenti sono indipendenti.\n___\n\n\n**Vettori Gaussiani Multivariati: Densità, Degenerazione e Rappresentazioni**\n\n**1. Vettori Gaussiani Assolutamente Continui**\n\nUn punto fondamentale è comprendere la condizione che rende un vettore gaussiano &quot;assolutamente continuo&quot;.\n\n- **Definizione/Proprietà Fondamentale:**\n    \n    - Un vettore aleatorio gaussiano $X$ (a valori in $\\mathbb{R}^n$) è assolutamente continuo **se e solo se** la sua matrice di covarianza $\\Sigma$ è strettamente definita positiva.\n    - Questo significa che $\\Sigma$ **non può** avere autovalori nulli.\n    - Se una matrice è strettamente definita positiva, allora è automaticamente invertibile.\n- **Densità di Probabilità:**\n    \n    - Nel caso in cui $X$ sia assolutamente continuo (cioè $\\Sigma$ è strettamente definita positiva), la sua densità di probabilità $f_X(x)$ è data da una formula specifica: $f_X(x) = c \\cdot e^{-\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu)}$ dove:\n        - $x$ è il vettore di variabili in $\\mathbb{R}^n$.\n        - $\\mu$ è il vettore delle medie di $X$.\n        - $\\Sigma^{-1}$ è la matrice inversa della matrice di covarianza $\\Sigma$.\n        - $c$ è una costante di normalizzazione (spesso specificata come $1 / (\\sqrt{(2\\pi)^n \\det(\\Sigma)})$ ) (Questo dettaglio sulla costante $c$ _non_ è esplicitamente dato nelle fonti, ma è la formula completa; le fonti si concentrano sulla forma esponenziale).\n    - Il termine nell&#039;esponente, $(x - \\mu)^T \\Sigma^{-1} (x - \\mu)$, è una **forma quadratica**.\n    - **Spiegazione:** L&#039;inclusione di $\\Sigma^{-1}$ nella formula della densità è cruciale e distingue il caso multivariato da quello unidimensionale in un modo specifico.\n      ![[Pasted image 20250424160002.png]]\n- **Confronto con il Caso Unidimensionale ($n=1$):**\n    \n    - Consideriamo il caso semplice in cui $n=1$, cioè $X$ è una singola variabile gaussiana $X \\sim N(\\mu, \\sigma^2)$.\n    - La matrice di covarianza $\\Sigma$ si riduce allo scalare $\\sigma^2$.\n    - La densità della gaussiana unidimensionale è proporzionale a $e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$.\n    - Possiamo riscrivere l&#039;esponente come $-\\frac{1}{2} (x-\\mu) (\\sigma^2)^{-1} (x-\\mu)$. Qui $(\\sigma^2)^{-1}$ è semplicemente $1/\\sigma^2$.\n    - **Analogia:** Questa riscrittura rende chiara l&#039;analogia con il caso multivariato: lo scalare $\\sigma^2$ corrisponde alla matrice $\\Sigma$, e il suo inverso $(\\sigma^2)^{-1}$ corrisponde all&#039;inverso matriciale $\\Sigma^{-1}$.\n    - **Punto di Attenzione:** È fondamentale **non confondere** $\\Sigma$ con $\\Sigma^{-1}$. Nelle formule standard:\n        - La **funzione caratteristica** di un vettore gaussiano $X$ è $e^{i t^T \\mu - \\frac{1}{2} t^T \\Sigma t}$ (la parte di media nulla $e^{-t^T \\Sigma t / 2}$ è menzionata). Questa formula usa $\\Sigma$.\n        - La **densità di probabilità** (per il caso assolutamente continuo) usa $\\Sigma^{-1}$.\n    - **Condizione di Invertibilità:** La matrice $\\Sigma^{-1}$ è definita **solo se** $\\Sigma$ è invertibile. La matrice di covarianza $\\Sigma$ è invertibile **se e solo se** è strettamente definita positiva.\n      ![[Pasted image 20250424160050.png]]\n- **Dimostrazione (Cenni):**\n    \n    - La dimostrazione della relazione tra assoluta continuità, matrice $\\Sigma$ strettamente definita positiva e la forma specifica della densità non viene svolta in dettaglio.\n    - Viene menzionato che si basa su un cambio di variabile.\n    - L&#039;enunciato è diviso idealmente in due parti: l&#039;assoluta continuità e la forma della densità.\n\n**2. Caso Degenerato: $\\Sigma$ non strettamente definita positiva**\n\nCosa succede se la matrice di covarianza $\\Sigma$ non è strettamente definita positiva?\n\n- **Proprietà:**\n    \n    - Se $\\Sigma$ è solo semidefinita positiva (ossia ha **almeno un autovalore nullo**), il vettore gaussiano $X$ **non è assolutamente continuo**.\n    - Questo perché $\\Sigma^{-1}$ non è definita in questo caso.\n- **Concentrazione su un Sottospazio:**\n    \n    - In questo caso degenere, il vettore $X$ è concentrato (con probabilità 1) su un **iperpiano** (un sottospazio lineare, possibilmente traslato dalla media $\\mu$).\n    - La **dimensione** di questo sottospazio è strettamente minore della dimensione $n$ dello spazio ambiente $\\mathbb{R}^n$.\n    - La dimensione di questo sottospazio è esattamente uguale al **rango di $\\Sigma$**.\n- **Esempio Unidimensionale ($n=1$):**\n    \n    - L&#039;unico caso degenere in dimensione 1 è quando la varianza $\\sigma^2$ è uguale a 0.\n    - In questo caso, la variabile aleatoria collassa su un punto (la sua media $\\mu$).\n    - La dimensione del sottospazio è 0, che è strettamente minore di $n=1$. Questo corrisponde al rango di $\\Sigma=0$, che è 0.\n- **Esempio Multidimensionale:**\n    \n    - In più dimensioni, se $\\Sigma$ non è definita positiva, la distribuzione gaussiana &quot;collassa&quot; su un sottospazio.\n    - Questo sottospazio è lineare (traslato da $\\mu$).\n    - La sua dimensione è data dal rango di $\\Sigma$. Ad esempio, in $\\mathbb{R}^4$, una gaussiana degenere può essere concentrata su un sottospazio di dimensione 3, 2, 1 o 0, a seconda del rango di $\\Sigma$.\n- **Importanza:** Questo concetto, pur essendo a volte considerato solo per &quot;cultura&quot; e potenzialmente non strettamente &quot;in programma&quot;, è importante per capire il comportamento dei vettori gaussiani quando la matrice di covarianza non è invertibile.\n    \n\n**3. Rappresentazioni e Trasformazioni Lineari dei Vettori Gaussiani**\n\n\n**Il Caso Degenerato: $\\Sigma$ non Strettamente Definita Positiva**\n\nQuesto è il caso in cui $\\Sigma$ è simmetrica e semidefinita positiva, ma **non** strettamente definita positiva. Ciò significa che $\\Sigma$ ha almeno un autovalore uguale a zero.\n\n**Conseguenza Principale:** Se $\\Sigma$ non è strettamente definita positiva, il vettore gaussiano $X$ **non è assolutamente continuo**. Di conseguenza, **non ammette una densità di probabilità** nel senso usuale. La formula della densità con $\\Sigma^{-1}$ non è applicabile perché $\\Sigma$ non è invertibile.\n\n**Dove si Concentra la Probabilità?**\n\n**Proposizione (non dimostrata nell&#039;audio, forse non in programma):** Se $X$ è un vettore gaussiano di parametri $\\mu$ e $\\Sigma$ e $\\Sigma$ non è strettamente definita positiva (ha autovalori nulli), allora $X$ è concentrato con probabilità 1 su un **iperpiano** (o sottospazio lineare traslato dalla media $\\mu$) di dimensione strettamente minore di $n$. La dimensione di questo iperpiano è uguale al rango della matrice $\\Sigma$.\n\n**Commento e Esempio Concettuale:** Questa affermazione spiega perché la gaussiana &quot;collassa&quot; in un caso degenere.\n\n- **Esempio 1D:** Nel caso unidimensionale ($n=1$), l&#039;unico caso degenere è $\\Sigma = \\sigma^2 = 0$. La matrice $\\Sigma$ è la matrice $1 \\times 1$ con elemento 0. Il suo rango è 0. La proposizione dice che la gaussiana è concentrata su un iperpiano di dimensione 0. Un iperpiano di dimensione 0 in $\\mathbb{R}^1$ è un punto. Infatti, in questo caso, la variabile aleatoria $X$ è la costante $\\mu$, che è concentrata sul punto $\\mu$. La dimensione 0 è $n - (\\text{numero di autovalori nulli}) = 1 - 1 = 0$ o anche uguale al rango di $\\Sigma$ (che è 0).\n    \n- **Esempio Multidimensionale (Concettuale):** Pensiamo alla costruzione $X = \\mu + O Z$ dove $Z$ ha componenti indipendenti $Z_j \\sim N(0, \\lambda_j^2)$. Se $\\Sigma$ ha $k &gt; 0$ autovalori nulli, allora $k$ dei $\\lambda_j^2$ sono zero. Questo significa che $k$ delle componenti $Z_j$ sono variabili aleatorie degenerate, concentrate su 0. Il vettore $Z$ vive in $\\mathbb{R}^n$, ma le sue $k$ componenti con varianza zero sono fisse a 0. Questo &quot;vincola&quot; $Z$ a un sottospazio di $\\mathbb{R}^n$ di dimensione $n-k$. Quando applichiamo la trasformazione lineare $OZ$ (una rotazione/riflessione) e la traslazione $\\mu$, il vettore risultante $X$ rimane confinato in un sottospazio affine (iperpiano) traslato, la cui dimensione è $n-k$, che è anche il rango di $\\Sigma$.\n    \n\n**Corollario Concettuale (Legato al Caso Degenerato):** Come osservato da uno studente, se abbiamo un vettore gaussiano $X \\sim N(\\mu, \\Sigma)$, possiamo studiarlo in un sistema di riferimento diverso. Considerando la trasformazione $Y = O^T (X - \\mu)$, dove $O$ diagonalizza $\\Sigma$. Sappiamo che $X = \\mu + O Z$, quindi $X - \\mu = O Z$. Allora $Y = O^T (O Z) = (O^T O) Z = I Z = Z$. Questo significa che il vettore $Y$ ha la stessa legge del vettore $Z$, le cui componenti sono indipendenti $Z_j \\sim N(0, \\lambda_j^2)$. Se $\\Sigma$ è degenere, alcuni $\\lambda_j^2$ sono nulli. Quindi, alcune componenti di $Y$ (e quindi di $Z$) sono degenerate (costanti uguali a 0). Questa trasformazione lineare (sottrarre la media e &quot;ruotare&quot; con $O^T$) permette di &quot;vedere&quot; la struttura intrinseca della gaussiana: un insieme di variabili indipendenti (alcune non degenerate, altre costanti). Il fatto che alcune siano costanti è la manifestazione della degenerazione e della concentrazione su un sottospazio di dimensione inferiore.\n\n**Non Unicità della Rappresentazione $X = \\mu + A Z_0$**\n\nUn aspetto correlato alla struttura di $\\Sigma$ (anche nel caso non degenere) è che, mentre la legge gaussiana è unicamente determinata da $\\mu$ e $\\Sigma$ (tramite la CF), la _costruzione_ tramite trasformazione di variabili gaussiane indipendenti non è unica. Possiamo ottenere un vettore gaussiano $X \\sim N(\\mu, \\Sigma)$ anche partendo da un vettore $Z_0$ di variabili standard normali indipendenti $Z_0 \\sim N(0, I)$ (dove $I$ è l&#039;identità, $\\text{Cov}(Z_0) = I$) e applicando una trasformazione affine $X = \\mu + A Z_0$.\n\nLa matrice di covarianza di $X$ in questo caso è $\\text{Cov}(X) = A \\text{Cov}(Z_0) A^T = A I A^T = A A^T$. Per ottenere $X \\sim N(\\mu, \\Sigma)$, dobbiamo avere $A A^T = \\Sigma$. Il punto chiave è che, per una data $\\Sigma$, l&#039;equazione matriciale $A A^T = \\Sigma$ può avere **molteplici soluzioni** per la matrice $A$. Ad esempio, la decomposizione di Cholesky o la &quot;radice quadrata&quot; della matrice $\\Sigma$ (se $\\Sigma$ è definita positiva) sono _alcune_ possibili soluzioni per $A$, ma non sono le uniche, specialmente se $A$ non è richiesta essere simmetrica o definita positiva. Questo significa che si può generare lo stesso vettore gaussiano $\\Sigma$ in modi diversi, usando matrici $A$ differenti, anche se si parte sempre da variabili standard normali indipendenti. Questa è un&#039;altra sottigliezza del mondo gaussiano che deriva dalle proprietà della matrice $\\Sigma$.\n![[Pasted image 20250424161840.png]]\n![[Pasted image 20250424162302.png]]\nIn sintesi, la degenerazione di un vettore gaussiano multivariato (quando $\\Sigma$ non è strettamente definita positiva) implica che esso non è assolutamente continuo, non ha densità, e concentra tutta la sua probabilità su un sottospazio di dimensione inferiore a $n$, determinata dal rango di $\\Sigma$. Questo comportamento è intrinsecamente legato alla presenza di autovalori nulli nella matrice di covarianza $\\Sigma$.\n\n\n#### References"},"6--full-note/prob-ese05":{"slug":"6--full-note/prob-ese05","filePath":"6- full note/prob-ese05.md","title":"prob-ese05","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-18 10:16\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nprob-ese05\nVariabili Aleatorie\nIntroduzione alle Variabili Aleatorie\nL’esercitazione di oggi è dedicata a un concetto fondamentale: le variabili aleatorie. Queste sono oggetti che possono essere considerati l’analogo delle funzioni in analisi. In probabilità, lavoreremo con variabili aleatorie, che sono anch’esse funzioni con proprietà specifiche.\nDefinizione di Variabile Aleatoria\nIn generale, lavoreremo assegnato uno spazio misurabile (\\Omega, \\mathcal{F}) e un altro spazio misurabile (E, \\mathcal{M}), dove \\Omega è l’insieme degli esiti possibili, \\mathcal{F} è una \\sigma-algebra su \\Omega, E è lo spazio di arrivo, e \\mathcal{M} è una \\sigma-algebra su E. Una variabile aleatoria X è una funzione:\nX: \\Omega \\rightarrow E\ntale che per ogni A \\in \\mathcal{M} (un insieme misurabile nello spazio di arrivo), la controimmagine di A sotto X, denotata come X^{-1}(A), sia un elemento della \\sigma-algebra di partenza \\mathcal{F}:\nX^{-1}(A) = \\set{\\omega \\in \\Omega : X(\\omega) \\in A} \\in \\mathcal{F} \\quad \\forall A \\in \\mathcal{M}\nQuesta proprietà è nota come misurabilità ed è cruciale per la definizione di variabile aleatoria.\nLegge di Probabilità Indotta da una Variabile Aleatoria\nSe aggiungiamo una probabilità P allo spazio (\\Omega, \\mathcal{F}), rendendolo uno spazio di probabilità (\\Omega, \\mathcal{F}, P), allora una variabile aleatoria X: \\Omega \\rightarrow E ha il potere di trasportare la probabilità P sullo spazio di arrivo E.\nLa legge (o legge immagine) di X, spesso denotata come L_X (o P_X), è una probabilità definita sullo spazio misurabile (E, \\mathcal{M}). Per un qualsiasi insieme A \\in \\mathcal{M}, la legge di X è data da:\nL_X(A) = P(X \\in A) = P({\\omega \\in \\Omega : X(\\omega) \\in A}) = P(X^{-1}(A))\nLa misurabilità di X è fondamentale perché garantisce che l’insieme X^{-1}(A) appartenga a \\mathcal{F}, e quindi la sua probabilità P(X^{-1}(A)) sia ben definita. Senza la misurabilità, la legge di X non sarebbe ben definita.\nCaso Discreto\nNel caso discreto, l’insieme di arrivo E è finito o numerabile. Una variabile aleatoria discreta assume un numero finito o numerabile di valori. Per ogni specifico valore che la variabile può assumere, si definisce una probabilità.\nFunzione di Ripartizione\nSi consideri una funzione reale di variabile reale F: \\mathbb{R} \\rightarrow, chiamata funzione di ripartizione (o funzione di distribuzione cumulativa, CDF). È definita come:\nF(x) = P(X \\le x)\ndove X è una variabile aleatoria reale. L’esercizio propone una specifica funzione F(x):\nF(x) = \\begin{cases} 0 &amp; \\text{se } x &lt; 0 \\\\ \\frac{1}{2} &amp; \\text{se } 0 \\le x &lt; 1 \\\\ \\frac{2}{3} &amp; \\text{se } 1 \\le x &lt; 2 \\\\ \\frac{11}{12} &amp; \\text{se } 2 \\le x &lt; 3 \\\\ 1 &amp; \\text{se } x \\ge 3 \\end{cases}\n\nProprietà della Funzione di Ripartizione\nUna funzione F è una funzione di ripartizione se soddisfa le seguenti proprietà:\n\nMonotona non decrescente: Se x_1 &lt; x_2, allora F(x_1) \\le F(x_2). Questa proprietà è legata al fatto che stiamo misurando insiemi della forma (-\\infty, x] e se x aumenta, l’insieme si ingrandisce (o rimane uguale).\nContinua da destra: \\lim_{h \\rightarrow 0^+} F(x + h) = F(x) per ogni x \\in \\mathbb{R}. Graficamente, la funzione può avere dei salti, ma nel punto del salto il valore della funzione è quello superiore (limite da destra). Essendo monotona, ha limiti a sinistra in ogni punto. Le discontinuità sono di tipo salto (saldità del primo tipo).\nLimiti agli infiniti:\n\n\\lim_{x \\rightarrow -\\infty} F(x) = 0\n\\lim_{x \\rightarrow +\\infty} F(x) = 1\n\n\n\nL’insieme di queste tre proprietà implica che F è una funzione di ripartizione di una certa probabilità L su (\\mathbb{R}, \\mathcal{B}(\\mathbb{R})), dove \\mathcal{B}(\\mathbb{R}) sono i boreliani della retta. In particolare, F(x) = L((-\\infty, x]).\nProbabilità Discreta e Funzione di Densità Discreta\nDimostrare che L è una probabilità discreta significa mostrare che è concentrata su un insieme finito o numerabile di punti. Una funzione di ripartizione come quella data, costante a tratti e discontinua in un numero finito di punti con discontinuità di tipo salto, suggerisce una probabilità discreta.\nL è concentrata sui punti di salto di F. L’ampiezza dei salti corrisponde alla probabilità di ciascun punto. In questo caso, i punti di salto sono x = 0, 1, 2, 3.\nLe ampiezze dei salti sono:\n\nA x = 0: F(0) - \\lim_{x \\rightarrow 0^-} F(x) = \\frac{1}{2} - 0 = \\frac{1}{2}\nA x = 1: F(1) - \\lim_{x \\rightarrow 1^-} F(x) = \\frac{2}{3} - \\frac{1}{2} = \\frac{4 - 3}{6} = \\frac{1}{6}\nA x = 2: F(2) - \\lim_{x \\rightarrow 2^-} F(x) = \\frac{11}{12} - \\frac{2}{3} = \\frac{11 - 8}{12} = \\frac{3}{12} = \\frac{1}{4}\nA x = 3: F(3) - \\lim_{x \\rightarrow 3^-} F(x) = 1 - \\frac{11}{12} = \\frac{1}{12}\n\nLa funzione di densità discreta p(x) è definita come la probabilità di ciascun punto in cui la probabilità è concentrata. In questo caso:\np(x) = \\begin{cases} \\frac{1}{2} &amp; \\text{se } x = 0 \\\\ \\frac{1}{6} &amp; \\text{se } x = 1 \\\\ \\frac{1}{4} &amp; \\text{se } x = 2 \\\\ \\frac{1}{12} &amp; \\text{se } x = 3 \\\\ 0 &amp; \\text{altrimenti} \\end{cases}\nLa probabilità L di un qualsiasi boreliano A \\subseteq \\mathbb{R} può essere scritta come:\nL(A) = \\frac{1}{2} \\mathbb{1}_{{0 \\in A}} + \\frac{1}{6} \\mathbb{1}_{{1 \\in A}} + \\frac{1}{4} \\mathbb{1}_{{2 \\in A}} + \\frac{1}{12} \\mathbb{1}_{{3 \\in A}}\ndove \\mathbb{1}_{{x \\in A}} è la funzione indicatrice, che vale 1 se x \\in A e 0 altrimenti. Questa formula indica che la probabilità di un insieme A è la somma delle probabilità dei punti 0, 1, 2, e 3 che appartengono ad A.\nCalcolo della Probabilità di Insiemi\nUtilizzando sia la funzione di ripartizione F(x) che la funzione di densità discreta p(x), possiamo calcolare la probabilità di diversi insiemi.\nEsempio 1: L((1/2, +\\infty))\nUtilizzando la proprietà del complementare:\nL((1/2, +\\infty)) = 1 - L((-\\infty, 1/2])\nDalla definizione di funzione di ripartizione:\nL((-\\infty, 1/2]) = F(1/2) = \\frac{1}{2}\nQuindi:\nL((1/2, +\\infty)) = 1 - \\frac{1}{2} = \\frac{1}{2}\nUtilizzando la funzione di densità discreta, gli unici punti in (1/2, +\\infty) con probabilità non nulla sono 1, 2, e 3:\nL((1/2, +\\infty)) = p(1) + p(2) + p(3) = \\frac{1}{6} + \\frac{1}{4} + \\frac{1}{12} = \\frac{2 + 3 + 1}{12} = \\frac{6}{12} = \\frac{1}{2}\nEsempio 2: L([2, 4))\nL([2, 4)) = L((-\\infty, 4)) - L((-\\infty, 2))\nPoiché la funzione di ripartizione è continua da destra:\nL((-\\infty, 4)) = F(4) = 1 L((-\\infty, 2)) = F(2) = \\frac{11}{12}\nQuindi:\nL([2, 4)) = 1 - \\frac{11}{12} = \\frac{1}{12}\nUtilizzando la funzione di densità discreta, l’unico punto in [2, 4) con probabilità non nulla è 2:\nL([2, 4)) = p(2) = \\frac{1}{4}\nErrore nella trascrizione: Il professore dice “Eh f2 11/12. Attenzione a prendere il valore corretto perché queste funzioni sono continue da destra, quindi nel valore eh di nel punto di salto dovete sempre prendere il valore corretto. Eh bene, andiamo avanti. 1 2 aperto. Questo è importante. Qual è la legge valutata sull’insieme 1 2 aperto?“.\nEsempio 3: L((1, 2))\nL((1, 2)) = L((-\\infty, 2)) - L((-\\infty, 1])\nL((-\\infty, 2)) = F(2) = \\frac{11}{12} L((-\\infty, 1]) = F(1) = \\frac{2}{3} = \\frac{8}{12}\nL((1, 2)) = \\frac{11}{12} - \\frac{8}{12} - P(X=1) = \\frac{3}{12} - \\frac{1}{6} = \\frac{1}{4} - \\frac{1}{6} = \\frac{3 - 2}{12} = \\frac{1}{12}\nUtilizzando la funzione di densità discreta, non ci sono punti in (1, 2) con probabilità non nulla:\nL((1, 2)) = 0\nChiarimento del professore: “Questo qua si fa a occhio, non ho bisogno di far conti. Quant’è questa probabilità? è 0 perché ho appena detto che tutto quello che non è 0 1 2 o 3 non influisce sulla mia probabilità, ma verifichiamo che è effettivamente così.”\nL((1, 2)) = L((-\\infty, 2)) - L((-\\infty, 1]) = F(2) - F(1) = \\frac{11}{12} - \\frac{2}{3} = \\frac{11 - 8}{12} = \\frac{3}{12} = \\frac{1}{4}\nUlteriore chiarimento del professore: “Perché? Perché questo non è altro che la legge di - infinito 2 a cui è stato tolto. sia il singoletto 2 che tutto il pezzo da meno infinito a 1. Qualche parentesi. Ok? Ma siccome sto operando sempre, sto togliendo ad un insieme due sottoinsiemi ancora una volta questo lo potete scrivere come la probabilità di questo oggetto che non è altro che F(2) - F(1) - P(X=2). F(2) = \\frac{11}{12}, F(1) = \\frac{2}{3}. La probabilità del singoletto 2 ce l’avete dalla densità se volete. Eh, la probabilità del singoletto 2 è l’ampiezza del salto. Eh, ce l’avete anche dalla funzione di ripartizione, ma da qua è più semplice, è 1/4. Quindi questi sono 8/12, questi sono tre. Il risultato è zero, ma ripeto, non c’era nessun bisogno di questo conto, ma almeno ci esercitiamo a farlo.”\nL((1, 2)) = F(2^-) - F(1) = \\frac{2}{3} - \\frac{2}{3} = 0\nEsempio 4: L((-\\infty, 3))\nL((-\\infty, 3)) = \\lim_{x \\rightarrow 3^-} F(x) = \\frac{11}{12}\nL((-\\infty, 3)) = L((-\\infty, 3]) - P(X=3) = F(3) - p(3) = 1 - \\frac{1}{12} = \\frac{11}{12}\nGenerazione di una Variabile Aleatoria con Legge L\nSi vuole generare una variabile aleatoria X che abbia L come legge, definita su uno spazio di probabilità sia continuo che discreto.\nCaso Continuo\nSi può scegliere lo spazio di probabilità (\\Omega, \\mathcal{F}, P) = (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}), L), dove L è la probabilità definita dalla funzione di ripartizione F. Si definisce la variabile aleatoria X: \\Omega \\rightarrow \\mathbb{R} come la mappa identità:\nX(\\omega) = \\omega\nIn questo caso, la legge di X, L_X, per un qualsiasi boreliano A \\in \\mathcal{B}(\\mathbb{R}) è:\nL_X(A) = P(X \\in A) = P({\\omega \\in \\mathbb{R} : X(\\omega) \\in A}) = P({\\omega \\in \\mathbb{R} : \\omega \\in A}) = L(A)\nQuindi, la variabile aleatoria identità sullo spazio (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}), L) ha esattamente L come sua legge.\nCaso Discreto\nSi può scegliere lo spazio di probabilità \\Omega = {0, 1, 2, 3} con la \\sigma-algebra delle parti \\mathcal{P}(\\Omega) e una probabilità P definita sui singoli punti come:\n\nP({0}) = \\frac{1}{2}\nP({1}) = \\frac{1}{6}\nP({2}) = \\frac{1}{4}\nP({3}) = \\frac{1}{12}\n\nSi definisce la variabile aleatoria X: \\Omega \\rightarrow \\mathbb{R} (o X: \\Omega \\rightarrow {0, 1, 2, 3}) come X(\\omega) = \\omega. La legge di X per un qualsiasi sottoinsieme A \\subseteq {0, 1, 2, 3} è:\nL_X(A) = P(X \\in A) = P({\\omega \\in \\Omega : X(\\omega) \\in A}) = P(A) = \\sum_{i \\in A} P({i})\nQuesta legge coincide con la probabilità discreta L definita precedentemente.\nValore Atteso\nIl valore atteso (o speranza matematica) di una variabile aleatoria discreta X che assume valori x_k con probabilità p(x_k) è definito come:\nE[X] = \\sum_{k} x_k P(X = x_k) = \\sum_{k} x_k p(x_k)\nNel nostro caso, la variabile aleatoria X (nel caso discreto costruito) assume i valori 0, 1, 2, 3 con le probabilità \\frac{1}{2}, \\frac{1}{6}, \\frac{1}{4}, \\frac{1}{12} rispettivamente. Quindi:\nE[X] = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{4} + 3 \\cdot \\frac{1}{12} = 0 + \\frac{1}{6} + \\frac{2}{4} + \\frac{3}{12} = \\frac{1}{6} + \\frac{1}{2} + \\frac{1}{4} = \\frac{2 + 6 + 3}{12} = \\frac{11}{12}\nVarianza\nLa varianza di una variabile aleatoria X, denotata come Var(X), è definita come il valore atteso del quadrato della differenza tra X e il suo valore atteso:\nVar(X) = E[(X - E[X])^2]\nLa varianza può anche essere calcolata utilizzando la formula:\nVar(X) = E[X^2] - (E[X])^2\nPer calcolare E[X^2], consideriamo la variabile aleatoria X^2 che assume i valori 0^2=0, 1^2=1, 2^2=4, 3^2=9 con le stesse probabilità di X:\nE[X^2] = 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{6} + 2^2 \\cdot \\frac{1}{4} + 3^2 \\cdot \\frac{1}{12} = 0 + \\frac{1}{6} + \\frac{4}{4} + \\frac{9}{12} = \\frac{1}{6} + 1 + \\frac{3}{4} = \\frac{2 + 12 + 9}{12} = \\frac{23}{12}\nOra possiamo calcolare la varianza:\nVar(X) = E[X^2] - (E[X])^2 = \\frac{23}{12} - \\left(\\frac{11}{12}\\right)^2 = \\frac{23}{12} - \\frac{121}{144} = \\frac{23 \\cdot 12 - 121}{144} = \\frac{276 - 121}{144} = \\frac{155}{144}\nTrasformazione di Variabili Aleatorie\nConsideriamo una funzione f: \\mathbb{R} \\rightarrow S iniettiva e boreliana. Definiamo una nuova variabile aleatoria Y = f(X). A causa dell’iniettività di f, esiste una corrispondenza biunivoca tra i valori di X e i valori di Y. La probabilità che Y assuma un valore f(i) è uguale alla probabilità che X assuma il valore i:\nP(Y = f(i)) = P(f(X) = f(i)) = P(X = i)\nSe f non è iniettiva, la distribuzione di Y può aggregare le probabilità di diversi esiti di X che vengono mappati allo stesso valore da f.\nSe f non è boreliana, Y = f(X) in generale non è una variabile aleatoria, e quindi non ha senso parlare della sua legge. Una funzione boreliana è una funzione misurabile rispetto alle \\sigma-algebre di Borel. Se una funzione è continua, allora è boreliana.\nEsempio: Y = X^2\nConsiderando Y = X^2, i possibili valori di Y sono 0^2=0, 1^2=1, 2^2=4, 3^2=9. Le probabilità di questi valori sono le stesse dei corrispondenti valori di X perché la funzione f(x) = x^2 è iniettiva sull’insieme dei valori assunti da X (che sono non negativi in questo caso):\n\nP(Y = 0) = P(X = 0) = \\frac{1}{2}\nP(Y = 1) = P(X = 1) = \\frac{1}{6}\nP(Y = 4) = P(X = 2) = \\frac{1}{4}\nP(Y = 9) = P(X = 3) = \\frac{1}{12}\n\nCaso di f Boreliana ma Non Iniettiva\nSe f è boreliana ma non iniettiva, la distribuzione di Y si ottiene sommando le probabilità di tutti i valori di X che vengono mappati allo stesso valore di Y.\nEsempio: Se f(x) = c (una costante), allora Y = c con probabilità 1. La distribuzione di Y è concentrata sul singolo valore c.\nEsempio con f(x) = 4 costante: Y = 4 certamente (con probabilità 1). La probabilità che Y = 4 è la probabilità che X assuma qualsiasi dei suoi valori (perché f li mappa tutti a 4), quindi P(Y = 4) = P(X=0) + P(X=1) + P(X=2) + P(X=3) = 1.\nCaso di f Non Boreliana\nSe f non è boreliana, allora Y = f(X) in generale non è una variabile aleatoria, e quindi non ha senso parlare della sua legge di probabilità.\nValore Atteso di f(X)\nPer una variabile aleatoria discreta X e una funzione boreliana f, il valore atteso di Y = f(X) può essere calcolato direttamente dalla distribuzione di X:\nE[f(X)] = \\sum_i f(x_i) P(X = x_i)\nQuesto evita la necessità di calcolare esplicitamente la distribuzione di Y.\nAnalisi della Variabile Aleatoria X_n: Numero di Biglie Rosse Estratte da un’Urna\nDefinizione del Problema\nConsideriamo un’urna contenente n biglie, di cui r sono rosse e b sono bianche, tale che r + b = n. Si decide di estrarre n piccolo palline dall’urna, con o senza reimmissione. Definiamo uno spazio di probabilità (\\Omega, \\mathcal{F}, P). Ci interessano gli eventi E_m, dove E_m è l’evento in cui l’ennesima biglia estratta è rossa, con m \\in {1, 2, ..., n}.\nIntroduciamo la variabile aleatoria X_n che descrive il numero di biglie rosse estratte. L’obiettivo è determinare la legge di probabilità di X_n e stabilire se è discreta o semplice, sia nel caso di estrazione con reimmissione sia senza reimmissione, e calcolarne il valore atteso.\nEspressione di X_n tramite Variabili Indicatori\nPer analizzare X_n, è utile esprimerla in funzione di variabili aleatorie più semplici. Definiamo Y_m come la funzione indicatrice dell’insieme E_m:\nY_m(\\omega) = \\begin{cases} 1 &amp; \\text{se } \\omega \\in E_m \\text{ (l&#039;m-esima pallina estratta è rossa)} \\\\ 0 &amp; \\text{se } \\omega \\notin E_m \\text{ (l&#039;m-esima pallina estratta è bianca)} \\end{cases}\nY_m è una variabile aleatoria discreta che può assumere i valori 0 o 1. La variabile aleatoria X_n, che conta il numero totale di biglie rosse estratte, può essere espressa come la somma di queste variabili indicatrici:\nX_n = \\sum_{m=1}^{n} Y_m\nPoiché X_n è la somma di un numero finito di variabili aleatorie discrete, essa stessa è una variabile aleatoria discreta.\nCaso 1: Estrazione con Reimmissione\nNel caso di estrazione con reimmissione, dopo ogni estrazione la biglia viene rimessa nell’urna. Questo implica che la composizione dell’urna (numero di biglie rosse e bianche) rimane costante ad ogni estrazione.\nLegge di Probabilità di Y_m\nLa probabilità di estrarre una biglia rossa in una qualsiasi estrazione è costante e pari a \\frac{r}{r+b} = \\frac{r}{n}. Quindi, la variabile aleatoria Y_m segue una distribuzione di Bernoulli con parametro p = \\frac{r}{n}:\nP(Y_m = 1) = p = \\frac{r}{n} P(Y_m = 0) = 1 - p = \\frac{b}{n}\nLegge di Probabilità di X_n\nPoiché le estrazioni sono indipendenti (a causa della reimmissione), le variabili aleatorie Y_1, Y_2, ..., Y_n sono indipendenti e identicamente distribuite (i.i.d.) come una Bernoulli di parametro p = \\frac{r}{n}. La somma di n variabili aleatorie di Bernoulli i.i.d. segue una distribuzione binomiale con parametri n e p.\nLa probabilità di estrarre esattamente k biglie rosse su n estrazioni con reimmissione è data da:\nP(X_n = k) = \\binom{n}{k} p^k (1-p)^{n-k} = \\binom{n}{k} \\left(\\frac{r}{n}\\right)^k \\left(\\frac{b}{n}\\right)^{n-k}\ndove k può assumere valori interi compresi tra 0 e n. Per valori di k esterni a questo intervallo, P(X_n = k) = 0, il che è coerente con la definizione del coefficiente binomiale.\nValore Atteso di X_n\nIl valore atteso di X_n è dato da:\nE[X_n] = \\sum_{k=0}^{n} k \\cdot P(X_n = k) = \\sum_{k=0}^{n} k \\binom{n}{k} p^k (1-p)^{n-k}\nPer calcolare questa somma, si osserva che per k=0 il termine è nullo, quindi possiamo iniziare la somma da k=1:\nE[X_n] = \\sum_{k=1}^{n} k \\frac{n!}{k!(n-k)!} p^k (1-p)^{n-k}\nUtilizzando la proprietà k \\cdot k! = k! e semplificando:\nE[X_n] = \\sum_{k=1}^{n} \\frac{n!}{(k-1)!(n-k)!} p^k (1-p)^{n-k}\nRiscriviamo n! = n \\cdot (n-1)! e portiamo fuori n e un fattore p dalla sommatoria (poiché non dipendono da k):\nE[X_n] = np \\sum_{k=1}^{n} \\frac{(n-1)!}{(k-1)!(n-k)!} p^{k-1} (1-p)^{n-k}\nNotiamo che n-k = (n-1) - (k-1). Sostituiamo j = k-1, quando k varia da 1 a n, j varia da 0 a n-1. La sommatoria diventa:\nE[X_n] = np \\sum_{j=0}^{n-1} \\frac{(n-1)!}{j!((n-1)-j)!} p^{j} (1-p)^{(n-1)-j}\nL’espressione all’interno della sommatoria è la probabilità di una variabile binomiale con parametri n-1 e p che assume il valore j. La somma di tutte le probabilità di una distribuzione è sempre 1:\n\\sum_{j=0}^{n-1} \\binom{n-1}{j} p^{j} (1-p)^{(n-1)-j} = 1\nPertanto, il valore atteso di X_n nel caso di estrazione con reimmissione è:\nE[X_n] = np = n \\cdot \\frac{r}{n} = \\frac{nr}{N}\nCommento: Il valore atteso del numero di biglie rosse estratte con reimmissione è proporzionale al numero di estrazioni e alla proporzione di biglie rosse presenti nell’urna.\nCaso 2: Estrazione Senza Reimmissione\nNel caso di estrazione senza reimmissione, le biglie estratte non vengono rimesse nell’urna. Questo significa che la composizione dell’urna cambia ad ogni estrazione, e quindi la probabilità di estrarre una biglia rossa varia ad ogni passo.\nLegge di Probabilità di Y_m\nLa probabilità che l’m-esima pallina estratta sia rossa dipende dagli esiti delle estrazioni precedenti. La legge di probabilità di Y_m è una Bernoulli con un parametro che dipende dall’esito delle estrazioni precedenti. Calcolare direttamente la legge di Y_m può essere complesso, in quanto richiede di considerare tutte le possibili sequenze di estrazioni precedenti.\nLegge di Probabilità di X_n\nLa variabile aleatoria X_n, che rappresenta il numero di biglie rosse estratte senza reimmissione, segue una distribuzione ipergeometrica con parametri N (dimensione della popolazione, n), K (numero di successi nella popolazione, r), e n (numero di estrazioni).\nLa probabilità di estrarre esattamente k biglie rosse su n estrazioni senza reimmissione è data da:\nP(X_n = k) = \\frac{\\binom{r}{k} \\binom{b}{n-k}}{\\binom{n}{n}}\ndove k è il numero di biglie rosse estratte, n-k è il numero di biglie bianche estratte, r è il numero totale di biglie rosse nell’urna, b è il numero totale di biglie bianche nell’urna (b = n - r), e n è il numero totale di biglie nell’urna da cui si estrae n piccolo palline. I valori ammissibili per k sono tali che i coefficienti binomiali siano ben definiti (non negativi nei termini inferiori e superiori, e il termine inferiore non supera il superiore). Se un coefficiente binomiale non è ben definito, il suo valore è considerato zero, il che è coerente con la probabilità nulla per eventi impossibili.\nValore Atteso di X_n\nIl valore atteso di X_n nel caso di estrazione senza reimmissione è:\nE[X_n] = \\sum_{k=0}^{n} k \\cdot P(X_n = k) = \\sum_{k=0}^{n} k \\frac{\\binom{r}{k} \\binom{b}{n-k}}{\\binom{n}{n}}\nUtilizzando la definizione dei coefficienti binomiali:\nE[X_n] = \\sum_{k=0}^{n} k \\frac{\\frac{r!}{k!(r-k)!} \\frac{b!}{(n-k)!(b-(n-k))!}}{\\frac{n!}{n!(n-n)!}}\nSi osserva che per k=0 il termine è nullo, quindi possiamo iniziare la somma da k=1:\nE[X_n] = \\sum_{k=1}^{n} k \\frac{r!}{k!(r-k)!} \\frac{b!}{(n-k)!(b-n+k)!} \\frac{n!}{(n)!}\nSemplificando k \\cdot k! = k! nel denominatore:\nE[X_n] = \\sum_{k=1}^{n} \\frac{r!}{(k-1)!(r-k)!} \\frac{b!}{(n-k)!(b-n+k)!} \\frac{n!}{n!}\nRiscriviamo r! = r \\cdot (r-1)! e n! = n \\cdot (n-1)!:\nE[X_n] = \\sum_{k=1}^{n} \\frac{r(r-1)!}{(k-1)!(r-k)!} \\frac{b!}{(n-k)!(b-n+k)!} \\frac{n(n-1)!}{n!}\nE[X_n] = \\frac{rn}{n} \\sum_{k=1}^{n} \\frac{(r-1)!}{(k-1)!(r-k)!} \\frac{b!}{(n-k)!(b-n+k)!} \\frac{(n-1)!}{(n-1)!}\nConsideriamo la sommatoria. Sostituiamo j = k-1, quindi quando k va da 1 a n, j va da 0 a n-1. Inoltre, r-k = (r-1) - j e n-k = (n-1) - j. La sommatoria diventa:\nE[X_n] = \\frac{rn}{n} \\sum_{j=0}^{n-1} \\frac{(r-1)!}{j!(r-1-j)!} \\frac{b!}{(n-1-j)!(b-(n-1-j))!} \\frac{(n-1)!}{(n-1)!}\nE[X_n] = \\frac{rn}{n} \\sum_{j=0}^{n-1} \\binom{r-1}{j} \\binom{b}{n-1-j} \\frac{(n-1)!}{n!}\nRiconosciamo che \\binom{n-1}{n-1} = \\frac{(n-1)!}{(n-1)! (n-1 - (n-1))!} = 1. Quindi moltiplichiamo e dividiamo per n-1:\nE[X_n] = \\frac{rn}{n} \\frac{1}{\\binom{n}{n}} \\sum_{j=0}^{n-1} \\binom{r-1}{j} \\binom{b}{n-1-j}\nPer l’identità di Vandermonde, sappiamo che \\sum_{j=0}^{n-1} \\binom{r-1}{j} \\binom{b}{n-1-j} = \\binom{(r-1)+b}{n-1} = \\binom{n-1}{n-1}.\nE[X_n] = \\frac{rn}{n} \\frac{\\binom{n-1}{n-1}}{\\binom{n}{n}} = \\frac{rn}{n} \\frac{1}{1} = \\frac{rn}{N}\nCommento: Sorprendentemente, il valore atteso del numero di biglie rosse estratte è lo stesso sia con reimmissione che senza reimmissione. Questo risultato è intuitivo se si considera la linearità del valore atteso: E[X_n] = E[\\sum_{m=1}^{n} Y_m] = \\sum_{m=1}^{n} E[Y_m]. Nel caso senza reimmissione, si può dimostrare che P(Y_m = 1) = \\frac{r}{n} per ogni m, anche se le Y_m non sono indipendenti. Quindi, E[Y_m] = 1 \\cdot P(Y_m = 1) + 0 \\cdot P(Y_m = 0) = \\frac{r}{n}, e E[X_n] = \\sum_{m=1}^{n} \\frac{r}{n} = n \\cdot \\frac{r}{n} = \\frac{nr}{N}.\nReferences"},"6--full-note/prob-ese06":{"slug":"6--full-note/prob-ese06","filePath":"6- full note/prob-ese06.md","title":"prob-ese06","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","paste/Esercitazioni-2-1.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-20 15:14\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nprob-ese06\nprima manca\nAnalisi Dettagliata dell’Esercizio 2: La Variabile Aleatoria Y_n\nDefinizione di Y_n come Somma di Indicatrici\nIl professore introduce la variabile aleatoria Y_n come risultato della somma delle prime n variabili aleatorie X_i, dove i varia da 1 a n. Formalmente, questa definizione si esprime come:\nY_n = \\sum_{i=1}^{n} X_i\nÈ importante ricordare che ogni X_i è stata precedentemente definita come la funzione indicatrice dell’insieme E_i, dove E_i rappresenta l’evento di successo all’i-esima prova. Di conseguenza, X_i assume il valore 1 se si verifica un successo all’i-esima prova e il valore 0 altrimenti.\nLa Natura Discreta di Y_n\nIl professore afferma che Y_n è una variabile aleatoria discreta. La motivazione di questa affermazione risiede nel fatto che Y_n è ottenuta come somma di un numero finito di variabili aleatorie discrete (X_1, X_2, \\dots, X_n).\nSpiegazione: Ogni X_i, essendo una funzione indicatrice, può assumere solamente due valori distinti: 0 e 1. Una variabile aleatoria che assume un numero finito di valori è per definizione discreta (e addirittura semplice, sebbene il professore preferisca usare il termine “discreta” per non introdurre troppe nomenclature). La somma di un numero finito di variabili aleatorie discrete produce una nuova variabile aleatoria che può assumere un numero finito di valori (nel caso specifico di Y_n, i valori possibili sono gli interi da 0 a n). Poiché l’immagine di Y_n è un insieme finito (e quindi numerabile), essa è una variabile aleatoria discreta.\nEsercizio Proposto: Come esercizio, viene suggerito di dimostrare formalmente che la somma di variabili aleatorie discrete è ancora una variabile aleatoria discreta. Questo implicherebbe mostrare che l’insieme dei valori che la somma può assumere è al più numerabile.\nInterpretazione Probabilistica di Y_n\nDal punto di vista probabilistico, Y_n ha un significato chiaro: rappresenta il numero totale di successi che si verificano nelle prime n prove. Questo discende direttamente dalla definizione di X_i. Ogni X_i “conta” se c’è stato un successo all’i-esima prova. Sommando questi indicatori per le prime n prove, Y_n fornisce il conteggio complessivo dei successi in quell’intervallo di prove.\nLa Legge di Probabilità di Y_n: Distribuzione Binomiale\nIl professore introduce un concetto cruciale: se si assume che gli eventi (le singole prove) siano indipendenti, allora la variabile aleatoria Y_n segue una distribuzione binomiale con parametri n (il numero di prove) e p (la probabilità di successo in una singola prova). Questa viene indicata con la notazione Y_n \\sim Bin(n, p).\nTeorema Implicito: La somma di n variabili aleatorie di Bernoulli indipendenti e identicamente distribuite (i.i.d.) con parametro p segue una distribuzione binomiale con parametri n e p. Ogni X_i è una variabile di Bernoulli con probabilità di successo p (dove p è la probabilità che \\Omega appartenga a E_n, ovvero la probabilità dell’evento di successo).\nLa probabilità che Y_n assuma un valore specifico k (cioè che si verifichino esattamente k successi in n prove) è data dalla funzione di massa di probabilità della distribuzione binomiale:\nP(Y_n = k) = \\binom{n}{k} p^k (1-p)^{n-k}\ndove:\n\nk è un intero che può variare da 0 a n (inclusi).\n\\binom{n}{k} = \\frac{n!}{k!(n-k)!} è il coefficiente binomiale, che rappresenta il numero di modi in cui si possono ottenere esattamente k successi in n prove.\np^k è la probabilità di ottenere k successi.\n(1-p)^{n-k} è la probabilità di ottenere n-k insuccessi.\n\nCalcolo del Valore Atteso di Y_n\nIl professore descrive due approcci per determinare il valore atteso di Y_n, E[Y_n].\nMetodo 1: Derivazione Diretta dalla Legge Binomiale (Ricapitolazione)\nSebbene i dettagli specifici non vengano ripetuti, il professore fa riferimento a un calcolo effettuato precedentemente. Questo metodo si basa sull’applicazione diretta della definizione di valore atteso per una variabile aleatoria discreta alla distribuzione binomiale:\nE[Y_n] = \\sum_{k=0}^{n} k \\cdot P(Y_n = k) = \\sum_{k=0}^{n} k \\binom{n}{k} p^k (1-p)^{n-k}\nAttraverso una serie di manipolazioni algebriche che coinvolgono le proprietà dei coefficienti binomiali e delle sommatorie, si dimostra che questo valore atteso è uguale a np.\nMetodo 2: Utilizzo della Linearità del Valore Atteso (Approccio Semplificato)\nIl professore presenta un metodo più elegante e concettualmente più semplice per calcolare E[Y_n], basato sulla proprietà fondamentale della linearità del valore atteso.\nRicordando che Y_n è definita come la somma delle variabili aleatorie X_i:\nY_n = \\sum_{i=1}^{n} X_i\nPossiamo esprimere il valore atteso di Y_n come il valore atteso di questa somma:\nE[Y_n] = E\\left[\\sum_{i=1}^{n} X_i\\right]\nGrazie alla proprietà di linearità del valore atteso, che afferma che il valore atteso di una somma di variabili aleatorie (non necessariamente indipendenti) è uguale alla somma dei loro valori attesi, possiamo scrivere:\nE[Y_n] = \\sum_{i=1}^{n} E[X_i]\nOra, consideriamo il valore atteso di una singola variabile di Bernoulli X_i con parametro p. Per definizione di valore atteso per una variabile discreta:\nE[X_i] = 1 \\cdot P(X_i = 1) + 0 \\cdot P(X_i = 0)\nSappiamo che P(X_i = 1) = p (probabilità di successo) e P(X_i = 0) = 1-p (probabilità di insuccesso). Quindi:\nE[X_i] = 1 \\cdot p + 0 \\cdot (1-p) = p\nSostituendo questo risultato nell’espressione per E[Y_n]:\nE[Y_n] = \\sum_{i=1}^{n} p = n \\cdot p\nQuesto secondo metodo dimostra in modo chiaro e conciso che il valore atteso del numero di successi in n prove indipendenti con probabilità di successo p è semplicemente il prodotto del numero di prove e della probabilità di successo.\nOsservazione Importante: Il professore enfatizza che, in generale, saper scomporre una variabile aleatoria in una somma di variabili più semplici può rappresentare una strategia efficace per calcolare proprietà come il valore atteso, specialmente quando l’utilizzo diretto della legge di probabilità può risultare complesso o laborioso. Questo approccio sfrutta proprietà lineari come quella del valore atteso, semplificando notevolmente i calcoli.\nEsercizio sulla Misurabilità di X_n\nCome ulteriore esercizio, il professore lascia agli studenti il compito di dimostrare che X_n è effettivamente una variabile aleatoria misurabile. Questo è un requisito fondamentale per poter parlare di X_n e, di conseguenza, di Y_n come variabili aleatorie ben definite all’interno dello spazio di probabilità considerato. La dimostrazione implicherebbe verificare che la controimmagine di ogni insieme di Borel della retta reale tramite la funzione X_n appartiene alla \\sigma-algebra dello spazio campionario.\nAnalisi Dettagliata dell’Esercizio 3: La Variabile Aleatoria Z\nDefinizione di Z e il suo Insieme di Valori\nIl professore introduce una nuova variabile aleatoria, denominata Z, definita in relazione alla sequenza di variabili X_n. Z è definita come il minimo dell’insieme degli indici interi n tali che X_n = 1. In altre parole, Z rappresenta la prima volta (in termini di indice) in cui si osserva un successo nella sequenza di prove.\nViene inoltre specificata una convenzione importante: se l’insieme degli indici per cui X_n = 1 è vuoto (ovvero, non si verifica mai un successo), allora il minimo di tale insieme è definito come più infinito (+\\infty).\nDi conseguenza, l’insieme dei valori che Z può assumere non è semplicemente l’insieme dei numeri naturali (\\mathbb{N}), ma l’unione dei numeri naturali e dell’infinito (\\mathbb{N} \\cup {+\\infty}). Il professore sottolinea che, sebbene l’evento {Z = +\\infty} possa avere probabilità nulla, ciò non significa che tale esito possa essere ignorato a priori. Questa cautela è particolarmente importante per distinguere tra variabili discrete e continue.\nInterpretazione Probabilistica di Z\nIl significato probabilistico di Z è chiaramente delineato: Z rappresenta l’indice della prova in cui si manifesta il primo successo. Se il valore di Z è k \\in \\mathbb{N}, significa che le prime k-1 prove sono state degli insuccessi (X_1 = 0, X_2 = 0, \\dots, X_{k-1} = 0) e la k-esima prova è stata un successo (X_k = 1). Se Z = +\\infty, ciò implica che non si è mai verificato un successo nella sequenza di prove.\nIl professore evidenzia che questo tipo di scenario (osservare il tempo d’attesa per il primo successo in una sequenza di prove dicotomiche) è strettamente legato alla distribuzione geometrica.\nLa Legge di Probabilità di Z\nPer determinare la legge di probabilità di Z, è necessario calcolare la probabilità che Z assuma ciascuno dei suoi possibili valori. Poiché Z è una variabile aleatoria discreta, la sua legge è completamente determinata dalle probabilità dei singoli esiti.\nProbabilità per valori finiti (Z = k, dove k \\in \\mathbb{N}, k \\ge 1)\nLa probabilità che il primo successo si verifichi esattamente alla k-esima prova, P(Z = k), implica che si siano verificati k-1 insuccessi seguiti da un successo. Assumendo l’indipendenza delle prove, la probabilità di questa sequenza è data dal prodotto delle probabilità dei singoli eventi:\nP(Z = k) = P(X_1 = 0, X_2 = 0, \\dots, X_{k-1} = 0, X_k = 1)\nPoiché P(X_i = 0) = 1-p e P(X_k = 1) = p (dove p è la probabilità di successo in una singola prova), e sfruttando l’indipendenza:\nP(Z = k) = (1-p)^{k-1} \\cdot p\nQuesta è la funzione di massa di probabilità della distribuzione geometrica, definita sull’insieme dei numeri naturali a partire da 1.\nProbabilità per valore infinito (Z = +\\infty)\nLa probabilità che Z sia uguale a più infinito, P(Z = +\\infty), corrisponde alla probabilità che non si verifichi mai un successo nella sequenza infinita di prove. Questo evento può essere espresso come l’intersezione degli eventi {Z &gt; k} per ogni k \\in \\mathbb{N}.\nUn modo per calcolare questa probabilità è utilizzare il complementare: P(Z = +\\infty) = 1 - P(Z &lt; +\\infty) = 1 - P(Z \\in \\mathbb{N}). Poiché gli eventi {Z = k} per k \\in \\mathbb{N} sono disgiunti, la probabilità che Z assuma un valore finito è la somma delle loro probabilità:\nP(Z \\in \\mathbb{N}) = \\sum_{k=1}^{\\infty} P(Z = k) = \\sum_{k=1}^{\\infty} (1-p)^{k-1} p\nQuesta è una serie geometrica. Riscrivendo la somma come p \\sum_{j=0}^{\\infty} (1-p)^j, dove j = k-1, e sapendo che la somma di una serie geometrica \\sum_{j=0}^{\\infty} r^j converge a \\frac{1}{1-r} per |r| &lt; 1, e ricordando che 0 \\le p \\le 1 (quindi 0 \\le 1-p &lt; 1 se p &gt; 0):\nP(Z \\in \\mathbb{N}) = p \\cdot \\frac{1}{1 - (1-p)} = p \\cdot \\frac{1}{p} = 1\nSe p &gt; 0. Se p = 0, allora P(Z=k) = 0 per ogni k \\in \\mathbb{N}, e P(Z=+\\infty) = 1.\nAssumendo p &gt; 0, la probabilità che Z sia finito è 1, e quindi la probabilità che Z sia infinito è:\nP(Z = +\\infty) = 1 - 1 = 0\nIl professore conclude che la probabilità che Z assuma il valore di più infinito è zero, il che è ragionevole in quanto, se esiste una probabilità positiva di successo ad ogni prova, prima o poi ci si aspetta di osservarne uno.\nOsservazione sulla Convenzione di \\mathbb{N}: Viene fatta una precisazione riguardo alla definizione dell’insieme dei numeri naturali. In questo contesto, e per coerenza con l’interpretazione di Z come l’indice del primo successo, si considera che \\mathbb{N} parta da 1. Se k fosse 0, l’espressione (1-p)^{-1} non avrebbe senso nel contesto del numero di insuccessi prima del primo successo.\nIn sintesi, Z è una variabile aleatoria discreta che segue una distribuzione geometrica con parametro p, definita sui valori {1, 2, 3, \\dots}, e la probabilità che Z sia infinito è 0 (assumendo p &gt; 0). The probability mass function of Z is P(Z=k) = (1-p)^{k-1}p for k \\in {1, 2, 3, \\dots}.\nCertamente. Ecco l’analisi integrata della variabile aleatoria W, tenendo conto delle considerazioni e dei ragionamenti del professore:\nAnalisi Dettagliata della Variabile Aleatoria W\nDefinizione di W e il suo Insieme di Valori\nL’esercizio introduce una nuova variabile aleatoria, W, definita in relazione a Z come W = Z - 1, dove Z è l’indice della prova del primo successo.\nIl professore introduce questa definizione e spiega intuitivamente che se Z rappresenta la prova in cui si verifica il primo successo, allora W = Z - 1 conta il numero di prove precedenti che sono state degli insuccessi.\nDato che Z assume valori nell’insieme \\mathbb{N} \\cup {+\\infty} (dove \\mathbb{N} = {1, 2, 3, \\dots}), i valori che W può assumere saranno:\n\nSe Z = k \\in \\mathbb{N}, allora W = k - 1. Poiché k parte da 1, W può assumere i valori 1-1 = 0, 2-1 = 1, 3-1 = 2, \\dots, ovvero l’insieme dei numeri naturali includendo lo zero (\\mathbb{N}_0 = {0, 1, 2, \\dots}). Il professore sottolinea come se il primo successo avviene alla prima prova (Z=1), allora il numero di insuccessi precedenti è 1-1=0.\nSe Z = +\\infty, allora W = +\\infty - 1 = +\\infty.\n\nPertanto, l’insieme dei valori che W può assumere è \\mathbb{N}_0 \\cup {+\\infty}.\nInterpretazione Probabilistica di W\nL’interpretazione probabilistica di W = Z - 1 è chiara: W rappresenta il numero di insuccessi che si verificano prima del primo successo.\n\nSe W = k \\in \\mathbb{N}_0, significa che ci sono stati esattamente k insuccessi seguiti dal primo successo alla prova k+1.\nSe W = +\\infty, significa che non si è mai verificato un successo, e quindi il numero di insuccessi prima di un eventuale successo (che non arriva mai) è infinito.\n\nIl professore osserva che questa interpretazione è logicamente coerente con la definizione di Z.\nLa Legge di Probabilità di W\nPer determinare la legge di probabilità di W, sfruttiamo la relazione W = Z - 1 e la legge di probabilità di Z che abbiamo derivato precedentemente. Il professore fa notare che questo è un caso di funzione iniettiva di una variabile aleatoria discreta.\nProbabilità per valori finiti (W = k, dove k \\in \\mathbb{N}_0)\nLa probabilità che si verifichino esattamente k insuccessi prima del primo successo, P(W = k), è equivalente alla probabilità che il primo successo si verifichi alla prova k+1, ovvero P(Z = k+1). Utilizzando la legge di Z:\nP(W = k) = P(Z = k+1) = (1-p)^{(k+1)-1} \\cdot p = (1-p)^k \\cdot p\nQuesta è la funzione di massa di probabilità di una distribuzione geometrica traslata o, a volte, definita sul numero di fallimenti prima del successo. Il professore la descrive come una legge geometrica ottenuta per traslazione.\nProbabilità per valore infinito (W = +\\infty)\nLa probabilità che W sia uguale a più infinito, P(W = +\\infty), corrisponde alla probabilità che Z sia uguale a più infinito, dato che W = Z - 1. Come abbiamo visto nell’analisi di Z, se p &gt; 0:\nP(W = +\\infty) = P(Z = +\\infty) = 0\nQuesto significa che, con probabilità 1, si verificherà un successo in un numero finito di prove, e quindi il numero di insuccessi prima del primo successo sarà finito. Il professore sottolinea la co-implicazione dei due eventi: {W = +\\infty} \\iff {Z = +\\infty}, pertanto hanno la stessa probabilità.\nIn sintesi, W è una variabile aleatoria discreta che segue una distribuzione geometrica (spesso definita sul numero di fallimenti) con parametro p, definita sui valori {0, 1, 2, \\dots}. La probabilità che W sia infinito è 0 (assumendo p &gt; 0). The probability mass function of W is P(W=k) = (1-p)^k p for k \\in {0, 1, 2, \\dots}. Il professore conclude osservando che per una funzione iniettiva (e in questo caso anche invertibile) di una variabile aleatoria discreta, come W = Z - 1, la legge della nuova variabile si ottiene direttamente dalla legge della variabile originale.\nReferences\nEsercitazioni 2 1.pdf"},"6--full-note/prob-lez05":{"slug":"6--full-note/prob-lez05","filePath":"6- full note/prob-lez05.md","title":"prob-lez05","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_finita","3--tag/probabilità","3--tag/sbobine"],"tags":["flashcard_zero","riscritto_zero","revisione_finita"],"content":"2025-02-25 13:16\n_Status: flashcard_zero  riscritto_zero  revisione_finita\n_Tags:  probabilità   sbobine\nprob-lez05\nBoreliani e Algebra\n\nQuando si definiscono i Boreliani, è necessario includere esplicitamente l’insieme vuoto per assicurarsi che sia un’algebra.\nSe M va da 1 a M, con B_i appartenente a vari intervallini e semirette, si deve considerare anche il caso in cui m = 0, dove per convenzione l’insieme è vuoto.\nQuesto è importante per la chiarezza e per garantire che la definizione soddisfi le proprietà di un’algebra.\n\nMisura di Lebesgue\n\nLa misura di Lebesgue su \\mathbb{R} e i suoi Boreliani è tale che la misura di un intervallo chiuso [a, b] è uguale a b - a.\nQuesta definizione si estende in modo analogo ai cubotti in dimensioni superiori.\n\nSigma Algebra e Traccia\n\n\nData una sigma algebra \\mathcal{F} definita su un insieme \\Omega, si consideri un insieme \\Delta \\in \\mathcal{F}.\n\n\n\nSi definisce la traccia della sigma algebra \\mathcal{F} su \\Delta come:\n\\qquad \\mathcal{F}_\\Delta = \\set{A \\cap \\Delta : A \\in \\mathcal{F}}\n\n\n\n\n\nIn altre parole, si prendono tutti gli insiemi A in \\mathcal{F} e si fa l’intersezione con \\Delta.\n\n\nAffermazione: \\mathcal{F}_\\Delta è una sigma algebra.\n\n\nEsempi Importanti\n\n**Intervallo **: Sia \\Delta =[0,1] e \\Omega = \\mathbb{R}. Si può prendere \\mathcal{F} come i Boreliani di \\mathbb{R}\noppure la restrizione dei Boreliani a |0,1|, che viene chiamata Boreliani di |0,1|.\n\ncontrolla\nI Boreliani  di  sono ottenuti prendendo un qualunque elemento misurabile rispetto ai Boreliani di \\mathbb{R} e facendo l’intersezione con .\n\n\nNumeri Positivi: Analogamente, si può fare la stessa cosa con i numeri positivi \\mathbb{R}^+ per ottenere i Boreliani di \\mathbb{R}^+.\n\nProbabilità Condizionali\n\n\nSi riprende l’argomento delle probabilità condizionali.\n\n\nIn uno spazio di probabilità (\\Omega, \\mathcal{F}, P), la probabilità condizionale di A dato B, con P(B) &gt; 0, è definita come:\n\\qquad P(A|B) = \\frac{P(A \\cap B)}{P(B)} se P(B)&gt;0\n\n\nImportante: P(A|B) è una funzione di due eventi, non è la probabilità di un evento “A dato B”. Si guarda come varia al variare di A.\n\n\nTeorema delle Probabilità Totali e Teorema di Bayes\n\n\nTeorema delle Probabilità Totali: Supponendo che H_i sia una partizione (famiglia al più numerabile di eventi disgiunti la cui unione è \\Omega) e P(H_i) &gt; 0, allora:\n\\qquad P(A) = \\sum_i P(A|H_i)P(H_i)\n\n\nTeorema di Bayes: Nelle stesse condizioni, per ogni i:\n\\qquad P(H_i|A) = \\frac{P(A|H_i)P(H_i)}{\\sum_j P(A|H_j)P(H_j)}\n\n\nEsempio delle Urne\n\n\nDescrizione: Ci sono due urne. La prima contiene 5 palline nere e 5 rosse, la seconda contiene 2 nere e 8 rosse. Si tira una moneta per scegliere un’urna e poi si estrae una pallina.\n\n\nEventi:\n\nR: Estrarre una pallina rossa.\nT: Uscita “testa” sulla moneta, che implica la scelta della prima urna.\n\n\n\nAssunzioni:\n\nP(T) = \\frac{1}{2} (la moneta è equilibrata).\nP(R|T) = \\frac{5}{10} (probabilità di estrarre una pallina rossa dalla prima urna).\nP(R|T^c) = \\frac{8}{10} (probabilità di estrarre una pallina rossa dalla seconda urna).\n\n\n\nCalcolo: Utilizzando il teorema di Bayes, si può calcolare la probabilità di aver estratto dalla prima urna, dato che è stata estratta una pallina rossa:\n\\qquad P(T|R) = \\frac{P(R|T)P(T)}{P(R|T)P(T) + P(R|T^c)P(T^c)}\n\n\nSostituendo i valori:\n\\qquad P(T|R) = \\frac{\\frac{5}{10} \\cdot \\frac{1}{2}}{\\frac{5}{10} \\cdot \\frac{1}{2} + \\frac{8}{10} \\cdot \\frac{1}{2}} = \\frac{\\frac{5}{20}}{\\frac{5}{20} + \\frac{8}{20}} = \\frac{5}{13}\n\n\nCostruzione dello Spazio di Probabilità\n\nViene fatto notare che manca la definizione esplicita dello spazio di probabilità (\\Omega, \\mathcal{F}, P).\nSi assume che esista uno spazio di probabilità (\\Omega, \\mathcal{F}, P) tale che gli eventi T (testa) ed R (pallina rossa) siano ben definiti e con le probabilità specificate.\n\nPartizioni e Sigma Algebra\n\nSi considerano due partizioni dello spazio \\Omega:\n\n\nH_1 = T e H_2 = T^c (testa o croce).\nE_1 = R e E_2 = R^c (pallina rossa o nera).\n\n\nSi formano le intersezioni: T \\cap R, T \\cap R^c, T^c \\cap R, T^c \\cap R^c.\n\n\n\n\nLa collezione (famiglia) B = \\set{(H_n \\cap E_k) \\ \\ \\ n\\geq1,k\\geq1} forma una partizione di \\Omega.\n\nDefinizione della Sigma Algebra\n\nSi definisce una sigma algebra generata dagli eventi in B  \\mathcal{F}= \\sigma(B).\nNel caso specifico, questa sigma algebra contiene eventi come “testa e pallina nera”, “testa e pallina rossa”, “croce e pallina nera”, “croce e pallina rossa”, ma anche eventi come “esce testa”.\nAd esempio, l’evento “esce testa” (H_1) può essere scritto come H_1 = (H_1 \\cap E_1) \\cup (H_1 \\cap E_2).\n\nProposizione Chiave\n\n\nSia {H_n} una partizione di eventi e {E_k} un’altra famiglia di eventi. La collezione B = {H_n \\cap E_k} è una partizione numerabile.\n\n\nSi assegnano una successione di pesi positivi per ogni n (p_n)_{n\\geq1} tali che \\sum_n p_n = 1,\n\n\ne pesi condizionali positivi per ogni n e k (p_{k|n})_{n\\geq1} tali che \\sum_k p_{k|n} = 1 per ogni n.\n\n\nTesi: Esiste una misura di probabilità P definita sulla sigma algebra generata da B tale che:\n\nP(H_n) = p_n per ogni n\nP(H_n \\cap E_k) = p_{k|n} p_n per ogni k e n\nP(E_k|H_n) = p_{k|n} per ogni k e n\n\n\n\nApplicazione all’Esempio delle Urne\n\n\nB = {T \\cap R, T \\cap R^c, T^c \\cap R, T^c \\cap R^c}.\np_1 = P(T) = 0.5 e p_2 = P(T^c) = 0.5.\np_{1|1} = P(R|T) = \\frac{5}{10} (probabilità di estrarre rosso dato testa).\np_{2|1} = P(R^c|T) = \\frac{5}{10} (probabilità di estrarre nero dato testa).\np_{1|2} = P(R|T^c) = \\frac{8}{10} (probabilità di estrarre rosso dato croce).\np_{2|2} = P(R^c|T^c) = \\frac{2}{10} (probabilità di estrarre nero dato croce).\nCon questi ingredienti, si può costruire una misura di probabilità ben definita.\n\nDimostrazione\n\nLa dimostrazione si basa sul fatto che, avendo una sigma algebra generata da un insieme numerabile B, è sufficiente definire una famiglia di numeri positivi q_{kn} (che dipendono da due indici perché la famiglia è indicizzata da due numeri) tali che la somma su tutti gli indici sia 1.\nSi definisce q_{kn} = p_{k|n} p_n.\nSi verifica che \\sum_{k,n} q_{kn} = \\sum_n p_n \\sum_k p_{k|n} = \\sum_n p_n \\cdot 1 = 1.\nQuindi, esiste una misura di probabilità P sulla sigma algebra generata da B tale che P(H_n \\cap E_k) = p_{k|n} p_n.\n\n\nIndipendenza di Eventi\nL’indipendenza è una proprietà della probabilità, non degli eventi stessi. Per una certa misura di probabilità, due eventi potrebbero essere indipendenti, mentre per un’altra no. Pertanto, si parla di eventi indipendenti rispetto a una specifica probabilità P.\nDefinizione di Indipendenza\nDue eventi A e B, appartenenti a uno spazio di probabilità (\\Omega, \\mathcal{F}, P), sono detti indipendenti se e solo se la probabilità della loro intersezione è uguale al prodotto delle loro probabilità:\nP(A \\cap B) = P(A) \\cdot P(B)\nIntuitivamente, conoscere l’esito di B non altera la valutazione di probabilità su A.\nProbabilità Condizionale e Indipendenza\nPartendo dalla definizione di probabilità condizionale:\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\nsi moltiplica per P(B), ottenendo:\nP(A \\cap B) = P(A \\mid B) \\cdot P(B)\nQuesta formula esprime che la probabilità che A e B si verifichino contemporaneamente è uguale alla probabilità di B moltiplicata per “qualcosa”. L’idea intuitiva è che avere informazioni su B aggiorna la probabilità su A.\nProprietà dell’Indipendenza\nSe due eventi A e B sono indipendenti, allora anche A e il complementare di B (indicato come B^c) sono indipendenti. Di conseguenza, anche le seguenti coppie di eventi sono indipendenti:\n\nA^c e B^c\nA^c e B\n\nQuesto significa che l’indipendenza è stabile rispetto all’operazione di complementazione.\nDimostrazione:\nPer dimostrare che A e B^c sono indipendenti, dobbiamo mostrare che P(A \\cap B^c) = P(A) \\cdot P(B^c).\nConsideriamo il diagramma di Venn. L’area rappresentante A \\cap B^c è contenuta in A. Possiamo scrivere A \\cap B^c come A - (A \\cap B).\nQuindi, P(A \\cap B^c) = P(A) - P(A \\cap B).\nPoiché A e B sono indipendenti, P(A \\cap B) = P(A) \\cdot P(B). Sostituendo:\nP(A \\cap B^c) = P(A) - P(A) \\cdot P(B) = P(A) \\cdot (1 - P(B)) = P(A) \\cdot P(B^c).\nQuesto dimostra che A e B^c sono indipendenti.\nErrore Comune\nÈ importante non confondere l’indipendenza (A e B indipendenti) con l’esclusività (A \\cap B = \\emptyset). L’indipendenza è una proprietà della probabilità, mentre l’esclusività è una relazione tra eventi.\nEsempio: Lancio di Due Dadi\nConsideriamo lo spazio campionario \\Omega formato da coppie di numeri, dove ogni numero rappresenta l’esito di un dado a sei facce:\n\\Omega = {(\\omega_1, \\omega_2) \\mid \\omega_1, \\omega_2 \\in {1, 2, 3, 4, 5, 6}}\nLa cardinalità di \\Omega è |\\Omega| = 6 \\times 6 = 36.\nAssumiamo che ogni coppia abbia la stessa probabilità di verificarsi (misura uniforme). Quindi, la probabilità di ogni singolo evento elementare è \\frac{1}{36}.\nDefiniamo i seguenti eventi:\n\nA: il primo dado mostra la faccia 1\nB: il secondo dado mostra la faccia 3\n\nMatematicamente:\n\nA = {(\\omega_1, \\omega_2) \\in \\Omega \\mid \\omega_1 = 1}\nB = {(\\omega_1, \\omega_2) \\in \\Omega \\mid \\omega_2 = 3}\n\nLa probabilità di A è P(A) = \\frac{6}{36} = \\frac{1}{6}, poiché ci sono sei coppie in cui il primo elemento è 1. Similmente, P(B) = \\frac{6}{36} = \\frac{1}{6}.\nL’intersezione di A e B è l’evento in cui il primo dado mostra 1 e il secondo dado mostra 3:\nA \\cap B = {(1, 3)}\nQuindi, P(A \\cap B) = \\frac{1}{36}.\nVerifichiamo se A e B sono indipendenti:\nP(A) \\cdot P(B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36} = P(A \\cap B)\nPoiché P(A \\cap B) = P(A) \\cdot P(B), gli eventi A e B sono indipendenti.\nIndipendenza di n Eventi\nGli eventi A_1, A_2, ..., A_n sono indipendenti se, per ogni sottoinsieme di k eventi distinti (con 2 \\leq k \\leq n), la probabilità dell’intersezione è uguale al prodotto delle probabilità:\nP(A_{i_1} \\cap A_{i_2} \\cap ... \\cap A_{i_k}) = P(A_{i_1}) \\cdot P(A_{i_2}) \\cdot ... \\cdot P(A_{i_k})\ndove i_1, i_2, ..., i_k sono indici distinti compresi tra 1 e n.\nEsempio con Tre Eventi (n = 3)\nSe n = 3, la definizione di indipendenza richiede che siano soddisfatte le seguenti condizioni:\n\nP(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\cdot P(A_2) \\cdot P(A_3)\nP(A_1 \\cap A_2) = P(A_1) \\cdot P(A_2)\nP(A_1 \\cap A_3) = P(A_1) \\cdot P(A_3)\nP(A_2 \\cap A_3) = P(A_2) \\cdot P(A_3)\n\nÈ importante notare che non è sufficiente che solo la prima condizione sia soddisfatta per concludere che i tre eventi sono indipendenti. Tutte le condizioni devono essere vere.\nConseguenze dell’Indipendenza\nSe A_1, A_2, ..., A_n sono indipendenti, allora anche gli eventi ottenuti complementando alcuni di essi sono indipendenti. Ad esempio, A_1, A_2, A_3^c sono indipendenti.\nIndipendenza di una Successione Numerabile di Eventi\nUna successione numerabile di eventi (A_n)_{n \\in \\mathbb{N}} è detta indipendente se ogni sua sottosuccessione finita è costituita da eventi indipendenti. In altre parole, per ogni m \\in \\mathbb{N}, gli eventi A_1, A_2, ..., A_m devono essere indipendenti.\nRegola della Catena (o Regola delle Probabilità Composte)\nSupponiamo di avere n eventi E_1, E_2, ..., E_n appartenenti a \\mathcal{F}, tali che P(E_1 \\cap E_2 \\cap ... \\cap E_n) &gt; 0. Allora, la probabilità dell’intersezione può essere scritta come: ricontrolla\n\n\n\nP(E_1 \\cap E_2 \\cap ... \\cap E_n) = P(E_1) \\cdot P(E_2 \\mid E_1) \\cdot P(E_3 \\mid E_1 \\cap E_2) \\cdot ... \\cdot P(E_n \\mid E_1 \\cap E_2 \\cap ... \\cap E_{n-1})\nDimostrazione (per n=2):\nP(E_1 \\cap E_2) = P(E_1) \\cdot P(E_2 \\mid E_1)\nQuesta formula deriva direttamente dalla definizione di probabilità condizionale. ricontrolla\n\n\nper n=2 \\mathbb{P}(E_1 \\cap E_2) = \\mathbb{P}(E_1) \\mathbb{P}(E_2 | E_1)\\mathbb{P}(E_1 \\cap E_2) = \\frac{\\mathbb{P}(E_1)\\mathbb{P}(E_2 | E_1)}{\\mathbb{P}(E_1)}\n\n\nIndipendenza Tra Eventi\n\nDue eventi A e B sono indipendenti se e solo se P(A \\cap B) = P(A)P(B).\nL’indipendenza è una proprietà della misura di probabilità, non degli eventi stessi.\n\nProprietà Importanti\n\nSe A e B sono indipendenti, allora anche A e B^c sono indipendenti. Di conseguenza, anche A^c e B^c, e A^c e B sono indipendenti.\nDimostrazione: P(A \\cap B^c) = P(A) - P(A \\cap B) = \\\\ P(A) - P(A)P(B) = \\\\ P(A)(1 - P(B)) = \\\\ P(A)P(B^c).\n\nEsempio con i Dadi\n\n\\Omega è l’insieme delle coppie (i, j) con i, j \\in {1, 2, 3, 4, 5, 6}, quindi |\\Omega| = 36.\n\\mathcal{F} è la sigma algebra delle parti di \\Omega, e P è la misura uniforme su \\Omega.\nA = {(i, j) \\in \\Omega : i = 1} (il primo dado mostra 1).\nB = {(i, j) \\in \\Omega : j = 3} (il secondo dado mostra 3).\nP(A) = \\frac{6}{36} = \\frac{1}{6}, P(B) = \\frac{6}{36} = \\frac{1}{6}.\nA \\cap B = {(1, 3)}, quindi P(A \\cap B) = \\frac{1}{36}.\nP(A)P(B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36} = P(A \\cap B), quindi A e B sono indipendenti.\n\nIndipendenza di n Eventi\n\n\nGli eventi A_1, A_2, \\dots, A_n sono indipendenti se per ogni k tra 2 e n, e per ogni scelta di k indici distinti i_1, i_2, \\dots, i_k, si ha:\n\\qquad P(A_{i_1} \\cap A_{i_2} \\cap \\dots \\cap A_{i_k}) = P(A_{i_1})P(A_{i_2})\\dots P(A_{i_k})\n\n\nEsempio con n = 3\n\nSe n = 3, gli eventi A_1, A_2, A_3 sono indipendenti se:\n\nP(A_1 \\cap A_2 \\cap A_3) = P(A_1)P(A_2)P(A_3)\nP(A_1 \\cap A_2) = P(A_1)P(A_2)\nP(A_1 \\cap A_3) = P(A_1)P(A_3)\nP(A_2 \\cap A_3) = P(A_2)P(A_3)\n\n\n\nConseguenze dell’Indipendenza\n\nSe A_1, \\dots, A_n sono indipendenti, allora anche A_1, \\dots, A_k, A_{k+1}^c, \\dots, A_n^c sono indipendenti.\n\nIndipendenza di una Successione Numerabile di Eventi\n\nUna successione numerabile di eventi {A_n} è indipendente se ogni sua sottosuccessione finita è costituita da eventi indipendenti.\n\n\nIndipendenza tra eventi\nDefinizione intuitiva\nL’idea di base è che conoscere qualcosa su un evento B non cambia la valutazione di probabilità su un evento A.\nDefinizione formale\nDue eventi A e B, appartenenti allo spazio di probabilità (\\Omega, \\mathcal{F}, P), sono indipendenti se e solo se:\nP(A \\cap B) = P(A) \\cdot P(B)\nProbabilità condizionata\nRicordando la definizione di probabilità condizionata:\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\nSe A e B sono (stocasticamente) indipendenti, allora P(A|B) = P(A), ovvero conoscere B non altera la probabilità di A.\nErrore comune\nNon confondere l’indipendenza con l’intersezione vuota:\n\nA e B indipendenti non implica A \\cap B = \\emptyset\nL’indipendenza è una proprietà della misura di probabilità P, non degli eventi A e B. Gli eventi A e B sono indipendenti rispetto a P.\n\nProprietà importante\nSe A e B sono indipendenti, allora anche:\n\nA e B^c sono indipendenti\nA^c e B sono indipendenti\nA^c e B^c sono indipendenti\n\nDove B^c è il complementare di B. In altre parole, l’indipendenza è stabile rispetto al complementare.\nDimostrazione\n\nConsideriamo P(A \\cap B^c). Vogliamo dimostrare che P(A \\cap B^c) = P(A) \\cdot P(B^c).\nP(A \\cap B^c) = P(A) - P(A \\cap B)\nSiccome A e B sono indipendenti, P(A \\cap B) = P(A) \\cdot P(B). Quindi:\nP(A \\cap B^c) = P(A) - P(A) \\cdot P(B) = P(A) \\cdot (1 - P(B)) = P(A) \\cdot P(B^c)\nEsempio: Lancio di due dadi\nConsideriamo il lancio di due dadi.\n\n\\Omega = {(w_1, w_2) : w_1, w_2 \\in {1, 2, 3, 4, 5, 6}}\n|\\Omega| = 36\nAssumiamo che la probabilità sia uniforme, quindi P({\\omega}) = \\frac{1}{36} per ogni \\omega \\in \\Omega.\n\nDefiniamo gli eventi:\n\nA = {\\omega \\in \\Omega : \\text{il primo dado mostra la faccia 1}}\nB = {\\omega \\in \\Omega : \\text{il secondo dado mostra la faccia 3}}\n\nCalcoliamo le probabilità:\n\nP(A) = \\frac{6}{36} = \\frac{1}{6}\nP(B) = \\frac{6}{36} = \\frac{1}{6}\nA \\cap B = \\set{\\omega =(1, 3)}\nP(A \\cap B) = \\frac{1}{36}\n\nVerifichiamo l’indipendenza:\nP(A) \\cdot P(B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36} = P(A \\cap B)\nQuindi, A e B sono indipendenti.\nIndipendenza di N eventi\nGli eventi A_1, A_2, ..., A_n \\in \\mathcal{F} sono indipendenti se per ogni sottoinsieme di indici distinti I_1, I_2, ..., I_k con 2 \\leq k \\leq n, vale:\nP(A_{I_1} \\cap A_{I_2} \\cap ... \\cap A_{I_k}) = P(A_{I_1}) \\cdot P(A_{I_2}) \\cdot ... \\cdot P(A_{I_k})\n\n\\mathbb{P} \\left( \\bigcap_{j=1}^{k} A_{ij} \\right) = \\prod_{j=1}^k \\mathbb{P}(A_{ij}) \\ \\ \\forall i,k \\leq n \\forall \\set{I_1, I_2, ..., I_k} \\subseteq \\set{1,\\cdots, n}\n\n\nIn altre parole, deve valere la fattorizzazione per ogni possibile combinazione di eventi.\nEsempio con N=3\nSe n = 3, allora A_1, A_2, A_3 sono indipendenti se valgono contemporaneamente le seguenti:\n\nP(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\cdot P(A_2) \\cdot P(A_3)\nP(A_1 \\cap A_2) = P(A_1) \\cdot P(A_2)\nP(A_1 \\cap A_3) = P(A_1) \\cdot P(A_3)\nP(A_2 \\cap A_3) = P(A_2) \\cdot P(A_3)\n\nNon è sufficiente che valga solo la prima condizione.\nConseguenze dell’indipendenza\nSe A_1, ..., A_n sono indipendenti, allora anche:\n\nA_1, ..., A_k, A_{k+1}^c, ..., A_n^c sono indipendenti (posso complementare qualsiasi sottoinsieme di eventi)\nSe prendo un sottoinsieme degli eventi, questi sono ancora indipendenti. Per esempio, A_1, A_2 sono indipendenti, A_1, A_3 sono indipendenti, ecc..\nSe A_1^c, A_2, A_3 sono indipendenti, allora A_1, A_2, A_3 sono indipendenti.\n\nIndipendenza di una successione numerabile di eventi\nUna successione numerabile di eventi (A_n)_{n \\in \\mathbb{N}} è indipendente se per ogni m \\in \\mathbb{N}, i primi m eventi sono indipendenti.\n\n\\text{Sono indipendenti se } \\\\ \\forall m \\ge 2 \\quad (A_1, \\dots, A_m) \\text{ sono indipendenti}\nIn altre parole, comunque si “arresti” la successione, si ottiene una famiglia finita di eventi indipendenti.\n\nReferences"},"6--full-note/prob-lez06":{"slug":"6--full-note/prob-lez06","filePath":"6- full note/prob-lez06.md","title":"prob-lez06","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-02-26 16:08\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:  sbobine   probabilità\nprob-lez06\nEventi Bernoulli (Eventi Bernoulliani)\n\n\n\nQuesto modello descrive una situazione con n eventi, E_1, E_2, ..., E_n, che sono indipendenti. Ogni evento E_i ha una probabilità associata di verificarsi.\n\nriscrivi\n\nIpotesi\n\nGli eventi E_1, E_2, ..., E_n sono indipendenti.\nLa probabilità di ogni singolo evento E_i è un numero p_i compreso tra 0 e 1: 0 \\le p_i \\le 1.\n\n\nriscrivi\n\nConvenzione di Scrittura\nPer semplificare la notazione, si introduce una convenzione:\n\nE_i^{(e_i)} dove e_i può essere 0 o 1.\n\nSe e_i = 1, allora E_i^{(e_i)} = E_i (l’evento si verifica).\nSe e_i = 0, allora E_i^{(e_i)} = E_i^c (l’evento non si verifica, si verifica il suo complementare).\n\n\n\n\nProbabilità dell’Intersezione\n\n\n\nConsiderando un vettore e = (e_1, e_2, ..., e_n) \\subseteq \\set{0,1}^n , si calcola la probabilità dell’intersezione degli eventi corrispondenti:\nP(\\bigcap_{i=1}^{n} E_i^{(e_i)})\nPoiché gli eventi sono indipendenti, questa probabilità può essere espressa come il prodotto delle probabilità dei singoli eventi o dei loro complementari:\nP(\\bigcap_{i=1}^{n} E_i^{(e_i)}) = \\prod_{i=1}^{n} P(E_i^{(e_i)})\nDove:\nP(E_i^{(e_i)}) = \\begin{cases} p_i, &amp; \\text{se } e_i = 1 \\\\ 1 - p_i, &amp; \\text{se } e_i = 0 \\end{cases}\nEvento A_k\nSi definisce l’evento A_k come l’unione di tutte le intersezioni possibili tali che esattamente k eventi si verifichino:\nA_k = \\bigcup_{\\begin{cases}\\textbf{e} \\in {0,1}^n :\\\\ \\sum_{i=1}^{n} e_i = k\\end{cases}} (\\bigcap_{i=1}^{n} E_i^{(e_i)})\nQuesto significa che A_k è l’evento in cui esattamente k degli n eventi E_i si verificano.\nCalcolo della Probabilità di A_k\nLa probabilità di A_k è la somma delle probabilità di tutte le intersezioni disgiunte che la compongono:\nP(A_k) = \\sum_{\\textbf{e} \\in {0,1}^n : \\sum_{i=1}^{n} e_i = k} P(\\bigcap_{i=1}^{n} E_i^{(e_i)})\nSostituendo con la formula dell’indipendenza:\nP(A_k) = \\sum_{\\textbf{e} \\in {0,1}^n : \\sum_{i=1}^{n} e_i = k} \\prod_{i=1}^{n} P(E_i^{(e_i)})\nUlteriore Semplificazione: Eventi Identicamente Distribuibili (i.i.d.)\n\n\nSe, oltre all’indipendenza, tutti gli eventi hanno la stessa probabilità p di verificarsi (cioè p_i = p per ogni i), allora l’espressione si semplifica ulteriormente. In questo caso, si parla di eventi bernoulliani.\n\nP(A_k) = \\binom{n}{k} p^k (1-p)^{n-k}\nDove \\binom{n}{k} è il coefficiente binomiale, che rappresenta il numero di modi di scegliere k eventi tra n.\nEsempio\nConsideriamo il lancio di n monete, dove ogni moneta ha probabilità p di dare testa. Gli esiti dei lanci sono indipendenti. Qual è la probabilità di osservare esattamente k teste? La risposta è data dalla distribuzione binomiale:\nP(A_k) = \\binom{n}{k} p^k (1-p)^{n-k}\nCostruzione di Eventi Bernoulli\n\n\nÈ possibile costruire uno spazio di probabilità in cui gli eventi E_i sono bernoulliani. Si può prendere \\Omega = {0, 1}^n, con la \\sigma-algebra delle parti e definire una misura di probabilità P tale che:\n\nP(\\omega) = \\prod_{i=1}^{n} p_i^{\\omega_i} (1 - p_i)^{(1 - \\omega_i)}\nDove \\omega = (\\omega_1, ..., \\omega_n) è un elemento di \\Omega.\nVerificare che \\sum_{\\omega \\in \\Omega} P(\\omega) = 1 e che gli eventi E_i = {\\omega \\in \\Omega : \\omega_i = 1} sono bernoulliani con probabilità p_i.\n\nIndipendenza Condizionale\n\n\n\nDefinizione A2:\n\n\n\nDati tre eventi E_1, E_2 e H appartenenti a una \\sigma-algebra \\mathcal{F}, E_1 e E_2 sono condizionatamente indipendenti dato H se:\nP(E_1 \\cap E_2 | H) = P(E_1 | H) \\cdot P(E_2 | H)\nIl professore sottolinea che questa definizione non implica che P(E_1 \\cap E_2) = P(E_1) \\cdot P(E_2), ma riguarda le probabilità condizionali.\nMisura di Probabilità Condizionale\nSe si definisce una funzione che associa a un insieme la probabilità P(E | H), questa è una misura di probabilità.\nDefinizione Equivalente di Indipendenza Condizionale\nUn modo equivalente per definire l’indipendenza condizionale è considerare che E_1 e E_2 sono indipendenti rispetto alla misura condizionale dato H. In altre parole, sono indipendenti rispetto alla misura P(\\cdot | H).\nGeneralizzazione a n Eventi\nLa definizione si estende a n eventi E_1, E_2, ..., E_n. Questi eventi sono indipendenti dato H se sono indipendenti rispetto a P(\\cdot | H).\nPer esempio, per tre eventi E_1, E_2, E_3, si deve verificare che:\n\nP(E_1 \\cap E_2 \\cap E_3 | H) = P(E_1 | H) \\cdot P(E_2 | H) \\cdot P(E_3 | H)\nP(E_1 \\cap E_2 | H) = P(E_1 | H) \\cdot P(E_2 | H)\nP(E_1 \\cap E_3 | H) = P(E_1 | H) \\cdot P(E_3 | H)\nP(E_2 \\cap E_3 | H) = P(E_2 | H) \\cdot P(E_3 | H)\n\nIn generale, la definizione di indipendenza viene riscritta sostituendo P con P(\\cdot | H) ovunque.\nImportante\nIl fatto che E_1 e E_2 siano condizionatamente indipendenti dato H non implica che E_1 e E_2 siano indipendenti.\nIl professore menziona che durante le esercitazioni verranno forniti esempi per chiarire ulteriormente questo concetto e illustrare situazioni in cui l’indipendenza condizionale emerge naturalmente.\n\nVariabili Aleatorie: Introduzione e Definizioni Preliminari\n\n\n\n\nL’argomento delle variabili aleatorie è introdotto come un punto cruciale nello studio della probabilità. Prima di arrivare alla definizione formale di variabile aleatoria, vengono presentati alcuni concetti preliminari fondamentali.\nSpazi di Punti e Sigma Algebre\nSi considerano due spazi, \\Omega e X, che rappresentano spazi di punti generici. Ad esempio:\n\n\\Omega = {1, 2, 3, 4, 5, 6} e X = {0, 1}.\n\\Omega = [0,1] X = \\mathbb{R}^d.\n\nA ciascuno di questi spazi viene assegnata una sigma algebra. Ad esempio, si possono usare:\n\nLa sigma algebra delle parti.\nI Boreliani di $.\nI Boreliani di \\mathbb{R}^d.\n\nEsempio Motivazionale: Lancio di un Dado\nPer chiarire meglio, si considera un esempio concreto: modellizzare l’esperimento del lancio di un dado e osservare se il risultato è pari o dispari.\n\nSpazio di partenza (\\Omega): Rappresenta i possibili esiti del lancio del dado, \\Omega = {1, 2, 3, 4, 5, 6}.\nSpazio di arrivo (X): Indica se il numero uscito è pari o dispari, X = \\set{0, 1}, dove 0 rappresenta “dispari” e 1 rappresenta “pari”.\nFunzione x: Mappa ogni esito del dado al valore corrispondente in X. In questo caso:\n\nx(\\omega) = 0 se \\omega \\in {1, 3, 5}.\nx(\\omega) = 1 se \\omega \\in {2, 4, 6}.\n\n\n\nL’obiettivo è quello di poter rispondere a domande del tipo “Qual è la probabilità che esca un numero pari?“.\nFunzioni Misurabili\n\nNon tutte le funzioni sono adatte per lavorare con probabilità. È necessario restringere l’attenzione a funzioni misurabili.\nDefinizione: Una funzione x \\colon \\Omega \\to X è detta misurabile se x^{-1}(A) \\in \\mathcal{F} per ogni A \\in \\Sigma_X, dove \\mathcal{F} è la sigma algebra su \\Omega e \\Sigma_X è la sigma algebra su X. In altre parole, la controimmagine di ogni insieme misurabile in X deve essere un insieme misurabile in \\Omega.\n\nx^{-1}(A) = \\set{\\omega \\in \\Omega : x(\\omega) \\in A} è la controimmagine di A.\n\nEsempio: Nell’esempio del dado, se A = {1} (cioè l’evento “esce pari”), allora x^{-1}(A) = {2, 4, 6}. Per poter calcolare la probabilità di questo evento, è necessario che {2, 4, 6} sia un insieme misurabile in \\Omega.\nVariabili Aleatorie\nDefinizione: Una variabile aleatoria è una funzione misurabile x \\colon \\Omega \\to X dove (\\Omega, \\mathcal{F}, P) è uno spazio di probabilità. Questo significa che, oltre agli spazi \\Omega e X e alle rispettive sigma algebre, è definita anche una misura di probabilità P su \\Omega.\n\nNumero aleatorio: Variabile aleatoria a valori reali, X = \\mathbb{R}.\nVettore aleatorio: Variabile aleatoria a valori in \\mathbb{R}^d.\n\nImportanza della Misurabilità: La misurabilità garantisce che abbia senso calcolare la probabilità di eventi del tipo {x \\in A}, dove A è un insieme misurabile in X. In altre parole, l’evento {\\omega \\in \\Omega : x(\\omega) \\in A} deve appartenere alla sigma algebra \\mathcal{F} per poter calcolarne la probabilità.\nP(x \\in A) = P({\\omega \\in \\Omega : x(\\omega) \\in A}) = P(x^{-1}(A))\nEsempio: Riprendendo l’esempio del dado, la probabilità di ottenere un numero pari è:\nP(x = 1) = P({\\omega \\in \\Omega : x(\\omega) = 1}) = P({2, 4, 6}) = \\frac{1}{2}\nProprietà delle Funzioni Misurabili\nPer manipolare le variabili aleatorie, è utile conoscere alcune proprietà fondamentali delle funzioni misurabili.\nLemma Fondamentale\nEnunciato: Sia x \\colon \\Omega \\to X una funzione, e sia \\mathcal{C} una famiglia di sottoinsiemi di X tale che \\sigma(\\mathcal{C}) = \\Sigma_X, dove \\sigma(\\mathcal{C}) è la sigma algebra generata da \\mathcal{C}. Allora, x è misurabile se e solo se x^{-1}(C) \\in \\mathcal{F} per ogni C \\in \\mathcal{C}.\nIn altre parole, per verificare che una funzione è misurabile, è sufficiente controllare che la controimmagine di ogni insieme in una famiglia che genera la sigma algebra di arrivo sia misurabile.\nDimostrazione: La dimostrazione di questo lemma coinvolge la definizione di una famiglia di insiemi \\mathcal{S} e la dimostrazione che \\mathcal{S} è una sigma algebra.\nCriteri di Misurabilità\n\n\nFunzioni a valori reali: Sia x \\colon \\Omega \\to \\mathbb{R}. Allora x è misurabile se e solo se x^{-1}((-\\infty, a]) \\in \\mathcal{F} per ogni a \\in \\mathbb{R}.\nQuesto criterio semplifica la verifica della misurabilità per funzioni a valori reali: basta controllare che la controimmagine di ogni semiretta sia misurabile.\n\n\nFunzioni vettoriali: Siano x_1, x_2 \\colon \\Omega \\to \\mathbb{R} misurabili. Allora il vettore (x_1, x_2) \\colon \\Omega \\to \\mathbb{R}^2 è misurabile.\nLa dimostrazione utilizza il lemma fondamentale e la proprietà che i rettangoli con basi misurabili generano la sigma algebra dei Boreliani in \\mathbb{R}^2.\n\n\nComposizione di funzioni misurabili: Siano x_1 \\colon \\Omega_1 \\to \\Omega_2 e x_2 \\colon \\Omega_2 \\to X funzioni misurabili. Allora la composizione x_2 \\circ x_1 \\colon \\Omega_1 \\to X è misurabile.\n\n\nFunzioni continue: Se h \\colon \\mathbb{R}^n \\to \\mathbb{R} è una funzione continua, allora h è misurabile rispetto ai Boreliani. La dimostrazione di questa proprietà richiede un richiamo sulle funzioni continue.\n\n\nConseguenze Importanti\nSiano x_1, x_2 \\colon \\Omega \\to \\mathbb{R} funzioni misurabili. Allora:\n\nx_1 + x_2 è misurabile.\nx_1 - x_2 è misurabile.\nx_1 \\cdot x_2 è misurabile.\n\\max{x_1, 0} (parte positiva di x_1) è misurabile.\n-\\min{x_1, 0} (parte negativa di x_1) è misurabile.\nSe f \\colon \\mathbb{R}^2 \\to \\mathbb{R} è continua, allora f(x_1, x_2) è misurabile.\n\nQueste proprietà permettono di costruire nuove funzioni misurabili a partire da funzioni misurabili note, utilizzando operazioni algebriche e composizioni con funzioni continue.\n\nEcco una spiegazione dettagliata sulle funzioni misurabili e variabili aleatorie, basata sulle lezioni del professore, con particolare attenzione ai passaggi matematici, esempi ed esercizi.\nFunzioni Misurabili e Variabili Aleatorie\n\n\n\n\nSpazi di Misura\nSi considerano due spazi, \\Omega e X, dove \\Omega rappresenta uno spazio di punti e X un altro spazio di punti. Ad esempio:\n\n\\Omega = {1, 2, 3, 4, 5, 6} e X = {0, 1}\n\\Omega = \\mathbb{R} e X = \\mathbb{R}^d\n\\Omega = e X = \\mathbb{R}^d\n\nAd ognuno di questi spazi si associa una \\sigma-algebra. Per esempio:\n\nIn \\Omega, la \\sigma-algebra delle parti \\mathcal{P}(\\Omega)\nIn X, la \\sigma-algebra delle parti \\mathcal{P}(X)\nIn , i Boreliani di \nIn \\mathbb{R}^d, i Boreliani di \\mathbb{R}^d\n\nDefinizione di Funzione Misurabile\nUna funzione \\xi: \\Omega \\rightarrow X si dice misurabile se:\n\\xi^{-1}(A) \\in \\mathcal{F} \\quad \\forall A \\in \\Sigma_X\ndove \\Sigma_X è la \\sigma-algebra su X e \\mathcal{F} è la \\sigma-algebra su \\Omega. In altre parole, la controimmagine di ogni insieme misurabile in X è un insieme misurabile in \\Omega.\nEsempio Motivazionale: Lancio di un Dado\nSi vuole modellizzare l’esperimento del lancio di un dado e osservare se il risultato è pari o dispari.\n\n\\Omega = {1, 2, 3, 4, 5, 6} rappresenta l’esito del lancio del dado\nX = {0, 1} rappresenta “dispari” (0) o “pari” (1)\n\nLa funzione \\xi: \\Omega \\rightarrow X è definita come:\n\n\\xi(\\omega) = 0 se \\omega \\in {1, 3, 5}\n\\xi(\\omega) = 1 se \\omega \\in {2, 4, 6}\n\nProbabilità di un Evento\nPer un probabilista, è fondamentale che, data una funzione, si possa propagare l’informazione sulla probabilità. Nell’esempio del dado, si vuole sapere qual è la probabilità che esca un numero pari.\nDefinizione di Variabile Aleatoria\nUna variabile aleatoria è una funzione misurabile da uno spazio di probabilità (\\Omega, \\mathcal{F}, P) a uno spazio misurabile (X, \\Sigma_X). Quindi, oltre alla misurabilità, si aggiunge la presenza di una misura di probabilità P su \\Omega.\nTipi di Variabili Aleatorie\n\nNumero aleatorio: Variabile aleatoria a valori reali, \\xi: \\Omega \\rightarrow \\mathbb{R}, dove \\mathbb{R} è dotato dei Boreliani.\nVettore aleatorio: Variabile aleatoria a valori in \\mathbb{R}^d, \\xi: \\Omega \\rightarrow \\mathbb{R}^d, dove \\mathbb{R}^d è dotato dei Boreliani.\n\nMisurabilità e Controimmagine\nSe \\xi è una variabile aleatoria, allora ha senso chiedersi qual è la probabilità che \\xi(\\omega) appartenga ad A, dove A è un insieme misurabile in X. Formalmente:\nP(\\xi \\in A) = P({\\omega \\in \\Omega : \\xi(\\omega) \\in A}) = P(\\xi^{-1}(A))\nÈ cruciale che \\xi^{-1}(A) sia un evento appartenente alla \\sigma-algebra \\mathcal{F} su \\Omega, affinché si possa calcolare la sua probabilità.\nEsempio: Probabilità di Pari nel Lancio del Dado\nLa probabilità di ottenere un numero pari è:\nP(\\xi = 1) = P({\\omega \\in \\Omega : \\xi(\\omega) = 1}) = P({2, 4, 6})\nProprietà delle Funzioni Misurabili\nFunzioni tra Spazi\nSi definisce una funzione nel senso matematico più generale, cioè una corrispondenza che associa ad ogni punto di \\Omega un punto in X. È importante notare che queste funzioni non sono necessariamente da \\mathbb{R} in \\mathbb{R} o da \\mathbb{R}^d in \\mathbb{R}, ma possono essere tra insiemi più generali.\nLemma Fondamentale\nSia \\xi: \\Omega \\rightarrow X una funzione, e sia \\mathcal{C} una famiglia di sottoinsiemi di X tale che \\sigma(\\mathcal{C}) = \\Sigma_X (cioè, \\mathcal{C} genera la \\sigma-algebra su X). Allora \\xi è misurabile se e solo se:\n\\xi^{-1}(C) \\in \\mathcal{F} \\quad \\forall C \\in \\mathcal{C}\nIn altre parole, per verificare che una funzione è misurabile, è sufficiente controllare che la controimmagine degli elementi di una famiglia che genera la \\sigma-algebra d’arrivo siano misurabili.\nProprietà Utili delle Controimmagini\nSia f: E \\rightarrow F una funzione. Allora:\n\nf^{-1}(\\emptyset) = \\emptyset\nf^{-1}(F) = E\nf^{-1}(\\bigcup_{i} V_i) = \\bigcup_{i} f^{-1}(V_i), dove V_i \\subseteq F\nf^{-1}(A^c) = (f^{-1}(A))^c\n\nConseguenze del Lemma\n\n\nFunzioni a valori reali: Una funzione \\xi: \\Omega \\rightarrow \\mathbb{R} è misurabile (rispetto alla \\sigma-algebra \\mathcal{F} su \\Omega e ai Boreliani \\mathcal{B}(\\mathbb{R}) su \\mathbb{R}) se e solo se:\n\\xi^{-1}((-\\infty, x]) \\in \\mathcal{F} \\quad \\forall x \\in \\mathbb{R}\nBasta quindi controllare che la controimmagine delle semirette sia misurabile.\n\n\nFunzioni vettoriali: Siano \\xi_1, \\xi_2: \\Omega \\rightarrow \\mathbb{R} due funzioni misurabili. Allora il vettore (\\xi_1, \\xi_2): \\Omega \\rightarrow \\mathbb{R}^2 è misurabile (rispetto alla \\sigma-algebra \\mathcal{F} su \\Omega e ai Boreliani \\mathcal{B}(\\mathbb{R}^2) su \\mathbb{R}^2).\nLa dimostrazione utilizza il lemma e il fatto che i rettangoli con basi misurabili generano i Boreliani di \\mathbb{R}^2. La controimmagine di un rettangolo A_1 \\times A_2 è:\n(\\xi_1, \\xi_2)^{-1}(A_1 \\times A_2) = \\xi_1^{-1}(A_1) \\cap \\xi_2^{-1}(A_2)\nPoiché \\xi_1 e \\xi_2 sono misurabili, \\xi_1^{-1}(A_1) \\in \\mathcal{F} e \\xi_2^{-1}(A_2) \\in \\mathcal{F}, quindi (\\xi_1, \\xi_2)^{-1}(A_1 \\times A_2) \\in \\mathcal{F}.\n\n\nComposizione di funzioni misurabili: Siano \\xi_1: (\\Omega_1, \\mathcal{F}_1) \\rightarrow (\\Omega_2, \\mathcal{F}_2) e \\xi_2: (\\Omega_2, \\mathcal{F}_2) \\rightarrow (X, \\Sigma_X) funzioni misurabili. Allora la funzione composta \\xi_2 \\circ \\xi_1: \\Omega_1 \\rightarrow X, definita come (\\xi_2 \\circ \\xi_1)(\\omega) = \\xi_2(\\xi_1(\\omega)), è misurabile (rispetto a \\mathcal{F}_1 e \\Sigma_X).\n\n\nFunzioni Continue e Misurabilità\nSe h: \\mathbb{R}^n \\rightarrow \\mathbb{R} è una funzione continua, allora h è misurabile (rispetto ai Boreliani).\nOperazioni con Funzioni Misurabili\nSiano \\xi_1, \\xi_2: \\Omega \\rightarrow \\mathbb{R} funzioni misurabili. Allora le seguenti funzioni sono misurabili:\n\n\\xi_1 + \\xi_2\n\\xi_1 - \\xi_2\n\\xi_1 \\cdot \\xi_2\n\\xi^+ = \\max{\\xi, 0} (parte positiva di \\xi)\n\\xi^- = -\\min{\\xi, 0} (parte negativa di \\xi)\n\nIn generale, se \\psi: \\mathbb{R}^2 \\rightarrow \\mathbb{R} è una funzione continua, allora \\psi(\\xi_1, \\xi_2) è misurabile.\nReferences"},"6--full-note/prob-lez07":{"slug":"6--full-note/prob-lez07","filePath":"6- full note/prob-lez07.md","title":"prob-lez07","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità","paste/Appunti-Prob-Lez07.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-02 21:55\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine   probabilità\nChiarimenti Preliminari\nIl professore inizia rispondendo ad alcune domande degli studenti per chiarire concetti non del tutto chiari dalla lezione precedente.\nEsempio di eventi Bernoulliani\nCostruzione di uno spazio con eventi Bernoulliani: L’esempio riguarda la costruzione di uno spazio in cui ci sono eventi bernoulliani. Lo spazio \\Omega è definito come le successioni di 0 e 1 di lunghezza n. I p_i sono numeri compresi tra 0 e 1, con i che va da 1 a n. Non è necessario che la loro somma faccia 1.\nDefinizione della misura di probabilità: L’esercizio consiste nel definire una misura di probabilità P su \\Omega. Dato un \\omega \\in \\Omega del tipo \\omega = (\\omega_1, \\omega_2, ..., \\omega_n), la probabilità di questo evento particolare (il singoletto) è definita come: P(\\set{\\omega})= \\prod_{i=1}^{n} p_i^{\\omega_i} (1 - p_i)^{1 - \\omega_i} L’obiettivo è dimostrare che tutti questi numeri sono maggiori o uguali a 0 e che la loro somma su tutti gli \\omega è uguale a 1.\nEsempio con n=2: Per n = 2, bisogna verificare che: \\sum_{\\omega \\in \\set{0,1}^2} \\prod_{i=1}^{2} p_i^{\\omega_i} (1 - p_i)^{1 - \\omega_i} = 1 Questo significa controllare se la somma su \\omega_1 e \\omega_2 appartenenti a {0, 1} di p_1^{\\omega_1} (1 - p_1)^{1 - \\omega_1} \\cdot p_2^{\\omega_2} (1 - p_2)^{1 - \\omega_2} fa 1. Questa somma può essere scritta come il prodotto di somme: \\sum_{\\omega_1 \\in \\set{0,1}} p_1^{\\omega_1} (1 - p_1)^{1 - \\omega_1} \\cdot \\sum_{\\omega_2 \\in \\set{0,1}} p_2^{\\omega_2} (1 - p_2)^{1 - \\omega_2} Ogni blocco della somma fa 1, quindi il risultato è 1 \\cdot 1 = 1.\n\nAttenzione alle notazioni: Non confondere P_i con P(\\omega_i). In questo caso, P_i si riferisce a un parametro per definire la probabilità, non alla probabilità di \\omega stesso. In un teorema precedente, quando si aveva uno spazio numerabile, si assegnavano direttamente le probabilità P_i agli elementi \\omega_i.\n\nFunzioni Misurabili\nIl professore spiega che la misurabilità è una proprietà che dipende non solo dalla funzione ma anche dalle sigma algebre sugli spazi di partenza e di arrivo.\n\nDefinizione: Una funzione \\xi: \\Omega \\rightarrow X è misurabile rispetto alle sigma algebre \\mathcal{F} su \\Omega e \\xi su X se per ogni A \\in \\xi, la controimmagine X^{-1}(A) appartiene a \\mathcal{F}.\nEsempio concreto: Consideriamo uno spazio di partenza \\Omega = \\set{1, 2, 3} e uno spazio di arrivo X = \\set{1, 2, 3}. Definiamo una funzione f(\\omega) = \\omega, cioè f(1) = 1, f(2) = 2, f(3) = 3.\n\n\n\nSe \\mathcal{F} = \\mathcal{P}(\\Omega) (l’algebra delle parti di \\Omega) e \\mathcal{X} = \\mathcal{P}(X), allora f è misurabile.\n\n\nSe \\tilde{\\mathcal{F}} = \\sigma({1, 2}) (la sigma algebra generata dall’insieme {1, 2}) e \\mathcal{X} = \\mathcal{P}(X), allora \\xi non è \\tilde{\\mathcal{F}}/\\mathcal{X} misurabile.\n\nLa sigma algebra \\sigma({1, 2}) è composta da \\set{\\emptyset, {1, 2}, {3}, \\Omega}.\nConsideriamo l’insieme {1} \\in \\xi. La sua controimmagine è f^{-1}({1}) = {1}, che non appartiene a \\mathcal{F}.\n\n\n\n\nLa spiegazione sulla continuità nei sources verte su due aspetti principali:\n\nDefinizione di continuità\nLegame tra continuità e misurabilità\n\nDefinizione di Continuità\nLa fonte presenta due definizioni di continuità e si focalizza su quella che è più utile per dimostrare la misurabilità:\n\nContinuità per successioni: Una funzione H: \\mathbb{R}^D \\rightarrow \\mathbb{R} è continua per successioni se, per ogni x \\in \\mathbb{R}^D e per ogni successione x_n in \\mathbb{R}^D convergente a x, allora H(x_n) converge a H(x).\nContinuità tramite controimmagini di aperti: Una funzione H: \\mathbb{R}^D \\rightarrow \\mathbb{R} è continua se per ogni aperto A di \\mathbb{R}, la controimmagine H^{-1}(A) è un aperto in \\mathbb{R}^D.\n\nIl professore indica di non usare la definizione di continuità per successioni, ma quella tramite controimmagini di aperti, in quanto più utile ai fini della dimostrazione della misurabilità.\n\nLegame tra Continuità e Misurabilità\nIl punto chiave è che se una funzione è continua, allora è anche misurabile rispetto alle sigma algebre dei Boreliani. Più precisamente, se H: \\mathbb{R}^D \\rightarrow \\mathbb{R} è continua, allora è Borel-misurabile . Questo significa che è misurabile rispetto alla sigma algebra dei Boreliani su \\mathbb{R}^D e alla sigma algebra dei Boreliani su \\mathbb{R}.\nDimostrazione\nLa dimostrazione utilizza un lemma che semplifica la verifica della misurabilità. In particolare, si usa il lemma che afferma che se la sigma algebra generata da una classe C è uguale alla sigma algebra di arrivo, basta verificare che la controimmagine di ogni elemento di C appartiene alla sigma algebra di partenza.\n\nI passaggi principali sono:\n\nSi sceglie C come la classe degli aperti di \\mathbb{R}. La sigma algebra generata da C è esattamente la sigma algebra dei Boreliani di \\mathbb{R}.\nSi sfrutta la continuità di H per dimostrare che per ogni aperto A \\in C, la controimmagine H^{-1}(A) è un aperto in \\mathbb{R}^D.\nSi conclude che H^{-1}(A) appartiene ai Boreliani di \\mathbb{R}^D, dato che gli aperti di \\mathbb{R}^D sono contenuti nei Boreliani di \\mathbb{R}^D.\nPer il lemma, si conclude che H è misurabile.\n\ndi, è Borel-misurabile.\nEsempio: Misurabilità della somma di due variabili aleatorie\nObiettivo: Dimostrare che se X_1 e X_2 sono variabili aleatorie misurabili, allora anche la loro somma X_1 + X_2 è misurabile.\n\nPassaggi:\n\n\nDefinizione delle variabili: Si considerano X_1 e X_2 definite su uno spazio \\Omega e a valori nei Boreliani di \\mathbb{R}. Entrambe sono misurabili rispetto alle sigma algebre appropriate.\n\n\nCreazione di una funzione vettoriale: Si crea una funzione \\xi che mappa \\omega \\in \\Omega in un vettore (X_1(\\omega), X_2(\\omega)) \\in \\mathbb{R}^2. Questa funzione è misurabile.\n\n\nDefinizione della funzione somma: Si definisce una funzione S: \\mathbb{R}^2 \\rightarrow \\mathbb{R} tale che S(x, y) = x + y. Questa funzione è la somma delle due componenti ed è continua.\n\n\nComposizione delle funzioni: Si considera la composizione S(X_1(\\omega), X_2(\\omega)) = X_1(\\omega) + X_2(\\omega). Questa è la somma delle due variabili aleatorie.\n\n\nApplicazione dei criteri di misurabilità:\n\nLe funzioni continue sono Borel-misurabili. Quindi S è misurabile.\nSe si hanno due variabili aleatorie misurabili, la funzione che le impacchetta in un vettore è congiuntamente misurabile.\nLa composizione di funzioni misurabili è misurabile.\n\n\n\nConclusione: Mettendo insieme questi tre ingredienti, si conclude che la somma X_1 + X_2 è misurabile.\n\n\nIn sintesi, l’esempio mostra come, sfruttando la continuità della somma e la misurabilità delle variabili aleatorie componenti, si possa dimostrare che la somma di due variabili aleatorie è ancora una variabile aleatoria misurabile.\nUtilità\nQuesto risultato è utile perché permette di stabilire facilmente la misurabilità di molte funzioni, semplicemente verificandone la continuità. Inoltre, la composizione di funzioni misurabili è misurabile. Perciò, combinando funzioni continue e variabili aleatorie misurabili, si possono costruire nuove variabili aleatorie misurabili.\nEcco la spiegazione del professore riguardo alle flashcard, integrata con i dettagli matematici, gli esempi e gli esercizi, formattata per chiarezza e leggibilità:\nFunzione indicatrice\nConsideriamo uno spazio \\Omega, \\mathcal{F} , considero A \\in \\mathcal{F} e introduciamo la seguente funzione:\n\n\nAd ogni \\omega \\in \\Omega associamo:\n\n0 se \\omega \\notin A\n1 se \\omega \\in A, dove A \\in \\mathcal{F}\n\n\n\nQuesta funzione è chiamata indicatrice e si indica con diverse notazioni come I, 1_A o I_A. In termini probabilistici, questa funzione indica se un evento si è verificato (1) o meno (0).\nMisurabilità della funzione indicatrice\nLa funzione indicatrice assume valori in [0, 1], quindi possiamo considerarla a valori reali.\nPer verificare se è misurabile, dobbiamo analizzare la controimmagine di un evento che sta in \\mathbb{R}.\nConsideriamo B \\subseteq \\mathbb{R}. Ci sono quattro casi possibili per la controimmagine di B:\n\nSe B contiene 1 ma non 0, allora I_A^{-1}(B) = A\nSe B contiene 0 ma non 1, allora I_A^{-1}(B) = A^c (complementare di A)\nSe B non contiene né 0 né 1, allora I_A^{-1}(B) = \\emptyset (insieme vuoto)\nSe B contiene sia 0 che 1, allora I_A^{-1}(B) = \\Omega\n\nPoiché A \\in \\mathcal{F}, anche A^c \\in \\mathcal{F}, e \\emptyset, \\Omega \\in \\mathcal{F} (perché \\mathcal{F} è una \\sigma-algebra). Quindi, la controimmagine di qualsiasi insieme B è un evento che sta in \\mathcal{F}, dimostrando che la funzione indicatrice è misurabile.\nLa più piccola \\sigma-algebra su \\Omega per cui questa funzione è misurabile è \\sigma(A), la \\sigma-algebra generata da A.\nFunzioni semplici\nPrendiamo A_1, \\dots, A_n \\in \\mathcal{F} e c_1, \\dots, c_M \\in \\mathbb{R} (numeri fissi). La funzione: \\omega \\rightarrow \\sum_{i=1}^M c_i I_{A_i}(\\omega) è misurabile. Se i c_i sono tutti uguali a 1, discende dal fatto che la somma di funzioni misurabili è misurabile. In generale, c_i \\cdot I_{A_i} è misurabile perché il prodotto di una costante per una funzione misurabile è misurabile (funzione continua di funzioni misurabili è misurabile), e quindi la somma di funzioni misurabili è misurabile.\nQueste funzioni si chiamano funzioni semplici e assumono solo un numero finito di valori su \\Omega, anche se \\Omega non è numerabile.\nLimite di funzioni misurabili\n\nSiano X_n : \\Omega \\to \\mathbb{R} funzioni misurabili. Se esiste il limite: X(\\omega) = \\lim_{n \\to \\infty} X_n(\\omega) \\quad \\forall \\omega \\in \\Omega allora X è misurabile rispetto alla \\sigma-algebra in gioco, \\mathcal{F}. In altre parole, se una funzione può essere approssimata puntualmente da una successione di funzioni misurabili, allora questa funzione è misurabile.\nSe il limite non esiste, si possono usare il limite superiore e il limite inferiore, ma è necessario conoscerne la definizione.\n\nProprietà delle Funzioni e Misurabilità\nIntroduzione alle Sigma Algebre e Spazi di Misura\nIl professore inizia sottolineando l’importanza di separare le sigma algebre dagli insiemi e di come si applichino le sigma algebre per parlare di misurabilità. Introduce la notazione standard:\n\nΩ (Omega): spazio di partenza\n\\mathcal{X}: spazio di arrivo\n\\mathcal{F} (F): sigma algebra su Omega\n\\xi (Xi): sigma algebra su X\nX: funzione da Ω a X\n\nViene ribadito che queste sono convenzioni di notazione e che la lettera \\xi è usata per sottolineare che tutto dipende dalla funzione ξ (xi), da omega, da \\mathcal{X} e dalle sigma algebre.\n\nMisura di Probabilità\nSuccessivamente, viene introdotta una misura di probabilità P sullo spazio Ω:\n\n(Ω, ℱ, P): spazio di probabilità\n\nQuesta notazione indica che \\xi è una funzione definita da Ω in X**, con ℱ su Ω, 𝒳 su \\chi e P su ℱ.\nVariabili Aleatorie\nSi introduce la notazione con la lettera X per indicare una funzione misurabile quando lo spazio di arrivo è ℝ.\n\nVariabili aleatorie: funzioni misurabili con spazio di arrivo in ℝ\nVettori aleatori: funzioni misurabili con spazio di arrivo in ℝ^D, con i boreliani di ℝ^D\n\n\nLa differenza fondamentale è che, parlando di funzioni misurabili, si hanno due spazi, una funzione e due sigma algebre. Invece, per le variabili aleatorie, si hanno due spazi, due sigma algebre e una misura di probabilità sullo spazio di partenza. Nel caso di variabili aleatorie a valori reali o vettori aleatori, lo spazio di arrivo è ℝ o ℝ^D, con le sigma algebre d’arrivo che sono i boreliani di ℝ o ℝ^D, e una misura di probabilità.\nEsempio del Dado\nViene ripreso l’esempio del dado per illustrare i concetti:\n\nΩ = {1, 2, 3, 4, 5, 6}\nX = {0, 1} (0 per dispari, 1 per pari)\nℱ = algebra delle parti di Ω\nP(ω) = 1/6 per ogni ω ∈ Ω\n\n\nLa variabile aleatoria X vale 0 se ω ∈ {1, 3, 5} e 1 se ω ∈ {2, 4, 6}.\n\nLa probabilità che esca pari è P(X = 1) = 1/2, e la probabilità che esca dispari è P(X = 0) = 1/2.\n\nQuesto esempio mostra come si possano dare valutazioni di probabilità a qualcosa che sta nello spazio di arrivo.\nLegge Immagine (o Distribuzione Indotta)\nDefinizione di Legge Immagine Dato uno spazio di probabilità (\\Omega, \\mathcal{F}, P) e una variabile aleatoria X : (\\Omega, \\mathcal{F}) \\to ({\\mathbb{R}}^D, \\mathcal{B}({\\mathbb{R}}^D),\nla legge immagine (o distribuzione immagine) di X, denotata come P_X,\nè una misura di probabilità definita su ({\\mathbb{R}}^D, \\mathcal{B}({\\mathbb{R}}^D) tale che P_X(A) = P(X^{-1}(A)) per ogni A \\in \\mathcal{B}({\\mathbb{R}}^D)&#039;.\nIn altre parole, la probabilità che la variabile aleatoria X assuma un valore in un insieme A è uguale alla probabilità che l’evento X^{-1}(A) si verifichi nello spazio di probabilità originale.\n\n\nLa notazione per la legge immagine è menzionata nella fonte “lezione”:\n\n\nData una variabile aleatoria X, la sua legge immagine è denotata come P_X.\n\n\nP_X(A) = P({\\omega \\in \\Omega : X(\\omega) \\in A}).\n\n\nEquivalentemente, si può scrivere P(X \\in A). Questo significa che la probabilità che X appartenga all’insieme A è la legge immagine di X applicata all’insieme A.\n\n\nFormalizzazione della Legge Immagine: La legge immagine P_X è definita come P_X(A) = P({\\omega \\in \\Omega : X(\\omega) \\in A}) per ogni A \\in \\mathcal{F}&#039;.\n\n\nSomma su insiemi disgiunti: Se A = \\bigcup_{n=1}^{\\infty} A_n, dove gli A_n sono insiemi disgiunti, allora P_X(A) = \\sum_{n=1}^{\\infty} P({\\omega : X(\\omega) \\in A_n}).\n\n\nMisura di Probabilità\n\nNon-negatività: P_X(A) \\geq 0 per ogni A.\nProbabilità dello spazio totale: P_X(\\mathbb{R}^D) = 1.\nAdditività completa: Per ogni successione di insiemi A_n incompatibili (cioè disgiunti), P_X(\\bigcup_{n=1}^{\\infty} A_n) = \\sum_{n=1}^{\\infty} P_X(A_n).\n\nEcco i passaggi della dimostrazione forniti in “lezione”:\n\nPositività: P_X(A) è una probabilità, quindi per definizione è maggiore o uguale a zero.\nProbabilità dello spazio totale: P_X(\\mathbb{R}^D) = 1 perché X assume valori in \\mathbb{R}^D. Ciò significa che la probabilità che X assuma un valore all’interno dello spazio totale è pari a 1.\nAdditività completa:\n\nP_X(\\bigcup_{n=1}^{\\infty} A_n) = P({\\omega : X(\\omega) \\in \\bigcup_{n=1}^{\\infty} A_n})\n= P(\\bigcup_{n=1}^{\\infty} \\set{\\omega : X(\\omega) \\in A_n})\n= \\sum_{n=1}^{\\infty} P(\\set{\\omega : X(\\omega) \\in A_n}) (perché gli A_n sono disgiunti)\n= \\sum_{n=1}^{\\infty} P_X(A_n)\n\n\n\nQuindi, P_X soddisfa tutti gli assiomi di una misura di probabilità.\nPassaggi della Dimostrazione\n\nPositività: P_X(A) è una probabilità, quindi è maggiore o uguale a zero.\nProbabilità dello spazio totale: P_X(ℝ^D) = 1 perché X assume valori in ℝ^D.\nAdditività completa:\n\nP_X(\\bigcup_{n=1}^{\\infty} A_n) = P({\\omega : X(\\omega) \\in \\bigcup_{n=1}^{\\infty} A_n})\n= P(\\bigcup_{n=1}^{\\infty} {\\omega : X(\\omega) \\in A_n})\n= \\sum_{n=1}^{\\infty} P({\\omega : X(\\omega) \\in A_n}) (perché gli A_n sono disgiunti)\n= \\sum_{n=1}^{\\infty} P_X(A_n)\n\n\n\nImportanza Concettuale\nsi sottolinea l’importanza fondamentale della legge immagine nella costruzione di modelli probabilistici. Spesso, nella pratica, si ha un modello probabilistico in mente, ma non si ha accesso diretto allo spazio di partenza \\Omega. Invece, si osserva l’esperimento nello spazio di arrivo, cioè nello spazio dei valori che la variabile aleatoria può assumere.\nLa legge immagine consente di trasportare la probabilità dallo spazio originale \\Omega allo spazio dei valori della variabile aleatoria, rendendo possibile lavorare direttamente con la distribuzione dei risultati osservabili.\nFunzioni di Ripartizione\naleatoria reale**. In questo caso, la variabile aleatoria X è una funzione misurabile da uno spazio di probabilità (\\Omega, \\mathcal{F}, P) all’insieme dei numeri reali (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}),P_x), dove P_x è la legge immagine su \\mathcal{B}(\\mathbb{R}) è la \\sigma-algebra dei Boreliani di \\mathbb{R}.\nDefinizione formale\nIl professore introduce la funzione di ripartizione, denotandola tipicamente con la lettera grande F, come una funzione da \\mathbb{R} a valori in [0,1] . Formalmente:\nF: \\mathbb{R} \\rightarrow [0,1]\nUna funzione di ripartizione deve soddisfare le seguenti proprietà:\n\n\nMonotona non decrescente: F è monotona non decrescente. Questo significa che se x_1 &lt; x_2, allora F(x_1) \\leq F(x_2).\n\n\nLimiti agli estremi:\n\n\\lim_{x \\to -\\infty} F(x) = 0\n\\lim_{x \\to +\\infty} F(x) = 1\n\n\n\nContinuità da destra: F è continua da destra. Questo significa che per ogni x_0 \\in \\mathbb{R}:\n\\lim_{x \\to x_0^+} F(x) = F(x_0)\novvero, per ogni x_0 \\in \\mathbb{R}, per ogni successione x_n \\to x_0 con x_n &gt; x_0, si ha \\lim_{n \\to \\infty} F(x_n) = F(x_0). Il professore sottolinea che, pur potendo avere dei punti di discontinuità, la funzione è continua da destra in ogni punto.\n\n\nLegame tra Misure di Probabilità e Funzioni di Ripartizione\nIl professore introduce un teorema fondamentale che collega le misure di probabilità sui Boreliani di \\mathbb{R} e le funzioni di ripartizione.\n\nTeorema:\n\n\nData una misura di probabilità P sui Boreliani di \\mathbb{R}, è possibile definire una funzione F_P(x) come:\nF_P(x) = P((-\\infty, x])\nQuesta funzione F_P(x) è una funzione di ripartizione nel senso definito in precedenza.\n\n\nViceversa, per ogni  funzione di ripartizione F(x), esiste una unica misura di probabilità P sui Boreliani di \\mathbb{R} tale che:\nP((-\\infty, x]) = F(x)\n\n\n\n\nQuesto teorema stabilisce una corrispondenza biunivoca tra le misure di probabilità sui Boreliani di \\mathbb{R} e le funzioni di ripartizione. In altre parole, ogni funzione di ripartizione definisce univocamente una misura di probabilità e viceversa.\nEsempi di Funzioni di Ripartizione\nIl professore presenta tre esempi specifici di funzioni di ripartizione per illustrare le proprietà sopra descritte:\n\n\nFunzione lineare a tratti:\n\nUna funzione definita come 0 fino a un certo punto, poi sale linearmente come una retta, e infine vale 1. Questa funzione è continua, quindi anche continua da destra, ed è monotona.\n\n\nFunzione esponenziale:\n\nF(x) = \\begin{cases} 0, &amp; \\text{se } x &lt; 0 \\\\ 1 - e^{-\\lambda x}, &amp; \\text{se } x \\geq 0 \\end{cases}\ndove \\lambda &gt; 0. Il professore osserva che questa funzione è continua (e quindi continua da destra) e i limiti agli estremi sono rispettati. Per x \\rightarrow -\\infty si ha che F(x) \\rightarrow 0. Per x \\rightarrow +\\infty si ha che F(x) \\rightarrow 1.\n\n\nFunzione a gradini:\n\nF(x) = \\begin{cases} 0, &amp; \\text{se } x &lt; 0 \\\\ 1/2, &amp; \\text{se } 0 \\leq x &lt; 2 \\ 1, &amp; \\text{se } x \\geq 2 \\end{cases}\nQuesta funzione è un esempio di funzione di ripartizione discontinua. È costante a tratti e ha dei salti in x=0 e x=2. Tuttavia, è continua da destra in ogni punto.\n\n\nEsercizio\nCalcolare la probabilità di intervalli dati gli esempi di funzioni di ripartizione.\nprob-lez07\nReferences\nAppunti Prob-Lez07.pdf"},"6--full-note/prob-lez08":{"slug":"6--full-note/prob-lez08","filePath":"6- full note/prob-lez08.md","title":"prob-lez08","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità","paste/appunti-prob-lez08.pdf","2--source-materials/Appunti-Prob--lez08'.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-03 15:26\n_Status: flashcard_zero  riscritto_zero  revisione_zero\nTags:sbobine probabilità\nRipasso di Concetti Fondamentali: Sigma Algebra e Funzione di Ripartizione\nProprietà della Sigma Algebra: Unione e Intersezione\nIl professore ha inizialmente chiarito una proprietà fondamentale delle sigma algebre. Se si hanno una sequenza di insiemi A_1, A_2, ..., A_n che appartengono a una data sigma algebra, allora non solo la loro unione (\\bigcup_{i=1}^{n} A_i) appartiene alla sigma algebra, ma anche la loro intersezione (\\bigcap_{i=1}^{n} A_i) appartiene alla sigma algebra.\nQuesta seconda affermazione, relativa all’intersezione, non viene esplicitamente inclusa tra gli assiomi che definiscono una sigma algebra, ma è una conseguenza di tali assiomi. Per dimostrarlo, si può utilizzare il fatto che se un insieme B appartiene alla sigma algebra, allora anche il suo complementare B^c appartiene alla sigma algebra. Inoltre, l’unione di insiemi appartenenti alla sigma algebra è anch’essa un elemento della sigma algebra.\nLa dimostrazione si basa sull’applicazione delle leggi di De Morgan. Consideriamo l’intersezione di una sequenza di insiemi A_i appartenenti alla sigma algebra: \\bigcap_{i=1}^{n} A_i. Possiamo riscrivere questa intersezione come il complementare dell’unione dei complementari:\n\\bigcap_{i=1}^{n} A_i = (\\bigcup_{i=1}^{n} A_i^c)^c\nPoiché ogni A_i appartiene alla sigma algebra, anche il suo complementare A_i^c appartiene alla sigma algebra per definizione di sigma algebra. Di conseguenza, l’unione dei complementari \\bigcup_{i=1}^{n} A_i^c appartiene anch’essa alla sigma algebra. Infine, il complementare di questa unione, (\\bigcup_{i=1}^{n} A_i^c)^c, che è uguale all’intersezione originale, appartiene anch’esso alla sigma algebra. Il professore ha suggerito di svolgere questa dimostrazione come esercizio.\nRipasso di Calcolo Combinatorio nell’Esercitazione\nIl professore ha annunciato che l’esercitazione successiva avrebbe riguardato un ripasso di calcolo combinatorio e del suo utilizzo nei problemi elementari di conteggio legati alla probabilità discreta su insiemi finiti. Ha sottolineato l’importanza di queste esercitazioni, pur precisando che la parte combinatorica del corso sarebbe stata abbastanza minimale.\nFunzione di Ripartizione per Misure di Probabilità su \\mathbb{R}\nDefinizione e Collegamento con la Misura di Probabilità\nIl professore ha ripreso il concetto di funzione di ripartizione per descrivere le misure di probabilità sull’insieme dei numeri reali, \\mathbb{R}. Ha ricordato l’enunciato fondamentale stabilito nella lezione precedente:\n\n\nSe F è una funzione di ripartizione (nel senso definito precedentemente), allora esiste un’unica misura di probabilità P_F sui borelliani di \\mathbb{R} tale che per ogni x \\in \\mathbb{R}: P_F((-\\infty, x]) = F(x).\n\n\nViceversa, data una misura di probabilità P sui borelliani di \\mathbb{R}, la funzione F(x) = P((-\\infty, x]) è una funzione di ripartizione.\n\n\nProprietà della Funzione di Ripartizione: Dimostrazioni\nIl professore ha poi ripreso la dimostrazione di alcune proprietà fondamentali della funzione di ripartizione F(x) = P((-\\infty, x]), dove P è una misura di probabilità sui borelliani di \\mathbb{R}.\n1. Monotonia non decrescente:\nPer x \\le y, l’evento (-\\infty, x] è contenuto nell’evento (-\\infty, y]. Poiché la misura di probabilità P è monotona, si ha:\nP((-\\infty, x]) \\le P((-\\infty, y])\nDalla definizione di F(x), questo implica che F(x) \\le F(y) per x \\le y. Quindi, F è una funzione monotona non decrescente.\n2. Limite a -\\infty:\nConsideriamo la successione di eventi A_n = (-\\infty, -n] per n \\in \\mathbb{N}. Questa è una successione decrescente di insiemi, cioè A_{n+1} \\subseteq A_n per ogni n, e la sua intersezione è l’insieme vuoto: \\bigcap_{n=1}^{\\infty} A_n = \\emptyset.\nPer la proprietà di continuità delle misure di probabilità, abbiamo:\n\\lim_{n \\to \\infty} P(A_n) = P(\\bigcap_{n=1}^{\\infty} A_n) = P(\\emptyset) = 0\nPoiché P(A_n) = P((-\\infty, -n]) = F(-n), si ha:\n\\lim_{n \\to \\infty} F(-n) = 0\nGrazie alla monotonia di F, questo risultato si estende a qualunque successione x_n che tende a -\\infty, quindi:\n\\lim_{x \\to -\\infty} F(x) = 0.\n3. Limite a +\\infty:\nConsideriamo la successione di eventi B_n = (-\\infty, n] per n \\in \\mathbb{N}. Questa è una successione crescente di insiemi, cioè B_n \\subseteq B_{n+1} per ogni n, e la sua unione è l’insieme di tutti i numeri reali: \\bigcup_{n=1}^{\\infty} B_n = \\mathbb{R}.\nPer la proprietà di continuità delle misure di probabilità, abbiamo:\n\\lim_{n \\to \\infty} P(B_n) = P(\\bigcup_{n=1}^{\\infty} B_n) = P(\\mathbb{R}) = 1\nPoiché P(B_n) = P((-\\infty, n]) = F(n), si ha:\n\\lim_{n \\to \\infty} F(n) = 1\nAncora per la monotonia di F, questo risultato si estende a qualunque successione x_n che tende a +\\infty, quindi:\n\\lim_{x \\to +\\infty} F(x) = 1.\n4. Continuità da destra:\nConsideriamo un punto x \\in \\mathbb{R} e la successione di eventi C_n = (-\\infty, x + \\frac{1}{n}] per n \\in \\mathbb{N}. Questa è una successione decrescente di insiemi, cioè C_{n+1} \\subseteq C_n per ogni n, e la sua intersezione è l’insieme (-\\infty, x]: \\bigcap_{n=1}^{\\infty} C_n = (-\\infty, x].\nPer la proprietà di continuità delle misure di probabilità, abbiamo:\n\\lim_{n \\to \\infty} P(C_n) = P(\\bigcap_{n=1}^{\\infty} C_n) = P((-\\infty, x])\nPoiché P(C_n) = P((-\\infty, x + \\frac{1}{n}]) = F(x + \\frac{1}{n}) e P((-\\infty, x]) = F(x), si ha:\n\\lim_{n \\to \\infty} F(x + \\frac{1}{n}) = F(x)\nQuesto dimostra che F è continua da destra in ogni punto x \\in \\mathbb{R}.\nIl professore ha menzionato un’osservazione fatta da uno studente riguardo alla continuità da sinistra, spiegando che l’approccio con x - \\frac{1}{n} non converge in modo monotono all’insieme desiderato, il che impedisce di applicare direttamente la proprietà di continuità della misura.\nFunzione di Ripartizione di una Variabile Aleatoria\nData una variabile aleatoria reale X definita su uno spazio di probabilità (\\Omega, \\mathcal{F}, P), la funzione di ripartizione associata a X, indicata con F_X(x), è definita come la probabilità che la variabile aleatoria X assuma un valore minore o uguale a x:\nF_X(x) = P({ \\omega \\in \\Omega : X(\\omega) \\le x }) = P(X \\le x)\nIl professore ha osservato che questa probabilità può anche essere interpretata come la probabilità che la legge immagine P_X (definita sui borelliani di \\mathbb{R}) associ all’intervallo (-\\infty, x]:\nF_X(x) = P_X((-\\infty, x])\nSecondo la proposizione precedentemente dimostrata, F_X(x) è effettivamente una funzione di ripartizione (monotona non decrescente, con limiti 0 a -\\infty e 1 a +\\infty, e continua da destra). Questo stabilisce un legame fondamentale tra variabili aleatorie e funzioni di ripartizione: ogni variabile aleatoria reale è associata a una specifica funzione di ripartizione che ne descrive la distribuzione di probabilità.\nEstrazione di Informazioni dalla Funzione di Ripartizione\nIl professore ha mostrato come estrarre informazioni probabilistiche su una variabile aleatoria X, con funzione di ripartizione F_X(x), direttamente dalla funzione stessa.\n1. Probabilità che X sia strettamente maggiore di x:\nP(X &gt; x) = 1 - P(X \\le x) = 1 - F_X(x).\n2. Probabilità che X appartenga all’intervallo semiaperto (a, b]:\nP(a &lt; X \\le b) = P(X \\le b) - P(X \\le a) = F_X(b) - F_X(a).\nQuesta formula si ottiene considerando l’evento {X \\le b} come l’unione disgiunta di {X \\le a} e {a &lt; X \\le b} e utilizzando la proprietà di additività delle probabilità.\n3. Probabilità che X sia strettamente minore di x:\nP(X &lt; x) = \\lim_{y \\to x^-} F_X(y) = F_X(x^-).\nQuesta probabilità è data dal limite sinistro della funzione di ripartizione nel punto x. Per dimostrarlo, si considera una successione crescente x_n che converge a x da sinistra. Gli eventi {X \\le x_n} formano una successione crescente di insiemi la cui unione è {X &lt; x}. Per la continuità dal basso delle misure di probabilità, si ha P(X &lt; x) = \\lim_{n \\to \\infty} P(X \\le x_n) = \\lim_{n \\to \\infty} F_X(x_n) = F_X(x^-). Questo punto era lasciato come esercizio.\n4. Probabilità che X sia uguale a x:\nP(X = x) = P(X \\le x) - P(X &lt; x) = F_X(x) - F_X(x^-).\nLa probabilità che X assuma esattamente il valore x è data dalla discontinuità (o salto) della funzione di ripartizione nel punto x. Se F_X è continua in x, allora P(X = x) = 0. In particolare, se la funzione di ripartizione è continua ovunque, la probabilità che la variabile aleatoria assuma un valore specifico è sempre zero. Il professore ha sottolineato che questa è una proprietà importante, sebbene a volte controintuitiva, e che sarebbe stata ripresa in seguito.\nEsempi di Funzioni di Ripartizione e Calcolo di Probabilità\nIl professore ha ripreso alcuni esempi di funzioni di ripartizione per illustrare come calcolare le probabilità .\nPrimo Esempio:\nF_1(x) = \\begin{cases} 0 &amp; x &lt; 0 \\\\ x &amp; 0 \\le x \\le 1 \\\\ 1 &amp; x &gt; 1 \\end{cases}\nQuesta funzione di ripartizione è continua ovunque . Il professore ha chiesto qual è la probabilità che una variabile aleatoria X_1 con questa funzione di ripartizione sia uguale a 3, P(X_1 = 3) . Poiché la funzione è continua in x=3, il salto è zero:\nP(X_1 = 3) = F_1(3) - F_1(3^-) = 1 - 1 = 0 .\nSuccessivamente, ha chiesto la probabilità che X_1 sia minore o uguale a 3, P(X_1 \\le 3) . Dalla definizione della funzione di ripartizione:\nP(X_1 \\le 3) = F_1(3) = 1 .\nInfine, ha chiesto la probabilità che X_1 appartenga all’intervallo, P(0 \\le X_1 \\le 1) . Utilizzando la formula per l’intervallo semiaperto:\nP(0 &lt; X_1 \\le 1) = F_1(1) - F_1(0) = 1 - 0 = 1\nPoiché la funzione è continua in 0, P(X_1 = 0) = F_1(0) - F_1(0^-) = 0 - 0 = 0. Quindi,\nP(0 \\le X_1 \\le 1) = P(X_1 = 0) + P(0 &lt; X_1 \\le 1) = 0 + 1 = 1 .\nQuesto indica che la variabile aleatoria X_1 assume valori nell’intervallo  con probabilità 1 .\nSecondo Esempio:\nF_2(x) = \\begin{cases} 0 &amp; x &lt; 0 \\ 1/2 &amp; 0 \\le x &lt; 2 \\ 1 &amp; x \\ge 2 \\end{cases}\nQuesta funzione di ripartizione ha dei salti in x=0 e x=2 . Il professore ha chiesto qual è la probabilità che una variabile aleatoria X_2 con questa funzione di ripartizione sia uguale a 0, P(X_2 = 0) . Utilizzando la formula per la probabilità di un singolo punto:\nP(X_2 = 0) = F_2(0) - F_2(0^-) = \\frac{1}{2} - 0 = \\frac{1}{2} .\nLa probabilità è data dal salto della funzione nel punto x=0 .\n\nEcco la spiegazione del professore contenuta nel flashcard, presentata in maniera dettagliata e formattata come richiesto:\nFunzione di Ripartizione di una Variabile Aleatoria\nDefinizione e Proprietà Fondamentali\nIl professore introduce la funzione di ripartizione (o funzione cumulativa di distribuzione), definendola come un oggetto ben definito per qualunque variabile aleatoria. Non è detto che debba necessariamente essere continua né la funzione cumulata di qualche densità, e quindi non necessariamente scrivibile come un integrale.\nVerifica delle Proprietà: Prima di considerare una funzione come una funzione di ripartizione, è fondamentale controllarne le proprietà. Se una funzione soddisfa tali proprietà, allora descrive completamente la variabile aleatoria o la misura di probabilità indotta.\nProbabilità Puntuale e Discontinuità\nIn presenza di discontinuità nella funzione di ripartizione, possiamo calcolare la probabilità che la variabile aleatoria assuma un valore specifico.\nEsempio: Consideriamo una variabile aleatoria X_2 la cui funzione di ripartizione ha un salto in x=0. Dal disegno (non fornito, ma descritto a parole), la funzione di ripartizione valutata in 0 è 1/2, mentre il limite da sinistra è 0. Il salto in 0 misura quindi 1/2.\nLa probabilità che X_2 sia uguale a 0 è data dalla differenza tra il valore della funzione di ripartizione in 0 e il suo limite da sinistra: P(X_2 = 0) = F_{X_2}(0) - \\lim_{x \\to 0^-} F_{X_2}(x) = \\frac{1}{2} - 0 = \\frac{1}{2}.\nQuesto esempio illustra come le discontinuità nella funzione di ripartizione corrispondano a probabilità puntuali non nulle.\nProbabilità di un Intervallo in Termini di Funzione di Ripartizione\nIl professore introduce un esercizio per esprimere la probabilità che una variabile aleatoria appartenga a un intervallo in termini della sua funzione di ripartizione. Vengono menzionati sia l’intervallo aperto che l’intervallo chiuso.\nPer risolvere questo tipo di esercizio, si devono utilizzare le proprietà della funzione di ripartizione e la definizione di probabilità degli eventi, inclusa la continuità lungo successioni monotone di eventi.\nEsempio di Variabile Aleatoria Uniforme sull’Intervallo\nViene presentato un esempio di una variabile aleatoria X con **distribuzione uniforme sull’intervallo **. La sua funzione di ripartizione F_X(x) è definita come segue:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\ x &amp; \\text{se } 0 &lt; x &lt; 1 \\ 1 &amp; \\text{se } x \\ge 1 \\end{cases}\nPer questa variabile aleatoria, la probabilità che X appartenga a un intervallo [a, b] con 0 \\le a \\le b \\le 1 è data dalla lunghezza dell’intervallo: P(a \\le X \\le b) = F_X(b) - F_X(a) = b - a.\nIl professore sottolinea che in questo caso particolare, poiché la funzione di ripartizione è continua, la probabilità che X assuma un singolo valore è 0. Questo implica che per l’intervallo [a, b] all’interno di : P(a \\le X \\le b) = P(a &lt; X \\le b) = P(a \\le X &lt; b) = P(a &lt; X &lt; b) = b - a.\nImportante: Il professore avverte che se la funzione di ripartizione non è continua, è cruciale prestare attenzione all’uso di minore o uguale (\\le) e minore stretto (&lt;) negli intervalli, poiché ciò può fare la differenza nel calcolo della probabilità.\nMisura di Lebesgue: Viene osservato che la misura di probabilità associata alla variabile uniforme su  coincide con la misura di Lebesgue ristretta all’intervallo .\nEsercizio: Si chiede come dimostrare che la probabilità che X appartenga a un insieme boreliano A tale che la sua intersezione con  sia l’insieme vuoto (A \\cap = \\emptyset) è zero.\nSoluzione dell’Esercizio: Se A \\cap = \\emptyset, allora A è contenuto nel complementare di (0, 1), ovvero A \\subseteq (-\\infty, 0] \\cup [1, +\\infty). Quindi, la probabilità che X appartenga ad A è minore o uguale alla probabilità che X appartenga a (-\\infty, 0] \\cup [1, +\\infty).\nP(X \\in (-\\infty, 0] \\cup [1, +\\infty)) = P(X \\le 0) + P(X \\ge 1) = F_X(0) + (1 - F_X(1)).\nDalla definizione di F_X(x), abbiamo F_X(0) = 0 e F_X(1) = 1. Quindi: P(X \\in (-\\infty, 0] \\cup [1, +\\infty)) = 0 + (1 - 1) = 0.\nPoiché P(X \\in A) \\le 0 e la probabilità è non negativa, ne consegue che P(X \\in A) = 0.\nCostruzione di Nuove Variabili Aleatorie tramite Trasformazioni\nIl professore introduce l’idea di costruire una nuova variabile aleatoria applicando una trasformazione a una variabile aleatoria esistente. Questo è utile sia dal punto di vista modellistico che teorico.\nEsempio 2: Si parte da una variabile aleatoria X_1 distribuita uniformemente su (0, 1), denotato come X_1 \\sim U(0, 1). La sua funzione di ripartizione è F_{X_1}(x) = x per x \\in, 0 per x &lt; 0 e 1 per x &gt; 1 (anche se nel testo viene definita in modo leggermente diverso con \\le 0 e \\ge 1, l’essenza è la stessa per la continuità).\nSi definisce una nuova variabile aleatoria X_2 = -\\log(X_1).\nConsiderazioni sul Dominio del Logaritmo: Il logaritmo è definito solo per numeri positivi. Poiché X_1 è uniforme su (0, 1), assume valori positivi con probabilità 1. Più precisamente, P(X_1 \\in (0, 1)) = 1.\nProprietà di X_2: Se X_1(\\omega) \\in (0, 1), allora -\\log(X_1(\\omega)) &gt; 0. Questo accade con probabilità 1, quindi P(X_2 &gt; 0) = 1.\nCalcolo della Funzione di Ripartizione di X_2: Si vuole calcolare F_{X_2}(x) = P(X_2 \\le x).\nF_{X_2}(x) = P(-\\log(X_1) \\le x)\nPer risolvere questa probabilità, si considera il caso in cui x \\le 0 e il caso in cui x &gt; 0.\nCaso 1: x \\le 0 Abbiamo dimostrato che P(X_2 &gt; 0) = 1. Quindi, la probabilità che X_2 sia minore o uguale a un numero non positivo è 0: F_{X_2}(x) = P(X_2 \\le x) = 0 per x \\le 0 .\nCaso 2: x &gt; 0 P(-\\log(X_1) \\le x) = P(\\log(X_1) \\ge -x) Esponenziando entrambi i lati (e ricordando che la funzione esponenziale è crescente): P(X_1 \\ge e^{-x})\nPoiché X_1 è uniforme su (0, 1), e stiamo considerando x &gt; 0, allora 0 &lt; e^{-x} &lt; 1. La probabilità che X_1 sia maggiore o uguale a e^{-x} è data da: P(X_1 \\ge e^{-x}) = 1 - P(X_1 &lt; e^{-x}) = 1 - F_{X_1}(e^{-x})\nDato che per 0 &lt; y &lt; 1, F_{X_1}(y) = y, abbiamo: 1 - F_{X_1}(e^{-x}) = 1 - e^{-x}\nQuindi, la funzione di ripartizione di X_2 è: F_{X_2}(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\ 1 - e^{-x} &amp; \\text{se } x &gt; 0 \\end{cases}\nQuesta è la funzione di ripartizione di una variabile aleatoria esponenziale con parametro \\lambda = 1.\nIl professore conclude sottolineando l’importanza di guardare “in faccia” la variabile aleatoria e la trasformazione prima di eseguire i calcoli, per capire le sue proprietà fondamentali.\n\nTrasformazione di Variabili Aleatorie e Funzione di Ripartizione\nIntroduzione: Calcolo della Probabilità di X^2 \\le X per X &gt; 0\nIl professore inizia concentrandosi sul calcolo della probabilità che X^2 sia minore o uguale a X, dato che una variabile aleatoria X_1 è strettamente maggiore di 0. Viene specificato che si restringe l’attenzione al caso X &gt; 0 perché la probabilità che X_1 appartenga all’intervallo (0, 1) è 1, semplificando l’analisi iniziale.\nSi definisce una nuova variabile aleatoria X_2 = -\\log(X_1), dove X_1 \\in (0, 1). L’obiettivo è calcolare la funzione di ripartizione di X_2, F_{X_2}(x) = P(X_2 \\le x), conoscendo la funzione di ripartizione di X_1, F_{X_1}(x).\nCalcolo della Funzione di Ripartizione di X_2 per x &gt; 0\nPer x &gt; 0, si ha: F_{X_2}(x) = P(X_2 \\le x) = P(-\\log(X_1) \\le x).\nManipolando la disuguaglianza: -\\log(X_1) \\le x \\iff \\log(X_1) \\ge -x X_1 \\ge e^{-x}.\nQuindi, P(-\\log(X_1) \\le x) = P(X_1 \\ge e^{-x}).\nIl professore sottolinea che l’evento {-\\log(X_1) \\le x} è esattamente uguale all’evento {X_1 \\ge e^{-x}} come sottoinsiemi dello spazio campionario \\Omega.\nLa probabilità P(X_1 \\ge e^{-x}) può essere espressa in termini della funzione di ripartizione di X_1: P(X_1 \\ge e^{-x}) = 1 - P(X_1 &lt; e^{-x}).\nPoiché X_1 è assunta avere una funzione di ripartizione assolutamente continua, la probabilità che X_1 sia uguale a un singolo valore è zero, quindi P(X_1 &lt; e^{-x}) = P(X_1 \\le e^{-x}) = F_{X_1}(e^{-x}).\nPertanto, per x &gt; 0: F_{X_2}(x) = 1 - F_{X_1}(e^{-x}).\nCaso Specifico: X_1 Distribuita Uniformemente in (0, 1)\nIl professore considera il caso in cui X_1 è distribuita uniformemente nell’intervallo (0, 1). In questo caso, la funzione di ripartizione di X_1 è: F_{X_1}(y) = \\begin{cases} 0 &amp; \\text{se } y &lt; 0 \\ y &amp; \\text{se } 0 \\le y \\le 1 \\ 1 &amp; \\text{se } y &gt; 1 \\end{cases}.\nPoiché stiamo considerando x &gt; 0, l’argomento di F_{X_1}, che è e^{-x}, sarà sempre compreso tra 0 e 1 (in quanto x &gt; 0 \\implies e^{-x} \\in (0, 1)).\nQuindi, per x &gt; 0, F_{X_1}(e^{-x}) = e^{-x}.\nSostituendo nell’espressione per F_{X_2}(x), otteniamo per x &gt; 0: F_{X_2}(x) = 1 - e^{-x}.\nFunzione di Ripartizione Completa di X_2\nPer completare la definizione della funzione di ripartizione di X_2, si considera anche il caso x \\le 0. F_{X_2}(x) = P(X_2 \\le x) = P(-\\log(X_1) \\le x).\nSe x \\le 0, allora -\\log(X_1) \\le x implica \\log(X_1) \\ge -x \\ge 0, quindi X_1 \\ge e^{-x} \\ge 1. Tuttavia, sappiamo che X_1 \\in (0, 1) con probabilità 1. Pertanto, per x \\le 0, l’evento {-\\log(X_1) \\le x} ha probabilità 0.\nQuindi, la funzione di ripartizione di X_2 è: F_{X_2}(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\ 1 - e^{-x} &amp; \\text{se } x &gt; 0 \\end{cases}.\nVerifica delle Proprietà della Funzione di Ripartizione\nIl professore verifica che la funzione F_{X_2}(x) ottenuta soddisfa le proprietà di una funzione di ripartizione:\n\nContinuità da destra: La funzione è continua per x &lt; 0 e per x &gt; 0. In x = 0, \\lim_{h \\to 0^+} F_{X_2}(0 + h) = 1 - e^0 = 1 - 1 = 0 = F_{X_2}(0). Quindi è continua da destra.\nMonotona non decrescente: Per x \\le 0, la funzione è costante a 0. Per x &gt; 0, la derivata è \\frac{d}{dx}(1 - e^{-x}) = e^{-x} &gt; 0, quindi è strettamente crescente.\nLimiti agli estremi:\n\n\\lim_{x \\to -\\infty} F_{X_2}(x) = \\lim_{x \\to -\\infty} 0 = 0.\n\\lim_{x \\to +\\infty} F_{X_2}(x) = \\lim_{x \\to +\\infty} (1 - e^{-x}) = 1 - 0 = 1.\n\n\n\nQueste verifiche confermano che F_{X_2}(x) è una funzione di ripartizione valida.\nErrore Tipico da Evitare\nIl professore avverte di un errore comune: dimenticare la parte della funzione di ripartizione per x \\le 0 e scrivere semplicemente F_{X_2}(x) = 1 - e^{-x} per ogni x. Questo porterebbe a risultati errati nel calcolo delle probabilità, specialmente per valori negativi di x.\nDefinizione di Variabile Aleatoria con Legge Esponenziale\nLa variabile aleatoria X_2 la cui funzione di ripartizione è F_{X_2}(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\\\ 1 - e^{-x} &amp; \\text{se } x &gt; 0 \\end{cases} è detta avere una legge esponenziale (o esponenziale negativa).\nQuesto esempio illustra la trasformazione di una variabile aleatoria: a partire dalla legge di X_1, si è derivata la legge della variabile trasformata X_2 = -\\log(X_1). Questo tipo di trasformazioni è frequente in probabilità.\nCorollario sull’Unicità delle Misure di Probabilità\nIl professore introduce un corollario basato sul criterio di unicità delle misure di probabilità:\nSe due variabili aleatorie X_1 e X_2 definite sullo stesso spazio di probabilità (\\Omega, \\mathcal{F}, P) hanno la stessa funzione di ripartizione, cioè F_{X_1}(x) = F_{X_2}(x) per ogni x \\in \\mathbb{R}, allora le loro leggi (misure immagine) sono uguali: P(X_1 \\in A) = P(X_2 \\in A) per ogni insieme boreliano A.\nQuesto deriva dal fatto che gli intervalli (-\\infty, x] formano una \\pi-classe che genera la \\sigma-algebra dei boreliani. Due misure di probabilità che coincidono su una \\pi-classe che genera la \\sigma-algebra, coincidono su tutta la \\sigma-algebra.\nImportanza del Concetto di Legge di una Variabile Aleatoria\nAvere la stessa legge non implica che due variabili aleatorie siano uguali con probabilità 1, anche se definite sullo stesso spazio di probabilità.\nEsempio: Sia \\Omega = {0, 1} con la \\sigma-algebra di tutte le parti e una misura di probabilità P({0}) = 1/2, P({1}) = 1/2. Definiamo due variabili aleatorie: X_1(\\omega) = \\omega X_2(\\omega) = 1 - \\omega\nLa probabilità che X_1 = X_2 è P({\\omega \\in {0, 1} \\mid \\omega = 1 - \\omega}) = P(\\emptyset) = 0. Quindi X_1 e X_2 sono diverse con probabilità 1.\nTuttavia, calcoliamo le loro funzioni di ripartizione:\nPer F_{X_1}(x):\n\nSe x &lt; 0, P(X_1 \\le x) = P(\\emptyset) = 0.\nSe 0 \\le x &lt; 1, P(X_1 \\le x) = P({0}) = 1/2.\nSe x \\ge 1, P(X_1 \\le x) = P({0, 1}) = 1.\n\nPer F_{X_2}(x):\n\nSe x &lt; 0, P(X_2 \\le x) = P(\\emptyset) = 0.\nSe 0 \\le x &lt; 1, P(X_2 \\le x) = P({1}) = 1/2.\nSe x \\ge 1, P(X_2 \\le x) = P({0, 1}) = 1.\n\nQuindi, F_{X_1}(x) = F_{X_2}(x) per ogni x \\in \\mathbb{R}, il che significa che X_1 e X_2 hanno la stessa legge, anche se non sono uguali con probabilità 1.\nCostruzione di una Variabile Aleatoria Data una Funzione di Ripartizione\nSe F è una funzione di ripartizione, esiste uno spazio di probabilità (\\Omega, \\mathcal{F}, P) e una variabile aleatoria X: \\Omega \\to \\mathbb{R} tale che la funzione di ripartizione di X, F_X(x) = P(X \\le x), è uguale a F(x) per ogni x \\in \\mathbb{R}.\nIl professore sottolinea che lo spazio di probabilità e la variabile aleatoria non sono unici. L’esempio di X_1 e X_2 sopra mostra due variabili aleatorie diverse definite sullo stesso spazio di probabilità che hanno la stessa funzione di ripartizione (e quindi la stessa legge).\nQuesto teorema garantisce che per ogni funzione che soddisfa le proprietà di una funzione di ripartizione, possiamo sempre immaginare che essa descriva la distribuzione di probabilità di qualche variabile aleatoria. Ad esempio, la funzione di ripartizione esponenziale trovata in precedenza corrisponde alla legge di una variabile aleatoria esponenziale.\nReferences\nappunti prob-lez08.pdf\nAppunti Prob- lez08’.pdf"},"6--full-note/prob-lez09":{"slug":"6--full-note/prob-lez09","filePath":"6- full note/prob-lez09.md","title":"prob-lez09","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità","2--source-materials/Appunti-Prob---lez09.pdf","2--source-materials/appunti-bussetti-lez09.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-06 15:06\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine probabilità\nprob-lez09\n\nprob-lez09\nSpiegazione del Professore su Argomenti di Probabilità\nChiarimento sulla Dimostrazione del Teorema di Bayes\nIl professore inizia la lezione rispondendo a domande di studenti riguardo alla dimostrazione del Teorema di Bayes. Viene chiarito che la dimostrazione è stata effettivamente presentata durante la lezione precedente, quando si è discusso del teorema di Bayes per eventi.\nDimostrazione per Eventi e Forma Ridotta\nLa dimostrazione si basa sulla scrittura del teorema di Bayes nella sua forma ridotta per due eventi, H e E. Questa dimostrazione consiste nello scrivere la formula stessa del teorema.\nApplicazione della Proprietà delle Probabilità Totali\nIl secondo passaggio della dimostrazione implica l’applicazione di quella che è stata definita la proprietà delle probabilità totali o di disintegrazione al denominatore della formula di Bayes.\nSe H_i costituisce una partizione dello spazio campionario, allora la probabilità di un evento E può essere scritta come la somma delle probabilità condizionate di E dato H_i, moltiplicate per le probabilità di H_i:\nP(E) = \\sum_{i} P(E|H_i) P(H_i)\nIl professore sottolinea che la dimostrazione del teorema di Bayes è intrinsecamente legata alla forma delle probabilità totali.\nFunzione di Ripartizione\nSuccessivamente, l’argomento si sposta sulla funzione di ripartizione, associata a una variabile aleatoria. La funzione di ripartizione svolge un ruolo cruciale nella descrizione di tutte le misure di probabilità su \\mathbb{R} e delle leggi di qualunque variabile aleatoria a valori reali.\nCorrispondenza Biunivoca con le Misure di Probabilità\n\nEsiste una corrispondenza biunivoca tra le funzioni di ripartizione e le misure di probabilità sui boreliani di \\mathbb{R}. Data una funzione di ripartizione, è possibile costruire uno spazio di probabilità e una variabile aleatoria tale che la funzione di ripartizione di questa variabile aleatoria coincida con la funzione di ripartizione data.\nDimostrazione dell’Esistenza di una Variabile Aleatoria con Data Funzione di Ripartizione (Dimostrazione Facoltativa)\nIl professore presenta una dimostrazione facoltativa di questo fatto, sottolineando che mette in luce un aspetto importante, anche se a prima vista può sembrare tautologico.\nCostruzione Canonica\nLa costruzione canonica proposta è la seguente:\n\nSi prende lo spazio di partenza \\Omega uguale allo spazio d’arrivo \\mathbb{R}.\nSi definisce la variabile aleatoria X come la funzione identità su \\mathbb{R}, ovvero X(\\omega) = \\omega per ogni \\omega \\in \\mathbb{R}. Questa funzione è (chiaramente) misurabile.\nSi sceglie una misura di probabilità P su \\Omega = \\mathbb{R} (sui boreliani di \\mathbb{R}).\n\nScelta della Misura di Probabilità P_F\nSi assume l’esistenza di una misura P_F tale che le probabilità delle semirette (-\\infty, x] coincidano con la funzione di ripartizione F(x) data. Questo fatto è basato su una proposizione vista precedentemente.\nP_F((-\\infty, x]) = F(x)\nVerifica della Funzione di Ripartizione di X\nLa funzione di ripartizione della variabile aleatoria X (l’identità) è data da:\nF_X(x) = P\\set{ \\omega : X \\le x} = P\\set{\\omega \\in \\mathbb{R} : \\omega \\le x}\nPoiché P è scelta come P_F, si ha:\nF_X(x) = P_F((-\\infty, x]) = F(x)\nQuesto dimostra che esiste una variabile aleatoria (in questo caso l’identità su \\mathbb{R} con la misura P_F) la cui funzione di ripartizione è la funzione F data. Il professore ribadisce che questa non è l’unica possibile costruzione.\nFunzione Quantile (Inversa Generalizzata)\nIl professore introduce la funzione quantile, o inversa generalizzata, di una funzione di ripartizione F. Questa funzione, indicata come F^{-}(u), è definita come:\nF^{-}(u) = \\inf \\set{x \\in \\mathbb{R} : F(x) \\ge u }, \\quad u \\in (0, 1)\nCaso di Funzione di Ripartizione Invertibile\nIn particolare, se la funzione di ripartizione F è strettamente monotona (e quindi invertibile), l’inversa generalizzata coincide con la funzione inversa usuale F^{-1}(u).\nF^{-}(u) = F^{-1}(u)\nInterpretazione Intuitiva\n\nLa funzione quantile F^{-1}(u) (nel caso invertibile) rappresenta quel valore x tale per cui la probabilità che la variabile aleatoria sia minore o uguale a x è uguale a u:\nP(X \\le F^{-1}(u)) = F(F^{-1}(u)) = u\nIn termini statistici, F^{-1}(1/2) corrisponde alla mediana, ovvero quel valore che divide la distribuzione di probabilità in due parti uguali. Per un quantile di ordine p, F^{-1}(p) è il valore al di sotto del quale cade una proporzione p dei dati.\nGeneralizzazione per Funzioni Non Invertibili\n\n\nLa definizione con l’infimum serve a generalizzare il concetto di inversa anche a funzioni di ripartizione che non sono strettamente monotone, ovvero che presentano tratti piatti o salti. In questi casi, per un dato valore di u, potrebbe non esistere un unico x tale che F(x) = u. La definizione tramite l’infimum seleziona il più piccolo di tali x (o il punto iniziale del tratto in cui F(x) \\ge u).\nCostruzione di una Variabile Aleatoria con Legge Arbitraria a Partire da una Variabile Uniforme\nIl professore presenta un metodo per costruire una variabile aleatoria con una legge di probabilità arbitraria, purché si sappia costruire una variabile aleatoria con legge uniforme sull’intervallo (0, 1).\nTeorema di Trasformazione Inversa ?\nSia F una funzione di ripartizione e sia U una variabile aleatoria con legge uniforme su (0, 1) definita su uno spazio di probabilità (\\Omega, \\mathcal{F}, P). Si definisce una nuova variabile aleatoria X come:\nX = F^{-}(U)\n\n\ndove F^{-} è la funzione quantile (inversa generalizzata) di F.\nProprietà Fondamentale\nLa proprietà fondamentale di questa costruzione è che la variabile aleatoria X così definita ha proprio F come sua funzione di ripartizione:\nP(X \\le x) = F(x)\nDimostrazione nel Caso di F Invertibile\n\nIl professore fornisce la dimostrazione di questa proprietà nel caso in cui la funzione di ripartizione F sia strettamente monotona e quindi invertibile. In questo caso, F^{-}(u) = F^{-1}(u).\nP(X \\le x) = P(F^{-1}(U) \\le x)\nPoiché F è strettamente monotona crescente, anche la sua inversa F^{-1} è strettamente monotona crescente. Quindi l’ineguaglianza F^{-1}(U) \\le x è equivalente a U \\le F(x):\nP(F^{-1}(U) \\le x) = P(U \\le F(x))\nDato che U ha una distribuzione uniforme su (0, 1), la sua funzione di ripartizione F_U(u) è data da:\n\nF_U(u) = P(U \\le u) = \\begin{cases} 0 &amp; \\text{se } u &lt; 0 \\\\ u &amp; \\text{se } 0 \\le u \\le 1 \\\\ 1 &amp; \\text{se } u &gt; 1 \\end{cases}\nPoiché F(x) è sempre un valore compreso tra 0 e 1, si ha:\nP(U \\le F(x)) = F_U(F(x)) = F(x)\nQuindi, P(X \\le x) = F(x), dimostrando che la variabile aleatoria X = F^{-1}(U) ha funzione di ripartizione F.\nCollegamento con la Derivazione della Legge Esponenziale\nIl professore fa notare che il procedimento utilizzato per derivare la legge esponenziale a partire da una uniforme è un caso particolare di questa trasformazione inversa.\nEsercizio menzionato: Verificare che l’esercizio fatto per introdurre la legge esponenziale a partire dall’uniforme è esattamente questo conto nel caso particolare di una specifica F.\n\nVariabili Aleatorie Discrete\nDefinizione di Funzione di Ripartizione (Caso Generale)\nSi consideri una variabile aleatoria U. La funzione di ripartizione di U, calcolata in un punto f(x) (dove f(x) è un numero), è definita come la probabilità che la variabile aleatoria U assuma un valore minore o uguale a f(x). Formalmente:\nP(U \\le f(x)) = F_U(f(x))\nDove F_U è la funzione di ripartizione di U. Il valore f(x) è sempre compreso tra 0 e 1, poiché è il valore di una funzione di ripartizione.\nNel caso di una variabile aleatoria U con distribuzione uniforme sull’intervallo (0, 1), la sua funzione di ripartizione F_U(x) in un punto x compreso tra 0 e 1 è semplicemente x stesso.\nDefinizione di Funzione di Ripartizione per Vettori Aleatori\nSi può estendere la definizione di funzione di ripartizione a un vettore aleatorio X = (X_1, ..., X_d) a valori in \\mathbb{R}^d. La funzione di ripartizione del vettore aleatorio F_X(x_1, ..., x_d) è definita come la probabilità che ciascuna componente X_i sia minore o uguale al corrispondente valore x_i per ogni vettore x = (x_1, ..., x_d) \\in \\mathbb{R}^d:\nF_X(x_1, ..., x_d) = P(X_1 \\le x_1, X_2 \\le x_2, ..., X_d \\le x_d)\nDove la notazione con la virgola indica l’intersezione degli eventi.\nTuttavia, lo studio della teoria equivalente per le funzioni di ripartizione in più dimensioni è più complesso rispetto al caso unidimensionale. Pertanto, ci si concentra principalmente sui risultati ottenuti per variabili aleatorie a valori in \\mathbb{R}.\nVariabili Aleatorie Discrete: Definizione e Supporto\nUna variabile aleatoria X a valori in \\mathbb{R}^d è detta discreta se esiste un insieme numerabile C \\subseteq \\mathbb{R}^d (che è anche un insieme boreliano in quanto unione di punti) tale che la probabilità che X appartenga a C sia uguale a 1:\nP\\set{X \\in C} = 1\nL’insieme C è anche detto supporto della variabile aleatoria o insieme dei valori ammissibili. Questo significa che la variabile aleatoria X assume i suoi valori solo all’interno dell’insieme C, e la probabilità di assumere valori al di fuori di C è zero. È importante distinguere tra un evento impossibile (probabilità zero) e un evento che non si osserva mai nella realizzazione della variabile aleatoria.\nNel caso d=1, l’insieme C è un sottoinsieme numerabile di \\mathbb{R} e può essere rappresentato come una sequenza di punti \\set{x_1, x_2, ...}.\n\nProbabilità per Variabili Aleatorie Discrete\n\nPer una variabile aleatoria discreta X con supporto C, la probabilità che X appartenga a un qualsiasi sottoinsieme A \\subseteq \\mathbb{R}^d può essere calcolata considerando solo l’intersezione di A con il supporto C:\nP(X \\in A) = P(X \\in C \\cap A)\nQuesto perché la probabilità che X assuma valori al di fuori di C è zero.\nFunzione di Massa di Probabilità (PMF) o Densità Discreta\nPer una variabile aleatoria discreta X con supporto C = \\set{x_1, x_2, ...}, si definisce la funzione di massa di probabilità (PMF) p_i come la probabilità che X assuma il valore x_i:\np_i = P(X = x_i)\nLa PMF soddisfa le seguenti proprietà:\n\np_i \\ge 0 per ogni i\n\\sum_{i} p_i = 1\n\nLa collezione di questi valori {p_i} descrive completamente la legge o distribuzione della variabile aleatoria discreta X. La legge immagine di X è una misura discreta.\nA volte si usa la notazione p(x_i) o p_X(x_i) per indicare la probabilità che la variabile aleatoria X assuma il valore x_i.\nFunzione di Ripartizione di una Variabile Aleatoria Discreta\nLa funzione di ripartizione F_X(x) di una variabile aleatoria discreta X a valori in \\mathbb{R} è data dalla somma delle probabilità di tutti i valori x_i nel supporto C che sono minori o uguali a x:\nF_X(x) = P(X \\le x) = \\sum_{x_i \\in C: \\ \\ x_i \\le x} p_i\nLa funzione di ripartizione di una variabile aleatoria discreta è una funzione a gradini, costante a tratti e continua da destra, con salti in corrispondenza dei punti del supporto C. L’altezza del salto in un punto x_i \\in C è pari alla probabilità p_i = P(X = x_i).\n\nVettori Aleatori Discreti e Funzione di Ripartizione\nLa definizione di variabile aleatoria discreta si estende ai vettori aleatori X = (X_1, ..., X_d) a valori in \\mathbb{R}^d. Se esiste un insieme numerabile C \\subseteq \\mathbb{R}^d tale che P(X \\in C) = 1, allora X è un vettore aleatorio discreto.\nLa funzione di ripartizione di un vettore aleatorio discreto X è ancora definita come:\n\\begin{aligned}F_X(x_1, ..., x_d) = \\\\ \\\\ P(X_1 \\le x_1, ..., X_d \\le x_d) \\\\ \\\\ \\sum_{\\begin{aligned}x = (x_1&#039;, ..., x_d&#039;) \\in C:\\\\ x_1&#039; \\le x_1, ..., x_d&#039; \\le x_d \\end{aligned}} p(x_1&#039;, ..., x_d&#039;)\\end{aligned}\nDove p(x_1&#039;, ..., x_d&#039;) = P(X_1 = x_1&#039;, ..., X_d = x_d&#039;) è la funzione di massa di probabilità congiunta del vettore aleatorio discreto.\nA volte, per comodità, si può considerare che il supporto C sia un prodotto cartesiano di insiemi numerabili C_1 \\times ... \\times C_d, anche se alcuni punti nel prodotto cartesiano potrebbero avere probabilità zero.\nDistribuzioni Marginali di Vettori Aleatori Discreti\n\nSe X = (X_1, ..., X_d) è un vettore aleatorio discreto con supporto C \\subseteq \\mathbb{R}^d e funzione di massa di probabilità congiunta p(x_1, ..., x_d), allora ogni componente X_i è anch’essa una variabile aleatoria discreta.\nLa funzione di massa di probabilità marginale di X_i, p_{X_i}(x_i), si ottiene marginalizzando (sommando) la funzione di massa di probabilità congiunta su tutti i possibili valori delle altre componenti:\np_{X_i}(x_i) = P(X_i = x_i) = \\sum_{(x_1, ..., x_{i-1}, x_{i+1}, ..., x_d) \\in C_{-i}} p(x_1, ..., x_{i-1}, x_i, x_{i+1}, ..., x_d)\nDove C_{-i} rappresenta l’insieme dei possibili valori delle componenti diverse da X_i nel supporto C.\nEsempio in due dimensioni (d=2): Sia X = (X_1, X_2) un vettore aleatorio discreto con supporto C = {(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3)} e una distribuzione uniforme su questi quattro punti (correzione dell’esempio del professore), quindi P(X = (x_1, x_2)) = 1/4 per (x_1, x_2) \\in {(1, 1), (1, 2), (2, 1), (2, 2)} e 0 altrove.\nLa funzione di massa di probabilità marginale di X_1 è:\np_{X_1}(1) = P(X_1 = 1) = P(X_1 = 1, X_2 = 1) + P(X_1 = 1, X_2 = 2) + P(X_1 = 1, X_2 = 3) = p(1, 1) + p(1, 2) + p(1, 3) = 1/4 + 1/4 + 0 = 1/2\np_{X_1}(2) = P(X_1 = 2) = P(X_1 = 2, X_2 = 1) + P(X_1 = 2, X_2 = 2) + P(X_1 = 2, X_2 = 3) = p(2, 1) + p(2, 2) + p(2, 3) = 1/4 + 1/4 + 0 = 1/2\np_{X_1}(x_1) = 0 per x_1 \\notin {1, 2}\nLa funzione di massa di probabilità marginale di X_2 è:\np_{X_2}(1) = P(X_2 = 1) = P(X_1 = 1, X_2 = 1) + P(X_1 = 2, X_2 = 1) = p(1, 1) + p(2, 1) = 1/4 + 1/4 = 1/2\np_{X_2}(2) = P(X_2 = 2) = P(X_1 = 1, X_2 = 2) + P(X_1 = 2, X_2 = 2) = p(1, 2) + p(2, 2) = 1/4 + 1/4 = 1/2\np_{X_2}(3) = P(X_2 = 3) = P(X_1 = 1, X_2 = 3) + P(X_1 = 2, X_2 = 3) = p(1, 3) + p(2, 3) = 0 + 0 = 0\np_{X_2}(x_2) = 0 per x_2 \\notin {1, 2, 3}\nIl professore introduce la notazione con la virgola per indicare l’intersezione di eventi, ad esempio P(X_1 = 1, X_2 = 1) invece di P(X_1 = 1 \\cap X_2 = 1).\nConclusioni\nSe si ha un vettore aleatorio discreto, allora tutti i suoi sottovettori, incluse le singole componenti, sono anch’essi variabili aleatorie discrete. La legge (distribuzione) di un vettore aleatorio discreto determina completamente la legge di tutte le sue distribuzioni marginali.\n\nVariabili Aleatorie Discrete e Valore Atteso\nDensità di Probabilità Congiunta per Vettori Discreti\nConsideriamo un vettore aleatorio (X_1, X_2) dove X_1 assume valori in un insieme finito C_1 e X_2 assume valori in un insieme finito C_2. La densità di probabilità congiunta del vettore (X_1, X_2) è una funzione P(x_1, x_2) che rappresenta la probabilità che X_1 = x_1 e X_2 = x_2, dove x_1 \\in C_1 e x_2 \\in C_2. Questa densità può essere rappresentata tramite una tabella di contingenza.\nAd esempio, se C_1 = {1, 3, 4} e C_2 = {1, 2, 3}, la tabella di contingenza conterrà le probabilità P(x_1, x_2) per ogni coppia (x_1, x_2).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX_2 \\setminus X_113411/400201/41/4301/40\nDa questa tabella, possiamo leggere diverse informazioni, come il supporto di X_1 e X_2 e la probabilità di ogni combinazione di valori. Ad esempio, la probabilità che X_1 = 3 e X_2 = 2 è P(3, 2) = 1/4. La probabilità che X_1 = 2 e X_2 = 1 è P(2, 1) = 0.\nDensità di Probabilità Marginale\nA partire dalla densità di probabilità congiunta, è possibile ricavare le densità di probabilità marginali delle singole componenti. La densità marginale di X_1, P_{X_1}(x_1), si ottiene sommando la densità congiunta su tutti i possibili valori di X_2:\nP_{X_1}(x_1) = \\sum_{x_2 \\in C_2} P(x_1, x_2)\nAnalogamente, la densità marginale di X_2, P_{X_2}(x_2), si ottiene sommando la densità congiunta su tutti i possibili valori di X_1:\nP_{X_2}(x_2) = \\sum_{x_1 \\in C_1} P(x_1, x_2)\nNell’esempio precedente, la densità marginale di X_1 è: P_{X_1}(1) = P(1, 1) + P(1, 2) + P(1, 3) = 1/4 + 0 + 0 = 1/4 P_{X_1}(3) = P(3, 1) + P(3, 2) + P(3, 3) = 0 + 1/4 + 1/4 = 1/2 P_{X_1}(4) = P(4, 1) + P(4, 2) + P(4, 3) = 0 + 1/4 + 0 = 1/4\nE la densità marginale di X_2 è: P_{X_2}(1) = P(1, 1) + P(3, 1) + P(4, 1) = 1/4 + 0 + 0 = 1/4 P_{X_2}(2) = P(1, 2) + P(3, 2) + P(4, 2) = 0 + 1/4 + 1/4 = 1/2 P_{X_2}(3) = P(1, 3) + P(3, 3) + P(4, 3) = 0 + 1/4 + 0 = 1/4\nQueste marginali possono essere aggiunte alla tabella di contingenza.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX_2 \\setminus X_1134P_{X_2}(x_2)11/4001/4201/41/41/2301/401/4P_{X_1}(x_1)1/41/21/41\nQuesto processo di ricavare le densità marginali dalla densità congiunta è chiamato marginalizzazione.\nRelazione tra Densità Congiunta e Marginali\nImportante: La densità congiunta determina univocamente le densità marginali, ma il viceversa non è vero. Date le densità marginali di X_1 e X_2, non è possibile ricostruire un’unica densità congiunta. Possono esistere diverse densità congiunte che producono le stesse marginali.\nAd esempio, कंसीडर la seguente tabella con la stessa marginali dell’esempio precedente:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX_2 \\setminus X_113411/161/81/1623/162/8 = 4/163/16302/8 = 4/160\n(Nota: il professore ha ammesso un errore nei suoi calcoli nell’esempio a lezione).\nQuesta tabella ha le stesse marginali dell’esempio precedente (verificabile sommando righe e colonne), ma la densità congiunta è diversa. Questo dimostra che la conoscenza delle sole marginali non è sufficiente per determinare la densità congiunta.\nValore Atteso di una Variabile Aleatoria Discreta\nSia X una variabile aleatoria discreta che assume valori in un insieme finito o numerabile C, con densità di probabilità discreta (o funzione di massa di probabilità) p_X(x) = P(X = x) per x \\in C.\nIl valore atteso (o speranza matematica, valor medio, media) di X, denotato con E[X] o \\mu, è definito come la somma (o serie):\nE[X] = \\sum_{x \\in C} x \\cdot p_X(x)\nCondizione di Esistenza: Il valore atteso è definito solo se la seguente somma converge assolutamente:\n\\sum_{x \\in C} |x| \\cdot p_X(x) &lt; \\infty\nSe questa condizione non è soddisfatta (ovvero la somma diverge a +\\infty), allora il valore atteso non è ben definito. Nel caso in cui C sia un insieme finito, questa somma è sempre convergente. Se C è infinito, è necessario verificare la convergenza assoluta. Questa condizione garantisce che la somma che definisce il valore atteso non dipenda dall’ordine in cui i termini vengono sommati.\nInterpretazione del Valore Atteso: Il valore atteso può essere interpretato come una sorta di baricentro dei valori che la variabile aleatoria può assumere, pesati dalle rispettive probabilità. In una dimensione, immagina dei punti sulla retta reale con delle masse corrispondenti alle loro probabilità; il valore atteso è la posizione del centro di massa.\nIl Valore Atteso Dipende dalla Legge Immagine: Tecnicamente, il valore atteso è definito a partire dalla variabile aleatoria X e dallo spazio di probabilità (\\Omega, \\mathcal{F}, P) su cui è definita. Tuttavia, il suo valore dipende esclusivamente dalla legge immagine (o distribuzione di probabilità) di X sullo spazio di arrivo (in questo caso, \\mathbb{R}).\nSe due variabili aleatorie discrete, definite anche su spazi di probabilità diversi, hanno la stessa legge immagine (cioè la stessa densità di probabilità discreta), allora avranno lo stesso valore atteso.\nEsempio 1: Distribuzione di Poisson\nSi consideri una variabile aleatoria X che assume valori negli interi non negativi N = {0, 1, 2, ...}. La probabilità che X = k è data dalla distribuzione di Poisson con parametro \\lambda &gt; 0:\nP(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}, per k \\in N\nVerifica che sia una densità di probabilità: La somma delle probabilità su tutti i possibili valori di k deve essere uguale a 1:\n\\sum_{k=0}^{\\infty} P(X = k) = \\sum_{k=0}^{\\infty} \\frac{\\lambda^k e^{-\\lambda}}{k!} = e^{-\\lambda} \\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!}\nRicordando l’espansione in serie di Taylor della funzione esponenziale e^x = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!}, abbiamo:\n\\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!} = e^{\\lambda}\nQuindi, \\sum_{k=0}^{\\infty} P(X = k) = e^{-\\lambda} \\cdot e^{\\lambda} = 1. Inoltre, P(X = k) \\ge 0 per ogni k \\in N e \\lambda &gt; 0.\nEsercizi:\n\n\nCalcolare la probabilità che X sia maggiore stretto di 1, i.e., P(X &gt; 1). P(X &gt; 1) = 1 - P(X \\le 1) = 1 - [P(X = 0) + P(X = 1)] P(X = 0) = \\frac{\\lambda^0 e^{-\\lambda}}{0!} = e^{-\\lambda} P(X = 1) = \\frac{\\lambda^1 e^{-\\lambda}}{1!} = \\lambda e^{-\\lambda} Pertanto, P(X &gt; 1) = 1 - (e^{-\\lambda} + \\lambda e^{-\\lambda}) = 1 - e^{-\\lambda}(1 + \\lambda).\n\n\nCalcolare il valore atteso di X, E[X], usando la definizione. E[X] = \\sum_{k=0}^{\\infty} k \\cdot P(X = k) = \\sum_{k=0}^{\\infty} k \\cdot \\frac{\\lambda^k e^{-\\lambda}}{k!} Notiamo che per k = 0, il termine è 0 \\cdot \\frac{\\lambda^0 e^{-\\lambda}}{0!} = 0. Possiamo quindi iniziare la somma da k = 1: E[X] = \\sum_{k=1}^{\\infty} k \\cdot \\frac{\\lambda^k e^{-\\lambda}}{k!} = \\sum_{k=1}^{\\infty} \\frac{k}{k!} \\lambda^k e^{-\\lambda} = \\sum_{k=1}^{\\infty} \\frac{1}{(k-1)!} \\lambda^k e^{-\\lambda} Facciamo un cambio di indice, ponendo j = k - 1, quindi k = j + 1. Quando k = 1, j = 0. La somma diventa: E[X] = \\sum_{j=0}^{\\infty} \\frac{1}{j!} \\lambda^{j+1} e^{-\\lambda} = \\lambda e^{-\\lambda} \\sum_{j=0}^{\\infty} \\frac{\\lambda^j}{j!} = \\lambda e^{-\\lambda} \\cdot e^{\\lambda} = \\lambda Quindi, il valore atteso di una variabile aleatoria di Poisson con parametro \\lambda è \\lambda.\n\n\nEsempio 2: Variabili Aleatorie con la Stessa Legge Immagine\nConsideriamo due spazi di probabilità diversi:\n\n\n(\\Omega_1, \\mathcal{F}_1, P_1) dove \\Omega_1 = {1, 2, 3, 4, 5, 6}, \\mathcal{F}_1 è la famiglia di tutti i sottoinsiemi di \\Omega_1, e P_1({\\omega}) = 1/6 per ogni \\omega \\in \\Omega_1 (modello di un dado equilibrato). Definiamo una variabile aleatoria X_1: \\Omega_1 \\rightarrow {0, 1} come l’indicatore dell’evento {\\omega \\in \\Omega_1 : \\omega \\le 3}: X_1(\\omega) = 1 se \\omega \\in {1, 2, 3} X_1(\\omega) = 0 se \\omega \\in {4, 5, 6} La legge di probabilità di X_1 è: P(X_1 = 1) = P_1({1, 2, 3}) = P_1({1}) + P_1({2}) + P_1({3}) = 1/6 + 1/6 + 1/6 = 3/6 = 1/2 P(X_1 = 0) = P_1({4, 5, 6}) = P_1({4}) + P_1({5}) + P_1({6}) = 1/6 + 1/6 + 1/6 = 3/6 = 1/2\n\n\n(\\Omega_2, \\mathcal{F}_2, P_2) dove \\Omega_2 =, \\mathcal{F}_2 è la \\sigma-algebra dei Boreliani di , e P_2 è la misura di Lebesgue ristretta a . Definiamo una variabile aleatoria X_2: \\Omega_2 \\rightarrow {0, 1} come: X_2(\\omega) = 1 se \\omega \\in [0, 1/2) X_2(\\omega) = 0 se \\omega \\in [1/2, 1] La legge di probabilità di X_2 è: P(X_2 = 1) = P_2([0, 1/2)) = 1/2 - 0 = 1/2 P(X_2 = 0) = P_2([1/2, 1]) = 1 - 1/2 = 1/2\n\n\nEntrambe le variabili aleatorie X_1 e X_2 assumono gli stessi valori {0, 1} con le stesse probabilità (legge immagine identica), anche se sono definite su spazi di probabilità (\\Omega, \\mathcal{F}, P) diversi.\nCalcolo del Valore Atteso:\nE[X_1] = \\sum_{x \\in {0, 1}} x \\cdot P(X_1 = x) = 0 \\cdot P(X_1 = 0) + 1 \\cdot P(X_1 = 1) = 0 \\cdot (1/2) + 1 \\cdot (1/2) = 1/2\nE[X_2] = \\sum_{x \\in {0, 1}} x \\cdot P(X_2 = x) = 0 \\cdot P(X_2 = 0) + 1 \\cdot P(X_2 = 1) = 0 \\cdot (1/2) + 1 \\cdot (1/2) = 1/2\nCome si vede, E[X_1] = E[X_2], il che dimostra che il valore atteso dipende unicamente dalla legge immagine della variabile aleatoria e non dallo specifico spazio di probabilità su cui è definita.\n\nReferences\nAppunti Prob - lez09.pdf\nappunti bussetti-lez09.pdf"},"6--full-note/prob-lez10":{"slug":"6--full-note/prob-lez10","filePath":"6- full note/prob-lez10.md","title":"prob-lez10","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","2--source-materials/appunti-bussetti--lez10.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-20 16:17\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nprob-lez10\nVariabili Aleatorie Discrete e Valore Atteso\nIntroduzione alle Variabili Aleatorie Discrete\nIl professore introduce l’argomento delle variabili aleatorie discrete, spiegando che spesso si userà una notazione come X \\sim qualche nome per indicare che la variabile aleatoria X è distribuita secondo una certa legge.\nVariabile Aleatoria di Poisson\nUn primo esempio è la variabile aleatoria di Poisson.\n\nNotazione: X \\sim Pois(\\lambda), dove \\lambda &gt; 0 è un parametro fissato.\nDefinizione: Una variabile aleatoria X è di Poisson , siccome è discreta sapppiamo che  la possiamo completamente caratterizzare con la sua densità (o funzione di probabilità) data da: P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}, per k = 0, 1, 2, \\dots\nSpazio di Probabilità: Il professore sottolinea che per essere rigorosi, si dovrebbe definire X su uno spazio di probabilità (\\Omega, \\mathcal{F}, P) a valori in \\mathbb{R} discreto (\\Omega, \\mathcal{F}, P) \\to (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}). La densità data rappresenta la legge immagine di P tramite X. Nella maggior parte dei casi, ci si concentrerà sullo spazio di arrivo della variabile aleatoria.\nSupporto: La densità è positiva per valori interi maggiori o uguali a zero e implicitamente vale zero al di fuori di questi valori.\n\nEsercizio sul Valore Atteso della Poisson\nIl professore propone di calcolare il valore atteso di una variabile aleatoria di Poisson. La definizione del valore atteso per una variabile aleatoria discreta X è E[X] = \\sum_{x} x P(X=x), dove la somma è estesa a tutti i possibili valori di X, purché \\sum_{x} |x| P(X=x) &lt; \\infty (convergenza assoluta).\nNel caso della Poisson, i valori possibili sono k \\ge 0, quindi il valore atteso è: E[X] = \\sum_{k=0}^{\\infty} k \\frac{\\lambda^k e^{-\\lambda}}{k!}\nOsservando che per k=0 il termine è zero, la somma può iniziare da k=1: E[X] = \\sum_{k=1}^{\\infty} k \\frac{\\lambda^k e^{-\\lambda}}{k!} = \\sum_{k=1}^{\\infty} \\frac{\\lambda^k e^{-\\lambda}}{(k-1)!}\nSi può riscrivere \\lambda^k come \\lambda \\cdot \\lambda^{k-1}: E[X] = \\sum_{k=1}^{\\infty} \\lambda \\frac{\\lambda^{k-1} e^{-\\lambda}}{(k-1)!} = \\lambda \\sum_{k=1}^{\\infty} \\frac{\\lambda^{k-1} e^{-\\lambda}}{(k-1)!}\nEffettuando un cambio di variabile, ponendo j = k-1, quando k=1 si ha j=0, e la somma diventa: E[X] = \\lambda \\sum_{j=0}^{\\infty} \\frac{\\lambda^{j} e^{-\\lambda}}{j!}\nSi riconosce che la somma \\sum_{j=0}^{\\infty} \\frac{\\lambda^{j} e^{-\\lambda}}{j!} è la somma delle probabilità di tutti i possibili valori di una variabile aleatoria di Poisson con parametro \\lambda, che è uguale a 1. Pertanto, il valore atteso di una variabile aleatoria di Poisson è: E[X] = \\lambda \\cdot 1 = \\lambda\nIl professore conclude che la media di una variabile aleatoria di Poisson è \\lambda.\nVariabile Aleatoria Binomiale\nUn altro esempio di variabile aleatoria discreta è la variabile aleatoria binomiale con parametri n \\in \\mathbb{N} e p \\in [0,1]\n\nNotazione: X \\sim Bin(n, p).\nDefinizione: La variabile aleatoria X può assumere valori k \\in {0, 1, 2, \\dots, n} con probabilità: P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}\nInterpretazione: Una variabile binomiale può essere pensata come il numero di successi in n prove di Bernoulli indipendenti, ognuna con probabilità di successo p.\nEsercizio: Il professore propone come esercizio il calcolo del valore atteso di una variabile binomiale, anticipando che risulterà essere np, e che questo risultato verrà ripreso in seguito come esempio di una proprietà del valore atteso.\n\nVariabile Aleatoria Geometrica\nIl terzo esempio è la legge geometrica. Questa viene introdotta partendo da un modello probabilistico.\n\nModello: Si consideri una successione infinita di eventi indipendenti E_1, E_2, \\dots tutti con la stessa probabilità P(E_i) = p di verificarsi.\nDefinizione della Variabile Aleatoria: Sia X la variabile aleatoria che rappresenta il più piccolo indice K tale che i primi K-1 eventi non si sono verificati e l’evento K-esimo si è verificato. In termini di “guasti”, X=K significa che il primo guasto avviene al tempo K.\nSupporto: La variabile aleatoria X assume valori in {1, 2, 3, \\dots} (è discreta)\nProbabilità: La probabilità che X sia uguale a K è data da: P(X=k) = P(E_1^c \\cap E_2^c \\cap \\dots \\cap E_{k-1}^c \\cap E_k) A causa dell’indipendenza degli eventi, questa probabilità si fattorizza come: P(X=k) = P(E_1^c) P(E_2^c) \\dots P(E_{k-1}^c) P(E_k) = (1-p)^{k-1} p\nDefinizione Formale: Una variabile aleatoria discreta con questa densità di probabilità è detta geometrica di parametro p.\n\nLa Funzione Indicatrice e il suo Valore Atteso\nIl professore introduce la funzione indicatrice di un insieme A, definita come: I_A(\\omega) = \\begin{cases} 1 &amp; \\text{se } \\omega \\in A \\\\ 0 &amp; \\text{se } \\omega \\notin A \\end{cases}\nA volte, per comodità, soprattutto quando l’insieme A è definito da una condizione che coinvolge una variabile aleatoria, si userà una notazione del tipo I_{\\set{X \\in B}} o semplicemente I(X \\in B).\nValore Atteso di una Funzione Indicatrice\nConsiderando una variabile aleatoria X = I_A, che può assumere solo i valori 0 e 1, il suo valore atteso è: E[X] = \\sum_{x} x P(X=x) = 0 \\cdot P(X=0) + 1 \\cdot P(X=1)\n\nSi ha che P(X=1) = P({\\omega : I_A(\\omega) = 1}) = P(A) e P(X=0) = P({\\omega : I_A(\\omega) = 0}) = P(A^c). Pertanto, il valore atteso di una funzione indicatrice è la probabilità dell’evento che essa indica: E[I_A] = P(A)\nIn particolare, se si considera una variabile aleatoria Z (invece di X per evitare confusione) definita su uno spazio di probabilità e un insieme B nello spazio di arrivo di Z, la variabile aleatoria Y = I_{{Z \\in B}} è una funzione indicatrice. Il suo valore atteso è la probabilità dell’evento {Z \\in B}: E[I_{{Z \\in B}}] = P(Z \\in B)\nQuesta proprietà verrà utilizzata frequentemente.\nTrasformazione di Variabili Aleatorie e Valore Atteso di g(X)\nCaso Semplice Iniziale e Motivazione\nIl professore inizia con un riferimento a un caso precedente, accennando alla differenza tra “sopra” e “sotto” e alla probabilità di un evento Z \\in B che può assumere solo valori 0 o 1.\nPoi introduce l’idea di trasformare una variabile aleatoria Z attraverso una funzione e calcolare il valore atteso della nuova variabile aleatoria ottenuta. Per generalizzare, introduce una variabile aleatoria X (discreta) con il suo supporto C_X e la sua funzione di probabilità p_X. Considera una funzione borelliana misurabile g: \\mathbb{R} \\rightarrow \\mathbb{R}.\n\nSi definisce una nuova variabile aleatoria Y = g(X). L’obiettivo è calcolare il valore atteso di Y, ovvero E[Y] = E[g(X)].\nDefinizione del Valore Atteso di Y = g(X)\nLa definizione del valore atteso di Y viene data come la somma sui possibili valori di Y, moltiplicati per la loro probabilità:\nE[Y] = \\sum_{y \\in C_Y} y \\cdot P(Y = y)\n\ndove C_Y è l’insieme dei valori che Y può assumere.\nOsservazione Importante: l’immagine di un insieme numerabile è al più un insieme numerabile tramite una funzione.\nIl professore sottolinea che se X è discreta, anche Y = g(X) è discreta. L’insieme dei valori che Y assume C_y è dato da {y \\in \\mathbb{R} \\mid \\exists x \\in C_X \\text{ tale che } y = g(x) }, e questo insieme ha probabilità 1.\n\nCostruzione di un’Espressione Alternativa per E[g(X)] (Proprietà Fondamentale)\nIl professore presenta un’espressione alternativa per calcolare E[g(X)] che è spesso più utile nella pratica:\nE[g(X)] = \\sum_{x \\in C_X} g(x) \\cdot P(X = x)\n\nImportante: Il professore insiste che questa non è la definizione di valore atteso di g(X), ma una proprietà. La definizione è quella basata sulla legge di probabilità di Y = g(X).\nDimostrazione della Proprietà (per g \\ge 0)\nPer semplificare la dimostrazione, si assume inizialmente che g(x) \\ge 0. Il valore atteso di Y = g(X) per definizione è:\nE[Y] = \\sum_{y \\in C_Y} y \\cdot P(Y = y)\nSi sostituisce Y = g(X):\nE[g(X)] = \\sum_{y \\in C_Y} y \\cdot P(g(X) = y)\nLa probabilità P(g(X) = y) è la probabilità dell’unione di tutti gli eventi {X = x} tali che g(x) = y:\nP(g(X) = y) = P\\left( \\bigcup_{x \\in C_X: g(x) = y} {X = x} \\right)\nPoiché gli eventi {X = x} per diversi valori di x sono disgiunti, la probabilità dell’unione è la somma delle probabilità:\nP(g(X) = y) = \\sum_{x \\in C_X: g(x) = y} P(X = x)\nSostituendo questa espressione nella formula per il valore atteso:\nE[g(X)] = \\sum_{y \\in C_Y} y \\cdot \\left( \\sum_{x \\in C_X: g(x) = y} P(X = x) \\right)\nOra si inverte l’ordine delle somme:\nE[g(X)] = \\sum_{x \\in C_X} \\left( \\sum_{y \\in C_Y: y = g(x)} y \\cdot P(X = x) \\right)\nDato che per ogni x fissato, y = g(x) è un valore unico perché g è una funzione, la somma interna si riduce a:\nE[g(X)] = \\sum_{x \\in C_X} g(x) \\cdot P(X = x)\n\nQuesta dimostrazione, inizialmente fatta per g(x) \\ge 0, può essere estesa al caso generale considerando g(x) = g^+(x) - g^-(x), dove g^+ e g^- sono le parti positiva e negativa di g, e richiedendo che E[|g(X)|] &lt; \\infty (cioè che la somma \\sum_{x \\in C_X} |g(x)| P(X = x) converge).\nProprietà del Valore Atteso\nIl professore introduce alcune proprietà importanti del valore atteso per variabili aleatorie discrete:\nLinearità\nSe a, b \\in \\mathbb{R} e X_1, X_2 sono variabili aleatorie discrete tali che E[|X_1|] &lt; \\infty e E[|X_2|] &lt; \\infty (ovvero le rispettive serie convergono assolutamente),\n \nallora il valore atteso della combinazione lineare aX_1 + bX_2 è ben definito e vale:\nE[aX_1 + bX_2] = aE[X_1] + bE[X_2]\nMonotonia\nSe una variabile aleatoria discreta X è tale che P(X \\le a) = 1, allora il suo valore atteso è minore o uguale ad a:\nSe P(X \\le a) = 1 \\implies E[X] \\le a\nCome conseguenza, se due variabili aleatorie discrete X_1 e X_2 soddisfano P(X_1 \\le X_2) = 1 e i loro valori attesi sono finiti, allora:\nE[X_1] \\le E[X_2]\nDisuguaglianza del Valore Assoluto\nIl modulo del valore atteso di una variabile aleatoria discreta X è minore o uguale al valore atteso del suo modulo:\n|E[X]| \\le E[|X|]\nQuesta è una conseguenza della proprietà di monotonia.\nSe una serie dei moduli è assolutamente convergente, cioè se \\sum_{n} |a_n| converge, allora il modulo della serie è minore o uguale alla serie dei moduli:\n|\\sum_{n} a_n| \\le \\sum_{n} |a_n|\nIl professore conclude sottolineando l’importanza di comprendere la distinzione tra la definizione del valore atteso di g(X) e la proprietà che permette di calcolarlo direttamente sulla distribuzione di X.\nesempio specifico nel contesto di variabili aleatorie discrete non negative.\nLinearità del Valore Atteso per Variabili Discrete Non Negative\nL’obiettivo è mostrare che, date due variabili aleatorie discrete x_1 e x_2 tali che x_1 \\ge 0 e x_2 \\ge 0, il valore atteso della loro somma è uguale alla somma dei loro valori attesi:\nE[x_1 + x_2] = E[x_1] + E[x_2]\nPer dimostrarlo, si parte dalla definizione del valore atteso di una funzione di un vettore aleatorio discreto. Se abbiamo un vettore aleatorio discreto (X_1, X_2) con densità congiunta P(x_1, x_2), il valore atteso di una funzione g(X_1, X_2) è dato da:\nE[g(X_1, X_2)] = \\sum_{x_1, x_2} g(x_1, x_2) P(x_1, x_2)\nNel nostro caso, g(x_1, x_2) = x_1 + x_2, quindi:\nE[x_1 + x_2] = \\sum_{x_1, x_2} (x_1 + x_2) P(x_1, x_2)\nAssumendo che la serie \\sum_{x_1, x_2} |(x_1 + x_2) P(x_1, x_2)| sia convergente (il professore menziona l’assoluta convergenza), possiamo separare la somma:\n\nE[x_1 + x_2] = \\sum_{x_1, x_2} x_1 P(x_1, x_2) + \\sum_{x_1, x_2} x_2 P(x_1, x_2)\nRiscrivendo le somme, portando fuori i termini che non dipendono dall’indice di sommazione interno:\nE[x_1 + x_2] = \\sum_{x_1} x_1 \\left( \\sum_{x_2} P(x_1, x_2) \\right) + \\sum_{x_2} x_2 \\left( \\sum_{x_1} P(x_1, x_2) \\right)\nLe somme interne rappresentano le densità marginali di x_1 e x_2 rispettivamente:\nP_{X_1}(x_1) = \\sum_{x_2} P(x_1, x_2)\nP_{X_2}(x_2) = \\sum_{x_1} P(x_1, x_2)\nSostituendo le densità marginali nell’espressione per il valore atteso:\nE[x_1 + x_2] = \\sum_{x_1} x_1 P_{X_1}(x_1) + \\sum_{x_2} x_2 P_{X_2}(x_2)\nQueste due somme sono per definizione il valore atteso di x_1 e il valore atteso di x_2:\nE[x_1 + x_2] = E[x_1] + E[x_2]\n\nIl professore sottolinea che questa dimostrazione è stata fornita in un caso particolare (x_1 \\ge 0, x_2 \\ge 0) per illustrare come la linearità del valore atteso discende dalla formula generale per il valore atteso di una funzione di un vettore aleatorio discreto. Le proprietà fondamentali introdotte sono la linearità e la monotonia del valore atteso.\nEstensione a Variabili Aleatorie Generali\nIl professore introduce la questione di come definire il valore atteso per variabili aleatorie non discrete. Egli anticipa che l’approccio in questo caso è più complesso e si basa sulla teoria della misura.\nSpazio Reale Esteso \\overline{\\mathbb{R}}\nViene anche menzionata la possibilità di considerare variabili aleatorie che possono assumere valori in \\overline{\\mathbb{R}} = \\mathbb{R} \\cup \\set{-\\infty, +\\infty}. Per fare ciò, è necessario definire una sigma algebra su questo spazio. La sigma algebra considerata è la più piccola sigma algebra che contiene sia la sigma algebra di Borel su \\mathbb{R} (\\mathcal{B}(\\mathbb{R})) che gli insiemi {-\\infty} e {+\\infty}. Questa viene chiamata la sigma algebra di Borel sulla retta estesa, \\mathcal{B}(\\overline{\\mathbb{R}}).\nUn insieme A \\in \\mathcal{B}(\\overline{\\mathbb{R}}) può essere scritto nella forma A = \\tilde{A} \\cup \\Delta, dove \\tilde{A} \\in \\mathcal{B}(\\mathbb{R}) e \\Delta è uno dei seguenti insiemi: \\set{\\emptyset}, \\set{-\\infty}, \\set{+\\infty}, \\set{-\\infty, +\\infty}.\nIl professore avverte che le proprietà della funzione di ripartizione (CDF) definite precedentemente valgono solo per variabili aleatorie a valori reali e non si estendono direttamente al caso di variabili aleatorie a valori nella retta estesa. Ad esempio, \\lim_{x \\to -\\infty} F_X(x) = 0 si basa sul fatto che P(X = -\\infty) = 0 per variabili reali.\n\nIntroduzione all’Integrale Rispetto a una Misura\nIl professore inizia a introdurre il concetto di integrale di una funzione misurabile rispetto a una misura. Consideriamo uno spazio misurabile (E, \\mathcal{E}) e una misura \\mu su di esso. Sia \\xi: E \\to \\overline{\\mathbb{R}} una funzione misurabile. L’integrale di \\xi rispetto a \\mu viene indicato con la notazione:\n\\int_E \\xi d\\mu \\quad \\text{oppure} \\quad \\int X d\\mu\nIl professore spiega che questa definizione astratta sarà applicata in tre contesti principali:\n\nIntegrale di Lebesgue: E = \\mathbb{R}^d, \\mathcal{E} = \\mathcal{B}(\\mathbb{R}^d), e \\mu è la misura di Lebesgue su \\mathbb{R}^d.\nValore Atteso: E = \\Omega (spazio di probabilità), \\mathcal{E} = \\mathcal{F} (sigma algebra degli eventi), e \\mu = P (misura di probabilità). In questo caso, se \\xi è una variabile aleatoria, l’integrale \\int_\\Omega \\xi dP rappresenta il valore atteso di \\xi, E[X].\nCambio di Variabili: E = \\mathbb{R}^d, \\mathcal{E} = \\mathcal{B}(\\mathbb{R}^d), e \\mu è la misura immagine di un vettore aleatorio \\xi. L’integrale di una funzione di \\xi, f(\\xi), potrà essere espresso come un integrale rispetto alla misura immagine.\n\n\nDefinizione dell’Integrale per Funzioni Semplici Positive\nPer iniziare a costruire la definizione generale dell’integrale, il professore introduce le funzioni semplici positive in forma canonica.\nFunzioni Semplici Positive in Forma Canonica\nUna funzione S: E \\to [0, +\\infty) è detta semplice positiva in forma canonica se esistono un numero finito m \\in \\mathbb{N}, costanti c_i \\ge 0 per i = 1, \\dots, m, e insiemi misurabili A_i \\in \\mathcal{E} tali che:\n\nA_i \\cap A_j = \\emptyset per i \\neq j (gli insiemi formano una partizione).\n\\bigcup_{i=1}^m A_i = E (gli insiemi coprono tutto lo spazio).\nS(x) = \\sum_{i=1}^m c_i \\mathbb{1}_{A_i}(x), dove \\mathbb{1}_{A_i}(x) è la funzione indicatrice dell’insieme A_i (vale 1 se x \\in A_i e 0 altrimenti).\n\nUna funzione semplice è misurabile perché è una combinazione lineare di funzioni indicatrici di insiemi misurabili.\n\nDefinizione dell’Integrale per Funzioni Semplici Positive\nPer una funzione semplice positiva S in forma canonica come definita sopra, l’integrale di S rispetto alla misura \\mu  (sigma finita)è definito come la somma:\n\\int_E S (e) \\cdot \\mu (de) = \\sum_{i=1}^m c_i \\mu(E_i) \\in [0, + \\infty]\ndove \\mu(A_i) è la misura dell’insieme A_i. Si noti che questo valore può essere anche +\\infty se \\mu(A_i) = +\\infty per qualche i con c_i &gt; 0.\nIl professore osserva che questa definizione è analoga al valore atteso per variabili discrete, dove si sommano i valori assunti dalla variabile moltiplicati per le loro probabilità. In questo caso, i valori c_i giocano il ruolo dei valori della variabile, e le misure \\mu(A_i) giocano il ruolo dei pesi (o probabilità, nel caso di misure di probabilità).\nIl passo successivo sarà estendere questa definizione di integrale a funzioni misurabili più generali.\nReferences\nappunti bussetti- lez10.pdf"},"6--full-note/prob-lez11":{"slug":"6--full-note/prob-lez11","filePath":"6- full note/prob-lez11.md","title":"prob-lez11","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità","2--source-materials/appunti-bussetti--lez11.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-07 12:31\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine  probabilità\nprob-lez11\nDefinizione dell’Integrale di Lebesgue\nIntroduzione al Problema e Funzioni Semplici Positive\nOggi affronteremo il problema di definire l’integrale di una funzione s che va da uno spazio di misura (E, \\mathcal{A}, \\mu) (dove E è uno spazio, \\mathcal{A} una \\sigma-algebra e \\mu una misura \\sigma-finita) a valori nei Boreliani di \\mathbb{R} o \\mathbb{R} esteso (\\overline{\\mathbb{R}} = \\mathbb{R} \\cup {-\\infty, +\\infty}) con i Boreliani di \\overline{\\mathbb{R}}.\nLa prima cosa che facciamo è definire l’integrale per una funzione semplice. Una funzione semplice s è costante a tratti su certi insiemi A_i \\in \\mathcal{A} che formano una partizione di E. Consideriamo inizialmente il caso in cui i valori c_i assunti dalla funzione semplice sono tutti maggiori o uguali di 0 (c_i \\ge 0) e gli insiemi A_i formano una partizione di E (E = \\bigcup_i A_i con A_i \\cap A_j = \\emptyset per i \\neq j). In questo caso, s è detta funzione semplice positiva.\nPer una funzione semplice positiva s(x) = \\sum_i c_i \\mathbb{1}_{A_i}(x) (dove \\mathbb{1}_{A_i}(x) è la funzione indicatrice di A_i), definiamo l’integrale di s rispetto a \\mu su E come:\n\\qquad \\int_E s (e) \\cdot \\mu(de) = \\sum_i c_i \\mu(A_i)\nQuesto è un numero maggiore o uguale di 0, poiché c_i \\ge 0 e \\mu(A_i) \\ge 0. Potrebbe anche essere +\\infty se \\mu(A_i) = +\\infty per qualche i con c_i &gt; 0, anche se la somma ha un numero finito di termini. Ad esempio, se \\mu è la misura di Lebesgue su \\mathbb{R}, e A_1 = (-\\infty, 0], A_2 = (0, +\\infty), allora \\mu(A_1) = +\\infty e \\mu(A_2) = +\\infty, e se la nostra funzione semplice è costante su questi insiemi con valori positivi, l’integrale sarà +\\infty. Nonostante ciò, questa definizione è ben posta.\nEstensione dell’Integrale a Funzioni Misurabili Positive\nPer definire l’integrale per una generica funzione misurabile positiva \\xi: E \\to \\overline {\\mathbb{R}}, utilizziamo un processo di approssimazione tramite funzioni semplici.\nProposizione:\nSia \\xi: E \\to \\overline {\\mathbb{R}} una funzione misurabile positiva\n\nEsiste una successione (s_n)_{n \\in \\mathbb{N}} di funzioni semplici positive tali che (s_n(x)) converge a \\xi(x) in modo monotono crescente per ogni x \\in E.\nQuesto significa che per ogni n e per ogni x \\in E, s_n(x) \\le s_{n+1}(x), e \\lim_{n \\to \\infty} s_n(x) = \\xi(x).\n\nSe (s_n)_{n \\in \\mathbb{N}} e (s&#039;_n)_{n \\in \\mathbb{N}} sono due successioni di funzioni semplici positive che convergono a \\xi in modo monotono crescente,\nallora: \\qquad \\lim_{n \\to \\infty} \\int_E s_n (e) \\cdot \\mu(de) = \\lim_{n \\to \\infty} \\int_E s&#039;_n (e) \\cdot \\mu(de) Questo implica che il limite degli integrali non dipende dalla particolare successione approssimante scelta. Inoltre, si afferma implicitamente che questi limiti esistono.\n\nDefinizione dell’integrale di una funzione misurabile positiva:\nSia \\xi: E \\to \\overline {\\mathbb{R}} una funzione misurabile positiva. Definiamo l’integrale di \\xi rispetto a \\mu su E come:\n\\qquad \\int_E  \\xi (e) \\cdot \\mu (de) = \\lim_{n \\to \\infty} \\int_E s_n(e) \\mu(de)\ndove (s_n)_{n \\in \\mathbb{N}} è una qualsiasi successione di funzioni semplici positive che converge a \\xi in modo monotono crescente (la cui esistenza è garantita dal punto 1 della proposizione precedente). In virtù del punto 2 della stessa proposizione, questo limite è ben definito e non dipende dalla scelta specifica della successione (s_n). Questo valore può essere un numero finito non negativo o +\\infty.\n\nSe \\int_E  \\xi (e) \\cdot \\mu (de)&lt; +\\infty, diciamo che la funzione \\xi è integrabile rispetto a \\mu e si dice che un integrale finito.\nIntuizione della costruzione (facoltativa):\nLa costruzione di Lebesgue differisce dall’integrale di Riemann nel modo in cui viene effettuata la partizione. Nell’integrale di Riemann, si partiziona il dominio (lo spazio di partenza), e si approssima la funzione con valori costanti su questi intervalli.\nNell’integrale di Lebesgue, l’idea è di partizionare il codominio (lo spazio di arrivo) e poi considerare le controimmagini di questi intervalli nel dominio. Per una funzione positiva, si suddivide l’asse reale non negativo in intervalli (ad esempio, [0, 1/2), [1/2, 1), [1, 3/2), \\dots) e si guarda la misura degli insiemi del dominio dove la funzione cade in ciascuno di questi intervalli. Si costruisce così una funzione semplice che approssima la funzione originale dal basso. Raffinando la partizione del codominio, si ottiene una successione di funzioni semplici monotone crescenti che convergono alla funzione originale.\n\nDefinizione dell’Integrale per Funzioni Misurabili Generali\n\n(parte negativa tratteggiata, positiva ricalcata)\nConsideriamo ora una funzione misurabile \\xi: E \\to \\overline{\\mathbb{R}} che può assumere valori sia positivi che negativi. Possiamo sempre scrivere \\xi come la differenza tra la sua parte positiva \\xi^+ = \\max(\\xi, 0) e la sua parte negativa \\xi^- = \\max(-\\xi, 0):\n\\qquad |\\xi| = \\xi^+ - \\xi^-\nSia \\xi^+ (x) = \\begin{cases} \\xi(x) &amp; \\text{se } \\xi(x) \\ge 0 \\\\ 0 &amp; \\text{se } \\xi(x) &lt; 0 \\end{cases} e \\xi^- (x) = \\begin{cases} 0 &amp; \\text{se } \\xi(x) \\ge 0 \\\\ -\\xi(x) &amp; \\text{se } \\xi(x) &lt; 0 \\end{cases}\nSe \\xi è misurabile, allora anche \\xi^+ e \\xi^- sono funzioni misurabili e positive. Possiamo quindi definire i loro integrali \\int_E \\xi^+ (e) \\cdot \\mu(de) e \\int_E \\xi^- (e) \\cdot \\mu(de), che saranno numeri in [0, +\\infty].\nDefinizione dell’integrale di una funzione misurabile generale:\nDefiniamo l’integrale di \\xi rispetto a \\mu su E come:\n\\qquad \\int_E \\xi (e) \\cdot \\mu(de) = \\int_E \\xi^+ (e) \\cdot \\mu(de) - \\int_E \\xi^- (e) \\cdot \\mu(de)\nQuesta definizione ha senso se almeno uno tra \\int_E \\xi^+ (e) \\cdot \\mu(de) e \\int_E \\xi^- (e) \\cdot \\mu(de) è finito.\n\nSe \\int_E \\xi^+ (e) \\cdot \\mu(de) &lt; +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) &lt; +\\infty, allora diciamo che \\xi è integrabile con integrale finito rispetto a \\mu, e il suo integrale è un numero finito.\n\nSe \\int_E \\xi^+ (e) \\cdot \\mu(de) = +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) &lt; +\\infty, allora poniamo \\int_E \\xi (e) \\cdot \\mu(de) = +\\infty.\nSe \\int_E \\xi^+ (e) \\cdot \\mu(de) &lt; +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) = +\\infty, allora poniamo \\int_E \\xi (e) \\cdot \\mu(de) = -\\infty.\nSe \\int_E \\xi^+ (e) \\cdot \\mu(de) = +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) = +\\infty, allora l’integrale di \\xi rispetto a \\mu è indefinito.\n\nOsserviamo anche che il modulo di \\xi può essere scritto come |\\xi| = \\xi^+ + \\xi^-.\nProposizione:\nUna funzione misurabile \\xi è integrabile (con integrale finito) se e solo se \\int_E |\\xi| (e) \\cdot \\mu(de) &lt; +\\infty. In questo caso, \\int_E \\xi^+ (e) \\cdot \\mu(de) &lt; +\\infty e \\int_E \\xi^- (e) \\cdot \\mu(de) &lt; +\\infty.\n\n(per dire che si ammette integrale basterà allora testare sul valore assoluto della funzione \\xi)\n\nIntegrabilità di una Funzione Misurabile\nPer garantire che l’integrale di una funzione misurabile \\xi sia ben definito (cioè che non si abbia la forma \\infty - \\infty), si richiede che l’integrale del modulo della funzione sia finito: \\int |\\xi| \\mu(de) &lt; \\infty\nSe il valore assoluto di una funzione misurabile \\xi è integrabile (ha integrale finito), allora automaticamente gli integrali della parte positiva (\\int \\xi^+ \\mu(de)) e della parte negativa (\\int \\xi^- \\mu(de)) sono finiti, e quindi la funzione \\xi ammette un integrale finito.\nIntegrale su un Insieme Misurabile\nSe A appartiene alla \\sigma-algebra \\mathcal{E}, si può definire l’integrale di una funzione misurabile \\xi ristretto all’insieme A: \\int_A \\xi(e) \\cdot \\mu(de) = \\int \\xi(e) \\cdot \\mathbb{1}_A \\mu(de)\ndove \\mathbb{1}_A è la funzione indicatrice dell’insieme A, definita come: \\mathbb{1}_A(x) = \\begin{cases} 1 &amp; \\text{se } x \\in A \\\\ 0 &amp; \\text{se } x \\notin A \\end{cases}\nQuesta definizione intuitivamente significa considerare la funzione \\xi che vale zero al di fuori dell’insieme A. La funzione \\xi \\cdot \\mathbb{1}_A è misurabile perché è il prodotto di due funzioni misurabili. Ci si può poi chiedere se questa nuova funzione sia integrabile. Questa operazione di restringere l’integrazione a un sottoinsieme misurabile non sempre funziona con l’integrale di Riemann.\nProprietà dell’Integrale Astratto\nSia (E, \\mathcal{E}, \\mu) uno spazio di misura con \\mu \\sigma-finita, e siano \\xi, \\xi_1, \\xi_2 funzioni misurabili da E a \\mathbb{R} \\cup \\set{-\\infty, +\\infty}.\n1. Monotonia\nSe \\xi \\ge 0 per ogni e \\in E, allora: \\int_E \\xi(e) \\cdot \\mu(de) \\ge 0\nQuesta proprietà segue direttamente dalla definizione dell’integrale per funzioni positive, che si basa su limiti di integrali di funzioni semplici positive.\n2. Linearità\nSe A, B \\in \\mathbb{R} e \\xi_1, \\xi_2 sono integrabili (hanno integrale finito), allora A\\xi_1 + B\\xi_2 è integrabile e: \\int_E (A\\xi_1 + B\\xi_2) \\mu(de) = A \\int_E \\xi_1 \\mu(de) + B \\int_E \\xi_2 \\mu(de)\nQuesta proprietà mostra che l’integrale è un operatore lineare, analogo alla linearità della somma per variabili aleatorie discrete e dell’integrale di Riemann.\n\n3. Insensitività agli Insiemi di Misura Nulla (?)\nSia A \\in \\mathcal{E} tale che \\mu(A) = 0. Se \\xi è integrabile, allora: \\int_A \\xi(e) \\cdot \\mu(de) = 0\nQuindi, l’integrale di una funzione integrabile su un insieme di misura nulla è zero.\nUna conseguenza importante di questa proprietà e della linearità è la seguente: se \\xi_1 e \\xi_2 sono integrabili e l’insieme {e \\in E \\mid \\xi_1(e) \\neq \\xi_2(e)} ha misura zero, allora: \\int_E \\xi_1 \\mu(de) = \\int_E \\xi_2 \\mu(de)\nQuesto significa che se si modifica una funzione integrabile su un insieme di misura nulla, il suo integrale non cambia. Questa è una differenza significativa rispetto all’integrale di Riemann.\n\n4. Teorema di Convergenza Monotona (MCT)\nSia (\\xi_n)_{n \\in \\mathbb{N}} una successione di funzioni misurabili tali che 0 \\le \\xi_n \\le \\xi_{n+1} per ogni n, e sia \\xi(e) = \\lim_{n \\to \\infty} \\xi_n(e) per ogni e \\in E. Allora: \\lim_{n \\to \\infty} \\int_E \\xi_n \\mu(de) = \\int_E \\xi(e) \\cdot \\mu(de)\nEquivalentemente, si può “portare il limite dentro l’integrale” in questo caso: \\lim_{n \\to \\infty} \\int_E \\xi_n(e) \\mu(de) = \\int_E \\left( \\lim_{n \\to \\infty} \\xi_n(e) \\right) \\mu(de)\nLe ipotesi di positività e convergenza monotona sono cruciali per questo teorema. Il limite degli integrali può anche essere +\\infty se l’integrale della funzione limite è +\\infty. Questo teorema non è generalmente valido per l’integrale di Riemann.\n5. Convergenza per Serie\nSia (\\xi_n)_{n \\in \\mathbb{N}} una successione di funzioni misurabili tali che \\xi_n \\ge 0 per ogni n. Allora: \\sum_{n=1}^{\\infty} \\int_E \\xi_n \\mu(de) = \\int_E \\left( \\sum_{n=1}^{\\infty} \\xi_n \\right) \\mu(de)\nAnche in questo caso, si può “scambiare la somma con l’integrale”, a condizione che le funzioni siano non negative. Questa proprietà può essere dimostrata usando il Teorema di Convergenza Monotona. I valori di entrambe le espressioni possono essere finiti o +\\infty.\n\n6. Integrabilità e Valori Finiti Quasi Ovunque\nSe \\xi è una funzione misurabile a valori in \\mathbb{R} \\cup {-\\infty, +\\infty} e \\int_E |\\xi (e)| \\mu(de) &lt; \\infty (cioè \\xi è integrabile), allora la misura dell’insieme \\set{e:|\\xi(e)| = +\\infty} è zero: \\mu\\set{e:|\\xi(e)| = +\\infty} = 0\nQuindi, se una funzione ha integrale finito, essa può assumere valori \\pm \\infty solo su un insieme di misura nulla. Di conseguenza, se si sa che \\int_E |\\xi| \\mu(de) &lt; \\infty, allora la funzione \\xi è finitamente valutata quasi ovunque. Questo implica che nella convergenza per serie, se \\sum_{n=1}^{\\infty} \\int_E \\xi_n \\mu(de) &lt; \\infty, allora la serie \\sum_{n=1}^{\\infty} \\xi_n(e) converge per quasi ogni e \\in E.\n\nEsempi\nEsempio 1: Integrale rispetto a una misura discreta\nSi consideri una misura \\mu definita come: \\mu = \\sum_{n} \\pi_n \\delta_{e_n} (de)\ndove (\\pi_n) è una successione di pesi positivi, (e_n) è una successione di punti in E, e \\delta_{e_n} (de) è la misura di Dirac nel punto e_n. L’integrale di una funzione \\xi rispetto a questa misura è dato da: \\int_E \\xi(e) \\cdot \\mu(de) = \\sum_{n\\ge1} \\xi(e_n) \\pi_n\nLa condizione di integrabilità in questo caso diventa \\sum_{n} |\\xi(e_n)| \\pi_n &lt; \\infty. L’integrale è quindi una serie pesata dei valori della funzione nei punti che supportano la misura. Se tutti i \\pi_n = 1 e E = \\mathbb{N} (o \\mathbb{Z}), allora l’integrale di \\xi su \\mathbb{R} è la serie \\sum_{n} \\xi(n), se questa è ben definita (cioè converge assolutamente).\n\nEsempio 2: Valore atteso di una variabile aleatoria discreta\nSia X una variabile aleatoria discreta a valori in \\mathbb{R}. Il valore atteso di X è definito come: E[X] = \\sum_{x} x P(X=x) = \\sum_{i} x_i P(X=x_i)\ndove (x_i) sono i possibili valori di X e P(X=x_i) sono le rispettive probabilità. Si scopre che questo valore atteso coincide con l’integrale astratto di X su \\Omega rispetto alla misura di probabilità P: E[X] = \\int_{\\Omega} X(\\omega) P(d\\omega)\nInoltre, questo coincide anche con l’integrale astratto della funzione identità x \\mapsto x su \\mathbb{R} rispetto alla misura immagine P_X di P tramite X: E[X] = \\int_{\\mathbb{R}} x P_X(dx)\ndove P_X(A) = P(X \\in A) per A \\subseteq \\mathbb{R} misurabile. Nel caso discreto, la misura immagine P_X è una misura discreta concentrata sui valori assunti da X con pesi dati dalle probabilità.\n\nIntegrale di Lebesgue su \\mathbb{R}^d\nL’integrale di Lebesgue è un caso particolare dell’integrale astratto dove lo spazio di partenza è \\mathbb{R}^d, la \\sigma-algebra è quella dei boreliani \\mathcal{B}(\\mathbb{R}^d), e la misura \\mu è la misura di Lebesgue m su \\mathbb{R}^d. Una funzione h: \\mathbb{R}^d \\to \\mathbb{R} è detta misurabile se è borel-misurabile.\n\nL’integrale di Lebesgue di h(x) su \\mathbb{R}^d si scrive come: \\int_{\\mathbb{R}^d} h(x) Leb_D(dx)\ne più comunemente come: \\int_{\\mathbb{R}^d} h(x) dx oppure \\int_{\\mathbb{R}^d} h(x_1, ..., x_d) dx_1 ... dx_d\nQuesto integrale è ben definito per funzioni misurabili e può valere un numero finito o \\pm \\infty.\nRelazione tra Integrale di Lebesgue e Integrale di Riemann\nSostanzialmente, tutte le funzioni che si dovranno integrare saranno integrabili secondo Lebesgue, e l’integrale di Riemann coinciderà con l’integrale di Lebesgue quando entrambi sono definiti.\nIl problema principale con l’integrale di Riemann sorge quando si vuole integrare una funzione h(x) su un sottoinsieme A \\subseteq \\mathbb{R}^d: \\int_A h(x) dx = \\int_{\\mathbb{R}^d} h(x) \\mathbb{1}_A(x) dx\nSe A è un insieme la cui funzione indicatrice \\mathbb{1}_A non è integrabile secondo Riemann (come ad esempio A = \\mathbb{Q} \\cap [0,1]), allora l’integrale di Riemann non è definito, mentre l’integrale di Lebesgue lo è.\n\nD’altra parte, se il modulo di una funzione h è integrabile secondo Riemann (in senso improprio, se necessario) su \\mathbb{R}, allora h è integrabile secondo Lebesgue e i due integrali coincidono: \\int_{\\mathbb{R}} h(x) dx_{\\text{Lebesgue}} = \\int_{\\mathbb{R}} h(x) dx_{\\text{Riemann}}\nAd esempio, \\int_0^1 x^2 dx calcolato con l’integrale di Riemann darà lo stesso risultato se calcolato con l’integrale di Lebesgue. Analogamente per \\int_0^{2\\pi} \\sin(x) dx.\nEsistono però casi in cui l’integrale di Riemann in senso improprio è definito ma la funzione non è integrabile secondo Lebesgue (cioè l’integrale del modulo è infinito), come ad esempio alcune funzioni oscillanti. Tuttavia, per gli scopi del corso, gli integrali che si dovranno calcolare potranno essere risolti usando le tecniche dell’integrale di Riemann (teorema fondamentale del calcolo, cambio di variabili, integrazione per parti). È fondamentale però riconoscere che l’integrale di Lebesgue offre una teoria più generale, in particolare per l’integrazione su insiemi più complessi e per i teoremi di convergenza.\n\nCostruzione di Misure di Probabilità a Partire da Funzioni\nSia f: \\mathbb{R}^d \\to \\mathbb{R} una funzione tale che:\n\nf(x) \\ge 0 per ogni x \\in \\mathbb{R}^d\nf è misurabile (borel-misurabile)\n\\int_{\\mathbb{R}^d} f(x) dx = 1 (l’integrale è inteso nel senso di Lebesgue)\n\nAllora, la funzione di insieme P definita per ogni insieme boreliano A \\in \\mathcal{B}(\\mathbb{R}^d) come: P(A) = \\int_A f(x) dx = \\int_{\\mathbb{R}^d} \\mathbb{1}_A(x) f(x) dx\n\nè una misura di probabilità sui boreliani di \\mathbb{R}^d.\n\nDimostrazione:\n\nNon negatività: P(A) = \\int_A f(x) dx \\ge 0 per la proprietà di monotonia dell’integrale, poiché f(x) \\ge 0 e \\mathbb{1}_A(x) \\ge 0.\nProbabilità dello spazio totale: P(\\mathbb{R}^d) = \\int_{\\mathbb{R}^d} f(x) dx = 1 per ipotesi.\n\\sigma-additività: Sia (A_n)_{n \\in \\mathbb{N}} una successione di insiemi boreliani a due a due disgiunti. Allora: P\\left( \\bigcup_{n=1}^{\\infty} A_n \\right) = \\int_{\\mathbb{R}^d} \\mathbb{1}_{\\bigcup_{n=1}^{\\infty} A_n}(x) f(x) dx Poiché gli A_n sono disgiunti, \\mathbb{1}_{\\bigcup_{n=1}^{\\infty} A_n}(x) = \\sum_{n=1}^{\\infty} \\mathbb{1}_{A_n}(x). Quindi: P\\left( \\bigcup_{n=1}^{\\infty} A_n \\right) = \\int_{\\mathbb{R}^d} \\left( \\sum_{n=1}^{\\infty} \\mathbb{1}_{A_n}(x) \\right) f(x) dx Per la proprietà di convergenza per serie dell’integrale astratto (che si applica all’integrale di Lebesgue): P\\left( \\bigcup_{n=1}^{\\infty} A_n \\right) = \\sum_{n=1}^{\\infty} \\int_{\\mathbb{R}^d} \\mathbb{1}_{A_n}(x) f(x) dx = \\sum_{n=1}^{\\infty} P(A_n) Quindi, P è \\sigma-additiva.\n\nEsempio: La funzione f(x) = \\mathbb{1}_{[0, +\\infty)}(x) e^{-x} è misurabile e non negativa su \\mathbb{R}. Il suo integrale su \\mathbb{R} è: \\int_{\\mathbb{R}} f(x) dx = \\int_0^{+\\infty} e^{-x} dx = [-e^{-x}]_0^{+\\infty} = 0 - (-1) = 1. Quindi, questa funzione f(x) definisce una misura di probabilità sui boreliani di \\mathbb{R} tramite P(A) = \\int_A e^{-x} \\mathbb{1}_{[0, +\\infty)}(x) dx.\n\nLa possibilità di costruire misure di probabilità in questo modo, integrando su insiemi che potrebbero avere indicatori non Riemann-integrabili, è una delle motivazioni per l’uso dell’integrale di Lebesgue.\nReferences\nappunti bussetti- lez11.pdf"},"6--full-note/prob-lez12":{"slug":"6--full-note/prob-lez12","filePath":"6- full note/prob-lez12.md","title":"prob-lez12","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-08 11:03\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nprob-lez12\nVettori Assolutamente Continui\nRichiami sull’Integrale Astratto e Misure di Probabilità\nIl professore inizia ricordando un risultato fondamentale collegato all’integrale astratto.\nProposizione: Sia f una funzione tale che f(x) \\ge 0 per ogni x \\in \\mathbb{R}^d e \\int_{\\mathbb{R}^d} f(x) dx = 1, dove l’integrale è inteso nel senso di Lebesgue. Allora, la funzione che associa ad ogni boreliano A \\subseteq \\mathbb{R}^d il valore \\int_A f(x) dx definisce una misura di probabilità sui boreliani di \\mathbb{R}^d.\nCommento: Questo significa che ogni funzione non negativa la cui integrale su tutto lo spazio sia unitario può essere vista come la densità di una misura di probabilità.\nDefinizione di Vettore Assolutamente Continuo\nPartendo da questa osservazione, il professore introduce la definizione di vettore aleatorio assolutamente continuo.\nDefinizione (Prima Forma): Un vettore aleatorio X definito su uno spazio di probabilità a valori in \\mathbb{R}^d (con la \\sigma-algebra dei boreliani) si dice con legge assolutamente continua se la sua funzione di ripartizione F_X(x), per ogni x = (x_1, \\dots, x_d) \\in \\mathbb{R}^d, può essere scritta come l’integrale multiplo di Lebesgue di una funzione f(y) \\ge 0 tale che \\int_{\\mathbb{R}^d} f(y) dy = 1. Nello specifico:\nF_X(x) = P(X_1 \\le x_1, \\dots, X_d \\le x_d) = \\int_{\\set{y \\in \\mathbb{R}^d: y_i \\le x_i, \\forall i=1,\\dots,d}} f_X(y) dy\nLa funzione f(x) è detta densità (o funzione di densità di probabilità, PDF) del vettore X.\nCommento: La funzione di ripartizione rappresenta la probabilità che il vettore aleatorio X cada nel “quadrante” (-\\infty, x_1] \\times \\dots \\times (-\\infty, x_d]. La definizione afferma che questa probabilità può essere calcolata integrando la densità su questo insieme.\n\nDefinizione Equivalente di Vettore Assolutamente Continuo\nIl professore presenta poi una definizione equivalente, più generale e spesso più utile.\nDefinizione (Seconda Forma): Un vettore aleatorio X è assolutamente continuo se esiste una funzione densità f_x(x) \\ge 0 con \\int_{\\mathbb{R}^d} f_x(x) dx = 1 tale che, per ogni insieme boreliano A \\subseteq \\mathbb{R}^d, la probabilità che X appartenga ad A sia data da:\nP(X \\in A) = \\int_A f(x) dx\nLa funzione f(x) è la densità del vettore X.\nDimostrazione dell’Equivalenza (Accennata):\n\nDalla seconda alla prima definizione: Se vale la seconda definizione, prendendo come insieme boreliano A il quadrante \\set{y \\in \\mathbb{R}^d: y_i \\le x_i, \\forall i=1,\\dots,d}, si ottiene direttamente la prima definizione.\nDalla prima alla seconda definizione: Si osserva che l’insieme dei quadranti definisce una classe \\mathcal{P} che genera tutti i boreliani di \\mathbb{R}^d. La funzione P&#039;(A) = \\int_A f(x) dx definisce una misura di probabilità sui boreliani. Per ipotesi (prima definizione), P(X \\in A) = P&#039;(A) per ogni A appartenente alla classe \\mathcal{P} dei quadranti. Poiché due misure di probabilità che coincidono su una classe \\mathcal{P} che genera la \\sigma-algebra devono coincidere su tutta la \\sigma-algebra, si ha che P(X \\in A) = \\int_A f(x) dx per ogni boreliano A \\subseteq \\mathbb{R}^d.\n\nCommento: La seconda definizione è più potente perché permette di calcolare la probabilità che il vettore aleatorio cada in qualsiasi insieme boreliano, non solo in particolari “quadranti”.\n\nRiassunto dei Tipi di Vettori Aleatori\nIl professore riassume i diversi modi per descrivere un vettore aleatorio. Dato un vettore aleatorio X a valori in \\mathbb{R}^d:\n\n\nLegge Immagine (o Misura di Probabilità Indotta): Si può sempre definire la misura di probabilità P_X(A) = P(X \\in A) per ogni boreliano A \\subseteq \\mathbb{R}^d.\n\n\nFunzione di Ripartizione: Si può sempre definire la funzione F_X(x) = P(X_1 \\le x_1, \\dots, X_d \\le x_d) per ogni x \\in \\mathbb{R}^d.\n\nPoi si distinguono due casi particolari:\n\n\nVettore Discreto: In questo caso, esiste un insieme numerabile di punti C \\subseteq \\mathbb{R}^d tale che P(X \\in C) = 1. Si può definire una densità discreta (o funzione di massa di probabilità) f_X(x) = P(X = x) per x \\in C, e f_X(x) = 0 altrimenti. La probabilità che X appartenga a un insieme A si ottiene sommando le probabilità dei punti di C contenuti in A: P(X \\in A) = \\sum_{x \\in A \\cap C} f_X(x).\n\n\nVettore Assolutamente Continuo: Come definito precedentemente, esiste una funzione di densità f_X(x) \\ge 0 con \\int_{\\mathbb{R}^d} f_X(x) dx = 1 tale che P(X \\in A) = \\int_A f_X(x) dx per ogni boreliano A \\subseteq \\mathbb{R}^d.\n\n\nCommento: Non tutte le leggi di probabilità rientrano in questi due casi (puramente discreto o assolutamente continuo), ma essi coprono una parte significativa delle distribuzioni utilizzate. In altri casi, si può ricorrere alla funzione di ripartizione per descrivere la legge di probabilità.\n\nRelazione tra Densità e Funzione di Ripartizione (Caso d=1)\nNel caso unidimensionale (d=1), esiste una relazione importante tra la funzione di ripartizione e la densità per variabili assolutamente continue.\nProposizione (Caso d=1): Se X è una variabile aleatoria assolutamente continua con densità f(x), allora la sua funzione di ripartizione F_X(x) è data da:\nF_X(x) = P(X \\le x) = \\int_{-\\infty}^{x} f(t) dt\nNel caso discreto, la funzione di ripartizione è data da:\nF_X(x) = P(X \\le x) = \\sum_{x_i \\le x} P(X = x_i) = \\sum_{x_i \\le x} f_X(x_i)\ndove la somma è estesa a tutti i valori x_i nel supporto (insieme numerabile di punti con probabilità non nulla) di X che sono minori o uguali a x. La funzione di ripartizione di una variabile discreta è una funzione costante a tratti.\n\nCommento: Nel caso assolutamente continuo, se la densità f(t) è continua in un punto x, allora la funzione di ripartizione F_X(x) è derivabile in quel punto e la sua derivata è uguale alla densità: F_X&#039;(x) = f(x) (Teorema Fondamentale del Calcolo)\nProprietà dei Vettori Assolutamente Continui\nIl professore sottolinea alcune importanti proprietà dei vettori assolutamente continui.\nProposizione: Se X è un vettore assolutamente continuo a valori in \\mathbb{R}^d, allora per ogni x \\in \\mathbb{R}^d, la probabilità che X sia esattamente uguale a x è zero:\nP(X = x) = 0\nDimostrazione: Un singolo punto x in \\mathbb{R}^d ha misura di Lebesgue zero. Quindi:\nP(X = x) = \\int_{{x}} f(y) dy = 0\ndove dx indica la misura di Lebesgue.\nProposizione: Se H \\subseteq \\mathbb{R}^d è un sottoinsieme con misura di Lebesgue nulla (ad esempio, un iperpiano di dimensione strettamente minore di d), allora la probabilità che X appartenga ad H è zero:\nP(X \\in H) = \\int_H f(y) dy = 0\nEsempio (Caso d=2): Se X = (X_1, X_2) è un vettore assolutamente continuo in \\mathbb{R}^2, allora la probabilità che X_1 = X_2 è zero. L’insieme {(x_1, x_2) \\in \\mathbb{R}^2: x_1 = x_2} è una retta (un iperpiano di dimensione 1 in \\mathbb{R}^2), che ha misura di Lebesgue zero.\nCommento: Questa proprietà può sembrare controintuitiva, ma significa che per una variabile assolutamente continua, non possiamo osservare un valore specifico con probabilità non nulla. Le probabilità sono associate a insiemi di misura positiva (intervalli, palle, ecc.) .\n\nDistinzione tra Probabilità Puntuale e Densità\nIl professore evidenzia una differenza cruciale :\nOsservazione: Per un vettore assolutamente continuo X con densità f(x):\n\nP(X = x) = 0 per ogni x \\in \\mathbb{R}^d .\nIl valore della densità f(x) in un punto x non rappresenta la probabilità che X sia uguale a x e non è necessariamente compreso tra 0 e 1 .\n\nCommento: La densità f(x) indica la “concentrazione” di probabilità attorno al punto x. Per ottenere una probabilità, è necessario integrare la densità su un insieme contenente x che abbia misura di Lebesgue positiva (un “volume” attorno a x) .\n\nContinuità della Funzione di Ripartizione (Caso d=1)\nProposizione (Caso d=1): Se X è una variabile aleatoria assolutamente continua, allora la sua funzione di ripartizione F_X(x) è continua ovunque .\nEsercizi, esempi e ulteriori passaggi matematici non sono presenti negli estratti forniti.\n\nVariabili Aleatorie Assolutamente Continue\nProbabilità di un Punto e Funzione di Ripartizione\nNel caso di una variabile aleatoria assolutamente continua, la probabilità di un singolo punto è sempre uguale a zero.\nP(X = x) = 0\nLa funzione di ripartizione (CDF), F_X(x) = P(X \\le x), associata a una variabile assolutamente continua può essere scritta come l’integrale della sua funzione di densità di probabilità (PDF), f_X(t):\nF_X(x) = \\int_{-\\infty}^{x} f_X(t) dt\nPer definizione, questa funzione di ripartizione F_X(x) è continua.\nDimostrazione (Accennata): Questa proprietà deriva dal fatto che F_X(x) = \\int_{-\\infty}^{x} f(t) dt. L’integrale di Lebesgue è continuo rispetto al limite superiore di integrazione\nCommento: La continuità della funzione di ripartizione è una caratteristica delle variabili assolutamente continue e le distingue dalle variabili discrete, la cui funzione di ripartizione presenta dei salti nei punti in cui la variabile assume valori con probabilità positiva. Tuttavia, la continuità della funzione di ripartizione non implica necessariamente che la variabile sia assolutamente continua (esistono distribuzioni singolari continue) . Il viceversa è vero: se una variabile è assolutamente continua, la sua funzione di ripartizione è continua .\nAttenzione: Non è vero il viceversa. Si possono avere funzioni di ripartizione continue che non corrispondono a leggi assolutamente continue. Un esempio è la funzione di Cantor (o scala del diavolo).\n\nMisure Non Atomiche\nIn dimensione d=1, le misure di probabilità che hanno una funzione di ripartizione continua sono dette non atomiche, il che significa che non esiste alcun punto con una massa di probabilità strettamente positiva.\nLa classe delle variabili aleatorie con legge assolutamente continua è un sottinsieme della classe più grande delle variabili aleatorie con funzione di ripartizione continua (non atomiche).\nSpesso si userà l’affermazione: “X ha legge assolutamente continua, quindi la sua funzione di ripartizione è assolutamente continua (e quindi continua)“. È importante non confondere “X assolutamente continua” con ”f_X(x) continua”.\nDefinizione di Legge Assolutamente Continua\nUna variabile aleatoria X ha una legge assolutamente continua se la sua funzione di ripartizione F_X(x) può essere espressa come l’integrale di una funzione f_X(t) positiva e integrabile (la densità):\nF_X(x) = \\int_{-\\infty}^{x} f_X(t) dt\nEsempio: Distribuzione Uniforme su (0, 1)\nConsideriamo una variabile aleatoria X distribuita uniformemente sull’intervallo (0, 1). La sua funzione di ripartizione F_X(x) è data da:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\\\ x &amp; \\text{se } 0 &lt; x &lt; 1 \\\\ 1 &amp; \\text{se } x \\ge 1 \\end{cases}\nPossiamo verificare che questa funzione di ripartizione può essere scritta come l’integrale di una densità f_X(t):\nf_X(t) = \\begin{cases} 1 &amp; \\text{se } 0 &lt; t &lt; 1 \\\\ 0 &amp; \\text{altrimenti} \\end{cases} \nInfatti, per ogni x \\in \\mathbb{R}:\n\\int_{-\\infty}^{x} f_X(t) dt = F_X(x)\nLa funzione f_X(t) è positiva, misurabile e il suo integrale su tutto \\mathbb{R} è uguale a 1:\n\\int_{-\\infty}^{\\infty} f_X(t) dt = \\int_{0}^{1} 1 dt = [t]_{0}^{1} = 1 - 0 = 1\nQuindi, la variabile aleatoria X con distribuzione uniforme su (0, 1) ha una legge assolutamente continua. Notiamo che la funzione di ripartizione F_X(x) è continua, mentre la sua densità f_X(t) non lo è (ha discontinuità nei punti t=0 e t=1). Questo conferma che l’assoluta continuità riguarda la legge (o la funzione di ripartizione), non necessariamente la densità.\n\nNon Unicità della Funzione di Densità\nLa funzione di densità f_X(x) per una variabile aleatoria assolutamente continua non è unica in senso stretto. Se modifichiamo la densità in un numero finito di punti (o più in generale, su un insieme di misura di Lebesgue nulla), la funzione di ripartizione associata non cambia.\nAd esempio, per la distribuzione uniforme su (0, 1), la densità potrebbe anche essere definita come:\nf&#039;_X(t) = \\begin{cases} 2 &amp; \\text{se } t = 0.5 \\\\ 1 &amp; \\text{se } 0 &lt; t &lt; 1, t \\neq 0.5 \\\\ 0 &amp; \\text{altrimenti} \\end{cases} \nQuesta f&#039;_X(t) è ancora una densità per la distribuzione uniforme su (0, 1) perché l’integrale di Lebesgue è insensibile a modifiche su insiemi di misura nulla. Tuttavia, nella pratica, si sceglie una rappresentazione conveniente della densità.\nLa densità contiene informazioni sulla probabilità di un intorno, non sul valore puntuale.\n\nDefinizione di Leggi Assolutamente Continue Tramite la Densità\nSpesso, le variabili aleatorie assolutamente continue vengono definite direttamente specificando la loro funzione di densità. Ad esempio:\n\nX ha una legge uniforme se la sua densità è costante su un intervallo e zero altrove.\nX ha una legge esponenziale se la sua densità ha una specifica forma funzionale (come vedremo in seguito).\nX ha una legge Gamma, ecc..\n\nIn questi casi, si assume che la variabile aleatoria sia assolutamente continua con la densità data.\nVerifica dell’Assoluta Continuità a Partire dalla Funzione di Ripartizione\nPer verificare se una funzione di ripartizione F(x) corrisponde a una variabile aleatoria assolutamente continua, si deve controllare se esiste una funzione positiva e integrabile f(t) tale che per ogni x:\nF(x) = \\int_{-\\infty}^{x} f(t) dt\nSe si riesce a trovare tale funzione f(t), allora essa è la densità della variabile aleatoria.\nIn dimensione uno, un modo pratico per trovare la densità, se esiste, è calcolare la derivata della funzione di ripartizione.\nRelazione tra Funzione di Ripartizione e Densità Tramite la Derivazione\nSe la funzione di ripartizione F_X(x) è derivabile su \\mathbb{R} meno un insieme finito di punti, allora la sua derivata è uguale alla funzione di densità di probabilità f_X(x) nei punti di derivabilità:\nf_X(x) = \\frac{d}{dx} F_X(x)\n\nEsempio: Distribuzione Uniforme (Riconsiderata)\nLa funzione di ripartizione della distribuzione uniforme su (0, 1) è:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x \\le 0 \\\\ x &amp; \\text{se } 0 &lt; x &lt; 1 \\\\ 1 &amp; \\text{se } x \\ge 1 \\end{cases}\nLa sua derivata è:\n\\frac{d}{dx} F_X(x) = \\begin{cases} 0 &amp; \\text{se } x &lt; 0 \\\\ 1 &amp; \\text{se } 0 &lt; x &lt; 1 \\\\ 0 &amp; \\text{se } x &gt; 1 \\end{cases}\nQuesta derivata coincide con la densità f_X(x) definita in precedenza, eccetto che nei punti x=0 e x=1 dove la derivata non esiste. Tuttavia, poiché questi sono solo due punti (un insieme di misura nulla), ciò non influisce sull’integrale.\n\nControesempio: Variabile Aleatoria Discreta\nConsideriamo una variabile aleatoria X tale che P(X = 0) = 1. La sua funzione di ripartizione è:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x &lt; 0 \\\\ 1 &amp; \\text{se } x \\ge 0 \\end{cases}\nQuesta funzione di ripartizione non è continua in x=0. Pertanto, la variabile aleatoria X non è assolutamente continua. Inoltre, la sua derivata è zero ovunque tranne in x=0 dove non è definita, e una funzione che è zero quasi ovunque non può integrare a 1 (che è la probabilità totale).\nApproccio Operativo per Trovare la Densità\nSe si sa che una variabile aleatoria è assolutamente continua, la sua densità può essere trovata derivando la funzione di ripartizione dove essa è derivabile (tipicamente ovunque tranne un insieme finito di punti).\nEsempio: Distribuzione Esponenziale\nConsideriamo una variabile aleatoria X con distribuzione esponenziale di parametro \\lambda &gt; 0. Si definisce che X è assolutamente continua con funzione di densità:\nf_X(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; \\text{se } x &gt; 0 \\\\ 0 &amp; \\text{se } x \\le 0 \\end{cases} \nVerifichiamo che questa è una densità: è positiva per x &gt; 0. Calcoliamo l’integrale su tutto \\mathbb{R}:\n\\int_{-\\infty}^{\\infty} f_X(x) dx = \\int_{0}^{\\infty} \\lambda e^{-\\lambda x} dx\nLa primitiva di \\lambda e^{-\\lambda x} è -e^{-\\lambda x}. Quindi:\n\\begin{aligned} \\int_{0}^{\\infty} \\lambda e^{-\\lambda x} dx = \\lim_{b \\to \\infty} [-e^{-\\lambda x}]_{0}^{b} = \\\\ \\\\ \\lim_{b \\to \\infty} (-e^{-\\lambda b} - (-e^{0})) = (0 - (-1)) = 1 \\end{aligned}\nQuindi f_X(x) è una funzione di densità. Calcoliamo ora la funzione di ripartizione F_X(x) = P(X \\le x) = \\int_{-\\infty}^{x} f_X(t) dt:\n\nSe x &lt; 0: F_X(x) = \\int_{-\\infty}^{x} 0 dt = 0\nSe x \\ge 0: \\begin{aligned} F_X(x) = \\int_{-\\infty}^{0} 0 dt + \\int_{0}^{x} \\lambda e^{-\\lambda t} dt =\\\\ 0 + [-e^{-\\lambda t}]_{0}^{x} = -e^{-\\lambda x} - (-e^{0}) = 1 - e^{-\\lambda x}\\end{aligned} \n\nQuindi la funzione di ripartizione della distribuzione esponenziale è:\nF_X(x) = \\begin{cases} 0 &amp; \\text{se } x &lt; 0 \\\\ 1 - e^{-\\lambda x} &amp; \\text{se } x \\ge 0 \\end{cases}\nQuesta funzione F_X(x) è continua. La sua derivata per x &gt; 0 è \\frac{d}{dx} (1 - e^{-\\lambda x}) = -(-\\lambda) e^{-\\lambda x} = \\lambda e^{-\\lambda x}, che coincide con la densità f_X(x) per x &gt; 0.\n\nChiarimento sulla Definizione di Assoluta Continuità e il Ruolo di \\Omega\nEssere assolutamente continua non presuppone necessariamente la conoscenza esplicita della funzione di ripartizione. La definizione formale si basa sull’esistenza di una densità.\nDal punto di vista teorico, una variabile aleatoria X è definita su uno spazio probabilistico (\\Omega, \\mathcal{F}, P). La sua legge (o distribuzione) è una misura di probabilità su \\mathbb{R}. Dire che X è assolutamente continua significa che questa misura di probabilità è assolutamente continua rispetto alla misura di Lebesgue, il che implica l’esistenza di una densità f_X.\nIn pratica, spesso si definisce una variabile aleatoria assolutamente continua specificando la sua densità f_X(x), che è una funzione positiva che integra a 1. Data una tale densità, si può definire una misura di probabilità e quindi (teoricamente) trovare uno spazio (\\Omega, \\mathcal{F}, P) e una variabile aleatoria X: \\Omega \\to \\mathbb{R} che abbia quella densità. Tuttavia, nella maggior parte delle applicazioni, non è necessario costruire esplicitamente \\Omega; è sufficiente lavorare con la densità.\nIn sintesi, quando si dice che X è assolutamente continua con una certa densità, si sta affermando che esiste uno spazio probabilistico sottostante tale che la variabile aleatoria X ha quella specifica densità, e quindi la sua funzione di ripartizione può essere ottenuta integrando tale densità.\nUnicità della Variabile Aleatoria Data una Densità\nAffermazione: Data una funzione di densità, non esiste un’unica variabile aleatoria che la possieda.\nCommento: Questa affermazione è valida anche per le funzioni di ripartizione (CDF), sebbene questo aspetto non sarà centrale per la discussione. L’analogia viene fatta con la distribuzione uniforme, dove, pur avendo una specifica funzione di ripartizione uniforme, è possibile costruire diverse variabili aleatorie che seguono tale distribuzione.\nEsempio: Si possono costruire in diversi modi variabili aleatorie distinte che condividono la stessa legge di probabilità.\nImplicazione: La definizione di una variabile aleatoria attraverso la sua densità o funzione di ripartizione fornisce informazioni sulla legge immagine di X, ovvero sulla distribuzione di probabilità dei valori che X può assumere. Per i calcoli, si può fare riferimento allo spazio campionario \\Omega, ma domande specifiche che dipendono dalla struttura di \\Omega potrebbero non essere risolvibili unicamente conoscendo la legge di X.\nEsempio: Se X è una variabile aleatoria geometrica, la sua legge è definita senza specificare lo spazio campionario \\Omega. È possibile calcolare il valore atteso di X con queste informazioni. Tuttavia, per sapere quali elementi \\omega \\in \\Omega corrispondono a un valore specifico di X, come X=3, è necessario conoscere la struttura di \\Omega.\nConclusione: Molte proprietà di una variabile aleatoria, come il valore atteso, dipendono solo dalla sua legge (e quindi, nel caso assolutamente continuo, dalla sua densità) e non dalla specifica realizzazione sullo spazio campionario \\Omega.\nProprietà della Distribuzione Esponenziale\nIl professore introduce la distribuzione esponenziale come esempio di variabile aleatoria assolutamente continua.\nProbabilità che X sia Maggiore o Uguale a Zero\nProprietà: Per una variabile aleatoria X con legge esponenziale, P(X \\ge 0) = 1.\nDimostrazione 1 (Integrale della Densità): \\begin{align}  P(X \\ge 0) =\\\\ \\int_{0}^{+\\infty} f(x) dx =  \\int_{0}^{+\\infty} \\lambda e^{-\\lambda x} dx = \\\\ [ -e^{-\\lambda x} ]_{0}^{+\\infty} =  -e^{-\\infty} - (-e^{0}) = 0 - (-1) = 1 \\end{align}.\nDimostrazione 2 (Funzione di Ripartizione): La funzione di ripartizione F(x) per una variabile aleatoria esponenziale è data da F(x) = 1 - e^{-\\lambda x} per x \\ge 0 e 0 per x &lt; 0. P(X \\ge 0) = 1 - P(X &lt; 0) = 1 - F(0^-) = 1 - 0 = 1. Oppure, P(X \\ge 0) = 1 - P(X &lt; 0). Poiché per x&lt;0, F(x)=0, allora P(X&lt;0) = \\lim_{x \\to 0^-} F(x) = 0. Quindi P(X \\ge 0) = 1 - 0 = 1.\nAssenza di Memoria della Distribuzione Esponenziale\nProblema: Calcolare la probabilità condizionata P(X &gt; t + s | X &gt; t) per s, t &gt; 0, dove X è una variabile aleatoria esponenziale di parametro \\lambda.\nDefinizione di Probabilità Condizionata: P(A | B) = \\frac{P(A \\cap B)}{P(B)}\nApplicazione al Problema: P(X &gt; t + s | X &gt; t) = \\frac{P(X &gt; t + s \\cap X &gt; t)}{P(X &gt; t)}.\nOsservazione sull’intersezione degli eventi: Se X &gt; t + s, allora necessariamente X &gt; t (poiché s &gt; 0). Quindi, l’evento {X &gt; t + s} è contenuto nell’evento {X &gt; t}, e la loro intersezione è l’evento più “piccolo”: {X &gt; t + s} \\cap {X &gt; t} = {X &gt; t + s}.\nCalcolo di P(X &gt; u): P(X &gt; u) = 1 - P(X \\le u) = 1 - F(u). Per u &gt; 0, F(u) = 1 - e^{-\\lambda u}, quindi P(X &gt; u) = 1 - (1 - e^{-\\lambda u}) = e^{-\\lambda u}.\nCalcolo della Probabilità Condizionata: P(X &gt; t + s | X &gt; t) = \\frac{P(X &gt; t + s)}{P(X &gt; t)} = \\frac{e^{-\\lambda (t + s)}}{e^{-\\lambda t}} = e^{-\\lambda t - \\lambda s + \\lambda t} = e^{-\\lambda s}.\nInterpretazione: Si osserva che e^{-\\lambda s} = P(X &gt; s). Quindi, P(X &gt; t + s | X &gt; t) = P(X &gt; s).\nConclusione (Proprietà di Assenza di Memoria): La probabilità che un guasto (o un evento modellato da una distribuzione esponenziale) non si verifichi per un ulteriore tempo s, dato che non si è verificato fino al tempo t, è uguale alla probabilità che non si verifichi per un tempo s a partire dall’istante iniziale (tempo zero). In altre parole, la “memoria” del processo si azzera.\n\nEsempio Pratico (Affidabilità di una Macchina): Se X rappresenta il tempo di guasto di una macchina, la proprietà di assenza di memoria implica che la probabilità che una macchina che ha funzionato per t unità di tempo continui a funzionare per altre s unità di tempo è la stessa della probabilità che una macchina nuova funzioni per s unità di tempo.\nCritica del Modello Esponenziale per Guasti Reali: Questa proprietà di assenza di memoria potrebbe non essere realistica per modellare il guasto di macchine reali, in cui la probabilità di guasto tende ad aumentare con l’usura.\nEstensione alla Distribuzione Geometrica (Discreta): Il professore menziona che la distribuzione geometrica (nel caso discreto) possiede una proprietà analoga di assenza di memoria.\nUnicità tra le Distribuzioni Continue Positive: Tra le variabili aleatorie assolutamente continue e positive, la distribuzione esponenziale è l’unica a godere della proprietà di assenza di memoria.\nAltri Esempi di Distribuzioni Assolutamente Continue\nDistribuzione Gaussiana (Normale)\nDefinizione: Una variabile aleatoria X si dice assolutamente continua con legge (o distribuzione) gaussiana (o normale) di parametri \\mu \\in \\mathbb{R} (media) e \\sigma^2 &gt; 0 (varianza) se la sua funzione di densità è data da: f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}, per x \\in \\mathbb{R}.\nVerifica che la Densità Integra a 1: \\int_{-\\infty}^{+\\infty} f(x) dx = \\int_{-\\infty}^{+\\infty} \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} dx Utilizzando il cambio di variabili t = \\frac{x - \\mu}{\\sigma}, si ha x = \\mu + \\sigma t e dx = \\sigma dt. Gli estremi di integrazione rimangono (-\\infty, +\\infty). \\int_{-\\infty}^{+\\infty} \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{t^2}{2}} \\sigma dt = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{+\\infty} e^{-\\frac{t^2}{2}} dt L’integrale \\int_{-\\infty}^{+\\infty} e^{-\\frac{t^2}{2}} dt = \\sqrt{2\\pi} (integrale gaussiano). Quindi, l’integrale della densità è \\frac{1}{\\sqrt{2\\pi}} \\sqrt{2\\pi} = 1.\n\nGaussiana Standard (Normale Standard): Un caso particolare è la gaussiana standard, con parametri \\mu = 0 e \\sigma^2 = 1. La sua densità è: \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\nFunzione di Ripartizione della Gaussiana: La funzione di ripartizione F(x) = P(X \\le x) = \\int_{-\\infty}^{x} f(t) dt non ha una forma chiusa esprimibile in termini di funzioni elementari (seno, coseno, esponenziale, ecc.). Può essere espressa in termini della funzione di errore (erf), che è comunque definita come un integrale.\n\nNotazione per la Funzione di Ripartizione della Gaussiana Standard: La funzione di ripartizione della gaussiana standard è spesso indicata con la lettera \\Phi(x).\nProprietà della Densità Gaussiana: La densità gaussiana è una funzione continua e derivabile ovunque.\nImportanza della Distribuzione Gaussiana: La distribuzione gaussiana è fondamentale nel calcolo delle probabilità e nella statistica, in particolare per il Teorema del Limite Centrale.\nDistribuzione di Cauchy\nDefinizione: Una variabile aleatoria X con distribuzione di Cauchy con parametri \\mu \\in \\mathbb{R} e \\sigma &gt; 0 ha una funzione di densità data da: f(x) = \\frac{1}{\\pi \\sigma \\left[ 1 + \\left( \\frac{x - \\mu}{\\sigma} \\right)^2 \\right]}\nSpesso, viene considerata la Cauchy standard con parametri \\mu = 0 e \\sigma = 1, la cui densità è: f(x) = \\frac{1}{\\pi (1 + x^2)}\nLa funzione di ripartizione della Cauchy con parametri \\mu e \\sigma è: F(x) = \\frac{1}{\\pi} \\arctan\\left( \\frac{x - \\mu}{\\sigma} \\right) + \\frac{1}{2}\nSimmetria della Gaussiana e della Cauchy: Sia la gaussiana standard che la Cauchy standard sono distribuzioni simmetriche rispetto allo zero. Una variabile aleatoria X ha la stessa legge di -X (indicato come X \\stackrel{\\mathcal{L}}{=} -X) se e solo se la sua distribuzione è simmetrica rispetto allo zero.\nVerifica della Simmetria: Per dimostrare che X \\stackrel{d}{=} -X, si può verificare che la funzione di ripartizione di X, F_X(x), è tale che F_X(x) = 1 - F_X(-x^-) = 1 - P(X &lt; -x). Alternativamente, si può mostrare che la densità f_X(x) è una funzione pari, ovvero f_X(x) = f_X(-x). Sia la densità gaussiana standard \\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}} che la densità Cauchy standard f(x) = \\frac{1}{\\pi (1 + x^2)} soddisfano questa proprietà.\n\nCode Leggere vs. Code Pesanti\nComportamento delle Code: La differenza tra la distribuzione gaussiana e la Cauchy risiede nel comportamento delle loro code, ovvero come la densità si avvicina a zero per |x| \\to \\infty.\n\n\nGaussiana: La densità gaussiana decade esponenzialmente, come e^{-x^2/2}, quindi molto rapidamente. Si dice che la gaussiana ha code leggere. Questo implica che la probabilità di osservare valori molto distanti dalla media è molto bassa.\n\n\nCauchy: La densità di Cauchy decade come un polinomio, specificamente come \\frac{1}{x^2}. Questo decadimento è molto più lento rispetto all’esponenziale. Si dice che la Cauchy ha code pesanti. Ciò significa che la probabilità di osservare valori estremi è significativamente più alta rispetto a una distribuzione gaussiana con parametri simili.\n\n\nImplicazione per il Valore Atteso: La distribuzione di Cauchy è un esempio di variabile aleatoria che non ha un valore atteso finito, a causa del comportamento delle code della sua densità.\nValore Atteso e Varianza per Variabili Aleatorie Discrete (Ricapitolazione e Anticipazione)\nValore Atteso (Caso Discreto)\nPer una variabile aleatoria discreta X con funzione di massa di probabilità P(X = x_i) = p_i, il valore atteso (o media) di X, denotato con E[X], è definito come: E[X] = \\sum_{i} x_i p_i, ammesso che la somma converga assolutamente.\nSe g è una funzione reale, il valore atteso di g(X) è: E[g(X)] = \\sum_{i} g(x_i) p_i, ammesso che la somma converga assolutamente.\nVarianza (Caso Discreto)\nLa varianza di una variabile aleatoria discreta X, denotata con Var(X) o \\sigma^2_X, è definita come il valore atteso del quadrato della deviazione di X dalla sua media: Var(X) = E[(X - E[X])^2]\nLa varianza può anche essere calcolata utilizzando la seguente formula: Var(X) = E[X^2] - (E[X])^2\nSpiegazione: Var(X) = E[(X - \\mu)^2] = E[X^2 - 2\\mu X + \\mu^2] = E[X^2] - 2\\mu E[X] + E[\\mu^2] Dato che \\mu = E[X] è una costante, E[\\mu X] = \\mu E[X] = \\mu^2 e E[\\mu^2] = \\mu^2. Quindi, Var(X) = E[X^2] - 2\\mu^2 + \\mu^2 = E[X^2] - \\mu^2 = E[X^2] - (E[X])^2.\nUtilizzo della Definizione per Esercizi: Negli esercizi, per ora, si richiede di utilizzare la definizione di varianza per il suo calcolo. Le proprietà della varianza saranno studiate più avanti.\nReferences"},"6--full-note/prob-lez13":{"slug":"6--full-note/prob-lez13","filePath":"6- full note/prob-lez13.md","title":"prob-lez13","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-03-19 11:06\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: sbobine. probabilità\nprob-lez13\nValore Atteso per Variabili Aleatorie Generali\nIntroduzione al Valore Atteso Generale\nL’argomento di oggi è l’estensione del concetto di valore atteso a variabili aleatorie qualunque, superando la definizione data per le sole variabili aleatorie discrete. L’obiettivo è definire il valore atteso in un contesto più generale, utilizzando la teoria dell’integrazione astratta.\nDefinizione Attraverso l’Integrale Astratto\nConsideriamo una variabile aleatoria X definita su uno spazio di probabilità (\\Omega, \\mathcal{F}, P), dove \\Omega è lo spazio campionario, \\mathcal{F} è la sigma-algebra degli eventi e P è la misura di probabilità. La variabile aleatoria X assume valori nei numeri reali Boreliani \\mathbb{R} (o eventualmente in \\mathbb{R} esteso) ed è una funzione misurabile X: \\Omega \\to \\mathbb{R} (o \\mathbb{R} \\cup {-\\infty, +\\infty}).\nL’integrale astratto di una funzione misurabile su uno spazio con una misura sigma-finita è un concetto matematico ben definito, sebbene la sua definizione rigorosa coinvolga l’approssimazione con funzioni semplici e il passaggio al limite.\nNel nostro caso, per definire il valore atteso di una variabile aleatoria X, utilizziamo l’integrale astratto con le seguenti specifiche scelte:\n\nLo spazio di misura è lo spazio di probabilità (\\Omega, \\mathcal{F}, P).\nLa funzione misurabile è la variabile aleatoria X: \\Omega \\to \\mathbb{R}.\n\nFormalmente, il valore atteso di X, denotato con E[X], è definito come l’integrale astratto di X rispetto alla misura di probabilità P su \\Omega:\nE[X] = \\int_\\Omega X(\\omega) dP(\\omega)\nÈ importante notare che questa notazione è, inizialmente, un simbolo che rappresenta un oggetto matematicamente ben definito sotto opportune condizioni. Affinché il valore atteso sia ben definito, in particolare, l’integrale astratto del modulo di X, \\int_\\Omega |X(\\omega)| dP(\\omega), deve essere finito.\nRichiamo al Caso Discreto\nQuando abbiamo introdotto il valore atteso per variabili aleatorie discrete, abbiamo implicitamente utilizzato questo concetto di integrale astratto con la specifica misura di probabilità definita sui punti dello spazio campionario discreto. La notazione \\int_\\Omega X(\\omega) dP(\\omega) nel caso discreto significa semplicemente applicare la definizione di integrale astratto a quella particolare scelta di P (la misura di probabilità discreta), di \\Omega (l’insieme discreto) e della variabile aleatoria X definita su di esso.\nDefinizione Costruttiva del Valore Atteso\nPer dare un senso più concreto al valore atteso, possiamo seguire una costruzione in tre passaggi:\n1. Valore Atteso per Variabili Aleatorie Semplici Positive\nUna variabile aleatoria semplice positiva X può essere espressa come una combinazione lineare finita di funzioni indicatrici di insiemi A_i \\in \\mathcal{F} con coefficienti c_i \\ge 0:\nX(\\omega) = \\sum_{i=1}^n c_i \\mathbf{1}_{A_i}(\\omega)\ndove \\mathbf{1}_{A_i}(\\omega) = 1 se \\omega \\in A_i e 0 altrimenti.\nIl valore atteso di una variabile aleatoria semplice positiva X è definito come:\nE[X] = \\sum_{i=1}^n c_i P(A_i)\n2. Valore Atteso per Variabili Aleatorie Positive Generali\nPer una variabile aleatoria X \\ge 0, non necessariamente semplice, si costruisce una successione di variabili aleatorie semplici positive {X_n}_{n \\ge 1} che converge monotonamente a X, cioè 0 \\le X_n(\\omega) \\le X_{n+1}(\\omega) \\le X(\\omega) per ogni \\omega \\in \\Omega e \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega).\nIl valore atteso di X è quindi definito come il limite dei valori attesi delle variabili semplici approssimanti:\nE[X] = \\lim_{n \\to \\infty} E[X_n]\nQuesto limite esiste (può essere finito o +\\infty) ed è indipendente dalla particolare successione di variabili semplici che converge monotonamente a X.\n3. Valore Atteso per Variabili Aleatorie Generali\nPer una variabile aleatoria X generica (che può assumere valori sia positivi che negativi), si considerano la sua parte positiva X^+ = \\max(X, 0) e la sua parte negativa X^- = \\max(-X, 0). Si ha che X = X^+ - X^- e |X| = X^+ + X^-.\nIl valore atteso di X è definito come:\nE[X] = E[X^+] - E[X^-]\npurché entrambi E[X^+] e E[X^-] siano finiti.\nSe uno solo tra E[X^+] e E[X^-] è infinito, allora E[X] è definito come +\\infty o -\\infty rispettivamente. Se entrambi E[X^+] e E[X^-] sono infiniti, allora il valore atteso di X non è ben definito.\nUna variabile aleatoria X è detta integrabile se il suo valore atteso del modulo è finito, cioè E[|X|] &lt; \\infty. Questa condizione è equivalente a richiedere che sia E[X^+] &lt; \\infty che E[X^-] &lt; \\infty. In questo caso, il valore atteso E[X] è un numero reale finito.\nDefinizione Alternativa del Valore Atteso\nEsiste una definizione alternativa del valore atteso di una variabile aleatoria X (anche non positiva) come l’estremo superiore dei valori attesi di tutte le variabili aleatorie semplici positive S che sono minori o uguali a X puntualmente:\nE[X] = \\sup {E[S] \\mid S \\text{ è semplice, } 0 \\le S(\\omega) \\le X(\\omega) \\text{ per ogni } \\omega \\in \\Omega }\nQuesta definizione è equivalente alla definizione costruttiva basata sul limite di variabili semplici approssimanti.\nNotazioni per il Valore Atteso\nOltre alla notazione E[X], si possono trovare anche le seguenti notazioni per il valore atteso:\n\n\\int_\\Omega X(\\omega) dP(\\omega) (integrale astratto esplicito)\n\\langle X \\rangle (usata spesso nella letteratura fisica)\n\nIl professore indica che userà prevalentemente la notazione E[X].\nProprietà del Valore Atteso\nPoiché il valore atteso è un caso particolare di integrale astratto (rispetto alla misura di probabilità P), esso eredita diverse proprietà. Vediamo alcune delle più importanti:\nLinearità\nSiano X_1 e X_2 due variabili aleatorie con valore atteso finito (integrabili) definite sullo stesso spazio di probabilità (\\Omega, \\mathcal{F}, P), e siano a, b \\in \\mathbb{R}. Allora la variabile aleatoria aX_1 + bX_2 è integrabile e il suo valore atteso è dato da:\nE[aX_1 + bX_2] = aE[X_1] + bE[X_2]\nMonotonia\nSe P(X_1 \\ge X_2) = 1, allora i loro valori attesi soddisfano la stessa disuguaglianza:\nE[X_1] \\ge E[X_2]\nCome caso particolare, se P(X_1 \\ge 0) = 1, allora E[X_1] \\ge 0. Questa proprietà è leggermente più debole rispetto alla proprietà analoga per l’integrale astratto, in quanto la condizione è richiesta solo con probabilità 1, non per ogni \\omega \\in \\Omega.\nDisuguaglianza del Valore Assoluto\nPer una variabile aleatoria X_1 con valore atteso finito, vale la seguente disuguaglianza:\n|E[X_1]| \\le E[|X_1|]\nInsensibilità a Eventi di Probabilità Zero\nSe due variabili aleatorie X_1 e X_2 sono uguali con probabilità 1, cioè P(X_1 = X_2) = 1, allora i loro valori attesi sono uguali:\nE[X_1] = E[X_2]\nIn particolare, se P(X_1 = c) = 1 per una costante c \\in \\mathbb{R}, allora E[X_1] = c.\nCorollario: Se A \\in \\mathcal{F} è un evento con probabilità nulla, P(A) = 0, e X_1 è una variabile aleatoria integrabile, allora:\nE[X_1 \\mathbf{1}_A] = 0\nValore Atteso e Variabili Aleatorie a Valori Estesi\nLe definizioni di valore atteso possono essere estese a variabili aleatorie che possono assumere i valori +\\infty o -\\infty. Tuttavia, se il valore atteso E[X_1] è finito, allora la probabilità che X_1 assuma valori infiniti è zero:\nP(X_1 \\in \\mathbb{R}) = 1\nQuesto può essere utile in situazioni in cui dimostrare direttamente che una variabile aleatoria non assume valori infiniti è complicato, ad esempio nel caso di limiti di successioni di variabili aleatorie. Se si riesce a dimostrare che il valore atteso del limite è finito, allora il limite stesso sarà finito con probabilità 1.\nDipendenza dalla Legge della Variabile Aleatoria\nIl valore atteso di una variabile aleatoria X dipende unicamente dalla sua legge (o distribuzione di probabilità), e non specificamente dallo spazio di probabilità (\\Omega, \\mathcal{F}, P) su cui è definita. Questa è una giustificazione del perché spesso si parla di variabili aleatorie con specifiche distribuzioni (esponenziale, Gamma, Gaussiana) senza menzionare esplicitamente lo spazio di probabilità sottostante.\nNel caso di variabili aleatorie assolutamente continue, la legge è descritta dalla funzione di densità di probabilità f_X(x). In questo caso, il valore atteso può essere calcolato come:\nE[X] = \\int_{-\\infty}^{+\\infty} x f_X(x) dx\nNel caso di variabili aleatorie discrete, la legge è descritta dalla funzione di massa di probabilità p_X(x) = P(X=x). In questo caso, il valore atteso è dato da:\nE[X] = \\sum_x x p_X(x)\ndove la somma è estesa a tutti i possibili valori x che la variabile aleatoria può assumere.\nTeoremi di Convergenza\nUn’altra motivazione fondamentale per l’introduzione del concetto generale di valore atteso attraverso l’integrale astratto è la possibilità di enunciare e dimostrare importanti teoremi di convergenza per successioni di variabili aleatorie. Questi teoremi forniscono condizioni sotto le quali è possibile scambiare il limite con l’operatore di valore atteso.\nConvergenza di Variabili Aleatorie e Teoremi Fondamentali\nIntroduzione alla Convergenza di Variabili Aleatorie\nIl corso approfondirà diversi tipi di convergenza di variabili aleatorie. Questa è la prima volta che si introduce questo argomento, che sarà ripreso in seguito con maggiore dettaglio. È fondamentale ricordare che non esiste un unico tipo di convergenza per variabili aleatorie, pertanto è sempre necessario specificare l’aggettivo che qualifica il tipo di convergenza.\nConvergenza Quasi Certamente\nDefinizione di Convergenza Quasi Certamente\nConsideriamo una successione di variabili aleatorie {X_n}_{n \\ge 1} definite su un comune spazio di probabilità (\\Omega, \\mathcal{F}, P) a valori in \\mathbb{R}, e una variabile aleatoria X definita sullo stesso spazio di probabilità.\nDefinizione: La successione di variabili aleatorie {X_n} converge quasi certamente a X se la probabilità dell’insieme degli \\omega \\in \\Omega tali per cui il limite di X_n(\\omega) è uguale a X(\\omega) è pari a 1.\nIn simboli, scriviamo X_n \\xrightarrow{q.c.} X se $$\nP\\left(\\left{\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega)\\right}\\right) = 1\n\n#### Interpretazione della Convergenza Quasi Certamente\n\nPer ogni $\\omega$ fissato, $X_n(\\omega)$ è una successione di numeri reali. La convergenza quasi certa significa che questa successione converge a $X(\\omega)$ per tutti gli $\\omega$ appartenenti a un sottoinsieme di $\\Omega$ che ha probabilità 1.\n\n**Osservazione:** La convergenza quasi certa è &quot;leggermente meno&quot; stringente della convergenza puntuale. Se $X_n(\\omega)$ converge a $X(\\omega)$ per ogni $\\omega \\in \\Omega$, allora la convergenza quasi certa è automaticamente verificata, poiché l&#039;insieme ${\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega)}$ coincide con $\\Omega$, e $P(\\Omega) = 1$. Tuttavia, è possibile avere convergenza quasi certa anche se la convergenza puntuale non si verifica su un insieme di misura di probabilità nulla.\n\nL&#039;espressione &quot;quasi certamente&quot; indica che un certo evento (in questo caso, la convergenza puntuale di $X_n(\\omega)$ a $X(\\omega)$) si verifica su un insieme $\\Omega&#039; \\subseteq \\Omega$ tale che $P(\\Omega&#039;) = 1$.\n\n**Esempio:** Se $P(X_1 = 0) = 1$, allora si può dire che $X_1$ è quasi certamente uguale a 0. In tal caso, il valore atteso di $X_1$ è $E[X_1] = 0$.\n\n### Teorema di Convergenza Monotona\n\nQuesto teorema stabilisce un importante risultato sul limite del valore atteso di una successione di variabili aleatorie non negative che convergono in modo monotono.\n\n**Teorema di Convergenza Monotona:** Sia ${X_n}_{n \\ge 1}$ una successione di variabili aleatorie definite su uno spazio di probabilità $(\\Omega, \\mathcal{F}, P)$ tali che:\n\n- $X_n \\ge 0$ quasi certamente per ogni $n \\ge 1$. Questo significa che $P(X_n \\ge 0) = 1$ per ogni $n$.\n- $X_n$ converge a $X$ in modo monotono crescente quasi certamente, cioè $X_{n+1} \\ge X_n$ quasi certamente per ogni $n \\ge 1$, e $X_n \\xrightarrow{q.c.} X$. In termini di probabilità, $P(X_{n+1} \\ge X_n) = 1$ per ogni $n$, e $P\\left(\\left{\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_n(\\omega) = X(\\omega)\\right}\\right) = 1$.\n\nAllora, il limite dei valori attesi di $X_n$ è uguale al valore atteso del limite $X$: $$ \\lim_{n \\to \\infty} E[X_n] = E[X] $$ È importante notare che i valori attesi possono essere finiti o anche $+\\infty$. Se il membro di destra è infinito, allora anche il membro di sinistra deve essere infinito, e viceversa.\n\n**Osservazione:** Le due condizioni del teorema (non negatività e convergenza monotona) sono cruciali e il risultato non vale per una qualunque successione di variabili aleatorie.\n\n### Corollario sulla Convergenza di Serie di Variabili Aleatorie Non Negative\n\nQuesto corollario, derivabile dal teorema di convergenza monotona (e anche dal teorema di convergenza dominata), riguarda la convergenza di serie di variabili aleatorie non negative.\n\n**Corollario:** Sia ${X_n}_{n \\ge 1}$ una successione di variabili aleatorie tali che $X_n \\ge 0$ quasi certamente per ogni $n \\ge 1$. Se la serie dei valori attesi converge, cioè $\\sum_{i=1}^{\\infty} E[X_i] &lt; \\infty$, allora la serie $\\sum_{i=1}^{\\infty} X_i$ converge quasi certamente a una variabile aleatoria finita.\n\n**Dimostrazione (Esercizio):** Si consideri la successione delle somme parziali $S_n = \\sum_{i=1}^{n} X_i$. Poiché $X_i \\ge 0$, la successione ${S_n}_{n \\ge 1}$ è monotona crescente. Si applichi il teorema di convergenza monotona alla successione ${S_n}$. Se $\\sum_{i=1}^{\\infty} E[X_i] = L &lt; \\infty$, allora $\\lim_{n \\to \\infty} E[S_n] = E[\\lim_{n \\to \\infty} S_n] = E\\left[\\sum_{i=1}^{\\infty} X_i\\right] = L &lt; \\infty$. Se il valore atteso della somma è finito, allora la somma stessa deve essere finita quasi certamente (proprietà di finitezza del valore atteso non esplicitata nelle fonti, ma richiamata dal professore).\n\n**Esempio:** Supponiamo di avere una successione di variabili aleatorie $X_i \\ge 0$ tali che $E[X_i] \\le \\frac{1}{i^2}$. Sappiamo che la serie numerica $\\sum_{i=1}^{\\infty} \\frac{1}{i^2}$ converge. Quindi, per il corollario, la serie di variabili aleatorie $\\sum_{i=1}^{\\infty} X_i$ converge quasi certamente.\n\n**Importanza del Corollario:** Questo risultato è utile perché spesso è più semplice calcolare o stimare il valore atteso di singole variabili aleatorie o di una serie di valori attesi, piuttosto che studiare direttamente la convergenza quasi certa di una serie di variabili aleatorie.\n\n### Teorema di Convergenza Dominata\n\nQuesto è un altro teorema fondamentale che fornisce condizioni per scambiare il limite con l&#039;integrale (o il valore atteso) quando si ha convergenza quasi certa.\n\n**Teorema di Convergenza Dominata:** Sia ${X_n}_{n \\ge 1}$ una successione di variabili aleatorie definite su uno spazio di probabilità $(\\Omega, \\mathcal{F}, P)$ tale che:\n\n- $X_n$ converge quasi certamente a una variabile aleatoria $X$, cioè $X_n \\xrightarrow{q.c.} X$.\n- Esiste una variabile aleatoria $Y$ definita sullo stesso spazio di probabilità tale che $|X_n| \\le Y$ quasi certamente per ogni $n \\ge 1$, e il valore atteso di $|Y|$ è finito, cioè $E[|Y|] &lt; \\infty$.\n\nAllora, vale il seguente risultato sul limite dei valori attesi: $$ \\lim_{n \\to \\infty} E[X_n] = E[X] $$ **Osservazione:** A differenza del teorema di convergenza monotona, le variabili aleatorie $X_n$ non devono essere non negative né convergere in modo monotono; è sufficiente la convergenza quasi certa. Tuttavia, è necessario trovare una variabile aleatoria $Y$ &quot;dominante&quot; che sia integrabile (cioè con valore atteso finito) e che limiti in modulo tutte le $X_n$ quasi certamente.\n\n**Domanda del Professore:** Le variabili aleatorie $X_n$ nel teorema di convergenza dominata possono avere valore atteso più infinito?\n\n**Risposta:** No, perché se $|X_n| \\le Y$ quasi certamente e $E[|Y|] &lt; \\infty$, allora per la proprietà di monotonia del valore atteso (non esplicitata nelle fonti, ma richiamata dal professore), anche $E[|X_n|]$ deve essere finito, e quindi anche $E[X_n]$ è ben definito e finito.\n\n**Confronto con il Teorema di Convergenza Monotona:** Nel teorema di convergenza monotona per variabili non negative, era possibile che i valori attesi fossero infiniti. Nel teorema di convergenza dominata, la condizione di dominazione con una variabile integrabile implica che i valori attesi delle $X_n$ (e di $X$) sono sempre finiti.\n\n**Osservazioni aggiuntive sul Teorema di Convergenza Dominata:** Esistono diverse varianti del teorema di convergenza dominata, alcune delle quali prevedono una dominazione non da una singola variabile $Y$ ma da una successione di variabili aleatorie. Esistono anche versioni per misure sigma-finite e per l&#039;integrale astratto, ma non saranno trattate nel corso. La versione presentata è la più semplice e spesso sufficiente per le applicazioni.\n\n# Valore Atteso e Cambiamento di Variabili\n\n## Introduzione al Valore Atteso e al Problema del Calcolo di $E[g(X)]$\n\nIl valore atteso di una variabile aleatoria è un concetto fondamentale nella teoria della probabilità. In termini astratti, dato uno spazio di misura $(\\Omega, \\mathcal{F}, P)$ e una variabile aleatoria $Y: \\Omega \\rightarrow \\mathbb{R}$, il valore atteso di $Y$, denotato con $E[Y]$, è definito come l&#039;integrale di Lebesgue di $Y$ rispetto alla misura di probabilità $P$:\n\n$$E[Y] = \\int_{\\Omega} Y(\\omega) dP(\\omega)$$\n\nSpesso ci troviamo nella situazione in cui vogliamo calcolare il valore atteso di una funzione di una variabile aleatoria, ovvero $E[g(X)]$, dove $X: \\Omega \\rightarrow X$ è una variabile aleatoria a valori in uno spazio $X$, e $g: X \\rightarrow \\mathbb{R}$ è una funzione misurabile. Calcolare direttamente l&#039;integrale su $\\Omega$ può essere complicato, specialmente quando la struttura di $\\Omega$ e la natura di $X$ non sono esplicitamente note.\n\n## Cambiamento di Variabili Astratto\n\n### Schema Generale\n\nConsideriamo il seguente schema:\n\n$\\Omega \\xrightarrow{X} X \\xrightarrow{g} \\mathbb{R}$\n\ndove:\n\n- $(\\Omega, \\mathcal{F}, P)$ è uno spazio di misura.\n- $X: \\Omega \\rightarrow X$ è una funzione misurabile (una variabile aleatoria astratta a valori nello spazio $X$).\n- $g: X \\rightarrow \\mathbb{R}$ è una funzione misurabile.\n\nLa variabile aleatoria $Y = g(X)$ è quindi una funzione misurabile da $\\Omega$ a $\\mathbb{R}$, e il suo valore atteso è dato da:\n\n$$E[g(X)] = \\int_{\\Omega} g(X(\\omega)) dP(\\omega)$$\n\n### Teorema di Cambiamento di Variabili\n\nIl teorema di cambiamento di variabili fornisce un modo alternativo per calcolare questo valore atteso, spesso più semplice.\n\n**Teorema (Cambiamento di Variabili Astratto):** Siano $X: \\Omega \\rightarrow X$ una variabile aleatoria astratta (funzione misurabile) e $g: X \\rightarrow \\mathbb{R}$ una funzione misurabile. Sia $P_X$ la misura immagine di $P$ tramite $X$ su $X$. Se $E[|g(X)|] &lt; \\infty$, allora:\n\n$$E[g(X)] = \\int_{X} g(x) dP_X(x)$$\n\ndove $P_X(B) = P(X^{-1}(B)) = P({ \\omega \\in \\Omega : X(\\omega) \\in B })$ per ogni insieme misurabile $B \\subseteq X$. In altre parole, il valore atteso di $g(X)$ può essere calcolato come l&#039;integrale di $g$ sullo spazio $X$ rispetto alla misura indotta $P_X$.\n\n**Dimostrazione:** (Implicita nel testo, il professore afferma che se uno dei due integrali è ben definito, lo è anche l&#039;altro e sono uguali).\n\n### Esempio Concreto: Vettore Aleatorio in $\\mathbb{R}^D$\n\nConsideriamo un vettore aleatorio $X = (X_1, ..., X_D): \\Omega \\rightarrow \\mathbb{R}^D$. In questo caso, lo spazio $X$ è $\\mathbb{R}^D$ con la sua $\\sigma$-algebra dei boreliani $\\mathcal{B}(\\mathbb{R}^D)$. La misura indotta $P_X$ è la misura immagine su $\\mathbb{R}^D$, che è la legge (o distribuzione) del vettore aleatorio $X$.\n\nSe $g: \\mathbb{R}^D \\rightarrow \\mathbb{R}$ è una funzione misurabile, allora il valore atteso di $g(X)$ è dato da:\n\n$$E[g(X)] = \\int_{\\mathbb{R}^D} g(x_1, ..., x_D) dP_X(x_1, ..., x_D)$$\n\nQuesto integrale è un integrale di Lebesgue su $\\mathbb{R}^D$ rispetto alla misura $P_X$.\n\n**Corollario:** Se $X$ è un vettore aleatorio in $\\mathbb{R}^D$ e $g: \\mathbb{R}^D \\rightarrow \\mathbb{R}$ è misurabile tale che $E[|g(X)|] &lt; \\infty$, allora il valore atteso di $g(X)$ può essere calcolato come l&#039;integrale di $g$ rispetto alla legge (misura immagine) di $X$ su $\\mathbb{R}^D$. Questo è un passo importante perché ci permette di lavorare su uno spazio più concreto come $\\mathbb{R}^D$ invece dell&#039;astratto $\\Omega$.\n\n## Caso Particolare: Variabile Aleatoria Reale\n\nSe $X: \\Omega \\rightarrow \\mathbb{R}$ è una variabile aleatoria reale, allora lo spazio $X$ è $\\mathbb{R}$ con la $\\sigma$-algebra dei boreliani $\\mathcal{B}(\\mathbb{R})$, e $P_X$ è la legge di $X$ su $\\mathbb{R}$. Per una funzione misurabile $g: \\mathbb{R} \\rightarrow \\mathbb{R}$, il valore atteso di $g(X)$ è:\n\n$$E[g(X)] = \\int_{\\mathbb{R}} g(x) dP_X(x)$$\n\n### Caso Assolutamente Continuo\n\nSe la variabile aleatoria reale $X$ è assolutamente continua, allora la sua legge $P_X$ può essere rappresentata da una funzione di densità di probabilità $f_X(x) \\ge 0$ tale che $\\int_{\\mathbb{R}} f_X(x) dx = 1$. In questo caso, l&#039;integrale rispetto alla misura $P_X$ si riduce a un integrale di Riemann (o Lebesgue) rispetto alla misura di Lebesgue $dx$:\n\n$$E[g(X)] = \\int_{\\mathbb{R}} g(x) f_X(x) dx$$\n\nIn particolare, il valore atteso di $X$ stesso (quando $g(x) = x$) è:\n\n$$E[X] = \\int_{\\mathbb{R}} x f_X(x) dx$$\n\na condizione che $\\int_{\\mathbb{R}} |x| f_X(x) dx &lt; \\infty$.\n\n## Proprietà del Valore Atteso\n\nIl professore menziona alcune proprietà importanti del valore atteso, valide sia nel caso astratto che nei casi particolari (discreto e assolutamente continuo):\n\n- **Linearità:** $E[aY + bZ] = aE[Y] + bE[Z]$ per variabili aleatorie $Y, Z$ e costanti $a, b$.\n- **Disuguaglianza del Modulo:** $|E[Y]| \\le E[|Y|]$.\n- **Monotonia:** Se $Y \\le Z$ (puntualmente), allora $E[Y] \\le E[Z]$.\n- **Teoremi di Convergenza:** (Non specificati nel dettaglio, ma importanti per passare al limite sotto il segno di valore atteso).\n\nQueste proprietà sono particolarmente utili perché valgono in generale, indipendentemente dalla natura discreta o continua della variabile aleatoria.\n\n## Calcolo del Valore Atteso nei Casi Specifici\n\n### Caso 1: Variabile Aleatoria Discreta\n\nSe $X$ è un vettore aleatorio discreto a valori in $\\mathbb{R}^D$, allora assume un insieme finito o numerabile di valori ${x_i}_{i \\in I}$ con probabilità $p_i = P(X = x_i) &gt; 0$ tali che $\\sum_{i \\in I} p_i = 1$. La legge di $X$, $P_X$, è una misura discreta concentrata sui punti ${x_i}$. Per una funzione $g: \\mathbb{R}^D \\rightarrow \\mathbb{R}$, il valore atteso di $g(X)$ è dato dalla somma:\n\n$$E[g(X)] = \\sum_{i \\in I} g(x_i) P(X = x_i) = \\sum_{i \\in I} g(x_i) p_i$$\n\nQuesto era già stato visto come la proprietà P0 nel caso discreto.\n\n### Caso 2: Variabile Aleatoria Assolutamente Continua (Unidimensionale)\n\nSe $X$ è una variabile aleatoria reale assolutamente continua con densità $f_X(x)$, allora per una funzione $g: \\mathbb{R} \\rightarrow \\mathbb{R}$ tale che $E[|g(X)|] &lt; \\infty$, il valore atteso di $g(X)$ è dato da:\n\n$$E[g(X)] = \\int_{\\mathbb{R}} g(x) f_X(x) dx$$\n\nIn particolare, il valore atteso di $X$ è:\n\n$$E[X] = \\int_{\\mathbb{R}} x f_X(x) dx$$\n\nse $\\int_{\\mathbb{R}} |x| f_X(x) dx &lt; \\infty$.\n\n## Esempi di Calcolo del Valore Atteso\n\n### Esempio 1: Variabile Aleatoria Uniforme su $$\n\nSia $X$ una variabile aleatoria uniforme sull&#039;intervallo $$. La sua densità di probabilità è:\n\n$$f_X(x) = \\begin{cases} 1 &amp; \\text{se } 0 \\le x \\le 1 \\ 0 &amp; \\text{altrimenti} \\end{cases}$$\n\n**Calcolo di $E[X]$:**\n\n$$E[X] = \\int_{\\mathbb{R}} x f_X(x) dx = \\int_{0}^{1} x \\cdot 1 dx = \\left[ \\frac{1}{2} x^2 \\right]_{0}^{1} = \\frac{1}{2} (1)^2 - \\frac{1}{2} (0)^2 = \\frac{1}{2}$$\n\nQuesto risultato è intuitivo: il valore medio di una variabile uniformemente distribuita tra 0 e 1 è il punto medio dell&#039;intervallo.\n\n**Calcolo di $E[X^2 \\mathbb{1}_{{X &gt; 1/2}}]$:**\n\nSia $g(x) = x^2 \\mathbb{1}_{{x &gt; 1/2}}(x)$. Allora:\n\n$$E[g(X)] = \\int_{\\mathbb{R}} g(x) f_X(x) dx = \\int_{\\mathbb{R}} x^2 \\mathbb{1}_{{x &gt; 1/2}}(x) f_X(x) dx$$\n\nSostituendo la densità di $X$:\n\n$$E[g(X)] = \\int_{0}^{1} x^2 \\mathbb{1}_{{x &gt; 1/2}}(x) \\cdot 1 dx$$\n\nL&#039;indicatrice $\\mathbb{1}_{{x &gt; 1/2}}(x)$ è 1 se $x &gt; 1/2$ e 0 altrimenti. Quindi l&#039;integrale diventa:\n\n$$E[g(X)] = \\int_{1/2}^{1} x^2 dx = \\left[ \\frac{1}{3} x^3 \\right]_{1/2}^{1} = \\frac{1}{3} (1)^3 - \\frac{1}{3} \\left(\\frac{1}{2}\\right)^3 = \\frac{1}{3} - \\frac{1}{3} \\cdot \\frac{1}{8} = \\frac{1}{3} - \\frac{1}{24} = \\frac{8 - 1}{24} = \\frac{7}{24}$$\n\n### Esempio 2: Variabile Aleatoria Esponenziale (Esercizio)\n\nSia $X$ una variabile aleatoria esponenziale di parametro $\\lambda = 3$. La sua densità di probabilità è:\n\n$$f_X(x) = \\begin{cases} 3 e^{-3x} &amp; \\text{se } x \\ge 0 \\ 0 &amp; \\text{se } x &lt; 0 \\end{cases}$$\n\n**Esercizio:** Calcolare il tempo medio di vita, ovvero $E[X]$:\n\n$$E[X] = \\int_{\\mathbb{R}} x f_X(x) dx = \\int_{0}^{+\\infty} x \\cdot 3 e^{-3x} dx$$\n\nQuesto integrale può essere risolto utilizzando l&#039;integrazione per parti.\n\n## Conseguenza Importante: Variabili Aleatorie con la Stessa Legge\n\n**Corollario:** Se due variabili aleatorie $X$ e $Y$ hanno la stessa legge (ovvero $P_X = P_Y$), allora, se i rispettivi valori attesi esistono, si ha $E[X] = E[Y]$ e più in generale, per una funzione misurabile $g$, $E[g(X)] = E[g(Y)]$. Questo è vero anche se $X$ e $Y$ sono definite su spazi di probabilità diversi. Il valore atteso dipende unicamente dalla legge (distribuzione) della variabile aleatoria e non dalla struttura dello spazio di probabilità sottostante.\n\n## Caso Multidimensionale Assolutamente Continuo (Chiarimento)\n\nUn vettore aleatorio $X = (X_1, ..., X_D)$ è assolutamente continuo se esiste una funzione di densità congiunta $f_X(x_1, ..., x_D) \\ge 0$ tale che per ogni insieme boreliano $A \\subseteq \\mathbb{R}^D$:\n\n$$P(X \\in A) = \\int_{A} f_X(x_1, ..., x_D) dx_1 ... dx_D$$\n\nIn questo caso, per una funzione misurabile $g: \\mathbb{R}^D \\rightarrow \\mathbb{R}$ tale che $E[|g(X)|] &lt; \\infty$, il valore atteso di $g(X)$ è dato dall&#039;integrale multiplo:\n\n$$E[g(X)] = \\int_{\\mathbb{R}^D} g(x_1, ..., x_D) f_X(x_1, ..., x_D) dx_1 ... dx_D$$\n\nQuesto estende il concetto del caso unidimensionale a dimensioni superiori.\n\n## Conclusione\n\nIl teorema di cambiamento di variabili è uno strumento fondamentale per il calcolo del valore atteso di funzioni di variabili aleatorie. Permette di passare da un integrale astratto sullo spazio $\\Omega$ a un integrale sullo spazio dei valori della variabile aleatoria (come $\\mathbb{R}$ o $\\mathbb{R}^D$) rispetto alla legge indotta. Nei casi particolari di variabili discrete e assolutamente continue, questo si traduce in somme e integrali (singoli o multipli) che possono essere calcolati utilizzando le rispettive funzioni di massa o densità di probabilità. Gli esempi illustrano come applicare queste formule in pratica.\n#### References\n\n[[Appunti Prob-lez13.pdf]]"},"6--full-note/prob-lez14":{"slug":"6--full-note/prob-lez14","filePath":"6- full note/prob-lez14.md","title":"prob-lez14","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/probabilità","3--tag/sbobine","atteso"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-08 15:51\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:probabilità  sbobine\nprob-lez14\nVarianza di una Variabile Aleatoria\nDefinizione di Varianza\nSia X una variabile aleatoria tale che il valore atteso di X^2, indicato come E[X^2], sia finito.\nSi definisce varianza di X, indicata con Var(X) o \\sigma_X^2, il valore atteso di (X - m)^2, dove m è il valore atteso di X, ovvero m = E[X].\nMatematicamente: Var(X) = E[(X - E[X])^2]\nQuesta definizione è valida sia per variabili aleatorie discrete che continue.\nCommento: La varianza misura la dispersione dei valori di una variabile aleatoria attorno alla sua media. Rappresenta la media dei quadrati delle distanze tra ogni realizzazione della variabile aleatoria e la sua media.\nMomenti di una Variabile Aleatoria\nMomento k-esimo\nIl momento k-esimo di una variabile aleatoria è definito come E[X^k], se questo valore atteso esiste ed è finito, dove k è un intero.\nMomento k-esimo assoluto\nIl momento k-esimo assoluto di una variabile aleatoria è definito come E[|X|^p], se questo valore atteso esiste ed è finito, dove p è un numero reale maggiore o uguale a 0 (p \\ge 0).\nCommento: La definizione di varianza richiede l’esistenza del momento secondo finito (E[X^2] &lt; \\infty). Se il momento secondo è finito, allora anche la media (momento primo) è finita.\n\nStruttura Tipica degli Esami\nGli esami sono generalmente costituiti da:\n\nDomande a risposta multipla (solitamente due nel compitino).\nDomande a risposta aperta (una nel compitino, due nei compiti più lunghi).\nEsercizi.\n\nEsempio di domanda a risposta aperta da un compito passato: Enunciare la definizione di varianza e dimostrare alcune sue proprietà.\nProprietà della Varianza\nProprietà 1: Non negatività\nProposizione: Var(X) \\ge 0.\nDimostrazione: La varianza è definita come il valore atteso di (X - m)^2, dove (X - m)^2 è sempre una quantità non negativa (essendo un quadrato). Il valore atteso di una funzione non negativa è sempre non negativo per la proprietà di monotonia del valore atteso.\nProprietà 2: Formula alternativa per la varianza\nProposizione: Var(X) = E[X^2] - (E[X])^2.\nDimostrazione: Partendo dalla definizione di varianza: Var(X) = E[(X - E[X])^2] Svolgendo il quadrato: Var(X) = E[X^2 + (E[X])^2 - 2X E[X]] Utilizzando la linearità del valore atteso: Var(X) = E[X^2] + E[(E[X])^2] - E[2X E[X]] Poiché E[X] è una costante, (E[X])^2 è anch’essa una costante, e 2E[X] è una costante. Quindi: Var(X) = E[X^2] + (E[X])^2 E - 2E[X] E[X] Ricordando che E = 1: Var(X) = E[X^2] + (E[X])^2 - 2(E[X])^2 Var(X) = E[X^2] - (E[X])^2\nCommento: Questa formula è spesso più comoda per calcolare la varianza, in quanto richiede il calcolo del valore atteso di X^2 e del quadrato del valore atteso di X.\nErrore comune da evitare: Non scrivere che Var(X) = E[X^2] - E[X]^2 (senza le parentesi), in quanto E[X^2] è generalmente diverso da (E[X])^2.\n\nProprietà 3: Varianza di una trasformazione lineare\nProposizione: Var(aX + b) = a^2 Var(X), per ogni a, b \\in \\mathbb{R} (costanti).\nDimostrazione: Utilizzando la definizione di varianza: Var(aX + b) = E[((aX + b) - E[aX + b])^2] Per la linearità del valore atteso, E[aX + b] = aE[X] + b. Sostituendo: Var(aX + b) = E[((aX + b) - (aE[X] + b))^2] Var(aX + b) = E[(aX + b - aE[X] - b)^2] Var(aX + b) = E[(aX - aE[X])^2] Var(aX + b) = E[(a(X - E[X]))^2] Var(aX + b) = E[a^2 (X - E[X])^2] Poiché a^2 è una costante, può essere portata fuori dal valore atteso per la linearità: Var(aX + b) = a^2 E[(X - E[X])^2] Riconoscendo che E[(X - E[X])^2] è la definizione di Var(X): Var(aX + b) = a^2 Var(X)\nCommento: Questa proprietà mostra come la varianza viene scalata per trasformazioni lineari. L’aggiunta di una costante b non influisce sulla varianza, mentre la moltiplicazione per una costante a comporta una moltiplicazione della varianza per a^2.\n\nProprietà 4: Varianza nulla\nProposizione: Var(X) = 0 se e solo se esiste una costante c tale che P(X = c) = 1.\nDimostrazione: (\\Rightarrow) Se Var(X) = 0, allora E[(X - E[X])^2] = 0. Poiché (X - E[X])^2 è una variabile aleatoria non negativa, il suo valore atteso è zero se e solo se la variabile è zero con probabilità 1. Quindi, P((X - E[X])^2 = 0) = 1, il che implica P(X - E[X] = 0) = 1, ovvero P(X = E[X]) = 1. In questo caso, c = E[X].\n(\\Leftarrow) Se esiste una costante c tale che P(X = c) = 1, allora E[X] = c. Quindi, Var(X) = E[(X - c)^2]. Poiché X = c con probabilità 1, (X - c)^2 = (c - c)^2 = 0 con probabilità 1. Pertanto, E[(X - c)^2] = E = 0, quindi Var(X) = 0.\nCommento: Una variabile aleatoria ha varianza zero solo se è degenere, cioè assume un singolo valore con probabilità 1.\n\nFinitudine dei Momenti\nOsservazione: Se il momento S-esimo assoluto di X è finito per S &gt; 0 (E[|X|^S] &lt; \\infty), allora il momento r-esimo assoluto di X è finito per ogni 0 &lt; r &lt; S (E[|X|^r] &lt; \\infty).\nSpiegazione: Si considera la variabile aleatoria non negativa |X|^r. Si ha che |X|^r \\le 1 + |X|^S. Applicando la linearità e la monotonia del valore atteso per variabili aleatorie positive (se P(Y \\le Z) = 1, allora E[Y] \\le E[Z]): E[|X|^r] \\le E[1 + |X|^S] = E + E[|X|^S] = 1 + E[|X|^S] Poiché E[|X|^S] è finito per ipotesi, anche 1 + E[|X|^S] è finito. Pertanto, E[|X|^r] è finito.\nConseguenza: Se il momento secondo è finito (E[X^2] &lt; \\infty), allora anche il momento primo assoluto (e quindi il momento primo) è finito (E[|X|] &lt; \\infty e E[X] &lt; \\infty). Questo giustifica l’assunzione che il valore atteso m = E[X] sia finito nella definizione di varianza.\n\nStandardizzazione di una Variabile Aleatoria\nSia X una variabile aleatoria con valore atteso m = E[X] e varianza finita Var(X) = \\sigma^2, dove \\sigma = \\sqrt{Var(X)} è la deviazione standard (assumendo \\sigma &gt; 0).\nSi definisce la standardizzazione di X una nuova variabile aleatoria Y data da: Y = \\frac{X - m}{\\sigma}\nProprietà della Variabile Aleatoria Standardizzata\nMedia di Y\nE[Y] = E\\left[\\frac{X - m}{\\sigma}\\right] = E\\left[\\frac{1}{\\sigma}X - \\frac{m}{\\sigma}\\right] Utilizzando la linearità del valore atteso: E[Y] = \\frac{1}{\\sigma}E[X] - \\frac{m}{\\sigma}E = \\frac{1}{\\sigma}m - \\frac{m}{\\sigma}(1) = \\frac{m}{\\sigma} - \\frac{m}{\\sigma} = 0 Quindi, la variabile aleatoria standardizzata Y ha media 0.\nVarianza di Y\nVar(Y) = Var\\left[\\frac{X - m}{\\sigma}\\right] = Var\\left[\\frac{1}{\\sigma}X - \\frac{m}{\\sigma}\\right] Utilizzando la proprietà Var(aX + b) = a^2 Var(X) con a = \\frac{1}{\\sigma} e b = -\\frac{m}{\\sigma}: Var(Y) = \\left(\\frac{1}{\\sigma}\\right)^2 Var(X) = \\frac{1}{\\sigma^2} \\sigma^2 = 1 Quindi, la variabile aleatoria standardizzata Y ha varianza 1.\nCommento: La standardizzazione trasforma una variabile aleatoria in una con media zero e varianza unitaria. Questo è utile per confrontare variabili aleatorie con scale e medie diverse. La standardizzazione non richiede alcuna ipotesi sulla forma della distribuzione di X, ma solo che abbia varianza finita.\n\nTrasformazione Lineare di una Variabile Aleatoria (Modello Scala-Posizione)\nSia X_0 una variabile aleatoria con funzione di ripartizione F_{X_0}(x_0). Definiamo una nuova variabile aleatoria X come una trasformazione lineare di X_0: X = sX_0 + \\mu dove \\mu \\in \\mathbb{R} e s &gt; 0 sono costanti. Questo tipo di modello è chiamato modello scala-posizione. \\mu rappresenta la traslazione (posizione), e s rappresenta la dilatazione o contrazione (scala).\nFunzione di Ripartizione di X\nProposizione: La funzione di ripartizione di X, F_X(x) = P(X \\le x), è data da: F_X(x) = F_{X_0}\\left(\\frac{x - \\mu}{s}\\right)\nDimostrazione: F_X(x) = P(X \\le x) = P(sX_0 + \\mu \\le x) Sottraendo \\mu da entrambi i lati della disuguaglianza: F_X(x) = P(sX_0 \\le x - \\mu) Dividendo per s (ricordando che s &gt; 0, quindi la direzione della disuguaglianza non cambia): F_X(x) = P\\left(X_0 \\le \\frac{x - \\mu}{s}\\right) Per definizione di funzione di ripartizione di X_0: F_X(x) = F_{X_0}\\left(\\frac{x - \\mu}{s}\\right)\n\nFunzione di Densità di X (se X_0 è assolutamente continua)\nProposizione: Se X_0 è assolutamente continua con funzione di densità f_{X_0}(x_0), allora anche X è assolutamente continua e la sua funzione di densità f_X(x) è data da: f_X(x) = \\frac{1}{s} f_{X_0}\\left(\\frac{x - \\mu}{s}\\right)\nDimostrazione (informale): La funzione di densità è la derivata della funzione di ripartizione (dove esiste). Quindi: f_X(x) = \\frac{d}{dx} F_X(x) = \\frac{d}{dx} F_{X_0}\\left(\\frac{x - \\mu}{s}\\right) Utilizzando la regola della catena: f_X(x) = f_{X_0}\\left(\\frac{x - \\mu}{s}\\right) \\cdot \\frac{d}{dx}\\left(\\frac{x - \\mu}{s}\\right) \\frac{d}{dx}\\left(\\frac{x - \\mu}{s}\\right) = \\frac{1}{s} \\frac{d}{dx}(x - \\mu) = \\frac{1}{s}(1 - 0) = \\frac{1}{s} Quindi: f_X(x) = \\frac{1}{s} f_{X_0}\\left(\\frac{x - \\mu}{s}\\right)\nCommento: Questa trasformazione mostra come la funzione di ripartizione e la funzione di densità cambiano sotto una trasformazione lineare. La divisione per s nella funzione di densità assicura che l’integrale della densità di X su tutto \\mathbb{R} sia ancora uguale a 1. La standardizzazione è un caso particolare di questa trasformazione con s = \\sigma e \\mu = m.\n\nEsercizi e Materiali Aggiuntivi\nIl professore ha caldamente invitato a fare gli esercizi, sia quelli svolti durante le esercitazioni di questa e della prossima settimana, sia quelli indicati nel materiale aggiuntivo fornito.\nNel materiale aggiuntivo è presente un riferimento puntuale agli esercizi e alle domande (sia teoriche che a risposta multipla) tratte dai compiti d’esame dell’anno scorso che si possono già svolgere con le conoscenze acquisite fino a questa lezione (inclusa la varianza). Questi esercizi rappresentano un buon esempio di ciò che potrebbe essere chiesto nel compitino.\nEsempio discusso dal professore: Considerare una variabile aleatoria discreta X che assume valori k con probabilità proporzionale a \\frac{k}{k^c} per k \\ge 1 (dove c è una costante tale che la serie \\sum_{k=1}^\\infty \\frac{k}{k^c} converge). In questo caso, la probabilità che X sia finita è 1, ma il valore atteso di X potrebbe essere infinito (ad esempio, se c \\le 2). Questo illustra che avere probabilità 1 che una variabile sia finita non implica che il suo valore atteso sia finito. La dimostrazione fornita era che E[X] = \\sum_{k} k \\cdot P(X=k), e se P(X=k) = \\frac{C k}{k^c}, allora E[X] = \\sum_{k} k \\cdot \\frac{C k}{k^c} = C \\sum_{k} \\frac{k^2}{k^c} = C \\sum_{k} k^{2-c}, che diverge se 2-c \\ge -1 (ovvero c \\le 3). L’esempio più preciso fatto dal professore era con P(X=k) \\propto \\frac{1}{k^c}, e in quel caso E[X] = \\sum k \\cdot \\frac{C}{k^c} = C \\sum k^{1-c}, che diverge se 1-c \\ge -1 (c \\le 2). Errore nella trascrizione precedente, la proporzionalità era a K/K^c e l’esempio fatto era che E[X] = \\sum K \\cdot \\frac{C K}{K^c} = C \\sum K^{2-c} diverge se 2-c \\ge -1 (c \\le 3). Tuttavia, il concetto chiave rimane: probabilità di essere finita uguale a 1 non implica valore atteso finito.\nIl professore ha anche menzionato che nei prossimi giorni potrebbe essere fornito ulteriore materiale.\n\n\nSpiegazione dei Concetti Chiave sulle Variabili Aleatorie\nDensità e Funzione di Ripartizione\nIndividuare la Densità e la Sua Verifica\nIl professore spiega come, data una funzione di ripartizione F(x), si possa ipotizzare la forma della densità f(x). Il metodo suggerito è di “guardare in faccia” la funzione di ripartizione. Se la funzione di ripartizione è concreta, si può controllare se è possibile derivarla.\nFormalmente, se si ha una funzione di ripartizione F_X(x), si può tentare di trovare la densità f_X(x) derivandola formalmente: f_X(x) = \\frac{d}{dx} F_X(x).\nTuttavia, il professore avverte che la derivata potrebbe non esistere in tutti i punti.\nUna volta ottenuta una forma per la densità, è necessario verificarla. La verifica consiste nel calcolare l’integrale della densità così ottenuta tra -\\infty e x e controllare se si ottiene la funzione di ripartizione originale: F_X(x) = \\int_{-\\infty}^{x} f_X(t) dt.\nQuesto processo di verifica è descritto come un cambio di variabili nell’integrale.\nModello Scala Posizione\nDefinizione e Vantaggi\nNel contesto di un modello scala posizione, si ha spesso una funzione di ripartizione o una densità assolutamente continua. La proprietà fondamentale di questo modello è che, a partire da una densità, si può costruire un’intera famiglia di densità tramite una trasformazione di scala e posizione.\nEsempio della Famiglia Gaussiana\nUn esempio significativo di modello scala posizione è la famiglia delle distribuzioni Gaussiane (o Normali) al variare dei parametri \\mu (media) e \\sigma^2 (varianza).\nLa densità di una variabile aleatoria X Gaussiana con media \\mu e varianza \\sigma^2 è data da: f_X(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}\nConsiderando una variabile aleatoria X_0 Gaussiana standard (con media 0 e varianza 1), la cui densità è: f_{X_0}(x_0) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x_0^2}{2}}.\nSi può notare che la densità di X può essere espressa in termini della densità di X_0: f_X(x) = f_{X_0}\\left(\\frac{x - \\mu}{\\sigma}\\right) \\cdot \\frac{1}{\\sigma}.\nQuesto dimostra che una variabile aleatoria Gaussiana con parametri \\mu e \\sigma^2 può essere vista come un modello scala posizione a partire da una Gaussiana standard. In altre parole, X può essere generata da X_0 tramite la trasformazione: X = \\sigma X_0 + \\mu.\nIl professore sottolinea che questo è un modo comodo di pensare una Gaussiana con parametri \\mu e \\sigma^2.\n\nValore Atteso e Varianza in un Modello Scala Posizione\nTrasformazioni Lineari e Momenti\nConsiderando una trasformazione scala posizione di una variabile aleatoria X_0 con parametri s (scala) e \\mu (posizione), definita come X = sX_0 + \\mu.\nSe la varianza di X_0 è finita, allora il valore atteso di X è: E[X] = E[sX_0 + \\mu] = sE[X_0] + \\mu.\nE la varianza di X è: Var(X) = Var(sX_0 + \\mu) = s^2 Var(X_0).\n\nDipendenza dai Momenti della Variabile Base\nIl professore evidenzia che in un modello scala posizione, \\mu non è sempre la media di X e s non è sempre la varianza di X. Dipende dai valori della media e della varianza di X_0.\n\nSe E[X_0] = 0, allora E[X] = \\mu.\nSe Var(X_0) = 1, allora Var(X) = s^2.\n\nEsempio della Gaussiana (Ritorno)\nNel caso della Gaussiana, se X_0 \\sim N(0, 1), allora E[X_0] = 0 e Var(X_0) = 1. Di conseguenza, se X = \\sigma X_0 + \\mu, allora E[X] = \\mu e Var(X) = \\sigma^2. Questo giustifica perché \\mu e \\sigma^2 sono chiamati rispettivamente media e varianza per la distribuzione Gaussiana.\nModello Scala Posizione Senza Momenti Finiti: L’Esempio della Cauchy\nIl professore menziona che si può avere un modello scala posizione anche per variabili aleatorie che non hanno varianza o media finita, come la distribuzione di Cauchy. Nella parametrizzazione del professore (indicata con S e M), la distribuzione di Cauchy è un modello scala posizione nonostante non ammetta né media né varianza finita.\nValore Atteso e Varianza della Gaussiana Standard\nVerifica della Media Nulla\nPer verificare che una Gaussiana standard X_0 ha media nulla, si calcola il valore atteso: E[X_0] = \\int_{-\\infty}^{+\\infty} x f_{X_0}(x) dx = \\int_{-\\infty}^{+\\infty} x \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}} dx.\nLa funzione integranda g(x) = x e^{-\\frac{x^2}{2}} è una funzione dispari (simmetrica rispetto all’origine), cioè g(-x) = -g(x). Pertanto, l’integrale su un intervallo simmetrico come (-\\infty, +\\infty) è uguale a 0: E[X_0] = 0.\nVerifica della Varianza Unitaria\nLa varianza di X_0 è data da Var(X_0) = E[X_0^2] - (E[X_0])^2. Poiché E[X_0] = 0, si ha Var(X_0) = E[X_0^2].\nVar(X_0) = \\int_{-\\infty}^{+\\infty} x^2 f_{X_0}(x) dx = \\int_{-\\infty}^{+\\infty} x^2 \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}} dx.\nIl professore lascia come esercizio verificare che questo integrale è uguale a 1.\n\nDisuguaglianze Basate sul Valore Atteso\nIntroduzione\nIl professore introduce il concetto di disuguaglianze costruite a partire dai valori attesi, tra cui la varianza, come strumenti per stimare quantità in probabilità.\nDisuguaglianza di Jensen\nEnunciato\nSia X una variabile aleatoria reale tale che E[X] sia finito. Sia g: \\mathbb{R} \\to \\mathbb{R} una funzione convessa e supponiamo che E[g(X)] sia ben definito e finito. Allora vale la disuguaglianza di Jensen: g(E[X]) \\le E[g(X)].\nFunzioni Convesse\nUna funzione g(x) è convessa se, per ogni coppia di punti x_1, x_2 e per ogni \\lambda \\in, si ha: g(\\lambda x_1 + (1 - \\lambda) x_2) \\le \\lambda g(x_1) + (1 - \\lambda) g(x_2). Geometricamente, il segmento che congiunge due punti sul grafico della funzione sta sopra o sulla funzione stessa.\nEsempi di Funzioni Convesse\nEsempi tipici di funzioni convesse sono il quadrato (g(x) = x^2) e il modulo (g(x) = |x|).\nRelazione con la Disuguaglianza del Modulo\nNel caso del modulo (g(x) = |x|), la disuguaglianza di Jensen diventa: |E[X]| \\le E[|X|]. Questa è la disuguaglianza del modulo, che può aiutare a ricordare la direzione della disuguaglianza di Jensen per funzioni convesse.\n\nDisuguaglianza di Markov Generalizzata\nEnunciato\nSia h: \\mathbb{R} \\to [0, +\\infty) una funzione misurabile non negativa tale che E[h(X)] &lt; +\\infty. Allora, per ogni \\epsilon &gt; 0, si ha: P(h(X) \\ge \\epsilon) \\le \\frac{E[h(X)]}{\\epsilon}\nDimostrazione\nSi definisce una variabile aleatoria Y = h(X) \\mathbb{1}_{{h(X) \\ge \\epsilon}}, dove \\mathbb{1}_{{h(X) \\ge \\epsilon}} è la funzione indicatrice dell’evento {h(X) \\ge \\epsilon}.\n\nSe h(X) &lt; \\epsilon, allora \\mathbb{1}_{{h(X) \\ge \\epsilon}} = 0, e Y = h(X) \\ge 0.\nSe h(X) \\ge \\epsilon, allora \\mathbb{1}_{{h(X) \\ge \\epsilon}} = 1, e Y = h(X) \\ge \\epsilon.\n\nQuindi, Y è una variabile aleatoria non negativa (Y \\ge 0). Inoltre, Y \\ge \\epsilon \\mathbb{1}_{{h(X) \\ge \\epsilon}}.\nPrendendo il valore atteso di entrambi i lati e usando la linearità del valore atteso e il fatto che E[\\mathbb{1}_A] = P(A): E[Y] \\ge E[\\epsilon \\mathbb{1}_{{h(X) \\ge \\epsilon}}] = \\epsilon E[\\mathbb{1}_{{h(X) \\ge \\epsilon}}] = \\epsilon P(h(X) \\ge \\epsilon).\nD’altra parte, per definizione di Y: E[Y] = E[h(X) \\mathbb{1}_{{h(X) \\ge \\epsilon}}].\nPoiché h(X) \\mathbb{1}_{{h(X) \\ge \\epsilon}} \\le h(X) (essendo \\mathbb{1} o 0 o 1 e h(X) \\ge 0), per la proprietà di monotonia del valore atteso: E[Y] \\le E[h(X)].\nCombinando le due disuguaglianze per E[Y]: \\epsilon P(h(X) \\ge \\epsilon) \\le E[Y] \\le E[h(X)].\nDividendo per \\epsilon (che è positivo): P(h(X) \\ge \\epsilon) \\le \\frac{E[h(X)]}{\\epsilon}.\n\nDisuguaglianza di Markov\nLa disuguaglianza di Markov è un caso particolare della disuguaglianza di Markov generalizzata. Sia p &gt; 0 e supponiamo che E[|X|^p] &lt; +\\infty. Scegliendo h(x) = |x|^p e \\epsilon = a^p (per a &gt; 0) nella disuguaglianza di Markov generalizzata, si ottiene: P(|X|^p \\ge a^p) \\le \\frac{E[|X|^p]}{a^p}.\nPoiché |X|^p \\ge a^p è equivalente a |X| \\ge a per p &gt; 0 e a &gt; 0, la disuguaglianza di Markov è: P(|X| \\ge a) \\le \\frac{E[|X|^p]}{a^p}.\nSpesso la disuguaglianza di Markov viene usata con p = 1: P(|X| \\ge a) \\le \\frac{E[|X|]}{a}.\n\nDisuguaglianza di Chebyshev\nLa disuguaglianza di Chebyshev è un altro caso particolare della disuguaglianza di Markov generalizzata. Supponiamo che la varianza di X, Var(X) = \\sigma^2, sia finita. Si sceglie h(x) = (x - E[X])^2 e \\epsilon = \\epsilon^2 (usando \\epsilon per la distanza dalla media) nella disuguaglianza di Markov generalizzata.\nP((X - E[X])^2 \\ge \\epsilon^2) \\le \\frac{E[(X - E[X])^2]}{\\epsilon^2}.\nL’evento (X - E[X])^2 \\ge \\epsilon^2 è equivalente a |X - E[X]| \\ge \\epsilon. Inoltre, E[(X - E[X])^2] = Var(X). Quindi la disuguaglianza di Chebyshev è: P(|X - E[X]| \\ge \\epsilon) \\le \\frac{Var(X)}{\\epsilon^2}.\nQuesta disuguaglianza fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una quantità maggiore o uguale a \\epsilon, in termini della sua varianza. Il professore commenta che se \\epsilon è piccolo, il limite potrebbe essere maggiore di 1 e quindi poco significativo, ma se la varianza è piccola, la probabilità di grandi deviazioni dalla media è limitata superiormente da un valore piccolo.\n\nRelazione tra Momenti Finiti\nIl professore introduce brevemente la relazione tra momenti finiti di ordini diversi. Se il momento s-esimo di |X| è finito (E[|X|^s] &lt; +\\infty) e r \\le s, allora anche il momento r-esimo di |X| è finito (E[|X|^r] &lt; +\\infty). Questa proprietà è stata dimostrata in precedenza utilizzando una disuguaglianza.\nDisuguaglianza di Lyapunov\nLa disuguaglianza di Lyapunov fornisce una relazione più precisa tra i momenti finiti. Se E[|X|^s] &lt; +\\infty per s &gt; r \\ge 0, allora: (E[|X|^r])^{1/r} \\le (E[|X|^s])^{1/s}.\nQuesta disuguaglianza implica che se il momento s-esimo è finito, allora anche tutti i momenti di ordine inferiore r (con r \\ge 0) sono finiti. La disuguaglianza di Lyapunov può essere dimostrata come conseguenza della disuguaglianza di Jensen. Il termine (E[|X|^p])^{1/p} è chiamato norma L^p di X. La disuguaglianza di Lyapunov afferma che la norma L^p è una funzione crescente di p.\nVariabili Aleatorie con Momento p-esimo Finito e Spazi L^p\nOsservazioni Preliminari sulle Disuguaglianze di Probabilità\nIntroduzione agli Spazi L^p\nSi introduce l’argomento delle variabili aleatorie con momento p-esimo finito, che sono collegate agli spazi L^p. Il professore specifica che la trattazione sarà limitata al caso delle variabili aleatorie, senza approfondire la teoria generale degli spazi L^p e della misura.\nDefinizione di L^p\nSi fissa p &gt; 0. Dato uno spazio di probabilità (\\Omega, \\mathcal{F}, P), si definisce L^p = L^p(\\Omega, \\mathcal{F}, P) (a volte indicato anche come L^p(\\Omega) o semplicemente L^p) come l’insieme di tutte le variabili aleatorie X a valori reali (borelliani) tali che il loro momento p-esimo è finito, ovvero E[|X|^p] &lt; \\infty.\nProprietà degli Spazi L^p\nConsideriamo due variabili aleatorie X e Y definite sullo stesso spazio di probabilità, tali che X \\in L^p e Y \\in L^p, cioè entrambe hanno momento p-esimo finito.\nSomma di Variabili Aleatorie in L^p\nUna domanda naturale è cosa si può dire di X + Y.\n\n\nDisuguaglianza Elementare per |X + Y|^p: Si ricorda una disuguaglianza elementare:\n\nSe 0 &lt; p \\le 1, allora |x + y|^p \\le |x|^p + |y|^p per ogni x, y \\in \\mathbb{R}.\nSe p &gt; 1, allora esiste una costante C_p (che dipende da p) tale che |x + y|^p \\le C_p (|x|^p + |y|^p) per ogni x, y \\in \\mathbb{R}. Questa disuguaglianza può essere dimostrata usando la proprietà di convessità della funzione x \\mapsto |x|^p per p &gt; 1.\n\n\n\n\nChiusura di L^p rispetto alla Somma: Se X_1 \\in L^p e X_2 \\in L^p, allora X_1 + X_2 \\in L^p.\n\nPer dimostrarlo, si considera il momento p-esimo di |X_1 + X_2|:\n\nE[|X_1 + X_2|^p] \\le E[C_p (|X_1|^p + |X_2|^p)] = C_p E[|X_1|^p] + C_p E[|X_2|^p] &lt; \\infty, dove C_p = 1 se 0 &lt; p \\le 1 e C_p = 2^{p-1} se p &gt; 1 (quest’ultima non è esplicitamente menzionata nel testo, ma è una forma comune della costante).\n\n\nPoiché E[|X_1|^p] &lt; \\infty e E[|X_2|^p] &lt; \\infty, anche E[|X_1 + X_2|^p] è finito, quindi X_1 + X_2 \\in L^p.\n\n\n\nChiusura di L^p rispetto alla Moltiplicazione per Scalare: Se X_1 \\in L^p e a \\in \\mathbb{R}, allora aX_1 \\in L^p.\n\nE[|aX_1|^p] = E[|a|^p |X_1|^p] = |a|^p E[|X_1|^p] &lt; \\infty, dato che E[|X_1|^p] &lt; \\infty e |a|^p è una costante finita.\n\n\n\n\nRelazione tra L^p e L^q\nSe X \\in L^p, allora X \\in L^q per ogni 0 &lt; q \\le p. Questo significa che se il momento di ordine p è finito, allora tutti i momenti di ordine inferiore q (con q \\le p) sono anch’essi finiti. Di conseguenza, gli spazi L^p sono “scatolati” uno dentro l’altro: più p cresce, più l’insieme L^p diventa “piccolo” (nel senso dell’inclusione).\nL^p come Spazio Lineare\nLe proprietà di chiusura rispetto alla somma e alla moltiplicazione per scalare implicano che L^p (sia la versione “storta” che quella “dritta”, come verrà spiegato) è uno spazio vettoriale (o spazio lineare). Questo significa che combinazioni lineari di elementi in L^p rimangono in L^p.\nDistinzione tra L^p “storto” e L^p “dritto”\nIl professore introduce una sottigliezza riguardante la definizione precisa degli spazi L^p, distinguendo tra una notazione L^p “piccolo” (o “storto”) e una notazione L^p “grande” (o “dritto”).\nIl Problema di L^p “storto”\nLo spazio L^p “storto” è definito come l’insieme delle variabili aleatorie (funzioni da \\Omega a \\mathbb{R}) con momento p-esimo finito. Il problema con questa definizione è che possono esistere due variabili aleatorie X e X&#039; tali che P(X(\\omega) = X&#039;(\\omega)) = 1 (sono uguali quasi certamente), ma X(\\omega) \\neq X&#039;(\\omega) per qualche \\omega \\in \\Omega. Considerate come funzioni, X e X&#039; sono distinte, ma ai fini probabilistici (calcolo di probabilità e valori attesi) si comportano in modo identico.\nSpazi Vettoriali Normati e la Necessità di L^p “dritto”\nUna proprietà fondamentale degli spazi vettoriali normati è che se la norma di un elemento è zero, allora l’elemento deve essere l’elemento nullo. Si introduce l’idea di definire una norma sugli spazi L^p, chiamata norma p, definita come ||X||_p = (E[|X|^p])^{1/p} (per p \\ge 1).\nIl problema sorge con L^p “storto” perché se E[|X|^p] = 0, ciò implica che P(X = 0) = 1, ma non necessariamente che X(\\omega) = 0 per ogni \\omega \\in \\Omega. Quindi, la norma p potrebbe essere zero per una variabile aleatoria che non è identicamente nulla come funzione.\nDefinizione di L^p “dritto” tramite Classi di Equivalenza\nPer ovviare a questo problema, si definisce L^p “dritto” (L^p) come l’insieme delle classi di equivalenza di variabili aleatorie in L^p “storto”. La relazione di equivalenza è definita come: X \\sim X&#039; se P(X = X&#039;) = 1 (uguaglianza quasi certa). Un elemento di L^p “dritto” non è una singola funzione, ma un insieme di funzioni che sono tutte uguali quasi certamente. In questo modo, se la norma p di una classe di equivalenza è zero, allora ogni rappresentante della classe è uguale a zero quasi certamente, e la classe di equivalenza è quella della variabile aleatoria identicamente nulla (quasi certamente).\n\nDisuguaglianza di Minkowski\nPer p \\ge 1, se X_1 \\in L^p e X_2 \\in L^p, vale la disuguaglianza di Minkowski: (E[|X_1 + X_2|^p])^{1/p} \\le (E[|X_1|^p])^{1/p} + (E[|X_2|^p])^{1/p} Questa disuguaglianza implica che L^p “dritto” è uno spazio normato rispetto alla norma ||X||_p = (E[|X|^p])^{1/p} per p \\ge 1. La disuguaglianza triangolare per la norma deriva proprio dalla disuguaglianza di Minkowski.\n\nOsservazioni sulla Praticità\nIl professore rassicura che per la maggior parte delle applicazioni del corso, non sarà necessario preoccuparsi eccessivamente della distinzione tra L^p “storto” e L^p “dritto”. Spesso si continuerà a lavorare con le variabili aleatorie direttamente, tenendo presente che le uguaglianze e i limiti sono da intendersi quasi certamente. L’introduzione di L^p “dritto” serve principalmente a fornire una base matematica rigorosa per definire gli spazi L^p come spazi normati.\nLa Proprietà Fondamentale degli Spazi Normati\nIn uno spazio normato, una proprietà essenziale è che la norma di un elemento è zero se e solo se l’elemento è l’elemento nullo. Matematicamente, questa proprietà si esprime come:\n|x| = 0 \\iff x = 0\ndove x è un elemento dello spazio normato e 0 è l’elemento neutro rispetto all’addizione (l’elemento nullo).\nIl professore sottolinea che questa affermazione non può essere fatta direttamente sullo spazio delle funzioni L^p “storto” (riferendosi allo spazio delle variabili aleatorie con momento p-esimo finito) senza l’introduzione delle classi di equivalenza.\nNecessità delle Classi di Equivalenza in L^p\nLa necessità delle classi di equivalenza nasce dal fatto che in L^p, una variabile aleatoria può avere norma zero senza essere la variabile aleatoria nulla in senso stretto. Questo accade perché la norma in L^p è definita in termini di valore atteso. Ad esempio, se il valore atteso di |X|^p è zero (E[|X|^p] = 0), ciò implica che la probabilità che X sia uguale a zero è uno (P(X=0) = 1). Tuttavia, questo non significa che la variabile aleatoria X sia identicamente zero su tutto lo spazio campionario; potrebbe essere diversa da zero su un insieme di probabilità zero.\nPer fare in modo che L^p sia effettivamente uno spazio normato, è necessario considerare le classi di equivalenza di variabili aleatorie che sono uguali quasi certamente.\nDefinizione di Classi di Equivalenza\nLe classi di equivalenza sono definite a partire da una relazione di equivalenza su un insieme. Quozientare un insieme rispetto a una relazione di equivalenza significa che un punto dello spazio quozientato rappresenta tutte le funzioni (o variabili aleatorie nel nostro caso) che sono equivalenti secondo quella relazione.\nNel contesto di L^p, la relazione di equivalenza è l’uguaglianza quasi certa. Due variabili aleatorie X e Y sono equivalenti (X \\sim Y) se P(X = Y) = 1. Una classe di equivalenza [X] è quindi l’insieme di tutte le variabili aleatorie Y tali che Y \\sim X.\n\nRappresentanti delle Classi di Equivalenza\nAll’interno di una classe di equivalenza, si può scegliere un rappresentante. Un rappresentante conveniente potrebbe essere la variabile aleatoria identicamente zero, ma la classe contiene anche altre variabili che sono zero quasi certamente ma non ovunque.\nIl professore afferma che per la verifica che L^p sia uno spazio vettoriale, non è strettamente necessario introdurre le classi di equivalenza. È sufficiente che la somma di due variabili aleatorie in L^p appartenga ancora a L^p, e questo vale per la funzione che è la classe di equivalenza della somma.\nIl Significato di Uguaglianza in L^p: “Quasi Certamente”\nIn L^p, quando si afferma che due variabili aleatorie sono uguali (X = Y), spesso questa uguaglianza deve essere interpretata nel senso di uguaglianza quasi certa (P(X = Y) = 1).\nIl professore fa notare che nel corso, spesso si incontreranno affermazioni come X + Y = 0, che in un contesto rigoroso di L^p dovrebbero essere intese come P(X + Y = 0) = 1. Questa è una sottigliezza che emerge quando si lavora formalmente con gli spazi L^p “dritti” (quozientati rispetto alle classi di equivalenza).\nUn altro esempio menzionato è che se il valore atteso di una variabile aleatoria X (in L^1) è finito, allora la variabile aleatoria è quasi certamente finita.\nSpazio Vettoriale L^p\nLo spazio L^p è uno spazio lineare. Questo significa che se si prendono due variabili aleatorie X e Y appartenenti a L^p, e due scalari a e b, allora la combinazione lineare aX + bY appartiene ancora a L^p.\nX_1, X_2 \\in L^p \\implies aX_1 + bX_2 \\in L^p, \\quad a, b \\in \\mathbb{R}\nIl professore sottolinea che per dimostrare che L^p è uno spazio lineare, non è necessario introdurre le classi di equivalenza.\nSpazio Normato L^p e la Norma\nPer definire una norma su L^p, e quindi fare di L^p uno spazio normato, è necessario identificare le variabili aleatorie quasi certamente uguali, il che porta all’introduzione dello spazio L^p “dritto” (delle classi di equivalenza).\nLa norma in L^p è definita come:\n|X|_p = (E[|X|^p])^{1/p}\nIl professore specifica che per poter definire una norma in questo modo e avere le proprietà di una norma (in particolare la disuguaglianza triangolare), è necessario che p \\ge 1. Se p &lt; 1, si può ancora definire una metrica, ma lo spazio non sarà uno spazio normato.\nLa Notazione L^p “Storto” vs. L^p “Dritto”\nIl professore utilizza la notazione L^p “storto” per riferirsi allo spazio delle variabili aleatorie con momento p-esimo finito, mentre L^p “dritto” si riferisce allo spazio delle classi di equivalenza di tali variabili aleatorie, dove l’equivalenza è definita dall’uguaglianza quasi certa.\nLa ragione per introdurre L^p “dritto” è principalmente per avere uno spazio che soddisfi rigorosamente la definizione di spazio normato, in particolare la proprietà che norma zero implica l’elemento nullo.\nTuttavia, il professore ammette che per la maggior parte delle applicazioni e concetti del corso, si può ragionare direttamente sulle variabili aleatorie senza necessariamente focalizzarsi sulle classi di equivalenza. Le affermazioni di uguaglianza dovranno essere interpretate tenendo conto che possono valere “quasi certamente”.\nEsempio di Somma di Variabili Aleatorie con Momenti Infiniti\n\nIl professore fornisce un esempio per illustrare che la somma di due variabili aleatorie che individualmente non hanno momento primo finito (e quindi non appartengono a L^1), può comunque avere momento primo finito.\nConsideriamo due variabili aleatorie:\nX_1 = X_0 + \\mu X_2 = -X_0\ndove E[|X_0|] = +\\infty e \\mu è una costante. In questo caso, E[|X_1|] = E[|X_0 + \\mu|] e E[|X_2|] = E[|-X_0|] = E[|X_0|] potrebbero essere infiniti.\nTuttavia, la somma delle due variabili aleatorie è:\nX_1 + X_2 = (X_0 + \\mu) + (-X_0) = \\mu\nSe \\mu è una costante finita, allora il suo valore atteso primo è finito (E[|\\mu|] = |\\mu| &lt; \\infty). Questo dimostra che anche se singolarmente le variabili non appartengono a L^1, la loro somma può appartenervi.\nIl professore conclude che se una variabile aleatoria appartiene a L^p, la stessa cosa vale per la sua classe di equivalenza. Inoltre, se abbiamo due variabili in L^p, la loro somma sarà ancora in L^p, ma non è detto che se due variabili non sono in L^p, la loro somma non possa esserlo.\nEsercizi sulle Variabili Aleatorie\nIl professore raccomanda di esercitarsi su variabili aleatorie di diversi tipi: discrete, assolutamente continue e miste. Suggerisce di considerare esercizi elementari che richiedono l’applicazione delle definizioni e il calcolo.\nEsempi di esercizi menzionati:\n\nMassimo tra 0 e X (\\max(0, X)): analizzare quando questa variabile è assolutamente continua e quando non lo è.\nFunzione di ripartizione di X + 3, data la funzione di ripartizione di X.\nFunzione di ripartizione di X^2 e |X|, data la funzione di ripartizione di X.\n\nÈ importante anche ripassare i concetti fondamentali di probabilità, come il teorema di Bayes, la probabilità elementare, il calcolo combinatorio, i valori attesi, i valori attesi di funzioni e le trasformazioni di variabili aleatorie.\nReferences"},"6--full-note/prob-lez15":{"slug":"6--full-note/prob-lez15","filePath":"6- full note/prob-lez15.md","title":"prob-lez15","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-14 08:40\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine   probabilità\nprob-lez15\nIndipendenza di Variabili Aleatorie\nRipasso: Disuguaglianza di Cauchy-Schwarz\nSottotitolo: Definizione e Proprietà\nIl professore inizia la lezione riprendendo un argomento precedente, la disuguaglianza di Cauchy-Schwarz.\nSiano X_1 e X_2 due variabili aleatorie con valore atteso e momento secondo finito. Ciò significa che X_1, X_2 \\in L^2.\nVale la seguente disuguaglianza: |\\mathbb{E}[X_1 X_2]| \\le \\mathbb{E}[|X_1 X_2|] \\le \\sqrt{\\mathbb{E}[X_1^2] \\mathbb{E}[X_2^2]} La seconda disuguaglianza è la versione della disuguaglianza di Cauchy-Schwarz.\n\nSottotitolo: Conseguenza Importante\nUna delle conseguenze di questa disuguaglianza è che se X_1 e X_2 hanno un momento secondo finito, il loro prodotto X_1 X_2 ha momento primo finito. In altre parole, se X_1, X_2 \\in L^2, allora X_1 X_2 \\in L^1.\nSottotitolo: Anticipazione sulla Covarianza\nIl professore anticipa che questa disuguaglianza sarà ritrovata in una forma riscritta quando si parlerà di covarianza.\nSottotitolo: Dimostrazione (Cenni)\nLa dimostrazione della disuguaglianza di Cauchy-Schwarz si basa sul considerare una variabile aleatoria positiva e sfruttare la linearità del valore atteso.\nSi fissa A e B e si considera il quadrato (AX_1 + BX_2)^2. Questa è una variabile aleatoria positiva, quindi il suo valore atteso è maggiore o uguale a zero: \\mathbb{E}[(AX_1 + BX_2)^2] \\ge 0 Sviluppando il quadrato e usando la linearità del valore atteso si ottiene: A^2 \\mathbb{E}[X_1^2] + B^2 \\mathbb{E}[X_2^2] + 2AB \\mathbb{E}[X_1 X_2] \\ge 0 Questa espressione è una forma quadratica in A e B che può essere scritta come \\mathbf{v}^T C \\mathbf{v} \\ge 0, dove \\mathbf{v} = \\begin{pmatrix} A \\ B \\end{pmatrix} e C = \\begin{pmatrix} \\mathbb{E}[X_1^2] &amp; \\mathbb{E}[X_1 X_2] \\ \\mathbb{E}[X_1 X_2] &amp; \\mathbb{E}[X_2^2] \\end{pmatrix}.\nPoiché questa forma quadratica è sempre maggiore o uguale a zero, la matrice C è semidefinita positiva, e quindi il suo determinante è maggiore o uguale a zero: \\det(C) = \\mathbb{E}[X_1^2] \\mathbb{E}[X_2^2] - (\\mathbb{E}[X_1 X_2])^2 \\ge 0 Da cui si ricava: (\\mathbb{E}[X_1 X_2])^2 \\le \\mathbb{E}[X_1^2] \\mathbb{E}[X_2^2] Prendendo la radice quadrata di entrambi i membri si ottiene la tesi (in modulo): |\\mathbb{E}[X_1 X_2]| \\le \\sqrt{\\mathbb{E}[X_1^2] \\mathbb{E}[X_2^2]}\n\nIntroduzione all’Indipendenza di Variabili Aleatorie\nSottotitolo: Definizione di Indipendenza per Famiglie di Sigma Algebre\nIl professore introduce il nuovo argomento dell’indipendenza di variabili aleatorie partendo dalla definizione di indipendenza per famiglie di sigma algebre.\nConsideriamo una famiglia di sotto sigma algebre { \\mathcal{G}_i }_{i \\in I} di una sigma algebra madre \\mathcal{F} su cui è definita una misura di probabilità \\mathbb{P}.\nQueste sigma algebre sono dette indipendenti se per ogni successione finita di indici distinti j_1, j_2, \\dots, j_k contenuti in I (cioè, per ogni k \\ge 1 e j_1, \\dots, j_k \\in I, con j_r \\neq j_s per r \\neq s) e per ogni scelta di eventi B_{j_1} \\in \\mathcal{G}_{j_1}, B_{j_2} \\in \\mathcal{G}_{j_2}, \\dots, B_{j_k} \\in \\mathcal{G}_{j_k}, si ha: \\mathbb{P}\\left( \\bigcap_{r=1}^{k} B_{j_r} \\right) = \\prod_{r=1}^{k} \\mathbb{P}(B_{j_r})\n\nSottotitolo: Confronto con l’Indipendenza di Eventi\nLa differenza con la definizione di indipendenza di eventi è che in quel caso si considera una famiglia di eventi, mentre qui si considera una famiglia di sigma algebre. Per verificare l’indipendenza di sigma algebre, è necessario considerare tutte le possibili scelte di eventi, uno da ciascuna sigma algebra nella sottofamiglia considerata.\nSottotitolo: Esercizio Mentale\nIl professore propone un esercizio mentale per confrontare le due definizioni.\nSottotitolo: Caso Particolare: Due Eventi\nConsideriamo il caso in cui l’insieme degli indici I è costituito solo da due elementi, I = \\set{1, 2}. Siano \\mathcal{G}_1 = \\sigma(B_1) la sigma algebra generata da un evento B_1 e \\mathcal{G}_2 = \\sigma(B_2) la sigma algebra generata da un evento B_2.\nRicordiamo che \\sigma(B_1) = \\set{ \\emptyset, B_1, B_1^c, \\Omega } e \\sigma(B_2) = \\set{ \\emptyset, B_2, B_2^c, \\Omega }.\nVerificare che B_1 e B_2 sono indipendenti (nel senso di \\mathbb{P}(B_1 \\cap B_2) = \\mathbb{P}(B_1) \\mathbb{P}(B_2)) è del tutto equivalente a dire che le sigma algebre \\mathcal{G}_1 e \\mathcal{G}_2 sono indipendenti. Questo si dimostra considerando tutte le possibili coppie di eventi, uno da \\mathcal{G}_1 e uno da \\mathcal{G}_2, e verificando la condizione di fattorizzazione della probabilità dell’intersezione.\n\nSottotitolo: Generalizzazione a più di Due Oggetti\nLa definizione più generale di indipendenza per sigma algebre è introdotta per poter trattare l’indipendenza di oggetti più complessi di semplici eventi.\nSottotitolo: Esercizio di Ripasso sull’Indipendenza di Eventi\nIl professore ricorda un esercizio svolto in precedenza: se A e B sono eventi indipendenti, allora anche A e B^c, A^c e B, A^c e B^c sono indipendenti. Questo può essere verificato come esercizio utilizzando la definizione di indipendenza di sigma algebre nel caso di due eventi.\nIndipendenza di Variabili Aleatorie\nSottotitolo: Definizione della Sigma Algebra Generata da una Variabile Aleatoria\nSia X una variabile aleatoria definita sullo spazio di probabilità (\\Omega, \\mathcal{F}, \\mathbb{P}) a valori in uno spazio misurabile (E, \\mathcal{E}). La sigma algebra generata da X, denotata con \\sigma(X), è la sigma algebra generata dalle controimmagini degli insiemi misurabili di E sotto X: \\sigma(X) = { X^{-1}(D) : D \\in \\mathcal{E} } X^{-1}(D) = { \\omega \\in \\Omega : X(\\omega) \\in D } è un evento in \\mathcal{F} poiché X è una variabile aleatoria. In generale, \\sigma(X) \\subseteq \\mathcal{F}, e può essere strettamente contenuta in \\mathcal{F} (ad esempio, se X è costante, \\sigma(X) è la sigma algebra banale { \\emptyset, \\Omega }).\nSottotitolo: Definizione di Indipendenza per Variabili Aleatorie\nSiano X_1, X_2, \\dots, X_n variabili aleatorie, dove X_i è definita su (\\Omega, \\mathcal{F}, \\mathbb{P}) e a valori in (E_i, \\mathcal{E}_i). Le variabili aleatorie X_1, X_2, \\dots, X_n sono dette indipendenti se per ogni scelta di insiemi misurabili \\forall B_1 \\in \\mathcal{E}_1, B_2 \\in \\mathcal{E}_2, \\dots, B_n \\in \\mathcal{E}_n, si ha: \\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2, \\dots, X_n \\in B_n) = \\mathbb{P}(X_1 \\in B_1) \\mathbb{P}(X_2 \\in B_2) \\dots \\mathbb{P}(X_n \\in B_n) Utilizzando la notazione per le controimmagini, questa condizione può essere riscritta come: \\mathbb{P}\\left( \\bigcap_{i=1}^{n} { X_i \\in B_i } \\right) = \\prod_{i=1}^{n} \\mathbb{P}(X_i \\in B_i) o equivalentemente: \\mathbb{P}\\left( \\bigcap_{i=1}^{n} X_i^{-1}(B_i) \\right) = \\prod_{i=1}^{n} \\mathbb{P}(X_i^{-1}(B_i))\nSottotitolo: Equivalenza con l’Indipendenza delle Sigma Algebre Generate\nL’indipendenza delle variabili aleatorie X_1, \\dots, X_n (secondo la definizione appena data) è equivalente all’indipendenza delle sigma algebre generate \\sigma(X_1), \\sigma(X_2), \\dots, \\sigma(X_n). Questo perché l’evento { X_i \\in B_i } è proprio un elemento della sigma algebra generata da X_i. Quindi, la definizione di indipendenza per variabili aleatorie è un caso particolare della definizione più generale di indipendenza per sigma algebre.\n\nSottotitolo: Osservazione sull’Indipendenza di Sottoinsiemi\nSe X_1, X_2, X_3 sono variabili aleatorie indipendenti, allora anche X_1 e X_2 sono indipendenti. Questo può essere visto considerando B_1 \\in \\mathcal{E}_1 e B_2 \\in \\mathcal{E}_2. Allora: \\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2) = \\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2, X_3 \\in \\Omega) Poiché X_1, X_2, X_3 sono indipendenti e X_3 \\in \\Omega è un evento con probabilità 1, si ha: \\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2, X_3 \\in \\Omega) = \\mathbb{P}(X_1 \\in B_1) \\mathbb{P}(X_2 \\in B_2) \\mathbb{P}(X_3 \\in \\Omega) = \\mathbb{P}(X_1 \\in B_1) \\mathbb{P}(X_2 \\in B_2) \\cdot 1 Quindi X_1 e X_2 sono indipendenti. Questa proprietà si generalizza a un numero arbitrario di variabili indipendenti: ogni sottoinsieme di variabili indipendenti è anch’esso indipendente.\n\nSottotitolo: Natura degli Spazi di Arrivo\nIl professore sottolinea che gli spazi di arrivo delle variabili aleatorie non devono necessariamente essere \\mathbb{R}. Si possono avere variabili a valori in \\mathbb{R}^n (vettori aleatori) o in spazi diversi.\nTeoremi sull’Indipendenza\nSottotitolo: Teorema sulle P-Classi\nEnunciato (senza dimostrazione): Siano { \\mathcal{G}_i }_{i \\in I} una famiglia di sigma algebre e { \\mathcal{C}_i }_{i \\in I} una famiglia di P-classi sugli spazi di arrivo corrispondenti, tali che ogni \\mathcal{C}_i contenga lo spazio totale e generi la sigma algebra \\mathcal{G}_i (cioè, \\sigma(\\mathcal{C}_i) = \\mathcal{G}_i). Se per ogni successione finita di indici distinti j_1, \\dots, j_k \\in I e per ogni scelta di insiemi B_{j_1} \\in \\mathcal{C}_{j_1}, \\dots, B_{j_k} \\in \\mathcal{C}_{j_k}, si ha: \\mathbb{P}\\left( \\bigcap_{r=1}^{k} B_{j_r} \\right) = \\prod_{r=1}^{k} \\mathbb{P}(B_{j_r}) allora le sigma algebre { \\mathcal{G}_i }_{i \\in I} sono indipendenti.\n\nCommento: Questo teorema fornisce un criterio più semplice per verificare l’indipendenza di sigma algebre, in quanto è sufficiente controllare la fattorizzazione della probabilità solo per gli elementi di P-classi che generano le sigma algebre, anziché per tutti gli elementi delle sigma algebre stesse. Questo è particolarmente utile nel caso di variabili aleatorie.\nSottotitolo: Teorema sul Valore Atteso di Funzioni di Variabili Indipendenti\nTeorema (senza dimostrazione): Siano X_1, \\dots, X_n variabili aleatorie indipendenti, dove X_i è a valori in (E_i, \\mathcal{E}_i). Allora le seguenti proprietà sono equivalenti:\n\nLe variabili aleatorie X_1, \\dots, X_n sono indipendenti.\nPer ogni scelta di funzioni misurabili e limitate g_i: (E_i, \\mathcal{E}_i) \\to (\\mathbb{R}, \\mathcal{B}(\\mathbb{R})), si ha: \\mathbb{E}[g_1(X_1) g_2(X_2) \\dots g_n(X_n)] = \\mathbb{E}[g_1(X_1)] \\mathbb{E}[g_2(X_2)] \\dots \\mathbb{E}[g_n(X_n)]\nEsiste una collezione di P-classi \\mathcal{C}_i negli spazi di arrivo (E_i, \\mathcal{E}_i) tali che ogni \\mathcal{C}_i contiene \\Omega (anche se il professore nota in che questa condizione potrebbe non essere strettamente necessaria in generale per la definizione di P-classe, ma è rilevante in questo contesto) e genera la sigma algebra \\mathcal{E}_i. In tal caso, le variabili aleatorie X_1, \\dots, X_n sono indipendenti se e solo se per ogni scelta di B_i \\in \\mathcal{C}_i, si ha: \\mathbb{P}(X_1 \\in B_1, X_2 \\in B_2, \\dots, X_n \\in B_n) = \\mathbb{P}(X_1 \\in B_1) \\mathbb{P}(X_2 \\in B_2) \\dots \\mathbb{P}(X_n \\in B_n) In altre parole, l’indipendenza delle sigma algebre generate dalle variabili aleatorie può essere verificata controllando la fattorizzazione della probabilità solo sugli elementi di queste P-classi generatrici. Questo fornisce un criterio più comodo per verificare l’indipendenza poiché le P-cla ssi sono spesso più semplici da controllare rispetto all’intera sigma algebra. Un esempio menzionato è nel caso di variabili aleatorie reali, dove la P-classe delle semirette chiuse (-\\infty, x] (unite eventualmente con \\mathbb{R}) genera i boreliani di \\mathbb{R}.\n\nQuesto terzo punto è strettamente legato alla verifica pratica dell’indipendenza, specialmente quando gli spazi di arrivo hanno una struttura complessa. Controllare la fattorizzazione per tutti gli insiemi misurabili potrebbe essere difficile, mentre restringerla a una P-classe generatrice può semplificare il compito.\n\nCommento: Questo teorema stabilisce che l’indipendenza implica la fattorizzazione del valore atteso di prodotti di funzioni delle singole variabili. Viceversa, se questa fattorizzazione vale per tutte le funzioni misurabili e limitate, allora le variabili sono indipendenti. Un caso particolare importante si ottiene scegliendo le g_i come funzioni indicatrici di insiemi B_i \\in \\mathcal{E}_i, che riconduce alla definizione di indipendenza.\nSottotitolo: Corollario per Variabili Aleatorie Reali e Funzione di Ripartizione\nProposizione (Corollario): Siano X_1, \\dots, X_n variabili aleatorie reali (a valori in \\mathbb{R}). Esse sono indipendenti se e solo se la funzione di ripartizione congiunta del vettore (X_1, \\dots, X_n) è uguale al prodotto delle funzioni di ripartizione marginali delle singole variabili.\nLa funzione di ripartizione congiunta è definita come: F_{X_1, \\dots, X_n}(x_1, \\dots, x_n) = \\mathbb{P}(X_1 \\le x_1, \\dots, X_n \\le x_n) dove x_i \\in \\mathbb{R} per i = 1, \\dots, n.\nLa condizione di indipendenza in termini di funzioni di ripartizione è: F_{X_1, \\dots, X_n}(x_1, \\dots, x_n) = F_{X_1}(x_1) F_{X_2}(x_2) \\dots F_{X_n}(x_n) dove F_{X_i}(x_i) = \\mathbb{P}(X_i \\le x_i) è la funzione di ripartizione marginale di X_i.\nDimostrazione (Cenni):\n\n\n(\\Rightarrow) Se X_1, \\dots, X_n sono indipendenti, allora per definizione per gli insiemi B_i = (-\\infty, x_i], si ha: \\mathbb{P}(X_1 \\in (-\\infty, x_1], \\dots, X_n \\in (-\\infty, x_n]) = \\prod_{i=1}^{n} \\mathbb{P}(X_i \\in (-\\infty, x_i]) che è esattamente la condizione sulle funzioni di ripartizione.\n\n\n(\\Leftarrow) Supponiamo che la funzione di ripartizione congiunta sia il prodotto delle marginali. Per dimostrare l’indipendenza, dobbiamo mostrare che per ogni scelta di insiemi boreliani B_1, \\dots, B_n, si ha \\mathbb{P}(X_1 \\in B_1, \\dots, X_n \\in B_n) = \\prod_{i=1}^{n} \\mathbb{P}(X_i \\in B_i). Si utilizza il teorema sulle P-classi enunciato precedentemente. La classe delle semirette (-\\infty, x] (unita a \\mathbb{R}) è una P-classe che genera la sigma algebra dei boreliani su \\mathbb{R}. Poiché la fattorizzazione vale per intersezioni di insiemi di questa forma (per ipotesi sulla funzione di ripartizione), allora per il teorema sulle P-classi, le sigma algebre generate da X_1, \\dots, X_n (che contengono tutti gli eventi { X_i \\in B_i } per B_i boreliani) sono indipendenti, e quindi le variabili aleatorie sono indipendenti.\n\n\n\nCommento: Questa proposizione fornisce un criterio pratico per verificare l’indipendenza di variabili aleatorie reali, basato sulle loro funzioni di ripartizione. Ha il vantaggio di valere sia per variabili assolutamente continue che discrete, e in generale per qualsiasi tipo di variabile aleatoria reale.\n\nIndipendenza di Variabili Aleatorie\nDefinizione di P-Classi\nPer un motivo tecnico, le \\mathcal{P}-classi devono avere misura totale. In generale, per come sono definite le \\mathcal{P}-classi, questa condizione non è strettamente necessaria. Tuttavia, per alcuni risultati che si basano sulle \\mathcal{P}-classi, come l’esempio trattato, è richiesto un requisito leggermente più forte.\nIndipendenza nel Caso Discreto\nSiano X_1, \\dots, X_n variabili aleatorie discrete con codominio finito o numerabile in \\mathbb{R}.\nDefinizione: X_1, \\dots, X_n sono indipendenti se e solo se la densità discreta del vettore (X_1, \\dots, X_n) fattorizza. Questo significa che per ogni scelta di x_1, \\dots, x_n \\in \\mathbb{R}, vale: P(X_1 = x_1, \\dots, X_n = x_n) = P(X_1 = x_1) \\cdot \\dots \\cdot P(X_n = x_n) = \\prod_{i=1}^{n} P(X_i = x_i)\nQuesta uguaglianza può essere riscritta esplicitamente come la probabilità che X_1 sia uguale a x_1 (piccolo), …, X_n sia uguale a x_n (piccolo) è uguale al prodotto per i che va da 1 a n della probabilità che X_i sia uguale a x_i, per ogni x_1, \\dots, x_n opportuni per cui questa espressione abbia senso.\n\nImportante: Questa scrittura è valida solo nel caso di variabili aleatorie discrete. Se X_1, \\dots, X_n fossero variabili assolutamente continue, si otterrebbe 0 = 0, sia nel caso di dipendenza che di indipendenza. Per questo motivo, la definizione generale di indipendenza si basa sulla probabilità che il vettore appartenga a un prodotto cartesiano di insiemi, come vedremo in seguito. Nel caso discreto, ci si può restringere agli insiemi costituiti da un singolo punto.\nCriterio Generale di Indipendenza per Variabili Reali\nPer variabili reali, esiste un criterio di indipendenza che vale in qualunque caso (discreto, continuo, misto). Siano X_1, \\dots, X_n variabili aleatorie reali. Esse sono indipendenti se e solo se per ogni x_1, \\dots, x_n \\in \\mathbb{R}, si ha: P(X_1 \\le x_1, \\dots, X_n \\le x_n) = P(X_1 \\le x_1) \\cdot \\dots \\cdot P(X_n \\le x_n) = \\prod_{i=1}^{n} P(X_i \\le x_i) Questa condizione è equivalente all’indipendenza per variabili reali in generale.\nIntuizione dell’Indipendenza\nL’indipendenza di variabili aleatorie è una proprietà che generalizza l’indipendenza di eventi. Dire che X_1 e X_2 sono indipendenti significa che la conoscenza del valore assunto da una variabile non implica alcuna informazione sulla conoscenza del valore assunto dall’altra.\nEsempio 1: Variabili Dipendenti Deterministamente\nConsideriamo una variabile aleatoria X a valori reali e definiamo X_1 = X e X_2 = X^2.\nNon facciamo ipotesi specifiche sulla natura di X (discreta, continua, ecc.).\nAffermazione: X_1 e X_2 sono dipendenti. Intuitivamente, questo è vero perché X_2 è una funzione deterministica di X_1. Se conosciamo il valore di X_1, conosciamo univocamente il valore di X_2. Questa è una forma di dipendenza molto forte, detta dipendenza deterministica.\nVerifica stocastica della dipendenza: Per dimostrare che X_1 e X_2 non sono indipendenti dal punto di vista stocastico, è sufficiente trovare una coppia di eventi per cui la probabilità dell’intersezione non è uguale al prodotto delle probabilità. Consideriamo gli eventi {X_1 \\le 2} e {X_2 \\le 9}.\nLa probabilità dell’intersezione è: P(X_1 \\le 2, X_2 \\le 9) = P(X \\le 2, X^2 \\le 9) L’evento {X^2 \\le 9} è equivalente a { -3 \\le X \\le 3 }. Quindi: P(X \\le 2, X^2 \\le 9) = P(X \\le 2, -3 \\le X \\le 3) = P(-3 \\le X \\le 2)\nOra consideriamo il prodotto delle probabilità degli eventi singoli: P(X_1 \\le 2) P(X_2 \\le 9) = P(X \\le 2) P(X^2 \\le 9) = P(X \\le 2) P(-3 \\le X \\le 3)\nIn generale, P(-3 \\le X \\le 2) è diverso da P(X \\le 2) P(-3 \\le X \\le 3). Scegliendo opportunamente la legge di probabilità di X, è possibile trovare casi in cui queste due quantità sono diverse. Pertanto, X_1 e X_2 non sono indipendenti.\n\nEsempio 2: Variabili Discrete Dipendenti\nConsideriamo due variabili aleatorie discrete X_1 e X_2 con i seguenti possibili valori: X_1 \\in {1, 2} e X_2 \\in {0, 1}. Supponiamo che la distribuzione di probabilità congiunta sia data dalla seguente tabella:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX_1 \\setminus X_20111/21/4201/4\nPer verificare se X_1 e X_2 sono indipendenti, controlliamo se P(X_1 = x_1, X_2 = x_2) = P(X_1 = x_1) P(X_2 = x_2) per tutte le coppie (x_1, x_2). Consideriamo il caso x_1 = 1 e x_2 = 0.\nDalla tabella, P(X_1 = 1, X_2 = 0) = 1/2.\nCalcoliamo le probabilità marginali: P(X_1 = 1) = P(X_1 = 1, X_2 = 0) + P(X_1 = 1, X_2 = 1) = 1/2 + 1/4 = 3/4 P(X_2 = 0) = P(X_1 = 1, X_2 = 0) + P(X_1 = 2, X_2 = 0) = 1/2 + 0 = 1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX_1 \\setminus X_20111/21/41/2 + 1/4201/40+1/41/2+01/4+1/4\nOra verifichiamo la condizione di indipendenza: P(X_1 = 1) P(X_2 = 0) = (3/4) \\cdot (1/2) = 3/8\nPoiché P(X_1 = 1, X_2 = 0) = 1/2 \\neq 3/8 = P(X_1 = 1) P(X_2 = 0), le variabili aleatorie X_1 e X_2 non sono indipendenti. Abbiamo trovato almeno una coppia di valori per cui la condizione di fattorizzazione non è soddisfatta.\nEsempio 3: Costruzione di Variabili Discrete Indipendenti con le Stesse Marginali\nConsideriamo le stesse marginali di X_1 e X_2 dell’esempio precedente: P(X_1 = 1) = 3/4, P(X_1 = 2) = 1/4 P(X_2 = 0) = 1/2, P(X_2 = 1) = 1/2\nVogliamo costruire due nuove variabili aleatorie discrete, \\tilde X_{1} e \\tilde X_{2}, con queste stesse marginali ma che siano indipendenti. Per l’indipendenza, la probabilità congiunta deve essere il prodotto delle probabilità marginali per ogni coppia di valori:\nP(\\tilde X_{1} = 1, \\tilde X_{2} = 0) = P(\\tilde X_{1} = 1) P(\\tilde X_{2} = 0) = (3/4) \\cdot (1/2) = 3/8 P(\\tilde X_{1} = 1, \\tilde X_{2} = 1) = P(\\tilde X_{1} = 1) P(\\tilde X_{2} = 1) = (3/4) \\cdot (1/2) = 3/8 P(\\tilde X_{1} = 2, \\tilde X_{2} = 0) = P(\\tilde X_{1} = 2) P(\\tilde X_{2} = 0) = (1/4) \\cdot (1/2) = 1/8 P(\\tilde X_{1} = 2, \\tilde X_{2} = 1) = P(\\tilde X_{1} = 2) P(\\tilde X_{2} = 1) = (1/4) \\cdot (1/2) = 1/8\nLa tabella di probabilità congiunta per \\tilde X_{1} e \\tilde X_{2} è quindi:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\tilde X_{1} \\setminus \\tilde X_{2}0113/83/81/221/81/81/23/41/4\nVerifichiamo che le marginali siano corrette: P(\\tilde X_{1} = 1) = 3/8 + 3/8 = 6/8 = 3/4 P(\\tilde X_{1} = 2) = 1/8 + 1/8 = 2/8 = 1/4 P(\\tilde X_{2} = 0) = 3/8 + 1/8 = 4/8 = 1/2 P(\\tilde X_{2} = 1) = 3/8 + 1/8 = 4/8 = 1/2\nLe marginali di \\tilde X_{1} sono uguali alle marginali di X_1, e le marginali di \\tilde X_{2} sono uguali alle marginali di X_2. Tuttavia, le leggi congiunte (X_1, X_2) e (\\tilde X_{1}, \\tilde X_{2}) sono diverse, poiché una coppia di variabili è dipendente e l’altra è indipendente.\n\nOsservazione: Non si può affermare che X_1 = \\tilde X_{1} con probabilità 1, in quanto non è stato definito lo spazio \\Omega su cui sono definite queste variabili aleatorie. Potrebbero persino essere definite su spazi di probabilità diversi, rendendo priva di significato l’espressione P(X_1 = \\tilde X_{1}).\nIndipendenza e Leggi Immagine\nConsideriamo due variabili aleatorie X_1 e X_2 indipendenti. Sia B_1 un boreliano nello spazio di arrivo di X_1 e B_2 un boreliano nello spazio di arrivo di X_2. Allora, l’evento {X_1 \\in B_1 \\text{ e } X_2 \\in B_2} corrisponde al fatto che la coppia (X_1, X_2) appartiene al prodotto cartesiano B_1 \\times B_2 nello spazio prodotto.\nLa probabilità di questo evento è data dalla legge immagine della variabile aleatoria vettoriale (X_1, X_2) calcolata sul boreliano B_1 \\times B_2. Per l’indipendenza, questa probabilità è uguale al prodotto delle probabilità marginali: P(X_1 \\in B_1, X_2 \\in B_2) = P(X_1 \\in B_1) P(X_2 \\in B_2)\nIn termini di leggi immagine, se \\mu_1 è la legge immagine di X_1 e \\mu_2 è la legge immagine di X_2, e \\mu_{12} è la legge immagine di (X_1, X_2), allora l’indipendenza implica che per ogni coppia di boreliani B_1 e B_2, si ha: \\mu_{12}(B_1 \\times B_2) = \\mu_1(B_1) \\mu_2(B_2)\n\nQuesto suggerisce che la proprietà di indipendenza può essere vista nello spazio immagine, confrontando la legge congiunta con il prodotto delle leggi marginali.\nAttenzione: Se si conoscono solo le leggi immagine marginali \\mu_1 e \\mu_2, in generale non è possibile ricostruire univocamente la legge immagine congiunta \\mu_{12} senza l’ulteriore ipotesi di indipendenza. Tuttavia, se si assume l’indipendenza, la legge congiunta è univocamente determinata dal prodotto delle marginali. L’esempio discreto precedente illustra come, a partire dalle leggi marginali, si possa costruire una legge congiunta che soddisfi l’indipendenza.\nLa motivazione per questo approccio è che spesso si lavora nello spazio di arrivo e si hanno informazioni sulle marginali, e si vuole costruire o studiare misure di probabilità sul prodotto di spazi.\n\nMisure Prodotto e Integrazione su Spazi Prodotto\nIntroduzione alle Misure Prodotto\nIl professore introduce il concetto di misure prodotto come generalizzazione di idee già incontrate, in particolare nel contesto delle misure di probabilità. Si anticipa che questo argomento è fondamentale e si lega al concetto di indipendenza. L’obiettivo è definire una misura su uno spazio prodotto a partire da misure definite sugli spazi componenti. Oltre alle misure di probabilità, si applicherà questo concetto alla misura di Lebesgue.\nCostruzione dello Spazio Prodotto e della Sigma Algebra Prodotto\nSpazio Prodotto\nDati due spazi misurabili (E_1, \\mathcal{E}_1) e (E_2, \\mathcal{E}_2), lo spazio prodotto è definito come l’insieme delle coppie: E = E_1 \\times E_2 = {(e_1, e_2) \\mid e_1 \\in E_1, e_2 \\in E_2}. Tipicamente, E_1 e E_2 saranno \\mathbb{R} con la sigma algebra dei Boreliani \\mathcal{B}(\\mathbb{R}), quindi lo spazio prodotto sarà \\mathbb{R}^2.\nSigma Algebra Prodotto\nPer definire una misura sullo spazio prodotto, è necessario dotarlo di una sigma algebra. La sigma algebra prodotto \\mathcal{E}_1 \\otimes \\mathcal{E}_2 è definita come la più piccola sigma algebra su E_1 \\times E_2 che contiene i rettangoli misurabili della forma A_1 \\times A_2, dove A_1 \\in \\mathcal{E}_1 e A_2 \\in \\mathcal{E}_2.\nIn altre parole: \\mathcal{E}_1 \\otimes \\mathcal{E}_2 = \\sigma({A_1 \\times A_2 \\mid A_1 \\in \\mathcal{E}_1, A_2 \\in \\mathcal{E}_2}).\n\nQuesta costruzione imita il modo in cui si definiscono i Boreliani di \\mathbb{R}^2 a partire dai Boreliani di \\mathbb{R}. Infatti, si ha che \\mathcal{B}(\\mathbb{R}) \\otimes \\mathcal{B}(\\mathbb{R}) = \\mathcal{B}(\\mathbb{R}^2). Il professore sottolinea che questa uguaglianza è vera per i Boreliani di \\mathbb{R}, ma potrebbe non valere in situazioni più generali.\n\nCostruzione della Misura Prodotto\nTeorema di Esistenza e Unicità della Misura Prodotto\nTeorema: Siano (E_1, \\mathcal{E}_1, \\mu_1) e (E_2, \\mathcal{E}_2, \\mu_2) due spazi misurabili con misure \\sigma-finite \\mu_1 e \\mu_2. Allora esiste un’unica misura \\sigma-finita \\mu sulla sigma algebra prodotto \\mathcal{E}_1 \\otimes \\mathcal{E}_2, che indicheremo con \\mu_1 \\otimes \\mu_2, tale che per ogni coppia di insiemi misurabili B_1 \\in \\mathcal{E}_1 e B_2 \\in \\mathcal{E}_2, si abbia:\n\\qquad (\\mu_1 \\otimes \\mu_2)(B_1 \\times B_2) = \\mu_1(B_1) \\cdot \\mu_2(B_2).\nQuesta misura \\mu_1 \\otimes \\mu_2 è chiamata misura prodotto di \\mu_1 e \\mu_2.\nIl professore fa un parallelo con la costruzione della misura di Lebesgue, dove si parte dai cuboidi e si estende la misura. La costruzione qui presentata è una versione astratta di quel procedimento.\n\nOsservazioni sulle Misure di Probabilità\nSe \\mu_1 e \\mu_2 sono misure di probabilità, allora anche la misura prodotto \\mu_1 \\otimes \\mu_2 è una misura di probabilità, poiché (\\mu_1 \\otimes \\mu_2)(E_1 \\times E_2) = \\mu_1(E_1) \\cdot \\mu_2(E_2) = 1 \\cdot 1 = 1.\nIl professore accenna al fatto che se si richiedesse solo che una misura sullo spazio prodotto abbia \\mu_1 e \\mu_2 come marginali, allora tale misura non sarebbe necessariamente unica. Tuttavia, se si richiede che la misura si fattorizzi sul prodotto di insiemi misurabili (come nella definizione della misura prodotto), allora l’unicità è garantita.\nApplicazione alla Misura di Lebesgue\nIl professore menziona che, oltre alle misure di probabilità, la costruzione della misura prodotto è particolarmente importante per la misura di Lebesgue.\nFunzioni Misurabili sullo Spazio Prodotto\nConsideriamo una funzione H: E_1 \\times E_2 \\to \\mathbb{R}. Dire che H è misurabile rispetto alla sigma algebra prodotto \\mathcal{E}_1 \\otimes \\mathcal{E}_2 e ai Boreliani di \\mathbb{R} (\\mathcal{B}(\\mathbb{R})) significa che per ogni B \\in \\mathcal{B}(\\mathbb{R}), l’insieme H^{-1}(B) = {(e_1, e_2) \\in E_1 \\times E_2 \\mid H(e_1, e_2) \\in B} appartiene a \\mathcal{E}_1 \\otimes \\mathcal{E}_2.\nIl professore usa la notazione H(e_1, e_2) per indicare il valore della funzione in un punto (e_1, e_2) \\in E_1 \\times E_2.\n\nSezioni di Funzioni Misurabili\nProposizione 2\nProposizione: Sia H: E_1 \\times E_2 \\to \\mathbb{R} una funzione misurabile rispetto alla sigma algebra prodotto \\mathcal{E}_1 \\otimes \\mathcal{E}_2 e ai Boreliani di \\mathbb{R}. Allora:\n\nPer ogni e_1 \\in E_1, la funzione H_{e_1}: E_2 \\to \\mathbb{R} definita da H_{e_1}(e_2) = H(e_1, e_2) è \\mathcal{E}_2-misurabile.\nPer ogni e_2 \\in E_2, la funzione H_{e_2}: E_1 \\to \\mathbb{R} definita da H_{e_2}(e_1) = H(e_1, e_2) è \\mathcal{E}_1-misurabile.\n\nIl professore spiega che questa proposizione afferma che se una funzione è misurabile sul prodotto, allora fissando una delle due variabili, la funzione risultante nell’altra variabile rimane misurabile. Queste funzioni H_{e_1} e H_{e_2} sono chiamate sezioni della funzione H.\nIl professore risponde a una domanda dello studente, confermando che se si hanno due funzioni misurabili, la loro composizione è misurabile, anche se precisa che qui si sta usando la misurabilità nella direzione indicata dalla proposizione.\n\nImportanza per l’Integrazione\nQuesta proprietà è fondamentale perché permette di dare un senso all’integrale parziale. Ad esempio, si considera l’espressione:\n\\qquad \\int_{E_2} H(e_1, e_2) , d\\mu_2(e_2)\nPerché questo integrale sia ben definito (almeno per funzioni positive), è necessario che, per ogni e_1 fissato, la funzione e_2 \\mapsto H(e_1, e_2) sia \\mathcal{E}_2-misurabile, cosa che è garantita dalla Proposizione 2.\n\nTeorema di Fubini-Tonelli (Caso di Funzioni Positive)\nTeorema\nTeorema: Siano (E_1, \\mathcal{E}_1, \\mu_1) e (E_2, \\mathcal{E}_2, \\mu_2) spazi misurabili con misure \\sigma-finite e sia H: E_1 \\times E_2 \\to [0, +\\infty] una funzione \\mathcal{E}_1 \\otimes \\mathcal{E}_2-misurabile e positiva. Allora:\n\nPer quasi ogni e_1 \\in E_1 (rispetto a \\mu_1), la funzione e_2 \\mapsto H(e_1, e_2) è \\mathcal{E}_2-integrabile (ovvero \\int_{E_2} H(e_1, e_2) , d\\mu_2(e_2) &lt; +\\infty).\nLa funzione e_1 \\mapsto \\int_{E_2} H(e_1, e_2) , d\\mu_2(e_2) è \\mathcal{E}_1-misurabile su [0, +\\infty].\nSi ha l’uguaglianza:\n\n\\qquad \\int_{E_1 \\times E_2} H(e_1, e_2) , d(\\mu_1 \\otimes \\mu_2)(e_1, e_2) = \\int_{E_1} \\left( \\int_{E_2} H(e_1, e_2) , d\\mu_2(e_2) \\right) , d\\mu_1(e_1).\nAnalogamente, invertendo l’ordine di integrazione:\n\nPer quasi ogni e_2 \\in E_2 (rispetto a \\mu_2), la funzione e_1 \\mapsto H(e_1, e_2) è \\mathcal{E}_1-integrabile.\nLa funzione e_2 \\mapsto \\int_{E_1} H(e_1, e_2) , d\\mu_1(e_1) è \\mathcal{E}_2-misurabile su [0, +\\infty].\nSi ha l’uguaglianza:\n\n\\qquad \\int_{E_1 \\times E_2} H(e_1, e_2) , d(\\mu_1 \\otimes \\mu_2)(e_1, e_2) = \\int_{E_2} \\left( \\int_{E_1} H(e_1, e_2) , d\\mu_1(e_1) \\right) , d\\mu_2(e_2).\nQuindi, per una funzione misurabile e positiva, l’integrale sullo spazio prodotto può essere calcolato come un integrale iterato, integrando prima rispetto a una variabile e poi rispetto all’altra, e l’ordine di integrazione non influisce sul risultato.\nIl professore sottolinea che l’ipotesi che H sia positiva è cruciale per garantire che la funzione integranda interna sia misurabile e che gli integrali siano ben definiti (anche se possono essere +\\infty). Inoltre, parte dell’enunciato è che se l’integrale doppio è finito, allora anche l’integrale iterato è finito, e viceversa.\nConnessione con l’Integrale Multiplo\nIl professore fa un collegamento con l’integrale multiplo visto in Analisi II, dove tipicamente si calcola l’integrale di una funzione su un dominio in \\mathbb{R}^2 (o \\mathbb{R}^n) tramite integrazione per sezioni. Il teorema di Fubini-Tonelli generalizza questa idea a spazi misurabili astratti e fornisce una giustificazione rigorosa per il calcolo degli integrali multipli come integrali iterati.\nProssimi Passi\nIl professore conclude anticipando che nella lezione successiva si approfondirà il teorema di Fubini-Tonelli per funzioni non necessariamente positive e si esplorerà la connessione con l’indipendenza. Si specifica che gli argomenti trattati fino a questo punto potrebbero rientrare nel programma del prossimo compitino. Le esercitazioni sono considerate fondamentali per la comprensione di questi concetti.\nReferences"},"6--full-note/prob-lez16":{"slug":"6--full-note/prob-lez16","filePath":"6- full note/prob-lez16.md","title":"prob-lez16","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/sbobine","3--tag/probabilità"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-14 10:36\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:sbobine  probabilità\nprob-lez16\nMisure Prodotto e Teorema di Tonelli\nSpazio Misurabile Prodotto\nDati due spazi di misura (E_1, \\mathcal{M}_1, \\mu_1) e (E_2, \\mathcal{M}_2, \\mu_2), si definisce lo spazio misurabile prodotto come il prodotto cartesiano E = E_1 \\times E_2 dotato della \\sigma-algebra prodotto.\nLa \\sigma-algebra prodotto, indicata con \\mathcal{M}_1 \\otimes \\mathcal{M}_2, è la più piccola \\sigma-algebra costituita dai rettangoli misurabili, ovvero insiemi della forma N_1 \\times N_2 dove N_1 \\in \\mathcal{M}_1 e N_2 \\in \\mathcal{M}_2.\nMisura Prodotto\nSe le misure \\mu_1 e \\mu_2 sono \\sigma-finite, allora esiste un’unica misura \\mu sullo spazio misurabile prodotto (E_1 \\times E_2, \\mathcal{M}_1 \\otimes \\mathcal{M}_2), chiamata misura prodotto e indicata con \\mu_1 \\times \\mu_2 o semplicemente \\mu, tale che per ogni rettangolo misurabile N_1 \\times N_2 si abbia:\n\\qquad \\mu(N_1 \\times N_2) = \\mu_1(N_1) \\mu_2(N_2)\n\nTeorema di Tonelli\nEnunciato: Sia h: E = E_1 \\times E_2 \\rightarrow [0, +\\infty] una funzione misurabile rispetto alla \\sigma-algebra prodotto \\mathcal{M}_1 \\otimes \\mathcal{M}_2. Allora, l’integrale doppio \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) è sempre ben definito (potendo essere anche +\\infty). Inoltre, valgono le seguenti uguaglianze:\n\\qquad \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) = \\int_{E_1} \\left( \\int_{E_2} h(e_1, e_2) d\\mu_2(e_2) \\right) d\\mu_1(e_1)\n\\qquad \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) = \\int_{E_2} \\left( \\int_{E_1} h(e_1, e_2) d\\mu_1(e_1) \\right) d\\mu_2(e_2)\nSpiegazione: Il teorema di Tonelli afferma che per funzioni positive misurabili, l’ordine di integrazione non influisce sul risultato dell’integrale. Se uno dei due integrali iterati è finito, allora anche l’altro lo è e coincidono con l’integrale sulla misura prodotto. Se uno dei due è +\\infty, anche gli altri sono +\\infty.\nOsservazione: Come sottolineato dal professore, l’integrale interno, ad esempio \\int_{E_2} h(e_1, e_2) d\\mu_2(e_2), risulta essere una funzione di e_1, e questa funzione è misurabile.\n\nTeorema di Fubini\nTeorema di Fubini\nEnunciato: Sia h: E = E_1 \\times E_2 \\rightarrow \\mathbb{R} (o \\mathbb{C}) una funzione misurabile rispetto alla \\sigma-algebra prodotto \\mathcal{M}_1 \\otimes \\mathcal{M}_2. Se l’integrale del modulo di h sulla misura prodotto è finito, ovvero:\n\\qquad \\int_{E_1 \\times E_2} |h(e_1, e_2)| d(\\mu_1 \\times \\mu_2)(e_1, e_2) &lt; +\\infty\nallora valgono le seguenti affermazioni:\n\nPer \\mu_1-quasi ogni e_1 \\in E_1, la funzione h(e_1, \\cdot): E_2 \\rightarrow \\mathbb{R} (o \\mathbb{C}) è \\mu_2-integrabile.\nPer \\mu_2-quasi ogni e_2 \\in E_2, la funzione h(\\cdot, e_2): E_1 \\rightarrow \\mathbb{R} (o \\mathbb{C}) è \\mu_1-integrabile.\nLe funzioni definite da: \\qquad I_1(e_1) = \\int_{E_2} h(e_1, e_2) d\\mu_2(e_2) \\qquad I_2(e_2) = \\int_{E_1} h(e_1, e_2) d\\mu_1(e_1) sono rispettivamente \\mu_1-integrabile e \\mu_2-integrabile.\nValgono le seguenti uguaglianze: \\qquad \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) = \\int_{E_1} \\left( \\int_{E_2} h(e_1, e_2) d\\mu_2(e_2) \\right) d\\mu_1(e_1) \\qquad \\int_{E_1 \\times E_2} h(e_1, e_2) d(\\mu_1 \\times \\mu_2)(e_1, e_2) = \\int_{E_2} \\left( \\int_{E_1} h(e_1, e_2) d\\mu_1(e_1) \\right) d\\mu_2(e_2)\n\nSpiegazione: Il teorema di Fubini estende la possibilità di scambiare l’ordine di integrazione a funzioni che non sono necessariamente positive, a condizione che l’integrale del loro valore assoluto sia finito. Questa condizione garantisce che le funzioni ottenute integrando rispetto a una variabile siano integrabili rispetto all’altra.\n\nInterpretazione dell’Uguaglianza: Come spiegato dal professore, l’uguaglianza degli integrali iterati va interpretata nel senso che la funzione interna potrebbe non essere ben definita su un insieme di misura zero (rispetto alla misura esterna). Tuttavia, questo non influisce sul valore dell’integrale esterno. In pratica, si può definire la funzione interna arbitrariamente (ad esempio, ponendola uguale a zero) su tale insieme di misura nulla senza cambiare il risultato dell’integrale finale.\nDifferenze tra Tonelli e Fubini\nLa differenza fondamentale tra i due teoremi risiede nelle ipotesi sulla funzione h:\n\nTonelli: Si applica a funzioni positive e misurabili. L’integrale doppio è sempre ben definito (anche se infinito), e l’ordine di integrazione può essere scambiato senza la necessità di verificare la finitezza dell’integrale.\nFubini: Si applica a funzioni non necessariamente positive, ma misurabili e tali che l’integrale del loro modulo sia finito. Questa condizione è cruciale per poter scambiare l’ordine di integrazione e garantire che gli integrali iterati siano ben definiti e finiti.\n\nApplicazione di Tonelli e Fubini\nPer applicare il teorema di Fubini a una funzione h non positiva, la strategia tipica è la seguente:\n\nConsiderare il modulo della funzione, |h|.\nApplicare il teorema di Tonelli alla funzione |h|, poiché è positiva. Si calcola uno degli integrali iterati di |h|.\nSe l’integrale di |h| (e quindi gli integrali iterati di |h|) è finito, allora si può applicare il teorema di Fubini alla funzione h, e l’ordine di integrazione può essere scambiato per l’integrale di h stesso.\n\nApplicazione a Misure di Lebesgue e Integrale Doppio\nCaso delle Misure di Lebesgue su \\mathbb{R}^{d_1} \\times \\mathbb{R}^{d_2}\nUn caso fondamentale in cui si applicano i teoremi di Fubini e Tonelli è quando gli spazi di misura sono \\mathbb{R}^{d_1} e \\mathbb{R}^{d_2} dotati della misura di Lebesgue e della \\sigma-algebra dei Boreliani. In questo caso, la \\sigma-algebra prodotto coincide con la \\sigma-algebra dei Boreliani di \\mathbb{R}^{d_1 + d_2}.\nSe abbiamo una funzione h(x_1, x_2) con x_1 \\in \\mathbb{R}^{d_1} e x_2 \\in \\mathbb{R}^{d_2}, l’integrale rispetto alla misura prodotto (misura di Lebesgue su \\mathbb{R}^{d_1 + d_2}) può essere scritto come:\n\\qquad \\int_{\\mathbb{R}^{d_1 + d_2}} h(x_1, x_2) dx_1 dx_2\nSe l’integrale di |h| è finito, per il teorema di Fubini possiamo scambiare l’ordine di integrazione:\n\\qquad \\int_{\\mathbb{R}^{d_1 + d_2}} h(x_1, x_2) dx_1 dx_2 = \\int_{\\mathbb{R}^{d_1}} \\left( \\int_{\\mathbb{R}^{d_2}} h(x_1, x_2) dx_2 \\right) dx_1 = \\int_{\\mathbb{R}^{d_2}} \\left( \\int_{\\mathbb{R}^{d_1}} h(x_1, x_2) dx_1 \\right) dx_2\n\nCollegamento con l’Integrale Doppio in Analisi\nIl professore fa notare che questo formalismo generalizza il concetto di integrale doppio visto in corsi di analisi su insiemi “normali” o plurirettangoli e per funzioni “integrabili” nel senso usuale. I teoremi di Fubini e Tonelli permettono di estendere questi risultati a insiemi misurabili Boreliani qualsiasi e a funzioni che sono Lebesgue-integrabili, una classe più ampia di funzioni rispetto a quelle Riemann-integrabili.\nIn pratica, per calcolare un integrale doppio, si procede come si è abituati: si integra prima rispetto a una variabile (mantenendo l’altra fissa) e poi si integra il risultato rispetto all’altra variabile. I teoremi di Fubini e Tonelli forniscono le condizioni sotto le quali questo procedimento è valido e il risultato è indipendente dall’ordine di integrazione.\nMarginali di Legge Assolutamente Continue\nCaso Discreto (Richiamo)\nIl professore ricorda che nel caso di vettori aleatori discreti, se si ha la distribuzione congiunta (ad esempio, una tabella di contingenza), la distribuzione marginale di una singola variabile (o di un sottovettore) si ottiene sommando (o “saturando”) sulla(e) variabile(i) non di interesse.\n\nCaso Assolutamente Continuo (d=2)\nConsideriamo un vettore aleatorio assolutamente continuo (X_1, X_2) con funzione di densità congiunta f(x_1, x_2). Vogliamo trovare la funzione di densità marginale di X_1, che denotiamo con f_{X_1}(x_1).\nCalcolo della Funzione di Ripartizione Marginale: La funzione di ripartizione marginale di X_1, F_{X_1}(x_1), è data da:\n\\qquad F_{X_1}(x_1) = P(X_1 \\leq x_1) = P(X_1 \\leq x_1, X_2 \\in \\mathbb{R})\nQuesta probabilità può essere espressa come l’integrale della densità congiunta sull’insieme {(t_1, t_2) \\in \\mathbb{R}^2 : t_1 \\leq x_1, t_2 \\in \\mathbb{R}}:\n\\qquad F_{X_1}(x_1) = \\int_{-\\infty}^{x_1} \\int_{-\\infty}^{+\\infty} f(t_1, t_2) dt_2 dt_1\n\nDerivazione della Densità Marginale: Applicando il teorema di Tonelli (poiché la densità congiunta è non negativa), possiamo scambiare l’ordine di integrazione:\n\\qquad F_{X_1}(x_1) = \\int_{-\\infty}^{x_1} \\left( \\int_{-\\infty}^{+\\infty} f(t_1, t_2) dt_2 \\right) dt_1\nDefiniamo la funzione f_{X_1}(t_1) = \\int_{-\\infty}^{+\\infty} f(t_1, t_2) dt_2. Allora possiamo scrivere:\n\\qquad F_{X_1}(x_1) = \\int_{-\\infty}^{x_1} f_{X_1}(t_1) dt_1\n\nPer la definizione di variabile assolutamente continua, questo significa che X_1 è assolutamente continua e la sua funzione di densità marginale è data da:\n\\qquad f_{X_1}(x_1) = \\int_{-\\infty}^{+\\infty} f(x_1, x_2) dx_2\n\nSpiegazione del Procedimento Logico: Il professore sottolinea che non si assume a priori che X_1 sia assolutamente continua. Il procedimento consiste nel calcolare la funzione di ripartizione marginale e mostrare che essa può essere espressa come l’integrale di una funzione (la densità marginale). Questo dimostra che X_1 è assolutamente continua e identifica la sua densità.\nCaso Generale (d &gt; 2)\nIl risultato si generalizza a vettori aleatori in d dimensioni. Se X = (X_1, ..., X_d) è assolutamente continuo con densità f(x_1, ..., x_d), allora ogni sottovettore è assolutamente continuo.\nIn particolare, la densità marginale di un sottovettore (X_{i_1}, ..., X_{i_k}) (dove 1 \\leq i_1 &lt; ... &lt; i_k \\leq d) si ottiene integrando la densità congiunta rispetto a tutte le altre variabili (cioè le variabili con indici j \\in {1, ..., d} \\setminus {i_1, ..., i_k}).\nMatematicamente, la densità marginale f_{X_{i_1}, ..., X_{i_k}}(x_{i_1}, ..., x_{i_k}) è data da:\n\\qquad f_{X_{i_1}, ..., X_{i_k}}(x_{i_1}, ..., x_{i_k}) = \\int_{\\mathbb{R}^{d-k}} f(x_1, ..., x_d) \\prod_{j \\notin {i_1, ..., i_k}} dx_j\n\nEsempio (d=3): Se d=3 e vogliamo la densità marginale di (X_1, X_3), cioè f_{X_1, X_3}(x_1, x_3), dobbiamo integrare la densità congiunta f(x_1, x_2, x_3) rispetto alla variabile x_2:\n\\qquad f_{X_1, X_3}(x_1, x_3) = \\int_{-\\infty}^{+\\infty} f(x_1, x_2, x_3) dx_2\n\n\nSpiegazione Sulla Assoluta Continuità, Marginali e Indipendenza\nAssoluta Continuità di Vettori Aleatori e Marginali\nIl professore introduce il concetto di assoluta continuità per vettori aleatori multidimensionali.\n\n\nDefinizione: Un vettore aleatorio è assolutamente continuo rispetto alla misura di Lebesgue se la sua probabilità può essere espressa come l’integrale di una funzione di densità.\n\n\nProprietà Fondamentale: Se un vettore aleatorio (X_1, X_2, ..., X_d) è assolutamente continuo, allora tutti i suoi sottovettori (incluse le marginali unidimensionali) sono anch’essi assolutamente continui. Questo significa che se il vettore “più grande” è assolutamente continuo, possiamo “sfilare” qualsiasi sottovettore, e questo manterrà la proprietà di essere assolutamente continuo.\n\n\nEsempio: Se abbiamo un vettore (X_1, X_2, X_3) assolutamente continuo, allora X_1, X_2, X_3, (X_1, X_2), (X_1, X_3), e (X_2, X_3) sono tutti assolutamente continui.\n\n\nCalcolo delle Marginali nel Caso Assolutamente Continuo\nIl calcolo delle densità marginali da una densità congiunta si effettua tramite integrazione, analogamente a come si fa con le somme nel caso discreto. Questa operazione è una conseguenza del teorema di Fubini-Tonelli.\n\n\nMarginale Unidimensionale: Per ottenere la densità marginale di una variabile X_i da una densità congiunta f(x_1, ..., x_d), si integra la densità congiunta rispetto a tutte le altre variabili: f_{X_i}(x_i) = \\int ... \\int f(x_1, ..., x_d) dx_1 ... dx_{i-1} dx_{i+1} ... dx_d.\n\n\nMarginale Multidimensionale: Per ottenere la densità marginale di un sottovettore, ad esempio (X_i, X_j), si integra la densità congiunta rispetto a tutte le variabili che non compaiono nel sottovettore: f_{X_i, X_j}(x_i, x_j) = \\int ... \\int f(x_1, ..., x_d) dx_1 ... dx_{i-1} dx_{i+1} ... dx_{j-1} dx_{j+1} ... dx_d.\n\n\nLa Non Implicazione Viceversa: Marginali Assolutamente Continue non Implicano Congiunta Assolutamente Continua\nUn punto cruciale sottolineato dal professore è che sebbene un vettore assolutamente continuo implichi marginali assolutamente continue, il contrario non è sempre vero.\n\n\nControesempio: X = (Y, Y) Consideriamo un vettore X = (X_1, X_2) dove X_1 = Y e X_2 = Y, e Y è una variabile aleatoria assolutamente continua.\n\n\nMarginali Assolutamente Continue: Marginalmente, sia X_1 che X_2 sono uguali a Y, quindi sono assolutamente continue.\n\n\nCongiunta Non Assolutamente Continua: Il vettore X = (Y, Y) non è assolutamente continuo. Per costruzione, la probabilità che X_1 = X_2 è sempre 1: P(X_1 = X_2) = P(Y = Y) = 1.\n\n\nDimostrazione per Assurdo: Se X fosse assolutamente continuo, esisterebbe una densità congiunta f_{X_1, X_2}(x_1, x_2) tale che: P(X_1 = X_2) = \\iint_{{(x_1, x_2) | x_1 = x_2}} f_{X_1, X_2}(x_1, x_2) dx_1 dx_2.\nL’insieme {(x_1, x_2) | x_1 = x_2} rappresenta una retta nel piano \\mathbb{R}^2. La misura di Lebesgue di una retta in \\mathbb{R}^2 è zero.\nSe f_{X_1, X_2} è integrabile (come dovrebbe essere per una densità), allora l’integrale di Lebesgue di una funzione integrabile su un insieme di misura di Lebesgue nulla è zero.\nQuindi, se X fosse assolutamente continuo, avremmo P(X_1 = X_2) = 0, che contraddice il fatto che P(X_1 = X_2) = 1. Pertanto, il vettore X = (Y, Y) non può essere assolutamente continuo, anche se le sue marginali lo sono.\n\n\nIntuizione Geometrica: La distribuzione di probabilità del vettore (Y, Y) è concentrata sulla retta x_1 = x_2 nel piano \\mathbb{R}^2. Una distribuzione assolutamente continua in \\mathbb{R}^2 dovrebbe essere “diffusa” su insiemi bidimensionali con misura di Lebesgue non nulla, non concentrata su un insieme di misura nulla come una retta.\n\n\n\n\n\nIndipendenza e Misure Prodotto\nIl professore introduce l’applicazione del teorema di Fubini-Tonelli nel contesto di spazi di probabilità e come questo porta al concetto di indipendenza.\n\n\nMisure Prodotto: Dati due spazi di probabilità (X_1, \\mathcal{A}_1, \\mu_1) e (X_2, \\mathcal{A}_2, \\mu_2), si può definire una misura prodotto P = \\mu_1 \\times \\mu_2 sullo spazio prodotto (X_1 \\times X_2, \\mathcal{A}_1 \\otimes \\mathcal{A}_2) tale che per ogni A_1 \\in \\mathcal{A}_1 e A_2 \\in \\mathcal{A}_2: P(A_1 \\times A_2) = \\mu_1(A_1) \\mu_2(A_2).\n\n\nVariabili Aleatorie e Misure Indotte: Se X_1 e X_2 sono variabili aleatorie definite su uno spazio di probabilità comune (\\Omega, \\mathcal{F}, P) a valori in (\\mathbb{R}, \\mathcal{B}(\\mathbb{R})), possiamo considerare le loro misure indotte \\mathbb{P}_{X_1}(A_1) = P(X_1 \\in A_1) e \\mathbb{P}_{X_2}(A_2) = P(X_2 \\in A_2).\n\n\n\nMisura Immagine e Misura Prodotto delle Marginali: La legge congiunta di (X_1, X_2) è la misura immagine \\mathbb{P}_{(X_1, X_2)}(A_1 \\times A_2) = P(X_1 \\in A_1, X_2 \\in A_2) sullo spazio prodotto \\mathbb{R}^2. Possiamo anche considerare la misura prodotto delle marginali: \\mathbb{P}_{X_1} \\times \\mathbb{P}_{X_2}(A_1 \\times A_2) = \\mathbb{P}_{X_1}(A_1) \\mathbb{P}_{X_2}(A_2) = P(X_1 \\in A_1) P(X_2 \\in A_2).\n\n\nDefinizione di Indipendenza: Due variabili aleatorie X_1 e X_2 sono indipendenti se per ogni A_1, A_2 misurabili (negli spazi di arrivo): P(X_1 \\in A_1, X_2 \\in A_2) = P(X_1 \\in A_1) P(X_2 \\in A_2).\n\n\nProposizione: Le variabili aleatorie X_1 e X_2 sono indipendenti se e solo se la loro misura immagine (legge congiunta) è uguale alla misura prodotto delle loro marginali: \\mathbb{P}_{(X_1, X_2)} = \\mathbb{P}_{X_1} \\times \\mathbb{P}_{X_2}.\nQuesta equivalenza deriva dal fatto che due misure di probabilità che coincidono su tutti i rettangoli del prodotto coincidono sull’intera sigma-algebra prodotto.\n\n\n\nTeorema di Fubini per Variabili Aleatorie Indipendenti\nUna delle conseguenze fondamentali dell’indipendenza, derivata dal teorema di Fubini-Tonelli, riguarda il calcolo del valore atteso di funzioni di variabili aleatorie indipendenti.\n\n\nTeorema: Siano X_1, X_2 variabili aleatorie reali definite su uno spazio di probabilità e indipendenti. Sia h: \\mathbb{R}^2 \\rightarrow \\mathbb{R} una funzione misurabile.\n\n\nCaso h \\ge 0: Se h è non negativa, allora: E[h(X_1, X_2)] = \\int_{\\mathbb{R}^2} h(x_1, x_2) d\\mathbb{P}_{(X_1, X_2)}(x_1, x_2) = \\int_{\\mathbb{R}} \\left( \\int_{\\mathbb{R}} h(x_1, x_2) d\\mathbb{P}_{X_2}(x_2) \\right) d\\mathbb{P}_{X_1}(x_1) = \\int_{\\mathbb{R}} \\int_{\\mathbb{R}} h(x_1, x_2) d\\mathbb{P}_{X_1}(x_1) d\\mathbb{P}_{X_2}(x_2).\nNel caso in cui X_1 e X_2 abbiano densità f_{X_1}(x_1) e f_{X_2}(x_2) rispettivamente, e quindi la densità congiunta sia f_{X_1, X_2}(x_1, x_2) = f_{X_1}(x_1) f_{X_2}(x_2) (per l’indipendenza), il teorema diventa: E[h(X_1, X_2)] = \\int_{\\mathbb{R}} \\int_{\\mathbb{R}} h(x_1, x_2) f_{X_1}(x_1) f_{X_2}(x_2) dx_1 dx_2.\n\n\nCaso E[|h(X_1, X_2)|] &lt; \\infty: Se il valore atteso del modulo di h(X_1, X_2) è finito, allora vale la stessa uguaglianza. Questo assicura che gli integrali sono ben definiti.\n\n\n\n\n\nCorollario: Valore Atteso del Prodotto di Variabili Aleatorie Indipendenti\nUn importante corollario del teorema di Fubini per variabili indipendenti riguarda il valore atteso del loro prodotto.\n\n\nCorollario: Siano X_1, ..., X_n variabili aleatorie reali indipendenti tali che il valore atteso di ognuna di esse sia finito (E[|X_i|] &lt; \\infty per ogni i). Allora, il valore atteso del loro prodotto è finito e uguale al prodotto dei loro valori attesi: E[X_1 ... X_n] = E[X_1] ... E[X_n].\nQuesta proprietà è fondamentale e semplifica notevolmente il calcolo dei momenti misti per variabili indipendenti. Invece di calcolare integrali multipli, si calcolano prodotti di integrali singoli.\n\n\n\nCriteri per Verificare l’Indipendenza\nIl professore menziona brevemente i criteri per verificare se due variabili aleatorie sono indipendenti.\n\n\nDefinizione Generale: X_1 e X_2 sono indipendenti se per ogni coppia di eventi A_1 e A_2 negli spazi di arrivo, P(X_1 \\in A_1 \\cap X_2 \\in A_2) = P(X_1 \\in A_1) P(X_2 \\in A_2). Verificarlo per tutti gli eventi può essere difficile.\n\n\nFunzione di Ripartizione: Per variabili aleatorie reali, X_1 e X_2 sono indipendenti se e solo se la loro funzione di ripartizione congiunta F_{X_1, X_2}(x_1, x_2) è uguale al prodotto delle loro funzioni di ripartizione marginali F_{X_1}(x_1) e F_{X_2}(x_2): F_{X_1, X_2}(x_1, x_2) = P(X_1 \\le x_1, X_2 \\le x_2) = P(X_1 \\le x_1) P(X_2 \\le x_2) = F_{X_1}(x_1) F_{X_2}(x_2). Questo criterio è generale ma la funzione di ripartizione congiunta potrebbe non essere sempre facile da calcolare.\n\n\nDensità (se esistono): Se X_1 e X_2 hanno densità f_{X_1}(x_1) e f_{X_2}(x_2), allora sono indipendenti se e solo se la loro densità congiunta f_{X_1, X_2}(x_1, x_2) è uguale al prodotto delle loro densità marginali: f_{X_1, X_2}(x_1, x_2) = f_{X_1}(x_1) f_{X_2}(x_2). Questo è un criterio pratico quando le densità sono note.\n\n\n\nIndipendenza di Vettori Aleatori Assolutamente Continui\nProposizione/Teorema: Condizione di Indipendenza Tramite la Fattorizzazione della Densità Congiunta\nSia X = (X_1, ..., X_d) un vettore assolutamente continuo con densità f(x) = f(x_1, ..., x_d). Le componenti X_1, ..., X_d sono indipendenti se e solo se la densità congiunta d_X(x) (utilizzando d per coerenza) fattorizza, ovvero se esiste una scelta di funzioni f_i(x_i) (che risulteranno essere le densità marginali) tali che:\nd_X(x_1, ..., x_d) = f_1(x_1) \\cdot f_2(x_2) \\cdot ... \\cdot f_d(x_d)\nper ogni scelta di vettori x = (x_1, ..., x_d) di dimensioni appropriate. È importante ricordare che le densità non sono definite ovunque, quindi questa uguaglianza deve valere laddove le densità sono definite. Questa condizione è analoga a quella del caso discreto, e non deve valere solo per qualche particolare x, ma per tutti i possibili x.\nDimostrazione (Supponendo che la Densità Fattorizzi)\nSupponiamo che la densità congiunta fattorizzi come d_X(t_1, ..., t_d) = f_1(t_1) \\cdot f_2(t_2) \\cdot ... \\cdot f_d(t_d). Vogliamo calcolare la funzione di ripartizione multivariata F_X(x) = P(X_1 \\le x_1, ..., X_d \\le x_d) in un punto generico x = (x_1, ..., x_d). Per la definizione di funzione di ripartizione, si ha:\nF_X(x_1, ..., x_d) = \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} d_X(t_1, ..., t_d) dt_d ... dt_1\nDato che stiamo assumendo che la densità fattorizza, possiamo sostituire d_X con il prodotto delle funzioni f_i:\nF_X(x_1, ..., x_d) = \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} f_1(t_1) \\cdot f_2(t_2) \\cdot ... \\cdot f_d(t_d) dt_d ... dt_1\n\nPer il teorema di Fubini-Tonelli, possiamo scambiare l’ordine di integrazione e, poiché ogni f_i(t_i) dipende solo da t_i, possiamo separare gli integrali:\nF_X(x_1, ..., x_d) = \\left( \\int_{-\\infty}^{x_1} f_1(t_1) dt_1 \\right) \\cdot \\left( \\int_{-\\infty}^{x_2} f_2(t_2) dt_2 \\right) \\cdot ... \\cdot \\left( \\int_{-\\infty}^{x_d} f_d(t_d) dt_d \\right)\nOgni termine di questo prodotto è la funzione di ripartizione marginale della corrispondente variabile X_i calcolata in x_i:\nF_{X_i}(x_i) = \\int_{-\\infty}^{x_i} f_i(t_i) dt_i\nQuindi, otteniamo:\nF_X(x_1, ..., x_d) = F_{X_1}(x_1) \\cdot F_{X_2}(x_2) \\cdot ... \\cdot F_{X_d}(x_d)\nPoiché la funzione di ripartizione congiunta fattorizza nel prodotto delle funzioni di ripartizione marginali, le variabili X_1, ..., X_d sono indipendenti.\n\nDimostrazione (Supponendo l’Indipendenza)\nSupponiamo che le variabili aleatorie X_1, ..., X_d siano indipendenti. Per variabili aleatorie reali, questo significa che la loro funzione di ripartizione congiunta fattorizza nel prodotto delle funzioni di ripartizione marginali: F_X(x_1, ..., x_d) = \\prod_{i=1}^{d} F_{X_i}(x_i).\nSappiamo che, per una variabile aleatoria assolutamente continua X_i, la sua funzione di ripartizione marginale può essere espressa come l’integrale della sua densità marginale f_{X_i}(t_i): F_{X_i}(x_i) = \\int_{-\\infty}^{x_i} f_{X_i}(t_i) dt_i.\nSostituendo queste espressioni nella condizione di indipendenza per le funzioni di ripartizione, otteniamo: \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} f(t_1, ..., t_d) dt_1 ... dt_d = \\prod_{i=1}^{d} \\left( \\int_{-\\infty}^{x_i} f_{X_i}(t_i) dt_i \\right).\nIl lato destro di questa equazione può essere riscritto come un integrale multiplo grazie al teorema di Fubini-Tonelli: \\prod_{i=1}^{d} \\left( \\int_{-\\infty}^{x_i} f_{X_i}(t_i) dt_i \\right) = \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} \\left( \\prod_{i=1}^{d} f_{X_i}(t_i) \\right) dt_1 ... dt_d.\nQuindi, abbiamo: \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} f(t_1, ..., t_d) dt_1 ... dt_d = \\int_{-\\infty}^{x_1} ... \\int_{-\\infty}^{x_d} \\left( \\prod_{i=1}^{d} f_{X_i}(t_i) \\right) dt_1 ... dt_d.\nQuesta uguaglianza vale per ogni scelta di x_1, ..., x_d. Ciò implica che le funzioni integrande devono essere uguali quasi ovunque (a meno di insiemi di misura di Lebesgue nulla): f(x_1, ..., x_d) = \\prod_{i=1}^{d} f_{X_i}(x_i).\nPertanto, se le variabili aleatorie sono indipendenti, la loro densità congiunta fattorizza nel prodotto delle densità marginali.\n\nQuesto dimostra che se le variabili sono indipendenti, la densità congiunta fattorizza nel prodotto delle densità marginali. La funzione prodotto \\prod_{i=1}^{d} f_{X_i}(x_i) è una funzione positiva e il suo integrale su \\mathbb{R}^d è uguale a 1 (per il teorema di Fubini, è il prodotto degli integrali di ogni f_{X_i} su \\mathbb{R}, che sono tutti uguali a 1). Pertanto, essa è una densità per il vettore X. Siccome la densità è unica a meno di insiemi di misura nulla, il prodotto delle densità marginali deve essere uguale alla densità congiunta (quasi ovunque).\nCriterio di Indipendenza Tramite Densità Congiunta e Marginali\nUn criterio utile per verificare l’indipendenza di un vettore assolutamente continuo è il seguente: se si ha la densità congiunta f(x_1, ..., x_d), si calcolano le densità marginali f_{X_i}(x_i) (integrando la densità congiunta rispetto a tutte le altre variabili). Se il prodotto delle densità marginali è uguale alla densità congiunta:\nf(x_1, ..., x_d) = f_{X_1}(x_1) \\cdot f_{X_2}(x_2) \\cdot ... \\cdot f_{X_d}(x_d)\nallora le variabili X_1, ..., X_d sono indipendenti. In teoria, si dovrebbe prima conoscere la congiunta, calcolare le marginali e poi verificare la loro relazione. Tuttavia, in alcuni casi, si può arrivare a questa conclusione in modo più sintetico.\nTrasformazioni di Vettori Aleatori e Indipendenza\nIn generale, trasformare vettori aleatori senza l’ipotesi di indipendenza può essere complicato. Tuttavia, l’indipendenza spesso semplifica notevolmente il problema. Esempi di trasformazioni già viste includono trasformazioni lineari e modelli scala posizione. È importante saper dedurre la funzione di ripartizione e la funzione di densità delle variabili trasformate. Altri esempi di trasformazioni includono il massimo, il minimo, il modulo e il quadrato di variabili aleatorie.\nCertamente, ecco la spiegazione del professore a partire dalla Funzione di Ripartizione del Massimo, integrata con i contenuti forniti e formattata come richiesto:\nStatistiche d’Ordine: Massimo e Minimo di Variabili Aleatorie Indipendenti\nIntroduzione alle Statistiche d’Ordine\nLe statistiche d’ordine si occupano dello studio di variabili aleatorie ottenute ordinando un campione di variabili aleatorie. Tra le statistiche d’ordine più semplici e importanti troviamo il massimo e il minimo di un insieme di variabili aleatorie indipendenti.\nConsideriamo n variabili aleatorie X_1, X_2, ..., X_n indipendenti. Definiamo il massimo M = \\max(X_1, X_2, ..., X_n) e il minimo m = \\min(X_1, X_2, ..., X_n). Essendo funzioni continue di variabili aleatorie, anche M e m sono variabili aleatorie.\nFunzione di Ripartizione del Massimo\nVogliamo calcolare la funzione di ripartizione del massimo, F_M(x) = P(M \\le x).\nL’evento {M \\le x} si verifica se e solo se tutte le variabili aleatorie X_1, X_2, ..., X_n sono minori o uguali a x: {M \\le x} = {\\max(X_1, ..., X_n) \\le x} = {X_1 \\le x, X_2 \\le x, ..., X_n \\le x}\nQuindi, la funzione di ripartizione del massimo è: F_M(x) = P(X_1 \\le x, X_2 \\le x, ..., X_n \\le x)\nSfruttando l’ipotesi di indipendenza delle variabili aleatorie, possiamo scrivere la probabilità congiunta come il prodotto delle probabilità marginali: F_M(x) = P(X_1 \\le x) P(X_2 \\le x) ... P(X_n \\le x)\nIntroduciamo ora l’ulteriore ipotesi che le variabili aleatorie siano identicamente distribuite (i.i.d.), cioè che abbiano tutte la stessa funzione di ripartizione F_X(x) = P(X_i \\le x) per ogni i = 1, ..., n: F_M(x) = [F_X(x)]^n\n\nQuesto risultato ci permette di esprimere la funzione di ripartizione del massimo in termini della funzione di ripartizione della singola variabile aleatoria quando queste sono indipendenti e identicamente distribuite.\nFunzione di Ripartizione del Minimo\nConsideriamo ora il minimo m = \\min(X_1, X_2, ..., X_n). Calcolare direttamente P(m \\le x) non è particolarmente agevole. È più conveniente calcolare la funzione di sopravvivenza (o contropartizione) del minimo, P(m &gt; x), e poi ricavare la funzione di ripartizione.\nL’evento {m &gt; x} si verifica se e solo se tutte le variabili aleatorie X_1, X_2, ..., X_n sono maggiori di x: {m &gt; x} = {\\min(X_1, ..., X_n) &gt; x} = {X_1 &gt; x, X_2 &gt; x, ..., X_n &gt; x}\nQuindi, la probabilità che il minimo sia maggiore di x è: P(m &gt; x) = P(X_1 &gt; x, X_2 &gt; x, ..., X_n &gt; x)\nSfruttando l’indipendenza delle variabili aleatorie: P(m &gt; x) = P(X_1 &gt; x) P(X_2 &gt; x) ... P(X_n &gt; x)\nSotto l’ipotesi di variabili i.i.d., dove P(X_i &gt; x) = 1 - F_X(x): P(m &gt; x) = [1 - F_X(x)]^n\nInfine, la funzione di ripartizione del minimo è data da: F_m(x) = P(m \\le x) = 1 - P(m &gt; x) = 1 - [1 - F_X(x)]^n\n\nEsempio 1: Minimo di Tempi di Guasto Esponenziali\nConsideriamo n tempi di guasto indipendenti, ciascuno distribuito secondo una legge esponenziale negativa con parametro \\lambda &gt; 0. La funzione di ripartizione di una variabile esponenziale con parametro \\lambda è F_X(x) = 1 - e^{-\\lambda x} per x &gt; 0, e F_X(x) = 0 per x \\le 0.\nVogliamo trovare la legge del minimo di questi tempi di guasto. Usando la formula per la funzione di ripartizione del minimo: F_m(x) = 1 - [1 - (1 - e^{-\\lambda x})]^n = 1 - [e^{-\\lambda x}]^n = 1 - e^{-n\\lambda x} per x &gt; 0. Per x \\le 0, F_X(x) = 0, quindi F_m(x) = 1 - ^n = 1 - 1 = 0.\nLa funzione di ripartizione F_m(x) = 1 - e^{-n\\lambda x} per x &gt; 0 è la funzione di ripartizione di una variabile aleatoria esponenziale negativa con parametro n\\lambda. Questo significa che il minimo di n variabili esponenziali i.i.d. con parametro \\lambda è ancora una variabile esponenziale, ma con un tasso di guasto n volte maggiore.\n\nEsercizio 1: Massimo di Variabili Uniformi su (0, 1)\nSiano X_1, ..., X_n variabili aleatorie indipendenti e identicamente distribuite secondo una legge uniforme sull’intervallo (0, 1). La funzione di ripartizione di una variabile uniforme su (0, 1) è: F_X(x) = \\begin{cases} 0 &amp; x \\le 0 \\\\ x &amp; 0 &lt; x &lt; 1 \\\\ 1 &amp; x \\ge 1 \\end{cases}\nCalcolare la funzione di ripartizione e la densità del massimo M = \\max(X_1, ..., X_n).\nUsando la formula per la funzione di ripartizione del massimo: F_M(x) = [F_X(x)]^n = \\begin{cases} 0^n = 0 &amp; x \\le 0 \\\\ x^n &amp; 0 &lt; x &lt; 1 \\\\ 1^n = 1 &amp; x \\ge 1 \\end{cases}\nPer trovare la densità f_M(x), deriviamo la funzione di ripartizione rispetto a x:\nf_M(x) = \\frac{d}{dx} F_M(x) = \\begin{cases} 0 &amp; x \\le 0 \\\\ nx^{n-1} &amp; 0 &lt; x &lt; 1 \\\\ 0 &amp; x \\ge 1 \\end{cases}\n\nda qui in poi un allucinazione\nTrasformazioni di Vettori Aleatori e Indipendenza\nQuando si considerano trasformazioni di vettori aleatori, l’indipendenza delle componenti semplifica notevolmente l’analisi. Senza l’ipotesi di indipendenza, determinare la legge della trasformazione può essere molto complesso. L’esempio dei massimi e minimi illustra come l’indipendenza permetta di ricavare le leggi delle statistiche d’ordine in modo relativamente semplice.\nFunzione Caratteristica della Gamma\nPer concludere, il professore introduce la funzione caratteristica della distribuzione Gamma, senza fornirne la derivazione.\nLa densità della distribuzione Gamma è proporzionale a x^{\\alpha - 1} e^{-\\beta x} per x &gt; 0, dove \\alpha &gt; 0 è il parametro di forma e \\beta &gt; 0 è il parametro di tasso (l’inverso del parametro di scala). La funzione caratteristica della distribuzione Gamma è data da: \\phi_X(t) = E[e^{itX}] = \\left( \\frac{\\beta}{\\beta - it} \\right)^\\alpha, per |t| &lt; \\beta .\nIl professore fa notare che la parametrizzazione della Gamma può variare a seconda della convenzione utilizzata (scala o tasso) . Nella forma presentata, \\beta è un parametro di tasso.\nCaso Particolare: Esponenziale\nCome caso particolare, la distribuzione Esponenziale con parametro \\lambda è una distribuzione Gamma con \\alpha = 1 e \\beta = \\lambda. La sua funzione caratteristica si ottiene sostituendo questi valori nella formula generale: \\phi_X(t) = \\left( \\frac{\\lambda}{\\lambda - it} \\right)^1 = \\frac{\\lambda}{\\lambda - it} = \\frac{1}{1 - it/\\lambda} .\nQuesto risultato può essere verificato direttamente tramite l’integrazione complessa, trattando l’integrale della funzione caratteristica come un integrale di funzioni complesse .\nEsercizio 2: Somma di Variabili Gamma Indipendenti\nConsiderare n variabili aleatorie indipendenti X_1, ..., X_n, dove ciascuna X_j segue una distribuzione Gamma con parametri (\\alpha_j, \\beta) (notare che hanno lo stesso parametro di tasso \\beta). Determinare la legge della somma S_n = X_1 + ... + X_n.\nSfruttando la proprietà che la funzione caratteristica della somma di variabili indipendenti è il prodotto delle loro funzioni caratteristiche: \\phi_{S_n}(t) = E[e^{itS_n}] = E[e^{it(X_1 + ... + X_n)}] = E[e^{itX_1} ... e^{itX_n}] = E[e^{itX_1}] ... E[e^{itX_n}] \\phi_{S_n}(t) = \\phi_{X_1}(t) ... \\phi_{X_n}(t) = \\left( \\frac{\\beta}{\\beta - it} \\right)^{\\alpha_1} ... \\left( \\frac{\\beta}{\\beta - it} \\right)^{\\alpha_n} = \\left( \\frac{\\beta}{\\beta - it} \\right)^{\\alpha_1 + ... + \\alpha_n}\nLa funzione caratteristica ottenuta è quella di una distribuzione Gamma con parametri (\\sum_{j=1}^n \\alpha_j, \\beta).\nCaso Particolare: Somma di Esponenziali\nSe consideriamo n variabili aleatorie esponenziali indipendenti con lo stesso parametro \\lambda (quindi \\alpha_j = 1 e \\beta = \\lambda per ogni j), la loro somma seguirà una distribuzione Gamma con parametri (n, \\lambda).\nQuesto conclude la parte della lezione richiesta, evidenziando l’importanza dell’indipendenza nello studio delle trasformazioni di variabili aleatorie e fornendo un’introduzione alla funzione caratteristica della distribuzione Gamma.\nReferences"},"6--full-note/prob-lez17":{"slug":"6--full-note/prob-lez17","filePath":"6- full note/prob-lez17.md","title":"prob-lez17","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-15 13:39\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags:\nprob-lez17\nSeconda Parte del Corso: Covarianza\nComplemento sull’Indipendenza\nFunzioni di Variabili Aleatorie Indipendenti\nIl professore inizia la seconda parte del corso con un complemento sulla proprietà dell’indipendenza che spesso si presenta nelle applicazioni.\nProposizione: Siano X_1, X_2, \\dots, X_n variabili aleatorie indipendenti. Si considerino delle funzioni misurabili g_1 di un sottoinsieme di queste variabili (ad esempio, X_{i_1}, \\dots, X_{i_k}) e g_2 di un altro sottoinsieme disgiunto (ad esempio, X_{j_1}, \\dots, X_{j_m}), dove {i_1, \\dots, i_k} \\cap {j_1, \\dots, j_m} = \\emptyset. Allora le variabili aleatorie Y_1 = g_1(X_{i_1}, \\dots, X_{i_k}) e Y_2 = g_2(X_{j_1}, \\dots, X_{j_m}) sono indipendenti.\nEsempio: Se X_1, X_2, X_3 sono variabili aleatorie indipendenti, allora Y_1 = g_1(X_1) = X_1^2 e Y_2 = g_2(X_2, X_3) = X_2^2 + X_3^2 sono indipendenti.\n\nDimostrazione (concettuale): La dimostrazione si basa sulla definizione di indipendenza tramite le controimmagini. Se X_i sono indipendenti, le sigma-algebre generate da gruppi disgiunti di queste variabili sono indipendenti. Le controimmagini di insiemi misurabili tramite g_1 e g_2 appartengono a queste sigma-algebre indipendenti, garantendo l’indipendenza di Y_1 e Y_2.\nApplicazione Tipica: Calcolo del Valore Atteso\nConsideriamo variabili aleatorie X_1, X_2, X_3 indipendenti con momento secondo finito, cioè E[X_i^2] &lt; \\infty per i = 1, 2, 3. Vogliamo calcolare il valore atteso di un’espressione come:\nY = (X_1^2 + \\sin(X_1 + X_2)) \\cdot e^{-|X_3|}\nDefiniamo Y_1 = X_1^2 + \\sin(X_1 + X_2) e Y_2 = e^{-|X_3|}. Notiamo che Y_1 è funzione di X_1 e X_2, mentre Y_2 è funzione solo di X_3. Poiché X_1, X_2, X_3 sono indipendenti, allora Y_1 e Y_2 sono indipendenti.\nSe E[|Y_1|] &lt; \\infty e E[|Y_2|] &lt; \\infty, allora il valore atteso del prodotto è il prodotto dei valori attesi:\nE[Y] = E[Y_1 Y_2] = E[Y_1] E[Y_2] = E[X_1^2 + \\sin(X_1 + X_2)] \\cdot E[e^{-|X_3|}]\nPer verificare che i valori attesi siano finiti:\n\n|Y_2| = |e^{-|X_3|}| = e^{-|X_3|} \\leq 1, quindi E[|Y_2|] \\leq 1 &lt; \\infty.\n|Y_1| = |X_1^2 + \\sin(X_1 + X_2)| \\leq |X_1^2| + |\\sin(X_1 + X_2)| \\leq X_1^2 + 1. Poiché E[X_1^2] &lt; \\infty, allora E[|Y_1|] \\leq E[X_1^2] + 1 &lt; \\infty.\n\nQuesta proprietà è fondamentale quando si analizzano funzioni complesse di variabili aleatorie indipendenti.\n\nCovarianza\nDefinizione\nDate due variabili aleatorie X_1 e X_2 con momento secondo finito (cioè E[X_1^2] &lt; \\infty e E[X_2^2] &lt; \\infty), la covarianza di X_1 e X_2 è definita come:\nCov(X_1, X_2) = E[(X_1 - E[X_1])(X_2 - E[X_2])]\nPerché la covarianza è importante? Consideriamo la varianza di una combinazione lineare di due variabili aleatorie:\nVar(aX_1 + bX_2) = E[(aX_1 + bX_2 - E[aX_1 + bX_2])^2] = E[(a(X_1 - E[X_1]) + b(X_2 - E[X_2]))^2] = E[a^2(X_1 - E[X_1])^2 + b^2(X_2 - E[X_2])^2 + 2ab(X_1 - E[X_1])(X_2 - E[X_2])] = a^2 E[(X_1 - E[X_1])^2] + b^2 E[(X_2 - E[X_2])^2] + 2ab E[(X_1 - E[X_1])(X_2 - E[X_2])] = a^2 Var(X_1) + b^2 Var(X_2) + 2ab Cov(X_1, X_2)\nLa covarianza emerge naturalmente quando si studia la variabilità di somme di variabili aleatorie.\n\n\n\nProprietà della Covarianza\n\n1. Covarianza di una variabile con se stessa\nProprietà: La covarianza di una variabile aleatoria con se stessa è uguale alla sua varianza.\nCov(X_1, X_1) = Var(X_1)\nCommento del professore: Nessuno vieta di considerare il vettore particolare che ha come componente sempre la stessa variabile aleatoria. In questo caso, applicando la definizione di covarianza, il prodotto (X_1 - E[X_1])(X_1 - E[X_1]) diventa (X_1 - E[X_1])^2, e il valore atteso di questo è proprio la definizione di varianza.\n2. Simmetria della Covarianza\nProprietà: La covarianza tra due variabili aleatorie è simmetrica.\nCov(X_1, X_2) = Cov(X_2, X_1)\nCommento del professore: Questa proprietà è ovvia direttamente dalla definizione di covarianza, poiché il prodotto (X_1 - E[X_1])(X_2 - E[X_2]) è commutativo. Quindi l’ordine delle variabili non influenza il risultato della covarianza. Questa proprietà implica che quando si calcola la varianza di una somma di variabili aleatorie, il termine Cov(X_i, X_j) è lo stesso di Cov(X_j, X_i), il che è importante per le formule generali.\n3. Relazione con il momento misto\nProprietà: La covarianza può essere espressa come il momento misto meno il prodotto dei momenti primi (valori attesi).\nCov(X_1, X_2) = E[X_1 X_2] - E[X_1]E[X_2]\nDimostrazione: Il professore svolge la dimostrazione nel seguente modo: Partendo dalla definizione: Cov(X_1, X_2) = E[(X_1 - E[X_1])(X_2 - E[X_2])] Si sviluppa il prodotto all’interno del valore atteso: Cov(X_1, X_2) = E[X_1 X_2 - X_1 E[X_2] - E[X_1] X_2 + E[X_1] E[X_2]] Utilizzando la linearità del valore atteso, si ottiene: Cov(X_1, X_2) = E[X_1 X_2] - E[X_1 E[X_2]] - E[E[X_1] X_2] + E[E[X_1] E[X_2]] Poiché E[X_1] e E[X_2] sono costanti, possono essere portate fuori dal valore atteso: Cov(X_1, X_2) = E[X_1 X_2] - E[X_1] E[X_2] - E[X_1] E[X_2] + E[X_1] E[X_2] Combinando gli ultimi due termini, si arriva a: Cov(X_1, X_2) = E[X_1 X_2] - E[X_1] E[X_2]\n\nCommento del professore: Questa è una dimostrazione tipica che può essere richiesta in un compito. Spesso è più comodo calcolare separatamente il momento misto E[X_1 X_2] e i momenti marginali E[X_1] e E[X_2] per poi trovare la covarianza.\n4. Effetto delle trasformazioni lineari\nProprietà: La covarianza è quadratica nei coefficienti e insensibile alle traslazioni. Per costanti a, b, c, d \\in \\mathbb{R}:\nCov(aX_1 + c, bX_2 + d) = ab Cov(X_1, X_2)\nDimostrazione: Il professore esegue la dimostrazione come segue: Partendo dalla definizione di covarianza applicata alle variabili trasformate: Cov(aX_1 + c, bX_2 + d) = E[((aX_1 + c) - E[aX_1 + c])((bX_2 + d) - E[bX_2 + d])] Si calcolano i valori attesi delle variabili trasformate: E[aX_1 + c] = aE[X_1] + c E[bX_2 + d] = bE[X_2] + d Sostituendo nella definizione: Cov(aX_1 + c, bX_2 + d) = E[(aX_1 + c - (aE[X_1] + c))(bX_2 + d - (bE[X_2] + d))] Cov(aX_1 + c, bX_2 + d) = E[(aX_1 - aE[X_1])(bX_2 - bE[X_2])] S Factorizzano le costanti a e b: Cov(aX_1 + c, bX_2 + d) = E[a(X_1 - E[X_1]) b(X_2 - E[X_2])] Cov(aX_1 + c, bX_2 + d) = E[ab(X_1 - E[X_1])(X_2 - E[X_2])] Per linearità del valore atteso, le costanti a e b possono essere portate fuori: Cov(aX_1 + c, bX_2 + d) = ab E[(X_1 - E[X_1])(X_2 - E[X_2])] = ab Cov(X_1, X_2)\n\nCommento del professore: Come per la varianza (che ha un solo coefficiente), la covarianza è insensibile alle traslazioni (l’aggiunta delle costanti c e d) e i coefficienti moltiplicativi a e b vengono portati fuori, moltiplicandosi tra loro.\n5. Covarianza di variabili indipendenti\nProprietà: Se due variabili aleatorie X_1 e X_2 sono indipendenti, allora la loro covarianza è zero.\nSe \\ X_1 \\ e \\ X_2 \\ sono \\ indipendenti, \\ allora \\ Cov(X_1, X_2) = 0\nDimostrazione: Il professore spiega la dimostrazione in questo modo: Se X_1 e X_2 sono indipendenti e hanno momento secondo finito (il che implica che abbiano anche momento primo finito, altrimenti non si potrebbe nemmeno scrivere la covarianza), allora E[X_1 X_2] = E[X_1] E[X_2]. Utilizzando la proprietà 3: Cov(X_1, X_2) = E[X_1 X_2] - E[X_1] E[X_2] = E[X_1] E[X_2] - E[X_1] E[X_2] = 0\n\nCommento del professore: Il fatto che siano indipendenti implica che il valore atteso del prodotto si fattorizza nel prodotto dei valori attesi, portando direttamente a una covarianza nulla.\nAttenzione: Il professore sottolinea che il viceversa non è sempre vero. Una covarianza nulla non implica necessariamente che le variabili aleatorie siano indipendenti. Possono esistere situazioni in cui la covarianza è zero ma le variabili sono dipendenti.\n6. Caso speciale: media nulla\nProprietà: Se una delle due variabili aleatorie ha media nulla (e la covarianza è finita), allora la covarianza è uguale al valore atteso del momento misto.\nSe \\ E[X_1] = 0 \\ (e \\ Cov(X_1, X_2) \\ è \\ finita), \\ allora \\ Cov(X_1, X_2) = E[X_1 X_2]\nSpiegazione: Se E[X_1] = 0, allora dalla proprietà 3: Cov(X_1, X_2) = E[X_1 X_2] - E[X_1] E[X_2] = E[X_1 X_2] - 0 \\cdot E[X_2] = E[X_1 X_2]\n\nCommento del professore: Questa è una proprietà semplice ma utile. Se si sa che una delle due variabili ha media zero, per calcolare la covarianza è sufficiente calcolare il valore atteso del loro prodotto, risparmiando un potenziale calcolo di un integrale.\nVarianza di una Combinazione Lineare di n Variabili Aleatorie\nGeneralizzando al caso di n variabili aleatorie X_1, \\dots, X_n e costanti a_1, \\dots, a_n, la varianza della combinazione lineare \\sum_{i=1}^n a_i X_i è data da:\nVar(\\sum_{i=1}^n a_i X_i) = \\sum_{i=1}^n \\sum_{j=1}^n a_i a_j Cov(X_i, X_j)\nQuesta formula può essere riscritta in diverse forme equivalenti:\nVar(\\sum_{i=1}^n a_i X_i) = \\sum_{i=1}^n a_i^2 Var(X_i) + \\sum_{i \\neq j} a_i a_j Cov(X_i, X_j)\nOppure:\nVar(\\sum_{i=1}^n a_i X_i) = \\sum_{j=1}^n a_j^2 Var(X_j) + 2 \\sum_{1 \\leq i &lt; j \\leq n} a_i a_j Cov(X_i, X_j)\nQueste espressioni mostrano come la variabilità di una somma di variabili aleatorie dipenda non solo dalle varianze individuali, ma anche dalle covarianze tra le coppie di variabili.\n\nCovarianza di Combinazioni Lineari\nDate due collezioni di variabili aleatorie {X_i}_{i=1}^m e {Y_j}_{j=1}^n definite sullo stesso spazio di probabilità, e costanti {a_i}_{i=1}^m e {b_j}_{j=1}^n, la covarianza delle combinazioni lineari \\sum_{i=1}^m a_i X_i e \\sum_{j=1}^n b_j Y_j è:\nCov(\\sum_{i=1}^m a_i X_i, \\sum_{j=1}^n b_j Y_j) = \\sum_{i=1}^m \\sum_{j=1}^n a_i b_j Cov(X_i, Y_j)\nQuesta proprietà, detta bilinearità della covarianza, è fondamentale per manipolare espressioni che coinvolgono combinazioni lineari di variabili aleatorie.\n\nEsempio: Cov(a_1 X_1 + a_2 X_2, b_1 Y_1 + b_2 Y_2) = a_1 b_1 Cov(X_1, Y_1) + a_1 b_2 Cov(X_1, Y_2) + a_2 b_1 Cov(X_2, Y_1) + a_2 b_2 Cov(X_2, Y_2)\nInoltre, la covarianza è insensibile alle traslazioni: Cov(X + c, Y) = Cov(X, Y) per qualsiasi costante c.\nEsempi di Calcolo di Covarianza\n\n\nCov(2X + 1, Y + 3Z) = Cov(2X, Y + 3Z) = 2 Cov(X, Y + 3Z) = 2 (Cov(X, Y) + Cov(X, 3Z)) = 2 Cov(X, Y) + 2 \\cdot 3 Cov(X, Z) = 2 Cov(X, Y) + 6 Cov(X, Z).\n\n\nCov(3X + 1, X + Y) = Cov(3X, X + Y) = 3 Cov(X, X + Y) = 3 (Cov(X, X) + Cov(X, Y)) = 3 (Var(X) + Cov(X, Y)).\n\n\nCov(c, X) = Cov(c + 0, X + 0) = 1 \\cdot 1 \\cdot Cov(\\text{costante nulla}, X) = Cov(0, X) = E[(0 - E)(X - E[X])] = E[0 \\cdot (X - E[X])] = E = 0. La covarianza tra una costante e una variabile aleatoria è sempre zero.\n\n\n\nCommento:\n\nInsensibilità alle traslazioni: La costante +1 nel primo argomento e +3z nel secondo argomento non influenzano la covarianza. Questo è dovuto alla proprietà che Cov(aX_1 + c, bX_2 + d) = ab Cov(X_1, X_2). Le costanti additive (c e d) vengono eliminate nel calcolo della covarianza perché si annullano quando si considerano le deviazioni dalla media.\nLinearità nei coefficienti: I coefficienti moltiplicativi (2 per x e potenzialmente un coefficiente implicito di 1 per y, e 3 per z) vengono estratti dalla covarianza. Cov(2x, y) = 2 Cov(x, y) e Cov(x, 3z) = 3 Cov(x, z). Quando abbiamo una combinazione lineare in entrambi gli argomenti, i coefficienti si moltiplicano, come si vede nel termine 2 \\cdot 3 \\cdot Cov(x, z).\nDistribuzione della covarianza: La covarianza si “distribuisce” sulla somma, in modo simile al valore atteso. Cov(2x + 1, y + 3z) = Cov(2x + 1, y) + Cov(2x + 1, 3z). Applicando poi l’insensibilità alle traslazioni e la linearità dei coefficienti, si arriva al risultato.\n\nEsercizio Difficile sulla Covarianza\nEsercizio: Siano X_1, X_2 e \\tilde{X}_1, \\tilde{X}_2 due vettori aleatori indipendenti con la stessa legge (stessa distribuzione congiunta). Dimostrare che:\nCov(X_1, X_2) = \\frac{1}{2} E[(X_1 - \\tilde{X}_1)(X_2 - \\tilde{X}_2)]\n\n\nSpiegazione intuitiva della Covarianza come indice di concordanza:\nLa covarianza misura come due variabili aleatorie variano insieme. Un valore positivo indica che tendono a muoversi nella stessa direzione, mentre un valore negativo indica che tendono a muoversi in direzioni opposte. Un valore vicino a zero suggerisce una relazione lineare debole o assente.\nL’esercizio proposto cerca di fornire un’ulteriore interpretazione della covarianza confrontando le realizzazioni di due coppie indipendenti con la stessa distribuzione. L’espressione E[(X_1 - \\tilde{X}_1)(X_2 - \\tilde{X}_2)] considera le differenze tra le prime componenti e le differenze tra le seconde componenti delle due coppie. Il valore atteso di questo prodotto è legato alla tendenza delle variazioni congiunte delle variabili.\nQuesto esercizio, pur non essendo direttamente utile per il compitino imminente, è prezioso per approfondire la comprensione delle proprietà delle variabili aleatorie e del concetto di covarianza.\n\nConclusione sull’Argomento Varianza, Covarianza e Correlazione\n\n\nDefinizione di Coefficiente di Correlazione Lineare\n\nDate due variabili aleatorie reali X_1 e X_2 con momento secondo finito (e quindi con varianza finita), il coefficiente di correlazione lineare, spesso indicato con r o \\rho, è definito come: \\rho = \\frac{Cov(X_1, X_2)}{\\sqrt{Var(X_1)Var(X_2)}}\nQuesta definizione è valida assumendo che le varianze siano diverse da zero.\nIl professore specifica che si tratterà solo di questo tipo di coefficiente di correlazione, sottolineando che ne esistono altri (come la \\tau di Kendall, legata a una diversa forma di dipendenza).\n\n\n\nProprietà del Coefficiente di Correlazione Lineare\n\nProposizione 1: Il coefficiente di correlazione lineare \\rho è un numero compreso tra -1 e 1, inclusi.\n\nCommento: La covarianza può assumere qualsiasi valore tra -\\infty e +\\infty. La divisione per la radice del prodotto delle varianze (che sono positive) normalizza la covarianza, restringendo l’intervallo dei valori possibili per \\rho.\n\n\nProposizione 2: I casi estremi, |\\rho| = 1 (ovvero \\rho = 1 o \\rho = -1), si verificano se e solo se esiste una relazione lineare tra X_1 e X_2 con probabilità 1. Ciò significa che esistono costanti a \\neq 0, b, c \\neq 0, e d tali che con probabilità 1 il vettore (X_1, X_2) è concentrato su una retta, la cui equazione è ax_1 + bx_2 = c. In altre parole, X_2 può essere espressa come una funzione lineare di X_1 (o viceversa), quasi certamente.\n\nSe \\rho = 1, allora X_2 = \\alpha X_1 + \\beta con \\alpha &gt; 0 quasi certamente.\nSe \\rho = -1, allora X_2 = \\alpha X_1 + \\beta con \\alpha &lt; 0 quasi certamente.\nCommento: Un valore di \\rho vicino a 1 o -1 suggerisce una forte tendenza alla dipendenza lineare, ma solo i valori estremi indicano una dipendenza lineare esatta con probabilità 1. È possibile avere dipendenza completa (dove una variabile è funzione deterministica dell’altra) senza che \\rho sia uguale a 1 o -1 se la relazione non è lineare.\n\n\n\n\n\n\nDimostrazione delle Proprietà della Correlazione Lineare\n\n\nConsideriamo la varianza della variabile aleatoria trasformata \\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2}: Var\\left(\\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2}\\right) \\geq 0 Questo è vero perché la varianza di qualsiasi variabile aleatoria reale è sempre non negativa.\n\n\nApplichiamo la proprietà della varianza della somma di due variabili aleatorie: Var(A + B) = Var(A) + Var(B) + 2 Cov(A, B). Nel nostro caso, A = \\frac{X_1}{\\sigma_1} e B = \\frac{X_2}{\\sigma_2}: Var\\left(\\frac{X_1}{\\sigma_1}\\right) + Var\\left(\\frac{X_2}{\\sigma_2}\\right) + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0\n\n\nUtilizziamo la proprietà della varianza di una variabile moltiplicata per una costante: Var(aX) = a^2 Var(X): \\frac{1}{\\sigma_1^2} Var(X_1) + \\frac{1}{\\sigma_2^2} Var(X_2) + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0\n\n\nSappiamo che Var(X_1) = \\sigma_1^2 e Var(X_2) = \\sigma_2^2, quindi: \\frac{\\sigma_1^2}{\\sigma_1^2} + \\frac{\\sigma_2^2}{\\sigma_2^2} + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0 1 + 1 + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0 2 + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, \\frac{X_2}{\\sigma_2}\\right) \\geq 0\n\n\nApplichiamo la proprietà della covarianza con costanti: Cov(aX, bY) = ab Cov(X, Y): 2 + 2 \\cdot \\frac{1}{\\sigma_1} \\cdot \\frac{1}{\\sigma_2} Cov(X_1, X_2) \\geq 0 2 + 2 \\frac{Cov(X_1, X_2)}{\\sigma_1 \\sigma_2} \\geq 0\n\n\nRiconosciamo nella frazione la definizione del coefficiente di correlazione \\rho: 2 + 2 \\rho \\geq 0 2 \\rho \\geq -2 \\rho \\geq -1\n\n\nOra consideriamo la varianza della variabile aleatoria trasformata \\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}: Var\\left(\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}\\right) \\geq 0\n\n\nApplichiamo la proprietà della varianza della somma (o differenza): Var(A - B) = Var(A) + Var(B) - 2 Cov(A, B): Var\\left(\\frac{X_1}{\\sigma_1}\\right) + Var\\left(-\\frac{X_2}{\\sigma_2}\\right) - 2 Cov\\left(\\frac{X_1}{\\sigma_1}, -\\frac{X_2}{\\sigma_2}\\right) \\geq 0\n\n\nUtilizzando le proprietà Var(aX) = a^2 Var(X) e Cov(aX, bY) = ab Cov(X, Y): \\frac{1}{\\sigma_1^2} Var(X_1) + \\left(-\\frac{1}{\\sigma_2}\\right)^2 Var(X_2) - 2 \\cdot \\frac{1}{\\sigma_1} \\cdot \\left(-\\frac{1}{\\sigma_2}\\right) Cov(X_1, X_2) \\geq 0 \\frac{\\sigma_1^2}{\\sigma_1^2} + \\frac{\\sigma_2^2}{\\sigma_2^2} + 2 \\frac{Cov(X_1, X_2)}{\\sigma_1 \\sigma_2} \\geq 0 1 + 1 + 2 \\rho \\geq 0\n\n\nAttenzione, c’è un errore nel passaggio riportato nella fonte. La covarianza di \\frac{X_1}{\\sigma_1} e -\\frac{X_2}{\\sigma_2} è -\\frac{1}{\\sigma_1 \\sigma_2} Cov(X_1, X_2) = -\\rho. Quindi la disuguaglianza corretta è: 1 + 1 - 2 (-\\rho) \\geq 0 2 + 2 \\rho \\geq 0, che ci riporta a \\rho \\geq -1.\nRipartiamo dal passo 8 con maggiore attenzione al segno: Var\\left(\\frac{X_1}{\\sigma_1}\\right) + Var\\left(-\\frac{X_2}{\\sigma_2}\\right) - 2 Cov\\left(\\frac{X_1}{\\sigma_1}, -\\frac{X_2}{\\sigma_2}\\right) \\geq 0 \\frac{1}{\\sigma_1^2} Var(X_1) + \\frac{1}{\\sigma_2^2} Var(X_2) - 2 \\left(-\\frac{1}{\\sigma_1 \\sigma_2}\\right) Cov(X_1, X_2) \\geq 0 1 + 1 + 2 \\frac{Cov(X_1, X_2)}{\\sigma_1 \\sigma_2} \\geq 0 2 + 2 \\rho \\geq 0 \\implies \\rho \\geq -1.\nOra rifacciamo il caso con il segno meno: Var\\left(\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}\\right) = Var\\left(\\frac{X_1}{\\sigma_1}\\right) + Var\\left(-\\frac{X_2}{\\sigma_2}\\right) + 2 Cov\\left(\\frac{X_1}{\\sigma_1}, -\\frac{X_2}{\\sigma_2}\\right) \\geq 0 1 + 1 + 2 \\left(-\\frac{1}{\\sigma_1 \\sigma_2}\\right) Cov(X_1, X_2) \\geq 0 2 - 2 \\rho \\geq 0 2 \\geq 2 \\rho 1 \\geq \\rho \\implies \\rho \\leq 1\n\nQuindi, combinando i risultati, otteniamo -1 \\leq \\rho \\leq 1.\n\n\n\n\nProprietà 2: |\\rho| = 1 se e solo se esiste una relazione lineare tra X_1 e X_2 con probabilità 1\nDimostrazione:\n\n\nCaso \\rho = 1: Dalla dimostrazione precedente, abbiamo visto che Var\\left(\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}\\right) = 2 - 2\\rho. Se \\rho = 1, allora Var\\left(\\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2}\\right) = 2 - 2(1) = 0. Se la varianza di una variabile aleatoria è zero, significa che la variabile è costante con probabilità 1. Quindi, esiste una costante c tale che: \\frac{X_1}{\\sigma_1} - \\frac{X_2}{\\sigma_2} = c con probabilità 1. X_1 = \\frac{\\sigma_1}{\\sigma_2} X_2 + c \\sigma_1 con probabilità 1. Questa è una relazione lineare della forma X_1 = \\alpha X_2 + \\beta dove \\alpha = \\frac{\\sigma_1}{\\sigma_2} &gt; 0 e \\beta = c \\sigma_1. Il segno positivo di \\alpha corrisponde a una correlazione positiva.\n\n\nCaso \\rho = -1: Dalla dimostrazione precedente, abbiamo visto che Var\\left(\\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2}\\right) = 2 + 2\\rho. Se \\rho = -1, allora Var\\left(\\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2}\\right) = 2 + 2(-1) = 0. Analogamente, esiste una costante c&#039; tale che: \\frac{X_1}{\\sigma_1} + \\frac{X_2}{\\sigma_2} = c&#039; con probabilità 1. X_1 = -\\frac{\\sigma_1}{\\sigma_2} X_2 + c&#039; \\sigma_1 con probabilità 1. Questa è una relazione lineare della forma X_1 = \\alpha X_2 + \\beta dove \\alpha = -\\frac{\\sigma_1}{\\sigma_2} &lt; 0 e \\beta = c&#039; \\sigma_1. Il segno negativo di \\alpha corrisponde a una correlazione negativa.\n\n\n\nViceversa: Se esiste una relazione lineare X_2 = \\alpha X_1 + \\beta con \\alpha \\neq 0 (condizione a \\neq 0 nella fonte), allora possiamo calcolare la covarianza e le varianze: Cov(X_1, X_2) = Cov(X_1, \\alpha X_1 + \\beta) = \\alpha Cov(X_1, X_1) = \\alpha Var(X_1) = \\alpha \\sigma_1^2. Var(X_2) = Var(\\alpha X_1 + \\beta) = \\alpha^2 Var(X_1) = \\alpha^2 \\sigma_1^2, quindi \\sigma_2 = |\\alpha| \\sigma_1. Sostituendo nella definizione di \\rho: \\rho = \\frac{\\alpha \\sigma_1^2}{\\sigma_1 |\\alpha| \\sigma_1} = \\frac{\\alpha}{|\\alpha|} = \\begin{cases} 1 &amp; \\text{se } \\alpha &gt; 0 \\ -1 &amp; \\text{se } \\alpha &lt; 0 \\end{cases} Quindi |\\rho| = 1. Lo stesso ragionamento si applica se X_1 è una funzione lineare di X_2.\n\n\n\nCommento:\nLa dimostrazione si basa sull’importante proprietà che la varianza di una variabile aleatoria è zero se e solo se la variabile è costante con probabilità 1. Normalizzando le variabili X_1 e X_2 per le loro deviazioni standard, si ottengono variabili con varianza unitaria. La varianza della somma o della differenza di queste variabili normalizzate è poi legata al coefficiente di correlazione. I casi estremi \\rho = 1 e \\rho = -1 si verificano quando la combinazione lineare delle variabili normalizzate ha varianza zero, il che implica una relazione lineare deterministica tra le variabili originali. Il segno di \\rho indica la direzione di questa relazione lineare.\nÈ importante notare che il coefficiente di correlazione lineare misura solo la dipendenza lineare tra le variabili. Se le variabili sono dipendenti ma la loro relazione non è lineare, il coefficiente di correlazione lineare potrebbe essere vicino a zero.\nOsservazione Importante sulla Varianza della Somma di Variabili Aleatorie Indipendenti\n\nSe X_1, X_2, ..., X_n sono variabili aleatorie indipendenti con varianza finita, allora la varianza della loro somma è uguale alla somma delle loro varianze: Var\\left(\\sum_{i=1}^{n} X_i\\right) = \\sum_{i=1}^{n} Var(X_i)\n\nGiustificazione: La varianza della somma è data da: Var\\left(\\sum_{i=1}^{n} X_i\\right) = \\sum_{i=1}^{n} Var(X_i) + \\sum_{i \\neq j} Cov(X_i, X_j) Se le variabili sono indipendenti, la loro covarianza è zero (Cov(X_i, X_j) = 0 per i \\neq j). Pertanto, il secondo termine della somma si annulla, lasciando solo la somma delle varianze.\n\nAttenzione: Questa proprietà vale solo sotto l’ipotesi di indipendenza (o più generalmente, se le variabili hanno correlazione nulla).\n\n\n\nEsempio: Varianza di una Variabile Aleatoria Binomiale\n\nSia X \\sim Bin(n, p) una variabile aleatoria binomiale con parametri n (numero di prove) e p (probabilità di successo).\nUna variabile binomiale può essere vista come la somma di n variabili aleatorie di Bernoulli indipendenti e identicamente distribuite I_i \\sim Bern(p) per i = 1, ..., n: X = \\sum_{i=1}^{n} I_i\nCalcolo del valore atteso (ripasso): E[X] = E\\left[\\sum_{i=1}^{n} I_i\\right] = \\sum_{i=1}^{n} E[I_i] Il valore atteso di una variabile di Bernoulli è E[I_i] = 0 \\cdot (1-p) + 1 \\cdot p = p. Quindi, E[X] = \\sum_{i=1}^{n} p = np.\nCalcolo della varianza: Poiché le variabili di Bernoulli sono indipendenti, possiamo applicare la proprietà della varianza della somma: Var(X) = Var\\left(\\sum_{i=1}^{n} I_i\\right) = \\sum_{i=1}^{n} Var(I_i) La varianza di una variabile di Bernoulli è: Var(I_i) = E[I_i^2] - (E[I_i])^2 Poiché per una Bernoulli I_i^2 = I_i (0²=0, 1²=1), si ha E[I_i^2] = E[I_i] = p. Quindi, Var(I_i) = p - p^2 = p(1 - p). Pertanto, la varianza della binomiale è: Var(X) = \\sum_{i=1}^{n} p(1 - p) = n p(1 - p)\n\n\nCommento: Questo esempio mostra come l’utilizzo della proprietà della va rianza della somma per variabili indipendenti semplifica il calcolo della varianza di una binomiale rispetto all’applicazione diretta della definizione alla sua densità discreta.\n\n\n\nTrasformazioni di Variabili Aleatorie\n\n\nProblema generale: Data una variabile aleatoria X con una certa legge, si vuole studiare la legge di una nuova variabile aleatoria Y = g(X), dove g è una funzione.\n\n\nCaso discreto: Se X è una variabile aleatoria discreta, allora anche Y = g(X) sarà discreta. La probabilità che Y assuma un valore y è data dalla somma delle probabilità di tutti i valori x nel dominio di X tali che g(x) = y: P(Y = y) = P(g(X) = y) = \\sum_{x: g(x) = y} P(X = x) = \\sum_{x: g(x) = y} f_X(x) dove f_X(x) è la densità discreta di X.\n\n\n\nCaso continuo: Se X è una variabile aleatoria assolutamente continua, la situazione per Y = g(X) è più complessa. In generale, Y potrebbe essere continua, discreta o mista (come visto in un esercizio del compito, ad esempio per il massimo di variabili aleatorie).\n\nEsempio menzionato: X^2, se X è assolutamente continua, è anch’essa assolutamente continua.\nIn generale, non si possono dare condizioni semplici su g per determinare la natura di Y‘s. Si analizza caso per caso.\nLa legge immagine di Y, caratterizzata dalla sua funzione di ripartizione o dalle probabilità di eventi, è data da: P(Y \\in A) = P(g(X) \\in A) = P(X \\in g^{-1}(A)) dove g^{-1}(A) = {x: g(x) \\in A} è la controimmagine dell’insieme A sotto la funzione g. Se X è assolutamente continua con densità f_X(x), allora: P(Y \\in A) = \\int_{g^{-1}(A)} f_X(x) dx = \\int_{\\set{x: g(x) \\in A}} f_X(x) dx Questo integrale, a seconda della funzione g e dell’insieme A, può essere più o meno facile da calcolare. Per calcolare la funzione di ripartizione di Y, si prende A = (-\\infty, y].\nEstensione a variabili vettoriali: Questi concetti si estendono al caso in cui X è un vettore aleatorio in \\mathbb{R}^d e g: \\mathbb{R}^d \\rightarrow \\mathbb{R}^k. L’unica differenza è che l’integrale è ora su un sottoinsieme di \\mathbb{R}^d.\n\n\n\n\nSomma di Variabili Aleatorie\n\n\nLa somma di variabili aleatorie è un caso particolare di trasformazione di variabili aleatorie, molto frequente in probabilità e statistica.\n\n\nSi considera il caso in cui X = (X_1, ..., X_d) è un vettore aleatorio e g(X) = \\sum_{i=1}^{d} X_i è la somma delle sue componenti.\n\n\nCaso discreto (d=2): Siano X_1 e X_2 due variabili aleatorie discrete e Y = X_1 + X_2. La densità discreta di Y in un punto y è data da: P(Y = y) = \\sum_{(x_1, x_2): x_1 + x_2 = y} P(X_1 = x_1, X_2 = x_2) Questa somma doppia può essere riscritta come una somma singola, fissando x_1 e determinando x_2 = y - x_1: P(Y = y) = \\sum_{x_1} P(X_1 = x_1, X_2 = y - x_1)\n\n\nCaso di variabili indipendenti: Se X_1 e X_2 sono indipendenti, allora P(X_1 = x_1, X_2 = x_2) = P(X_1 = x_1) P(X_2 = x_2). In questo caso, la densità discreta della somma diventa: P(Y = y) = \\sum_{x_1} P(X_1 = x_1) P(X_2 = y - x_1) Questa operazione è nota come convoluzione discreta delle densità di probabilità di X_1 e X_2.\n\n\n\nEsercizio proposto: Considerare due variabili aleatorie di Poisson X_1 \\sim Poisson(\\lambda_1) e X_2 \\sim Poisson(\\lambda_2), indipendenti. Determinare la legge di densità della loro somma Y = X_1 + X_2.\n\nCommento: Per risolvere questo esercizio, si applicherebbe la formula della convoluzione discreta, tenendo conto dei possibili valori che X_1 e X_2 possono assumere (interi non negativi) e dei valori che Y può assumere. La somma sarebbe effettuata sugli x_1 \\geq 0 tali che y - x_1 \\geq 0.\n\n\n\n\nTrasformazioni di Variabili Aleatorie\nCaso Discreto: La Somma di Variabili Aleatorie Discrete\n\nConsideriamo due variabili aleatorie discrete, x_1 e x_2.\nLa probabilità che la loro somma y = x_1 + x_2 assuma un certo valore y è data dalla somma delle probabilità congiunte di tutte le coppie (x_1, x_2) tali che x_1 + x_2 = y.\nMatematicamente, questo si esprime come: P(y = x_1 + x_2) = \\sum_{x_1} P(x_1, y - x_1)\nLa sommatoria è intesa per tutte le x_1 nel supporto di x_1 tali che y - x_1 sia nel supporto di x_2. Se y - x_1 non appartiene al supporto di x_2, quel termine semplicemente non compare nella somma.\nEsempio: Il professore suggerisce di considerare il caso della distribuzione di Poisson per farsi un’idea.\n\nCaso Continuo: La Somma di Variabili Aleatorie Assolutamente Continue\n\nConsideriamo due variabili aleatorie assolutamente continue, x_1 e x_2, con densità congiunta f_X(x_1, x_2).\nLa variabile aleatoria y = x_1 + x_2 è anch’essa assolutamente continua.\nLa densità di probabilità di y, f_y(y), può essere ottenuta calcolando prima la funzione di ripartizione F_y(y) = P(x_1 + x_2 \\le y) e poi derivandola rispetto a y.\nLa densità f_y(y) ha la seguente struttura nel caso di due variabili: f_y(y) = \\int_{-\\infty}^{+\\infty} f(x_1, y - x_1) dx_1\nOsservazione: Questa è l’analogo continuo della somma che si ha nel caso discreto.\nEsercizio (suggerito): Il professore suggerisce di provare a dimostrare questa formula come esercizio, mostrando come la funzione di ripartizione si può scrivere come un integrale e come si arriva a questa espressione per la densità.\nCaso di Indipendenza: Se x_1 e x_2 sono indipendenti, la loro densità congiunta si fattorizza f(x_1, x_2) = f_{x_1}(x_1) f_{x_2}(x_2), e la densità della somma diventa la convoluzione delle densità marginali: f_y(y) = \\int_{-\\infty}^{+\\infty} f_{x_1}(x_1) f_{x_2}(y - x_1) dx_1 = (f_{x_1} * f_{x_2})(y) A volte la convoluzione è indicata con l’asterisco.\nOsservazione: L’integrazione non è sempre su tutto \\mathbb{R}. Ad esempio, se si considerano due variabili aleatorie esponenziali negative, la densità può essere zero per certi valori.\nComplicazione per più variabili: Per la somma di tre variabili aleatorie, si otterrebbe un integrale doppio, per quattro un integrale triplo, e così via, rendendo i calcoli spesso complessi.\n\n\nMatrice di Varianze e Covarianze\n\nDefinizione\n\nConsideriamo un vettore di variabili aleatorie Y = \\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_d \\end{pmatrix}.\nValore Atteso di un Vettore/Matrice: Il valore atteso di un vettore o di una matrice di variabili aleatorie è definito componente per componente. Il valore atteso di un vettore Y è il vettore delle medie dei suoi componenti: E[Y] = E \\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_D \\end{pmatrix} = \\begin{pmatrix} E[Y_1] \\\\ E[Y_2] \\\\ \\vdots \\\\ E[Y_D] \\end{pmatrix} Questo è ben definito se il valore atteso di ogni componente è finito.\nLinearità del Valore Atteso (con Matrici Deterministiche): Se A, B, C sono matrici deterministiche compatibili e Y è un vettore/matrice aleatorio, allora E[A Y B + C] = A E[Y] B + C, mantenendo l’ordine delle moltiplicazioni perché le matrici non commutano.\n\n2.2 Definizione della Matrice di Varianze e Covarianze Per un vettore aleatorio Y a valori in \\mathbb{R}^D, la matrice di varianze e covarianze (a volte indicata come matrice di covarianza o matrice di varianza) è una matrice D \\times D dove l’elemento alla posizione (i, j) è la covarianza tra Y_i e Y_j. \\text{Cov}(Y)_{ij} = \\text{Cov}(Y_i, Y_j) = E[(Y_i - E[Y_i])(Y_j - E[Y_j])] Sulla diagonale principale di questa matrice si trovano le varianze delle singole componenti, poiché \\text{Cov}(Y_i, Y_i) = \\text{Var}(Y_i).\n\n2.3 Proprietà della Matrice di Varianze e Covarianze Si assume che tutte le componenti di Y abbiano varianza finita, altrimenti non si potrebbe definire la matrice.\n2.3.1 Osservazione 1: La matrice di varianze e covarianze può essere scritta in forma compatta usando il valore atteso di un prodotto esterno: \\text{Cov}(Y) = E[(Y - E[Y])(Y - E[Y])^T] Questo perché la componente (i, j) della matrice (Y - E[Y])(Y - E[Y])^T è (Y_i - E[Y_i])(Y_j - E[Y_j]), e il valore atteso di questa quantità è per definizione la covarianza \\text{Cov}(Y_i, Y_j).\n\n2.3.2 Proprietà di Traslazione: Se B è un vettore deterministico, aggiungere B al vettore aleatorio Y non cambia la sua matrice di varianze e covarianze: \\text{Cov}(Y + B) = \\text{Cov}(Y) Questo deriva dalla definizione: (Y+B) - E[Y+B] = Y+B - (E[Y] + B) = Y - E[Y], quindi la formula E[(Y - E[Y])(Y - E[Y])^T] rimane invariata.\n2.3.3 Proprietà Fondamentali (Proposizione) Per un vettore aleatorio Y in \\mathbb{R}^D con varianze finite:\n\nSimmetria e Semidefinita Positività: La matrice \\text{Cov}(Y) è simmetrica e semidefinita positiva. Si usa la notazione \\text{Cov}(Y) \\ge 0 per indicare la semidefinita positività. La simmetria è dovuta alla simmetria della covarianza: \\text{Cov}(Y_i, Y_j) = \\text{Cov}(Y_j, Y_i).\nTrasformazione Lineare: Se A è una matrice deterministica M \\times D e B è un vettore deterministico in \\mathbb{R}^M, allora la matrice di varianze e covarianze del vettore aleatorio AY + B (che sta in \\mathbb{R}^M) è data da: \\text{Cov}(AY + B) = A \\text{Cov}(Y) A^T\n\n2.3.4 Dimostrazione della Proprietà 2 (Trasformazione Lineare) (Dimostrazione)\n\n\nPassaggio 1: Usando la proprietà di traslazione (Osservazione 1): \\text{Cov}(AY + B) = \\text{Cov}(AY)\nPassaggio 2: Usando la definizione \\text{Cov}(Z) = E[(Z - E[Z])(Z - E[Z])^T] con Z = AY: \\text{Cov}(AY) = E[(AY - E[AY])(AY - E[AY])^T]\nPassaggio 3: Usando la linearità del valore atteso E[AY] = AE[Y] e la proprietà del trasposto (MN)^T = N^T M^T: E[(AY - AE[Y])(AY - AE[Y])^T] = E[A(Y - E[Y]) (A(Y - E[Y]))^T] = E[A(Y - E[Y]) (Y - E[Y])^T A^T]\n\nPassaggio 4: Usando la linearità del valore atteso per estrarre le matrici deterministiche A e A^T: A E[(Y - E[Y])(Y - E[Y])^T] A^T\nRisultato: Riconoscendo che E[(Y - E[Y])(Y - E[Y])^T] è per definizione \\text{Cov}(Y): \\text{Cov}(AY + B) = A \\text{Cov}(Y) A^T Questo conclude la dimostrazione della Proprietà 2.\n\n2.3.5 Dimostrazione della Proprietà 1 (Semidefinita Positiva) (Dimostrazione)\n\nPassaggio 1: Ricordare la definizione di matrice semidefinita positiva S: x^T S x \\ge 0 per ogni vettore x. Vogliamo dimostrare che x^T \\text{Cov}(Y) x \\ge 0 per ogni x \\in \\mathbb{R}^D.\nPassaggio 2: Si consideri un vettore deterministico x \\in \\mathbb{R}^D e si definisca una matrice A = x^T. Questa è una matrice 1 \\times D.\nPassaggio 3: Si consideri la variabile aleatoria scalare Z = A Y = x^T Y. Questa è una combinazione lineare delle componenti di Y, Z = \\sum_{i=1}^D x_i Y_i.\nPassaggio 4: Si applichi la Proprietà 2 (dimostrata al punto 2.3.4) al vettore aleatorio AY con A=x^T. Il risultato è una matrice 1 \\times 1 (uno scalare): \\text{Cov}(x^T Y) = x^T \\text{Cov}(Y) (x^T)^T = x^T \\text{Cov}(Y) x\nPassaggio 5: Riconoscere che \\text{Cov}(x^T Y) è semplicemente la varianza della variabile aleatoria scalare Z = x^T Y: \\text{Cov}(x^T Y) = \\text{Var}(x^T Y)\nPassaggio 6: La varianza di qualunque variabile aleatoria scalare (se esiste finita) è sempre non negativa: \\text{Var}(x^T Y) \\ge 0\nRisultato: Combinando i passaggi 4, 5 e 6: x^T \\text{Cov}(Y) x = \\text{Var}(x^T Y) \\ge 0 Questo vale per ogni vettore x \\in \\mathbb{R}^D, dimostrando che \\text{Cov}(Y) è una matrice semidefinita positiva. La simmetria è già stata osservata.\n\nDefinizione: Una matrice S è semidefinita positiva (S \\ge 0) se x^T S x \\ge 0 per ogni vettore x. È definita positiva (S &gt; 0) se x^T S x &gt; 0 per ogni x \\ne 0. Per le matrici simmetriche, questo equivale ad avere tutti gli autovalori reali non negativi (semidefinita positiva) o strettamente positivi (definita positiva).\n\n3. Funzioni Caratteristiche\nLe funzioni caratteristiche sono un altro strumento per caratterizzare la legge di una variabile aleatoria o di un vettore.\n3.1 Introduzione e Motivazione Abbiamo già visto diversi oggetti (funzione di ripartizione, densità, densità discreta) che caratterizzano la legge di una variabile aleatoria. Tuttavia, come suggerito dall’esempio della somma, calcolare la densità della somma può essere computazionalmente oneroso (grandi integrali/somme di convoluzione). Avere più strumenti equivalenti per caratterizzare le distribuzioni e semplificare i calcoli è utile. Le funzioni caratteristiche sono uno di questi strumenti.\n3.2 Definizione per Variabile Aleatoria Reale Per definire le funzioni caratteristiche, si usa l’esponenziale complesso. È utile ricordare che per un numero reale x, e^{ix} = \\cos(x) + i \\sin(x).\nDefinizione: Data una variabile aleatoria reale X, la sua funzione caratteristica \\phi_X(t) è definita per ogni t \\in \\mathbb{R} come il valore atteso dell’esponenziale complesso e^{itX}: \\phi_X(t) = E[e^{itX}] e^{itX} è una variabile aleatoria a valori complessi, che si può scrivere come \\cos(tX) + i \\sin(tX). Il valore atteso di una variabile aleatoria complessa si definisce come il valore atteso della parte reale più i volte il valore atteso della parte immaginaria: E[e^{itX}] = E[\\cos(tX) + i \\sin(tX)] = E[\\cos(tX)] + i E[\\sin(tX)] La funzione caratteristica \\phi_X(t) è sempre ben definita per ogni t \\in \\mathbb{R}. Questo perché le funzioni coseno e seno sono limitate (il modulo di e^{itX} è | \\cos(tX) + i \\sin(tX) | = \\sqrt{\\cos^2(tX) + \\sin^2(tX)} = 1). Pertanto, \\cos(tX) e \\sin(tX) sono variabili aleatorie limitate, e il loro valore atteso esiste sempre ed è finito. La funzione caratteristica è una funzione da \\mathbb{R} a \\mathbb{C}.\n\n3.3 Definizione per Vettore Aleatorio La definizione si estende ai vettori aleatori.\nDefinizione: Dato un vettore aleatorio X a valori in \\mathbb{R}^D, la sua funzione caratteristica \\phi_X(t) è definita per ogni vettore t \\in \\mathbb{R}^D come il valore atteso dell’esponenziale complesso e^{i t \\cdot X}, dove t \\cdot X è il prodotto scalare tra t e X: \\phi_X(t) = E[e^{i t \\cdot X}] Il prodotto scalare t \\cdot X è \\sum_{j=1}^D T_j X_j. Quindi e^{i t \\cdot X} è e^{i \\sum T_j X_j}, che è l’esponenziale di uno scalare, e la definizione è l’analoga multidimensionale del caso unidimensionale. La funzione caratteristica di un vettore è una funzione da \\mathbb{R}^D a \\mathbb{C}. È anch’essa sempre ben definita.\n\n3.4 Calcolo (Somme/Integrali) Calcolare la funzione caratteristica richiede il calcolo di un valore atteso.\n\nSe X è una variabile aleatoria discreta con densità (PMF) P(x), la funzione caratteristica è una somma: \\phi_X(t) = \\sum_x e^{itx} P(x) La somma è su tutti i valori x nel dominio di X.\nSe X è una variabile aleatoria assolutamente continua con densità (PDF) f(x), la funzione caratteristica è un integrale su \\mathbb{R}: \\phi_X(t) = \\int_{-\\infty}^{\\infty} e^{itx} f(x) dx\nSe X è un vettore aleatorio assolutamente continuo in \\mathbb{R}^D con densità f(x), la funzione caratteristica è un integrale su \\mathbb{R}^D: \\phi_X(t) = \\int_{\\mathbb{R}^D} e^{i t \\cdot x} f(x) dx = \\int_{\\mathbb{R}^D} e^{i \\sum_{j=1}^D T_j X_j} f(x_1, \\dots, x_D) dx_1 \\dots dx_D A seconda dei casi, calcolare questi integrali o somme può essere più o meno semplice.\n\n3.5 Teorema di Unicità (Teorema Fondamentale) Questo teorema è fondamentale per l’utilità delle funzioni caratteristiche.\n\nTeorema di Unicità: Due vettori aleatori X_1 e X_2 a valori in \\mathbb{R}^D hanno la stessa legge immagine (cioè, la stessa distribuzione di probabilità) se e solo se le loro funzioni caratteristiche sono uguali per ogni vettore t \\in \\mathbb{R}^D: X_1 \\sim X_2 \\iff \\phi_{X_1}(t) = \\phi_{X_2}(t) \\quad \\forall t \\in \\mathbb{R}^D\n\nCiò significa che la funzione caratteristica caratterizza univocamente la distribuzione di probabilità. Se si riesce a dimostrare che due variabili o vettori aleatori hanno la stessa funzione caratteristica, si può concludere che hanno la stessa legge, anche se non si conosce esplicitamente la densità o la PMF. Un esempio d’uso è dimostrare che una variabile binomiale è una somma di variabili di Bernoulli calcolando e confrontando le loro funzioni caratteristiche.\n3.6 Esempi di Calcolo (Esercizi) Vengono mostrati esempi di calcolo della funzione caratteristica per distribuzioni discrete.\nEsempio 1: Variabile di Bernoulli(p) Sia X \\sim \\text{Bernoulli}(p). La variabile assume valore 1 con probabilità p e 0 con probabilità 1-p.\n\n\nPassaggio 1: Applicare la definizione di funzione caratteristica \\phi_X(t) = E[e^{itX}].\n\n\nPassaggio 2: Calcolare il valore atteso usando la definizione per variabili discrete (somma sui valori possibili): E[e^{itX}] = e^{it \\cdot 1} P(X=1) + e^{it \\cdot 0} P(X=0)\n\n\nPassaggio 3: Sostituire le probabilità e semplificare: = e^{it} \\cdot p + e^0 \\cdot (1-p) = p e^{it} + 1 \\cdot (1-p) = p e^{it} + 1 - p\n\n\nRisultato: La funzione caratteristica di una Bernoulli(p) è: \\phi_X(t) = 1 - p + p e^{it}\n\nEsempio 2: Variabile di Poisson(\\lambda) Sia X \\sim \\text{Poisson}(\\lambda). La variabile assume valori k \\in {0, 1, 2, \\dots } con probabilità P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}.\n\n\nPassaggio 1: Applicare la definizione di funzione caratteristica \\phi_X(t) = E[e^{itX}].\n\n\nPassaggio 2: Calcolare il valore atteso usando la definizione per variabili discrete (somma sui valori possibili k): E[e^{itX}] = \\sum_{k=0}^\\infty e^{itk} P(X=k)\n\n\nPassaggio 3: Sostituire la PMF della Poisson: = \\sum_{k=0}^\\infty e^{itk} \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\n\nPassaggio 4: Estrarre il termine e^{-\\lambda} dalla somma: = e^{-\\lambda} \\sum_{k=0}^\\infty e^{itk} \\frac{\\lambda^k}{k!}\n\n\nPassaggio 5: Riscrivere il termine generale della somma come \\frac{(e^{it} \\lambda)^k}{k!}: = e^{-\\lambda} \\sum_{k=0}^\\infty \\frac{(e^{it} \\lambda)^k}{k!}\n\n\nPassaggio 6: Riconoscere la serie di Taylor dell’esponenziale per argomento complesso z = e^{it} \\lambda. La serie \\sum_{k=0}^\\infty \\frac{z^k}{k!} converge a e^z anche per z \\in \\mathbb{C}. = e^{-\\lambda} e^{e^{it} \\lambda}\n\n\nPassaggio 7: Semplificare l’espressione: = e^{\\lambda e^{it}} e^{-\\lambda} = e^{\\lambda e^{it} - \\lambda} = e^{\\lambda(e^{it} - 1)}\n\n\nRisultato: La funzione caratteristica di una Poisson(\\lambda) è: \\phi_X(t) = e^{\\lambda(e^{it} - 1)} Questo risultato è importante perché, grazie al teorema di unicità, se una variabile aleatoria ha questa funzione caratteristica, allora la sua legge deve essere di Poisson con parametro \\lambda.\n\n\n\nReferences"},"6--full-note/prob-lez18":{"slug":"6--full-note/prob-lez18","filePath":"6- full note/prob-lez18.md","title":"prob-lez18","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/probabilità","3--tag/sbobine","2--source-materials/Appunti-Prob---18.pdf"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-23 16:09\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: probabilità  sbobine\nprob-lez18\nAppunti sulla Funzione Caratteristica\nDefinizione (implicita nel testo) La funzione caratteristica di un vettore aleatorio x (calcolata in un vettore t) è definita come il valore atteso di e^{i t^T x}.\nProprietà Importanti della Funzione Caratteristica\nVengono presentate e dimostrate tre proprietà fondamentali della funzione caratteristica.\nProposizione 1: Valore nell’Origine La prima proprietà importante è che la funzione caratteristica del vettore x calcolata nel vettore nullo (t=0) è uguale a 1. In simboli: \\phi_x(\\mathbf{0}) = 1\n\nDimostrazione della Proposizione 1 Calcolando la funzione caratteristica nel punto \\mathbf{0}, si ha: \\phi_x(\\mathbf{0}) = E[e^{i \\mathbf{0}^T x}] Il prodotto scalare \\mathbf{0}^T x è uguale a 0. Quindi l’espressione diventa: E[e^{i \\cdot 0}] = E[e^0] e^0 = 1, quindi il valore atteso è: E = 1 Questa proprietà è considerata ovvia data la definizione.\n\nProposizione 2: Continuità Uniforme La seconda proprietà importante afferma che la funzione caratteristica, che mappa t a \\phi_x(t), è uniformemente continua su tutto \\mathbb{R}^D, dove D è la dimensione del vettore x.\n\nDimostrazione della Proposizione 2 Per dimostrare la continuità (e poi l’uniforme continuità), si considera la differenza tra la funzione caratteristica valutata in due punti vicini, t+h e t, dove t e h sono vettori. Si vuole analizzare \\phi_x(t+h) - \\phi_x(t). Per definizione: \\phi_x(t+h) = E[e^{i (t+h)^T x}] \\phi_x(t) = E[e^{i t^T x}] La differenza è: \\phi_x(t+h) - \\phi_x(t) = E[e^{i (t+h)^T x}] - E[e^{i t^T x}] Usando la linearità del valore atteso: \\phi_x(t+h) - \\phi_x(t) = E[e^{i (t+h)^T x} - e^{i t^T x}] Espandendo l’esponente: (t+h)^T x = t^T x + h^T x Quindi: e^{i (t^T x + h^T x)} - e^{i t^T x} = e^{i t^T x} e^{i h^T x} - e^{i t^T x} Si può raccogliere il termine comune e^{i t^T x}: e^{i t^T x} (e^{i h^T x} - 1) Quindi la differenza diventa: \\phi_x(t+h) - \\phi_x(t) = E[e^{i t^T x} (e^{i h^T x} - 1)] Si applica la disuguaglianza del modulo per il valore atteso, |!|E[Y]|!| \\le E[|!|Y|!|]: |!|\\phi_x(t+h) - \\phi_x(t)|!| \\le E[|!|e^{i t^T x} (e^{i h^T x} - 1)|!|] Usando la proprietà del modulo di un prodotto, |!|ab|!| = |!|a|!| |!|b|!|: E[|!|e^{i t^T x}|!| |!|e^{i h^T x} - 1|!|] Il modulo di e^{i \\theta} è sempre 1 per qualsiasi \\theta \\in \\mathbb{R}. Quindi |!|e^{i t^T x}|!| = 1. La disuguaglianza diventa: |!|\\phi_x(t+h) - \\phi_x(t)|!| \\le E[|!|e^{i h^T x} - 1|!|] Il termine a destra, E[|!|e^{i h^T x} - 1|!|], dipende solo da h, non da t. Il modulo di un numero complesso della forma e^{i\\alpha} - 1 ha modulo sempre minore o uguale a 2 (poiché e^{i\\alpha} è sulla circonferenza unitaria e -1 è il punto opposto). La variabile aleatoria |!|e^{i h^T x} - 1|!| è quindi dominata dalla costante 2. Si applica il teorema della convergenza dominata per valutare il limite di questo termine a destra per h \\to \\mathbf{0}. \\lim_{h \\to \\mathbf{0}} E[|!|e^{i h^T x} - 1|!|] = E[\\lim_{h \\to \\mathbf{0}} |!|e^{i h^T x} - 1|!|] Il limite interno è: \\lim_{h \\to \\mathbf{0}} e^{i h^T x} Poiché h \\to \\mathbf{0}, h^T x \\to 0. Quindi, e^{i h^T x} \\to e^{i \\cdot 0} = e^0 = 1. Il limite del modulo è: \\lim_{h \\to \\mathbf{0}} |!|e^{i h^T x} - 1|!| = |!|1 - 1|!| = |!|0|!| = 0. Quindi, per il teorema della convergenza dominata, il valore atteso di questo limite è 0. Questo implica che: \\lim_{h \\to \\mathbf{0}} |!|\\phi_x(t+h) - \\phi_x(t)|!| = 0 Ciò dimostra che la funzione caratteristica è continua. Poiché il membro di destra della disuguaglianza, E[|!|e^{i h^T x} - 1|!|], dipende solo da h e non da t, la convergenza a 0 per h \\to \\mathbf{0} è uniforme rispetto a t. Questo significa che la continuità è uniforme su tutto \\mathbb{R}^D. Il concetto di uniforme continuità implica che la scelta di \\delta per una data \\epsilon non dipende dal punto t considerato.\n\nProposizione 3: Funzione Caratteristica di una Trasformazione Lineare La terza proprietà, considerata molto utile nelle applicazioni, descrive la funzione caratteristica di un vettore trasformato linearmente. Fissata una matrice A e un vettore B, compatibili per l’operazione A x + B, la funzione caratteristica del nuovo vettore y = A x + B calcolata in t può essere espressa come: \\phi_{Ax+B}(t) = E[e^{i t^T (Ax+B)}]\n\nDimostrazione della Proposizione 3 Si parte dalla definizione: \\phi_{Ax+B}(t) = E[e^{i t^T (Ax+B)}] Si distribuisce il prodotto scalare nell’esponente: t^T (Ax+B) = t^T (Ax) + t^T B Quindi l’espressione diventa: E[e^{i (t^T (Ax) + t^T B)}] Usando la proprietà e^{a+b} = e^a e^b: E[e^{i t^T (Ax)} e^{i t^T B}] Il termine e^{i t^T B} è una costante rispetto all’operatore di valore atteso, poiché B e t sono vettori deterministici (non aleatori). Si può quindi portare fuori dal valore atteso per linearità: e^{i t^T B} E[e^{i t^T (Ax)}] Ora si riscrive il prodotto scalare t^T (Ax). Usando la proprietà (AB)^T = B^T A^T, si ha che (Ax)^T t = x^T A^T t. Poiché il prodotto scalare è commutativo, t^T (Ax) = (Ax)^T t = x^T A^T t. In alternativa, si può vedere t^T A come (A^T t)^T. Quindi t^T (Ax) = (A^T t)^T x. Sostituendo nell’espressione: e^{i t^T B} E[e^{i (A^T t)^T x}] Osservando la forma del termine del valore atteso, E[e^{i v^T x}], dove v = A^T t, si riconosce la definizione della funzione caratteristica di x valutata nel vettore A^T t: E[e^{i (A^T t)^T x}] = \\phi_x(A^T t) Quindi la funzione caratteristica di A x + B è: \\phi_{Ax+B}(t) = e^{i t^T B} \\phi_x(A^T t) Questa formula è utile per calcolare la funzione caratteristica di trasformazioni affini (scala-posizione) di vettori aleatori, anche in più dimensioni.\n\n\n\nCaratterizzazione dell’Indipendenza tramite Funzioni Caratteristiche\n\nUn altro risultato importante lega l’indipendenza delle componenti di un vettore aleatorio alla sua funzione caratteristica.\nProposizione 4: Caratterizzazione dell’Indipendenza Sia x = (X_1, X_2, \\dots, X_D) un vettore aleatorio con componenti X_j. Le componenti X_1, X_2, \\dots, X_D sono stocasticamente indipendenti se e solo se la funzione caratteristica del vettore x calcolata in un vettore t = (t_1, t_2, \\dots, t_D) è uguale al prodotto delle funzioni caratteristiche marginali di ciascuna componente, calcolata nel proprio t_j. Questo deve valere per ogni vettore t \\in \\mathbb{R}^D. In simboli: X_1, \\dots, X_D sono indipendenti \\iff \\phi_x(t_1, \\dots, t_D) = \\prod_{j=1}^D \\phi_{X_j}(t_j) per ogni (t_1, \\dots, t_D) \\in \\mathbb{R}^D.\n\n\nImportante Distinzione È cruciale non confondere questo enunciato con l’espressione della funzione caratteristica della somma di variabili aleatorie. La funzione caratteristica della somma S = X_1 + \\dots + X_D (che è una variabile scalare, non un vettore) calcolata in uno scalare t è data da \\phi_S(t) = E[e^{i t S}] = E[e^{i t (X_1 + \\dots + X_D)}] = E[e^{i t X_1 + \\dots + i t X_D}] = E[\\prod_{j=1}^D e^{i t X_j}]. Se gli X_j sono indipendenti, allora E[\\prod Y_j] = \\prod E[Y_j], quindi \\phi_S(t) = \\prod_{j=1}^D E[e^{i t X_j}] = \\prod_{j=1}^D \\phi_{X_j}(t). Nel caso della somma, il prodotto è delle funzioni caratteristiche marginali tutte valutate nello stesso scalare t. Nella caratterizzazione dell’indipendenza delle componenti di un vettore, la funzione caratteristica vettoriale è valutata nel vettore (t_1, \\dots, t_D) e il prodotto è delle funzioni caratteristiche marginali, ciascuna valutata nella sua componente t_j. L’espressione della funzione caratteristica di un vettore x calcolata sulla “diagonale” con componenti uguali a uno scalare t, cioè \\phi_x(t, t, \\dots, t), è sempre esprimibile come \\phi_{X_1+\\dots+X_D}(t). Questa è una conseguenza della definizione, sempre vera indipendentemente dall’indipendenza.\n\n\n\nDimostrazione della Proposizione 4 La dimostrazione procede in due direzioni.\nDirezione 1: Indipendenza \\implies Fattorizzazione Supponiamo che le componenti X_1, \\dots, X_D siano indipendenti. Si vuole dimostrare che \\phi_x(t) = \\prod_{j=1}^D \\phi_{X_j}(t_j). Si parte dalla definizione della funzione caratteristica del vettore x calcolata in t=(t_1, \\dots, t_D): \\phi_x(t_1, \\dots, t_D) = E[e^{i t^T x}] Si scrive esplicitamente il prodotto scalare t^T x: t^T x = \\sum_{j=1}^D t_j X_j Quindi: \\phi_x(t_1, \\dots, t_D) = E[e^{i \\sum_{j=1}^D t_j X_j}] Usando la proprietà e^{\\sum a_j} = \\prod e^{a_j}: \\phi_x(t_1, \\dots, t_D) = E[\\prod_{j=1}^D e^{i t_j X_j}] Poiché le variabili aleatorie X_1, \\dots, X_D sono indipendenti, le variabili Y_j = e^{i t_j X_j} (che sono funzioni misurabili delle X_j) sono anch’esse indipendenti. Per variabili indipendenti, il valore atteso del prodotto è uguale al prodotto dei valori attesi: E[\\prod_{j=1}^D e^{i t_j X_j}] = \\prod_{j=1}^D E[e^{i t_j X_j}] Per definizione, E[e^{i t_j X_j}] è la funzione caratteristica della variabile scalare X_j calcolata nello scalare t_j: E[e^{i t_j X_j}] = \\phi_{X_j}(t_j) Quindi, si ottiene la fattorizzazione: \\phi_x(t_1, \\dots, t_D) = \\prod_{j=1}^D \\phi_{X_j}(t_j) Questa direzione è considerata più semplice.\n\nDirezione 2: Fattorizzazione \\implies Indipendenza Supponiamo che la funzione caratteristica del vettore x fattorizzi, cioè \\phi_x(t_1, \\dots, t_D) = \\prod_{j=1}^D \\phi_{X_j}(t_j) per ogni t \\in \\mathbb{R}^D. Si vuole dimostrare che le componenti X_j sono indipendenti. Si parte dalla supposta uguaglianza: \\phi_x(t_1, \\dots, t_D) = \\prod_{j=1}^D \\phi_{X_j}(t_j) Il membro di sinistra, \\phi_x(t), è per definizione E[e^{i t^T x}]. Questo è l’integrale di e^{i t^T x} rispetto alla legge (misura di probabilità immagine) del vettore x, che chiamiamo P_x: \\phi_x(t) = \\int_{\\mathbb{R}^D} e^{i t^T y} dP_x(y) Il membro di destra è il prodotto di D integrali. La funzione caratteristica marginale \\phi_{X_j}(t_j) è per definizione E[e^{i t_j X_j}]. Questo è l’integrale di e^{i t_j y_j} rispetto alla legge (misura di probabilità immagine) della variabile X_j, che chiamiamo P_{X_j}: \\phi_{X_j}(t_j) = \\int_{\\mathbb{R}} e^{i t_j y_j} dP_{X_j}(y_j) Quindi la fattorizzazione si scrive come: \\int_{\\mathbb{R}^D} e^{i t^T y} dP_x(y) = \\prod_{j=1}^D \\int_{\\mathbb{R}} e^{i t_j y_j} dP_{X_j}(y_j) Il prodotto di integrali, per il teorema di Fubini (utilizzato nella direzione “inversa”), è uguale all’integrale del prodotto rispetto alla misura prodotto. La misura prodotto delle leggi marginali P_{X_1}, \\dots, P_{X_D} è la misura P_{X_1} \\otimes \\dots \\otimes P_{X_D} sullo spazio prodotto \\mathbb{R}^D. L’integrale del prodotto \\prod_{j=1}^D e^{i t_j y_j} = e^{i t_1 y_1} \\dots e^{i t_D y_D} = e^{i \\sum t_j y_j} = e^{i t^T y} rispetto alla misura prodotto P_{X_1} \\otimes \\dots \\otimes P_{X_D} è: \\prod_{j=1}^D \\int_{\\mathbb{R}} e^{i t_j y_j} dP_{X_j}(y_j) = \\int_{\\mathbb{R}^D} e^{i t^T y} d(P_{X_1} \\otimes \\dots \\otimes P_{X_D})(y) (Il professore illustra questo passaggio mostrando il caso D=2 in dettaglio, spiegando come l’integrale doppio rispetto alla misura prodotto si scomponga nel prodotto degli integrali singoli, e come il termine e^{i t^T y} sia un prodotto di funzioni ciascuna dipendente solo da una componente y_j, permettendo l’applicazione di Fubini in entrambe le direzioni). Quindi, dalla supposta fattorizzazione, si ottiene l’uguaglianza di due funzioni caratteristiche: \\int_{\\mathbb{R}^D} e^{i t^T y} dP_x(y) = \\int_{\\mathbb{R}^D} e^{i t^T y} d(P_{X_1} \\otimes \\dots \\otimes P_{X_D})(y) Questa uguaglianza vale per ogni t \\in \\mathbb{R}^D. Per il teorema di unicità per le funzioni caratteristiche, se due funzioni caratteristiche coincidono, allora le corrispondenti misure di probabilità (leggi) devono coincidere. Pertanto, la legge del vettore aleatorio x, P_x, deve essere uguale alla misura prodotto delle leggi marginali: P_x = P_{X_1} \\otimes \\dots \\otimes P_{X_D} Questa uguaglianza delle leggi è una delle definizioni (o caratterizzazioni equivalenti) dell’indipendenza delle componenti di un vettore aleatorio. Quindi, se la funzione caratteristica fattorizza, le componenti del vettore x sono indipendenti. La dimostrazione di questa direzione ha utilizzato tre risultati importanti: il teorema di Fubini, il teorema di unicità delle funzioni caratteristiche e una caratterizzazione dell’indipendenza tramite la legge prodotto.\n\n\n\n\n\nLa Funzione Caratteristica e i Momenti\nQuesta sezione tratta un argomento molto importante: la relazione tra la funzione caratteristica e i momenti di una variabile aleatoria. La funzione caratteristica è uno strumento fondamentale che verrà ripreso più volte, specialmente in relazione ai concetti di convergenza e al teorema del limite centrale.\nEsistenza della Funzione Caratteristica vs. Esistenza dei Momenti\nLa funzione caratteristica di una variabile aleatoria può essere scritta senza bisogno di alcuna ipotesi sui momenti. Questo significa che si può definire la funzione caratteristica anche per variabili aleatorie che non possiedono il primo momento (valor atteso), il secondo momento, o nessun momento.\n\nEsempio: La distribuzione di Cauchy è un esempio di variabile aleatoria assolutamente continua che non ha momenti. Nonostante ciò, la sua funzione caratteristica esiste e può essere scritta in forma chiusa, risultando semplice. Quindi, una funzione caratteristica ben definita non implica necessariamente che la variabile aleatoria associata abbia momenti.\n\nTeorema Fondamentale: Momenti Implicano Derivabilità della Funzione Caratteristica e Sviluppo di Taylor\nConsideriamo una variabile aleatoria reale (dimensione 1) X con funzione caratteristica \\phi_X(t) (indicata come f nelle fonti).\nCondizione: Supponiamo che esista il momento assoluto di X di ordine n + \\delta, ovvero che E[|X|^{n+\\delta}] &lt; \\infty, dove n è un intero non negativo (n \\ge 0) e \\delta è un valore compreso tra 0 e 1, inclusi gli estremi (0 \\le \\delta \\le 1).\nConclusioni: Se la condizione precedente è soddisfatta, allora valgono i seguenti punti:\n\n\nDerivabilità e Legame con i Momenti (per n \\ge 1):\n\nLa funzione caratteristica \\phi_X(t) ammette derivata di ordine k per ogni k compreso tra 1 e n (1 \\le k \\le n).\nLa derivata k-esima della funzione caratteristica valutata nell’origine (t=0) è legata al momento k-esimo di X dalla seguente formula: \\phi_X^{(k)}(0) = i^k E[X^k] Questo ha senso solo se n \\ge 1, in modo che k possa assumere valori maggiori o uguali a 1.\n\n\n\nSviluppo di Taylor nell’Origine:\n\nLa funzione caratteristica può essere sviluppata in serie di Taylor attorno all’origine (t=0) fino all’ordine n.\nLo sviluppo di Taylor usuale è: \\phi_X(t) = \\sum_{k=0}^{n} \\frac{\\phi_X^{(k)}(0)}{k!} t^k + R_n(t) Utilizzando la relazione tra le derivate nell’origine e i momenti ( \\phi_X^{(k)}(0) = i^k E[X^k] per k \\ge 1), e ricordando che \\phi_X(0) = E[e^{i \\cdot 0 \\cdot X}] = E = 1 (momento di ordine 0), lo sviluppo diventa: \\phi_X(t) = 1 + \\sum_{k=1}^{n} \\frac{i^k E[X^k]}{k!} t^k + R_n(t)\nComportamento del Resto (R_n(t)):\n\nSe esiste almeno il momento n-esimo (E[|X|^n] &lt; \\infty, corrispondente al caso \\delta = 0), allora il resto è un “o piccolo” di t^n: R_n(t) = o(t^n) Questo significa che \\lim_{t \\to 0} \\frac{R_n(t)}{t^n} = 0.\nSe esiste un momento di ordine leggermente superiore a n, ovvero E[|X|^{n+\\delta}] &lt; \\infty con \\delta &gt; 0, allora si ha un controllo più preciso sul resto. Il resto è un “O grande” di t^{n+\\delta}: R_n(t) = O(t^{n+\\delta}) Questo significa che esiste una costante C tale che |R_n(t)| \\le C |t|^{n+\\delta} per t vicino a 0. La costante C dipende solo da n e \\delta e da E[|X|^{n+\\delta}]. Nello specifico, la dipendenza da X è interamente contenuta nel fattore E[|X|^{n+\\delta}].\n\n\n\n\n\nIn sintesi, il teorema dice che l’esistenza del momento n-esimo implica la derivabilità n volte della funzione caratteristica e garantisce che il resto dello sviluppo di Taylor sia o(t^n). Se esiste un momento di ordine n+\\delta con \\delta &gt; 0, si ottiene un controllo ancora più preciso sul resto (O(t^{n+\\delta})).\nIdea della Dimostrazione (Relazione Derivata-Momento)\nL’idea alla base della relazione tra le derivate della funzione caratteristica nell’origine e i momenti non è così strana.\nConsideriamo la derivata prima della funzione caratteristica: \\phi_X&#039;(t) = \\frac{d}{dt} E[e^{itX}] Supponendo di poter scambiare l’operazione di derivata con l’operazione di valore atteso (questo è uno dei passaggi che richiederebbe una giustificazione formale, ma è l’idea intuitiva): \\phi_X&#039;(t) = E\\left[\\frac{d}{dt} e^{itX}\\right] = E[iX e^{itX}] Ora, valutiamo questa derivata nell’origine (t=0): \\phi_X&#039;(0) = E[iX e^{i \\cdot 0 \\cdot X}] = E[iX e^0] = E[iX] = i E[X] Quindi, abbiamo \\phi_X&#039;(0) = i E[X], il che implica E[X] = \\frac{\\phi_X&#039;(0)}{i}. Questa è esattamente la formula \\phi_X^{(k)}(0) = i^k E[X^k] per k=1.\nL’idea è che, iterando questo processo di derivazione e scambio con il valore atteso, si ottengono le formule per le derivate di ordine superiore, legandole ai momenti di ordine superiore. Se si ha “quel tantino in più” (l’esistenza del momento dell’ordine appropriato) si può giustificare lo scambio e procedere. Una volta ottenute queste formule per le derivate nell’origine, si applica semplicemente lo sviluppo di Taylor per ottenere la tesi del teorema riguardante l’espansione.\n\nSignificato e Utilità del Teorema\nQuesto teorema è molto importante per diversi motivi.\n\nLegame tra Momenti e Funzione Caratteristica: Esiste un legame diretto che, in certi casi, può essere comodo. Se si desidera calcolare un momento ma l’integrale per il valor atteso è complicato, mentre la funzione caratteristica è facile da calcolare e derivare (soprattutto da valutare in zero), si può usare la formula E[X^k] = \\frac{\\phi_X^{(k)}(0)}{i^k} per ricavare il valore numerico del momento.\nRegolarità: La funzione caratteristica è sempre uniformemente continua senza alcuna ipotesi sui momenti. L’aggiunta di ipotesi sui momenti “aggiunge regolarità” alla funzione caratteristica, permettendo di svilupparla in serie di Taylor nell’origine. Questo non è sorprendente se si conosce la parte 1 del teorema e il comportamento dei resti di Taylor. La cosa fondamentale è che il teorema fornisce gratuitamente il resto o(t^n) se esiste il momento n-esimo. Se si ha qualcosa di più (momento n+\\delta), si ottiene un controllo più preciso del resto (O(t^{n+\\delta})). Questo controllo è importante perché si sa esattamente da cosa dipende la costante nell’O grande (dal momento n+\\delta e costanti universali che dipendono da n e \\delta).\n\nL’aspetto essenziale da ricordare è che l’esistenza dei momenti implica la derivabilità della funzione caratteristica e il comportamento o(t^n) del resto di Taylor.\nOsservazione Importante: L’Implicazione è Unidirezionale (Generalmente)\nÈ fondamentale notare che l’implicazione stabilita dal teorema è quella scritta: se esiste il momento n-esimo, allora la funzione caratteristica è derivabile n volte con continuità e la sua derivata k-esima nell’origine è legata al momento k-esimo dalla formula.\nIn generale, non è vero il contrario. Cioè, il fatto che la funzione caratteristica sia derivabile n volte con continuità non implica necessariamente che esista il momento n-esimo. Esistono risultati più fini che distinguono tra n pari e dispari, ma non verranno usati nel contesto presentato.\nLegame tra Comportamento della Funzione Caratteristica vicino allo Zero e Code della Distribuzione\nUn altro aspetto importante, collegato al teorema, è che il comportamento della funzione caratteristica nell’origine (per t piccolo) è controllato dai momenti. Poiché i momenti dipendono da come si comporta la distribuzione per valori grandi della variabile aleatoria (le “code” della distribuzione), esiste un legame tra il comportamento della probabilità di X molto grande e il comportamento della funzione caratteristica per t piccolo.\nConcetti simili, che mettono in relazione il comportamento di una funzione a infinito con il comportamento di una sua trasformata (duale) nell’origine, sono studiati nei cosiddetti teoremi tauberiani.\nAltre Trasformate Integrali\nLa funzione caratteristica è una delle trasformate integrali usate per studiare le variabili aleatorie, strettamente imparentata con la Trasformata di Fourier in analisi. Esistono altre trasformate che possono essere utili in circostanze diverse:\n\nFunzione Generatrice dei Momenti (MGF): Presente negli appunti, ma non trattata nel corso.\nFunzione Generatrice di Probabilità (PGF): Si applica alle variabili aleatorie discrete.\n\nCaso Multidimensionale\nIl teorema discusso finora si riferisce a variabili aleatorie reali (dimensione 1). Per vettori aleatori, esiste un risultato analogo che coinvolge i momenti misti e uno sviluppo di Taylor multidimensionale. Questo si può fare e l’idea non è molto diversa dal caso unidimensionale, ma è formalmente più complessa a causa dei multi-indici. L’esistenza di questo risultato per vettori è menzionata, ma non discussa nel dettaglio.\nEsempi ed Esercizi\nLe fonti presentano esempi di funzioni caratteristiche calcolate per specifiche distribuzioni, in particolare la costruzione della funzione caratteristica della Binomiale a partire da quella della Bernoulli, e un esercizio sul campionamento.\nFunzione Caratteristica della Distribuzione di Bernoulli\nConsideriamo una variabile aleatoria Y \\sim \\text{Bernoulli}(p). La sua funzione di probabilità è P(Y=1)=p e P(Y=0)=1-p. La funzione caratteristica è definita come E[e^{itY}]: \\phi_Y(t) = E[e^{itY}] = e^{it \\cdot 0} P(Y=0) + e^{it \\cdot 1} P(Y=1) \\phi_Y(t) = e^0 (1-p) + e^{it} p \\phi_Y(t) = 1 \\cdot (1-p) + e^{it} p \\phi_Y(t) = 1 - p + p e^{it} Questa è la funzione caratteristica della distribuzione di Bernoulli(p).\nFunzione Caratteristica della Distribuzione Binomiale\nConsideriamo una variabile aleatoria X \\sim \\text{Binomiale}(n, p). Una variabile Binomiale può essere vista come la somma di n variabili aleatorie di Bernoulli indipendenti e identicamente distribuite (i.i.d.), Y_1, Y_2, \\dots, Y_n, dove Y_i \\sim \\text{Bernoulli}(p) per ogni i. Quindi, X = \\sum_{i=1}^n Y_i.\nUna proprietà fondamentale della funzione caratteristica è che la funzione caratteristica di una somma di variabili aleatorie indipendenti è il prodotto delle loro funzioni caratteristiche individuali. Se le variabili sono anche identicamente distribuite, il prodotto diventa una potenza.\nPoiché Y_i sono i.i.d. Bernoulli(p), la funzione caratteristica di \\sum_{i=1}^n Y_i è il prodotto delle funzioni caratteristiche di ciascun Y_i. Dato che sono identiche, è (\\phi_Y(t))^n. \\phi_X(t) = \\phi_{\\sum_{i=1}^n Y_i}(t) = \\prod_{i=1}^n \\phi_{Y_i}(t) = (\\phi_Y(t))^n Sostituendo la funzione caratteristica della Bernoulli: \\phi_X(t) = (1 - p + p e^{it})^n Questa è la funzione caratteristica della distribuzione Binomiale(n, p).\nEsercizio: Funzione Caratteristica della Frequenza Empirica\nConsideriamo di nuovo n variabili aleatorie Y_1, \\dots, Y_n i.i.d. \\sim \\text{Bernoulli}(p). Definiamo la variabile aleatoria S_n come la media di queste variabili, che rappresenta la frequenza empirica di successo (o la probabilità empirica di ottenere 1): S_n = \\frac{1}{n} \\sum_{i=1}^n Y_i\nDomanda 1: S_n è una variabile aleatoria Binomiale? Risposta: No. La variabile Binomiale(n, p) può assumere valori interi {0, 1, 2, \\dots, n}. Invece, S_n può assumere valori {0/n, 1/n, 2/n, \\dots, n/n = 1}. Il dominio (supporto) dei valori possibili è diverso, quindi S_n non è una Binomiale.\nDomanda 2: Qual è la funzione caratteristica di S_n? Per calcolare la funzione caratteristica di S_n = \\frac{1}{n} \\sum_{i=1}^n Y_i, possiamo usare la proprietà che per costanti scalari a, b, la funzione caratteristica di aX+b è \\phi_{aX+b}(t) = e^{itb} \\phi_X(at). Nel nostro caso, S_n è della forma aX con a = \\frac{1}{n} e X = \\sum_{i=1}^n Y_i. Non c’è il termine ‘b’. Quindi, la funzione caratteristica di S_n è: \\phi_{S_n}(t) = \\phi_{\\frac{1}{n} (\\sum_{i=1}^n Y_i)}(t) Applicando la proprietà di scaling con a = \\frac{1}{n} e X = \\sum_{i=1}^n Y_i: \\phi_{S_n}(t) = \\phi_{\\sum_{i=1}^n Y_i}\\left(\\frac{t}{n}\\right) Sappiamo che X = \\sum_{i=1}^n Y_i dove Y_i sono i.i.d. Bernoulli(p) è una variabile aleatoria Binomiale(n, p). Abbiamo calcolato la sua funzione caratteristica come \\phi_X(t) = (1 - p + p e^{it})^n.\nSostituiamo questa espressione, valutandola in \\frac{t}{n} anziché t: \\phi_{S_n}(t) = \\left(1 - p + p e^{i \\frac{t}{n}}\\right)^n Questo completa il calcolo della funzione caratteristica della frequenza empirica S_n per variabili di Bernoulli.\nSpero questa rielaborazione dettagliata, basata esclusivamente sulle fonti fornite, ti sia utile per comprendere meglio i concetti e i passaggi presentati.\n\n\nSpiegazione sulle Funzioni Caratteristiche\nIntroduzione al Contesto e agli Esempi\nIl professore introduce il concetto di funzione caratteristica riprendendo degli esempi. Viene menzionato un Esempio 1 in cui delle variabili X_j sono \\text{01}. Questo può essere immaginato come il lancio di n monetine, contando il numero di successi e dividendolo per n per ottenere la frequenza di successi su n lanci.\nSi passa poi all’Esempio 2.\nEsempio: Somma di Variabili Casuali Poisson Indipendenti\n\n\nDefinizione e Obiettivo Si considerano variabili casuali X_j indipendenti, ognuna con il proprio parametro \\lambda_j. L’obiettivo è calcolare la funzione caratteristica della loro somma.\n\n\nCalcolo della Funzione Caratteristica della Somma (Utilizzo della proprietà del prodotto) La funzione caratteristica della somma di variabili casuali indipendenti è il prodotto delle funzioni caratteristiche individuali. Viene ricordata (anche se con una potenziale notazione intermedia un po’ confusa nella trascrizione della fonte) la forma della funzione caratteristica per una singola variabile Poisson di parametro \\lambda: \\phi_X(t) = e^{\\lambda(e^{it}-1)}. Questa forma è presentata nella fonte come e^{-\\lambda(1-e^{it})} o e^{-\\lambda} e^{\\lambda e^{it}} o ancora e^{-\\lambda + \\lambda e^{it}}.\n\n\nFormule Matematiche (come presentate nella fonte, con LaTeX) Considerando la somma, si deve fare il prodotto delle funzioni caratteristiche: \\phi_{\\sum X_j}(t) = \\prod_j \\phi_{X_j}(t). Usando la forma della funzione caratteristica per ogni X_j \\sim \\text{Poisson}(\\lambda_j), che è \\phi_{X_j}(t) = e^{\\lambda_j(e^{it}-1)}, il prodotto diventa: \\prod_j e^{\\lambda_j(e^{it}-1)} Per la proprietà dell’esponenziale, il prodotto di esponenziali è l’esponenziale della somma degli esponenti: \\exp\\left(\\sum_j \\lambda_j(e^{it}-1)\\right) Si può raccogliere il termine (e^{it}-1) dalla somma: \\exp\\left(\\left(\\sum_j \\lambda_j\\right)(e^{it}-1)\\right) Il professore introduce \\lambda_{barra} = \\sum_j \\lambda_j. La formula ottenuta è: e^{\\lambda_{barra}(e^{it}-1)} (Nella fonte questa viene presentata come e^{-\\lambda_{barra}(1 - e^{it})}, che è la stessa formula).\n\n\n\nConclusione per la Somma di Poisson Riconoscendo la forma della funzione caratteristica ottenuta, si conclude che essa è esattamente la funzione caratteristica di una variabile casuale Poisson con parametro \\lambda_{barra} = \\sum_j \\lambda_j. Pertanto, in una riga (utilizzando il teorema di unicità della funzione caratteristica), si è dimostrato che la somma di variabili casuali Poisson indipendenti è una variabile casuale Poisson il cui parametro è la somma dei parametri individuali.\n\n\nConfronto con altre Distribuzioni (Uniforme) Viene sottolineato che questa proprietà di “stabilità” (la somma rimane nella stessa famiglia di distribuzioni) non è generale per tutte le famiglie di distribuzioni. Ad esempio, la somma di due variabili casuali Uniformi tra 0 e 1 non è una variabile casuale Uniforme.\n\n\nRilevanza (Processo di Poisson) Questa proprietà è una delle ragioni per cui la distribuzione di Poisson è importante. Ad esempio, nel processo di Poisson, se si contano eventi indipendenti in diverse zone, la somma totale degli eventi nelle zone, ipotizzando che gli eventi in ogni singola zona seguano una distribuzione di Poisson indipendente, sarà una variabile casuale Poisson.\n\n\nStudio della Funzione Caratteristica della Variabile Casuale Normale (Gaussiana)\n\n\nImportanza La funzione caratteristica della Gaussiana è presentata come molto importante.\n\n\nDefinizione e Forma della Funzione Caratteristica per N(\\mu, \\sigma^2) Si considera una variabile casuale reale X con legge Normale (o Gaussiana) di media \\mu e varianza \\sigma^2. La funzione caratteristica di X calcolata in t, denotata \\phi_X(t), è data da: \\phi_X(t) = e^{i \\mu t} e^{-\\frac{\\sigma^2 t^2}{2}} Viene fatto notare che assomiglia un po’ alla funzione di densità, ma non bisogna confondere le due, poiché \\sigma e \\mu compaiono in posizioni diverse.\n\n\nRelazione tra Gaussiana Generale e Gaussiana Standard (N(0,1)) Si osserva che una variabile casuale Gaussiana X \\sim N(\\mu, \\sigma^2) può essere scritta come X = \\mu + \\sigma X_0, dove X_0 è una Gaussiana standard, X_0 \\sim N(0, 1). Questo deriva dal fatto che la famiglia Gaussiana è una famiglia di scala e posizione. Questo può essere verificato scrivendo la densità e riconoscendo la densità di una Gaussiana standard dopo una trasformazione lineare di scala e posizione.\n\n\nUtilizzo della Gaussiana Standard per la Dimostrazione Grazie alla proprietà che la Gaussiana è una famiglia di scala e posizione, se si conosce la funzione caratteristica della Gaussiana standard N(0, 1), è sufficiente per ottenere la funzione caratteristica di qualsiasi Gaussiana generale N(\\mu, \\sigma^2). La funzione caratteristica di aX+b è \\phi_{aX+b}(t) = e^{ibt} \\phi_X(at). Applicando questa a X = \\mu + \\sigma X_0 (con X_0 \\sim N(0,1)), si ha: \\phi_X(t) = \\phi_{\\mu + \\sigma X_0}(t) = e^{i \\mu t} \\phi_{X_0}(\\sigma t) Se si dimostra che \\phi_{X_0}(t) = e^{-t^2/2} per la Gaussiana standard, allora: \\phi_X(t) = e^{i \\mu t} \\phi_{X_0}(\\sigma t) = e^{i \\mu t} e^{-(\\sigma t)^2/2} = e^{i \\mu t} e^{-\\frac{\\sigma^2 t^2}{2}} Questo è esattamente quanto si voleva dimostrare. Quindi, basta dimostrare l’espressione per una Gaussiana standard. Questa è una strategia comune: dimostrare proprietà per i parametri più comodi quando si ha una famiglia di scala e posizione. Non è applicabile, ad esempio, alla Poisson o alla Binomiale perché i loro parametri non sono di scala o posizione.\n\n\n\n(Dimostrazione) Derivazione della Funzione Caratteristica per la Gaussiana Standard N(0,1)\n\n\nObiettivo e Metodologia (ODE) Questa dimostrazione non è formalmente richiesta, ma usa tecniche di analisi ed equazioni differenziali ordinarie (ODE).\n\n\nImpostazione della Derivata della Funzione Caratteristica (Forma Integrale) La funzione caratteristica di una variabile casuale con densità f(x) è data dall’integrale \\int_{-\\infty}^{\\infty} e^{itx} f(x) dx. Per la Gaussiana standard X_0, la densità è f_{X_0}(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2} (la costante \\frac{1}{\\sqrt{2\\pi}} è menzionata come “mi ero dimenticato \\sqrt{2\\pi}” in, suggerendo che sia stata omessa durante la derivazione). La funzione caratteristica è \\phi_{X_0}(t) = \\int_{-\\infty}^{\\infty} e^{itx} f_{X_0}(x) dx. Questo è anche il valore atteso di e^{itX_0} dove X_0 \\sim N(0,1). Si calcola la derivata prima rispetto a t: \\phi&#039;_{X_0}(t) = \\frac{d}{dt} \\int_{-\\infty}^{\\infty} e^{itx} f_{X_0}(x) dx Assumendo di poter portare la derivata dentro l’integrale (è una quasi dimostrazione): \\phi&#039;_{X_0}(t) = \\int_{-\\infty}^{\\infty} \\frac{d}{dt}(e^{itx}) f_{X_0}(x) dx = \\int_{-\\infty}^{\\infty} i x e^{itx} f_{X_0}(x) dx Sostituendo la densità (e omettendo temporaneamente la costante \\frac{1}{\\sqrt{2\\pi}} come fatto nella fonte per i calcoli espliciti): \\phi&#039;_{X_0}(t) = \\int i x e^{itx} e^{-x^2/2} dx\n\n\nPassaggi Matematici (Integrazione per Parti) Si riarrangia l’integrale per applicare l’integrazione per parti \\int u dv = uv - \\int v du. Il termine ix e^{itx} e^{-x^2/2} viene visto come i \\cdot e^{itx} \\cdot x e^{-x^2/2}. Si sceglie u = e^{itx} e dv = x e^{-x^2/2} dx. Allora du = it e^{itx} dx. Per trovare v, si integra dv. Si nota che x e^{-x^2/2} è la derivata di -e^{-x^2/2} rispetto a x: \\frac{d}{dx}(-e^{-x^2/2}) = -(-x)e^{-x^2/2} = x e^{-x^2/2}. Quindi v = -e^{-x^2/2}.\nL’integrale diventa, includendo l’iniziale fattore i (menzionato come “davanti a tutta la parente” in): \\phi&#039;_{X_0}(t) = i \\left[ (e^{itx})(-e^{-x^2/2}) \\Big|_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} (-e^{-x^2/2}) (it e^{itx}) dx \\right]\n\n\nTermine di Bordo (valutazione a \\pm \\infty) Il primo termine (termine di bordo uv \\big|_{-\\infty}^{\\infty}) si valuta agli estremi. Poiché e^{-x^2/2} \\to 0 sia per x \\to -\\infty che per x \\to +\\infty, il termine di bordo è 0.\n\n\nTermine Integrale Rimanente Il termine integrale rimanente è: - \\int_{-\\infty}^{\\infty} (-e^{-x^2/2}) (it e^{itx}) dx Si semplificano i segni e si porta fuori la costante it: = it \\int_{-\\infty}^{\\infty} e^{itx} e^{-x^2/2} dx Questo integrale, includendo la costante \\frac{1}{\\sqrt{2\\pi}} omessa nei passaggi intermedi, sarebbe \\int e^{itx} f_{X_0}(x) \\sqrt{2\\pi} dx. Il professore corregge l’omissione e dice che l’integrale rimanente è la funzione caratteristica stessa.\n\n\nRisultato dell’Integrazione per Parti e Semplificazione Combinando il fattore i iniziale con il risultato dell’integrazione per parti: \\phi&#039;_{X_0}(t) = i \\left[ 0 - \\left( it \\int_{-\\infty}^{\\infty} e^{itx} e^{-x^2/2} dx \\right) \\right] (Attenzione alla gestione dei segni come descritta in, “meno la derivata del primo”, “meno i tivo”). Seguendo la descrizione del risultato finale in: Il termine integrale dà ”- t” moltiplicato per la funzione caratteristica. Con il fattore i iniziale e il it dall’integrazione per parti (i \\cdot it = i^2 t = -t), si ottiene -t. Il professore riassume che il risultato è ”- t volte f(x) con 0 calcolata in t”, dove f(x) con 0 calcolata in t è \\phi_{X_0}(t).\n\n\nDerivazione dell’Equazione Differenziale Ordinaria (ODE) Il calcolo della derivata porta alla seguente equazione differenziale ordinaria (ODE): \\phi&#039;_{X_0}(t) = -t \\phi_{X_0}(t)\n\n\nCondizione Iniziale La condizione iniziale per questa ODE è data dal valore della funzione caratteristica in t=0: \\phi_{X_0}(0) = E[e^{i \\cdot 0 \\cdot X_0}] = E = 1 La funzione caratteristica calcolata in zero vale sempre 1.\n\n\nSoluzione dell’ODE Questa ODE \\frac{d\\phi}{dt} = -t \\phi è di facile soluzione (a variabili separabili): \\frac{d\\phi}{\\phi} = -t , dt Integrando ambo i lati: \\int \\frac{d\\phi}{\\phi} = \\int -t , dt \\ln|\\phi(t)| = -\\frac{t^2}{2} + C \\phi(t) = A e^{-t^2/2} Utilizzando la condizione iniziale \\phi_{X_0}(0) = 1: 1 = A e^{-0^2/2} = A e^0 = A Quindi A=1. La soluzione unica di questa ODE è: \\phi_{X_0}(t) = e^{-t^2/2}\n\n\nFormula Finale per N(0,1) La funzione caratteristica della Gaussiana standard N(0,1) è e^{-t^2/2}.\n\n\nNota sulla Non Richiesta della Dimostrazione Questa dimostrazione non è richiesta all’esame, ma è un esempio di applicazione dell’analisi e delle ODE. È fondamentale, invece, conoscere la definizione e la forma della funzione caratteristica di una Gaussiana e non confonderla con la densità.\n\n\n\n\nRitorno alla Gaussiana Generale (Derivazione dalla Standard) Come visto in precedenza, conoscendo \\phi_{X_0}(t) = e^{-t^2/2} e usando la relazione X = \\mu + \\sigma X_0 e la proprietà \\phi_{aX+b}(t) = e^{ibt} \\phi_X(at), si ottiene la funzione caratteristica della Gaussiana generale N(\\mu, \\sigma^2): \\phi_X(t) = e^{i \\mu t} \\phi_{X_0}(\\sigma t) = e^{i \\mu t} e^{-(\\sigma t)^2/2} = e^{i \\mu t} e^{-\\frac{\\sigma^2 t^2}{2}}\n\n\n\n(Proposizione) Somma di Variabili Casuali Normali Indipendenti\n\n\nEnunciato della Proposizione Si prendono n variabili casuali Gaussiane indipendenti, X_j \\sim N(\\mu_j, \\sigma_j^2), ognuna con la propria media \\mu_j e varianza \\sigma_j^2. Allora la somma S_n = \\sum_{j=1}^n X_j è anch’essa una variabile casuale Normale.\n\n\nRisultati “Banali” (Media e Varianza della Somma) Una parte di questo enunciato è considerata banale. La media della somma di variabili casuali (anche non indipendenti) è la somma delle medie: E[\\sum X_j] = \\sum E[X_j] = \\sum \\mu_j. La varianza della somma di variabili casuali indipendenti è la somma delle varianze: \\text{Var}(\\sum X_j) = \\sum \\text{Var}(X_j) = \\sum \\sigma_j^2. Quindi, se si sa già che la somma è una Gaussiana, i suoi parametri (media e varianza) devono necessariamente essere la somma delle medie e la somma delle varianze.\n\n\nRisultato Non Banale (La Somma Resta Gaussiana) La parte non banale della proposizione è che quando si sommano Gaussiane indipendenti, queste sono “stabili” nel senso che la loro somma rimane una Gaussiana.\n\n\nRarità di Questa Proprietà Viene ribadito che questa stabilità non è una proprietà comune a molte distribuzioni; accade per la Poisson e per la Gaussiana, ma non per tantissimi altri casi.\n\n\n(Dimostrazione) Dimostrazione della Somma di Normali Indipendenti (Uso Funzioni Caratteristiche)\n\n\nVantaggio dell’Uso delle Funzioni Caratteristiche (vs Convoluzione) Questa dimostrazione, a differenza del calcolo con la formula di convoluzione (che sarebbe complicato, anche per sole due variabili), è molto facile usando le funzioni caratteristiche.\n\n\nImpostazione: Funzione Caratteristica della Somma = Prodotto delle Funzioni Caratteristiche Per variabili casuali indipendenti, la funzione caratteristica della somma è il prodotto delle funzioni caratteristiche individuali: \\phi_{S_n}(t) = \\phi_{\\sum_{j=1}^n X_j}(t) = \\prod_{j=1}^n \\phi_{X_j}(t)\n\n\nSostituzione delle Funzioni Caratteristiche Individuali Si sostituisce la forma della funzione caratteristica per ogni Gaussiana X_j \\sim N(\\mu_j, \\sigma_j^2), che è \\phi_{X_j}(t) = e^{i \\mu_j t} e^{-\\frac{\\sigma_j^2 t^2}{2}}: \\phi_{S_n}(t) = \\prod_{j=1}^n \\left(e^{i \\mu_j t} e^{-\\frac{\\sigma_j^2 t^2}{2}}\\right)\n\n\nSviluppo del Prodotto (Somma degli Esponenti) Usando la proprietà \\prod e^{a_j} = e^{\\sum a_j}: \\phi_{S_n}(t) = \\exp\\left(\\sum_{j=1}^n \\left(i \\mu_j t - \\frac{\\sigma_j^2 t^2}{2}\\right)\\right)\n\n\nRiorganizzazione dell’Esponente Si riorganizza la somma degli esponenti: \\sum_{j=1}^n i \\mu_j t - \\sum_{j=1}^n \\frac{\\sigma_j^2 t^2}{2} Si raccolgono i termini comuni: i t \\left(\\sum_{j=1}^n \\mu_j\\right) - \\frac{t^2}{2} \\left(\\sum_{j=1}^n \\sigma_j^2\\right)\n\n\nFormula Finale della Funzione Caratteristica della Somma La funzione caratteristica della somma è quindi: \\phi_{S_n}(t) = \\exp\\left( i t \\left(\\sum_{j=1}^n \\mu_j\\right) - \\frac{t^2}{2} \\left(\\sum_{j=1}^n \\sigma_j^2\\right) \\right) \\phi_{S_n}(t) = e^{i \\left(\\sum_{j=1}^n \\mu_j\\right) t} e^{-\\frac{\\left(\\sum_{j=1}^n \\sigma_j^2\\right) t^2}{2}}\n\n\nRiconoscimento della Forma (Funzione Caratteristica di una Gaussiana) Guardando questa espressione, si riconosce che ha esattamente la forma della funzione caratteristica di una variabile casuale Gaussiana e^{i \\mu t} e^{-\\frac{\\sigma^2 t^2}{2}}.\n\n\nParametri della Gaussiana Risultante (Media e Varianza) Confrontando la forma ottenuta con la forma generale della funzione caratteristica Gaussiana, si deduce che la somma S_n è una Gaussiana con:\n\nMedia \\mu = \\sum_{j=1}^n \\mu_j\nVarianza \\sigma^2 = \\sum_{j=1}^n \\sigma_j^2\n\n\n\nNota sull’Additività delle Varianze (non degli Scarti Quadratici Medi) Viene evidenziato che si sommano le varianze (\\sigma^2), non gli scarti quadratici medi (\\sigma). Viene menzionato che alcuni software statistici, come R, usano la notazione \\mu, \\sigma invece di \\mu, \\sigma^2, quindi bisogna fare attenzione.\n\n\n\nConsiderazioni Finali sull’Importanza delle Funzioni Caratteristiche\n\n\nApplicazioni alle Somme La funzione caratteristica è molto utile nello studio delle somme di variabili casuali indipendenti.\n\n\nTeorema Centrale del Limite (Cenni) Storicamente, la funzione caratteristica ha avuto grande importanza nello studio del Teorema Centrale del Limite (TCL), che riguarda anch’esso le somme di variabili casuali.\n\n\nComunicazioni Amministrative\n\n\nCorrezione Compiti e Valutazione Il professore ha quasi finito di correggere i compiti e non li ha trovati terribili, nonostante una valutazione “estremamente larga”. Soluzioni ed esiti verranno pubblicati.\n\n\nQuestione Visione Scritti Si pone la questione della visione degli scritti.\n\n\nProposta di Modalità In accordo con un collega (Di Primio), viene suggerita una modalità: fissare un giorno, presentare prima una “zoologia” degli errori canonici (per cui magari non è necessario venire individualmente) e poi fare una coda per coloro che hanno bisogno di chiedere informazioni specifiche.\n\n\nProposta di Data Originariamente si pensava a giovedì prossimo (settimana successiva al 16/17, quindi 23/24), ma si ipotizza che molti non siano presenti.\n\n\nValutazione di Streaming vs Presenza (Sondaggio informale) Viene considerato di fare tutto in streaming se la presenza è minima, poiché anche per i professori è più comodo non doversi spostare apposta (il professore è di Milano e sarebbe presente, Di Primio no). Viene quindi proposto un sondaggio informale tra i presenti.\n\n\nEsito del Sondaggio Viene chiesto chi sarebbe presente il 23 o 24. L’esito informale indica che non c’è “zero” presenza, sebbene sembra che pochi abbiano alzato la mano. Si decide comunque di procedere con un sondaggio formale a questo punto.\n\n\nReferences\nAppunti Prob - 18.pdf"},"6--full-note/prob-lez19":{"slug":"6--full-note/prob-lez19","filePath":"6- full note/prob-lez19.md","title":"prob-lez19","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/probabilità","3--tag/sbobine"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-24 12:49\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: probabilità   sbobine\nprob-lez19\nDistribuzione Gaussiana Multivariata: Estensione e Proprietà\nIn questa lezione si estende il concetto di variabile aleatoria Gaussiana, precedentemente visto per il caso unidimensionale, ai vettori aleatori (caso multivariato, con dimensione n \\ge 2). Lo strumento principale utilizzato per questa estensione è la funzione caratteristica, data la sua definizione e le sue proprietà viste in precedenza.\nRichiamo sulla Gaussiana Unidimensionale\nUna variabile aleatoria scalare X_J ha legge Gaussiana con media \\mu_J e varianza \\sigma_J^2 (indicata con X_J \\sim \\mathcal{N}(\\mu_J, \\sigma_J^2)) se:\n\nÈ una variabile aleatoria assolutamente continua con densità di probabilità: f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_J^2}} e^{-\\frac{(x-\\mu_J)^2}{2\\sigma_J^2}}. Questo vale se \\sigma_J^2 &gt; 0.\nHa funzione caratteristica: \\phi_{X_J}(t) = E[e^{itX_J}] = e^{i\\mu_J t - \\frac{1}{2}\\sigma_J^2 t^2}.\n\nÈ stato notato che la famiglia delle Gaussiane univariate è una famiglia di scala-posizione, ottenuta da una Gaussiana standard \\mathcal{N}(0, 1) tramite X_J = \\mu_J + \\sigma_J Z_0, dove Z_0 \\sim \\mathcal{N}(0, 1). Inoltre, una combinazione lineare di Gaussiane indipendenti è ancora una Gaussiana.\n\nIl Caso Degenerato (\\sigma^2 = 0)\nSi può adottare la convenzione che una variabile aleatoria X con “legge Gaussiana degenere” con varianza zero (\\sigma^2=0) e media \\mu sia semplicemente una costante uguale a \\mu con probabilità 1. Questa è una convenzione utile ma “pericolosa”, perché una costante non è assolutamente continua e quindi non ha una densità nel senso usuale. Tuttavia, la sua funzione caratteristica è ben definita: \\phi_X(t) = E[e^{itX}] = E[e^{it\\mu}] = e^{it\\mu}. La convenzione è giustificata dal fatto che la funzione caratteristica della Gaussiana unidimensionale \\phi_{X_J}(t) = e^{i\\mu_J t - \\frac{1}{2}\\sigma_J^2 t^2}, se calcolata per \\sigma_J^2 = 0, produce esattamente e^{i\\mu_J t}, che è la funzione caratteristica di una costante pari a \\mu_J. Quindi, a livello di funzione caratteristica, il caso degenere è incluso naturalmente.\n\nPassaggio 1: Obiettivo - Estendere il Concetto a Vettori Aleatori (n \\ge 2)\nL’obiettivo è estendere il concetto di variabile Gaussiana ai vettori aleatori n-dimensionali. Questo richiede l’uso delle funzioni caratteristiche per vettori aleatori.\nPassaggio 2: Un Primo Tentativo - Vettore di Componenti Gaussiane Indipendenti\nSi considera un vettore \\mathbf{z} = (Z_1, ..., Z_n)^T, dove Z_j sono variabili aleatorie indipendenti, ognuna distribuita come una Gaussiana con media 0 e varianza \\sigma_j^2 (Z_j \\sim \\mathcal{N}(0, \\sigma_j^2)). Si ammette che alcune \\sigma_j^2 possano essere zero (caso degenere, Z_j=0 con probabilità 1). Questo vettore è chiamato un “vettore Gaussiano” in prima battuta. Questa definizione iniziale è limitata perché copre solo vettori le cui componenti sono indipendenti. Non è detto che un tale vettore sia assolutamente continuo, specialmente se alcune \\sigma_j^2 = 0.\nIn questa formulazione iniziale, è fondamentale notare che si tratta sostanzialmente di una semplice notazione e non di una generalizzazione profonda del concetto. Questo approccio descrive un caso molto specifico: un vettore aleatorio le cui componenti marginali sono tutte Gaussiane e sono indipendenti. L’obiettivo più ambizioso è invece riuscire a definire vettori Gaussiani in cui le componenti non siano necessariamente indipendenti.\nPer convenzione, anche in questo contesto multidimensionale e per componenti indipendenti, si ammette la possibilità che alcune delle varianze \\sigma_j^2 possano essere uguali a zero. Come nel caso unidimensionale degenere, una variabile Gaussiana con varianza zero e media nulla (Z_j \\sim \\mathcal{N}(0, 0)) intende semplicemente una variabile aleatoria che è una costante concentrata in zero con probabilità 1.\nQuesto primo tentativo di definizione può essere espresso formalmente usando la notazione \\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, D), dove \\mathbf{0} è il vettore nullo (rappresentando le medie nulle) e D è una matrice diagonale. Sulla diagonale di questa matrice D si trovano le varianze individuali delle componenti \\sigma_j^2, mentre tutti gli elementi fuori dalla diagonale sono zero.\nLa possibilità che alcune varianze \\sigma_j^2 siano zero ha una conseguenza diretta e importante: il vettore \\mathbf{z}, anche se le sue componenti sono indipendenti, non è necessariamente assolutamente continuo. Questo accade perché una variabile costante (con varianza zero) non è assolutamente continua e non possiede una densità di probabilità nel senso usuale.\nQuesto punto evidenzia una limitazione dell’approccio basato sulla densità di probabilità per definire il vettore Gaussiano generale. Se si desidera la massima generalità, includendo i casi degeneri con varianza zero, non è conveniente partire dalla definizione tramite densità, poiché questa non coprirebbe adeguatamente tali scenari. Questa limitazione giustifica l’adozione di un altro strumento matematico per la definizione generale del vettore Gaussiano multivariato: l’uso delle funzioni caratteristiche, le quali rimangono ben definite anche quando la varianza è zero. La funzione caratteristica per questo vettore di componenti indipendenti con media zero si calcola facilmente come il prodotto delle funzioni caratteristiche individuali e ha la forma e^{- \\frac{1}{2} \\sum_{j=1}^n \\sigma_j^2 t_j^2}. Questa si può riscrivere usando la matrice diagonale D come e^{- \\frac{1}{2} \\mathbf{t}^T D \\mathbf{t}}.\n\nPassaggio 3: Funzione Caratteristica del Vettore di Componenti Indipendenti\nLa funzione caratteristica del vettore \\mathbf{z} calcolata in un vettore \\mathbf{t} = (t_1, ..., t_n)^T \\in \\mathbb{R}^n è data da: \\phi_{\\mathbf{z}}(\\mathbf{t}) = E[e^{i\\mathbf{t}^T\\mathbf{z}}] Poiché \\mathbf{z} ha componenti indipendenti, l’aspettazione del prodotto si fattorizza nel prodotto delle aspettazioni: E[e^{i\\mathbf{t}^T\\mathbf{z}}] = E[e^{i \\sum_{j=1}^n t_j Z_j}] = E[\\prod_{j=1}^n e^{i t_j Z_j}] = \\prod_{j=1}^n E[e^{i t_j Z_j}] Ognuno dei fattori nell’ultimo prodotto è la funzione caratteristica della variabile unidimensionale Z_j, valutata in t_j. Dato che Z_j \\sim \\mathcal{N}(0, \\sigma_j^2), la sua funzione caratteristica è e^{-\\frac{1}{2}\\sigma_j^2 t_j^2}. Quindi, la funzione caratteristica di \\mathbf{z} è: \\phi_{\\mathbf{z}}(\\mathbf{t}) = \\prod_{j=1}^n e^{-\\frac{1}{2}\\sigma_j^2 t_j^2} = e^{\\sum_{j=1}^n -\\frac{1}{2}\\sigma_j^2 t_j^2} = e^{-\\frac{1}{2} \\sum_{j=1}^n \\sigma_j^2 t_j^2} Questa somma nell’esponente può essere scritta in forma matriciale usando la matrice diagonale \\mathbf{D} con \\sigma_j^2 sulla diagonale principale e zero altrove. \\sum_{j=1}^n \\sigma_j^2 t_j^2 = \\mathbf{t}^T \\mathbf{D} \\mathbf{t} Quindi, la funzione caratteristica è: \\phi_{\\mathbf{z}}(\\mathbf{t}) = e^{-\\frac{1}{2} \\mathbf{t}^T \\mathbf{D} \\mathbf{t}} Questa forma vale anche quando alcune \\sigma_j^2 = 0.\n\nPassaggio 4: Matrici Simmetriche e Semidefinite Positive\nUna matrice n \\times n simmetrica e semidefinita positiva, indicata con \\boldsymbol{\\Sigma}, possiede la proprietà fondamentale di essere diagonalizzabile tramite una matrice ortonormale \\mathbf{O}. Questo significa che esiste una matrice ortonormale \\mathbf{O} tale che: \\mathbf{O}^T \\boldsymbol{\\Sigma} \\mathbf{O} = \\mathbf{D} dove \\mathbf{D} è una matrice diagonale i cui elementi sulla diagonale sono gli autovalori di \\boldsymbol{\\Sigma}. Poiché \\boldsymbol{\\Sigma} è semidefinita positiva, i suoi autovalori sono maggiori o uguali a zero (\\lambda_i \\ge 0). Si possono indicare questi autovalori come \\lambda_i (o \\sigma_i^2 nel contesto delle varianze). Dalla relazione di diagonalizzazione si ottiene anche \\boldsymbol{\\Sigma} = \\mathbf{O} \\mathbf{D} \\mathbf{O}^T, poiché \\mathbf{O}^T \\mathbf{O} = \\mathbf{O} \\mathbf{O}^T = \\mathbf{I} (matrice identità) per matrici ortonormali.\n\nPassaggio 5: Costruzione di un Vettore Gaussiano Generale\nSi definisce un vettore aleatorio \\mathbf{x} tramite una trasformazione affine di un vettore di Gaussiane indipendenti (come in Passaggio 2). Si prende un vettore \\boldsymbol{\\mu} \\in \\mathbb{R}^n, una matrice simmetrica e semidefinita positiva \\boldsymbol{\\Sigma}, si diagonalizza \\boldsymbol{\\Sigma} per trovare \\mathbf{O} e \\mathbf{D} (con gli autovalori \\lambda_j sulla diagonale di \\mathbf{D}). Si costruisce il vettore \\mathbf{z} con componenti Z_j indipendenti, Z_j \\sim \\mathcal{N}(0, \\lambda_j). Si definisce \\mathbf{x} come: \\mathbf{x} = \\boldsymbol{\\mu} + \\mathbf{O} \\mathbf{z} Questo è un vettore aleatorio poiché \\mathbf{z} è aleatorio e \\boldsymbol{\\mu} e \\mathbf{O} sono costanti.\nPassaggio 6: Proposizione - Funzione Caratteristica del Vettore Costruito\nProposizione: La funzione caratteristica del vettore \\mathbf{x} = \\boldsymbol{\\mu} + \\mathbf{O} \\mathbf{z} (costruito come sopra, dove \\mathbf{z} ha componenti Z_j \\sim \\mathcal{N}(0, \\lambda_j) indipendenti e \\lambda_j sono gli autovalori di \\boldsymbol{\\Sigma}) è data da: \\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}\n\nDimostrazione (della Proposizione) Si usa la proprietà della funzione caratteristica per trasformazioni affini: per un vettore aleatorio \\mathbf{y} e costanti matriciali \\mathbf{A} e vettoriali \\mathbf{b}, la funzione caratteristica di \\mathbf{A}\\mathbf{y} + \\mathbf{b} è \\phi_{\\mathbf{A}\\mathbf{y} + \\mathbf{b}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\mathbf{b}} \\phi_{\\mathbf{y}}(\\mathbf{A}^T \\mathbf{t}). Nel nostro caso, \\mathbf{x} = \\mathbf{O}\\mathbf{z} + \\boldsymbol{\\mu}. Quindi \\mathbf{A} = \\mathbf{O} e \\mathbf{b} = \\boldsymbol{\\mu}. \\phi_{\\mathbf{x}}(\\mathbf{t}) = \\phi_{\\mathbf{O}\\mathbf{z} + \\boldsymbol{\\mu}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu}} \\phi_{\\mathbf{z}}(\\mathbf{O}^T \\mathbf{t}) Si sostituisce la forma della funzione caratteristica di \\mathbf{z} (da Passaggio 3), ricordando che le varianze sulla diagonale di \\mathbf{D} sono \\lambda_j: \\phi_{\\mathbf{z}}(\\mathbf{t}) = e^{-\\frac{1}{2} \\mathbf{t}^T \\mathbf{D} \\mathbf{t}} Sostituendo l’argomento \\mathbf{O}^T \\mathbf{t} al posto di \\mathbf{t}: \\phi_{\\mathbf{z}}(\\mathbf{O}^T \\mathbf{t}) = e^{-\\frac{1}{2} (\\mathbf{O}^T \\mathbf{t})^T \\mathbf{D} (\\mathbf{O}^T \\mathbf{t})} Si semplifica l’argomento dell’esponenziale: (\\mathbf{O}^T \\mathbf{t})^T \\mathbf{D} (\\mathbf{O}^T \\mathbf{t}) = \\mathbf{t}^T (\\mathbf{O}^T)^T \\mathbf{D} \\mathbf{O}^T \\mathbf{t} = \\mathbf{t}^T \\mathbf{O} \\mathbf{D} \\mathbf{O}^T \\mathbf{t} Richiamando la diagonalizzazione \\boldsymbol{\\Sigma} = \\mathbf{O} \\mathbf{D} \\mathbf{O}^T, l’espressione diventa: \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} Quindi, la funzione caratteristica di \\mathbf{x} è: \\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu}} e^{-\\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}} = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}} Questo completa la dimostrazione.\n\nSignificato della Proposizione Questo risultato dimostra che la funzione nella forma e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}, per un vettore \\boldsymbol{\\mu} e una matrice \\boldsymbol{\\Sigma} simmetrica e semidefinita positiva, è una funzione caratteristica valida. Non tutte le funzioni lo sono, anche se soddisfano proprietà minimali.\nPassaggio 7: Definizione Formale di Vettore Gaussiano Multivariato\nDefinizione: Un vettore aleatorio n-dimensionale \\mathbf{x} ha legge Gaussiana con parametri \\boldsymbol{\\mu} \\in \\mathbb{R}^n (vettore) e \\boldsymbol{\\Sigma} (n \\times n matrice simmetrica e semidefinita positiva) se la sua funzione caratteristica è: \\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}\n\nBen Definizione della Legge Gaussiana Multivariata Questa definizione è ben posta per due motivi:\n\nTeorema di Unicità: La legge di una variabile (o vettore) aleatoria è completamente caratterizzata dalla sua funzione caratteristica. Se due vettori aleatori hanno la stessa funzione caratteristica, hanno la stessa legge.\nEsistenza: La proposizione precedente (Passaggio 6) dimostra che esiste almeno un vettore aleatorio (quello costruito come \\boldsymbol{\\mu} + \\mathbf{O}\\mathbf{z}) che ha esattamente questa funzione caratteristica.\n\nInterpretazione della Costruzione La definizione e la costruzione mostrano che un vettore aleatorio Gaussiano è ottenuto a partire da variabili aleatorie scalari indipendenti Gaussiane (con varianze pari agli autovalori di \\boldsymbol{\\Sigma}) tramite una opportuna trasformazione lineare affine (una “frullata opportunamente”). Questa trasformazione consiste in una rotazione/scalatura data dalla matrice \\mathbf{O} (e dalla scelta delle varianze di \\mathbf{z}) e una traslazione data dal vettore \\boldsymbol{\\mu}. Come nel caso unidimensionale degenere, un vettore Gaussiano multivariato non è necessariamente assolutamente continuo; questo accade se la matrice \\boldsymbol{\\Sigma} è singolare (ovvero, se alcuni autovalori sono zero).\nPassaggio 8: Proprietà Fondamentale - Chiusura Rispetto a Trasformazioni Affini\nProposizione: Se \\mathbf{x} è un vettore Gaussiano n-dimensionale con parametri \\boldsymbol{\\mu} e \\boldsymbol{\\Sigma}, e \\mathbf{A} è una matrice m \\times n e \\mathbf{b} è un vettore m-dimensionale, allora il vettore aleatorio m-dimensionale \\mathbf{y} = \\mathbf{A}\\mathbf{x} + \\mathbf{b} è ancora un vettore Gaussiano. I suoi parametri sono:\n\nVettore medio: \\boldsymbol{\\mu}&#039; = \\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b}\nMatrice di covarianza: \\boldsymbol{\\Sigma}&#039; = \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^T\n\nQuesta proprietà è molto generale, vale anche per matrici \\mathbf{A} rettangolari (non necessariamente n \\times n) e include casi in cui il vettore risultante \\mathbf{y} è degenere (ad esempio, se m &lt; n o se \\mathbf{A} non ha rango pieno).\n\nDimostrazione (della Proprietà di Chiusura) Si calcola la funzione caratteristica di \\mathbf{y}: \\phi_{\\mathbf{y}}(\\mathbf{t}) = E[e^{i \\mathbf{t}^T \\mathbf{y}}] = E[e^{i \\mathbf{t}^T (\\mathbf{A}\\mathbf{x} + \\mathbf{b})}] = E[e^{i \\mathbf{t}^T \\mathbf{b}} e^{i \\mathbf{t}^T \\mathbf{A} \\mathbf{x}}] = e^{i \\mathbf{t}^T \\mathbf{b}} E[e^{i (\\mathbf{A}^T \\mathbf{t})^T \\mathbf{x}}] L’aspettazione è la funzione caratteristica di \\mathbf{x} valutata nel vettore \\mathbf{A}^T \\mathbf{t}. \\phi_{\\mathbf{x}}(\\boldsymbol{\\tau}) = e^{i \\boldsymbol{\\tau}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\boldsymbol{\\tau}^T \\boldsymbol{\\Sigma} \\boldsymbol{\\tau}} con \\boldsymbol{\\tau} = \\mathbf{A}^T \\mathbf{t}. Quindi: \\phi_{\\mathbf{y}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\mathbf{b}} e^{i (\\mathbf{A}^T \\mathbf{t})^T \\boldsymbol{\\mu} - \\frac{1}{2} (\\mathbf{A}^T \\mathbf{t})^T \\boldsymbol{\\Sigma} (\\mathbf{A}^T \\mathbf{t})} Si semplificano gli esponenti: (\\mathbf{A}^T \\mathbf{t})^T \\boldsymbol{\\mu} = \\mathbf{t}^T (\\mathbf{A}^T)^T \\boldsymbol{\\mu} = \\mathbf{t}^T \\mathbf{A} \\boldsymbol{\\mu} (\\mathbf{A}^T \\mathbf{t})^T \\boldsymbol{\\Sigma} (\\mathbf{A}^T \\mathbf{t}) = \\mathbf{t}^T (\\mathbf{A}^T)^T \\boldsymbol{\\Sigma} \\mathbf{A}^T \\mathbf{t} = \\mathbf{t}^T \\mathbf{A} \\boldsymbol{\\Sigma} \\mathbf{A}^T \\mathbf{t} Sostituendo nell’espressione per \\phi_{\\mathbf{y}}(\\mathbf{t}): \\phi_{\\mathbf{y}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\mathbf{b}} e^{i \\mathbf{t}^T \\mathbf{A} \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T (\\mathbf{A} \\boldsymbol{\\Sigma} \\mathbf{A}^T) \\mathbf{t}} Raccogliendo i termini nell’esponente: \\phi_{\\mathbf{y}}(\\mathbf{t}) = e^{i (\\mathbf{t}^T \\mathbf{b} + \\mathbf{t}^T \\mathbf{A} \\boldsymbol{\\mu}) - \\frac{1}{2} \\mathbf{t}^T (\\mathbf{A} \\boldsymbol{\\Sigma} \\mathbf{A}^T) \\mathbf{t}} \\phi_{\\mathbf{y}}(\\mathbf{t}) = e^{i \\mathbf{t}^T (\\mathbf{A} \\boldsymbol{\\mu} + \\mathbf{b}) - \\frac{1}{2} \\mathbf{t}^T (\\mathbf{A} \\boldsymbol{\\Sigma} \\mathbf{A}^T) \\mathbf{t}} Questa funzione caratteristica è esattamente nella forma della definizione di Gaussiana multivariata (Passaggio 7), con nuovi parametri \\boldsymbol{\\mu}&#039; = \\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b} e \\boldsymbol{\\Sigma}&#039; = \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^T. Questo dimostra che \\mathbf{y} è Gaussiana.\n\nPassaggio 9: Corollario - Combinazioni Lineari di Componenti\nCorollario: Se \\mathbf{x} = (X_1, ..., X_n)^T è un vettore Gaussiano n-dimensionale con parametri \\boldsymbol{\\mu} e \\boldsymbol{\\Sigma}, allora ogni combinazione lineare delle sue componenti, Y = \\sum_{j=1}^n a_j X_j + b, dove a_j e b sono costanti reali, è una variabile aleatoria\nGaussiana unidimensionale.\nQuesto corollario è un caso particolare della proprietà di chiusura per trasformazioni affini (Passaggio 8). Si considera il caso in cui la matrice \\mathbf{A} è un vettore riga 1 \\times n, \\mathbf{a} = (a_1, ..., a_n), e \\mathbf{b} è uno scalare b (visto come un vettore 1 \\times 1). Allora \\mathbf{y} = \\mathbf{A}\\mathbf{x} + \\mathbf{b} diventa lo scalare Y = \\mathbf{a}\\mathbf{x} + b = \\sum a_j X_j + b. I parametri della Gaussiana unidimensionale risultante sono:\n\nMedia: \\mu_Y = \\mathbf{a}\\boldsymbol{\\mu} + b = \\sum_{j=1}^n a_j \\mu_j + b. Questo si ottiene da \\mathbf{A}\\boldsymbol{\\mu} + \\mathbf{b} con \\mathbf{A}=\\mathbf{a} (vettore riga) e \\mathbf{b}=b (scalare). Il prodotto \\mathbf{a}\\boldsymbol{\\mu} è un prodotto scalare.\nVarianza: \\sigma_Y^2 = \\mathbf{a}\\boldsymbol{\\Sigma}\\mathbf{a}^T. Questo si ottiene da \\mathbf{A}\\boldsymbol{\\Sigma}\\mathbf{A}^T con \\mathbf{A}=\\mathbf{a}. Il prodotto \\mathbf{a}\\boldsymbol{\\Sigma}\\mathbf{a}^T è una forma quadratica. Se \\boldsymbol{\\Sigma} ha elementi \\Sigma_{ij}, questa forma quadratica è \\sum_{i=1}^n \\sum_{j=1}^n a_i \\Sigma_{ij} a_j.\n\nQuesto generalizza il risultato sulla somma di Gaussiane indipendenti al caso di componenti non necessariamente indipendenti. Un caso particolare di combinazione lineare è l’estrazione di una singola componente X_k (scegliendo a_k=1, a_j=0 per j \\neq k, b=0). Questo implica che le distribuzioni marginali di un vettore Gaussiano sono univariate Gaussiane.\n\nInterpretazione dei Parametri \\boldsymbol{\\mu} e \\boldsymbol{\\Sigma}\nLa proprietà di chiusura rispetto a trasformazioni affini e il corollario sulle combinazioni lineari permettono di interpretare i parametri \\boldsymbol{\\mu} e \\boldsymbol{\\Sigma} nella definizione di Gaussiana multivariata:\n\n\\boldsymbol{\\mu} è il vettore delle medie delle componenti del vettore Gaussiano. La sua j-esima componente \\mu_j è la media di X_j, E[X_j] = \\mu_j. (Si può dimostrare questo prendendo a_j=1, a_i=0 per i\\neq j, b=0 nel corollario, e la media è \\mu_j).\n\\boldsymbol{\\Sigma} è la matrice di covarianza del vettore Gaussiano. L’elemento \\Sigma_{ij} in posizione (i, j) è la covarianza tra X_i e X_j, \\text{Cov}(X_i, X_j) = E[(X_i - E[X_i])(X_j - E[X_j])] = E[(X_i - \\mu_i)(X_j - \\mu_j)]. Gli elementi sulla diagonale sono le varianze \\Sigma_{ii} = \\text{Var}(X_i) = \\sigma_i^2. (La formula per la varianza della combinazione lineare \\mathbf{a}\\boldsymbol{\\Sigma}\\mathbf{a}^T coincide con la formula generale per la varianza di una combinazione lineare di variabili aleatorie in termini della loro matrice di covarianza).\n\nPassaggio 10: Importanza della Distribuzione Gaussiana Multivariata\nIl “mondo Gaussiano” è “particolarmente bello” e importante in molte applicazioni di statistica e modellistica. Le ragioni includono:\n\nLa sua ubiquità, legata in parte al Teorema Centrale del Limite (che non è stato ancora affrontato in dettaglio in questo estratto, ma viene menzionato).\nLa sua “niceness” e semplicità di molte proprietà, prima fra tutte la chiusura rispetto a trasformazioni affini. Se si parte da un vettore Gaussiano e lo si trasforma linearmente (scalatura, rotazione) e lo si trasla, il risultato è ancora Gaussiano. Anche proiezioni o combinazioni lineari delle componenti risultano Gaussiane.\n\nQueste proprietà rendono i modelli basati sulla distribuzione Gaussiana multivariata gestibili e teoricamente trattabili in molti contesti.\n\nRipasso e Parametri della Gaussiana Multivariata\nQuando si definisce una Gaussiana multivariata, è necessario specificare due parametri. Il primo parametro è \\mu, che è un generico vettore. Il secondo parametro è \\Sigma, che è una generica matrice. Attenzione, questa matrice \\Sigma non è una matrice qualunque, ma deve essere una matrice simmetrica e semidefinita positiva. Il professore sottolinea che un tipico errore è dimenticare di controllare queste proprietà per la matrice \\Sigma.\nMomenti di una Gaussiana Multivariata\nSe un vettore aleatorio X è una Gaussiana di parametri \\mu e \\Sigma, il momento della componente j-esima non è altro che \\mu_j. La matrice di varianze e covarianze di X è proprio \\Sigma.\nCome si può vedere questo? Partiamo da un lemma precedente (non fornito nella fonte completa, ma citato come base) secondo cui si può scrivere X nella forma: X = \\mu + O Z dove O è una matrice ortonormale (tale per cui O^{-1} = O^T) e D è una matrice diagonale con gli autovalori di \\Sigma, e vale la relazione O^T \\Sigma O = D (o equivalentemente \\Sigma = O D O^T). Z è un vettore Gaussiano “particolare”. Questo vettore Z è costruito in modo tale che le sue componenti Z_j sono Gaussiane unidimensionali. In questo caso particolare, le componenti Z_j hanno media 0 e varianza \\lambda_j^2, dove \\lambda_j sono gli autovalori di \\Sigma (quindi gli elementi sulla diagonale di D). Pertanto, il vettore delle medie di Z, E[Z], è un vettore di zeri.\n\nCalcolo del Vettore delle Medie E[X]\nUsando la proprietà di linearità del valore atteso per vettori: E[X] = E[\\mu + O Z] E[X] = E[\\mu] + E[O Z] Poiché \\mu è un vettore costante, E[\\mu] = \\mu. E[O Z] = O E[Z] Abbiamo detto che E[Z] è il vettore degli zeri. O E[Z] = O \\mathbf{0} = \\mathbf{0} (moltiplicando un vettore di zeri per una matrice si ottiene il vettore di zeri). Quindi: E[X] = \\mu + \\mathbf{0} = \\mu Questo dimostra che il vettore delle medie di X è \\mu, e componente per componente E[X_j] = \\mu_j.\nCalcolo della Matrice di Varianze e Covarianze \\Sigma_X\nUsando le proprietà delle matrici di varianze e covarianze: La matrice di varianze e covarianze è invariante per traslazioni. Quindi \\Sigma_X = \\Sigma_{X-\\mu}. \\Sigma_X = \\Sigma_{O Z} Una proprietà della matrice di covarianza di una trasformazione lineare AY è A \\Sigma_Y A^T. In questo caso A=O e Y=Z. \\Sigma_{O Z} = O \\Sigma_Z O^T La matrice di varianze e covarianze di Z, \\Sigma_Z, è una matrice diagonale perché le componenti Z_j sono indipendenti (costruzione del lemma). Fuori dalla diagonale, la covarianza è zero perché l’indipendenza implica covarianza nulla. Sulla diagonale ci sono le varianze, che sono \\lambda_j^2. Quindi \\Sigma_Z = D, dove D è la matrice diagonale degli autovalori. \\Sigma_X = O D O^T Sappiamo dalla costruzione che \\Sigma = O D O^T. Quindi: \\Sigma_X = \\Sigma Questo dimostra che la matrice di varianze e covarianze di X è \\Sigma. La matrice \\Sigma non è una qualunque matrice, ma deve essere simmetrica e semidefinita positiva.\n\nProposizione 1: Sottovettori di una Gaussiana Multivariata\nEnunciato: Se X è un vettore n-dimensionale Gaussiano di parametri \\mu e \\Sigma, allora qualunque sottovettore di X è Gaussiano. Le distribuzioni marginali di una Gaussiana sono tutte Gaussiane. Questo è vero a vari gradi (quindi anche prendendo più componenti).\nParametri del Sottovettore\nSe si prende un sottovettore di indici I = {i_1, i_2, \\dots, i_k}: Il vettore delle medie del sottovettore X_I, \\mu_I, è semplicemente il sottovettore di \\mu che contiene le componenti \\mu_j con j \\in I. La matrice di varianze e covarianze del sottovettore X_I, \\Sigma_I, è la matrice che si ottiene incrociando le righe e le colonne della matrice \\Sigma con gli indici contenuti in I. Prendete la matrice \\Sigma e selezionate solo le righe e le colonne corrispondenti agli indici i_1, \\dots, i_k.\n\nDimostrazione della Proposizione 1 (Idea generale usando Funzioni Caratteristiche)\nLa dimostrazione di questa proposizione si basa sulla proprietà di unicità della funzione caratteristica: se due variabili aleatorie (o vettori aleatori) hanno la stessa funzione caratteristica, allora hanno la stessa legge (distribuzione).\nLa funzione caratteristica di un vettore Gaussiano n-dimensionale \\mathbf{x} con parametri \\boldsymbol{\\mu} e \\boldsymbol{\\Sigma}, calcolata in un vettore \\mathbf{t} = (t_1, ..., t_n)^T \\in \\mathbb{R}^n, è data da: \\phi_{\\mathbf{x}}(\\mathbf{t}) = E[e^{i \\mathbf{t}^T \\mathbf{x}}] = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}.\nConsideriamo prima il caso più semplice e fondamentale: la dimostrazione che una singola componente X_k (una marginale) è Gaussiana. La funzione caratteristica di una singola componente X_k, \\phi_{X_k}(u), dove u è uno scalare, può essere ottenuta dalla funzione caratteristica congiunta del vettore \\mathbf{x}. Per definizione, \\phi_{X_k}(u) = E[e^{i u X_k}]. Questo è equivalente a valutare la funzione caratteristica congiunta \\phi_{\\mathbf{x}}(\\mathbf{t}) nel vettore \\mathbf{t} che ha la componente k-esima uguale a u e tutte le altre componenti uguali a zero. Ossia, poniamo \\mathbf{t} = (0, ..., 0, u_k=u, 0, ..., 0)^T (dove u è nella posizione k-esima).\nSostituendo questo vettore \\mathbf{t} nella formula della funzione caratteristica congiunta: \\phi_{X_k}(u) = \\phi_{\\mathbf{x}}(0, ..., u_k=u, ..., 0) = e^{i (0, ..., u, ..., 0)^T \\boldsymbol{\\mu} - \\frac{1}{2} (0, ..., u, ..., 0)^T \\boldsymbol{\\Sigma} (0, ..., u, ..., 0)}.\nAnalizziamo i due termini nell’esponente:\n\ni \\mathbf{t}^T \\boldsymbol{\\mu} = i (0, ..., u, ..., 0) \\begin{pmatrix} \\mu_1 \\\\ \\vdots \\\\ \\mu_k \\\\ \\vdots \\\\ \\mu_n \\end{pmatrix}. Questo prodotto scalare seleziona solo la componente k-esima di \\boldsymbol{\\mu} moltiplicata per u. Quindi, i \\mathbf{t}^T \\boldsymbol{\\mu} = i u \\mu_k.\n\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} = (0, ..., u, ..., 0) \\begin{pmatrix} \\Sigma_{11} &amp; \\dots &amp; \\Sigma_{1k} &amp; \\dots &amp; \\Sigma_{1n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\Sigma_{k1} &amp; \\dots &amp; \\Sigma_{kk} &amp; \\dots &amp; \\Sigma_{kn} \\\\ \\vdots &amp; \\ddots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\Sigma_{n1} &amp; \\dots &amp; \\Sigma_{nk} &amp; \\dots &amp; \\Sigma_{nn} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ \\vdots \\\\ u \\\\ \\vdots \\\\ 0 \\end{pmatrix}. Quando si esegue questo prodotto, il vettore riga (0, ..., u, ..., 0) seleziona la riga k-esima di \\boldsymbol{\\Sigma} moltiplicata per u. Il risultato è u \\cdot (\\Sigma_{k1}, \\dots, \\Sigma_{kk}, \\dots, \\Sigma_{kn}). Moltiplicando questo vettore riga per il vettore colonna (0, ..., u, ..., 0)^T, si seleziona solo la componente k-esima del vettore riga, che è \\Sigma_{kk}, moltiplicata per u. Quindi, \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} = u \\cdot (\\Sigma_{k1}, \\dots, \\Sigma_{kk}, \\dots, \\Sigma_{kn}) \\begin{pmatrix} 0 \\\\ \\vdots \\ u \\\\ \\vdots \\\\ 0 \\end{pmatrix} = u \\cdot (u \\Sigma_{kk}) = u^2 \\Sigma_{kk}.\n\nSostituendo questi termini nell’esponente, otteniamo la funzione caratteristica di X_k: \\phi_{X_k}(u) = e^{i u \\mu_k - \\frac{1}{2} u^2 \\Sigma_{kk}}.\nQuesta è esattamente la funzione caratteristica di una variabile aleatoria Gaussiana unidimensionale con media \\mu_k e varianza \\Sigma_{kk}. Poiché la funzione caratteristica di X_k corrisponde a quella di una Gaussiana unidimensionale, per il teorema di unicità, X_k è una variabile aleatoria Gaussiana unidimensionale.\nLa dimostrazione per un sottovettore X_I di dimensione k &gt; 1 segue la stessa logica ed è stata descritta come “un filino più laboriosa” ma concettualmente identica. Per ottenere la funzione caratteristica del sottovettore X_I = (X_{i_1}, \\dots, X_{i_k})^T calcolata in un vettore \\mathbf{u} = (u_1, \\dots, u_k)^T, si valuta la funzione caratteristica congiunta del vettore completo \\mathbf{x} in un vettore \\mathbf{t} \\in \\mathbb{R}^n dove le componenti t_j sono nulle se j \\notin I, e sono uguali alle corrispondenti componenti di \\mathbf{u} se j \\in I. Ossia, se j = i_m per qualche m \\in {1, \\dots, k}, allora t_j = u_m, altrimenti t_j = 0.\nLa funzione caratteristica di X_I è \\phi_{X_I}(\\mathbf{u}) = E[e^{i \\mathbf{u}^T X_I}]. Questo è uguale a E[e^{i \\sum_{m=1}^k u_m X_{i_m}}], che è la funzione caratteristica di \\mathbf{x} valutata nel vettore \\mathbf{t} descritto sopra. \\phi_{X_I}(\\mathbf{u}) = \\phi_{\\mathbf{x}}(\\mathbf{t}).\nSostituendo questo vettore \\mathbf{t} (con zeri nelle posizioni fuori da I e componenti di \\mathbf{u} nelle posizioni indicate da I) nella formula della funzione caratteristica congiunta \\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}, si ottiene:\n\ni \\mathbf{t}^T \\boldsymbol{\\mu}: Questo prodotto selezionerà solo le componenti di \\boldsymbol{\\mu} corrispondenti agli indici in I, moltiplicate per le rispettive componenti di \\mathbf{u}. Il risultato è i \\mathbf{u}^T \\boldsymbol{\\mu}_I, dove \\boldsymbol{\\mu}_I è il sottovettore di \\boldsymbol{\\mu} con le componenti indicate da I.\n\\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}: Questo prodotto seleziona la forma quadratica definita dalla sottomatrice di \\boldsymbol{\\Sigma} corrispondente agli indici in I, applicata al vettore \\mathbf{u}. Il risultato è \\mathbf{u}^T \\boldsymbol{\\Sigma}_I \\mathbf{u}, dove \\boldsymbol{\\Sigma}_I è la sottomatrice di \\boldsymbol{\\Sigma} ottenuta incrociando righe e colonne con indici in I.\n\nQuindi, la funzione caratteristica del sottovettore X_I è: \\phi_{X_I}(\\mathbf{u}) = e^{i \\mathbf{u}^T \\boldsymbol{\\mu}_I - \\frac{1}{2} \\mathbf{u}^T \\boldsymbol{\\Sigma}_I \\mathbf{u}}.\nQuesta è esattamente la forma della funzione caratteristica di un vettore Gaussiano k-dimensionale con vettore delle medie \\boldsymbol{\\mu}_I e matrice di varianze e covarianze \\boldsymbol{\\Sigma}_I. Per il teorema di unicità, il sottovettore X_I segue una distribuzione Gaussiana con questi parametri.\nLe fonti indicano che la dimostrazione dettagliata per il caso generale del sottovettore, sebbene concettualmente simile a quella della singola componente, non è stata formalmente completata nelle lezioni per intero con tutte le notazioni, ma l’idea di “selezionare la sottomatrice” è stata esplicitata. Questo risultato conferma che tutte le marginali di un vettore Gaussiano (singole componenti o sottovettori) sono esse stesse Gaussiane.\n\nCaso generale (più componenti): Se si considerano k componenti (k&gt;1), si fa la stessa cosa ma il vettore t avrà k elementi non nulli. La forma quadratica t^T \\Sigma t seleziona la sottomatrice \\Sigma_I corrispondente agli indici I delle componenti scelte, e il prodotto scalare t^T \\mu seleziona il sottovettore \\mu_I. La conclusione è la stessa: si ottiene la funzione caratteristica di una Gaussiana di dimensione k con parametri \\mu_I e \\Sigma_I.\nQuesto spiega la Proposizione 1: le marginali (sottovettori) sono Gaussiane.\nProposizione 2: Indipendenza delle Componenti e Matrice di Covarianza\nEnunciato (Punto 2 come chiamato nella fonte, o Punto 3 come chiamato nella fonte): Il vettore Gaussiano X ha componenti indipendenti se e solo se la sua matrice di varianze e covarianze \\Sigma è una matrice diagonale. Corollario (Punto 2 bis nella fonte, parte del Punto 3 nella fonte): Due componenti X_{i_1} e X_{i_2} di un vettore Gaussiano X sono indipendenti se e solo se l’elemento \\sigma_{i_1, i_2} (cioè la covarianza tra X_{i_1} e X_{i_2}) è uguale a 0. Il professore sottolinea che questa è un’affermazione forte. In generale, la covarianza nulla non implica indipendenza, ma nel mondo Gaussiano sì. Se si sa che due componenti Gaussiane hanno covarianza nulla, si può concludere che sono indipendenti.\n\nEsempio con Matrice 3x3\nConsideriamo un vettore Gaussiano X = (X_1, X_2, X_3) con vettore delle medie \\mu = (0, 0, 0) e una matrice di covarianza \\Sigma data da: \\Sigma = \\begin{pmatrix} \\Sigma_{11} &amp; \\Sigma_{12} &amp; \\Sigma_{13} \\\\ \\Sigma_{21} &amp; \\Sigma_{22} &amp; \\Sigma_{23} \\\\ \\Sigma_{31} &amp; \\Sigma_{32} &amp; \\Sigma_{33} \\end{pmatrix} Sappiamo che \\Sigma è simmetrica, quindi \\Sigma_{ij} = \\Sigma_{ji}. La covarianza tra X_i e X_j è \\Sigma_{ij}.\nSupponiamo di avere la seguente matrice \\Sigma (esempio del professore): \\Sigma = \\begin{pmatrix} \\Sigma_{11} &amp; 0 &amp; \\Sigma_{13} \\\\ 0 &amp; \\Sigma_{22} &amp; \\Sigma_{23} \\\\ \\Sigma_{31} &amp; \\Sigma_{32} &amp; \\Sigma_{33} \\end{pmatrix} Guardando gli elementi fuori dalla diagonale (che rappresentano le covarianze tra diverse componenti):\n\n\\Sigma_{12} = 0 (e \\Sigma_{21}=0 per simmetria). Questo significa che la covarianza tra X_1 e X_2 è zero. Poiché X_1 e X_2 sono componenti di un vettore Gaussiano (quindi marginalmente Gaussiane per la Proposizione 1), la covarianza nulla implica indipendenza. Quindi, X_1 e X_2 sono indipendenti.\n\\Sigma_{13} \\ne 0 (nell’esempio grafico del professore, anche se non è specificato un valore numerico, è rappresentato come non zero). Questo significa che la covarianza tra X_1 e X_3 non è zero. Quindi, X_1 e X_3 non sono indipendenti.\n\\Sigma_{23} \\ne 0. Questo significa che la covarianza tra X_2 e X_3 non è zero. Quindi, X_2 e X_3 non sono indipendenti.\n\nQuesto esempio mostra come si può determinare l’indipendenza tra le componenti di un vettore Gaussiano semplicemente guardando se gli elementi fuori dalla diagonale della matrice di covarianza \\Sigma sono zero. Questa proprietà è molto utile negli esercizi, specialmente nei quesiti vero/falso.\n\nDimostrazione della Proposizione 2 (Idea generale usando Funzioni Caratteristiche)\nLa dimostrazione si basa principalmente sull’uso della funzione caratteristica del vettore aleatorio \\mathbf{x} e sul teorema di unicità della funzione caratteristica, che afferma che due variabili (o vettori) aleatorie con la stessa funzione caratteristica hanno la stessa distribuzione. Inoltre, si utilizza il criterio che lega l’indipendenza delle componenti di un vettore aleatorio alla fattorizzazione della sua funzione caratteristica congiunta nel prodotto delle funzioni caratteristiche marginali.\nProcediamo con la dimostrazione in due parti, date dall’enunciato “se e solo se”:\nParte 1: Se le componenti X_1, \\dots, X_n sono indipendenti, allora la matrice \\boldsymbol{\\Sigma} è diagonale.\nQuesto è il lato “facile” dell’implicazione, valido per qualsiasi tipo di variabili aleatorie, non solo Gaussiane. La matrice di varianze e covarianze \\boldsymbol{\\Sigma} ha come elementi \\Sigma_{ij} = \\text{Cov}(X_i, X_j). Per definizione di indipendenza, se due variabili aleatorie X_i e X_j (con i \\neq j) sono indipendenti, la loro covarianza è nulla: \\text{Cov}(X_i, X_j) = E[(X_i - E[X_i])(X_j - E[X_j])] = 0. Dato che stiamo considerando le componenti X_1, \\dots, X_n come indipendenti, questo significa che \\text{Cov}(X_i, X_j) = \\Sigma_{ij} = 0 per ogni i \\neq j. Gli elementi sulla diagonale della matrice \\boldsymbol{\\Sigma} sono le varianze delle singole componenti: \\Sigma_{ii} = \\text{Var}(X_i). Questi elementi non sono necessariamente zero (a meno di casi degeneri in cui la componente è una costante, ma anche in quel caso la varianza è la parte diagonale corretta). Pertanto, se tutte le covarianze fuori dalla diagonale sono zero, la matrice \\boldsymbol{\\Sigma} è, per definizione, una matrice diagonale. Questo dimostra la prima parte.\n\nParte 2: Se la matrice \\boldsymbol{\\Sigma} è diagonale, allora le componenti X_1, \\dots, X_n sono indipendenti.\nQuesta è la parte più significativa per i vettori Gaussiani, e la dimostrazione si basa sull’uso della funzione caratteristica. La funzione caratteristica di un vettore Gaussiano \\mathbf{x} con parametri \\boldsymbol{\\mu} e \\boldsymbol{\\Sigma}, calcolata in un vettore \\mathbf{t} = (t_1, \\dots, t_n)^T \\in \\mathbb{R}^n, è data da: \\phi_{\\mathbf{x}}(\\mathbf{t}) = E[e^{i \\mathbf{t}^T \\mathbf{x}}] = e^{i \\mathbf{t}^T \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}}.\nAssumiamo che \\boldsymbol{\\Sigma} sia una matrice diagonale. Questo significa che gli elementi fuori dalla diagonale sono zero (\\Sigma_{ij} = 0 per i \\neq j), e gli elementi sulla diagonale sono le varianze \\Sigma_{ii}. Il primo termine nell’esponente è il prodotto scalare i \\mathbf{t}^T \\boldsymbol{\\mu}. Questo è semplicemente i \\sum_{j=1}^n t_j \\mu_j. Il secondo termine nell’esponente, \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t}, è una forma quadratica. Se \\boldsymbol{\\Sigma} è diagonale, con elementi \\Sigma_{jj} sulla diagonale, questo prodotto si semplifica notevolmente. In forma matriciale, \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} = \\sum_{i=1}^n \\sum_{j=1}^n t_i \\Sigma_{ij} t_j. Poiché \\Sigma_{ij} = 0 per i \\neq j, rimangono solo i termini per cui i = j: \\mathbf{t}^T \\boldsymbol{\\Sigma} \\mathbf{t} = \\sum_{j=1}^n t_j \\Sigma_{jj} t_j = \\sum_{j=1}^n \\Sigma_{jj} t_j^2. (Nota: le fonti usano anche la notazione \\sigma_j^2 o \\sigma_{jj}^2 per gli elementi diagonali di \\boldsymbol{\\Sigma} in contesti specifici, ma il significato è lo stesso: la varianza della j-esima componente).\nSostituendo questi termini nell’esponente della funzione caratteristica congiunta, otteniamo: \\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{i \\sum_{j=1}^n t_j \\mu_j - \\frac{1}{2} \\sum_{j=1}^n \\Sigma_{jj} t_j^2}.\nOra, possiamo riscrivere l’esponente come una somma e quindi l’intera espressione come un prodotto di esponenziali: \\phi_{\\mathbf{x}}(\\mathbf{t}) = e^{\\sum_{j=1}^n (i t_j \\mu_j - \\frac{1}{2} \\Sigma_{jj} t_j^2)} = \\prod_{j=1}^n e^{i t_j \\mu_j - \\frac{1}{2} \\Sigma_{jj} t_j^2}.\nOgni fattore nel prodotto, e^{i t_j \\mu_j - \\frac{1}{2} \\Sigma_{jj} t_j^2}, è esattamente la funzione caratteristica di una variabile aleatoria Gaussiana unidimensionale con media \\mu_j e varianza \\Sigma_{jj}. Queste sono le funzioni caratteristiche marginali \\phi_{X_j}(t_j) delle singole componenti X_j. Quindi, abbiamo dimostrato che se \\boldsymbol{\\Sigma} è diagonale, la funzione caratteristica congiunta del vettore \\mathbf{x} è uguale al prodotto delle funzioni caratteristiche marginali delle sue componenti: \\phi_{\\mathbf{x}}(\\mathbf{t}) = \\prod_{j=1}^n \\phi_{X_j}(t_j) per ogni \\mathbf{t} \\in \\mathbb{R}^n.\nPer il criterio che lega l’indipendenza alla funzione caratteristica, questa fattorizzazione implica che le componenti X_1, \\dots, X_n sono indipendenti.\nQuesto completa la dimostrazione della Proposizione 2, confermando che per un vettore Gaussiano, l’indipendenza delle componenti è equivalente alla matrice di varianze e covarianze essere diagonale. Questa è una delle “cose belle” e semplificanti del “mondo Gaussiano”.\nCorollario correlato (Punto 3 o 2 bis): Se si prendono due singole componenti X_i e X_j da un vettore Gaussiano (che formano un sottovettore Gaussiano di dimensione 2 per la Proposizione 1, non dimostrata formalmente ma discussa nelle fonti), esse sono indipendenti se e solo se la loro covarianza \\Sigma_{ij} è zero. Questo discende direttamente dalla Proposizione 2 applicata al sottovettore (X_i, X_j)^T, la cui matrice di covarianza è una sottomatrice 2 \\times 2 di \\boldsymbol{\\Sigma} contenente \\Sigma_{ii}, \\Sigma_{ij}, \\Sigma_{ji}, \\Sigma_{jj}. Se questa sottomatrice è diagonale (cioè \\Sigma_{ij} = \\Sigma_{ji} = 0), le due componenti sono indipendenti.\n\nVettori Gaussiani Multivariati: Densità, Degenerazione e Rappresentazioni\n1. Vettori Gaussiani Assolutamente Continui\nUn punto fondamentale è comprendere la condizione che rende un vettore gaussiano “assolutamente continuo”.\n\n\nDefinizione/Proprietà Fondamentale:\n\nUn vettore aleatorio gaussiano X (a valori in \\mathbb{R}^n) è assolutamente continuo se e solo se la sua matrice di covarianza \\Sigma è strettamente definita positiva.\nQuesto significa che \\Sigma non può avere autovalori nulli.\nSe una matrice è strettamente definita positiva, allora è automaticamente invertibile.\n\n\n\nDensità di Probabilità:\n\nNel caso in cui X sia assolutamente continuo (cioè \\Sigma è strettamente definita positiva), la sua densità di probabilità f_X(x) è data da una formula specifica: f_X(x) = c \\cdot e^{-\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu)} dove:\n\nx è il vettore di variabili in \\mathbb{R}^n.\n\\mu è il vettore delle medie di X.\n\\Sigma^{-1} è la matrice inversa della matrice di covarianza \\Sigma.\nc è una costante di normalizzazione (spesso specificata come 1 / (\\sqrt{(2\\pi)^n \\det(\\Sigma)}) ) (Questo dettaglio sulla costante c non è esplicitamente dato nelle fonti, ma è la formula completa; le fonti si concentrano sulla forma esponenziale).\n\n\nIl termine nell’esponente, (x - \\mu)^T \\Sigma^{-1} (x - \\mu), è una forma quadratica.\nSpiegazione: L’inclusione di \\Sigma^{-1} nella formula della densità è cruciale e distingue il caso multivariato da quello unidimensionale in un modo specifico.\n\n\n\n\nConfronto con il Caso Unidimensionale (n=1):\n\nConsideriamo il caso semplice in cui n=1, cioè X è una singola variabile gaussiana X \\sim N(\\mu, \\sigma^2).\nLa matrice di covarianza \\Sigma si riduce allo scalare \\sigma^2.\nLa densità della gaussiana unidimensionale è proporzionale a e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}.\nPossiamo riscrivere l’esponente come -\\frac{1}{2} (x-\\mu) (\\sigma^2)^{-1} (x-\\mu). Qui (\\sigma^2)^{-1} è semplicemente 1/\\sigma^2.\nAnalogia: Questa riscrittura rende chiara l’analogia con il caso multivariato: lo scalare \\sigma^2 corrisponde alla matrice \\Sigma, e il suo inverso (\\sigma^2)^{-1} corrisponde all’inverso matriciale \\Sigma^{-1}.\nPunto di Attenzione: È fondamentale non confondere \\Sigma con \\Sigma^{-1}. Nelle formule standard:\n\nLa funzione caratteristica di un vettore gaussiano X è e^{i t^T \\mu - \\frac{1}{2} t^T \\Sigma t} (la parte di media nulla e^{-t^T \\Sigma t / 2} è menzionata). Questa formula usa \\Sigma.\nLa densità di probabilità (per il caso assolutamente continuo) usa \\Sigma^{-1}.\n\n\nCondizione di Invertibilità: La matrice \\Sigma^{-1} è definita solo se \\Sigma è invertibile. La matrice di covarianza \\Sigma è invertibile se e solo se è strettamente definita positiva.\n\n\n\n\nDimostrazione (Cenni):\n\nLa dimostrazione della relazione tra assoluta continuità, matrice \\Sigma strettamente definita positiva e la forma specifica della densità non viene svolta in dettaglio.\nViene menzionato che si basa su un cambio di variabile.\nL’enunciato è diviso idealmente in due parti: l’assoluta continuità e la forma della densità.\n\n\n\n2. Caso Degenerato: \\Sigma non strettamente definita positiva\nCosa succede se la matrice di covarianza \\Sigma non è strettamente definita positiva?\n\n\nProprietà:\n\nSe \\Sigma è solo semidefinita positiva (ossia ha almeno un autovalore nullo), il vettore gaussiano X non è assolutamente continuo.\nQuesto perché \\Sigma^{-1} non è definita in questo caso.\n\n\n\nConcentrazione su un Sottospazio:\n\nIn questo caso degenere, il vettore X è concentrato (con probabilità 1) su un iperpiano (un sottospazio lineare, possibilmente traslato dalla media \\mu).\nLa dimensione di questo sottospazio è strettamente minore della dimensione n dello spazio ambiente \\mathbb{R}^n.\nLa dimensione di questo sottospazio è esattamente uguale al rango di \\Sigma.\n\n\n\nEsempio Unidimensionale (n=1):\n\nL’unico caso degenere in dimensione 1 è quando la varianza \\sigma^2 è uguale a 0.\nIn questo caso, la variabile aleatoria collassa su un punto (la sua media \\mu).\nLa dimensione del sottospazio è 0, che è strettamente minore di n=1. Questo corrisponde al rango di \\Sigma=0, che è 0.\n\n\n\nEsempio Multidimensionale:\n\nIn più dimensioni, se \\Sigma non è definita positiva, la distribuzione gaussiana “collassa” su un sottospazio.\nQuesto sottospazio è lineare (traslato da \\mu).\nLa sua dimensione è data dal rango di \\Sigma. Ad esempio, in \\mathbb{R}^4, una gaussiana degenere può essere concentrata su un sottospazio di dimensione 3, 2, 1 o 0, a seconda del rango di \\Sigma.\n\n\n\nImportanza: Questo concetto, pur essendo a volte considerato solo per “cultura” e potenzialmente non strettamente “in programma”, è importante per capire il comportamento dei vettori gaussiani quando la matrice di covarianza non è invertibile.\n\n\n3. Rappresentazioni e Trasformazioni Lineari dei Vettori Gaussiani\nIl Caso Degenerato: \\Sigma non Strettamente Definita Positiva\nQuesto è il caso in cui \\Sigma è simmetrica e semidefinita positiva, ma non strettamente definita positiva. Ciò significa che \\Sigma ha almeno un autovalore uguale a zero.\nConseguenza Principale: Se \\Sigma non è strettamente definita positiva, il vettore gaussiano X non è assolutamente continuo. Di conseguenza, non ammette una densità di probabilità nel senso usuale. La formula della densità con \\Sigma^{-1} non è applicabile perché \\Sigma non è invertibile.\nDove si Concentra la Probabilità?\nProposizione (non dimostrata nell’audio, forse non in programma): Se X è un vettore gaussiano di parametri \\mu e \\Sigma e \\Sigma non è strettamente definita positiva (ha autovalori nulli), allora X è concentrato con probabilità 1 su un iperpiano (o sottospazio lineare traslato dalla media \\mu) di dimensione strettamente minore di n. La dimensione di questo iperpiano è uguale al rango della matrice \\Sigma.\nCommento e Esempio Concettuale: Questa affermazione spiega perché la gaussiana “collassa” in un caso degenere.\n\n\nEsempio 1D: Nel caso unidimensionale (n=1), l’unico caso degenere è \\Sigma = \\sigma^2 = 0. La matrice \\Sigma è la matrice 1 \\times 1 con elemento 0. Il suo rango è 0. La proposizione dice che la gaussiana è concentrata su un iperpiano di dimensione 0. Un iperpiano di dimensione 0 in \\mathbb{R}^1 è un punto. Infatti, in questo caso, la variabile aleatoria X è la costante \\mu, che è concentrata sul punto \\mu. La dimensione 0 è n - (\\text{numero di autovalori nulli}) = 1 - 1 = 0 o anche uguale al rango di \\Sigma (che è 0).\n\n\nEsempio Multidimensionale (Concettuale): Pensiamo alla costruzione X = \\mu + O Z dove Z ha componenti indipendenti Z_j \\sim N(0, \\lambda_j^2). Se \\Sigma ha k &gt; 0 autovalori nulli, allora k dei \\lambda_j^2 sono zero. Questo significa che k delle componenti Z_j sono variabili aleatorie degenerate, concentrate su 0. Il vettore Z vive in \\mathbb{R}^n, ma le sue k componenti con varianza zero sono fisse a 0. Questo “vincola” Z a un sottospazio di \\mathbb{R}^n di dimensione n-k. Quando applichiamo la trasformazione lineare OZ (una rotazione/riflessione) e la traslazione \\mu, il vettore risultante X rimane confinato in un sottospazio affine (iperpiano) traslato, la cui dimensione è n-k, che è anche il rango di \\Sigma.\n\n\nCorollario Concettuale (Legato al Caso Degenerato): Come osservato da uno studente, se abbiamo un vettore gaussiano X \\sim N(\\mu, \\Sigma), possiamo studiarlo in un sistema di riferimento diverso. Considerando la trasformazione Y = O^T (X - \\mu), dove O diagonalizza \\Sigma. Sappiamo che X = \\mu + O Z, quindi X - \\mu = O Z. Allora Y = O^T (O Z) = (O^T O) Z = I Z = Z. Questo significa che il vettore Y ha la stessa legge del vettore Z, le cui componenti sono indipendenti Z_j \\sim N(0, \\lambda_j^2). Se \\Sigma è degenere, alcuni \\lambda_j^2 sono nulli. Quindi, alcune componenti di Y (e quindi di Z) sono degenerate (costanti uguali a 0). Questa trasformazione lineare (sottrarre la media e “ruotare” con O^T) permette di “vedere” la struttura intrinseca della gaussiana: un insieme di variabili indipendenti (alcune non degenerate, altre costanti). Il fatto che alcune siano costanti è la manifestazione della degenerazione e della concentrazione su un sottospazio di dimensione inferiore.\nNon Unicità della Rappresentazione X = \\mu + A Z_0\nUn aspetto correlato alla struttura di \\Sigma (anche nel caso non degenere) è che, mentre la legge gaussiana è unicamente determinata da \\mu e \\Sigma (tramite la CF), la costruzione tramite trasformazione di variabili gaussiane indipendenti non è unica. Possiamo ottenere un vettore gaussiano X \\sim N(\\mu, \\Sigma) anche partendo da un vettore Z_0 di variabili standard normali indipendenti Z_0 \\sim N(0, I) (dove I è l’identità, \\text{Cov}(Z_0) = I) e applicando una trasformazione affine X = \\mu + A Z_0.\nLa matrice di covarianza di X in questo caso è \\text{Cov}(X) = A \\text{Cov}(Z_0) A^T = A I A^T = A A^T. Per ottenere X \\sim N(\\mu, \\Sigma), dobbiamo avere A A^T = \\Sigma. Il punto chiave è che, per una data \\Sigma, l’equazione matriciale A A^T = \\Sigma può avere molteplici soluzioni per la matrice A. Ad esempio, la decomposizione di Cholesky o la “radice quadrata” della matrice \\Sigma (se \\Sigma è definita positiva) sono alcune possibili soluzioni per A, ma non sono le uniche, specialmente se A non è richiesta essere simmetrica o definita positiva. Questo significa che si può generare lo stesso vettore gaussiano \\Sigma in modi diversi, usando matrici A differenti, anche se si parte sempre da variabili standard normali indipendenti. Questa è un’altra sottigliezza del mondo gaussiano che deriva dalle proprietà della matrice \\Sigma.\n\n\nIn sintesi, la degenerazione di un vettore gaussiano multivariato (quando \\Sigma non è strettamente definita positiva) implica che esso non è assolutamente continuo, non ha densità, e concentra tutta la sua probabilità su un sottospazio di dimensione inferiore a n, determinata dal rango di \\Sigma. Questo comportamento è intrinsecamente legato alla presenza di autovalori nulli nella matrice di covarianza \\Sigma.\nReferences"},"6--full-note/settimana-1":{"slug":"6--full-note/settimana-1","filePath":"6- full note/settimana 1.md","title":"settimana 1","links":["tags/settimana_in_corso","3--tag/sbobine","6--full-note/MateNum--Lez01","6--full-note/mateNum--Lez02","Matenum--Lab00","6--full-note/Prob--Lez01'","6--full-note/Prob--Lez02","6--full-note/Prob--Lez03","6--full-note/prob--Lez04","6--full-note/fisica-1---Lez01","6--full-note/Fisica1---Ese01","6--full-note/fisica-1--Lez02","6--full-note/fisica1--Lez03","6--full-note/fisica-lez03'","6--full-note/Analisi3--Lez07","6--full-note/Autm---Lez01","6--full-note/Autm---Lez02","6--full-note/Edp---Lez01","6--full-note/Edp--Lez02","6--full-note/Edp--Lez03","6--full-note/Edp--Lez04"],"tags":["settimana_in_corso"],"content":"2025-03-04 17:45\n_Status: settimana_in_corso\n_Tags: sbobine\nSettimana 1\n\nMatematica numerica\n\nprima lezione inutile\nMateNum- Lez01\nmateNum- Lez02\nMatenum- Lab00*\n\n\nProbabilità\n\nProb- Lez01’\nProb- Lez02\nProb- Lez03\nprob- Lez04\n\n\nFisica 1\n\nfisica 1 - Lez01*\nFisica1 - Ese01*\nfisica 1- Lez02*\nfisica1- Lez03*\nfisica-lez03’\n\n\n\n\n\nChimica\n\n.\n.\n.\n\n\nMeccanica Razionale\n\n.\n.\n.\n.\n\n\nAnalisi III\n\nAnalisi3- Lez07\n.\n\n\n\n\n\nAutomatica\n\nAutm - Lez01\n. Autm - Lez02\n.\n\n\nEDP\n\nEdp - Lez01==\nEdp- Lez02==\nEdp- Lez03==\nEdp- Lez04==\n\n\n\nReferences"},"6--full-note/settimana-3":{"slug":"6--full-note/settimana-3","filePath":"6- full note/settimana 3.md","title":"settimana 3","links":["tags/settimana_in_corso","3--tag/sbobine","6--full-note/mateNum--Lez06","6--full-note/mateNum--Lez07","6--full-note/mateNum--Lez08","6--full-note/Matenum--lab02","6--full-note/prob-lez08","6--full-note/Prob--Ese02","6--full-note/prob-lez09","/","6--full-note/fisica1--Lez07"],"tags":["settimana_in_corso"],"content":"2025-03-03 10:04\n_Status: settimana_in_corso\n_Tags: sbobine\nsettimana 3\n\nMatematica numerica\n\nmateNum- Lez06\nmateNum- Lez07\nmateNum- Lez08\nMatenum- lab02\n\n\nProbabilità\n\nprob-lez08\nProb- Ese02*\nlauree\nprob-lez09***\n\n\nFisica 1\n\n\n\n\nfisica1- Lez07\n\n\n\n\n\nChimica\n\n\n\n\n\n\nMeccanica Razionale\n\n\n\n\n\n\n\nAnalisi III\n\n\n\n\n\n\n\n\nAutomatica\n\n\n\n\n\n\n\n\nReferences"},"6--full-note/settimana-4":{"slug":"6--full-note/settimana-4","filePath":"6- full note/settimana 4.md","title":"settimana 4","links":["tags/settimana_in_corso","3--tag/sbobine","6--full-note/mateNum--Lez10","6--full-note/Matenum--lez11","6--full-note/mateNum--Lez12","6--full-note/matenum-lab04","6--full-note/prob-lez10","6--full-note/Prob--Ese03","6--full-note/prob-lez11","6--full-note/prob-lez12","6--full-note/fisica1--Lez0boh","6--full-note/fisica1--Ese08","/"],"tags":["settimana_in_corso"],"content":"2025-03-10 13:41\n_Status: settimana_in_corso\n_Tags: sbobine*\nsettimana 4\n\nMatematica numerica\n\nmateNum- Lez10\nMatenum- lez11\nmateNum- Lez12\nmatenum-lab04*\n\n\nProbabilità\n\nprob-lez10\nProb- Ese03***\nprob-lez11\nprob-lez12\n\n\nFisica 1\n\nfisica1- Lez0boh***\nfisica1- Ese08*\n*\n*\n\n\n\n\n\nChimica\n\n*\n*\n*\n\n\nMeccanica Razionale\n\n*\n*\n*\n*\n\n\nAnalisi III\n\n*\n*\n\n\n\n\n\nAutomatica\n\n*\n*\n*\n\n\n\n\nReferences"},"6--full-note/settimana-5":{"slug":"6--full-note/settimana-5","filePath":"6- full note/settimana 5.md","title":"settimana 5","links":["tags/settimana_in_corso","3--tag/sbobine","6--full-note/matenum-lab04","6--full-note/mateNum--Lez13","6--full-note/mateNum--Lez14","6--full-note/matenum-lab05","6--full-note/prob-lez13","6--full-note/prob-ese05","6--full-note/prob-lez14","6--full-note/prob-ese06","/","6--full-note/fisica1--Lez11","fisica-lez12"],"tags":["settimana_in_corso"],"content":"2025-03-18 10:20\n_Status: settimana_in_corso\n_Tags: sbobine*\nsettimana 5\n\nMatematica numerica\n\nmatenum-lab04***\nmateNum- Lez13\nmateNum- Lez14\nmatenum-lab05\n\n\nProbabilità\n\nprob-lez13\nprob-ese05*\nprob-lez14\nprob-ese06***\n\n\nFisica 1\n\n*\nfisica1- Lez11***\nfisica lez12***\n*\n\n\n\n\n\nChimica\n\n*\n*\n*\n\n\nMeccanica Razionale\n\n*\n*\n*\n*\n\n\nAnalisi III\n\n*\n*\n\n\n\n\n\nAutomatica\n\n*\n*\n*\n\n\n\n\nReferences"},"6--full-note/settimana-6":{"slug":"6--full-note/settimana-6","filePath":"6- full note/settimana 6.md","title":"settimana 6","links":["tags/settimana_in_corso","3--tag/sbobine","6--full-note/mateNum--Lez15","6--full-note/mateNum--Lez16","/","6--full-note/prob-lez15","6--full-note/prob-lez16","6--full-note/prob-lez17"],"tags":["settimana_in_corso"],"content":"2025-04-14 10:17\n_Status: settimana_in_corso\n_Tags: sbobine*\nsettimana 6\n\nMatematica numerica\n\nmateNum- Lez15*\nmateNum- Lez16*\n*\n*\n\n\nProbabilità\n\nprob-lez15\nprob-lez16\nprob-lez17\n\n\n\nFisica 1\n\n*\n*\n*\n*\n\n\n\n\n\nChimica\n\n*\n*\n*\n\n\nMeccanica Razionale\n\n*\n*\n*\n*\n\n\nAnalisi III\n\n*\n*\n\n\n\n\n\nAutomatica\n\n*\n*\n*\n\n\n\n\nReferences"},"6--full-note/settimana-7":{"slug":"6--full-note/settimana-7","filePath":"6- full note/settimana 7.md","title":"settimana 7","links":["tags/settimana_in_corso","3--tag/sbobine","/","6--full-note/prob-lez18","6--full-note/prob-lez19"],"tags":["settimana_in_corso"],"content":"2025-04-14 14:46\n_Status: settimana_in_corso\n_Tags: sbobine*\nsettimana 7\n\nMatematica numerica\n\n*\n*\n*\n*\n\n\nProbabilità\n\nprob-lez18\nprob-lez19*\n*\n*\n\n\nFisica 1\n\n*\n*\n*\n*\n\n\n\n\n\nChimica\n\n*\n*\n*\n\n\nMeccanica Razionale\n\n*\n*\n*\n*\n\n\nAnalisi III\n\n*\n*\n\n\n\n\n\nAutomatica\n\n*\n*\n*\n\n\n\n\nReferences"},"6--full-note/temporaneo-3":{"slug":"6--full-note/temporaneo-3","filePath":"6- full note/temporaneo 3.md","title":"temporaneo 3","links":[],"tags":[],"content":"I teoremi enunciati senza dimostrazione sono in ==corsivo==. I teoremi con dimostrazione inclusa nel solo programma completo sono indicati in rosso.\n1 Definizione assiomatica di probabilità\n\n﻿﻿Operazioni insiemistiche elementari, leggi di De Morgan, limiti di successioni di insiemi inscatolati.\n﻿﻿Controimmagini e proprietà.\n﻿﻿Operazioni fra funzioni reali di variabile categorica: somma, differenza, moltiplicazione, rapporto, massimo, minimo, limite.\n﻿﻿Spazio campionario, esiti, eventi: definizione, interpretazione modellistica, esempi.\n﻿﻿Operazioni logiche fra eventi.\n﻿﻿o-algebra degli eventi: definizione, interpretazione modellistica, prime proprietà.\n﻿﻿o-algebra banale, o-algebra delle parti ed altri esempi di o-algebre.\n﻿﻿Spazio misurabile: definizione.\n﻿﻿o-algebra generata da una collezione di eventi. Definizione. La definizione è ben posta. Esempi.\n﻿﻿o-algebra di Borel su R. Definizione. Classi di insiemi che generano la o-algebra di Borel. Le semirette chiuse illimitate a sinistra generano la o-algebra di Borel\n﻿﻿Probabilità: interpretazione modellistica, esempi, definizione.\n﻿﻿P(0) = 0; ogni probabilità è additiva. Proprietà elementari implicate dalla additività.\n﻿﻿Successioni di eventi crescenti e decrescenti: definizione e probabilità dell’evento limite.\n﻿﻿La probabilità è subadditiva.\n﻿﻿Spazi campionari discreti: la probabilità è caratterizzata dalla densità (discreta); caratterizzazione di una densità (discreta). Esempi. Generalizzazione a o-algebre generate da partizioni discrete. Esempi.\n\n• Eventi impossibili, improbabili, certi e quasi certi.\n2 Probabilità condizionata e indipendenza di eventi\n\n\n﻿﻿Probabilità condizionata: definizione, interpretazione modellistica, casi estremi.\n\n\n﻿﻿La probabilità condizionata è una probabilità nel suo primo argomento.\n\n\n﻿﻿Esempi di utilizzo modellistico della probabilità condizionata.\n\n\n﻿﻿La formula di disintegrazione e delle probabilità totali. Generalizzazioni.\n\n\n﻿﻿La formula di Bayes.\n\n\n﻿﻿Esempi e controesempi.\n\n\n﻿﻿Probabilità di una intersezione e probabilità condizionate.\n\n﻿﻿Coppia di eventi indipendenti: definizione, interpretazione modellistica, casi estremi, esempi.\n\n\n\n﻿﻿Due eventi sono indipendenti se e solo se lo sono i complementari, se e solo se…\n\n\n﻿﻿Famiglia di eventi (mutuamente) indipendenti: definizione, interpretazione modellistica.\n\n\n3 Costruzione di una probabilità su R\n• Criterio di Caratheodory. Controesempio.\n• Lunzione di ripartizione: dehnizione.\n\n﻿﻿Condizioni necessarie e sufficienti per essere la funzione di ripartizione di una probabilità sui bore-liani; probabilità di intervalli e di punti; una probabilità sui boreliani è caratterizzata dalla funzione di ripartizione.\n﻿﻿Esempi di probabilità su R: delta di Dirac, probabilità discrete, probabilità con densità Riemann integrabili.\n\n4 Variabili aleatorie\n\n﻿﻿Variabile aleatoria: definizione, interpretazione modellistica, primi esempi.\n﻿﻿La composizione di funzioni misurabili è misurabile.\n﻿﻿Criteri di misurabilità per funzioni a valori in R e R”; somme, prodotti, max, min, sup, inf, limiti di variabili aleatorie reali sono misurabili.\n﻿﻿Le funzioni continue sono misurabili rispetto alle o-algebre di Borel.\n﻿﻿Altri esempi di variabili aleatorie.\n﻿﻿Legge / distribuzione di una variabile aleatoria: definizione, interpretazione e importanza modelli-stica.\n﻿﻿La legge di una variabile aleatoria è una probabilità. Esempi.\n﻿﻿Variabili uguali quasi certamente: definizione e ruolo modellistico. Classi di equivalenza di variabili\nuguali quasi certamente.\n﻿﻿Due variabili uguali quasi certamente hanno la stessa legge. Esempi e controesempi.\n﻿﻿Proprietà valide quasi certamente.\n\n5 Valore atteso / Media / Integrale rispetto ad una probabilità\n\n﻿﻿Variabile aleatoria reale semplice: definizione e caratterizzazione.\n﻿﻿Valore atteso di una variabile aleatoria reale semplice: definizione e interpretazione modellistica.\n﻿﻿Approssimazione di variabili non negative tramite variabili semplici non negative.\n﻿﻿Valore atteso di una variabile aleatoria non negativa: definizione e prime proprietà.\n﻿﻿Variabili non negative con valore atteso infinito e variabili non negative che assumono valore infinito.\n﻿﻿Parte positiva e parte negativa di una variabile aleatoria reale: definizione.\n﻿﻿Variabile aleatoria reale che ammette valore atteso, variabile aleatoria reale integrabile, L’: definizioni\n﻿﻿Valore atteso di una variabile aleatoria reale integrabile e di una variabile aleatoria reale che ammette valore atteso: definizione.\n\n﻿﻿Prime proprietà del valore atteso: {’ è spazio vettoriale, il valore atteso è lineare e positivo, una variabile non negativa a media nulla è nulla q.c., |E[X]| ≤ E[|X|], convergenza monotona,  convergenza dominata.\n\n\n﻿﻿Ulteriori proprietà del valore atteso.\n﻿﻿Primi esempi: il valore atteso su uno spazio campionario discreto, il valore atteso su R con una probabilità discreta.\n﻿﻿Esempi e controesempi per convergenza monotona, convergenza dominata.\n﻿﻿Integrale di una variabile aleatoria reale su un evento rispetto ad una probabilità: definizione.\n﻿﻿Valore atteso di una serie e serie dei valori attesi.\n\n• Disuguaghanza di Markov.\n\n\n﻿﻿Insiemi di variabili aleatorie reali CP e LP, 1 ≤ p &lt; ∞0.\n\n\n﻿﻿Disuguaglianza di Cauchy-Schwarz; L^2 \\subset L^1, E[X]^2 &lt; E[x^2]; L^2 è spazio lineare.\n\n\n﻿﻿Varianza di una variabile aleatoria reale in L*: definizione, interpretazione modellistica, prime proprietà.\n\n\n﻿﻿Disuguaglianza di Chebichev.\n\n\n﻿﻿Regola del valore atteso.\n\n\n6 Variabili aleatorie reali discrete\n\n﻿﻿Variabile aleatoria reale discreta: definizione.\n﻿﻿Regola del valore atteso per variabili aleatorie reali discrete.\n﻿﻿Esempi.\n\n7 Variabili aleatorie reali (assolutamente) continue\n• Misura di Ledesgue su k: dennione, interpretazione, esistenza, unicita.\n• Integrale di una funzione reale di variabile reale rispetto alla misura di Lebesgue. Relazione con l’integrale di Riemann.\n• Densita (continua) di una probabilta su k, probabilta (assolutamente) continua su k, variabile aleatoria reale (assolutamente) continua: definizioni.\n• Condizioni sufficienti affinché una funzione di ripartizione definisca una probabilità (assolutamente) continua\n\n﻿﻿Caratterizzazione di una densità su K e relazione con la relativa probabilità.\n﻿﻿Regola del valore atteso per variabilli aleatorie reali continue.\n\n• Esempi e controesempi."},"6--full-note/temporaneo":{"slug":"6--full-note/temporaneo","filePath":"6- full note/temporaneo.md","title":"temporaneo","links":[],"tags":[],"content":"Secondo me verrà una disgrazia sta registrazione. Allora, cerchiamo di capire, anzi rifaccio un attimo il punto della situazione. L’ultima volta abbiamo incominciato a gestire i sistemi indeterminati distinguendo tra sistemi sovradeterminati, ovvero quelli che hanno eh m mag n. Ok? Quindi sono i sistemi per i quali abbiamo modificato la definizione di soluzione in senso classico, distinguendo il caso in cui la matrice A sia a rango pieno e in quel caso lì si poteva arrivare alle equazioni normali, se vi ricordate, per le quali o uno procedeva con i solver per le matrici simmetriche definite positive oce del fatto che questo avrebbe portato inevitabilmente degli errori numerici si procedeva via fattorizzazione QR reclutato. Ok? Poi invece avevamo chiuso gestendo i sistemi sovradeterminati non a rango massimo. E a questo punto avevamo detto che la soluzione nel senso dei minimi quadrati, cioè quella che minimizza la norma del del residuo, non era più sufficiente per definire in modo unico quella soluzione, quindi si andava alla ricerca di una soluzione che minimizzasse eh la la norma del residuo, ma a norma minima. Ok? E quindi gli avevamo introdotto tutta la parte della ST, mi sembra che fossimo fermi di Ok? Quindi ci mancano i sistemi sottodeterminati per i quali in realtà diremo molto di meno, quindi sarà una cosa sicuramente più veloce. E però prima di far questo vorrei legare i due concetti, cioè i due momenti, se avete fatto caso, in cui abbiamo parlato di equazioni normali. Quindi abbiamo citato una volta le equazioni normali parlando di quando abbiamo costruito la retta di regressione e la sua generalizzazione. Ok? Quindi il sistema che era fatto che aveva come entrate eh la somma in composition la somma di tutti uno, la somma di tutti gli isconi, la somma di tutti gli isconi al quadrato, eccetera. Ok? E poi parlato di pozioni normali la scorsa volta gestendo i sistemi sovradeterminati nella fattispecie il caso del rango pieno. Ok? Quindi ed erano apparentemente due cose diverse. Allora, adesso quello che vogliamo fare è capire che in realtà stiamo parlando della stessa cosa, ok? Quindi unire un po’ eh i punichini in modo corretto. Allora, se vi ricordate, quando abbiamo definito il nostro polinomio eh nel senso dei minimi quadrati, eh l’abbiamo in indicato, mi pare con FT e l’abbiamo caratterizzato con la proprietà di andare a minimizzare, vi ricordate, la somma degli scarti quadratici, ok? Quindi andavamo a fare la differenza tra y i f², ok? E questo c rimbombavo anche il gesso, giusto? È bellissimo. Ok, cioè non so cos’altro fare. C’ho l’alternativa chiamare il tecnico. Vediamo fin quando non impazziamo con questo rimbombo. Allora, questa possiamo andare a riespanderla. Eh, se vi ricordate questo FT discon i era un polinomio di grado T con M. Quindi ricostruisco un attimo le cose che c’eravamo detti e avevamo detto che questo polinomio era caratterizzato da certi specifici coefficienti che avevamo battezzato B con0, B con 1, B con M. Ok? E questi coefficienti, adesso non ricordo se mi chiamato con A quelli del fetilde e con B quelli del polinomio generico, lo recupero o viceversa. Anche ve lo ricordate per caso? Al contrario. Perfetto. Quindi questo era il generico polinomio p m, ok? Appartenente alla famiglia dei pic con m. Lui invece era quello identificato dai coefficienti a 0 + a 1 * x + a m * x^ m, quindi dai coefficienti a con 0 con 1 con m. Ok? Quindi queste dovrebbero essere notazioni eh corrette rispetto alla scorsa volta e quindi alla luce di questo Questa quantità qua possiamo giustamente andare a scriverla. Questo è generico polinomio di grado m, quindi 0 +1 * x i + dm * x i^ il tutto elevato al quadrato. Ok? E quindi, se vi ricordate avevamo tradotto la disuguaglianza che identifica f Ok? Che praticamente prevede questo uguale tramitarsi in un numero uguale. Ok? Quindi questa, se vi ditemi se vi torna è la disuguaglianza da cui eravamo partiti per definire il nostro polinomio minimi quadrati, ok? Dove questo è il generico polinomio di grado m valutato in x y. Quindi a destra avete lo scatto quadratico tra i dati che vogliamo approssimare e il generico polinomio. valutato in corrispondenza dei dati. A sinistra c’è il nostro polinomio minimi quadrati e quindi ho lo scarto quadratico tra y con i e il valore assunto da questo oggetto in corrispondenza di questi nodi. Ok? Mi sembra che questo fosse il frame da cui eravamo partiti. Ok? Quindi questa disuguaglianza eravamo andati a eh tramutarla in un problema di minimizzazione introducendo la famosa funzione f, ok? Per la quale poi eravamo andati a calcolare le derivate parziali rispetto ai alle nostre variabili che sono B0 - BM, imponendo che queste derivate parziali quando valutate nei cofficienti di fetille fossero uguale a zero. Ok? Questa era la strada che avevamo fatto in piccolo poi generalizzandola. Ok? Allora, fondamentalmente questa strada possiamo andare a riscriverla. Possiamo andare a riscriverla nel seguente modo. Io ho il mio vettore A e il vettore A è il vettore che raccoglie i cofficienti a 0 a 1 a m. E questo vettore a quello che realizza il minimo al variare di B in RM, ok? Dove B è il vettore invece che raccoglie i coefficienti del generico polinomio PM. Ok? Quindi possiamo, se ci affidiamo a quella disuguaglianza là sopra, dire che il vettore a quello che realizza il minimo di che cosa? Della somma di i che va da 0 ad n, esattamente di quello che abbiamo a destra, quindi di y - b0 + b1 * x i + bm * x i^ m². Ok? Quindi esattamente un modo equivalente di andare a riscrivere la relazione che avevamo scritto scomodando la funzione f. Ok? Quindi la somma degli scatti quadratici nel momento in cui i coefficienti variano in R viene ottenuta quando scelgo il vettore generico che sta in R con M coincidente col vettore a. Ok? Esattamente la stessa cosa. E si può vedere che dire questo è equivalente a cercare l’oggetto che minimizza sempre al variare del nostro vettore B in R + 1 la seguente quantità. Allora, scrivo A, dobbiamo dare un nome a questi oggetto, a questa matrice a * B - y a quadrato dove B l’abbiamo definito y Quindi con la seconda uguaglianza dobbiamo eh convincere. Ok? Y è il vettore che raccoglie i dati Y0, Y1, YM, ok? Em pa A invece è la matrice che definiamo nel nel seguente modo 1 x0 x0^ X0^ m. Adesso verifichiamo tutto qua. Quanto? E in fondo abbiamo 1 x n x n qu x n^ m. Ok? Allora, quindi fino a qui è tutta roba vecchia. Ditemi se vi torna. Ok? Questa è la vecchia f, giusto? Quindi, anziché dire che f di a0 1 m uguale di f b0 b1 bm * ogni b0 b1 bm. in RM l’ho tradotta dicendo che A realizza il minimo di questa cosa. Ok? Questo invece è un passaggio nuovo. Quindi quello di cui dobbiamo accertarci è che questa sommatoria corrisponde a questo oggetto, ok? Dove Y, dove v l’abbiamo definito y è il vettore che raccoglie i dati coinvolti nella somma degli scarsi quadratici, quindi il vettore y0, y1, YM e A e quella matrice lì. Ok? Allora, perché è vera sta cosa? andiamo a eh capire dove tra l’altro questa matrice l’abbiamo già vista chi è. È la matrice di alzo un attimo di Vermond. Ok? Quindi una matrice che sappiamo non essere delle più amichevoli. Allora, cerchiamo di capire se vale o meno quell’uguaglianza che ho scritto lì, ok? Perché sarà proprio quella che ci porterà a trovare il link con i sistemi sopradeterminati. Allora, innanzitutto questa somma di oggetti al quadrato ci torna è una domanda che sia possa essere intesa come la definizione di una norma euclide al quadrato, giusto? La norma al quadrato è una somma delle componenti di un vettore al quadrato, corretto? Quindi ritorno qua perché mi serve a attivare dei puntatori. Possiamo dire che questa somma per i che va da 0 a n al quadrato di oggetti al quadrato, possa essere intesa effettivamente come l’implementazione di una norma idea di un vettore il cui vettore ha questo come argomento, giusto?\nEh am sì, certo. Grazie. Sì, anche qua questo è giusto. Ok, grazie. Eh, va bene. Quindi questa è la norma euclidea al quadrato di un vettore che ha questo come generica componente, ok? E questa generica componente è del tipo y i, ok? Meno questo oggetto, quindi è una differenza di vettori, quindi che uno dei due vettori sia y direi che deriva dal fatto che qui abbiamo un y con i, ok? E l’altro vettore chi sarà? Boh, da quello che mi si racconta qua, dovrebbe essere il prodotto di quella matrice di Vanermond per il mio vettore B delle eh incognite. Ok? Infatti, se voi provate a fare la prima riga di A per il vettore delle B, che cosa ottenete? B0 * 1 + B1 * X0 + b2 * x0^ che sarebbe qua + b * x0^ m. Ok? Quindi questo oggetto qua per i = 0 ci dà proprio la differenza tra la prima componente del vettore y è la prima componente del vettore prodotto fra la matrice A e il vettore B. È giusto? Provo avere sta cosa. Allora, quindi noi abbiamo da un lato il vettore y0 y1 y con m e poi abbiamo qua il prodotto della mia matrice di Vandermond X0 X0 X0^ M. Simil cosa fino all’ultimo dato che è x n x n² x n^ m e questo va moltiplicare il mio vettore0 b1 bm. Ok? Io sto dicendo che la quantità al quadrato, questa è una differenza di vettori, quindi il primo vettore sarà uguale proprio a y0 - b0 - b0 eh - b0 - b1 * x0 - b2 * x0^ - bm * x0^ m. Ok? Fino all’ultimo e l’ultimo sarà y con n - esattamente la stessa cosa, quindi v0 - b1 * x n - b2 * x n - bm * x n^ m, giusto? Quindi ognuna di queste righe è laima componente del vettore y, il segno è rilevante - a* b. È corretto? Allora, provo a ripeterlo fino a qui. Ditemi se ci siete almeno su questa uguaglianza. Questa roba è materia vecchia, però se non vi torna la riguardiamo un attimo insieme. Vi torna. Ok? Adesso, visto che io vorrei legare i due momenti in cui visto le equazioni normali, cerco di ricondurre questa cosa che abbiamo già portato a casa con una parte nuova, ok? E alla fine la prima cosa che dico è che questa somma di scarti quadratici si può in realtà leggere come una norma euclide. al quadrato. Ok? Ci ricordiamo che se io ho un generico vettore W di componenti W1, anzi parliamo pure W0 WM, ok? Quindi un oggetto che sta in R di M + 1, ci ricordiamo tutti che la norma e l’idea di doppio al quadrato non è nient’altro che la somma qu che va da 0 a m di un w^, è corretto? Ok. Quindi questa somma di una parentesi di un oggetto con componente i al quadrato può essere vista come la componente i esima di un vettore di RM1, giusto? Quindi quello è il punto di partenza, capire, interpretare questa somma di quadrati. Ok? E quindi adesso quello che voglio vedere è che la componentesima del mio vettore, effettivamente se interpreto questa come la componentesima di un vettore, voglio capire chi è questo vettore. È una differenza di vettore. Il primo vettore è facile da capire chi è, è Y. Ok? Il secondo vettore ha esattamente la struttura tipica di un prodotto riga per colonna. E allora se io vado a definire A come la matrice di Vanderlond, effettivamente se voi andate a espandere questo prodotto, scusate questo prodotto meno questa somma, trovate questi oggetti, il vettore caratterizzato da queste componenti e l’esima componente di questo vettore è esattamente questo. Ok? Quindi Quindi possiamo dire che il la parte vecchia effettivamente può essere riletta con una minimizzazione di che cos’è questo? Il solito residuo al quadrato, giusto? La norma al quadrato del residuo. Bene, ma allora abbiamo imparato a calcolare la soluzione della minimizzazione di un problema che ci porta a cercare il vettore tale per cui viene minimizzata la norma al quadrato di un residuo, giusto? È esattamente la nuova definizione che abbiamo dato di di soluzione quando abbiamo i sistemi sovradeterminati a rango massimo, corretto? È la prima definizione nuova che mi è andato l’altra volta e per quello avevamo detto che cosa? Quindi questo problema qui avevamo scoperto che aveva una soluzione che avevamo battezzato eh forse con X star. Ok? Questa soluzione è esattamente il nostro vettore A e questo vettore A, quindi a suo tempo abbiamo trovato il sistema a trasposto per Ax² è uguale ad A trasposto per B. Questo per quello che ci siamo detti genericamente la scorsa volta dove Xstar era la soluzione del sistema sovradeterminato a rango pieno. Ok? Anche questo è un sistema sopradeterminato, giusto? La dimensione è quella di un sistema sovradeterminato e quindi che il nostro vettore A è soluzione della matrice A trasposto per A ed è uguale ad A trasposto per B. Ok? Quindi quante righe qua ho? O n + 1 righe, ok? O m + 1 colonne. E in generale, nel caso di un’approssimazione di minimi quadrati n è molto più grande di m, quindi vuol dire che più righe che colonne, quindi questo è esattamente un sistema sovradeterminato, è corretto? Ok? Dopodiché questo è quello che abbiamo imparato come soluzione del nostro sistema sopradeterminato quest’a non è la stessa di qua sopra, era la soluzione e la a del sistema visto la scorsa volta, ok? È semplicemente per ritrovare la struttura che avevamo imparato precedentemente. Quindi tra un secondo sparirà per un confusione che è applicata al nostro caso specifico e identica dove la matrice A in realtà è undermond, dove il vettore X star è il nostro vettore delle incognite, quello che realizza il minimo della norma del residuo, quindi l’abbiamo battezzato A e anziché B, giustamente qua, scusatemi, abbiamo Y. Ok? Quindi questa è la soluzione che ci viene data nel momento in cui io vado a rileggere il mio problema della ricerca dei polinomie minimi quadrati come la risoluzione nel senso di eh minimi quadrati di un sistema sovradeterminato. Ok? E quindi adesso per chiudere il cerchio cosa dobbiamo dimostrare? Che questa cosa qui coincide col nostro sistema di equazioni normali che abbiamo derivato quando abbiamo fatto la retta di regressione. Ok? Questo ci permetterebbe di chiudere effettivamente il cerchio. Corretto? Allora, chi è al trasposto per A? Questo è a trasposto è la matrice, quindi con tutti 1 sulla prima riga con x 0, x 1, x n. Sulla seconda riga, sull’ultima riga abbiamo x 0^ m, x1^ m, x * n^ m. Ok? E quindi quando vado a fare il prodotto di questi due oggetti, quindi questo è il nostro a trasporto per a che abbiamo riscritto, cosa succede? Che quando faccio, per esempio, la prima riga per la prima colonna trovo una somma di tutti uno. Ok? Quindi troviamo la famosa sommatoria di 1 * i che conta da 0 a n. Quando faccio la prima riga per la seconda colonna ho proprio la somma di tutti gli isconi, ok? Quindi trovo la somma degli sconogi per i che va da 0 ad n. Quando faccio la prima riga per l’ultima colonna cosa avrò? Avrò la somma delle potenze ennesime di tutti gli sconi, quindi la somma i che va da 0 ad n dei miei x con i^ m. E ad esempio prendiamo in posizione 1 per vedere se ci ritrovi Seconda riga per prima colonna ritrovo la somma di tutti i discori e così via. E quando farò l’ultima riga per l’ultima colonna effettivamente ho la somma del disconi elevato 2m. Ok? Quindi questa matrice ha trasposto per A, per fortuna, quella che ci viene eh diciamo identificata come la matrice del sistema delle equazioni normali via minimizzazione della norma del residuo è esattamente la matrice a cui siamo arrivati quando abbiamo fatto la retta di regressione e poi l’abbiamo generalizzata. Ok? Quindi esattamente la nostra matrice prima di che che avevamo prima di iniziare a parlare di sistemi sovradeterminati. Siamo d’accordo? E analogamente quando faccio trasposto per Y, eh, quindi uso questa matrice qua. Rimettiamoci qua. Se faccio a trasposto per Y, quindi ho tutti 1, ho x0 X con 1 x m o x0^ x con n, scusate, x0^ m x 1^ m x n^ m. Questo va a moltiplicare il mio y0 y1 y m. Ok? E quando faccio a trasposto per y, allora cosa ottengo? Prima riga per la il vettore degli y o la somma degli y con i. Seconda riga, per il vettore delle y ho i prodotti del tipo xi y con i. Se avessi esplicitato la terza riga, avrei la somma dei disco i al quadrato * y i fino all posizione in cui la somma degli con i^ m * y e anche questo è esattamente il termine noto che avevamo quando abbiamo ricavato per la prima volta le equazioni naturali, giusto? Ritorna. Quindi per fortuna questi due sistemi visti in due momenti diversi seguendo due strade completamente opposte effettivamente vengono a coincidere. Ok? Quindi la nostra il nostro polinomio minimi quadrati potete vedere o costruito normalmente attraverso appunto la minimizzazione del funzionale F con le derivate eccetera, oppure potete ricondurre la nostra minimizzazione della somma degli scarti quadratici come la minimizzazione del la norme qued quadrato di un residuo, quindi procedere secondo la strada soluzione mini quadrati di un sistema sureterminato e alla fine giustamente si arriva la stessa cosa. Ok? Ci siete? Non è banale, però se vi mettete di concamera e fate questi passaggi, alla fine si tratta proprio di vedere che si arriva alla stessa matrice prima e dopo il trattamento sovradeterminati. Ok? Va bene. Allora, se ci siete su questo, sperando che a caso sia ancora tutto stabile, eh passerà ai sistemi sottodeterminati su cui diciamo molto meno, quindi sarà più rapido. Ok. Cancello. Allora, quindi parliamo di sistemi sottodeterminati. Quindi questa volta abbiamo meno equazioni che incognite, quindi ci mancano delle informazioni, ok? Quindi ho sempre il mio sistema ax = y, dove a sempre la matrice rettangolare m * n, ma questa volta m è min in senso stretto di n. Ok? Quindi vuol dire che la mia matrice, anziché essere alta e magra è larga. Ok? Quindi questa è, per esempio, la nostra matrice A. A questo punto il vettore X continua a stare in R, quindi il vettore X invece ha una dimensionalità maggiore. Questo X che ha n colonne e il vettore y continua a stare in rensionalità più piccola. Ok? Quindi m Allora, eh esattamente come avevamo incominciato a fare per i sistemi sovradeterminati ad assumere che il rango della matrice A sia massimo e quindi supponiamo che il rango di A sia pari ad M. Ok? Allora, qual è il problema di avere una configurazione in cui ho più incognite che equazioni? Beh, sicuramente avevamo fatto l’esempio della retta a cui chiedo di passare per un punto, quindi non ho un numero sufficiente di condizioni per definirle in modo univoco, ok? In una retta, una retta, scusatemi. per un punto passano infinite rette. E allora in quel caso lì, per identificare nel fascio di rette che passano per un punto la retta che ci interessa, quello che avevamo detto che bisognava fare era andare a aggiungere una condizione. Ok? Quindi anche qui la soluzione di un sistema sottodeterminato verrà cercata come la soluzione classica, quindi che soddisfa x = y, ma con una condizione addizionale. Quindi si può dimostrare che aggiungere una condizione effettivamente sufficiente per dare l’unicità di x. E analogamente a quanto abbiamo visto, per i sistemi sopradeterminati a rango non massimo verrà cercata la soluzione nuovamente con norma eutidea minima. Ok? Quindi è una delle opzioni che andiamo a sfruttare, quindi diciamo che X Star è soluzione del nostro sistema sotto determinato a x = a y. Se quindi eh x asterisco utilizziamo la notazione dell’argamin che abbiamo appena utilizzato, quindi realizza la il minimo della eh Rn. Ok? Quindi realizza il minimo della funzione norma di x varia di x in r con l ed è tale che a* x star st è uguale all y. Ok? Quindi dire questo vuol dire cercare una soluzione in senso classico a cui andiamo ad aggiungere questo vincolo ulteriore per garantire l’unicità. Ok? Quindi, se volete, rispetto a prima, quando parlavamo di minimizzare la norma della soluzione, quella soluzione di cui ce cercavamo il minimo della norma minimizzava il residuo. Questa invece risolve il sistema in senso classico, ok? Quindi c’è una discretanza rispetto a cosa avevamo prima, ok? Quando siamo andati ad aggiungere il vincolo di avere un oggetto a norma minima. D’accordo? Allora, quello che si può dimostrare è che la nostra x è così definibile, coincide con la trasposta di A che moltiplica l’inversa di a * a trasposto per Y. Ok? Quindi adesso noi andremo a verificare che questa scelta soddisfa entrambe queste condizioni qua. Quindi e soluzione classica del mio sistema ax = y in più a prima. Ok, andiamo a verificarlo. Quindi verifichiamo due cose. La prima cosa che andiamo a verificare è che X star, così definit Quindi ci domandiamo se a* x asterisco effettivamente è uguale a y. Ok? Per far questo andiamo a sfruttare l’espressione di x asterisco. Quindi abbiamo a per a trasposto per A * A trasposto all -1 * y. Quindi ci domandiamo se si avverà questa uguaglianza, ma Questo è il nostro AX trascosto. Beh, vediamo immediatamente che è vera, perché questa è una matrice che comunque battezziamo, la battezziamo B o B per la verso inversa, quindi l’identità e quindi questo è chiaramente Y. Ok? Quindi la prima cosa che verifico è data questa definizione per X star che effettivamente è soluzione in senso classico, cioè a di x star st fa y. Ok? E adesso invece dobbiamo andare a verificare l’altra cosa, cioè che effettivamente realizza il minimo della norma di x. Quindi quello che dobbiamo andare a verificare è che la norma eidea di x asterisco così definita minimizza, prendiamola pure al quadrato, è minore o uguale della norma eupleidea di x qu. Questo per ogni x che sta in rale da essere soluzione classico del mio sistema, cioè tale che a* x risulti essere essere uguale a y. Quindi, se volete, uno che abbiamo verificato è questa parte, due che stiamo per verificare è questa parte qui. Ok? Quindi abbiamo verificato uno che x stare è soluzione in senso classico. Per verificare che x stare realizza il minimo della norma e più di x, andiamo a vedere che la norma equide di x al quadrato, se pure al quadrato è minore o uguale della norma equa al quadrato di un qualunque altro vettore x R con n che è soluzione in senso classico del nostro sistema. Ok? E per far questo abbiamo bisogno di un risultato per eliminare, quindi vi metto qua, ovvero il risultato preliminare dice la seguente cosa che x - asterisco - x asterisco trasposto per x asterisco fondamentalmente fa Adesso vediamo perché allora eh incomincio a espandere questo x asterisco con la sua definizione che abbiamo sopra. Quindi abbiamo a trasposto che moltiplica a * a trasposto -1 * y posso scriverlo mettendo insieme questi due oggetti. Ok? Vi ricordo che la trasposta di un prodotto o il trasposto di un prodotto è il prodotto dei trasposti in senso opposto. Ok? Quindi questi due oggetti qua io come posso andare a scriverli? Posso scriverli come a che moltiplica x - x asterisco il tutto trasposto. Giusto? Quindi questo incomincio a scriverlo come a x - x² trascosto e poi mi rimane a per a trascosto -1 * y, ma questa quantità qui che quindi è uguale ad a * x - a * x² è uguale Da quanto? Quant’è a * x?\nQuant’è a* x?\nY. Quindi questo è\n0 e quindi vuol dire che tutto questo oggetto è zero. Ok? Perché xara abbiamo dimostrato che soddisfa la soluzione del mio problema in senso classico x. Stiamo supponendo che lo facci Ok, quindi questa quantità è nulla. Ok? E allora questo preliminare ci serve per andare a dimostrare questo. Come facciamo? Allora, parto dalla norma di x quadrato che vado a scrivere tramite un’uguaglianza aggiungendo e togliendo la stessa quantità e questa quantità ovviamente è x a stisco. Ok? Dopodiché questo posso andare a scriverlo. Potete vederlo in vari modi, o usando Pitagoras, se li leggete come vettori, oppure eh interpretando, per esempio, questo come un vettore A, questo come un vettore B. E allora questa è Ea + B trasposto per a + b definizione di norme equide a quadrato. Ok? E questo prodotto scalare vi dà a trasporto per A, che è la norma di questo oggetto al quadrato, più pi trasposto per B, che è la norma di questo oggetto al quadrato e poi ci sono i due doppi prodotti A trasposto per B o B trasposto per A che è uguale quindi a due volte un oggetto di di tipo questo trasposto per questo. Ok? Quindi questa cosa qua Possiamo vederla come la norma di x qu la norma di x - x star qu più due volte x - x asterisco trasposto per x asterisco. Ok? Quindi vedete cosa vi torna più comodo. O li leggete come vettore, applicate banalmente Pitagoro, o espandete la definizione di norma, una somma di due oggetti. Quindi avete a + b trasposto per A + B. A trasposto per A dà eh A e questo oggetto. Poi avete A trasposto per B che è uno di questi due signori, B trasposto per A che è l’altro di questi due signori, B trasposto per B che è questa norma qui. Ok? Dopodiché questo oggetto qui per per il nostro preliminare è uguale a 0 Ok? Quindi cosa abbiamo? Abbiamo che la norma di x^ coincide con la norma di x asterisco al quadrato più la norma di x - x asterisco quadrato. Allora, questa è sempre una quantità maggiore o uguale di 0 e quindi cosa possiamo dire? Che la nostra norma di x quadrato è sempre maggiore o uguale della norma di x asterisco al quadrato. Ok. E quindi abbiamo dimostrato anche il punto due. Ok. Bene. Dopodiché, esattamente come succedeva nel caso dei sistemi sovradeterminati, questo computo qua si può dimostrare che numericamente è instabile. Ok? E quindi faremo la strada alternativa di andare a calcolare X asterisco usando la fattorizzazione QR. Ok? Quindi teniamo la formula esplicita, qua sotto è la dimostrazione e adesso vediamo quello che invece è l’approccio grafico per andare a calcolare X star tramite fattorizzazione QR. Quindi nella pratica il nostro X star si calcola usando la fattorizzazione QR. In realtà si usa la fattorizzazione ridotta QR. Attenzione della matrice a trasposto e questo ci riporta Il terra è conosciuto è perché la matrice A è, diciamo, rettangolare nel senso della lunghezza. Facendo la matrice, la fattorizzazione, scusatemi, QR, QR ridotta della matrice trasposta e ritorniamo a parlare della fattorizzazione QR che è una matrice tipica di un sistema sopradeterminato, quindi ritorniamo a qualcosa che già abbiamo gestito, ok? E quindi noi supponiamo di avere a nostra disposizione questa fattorizzazione, quindi supponiamo di poter scrivere a trascosto come utilde rtille. Ok? E allora niente, andiamo a espandere chix asterisco e vediamo come si può utilizzare questa fattorizzazione. Ok? Allora, a trasporto viene rimpiazzata dalla sua fattorizzazione ridotta, quindi è utile per rtind. Poi eh a vuol dire che andiamo a fare il trasposto di questi oggetti qua. Quindi abbiamo utilde ril trasposto. Quindi vi rimetto l’etichetta qua sotto. Questo è trasposto. Questo di conseguenza è a. Poi ha trasposto e di nuovo e questo è il nostro ha trascosto tutto. Questo è all -1 e poi abbiamo Y. Ok? Conviene ovviamente andare a espandere questo trasposto per vedere se possiamo in qualche modo sfruttare l’ortogonalità di cutile. Quindi questo oggetto al momento è utilde per rt tilde che moltiplica r tilde trasposto per tilde trasposto per tilde per rchilde. ^ -1 * y. Ma intanto questo oggetto qui ci dà l’identità. Inizio a togliere due protagonisti. Quindi abbiamo utilde per r tilde che moltiplica rt tilde trascosto per rt tilde^ -1 * y. Ok? Quindi ho semplicemente espanso questo operatore di trasposizione e sfruttato l’ortogonalità della matrice Qilde. E a questo punto vado ancora a sfruttare questo inverso, ricordandoci che così come il trasposto di un prodotto è il prodotto dei trasposti in ordine al costo, anche l’inverso di un prodotto è l’inverso è il prodotto degli inversi in ordine inverso. Ok? Quindi questo oggetto qui a che è uguale? È uguale a utilde per r tilde che rimangono tali e quali. Poi abbiamo r tilde^ -1 così che questo ci dà l’identità. Abbiamo rt^ - t abbiamo y, ok? Così cheé alla fine il nostro la nostra soluzione x asterisco del sistema sottodeterminato, si può nella pratica andare a calcolare come prodotto qutilde per r til all - t per y Ok? E questo è il modo con cui viene calcolata la soluzione. Siè perso mettere l’annotazione\ndeve fare il l’inverso del trasposto.\nCioè vuol dire rt^ -1.\nVuol dire rt^ -1. Certo.\nBeh, se vi tu poi lo tenete spacchettato, insomma.\nOk.\nFaccio l’inverso del trascosto. Se potete battezzare il trasposto in un qualche modo e poi ci applicate inverso. Ok. Fine dei sistemi indeterminati. Alleluia. Mi sento di dire l’unica cosa che l’anno scorso avevo fatto e poi in realtà mi ero persa in cioè c’eravamo persi in mille tecnicismi per cui quest’anno ho deciso di lasciarvelo eventualmente da guardare sul libro e capire come volendo uno, non avendo matrava costruisce la fattorizzazione QR di una matrice. Ok? È giusto per dire veramente il minimo essenziale, poi ripeto Sto conto ci sono i conti fatti tutti per bene, tutti espansi, quindi direi che non stiamo a perdere mezz’ora per guardare dei tecnicismi, però abbiamo già detto che la fattorizzazione QR si ottiene e di conseguenza per quella ridotta si ottiene applicando l’algoritmo di autonormalizzazione di grmit alle colonne di A. Ok? Quindi fondamentalmente battezzando sono dei vettori contiene con i coefficienti di prima. Battezzando con A1 eh questa è una M * N, quindi A n colonne a n le colonne della matrice a attraverso gramit si ottiene una base porta normale di vettori e2 e nmostrato sul libro la matrice Q non sarà nient’altro che la matrice che raccoglie proprio questi vettori ortonormali e 1 e nelle sue colonne. Ok? mentre la matrice R eh andrà a raccogliere, insomma, le entrate saranno del tipo m prodotto E1 contro A1, E1 contro A2, quindi sarà la proiezione E1 contro A con N e così via, che è la matrice pseudo triangolare superiore che raccoglie questi queste proiezioni. Ok? Comunque ripeto, sul libro avete proprio tutti gli operatori definiti per bene di proiezione, lezzazioni. Per chi è interessato è un buon esercizio per ripassare il gradmit. Ok, non stiamo a farlo. Eh bene, direi che questo chiude per quel che dovrebbe riguardarci definitivamente i sistemi, quindi non diciamo sembravano già chiusi i fatti gli iterativi, poi sono ritornati sono rientrati dalla finestra posta approssimazione di date e funzioni. Direi che li utilizzeremo soltanto più i quando serviranno, ma non parleremo, se non mi sbaglio, più di metodi per risolvere i sistemi, ok? E quindi quello che facciamo adesso è completamente andare a cambiare argomento, cioè imparare ad approssimare degli oggetti completamente diversi, quindi parleremo di approssimazione di derivate, super corto e approssimazione di integrali. Entrambi gli argomenti sono legati all’interpolazione, quindi se volete sono in continuità anche loro col concetto di interpolazione. Ecco. Quindi portano le derivate che queste sicuramente ci stanno nel tempo che abbiamo e poi se tempo iniziamo gli integrali. Allora, in realtà abbiamo già parlato di in modo molto blando di approssimazione di derivate. Se vi ricordate quando l’altra volta abbiamo citato le spline, ok? Queste funzioni interpolanti super regolari dicendo che un po’ con un abuso di forzando un po’ la mano uno può utilizzare la derivata della spl per approssimare la derivata della funzione. Vi ricordate questo discorso? Ok? E quindi in quel contesto lì parlavamo di approssimazione di derivata come approssimazione di una funzione che rappresenta la derivata. Ok? Quindi approssimo f’, quindi dato una funzione f1 via b, avevamo, diciamo, pensato a come approssimare f’ come funzione. Ok? In realtà adesso cambiamo un attimino lo scenario e ci occupiamo di imare non f’ come funzione, ma f’ come valore assunto dalla derivata prima in un certo punto x asterisco che appartiene al dominio di definizione. Ok? Quindi faremo ci occuperemo di schemi per approssimare questi che sono banalmente dei numeri reali, ok? Quindi sono schemi per approssimare il valore puntuale della derivata prima in un punto del dominio. Ok? Quindi, ricapitolando, abbiamo la nostra funzione f definita sono un intervallo b della retta reale a valori reali che ha una certa regolarità e una funzione C1 e siamo alla ricerca di un’approssimazione per la derivata prima in un qualche punto di AB. Ok, va bene. Poi magari commenteremo avendo questi, come faccio a costruirmi l’approssimazione di F prima. Ma prima di inoltrarci nel mondo delle approssimazioni, volevo sondare un attimo m quanto avete chiaro il concetto di derivata, cioè perché il concetto di derivata potrebbe essere utile fisicamente. Quindi le mettiamoci usciamo dalla veste del matematico e mettiamoci il cappellino da ingegnere perché\nquello è un un punto di vista geometrico. Adesso con il passare dei mesi, degli anni acquisirete sempre più un senso pragmatico delle cose. Quindi il concetto di derivata è associato in indipendentemente dalla simulazione numerica al concetto di velocità più in generale\ncambiamento\nvariazione. Ok? E in tante applicazioni è molto più importante monitorare la variazione della quantità che sto modellando piuttosto che la quantità che sto modellando. Faccio un esempio. Se penso a una membrana che si deforma, ok? Dietro alla deformazione di una membrana c’è un’equazione che lungi da questo corso, comunque si chiama equazione dell’elasticità. Ok? Questo suona credibile. l’equazione dell’elasticità ha come incognita lo spostamento, ok? Quindi lei è la nostra funzione f. Quantità legate allo spostamento in realtà alle derivate dello spostamento sono per esempio le deformazioni, gli sforzi, ok? Per le applicazioni da un punto di vista per esempio dell’ingegneria civile, della statica, dell’analisi delle strutture, sicuramente gli sforzi piuttosto che gli stress sono molto più importanti da monitorare piuttosto che alla variazione rispetto alla posizione di equilibrio. Ok? Da un punto di vista fluidodinamico, se io, per esempio, attivo il modello per monitorare eh facciamo un esempio più semplice, la diffusione del solito inquinante nel fiume della doccia di inchiostro nella bacinella, quindi se la mia funzione f misura la concentrazione dell’inchiostro dell’inquinante nel fiume piuttosto che nella bacinella, quella è F. Se passo alla derivata sto pensando al flusso di questo inquinante o di questo inchiostro attraverso una qualche per esempio porzione del dominio e quindi ad esempio i fini ambientali è molto più interessante sapere che ne so, il flusso di schifenza, cioè di inquinante che va a deteriorare una certa zona che devo salvaguardare piuttosto che sapere esattamente che concentrazione c’è. Ok? Quindi tutto questo per dire che a volte, anzi molto spesso nelle applicazioni può essere più interessante capire quanto vale la derivata piuttosto che la funzione stessa. Da qui la necessità di andare ad approssimarla e a volte è proprio per esempio l’esempio del fiume parla chiaro, anziché monitorare la var il flusso della mia Il mio inquinante su tutto il percorso del fiume può essere più interessante monitorarlo in certi punti dove magari ho le soldine che misurano, dove magari ci sono che ne so gli animali da proteggere, eccetera eccetera. Ok? Quindi questo per giustificare perché c’è interesse per le derivate. Dopodiché, come sempre, andiamo a partiamo da quello che l’analisi ci offre per il calcolo della derivata, come viene calcolata dall’analisi la derivata di una funzione in un punto\ncome famoso limite di un rapporto incrementale, ok? Quindi, per esempio, f’ non è l’unico modo per cui posso andare a scrivere f’ di xa, ma posso andare a scriverlo come il limite per h che tende a 0 dal famoso rapporto incrementale una possibilità e scriverlo come fx + h - fx / h. Ok? Questo è il famoso rapporto incrementale che cita il vostro collega e quindi io faccio tendere h0 e questo mi trova il valore di f’ x. Vi ricordo che se questa è la nostra f e questa è la nostra x asterisco, f’ in x star è il coefficiente angolare della retta tangente ad f nel punto di coordinate x star f x, giusto? Quindi è un numero, ok? E quindi Se guardo quella definizione lì, io cosa sto facendo? Sto chiedendo informazioni al punto x st + h che sta dopo x asteristo, ok? E prendere il rapporto incrementale vuol dire fondamentalmente rimpiazzare la tangente con questa retta. Ok? Quindi io dovrei surrogare la pendenza della tangente con la pendenza di questa retta. Quindi in questo caso non va proprio con bene bene perché addirittura ho un coefficiente positivo contro il coefficiente negativo, ma c’è un limite. E quindi il limite cosa fa? Fa scorrere questo punto lungo la curva. Ok? E se voi fate scorrere questa questa retta mano avvicinando questo punto qua, vedete che la vostra retta secante effettivamente per h che va a 0 tende a sovrapporsi alla tangente. Ok? Quindi questa è l’interpretazione grafica della derivata. D’accordo? Bene. Ora con riferimento a questa definizione analitica che è sicuramente esatta, c’è qualcosa che ci turba, cioè che al nostro calcolatore non va tanto bene o siamo tranquilli e usiamo questa. Esattamente c’è il limite che non va bene. Tutto ciò che risuona con l’infinito abbiamo capito che non è il concetto digeribile da un calcolatore e il limite ovviamente è un asintotico e quindi non va bene. Ok? Allora, nell’andare a proporre un possibile schema per approssimare f’ in X star, cosa è stato fatto? Beh, semplicemente si è deciso di rimuovere questo limite, ok? E quindi di andare ad approssimare le prime di X asterisco con un oggetto che usando le notazioni della letteratura viene indicato con delta + fx asterisco. Delta + f è un unico simbolo. Ok, adesso vediamo questo più cosa vuol dire. E questo delta + fx asterisco semplicemente coincide col rapporto incrementale scomodato nella definizione esatta, quindi è fx asterisco + h - f(x) asterisco diviso H. Ok.\nMa H chi è?\nEh,\nh chi è?\nH è questa distanza qua,\nè decisa in maniera arbitraria.\nAllora, in questo caso qui va a zero. Per quello che abbiamo visto l’andamento della retta, questo h dovrà essere ovviamente piccolo, ok? Perché altrimenti effettivamente questo è un caso disgraziato in cui ho una segante che è una pendenza contro una tangente che ne un’altra. Ok? Quindi h, diciamo la solita frase che poi nella pratica non serve a niente, deva essere preso opportunamente piccolo. Ok? Poi uno se la gioca ogni volta a seconda dell’approssimazione, cerca di sopravvivere prendendo un’aria abbia senso. Allora, questo oggetto è una prima modalità per approssimare f’ di X star e si chiama schema alle differenze finite in avanti. Perché mai si chiamerà differenza finita in avanti? La qualcosa giustifica questo più perché per approssimare il valore di f il segnato io sto ricercando informazioni in un punto che sta davanti a x star, ok? Cioè x star + h. Ok? Chiaramente ci sarà anche quella all’indietro, sarà la seconda proposta di approssimazione che vi farò, ok? Andiamo, messo lì il, diciamo, la proposta di approssimazione, come sempre, cercare di capire se è approssimata, quanto è approssimata questa questo oggetto, questa prima questo primo surrogato di fara. E per far questo, quindi, quello che vogliamo andare a calcolare, per intenderci, è il solito errore tra f’ di x st e il nostro delta + fx st. Ok? E come sempre, cioè come sempre, e per far questo utilizziamo uno strumento classico dell’analisi che è l’espressione di Taylor. Ok? Quindi usiamo Taylor, lo tronchiamo a second Questo quindi ci porta a chiedere che la nostra funzione f sia una funzione C2 di AB. Ok? Allora, scriviamo valutandolo in x st + h, centrandolo in x asterisco e eh trandolo al secondo ordine. Ok? Quindi abbiamo che f + a è ugx + h vol star + h2 su 2 per la derivata seconda di f calcolato in un qualche punto alfa dove alfa se ne sta tra x e x + h. Ok? Quindi cosa basta fare per andare a stimare questa quantità? Ve riconosco dei tratti dei pezzi costituenti delta + f. Ok? Quindi inizio a dividere tutto per h. Ok? Quindi questo si divide per h, questo si divide per h, questo sparisce, questo diventa un h. E a questo punto cosa è sufficiente fare? Beh, è sufficiente muovere questo oggetto a destra. e muovere questo oggetto a sinistra.\nOk? Quindi abbiamo che cosa? Abbiamo che f’ di x star a f’ di x andiamo a sottrarre f star + h / h. Poi ci rimane un + fx sta/ h. E questo è uguale a - h/2^ derivata seconda di f. Ok, ci siete? Quindi sto calcolando l’errore. Ho deciso di appoggiarmi a Taylor che centro in x asterisco, valido in x asterisco + h tronco al secondo ordine. Quindi poi ho diviso tutto per h e sto spostando un po’ di oggetti a destra e a sinistra perché a questo punto questo termine qui se mettete se raccogliete un meno 1 su h che è esattamente la vostra differenza finita in avanti, giusto? Se raccogliete un 1 su h vuol dire che faccio una frazione unica e qua c’era un più, quindi vuol dire che metto un meno. Ok? Sguardi super persi. Dove siete persi? Peppa rossa qua davanti. Mattia\nè approssimato\nda delta + fx che è uguale a quell’oggetto.\nUn delta p+ o delta+?\nEh no, è un delta p+ta destra.\nOk,\nl’ho detto. Eh, questo oggetto qua è il suo delta più, vero o falso? Ok.\nNo, no, no, no. È una notazione infelice, ma è molto classica. È come si chiamasse G, ok? Delta + F. Qua ci sono altre domande? Ci siete? Non è successo nulla di drammatico, semplicemente abbiamo fatto Taylor, abbiam diviso, abbiam raccolto, messo in forno a 180° e viene fuori sta cosa qua. Ci siete? Devo ripetere? No, va bene. Bene. Quindi questo oggetto qui, se la lavagna collabora, è delta + f un unico simbolo di x asterisco, ok? E quindi abbiamo che il nostro errore è uguale a - h/2 per la derivata seconda di f calcolato in questo punto è alfa. Ok? Quindi faccio due azioni, una di natura pratica. Questo altro è il solito punto che non si sa bene chi sia. Quindi poi come sempre a cosa servirà questa formula? Per andare a calcolare il massimo dell’errore, ok? Dove h/2 perderà il segno, quindi rimarrà un h/2 e prenderò il massimo della derivata seconda. Quindi da un punto di vista pratico, poi questo oggetto di destra diventa utile rendendo questo punto identificabile. Visto che non so chi è, faccio che prendere il massimo di questi oggetti e già successa questa cosa quando parlavamo di interpolazione, forse. Ok? La seconda osservazione che faccio è che per fortuna questo errore vedo che per h che va a 0, cioè man mano che il mio punto x star + h si avvicina a x star, dove va? A zero. Quindi stiamo dicendo e l’abbiamo visto graficamente che effettivamente la mia secante per alta che va a zero va a sovrapporsi con la tangente, ok? E ci va con una certa velocità. Questa velocità è come sempre data dalla potenza di la potenza di se h che va 0, qualcuno va a zero, quindi con che con una velocità che è data dalla potenza di ho sentito forse neiandri h ok che potenza ha ho. Quindi si dice che questo è uno schema che converge a zero linearmente per h che va a 0. Quindi stiamo dicendo, vabbè, è uno schema che quantomeno tende, preso un arco opportunamente piccolo, facendolo tendere a zero, va al valore esatto F’ di SAR. Certo, non è dei più rapidi, però intanto per arco che opportunamente piccolo ho un’accuratezza desiderata, mettiamola così. Ok? Bene, questo è il primo schema. Dopodiché, chiaramente uno può dirmi “Vabbè, ma perché prendi il punto in avanti e non prendi il punto indietro?” Giusto, effettivamente potevo andare a definirvi la derivata esatta di f’ in x star anziché in limite attraverso il limite che c’è sopra come limite per h che va a 0 di fx asterisco - f asterisco - h / hita cosa elevato alla potenza di h.\nOk? Eh, quindi la cosa ho detto due cose, una è della diciamo modalità pragmatica. Cosa me ne faccio di questo oggetto? Questo è a costo. Ok? E l’altro è che questo è l’errore di approssimazione della derivata, quindi stiamo dicendo che questa quantità se ne va 0 per h che va 0, ok? E lo fa come sempre con una certa velocità. Questa velocità è dettata da questo h che va 0, da questo h che va a 0 e qui abbiamo una potenza 1, quindi diciamo che è uno schema curato al primo ordine per altro che va a zero dove al primo ordine che convergi linearmente a te. Ok, prego. Altre domande su questa parte qui? Non siate timidi, eh, tanto io non mi ricordo che vi fa le domande, quindi qualunque cosa diciate non verrà usata contro di voi. Ritorna. Per me questa è una parte super facile, quindi di solito la faccio abbastanza velocemente, però come ho colto prima a voi sembrano uguali i sistemi, i metodi itativi con l’approssimazione di dati e funzioni, per cui vuol dire che io non ho assolutamente il poso di questa classe la cosa. Quindi se Ti devi libermi di chiedermi qualunque cosa a sto punto. Bene, se siete lì, se ci siete fino al lì sotto, abbiamo detto che alternativamente potevamo definire la derivata in questo modo, giusto? Quindi, fondamentalmente vuol dire che saremmo andati a prendere un punto x - h più piccolo di x asterisco, saremmo andati a considerare la secante che passa per questi due punti, ok? Quantomeno abbiamo il coefficiente angolare positivo come per la tangente e nuovamente per h che va a 0 punto si avvicina a questo e quindi la mia approssimazione diventa coincidente con la tangente. Ok? Quindi è un’altra opzione, giusto? Perché considerare x st + h da buon una buona persona che va controtendenza uno può prendere x- H. E allora a questo punto questa è di nuovo la definizione esatta che ci risulta in digest esattamente come quella prima per la presenza del limite. Quindi definisco un secondo possibile schema per approssimare f’ di xar. Come mai si chiamerà secondo voi? Delta - f di xar e sarà uno schema di differenze finite al indietro se premere in avanti. Ok? Quindi da questo segue il secondo schema di approssimazione. che mi porta a definire un oggetto che in modo compatto chiamiamo delta - f x asterisco e questo coincide col rapporto incrementale che abbiamo scritto qua sopra e quindi fx st - fx -/ h schema alle differenze finite all’indietro domanda. Vi aspettate che sia meglio di questo schema, cioè che lo schema le differenze finite all’indietro sia meglio dello schema le differenze finite in avanti o no?\nNon ho capito. Sappiamo che sappiamo che\nEsatto. Cioè, ma anche graficamente non vi ma che in certi casi in particolari può darsi che ci sia differenza, ok? Quindi bene o male sembra brutto tanto uguale e infatti lo facciamo con un passaggio, si può verificare di nuovo con di nuovo supponendo regolarità C2 che è esattamente uno schema del primo ordine anche questo. Ok? Fino a quel punto uno vale l’altro. Quindi calcoliamo f’ x star - delta - f. Questa volta pur centrando lo sviluppo di telo sempre in x asterisco e ancora al secondo ordine, andiamo a valutarlo in x - h. Quindi l’unica cosa a cui stare attenti sono i segni che si alternano, ok? Quindi abbiamo fx - h vol’ x² + h2 per la derivata seconda di falcolato in un certo beta dove questa volta beta vive tra x² - h. Ok? Quindi rispetto a prima c’è un meno che balla e la valutazione dove viene fatta la valutazione. E allora procedo esattamente come prima, divido per h, ok? E questa volta conviene portare chi questi due oggetti a sinistra e il resto lascio tutto dov’è. Ok? Quindi abbiamo f’ di x asterisco, poi abbiamo lui - fx asterisco/ fx asterisco - h / h e questo è uguale a h/2 per la derivata. seconda di essere qualitate in beta. Ok? Bene. Nuovamente accorpiamo questi due oggetti, quindi facendo una frazione unica, 1/ h sparisce e qua rimane un e questo oggetto qui è esattamente il nostro delta - fx st. Ok? Quindi l’errore è esattamente identico tranne che per un cambio di segno e quindi anche questo è uno schema. Qua c’è un uno del primoordine per h che va a 0. Ok? Quindi, visto che noi non ci accontentiamo mai e sono d’accordo su questo approccio alla vita, eh Vi domando, abbiamo due schemi che sono, insomma, due schemi del primo ordine, quindi due cose vagamente poco utili sul tavolo. Ok? C’è un modo per avere uno schema del secondo ordine, cioè vale il solito detto che noi non abbiamo tempo da aspettare, ok? Quindi se avesse uno schema del secondo ordine questo convergerebbe molto più velocemente. Secondo voi, guardando là, qui la parte geometrica sempre un po’ aiuta quando siamo in difficoltà? La media,\npiù che la media uso il non è una media esattamente, ma quale retta considero? Viene viene in mente un’altra retta per inciso. Esercizio tanto utile. Questa retta qua chi è? Usando il gergo che avevo imparato in due argomenti precedenti, è la retta che\ninterpola F in queste due coppie di dati, giusto? Quindi vi inviterei a fare il seguente esercizio che non fa male. Prendete le due coppie di punti X star f x star, poi dopo ritorna alla domanda x star + h fx star + h. Ok? Avete due copie, due dati, due copri di dati. Costruite la retta che interpola queste due copie di dati che, guarda caso è proprio questa retta qua. Quindi costruite P 1 F che interpola questi due dati e poi fatene la derivata e scoprirete che quello che ottenete è esattamente il vostro delta + fx stara. Ok? Quindi, fatelo esplicitamente, vuol dire che dovete costruire i polinomi caratteristici di la granja. Quando fate riferimento a questo nodo, eh dovete costruire il polinomio associato a lui e quindi insomma dovete tenere propriamente in considerazione verrà moltiplicato per questo valore più questo valore per il polinomio caratteristico associato a x star st h fate proprio i conti a manina due punti okruite questo, lo derivate e troverete esattamente la stessa cosa. È la traduzione grafica di quello che abbiamo fatto. Abbiamo preso la retta che passa per queste due coppie di punti reinterpola, ok? E la sua pendenza che è la derivata del nostro delta + f. Analogamente non sto a dirlo se prendessi x - h f x² - h f x² - h x² f x ok stessa cosa, è un esercizio interessante che vi fa capire immediatamente se avete capito l’interpolazione di la grange, per quello dico è interessante. Quindi siamo alla ricerca di qualcosa di più furbo, cioè qualcosa che converga prima. Quindi guardando la retta, anziché guardando, scusatemi il grafico, anziché farla media, che non è che mi faccio tanto felice come risposta, che retta vi verrebbe da prendere in considerazione? Eh, la digazione,\nno, molto più facile. Guardate sti punti, li avete accoppiati in un certo modo. Avete preso sempre due coppie di punti consecutivi successivi, va bene? Uguale. Quindi perché non andare a prendere baretta\nverso la casa. Stai che passa in basso\nmi debide le coordinate perché forse è giusto.\nSì, il primo quello xerisco - h la altro x + h poi la retta che fa lì\nm gli parafruso perché non è del tutto giusta. Prendo la retta che interpola le coppie x star - h f x - h x + h f star + h. Ok? Volevo dire più o meno questo. No, ma non importa, faccio finta di Sì, certo, ovvio. Ok. Bene. Quindi prendo questa retta qua. Ok. Giusto. Ah. Ah. Ok. Ok.\nOk. Pazienza. prendo questa retta e come vedete questa retta è già molto più simile alla mia tangente, giusto? Quindi quella associata delta più andava esattamente da un’altra parte, quella associata a delta meno ha ancora una pendenza molto diversa. La tangente che è questa e questa che passa per queste due coppie di punti effettivamente è meglio, sembra meglio, ma adesso verifichiamo che è meglio di suo. Quindi andiamo a definire il terzo e ultimo schema per approssimare la nostra derivata prima così che 5 minuti visto il disagio tecnico che abbiamo avuto inizialmente. Quindi vuol dire questa volta che se vogliamo sempre fa riferimento all’analisi andremo a considerare il limite per h che tende a 0 di fx + h - fx - h. Questa volta diviso\n2\n2h Ok? Quindi il rapporto incrementale, ricordatevi che deve sempre far parlare quantità in ordinate e quantità in ascissa corrispondenti, quindi la copertura in x è di 2h. H. Buttiamo via al limite e così diamo luogo al terzo schema per approssimare la vostra f’ di Xstar, che questa volta indichiamo senza meno e senza più perché sto centrando l’informazione, quindi lo indichiamo soltanto con delta fx star e questo è uguale a f di x² + h - f x - h / 2 e questo si chiama differenza finita centrata. E adesso l’ultima cosa che facciamo è vedere effettivamente uno schema di ordine 2 rispetto ad h. Quindi andiamo a calcolare questa cosa qua. Quindi la differenza tra f’ di x car delta f di x star. Come sempre non c’è nulla di gratuito, ok? E quindi portare a casa uno schema che converge più velocemente, quindi il cui errore converge più velocemente a zero, ci porterà ad aumentare ai noi le richieste di regolarità su F, che quindi non basterà più che sia C2, ma dovremmo chiedere C3. Questo è il pegno che dobbiamo pagare. E allora per trovare l’espressione dell’errore, quindi questa quantità qua, procediamo in parallelo andando a espandere i Taylor, scusate, andando a espandere attraverso Taylor F, la centriamo sempre in x asterisco, la tronchiamo al terzo ordine e una volta la valutiamo in x segnato + h, l’altra volta la valutiamo in x segnato - h. Ok? Quindi abbiamo f x + h che è uguale a f x st + h vol f’ x st + h2 su 2 per la derivata seconda di f calcolata ancora in x aster e poi abbiamo h su 6 per la derivata terza di f calcolato in un qualche punto sigma che se ne sta tra il segnato x star scusate e xar. Ok? Faccio lo stesso esercizio valutando in x st - h, quindi abbiamo fx star - h vol + h2 * f - h3 su per la derivata terza di f calcolata in un qualche punto gamma che se ne sta tra x asterisco - h e x asterisco Ok, quindi l’espansione di failor, diciamo, all’ordine successivo. Ok, procediamo facendo che cosa? Dobbiamo valutare la differenza tra f’ e quel nuovo oggetto lì. Quindi, come combiniamo questi due sviluppi? Andiamo a o rismiamo e sottraiamolo. Dobbiamo trasparire una deriva, la derivata la prima lo dobbiamo tenere perché dobbiamo valutare sta cosa, no? Quindi chi è che ci dà noi la derivata seconda, giusto? Che ci serve la derivata seconda? A niente, quindi le sottraiamo ovviamente. Ok? Quindi sottraiamo le due equazioni. Quindi abbiamo f x² + h - fx - H. Ok? Tutti tutte le gli oggetti, diciamo, tutte le derivate di ordine fare vanno via, quindi la derivata zeresima che è la valutazione di f. Ok? Quindi andando a sottrarre questi due oggetti rimane un h - h che ci dà due volte h * f’ x². Questi e questi si semplificano e qua rimane un + h su che moltiplica la derivata terza di falcolata in sigma più la derivata terza di falcolata in gamma. Ok? Ritorna. Quindi ho sottratto membro a membro. Ok? Adesso, anziché dividere tutto per h come facevamo prima, divido per 2 sono sempre alla ricerca del denominatore di delta f. Quindi questo è diviso 2H, questo è diviso 2H, questo sparisce, questo diventa un quadrato e qua rimane un 2. Ok? E a questo punto cosa faccio? Sposto questi due oggetti a destra e questo oggetto a sinistra. Quindi riscrivo i vari pezzi. Ho f’ di x asterisco - fx asterisco + h / 2h + f asterisco - h / 2 e questo è uguale a - H2 / 12 per la derivata terza di f calcolata in sigma più la derivata terza calcolata in gamma. Quindi ho, diciamo, aumentato espanso un ordine più ad un ordine più alto le due espansioni di tela che avevamo usato prima, le ho combinate con una sottrazione per eliminare le cose che non compaiono in quello che devo valutare. Ho diviso anziché per h* 2h perché è il nuovo denominatore che abbiamo e sposto le cose in modo da avere f’ x - delta f. Ok? Quindi siamo qua. Come sempre metto questi due oggetti in un’unica frazione, quindi più divento un men e i 2h dei 2h me ne rimane 1. E questo è esattamente il mio delta fx star sale Ok? E quindi abbiamo un errore che grazie a Dio se ne va a zero per h che va a 0, ma questa volta lo fa con un esponente che da 1 diventa 2. Ok? Quindi la differenza finita centrata è uno schema di ordine 2 per approssimare la derivata prima, giusto? Quindi mi risulta, ditemi se risulta anche a voi che in questo momento voi avete tre schemi per approssimare la derivata prima. Avete delta + fx, delta - f e delta f. Ok? Giusto? Avete uno schema differenze finite in avanti, uno l’indietro e uno centrato. Quindi ammesso di avere tutta la regolarità che vi serve, quale scegliete? Questo.\nQuello centrato, giusto? Perché è un ordine peggiore. Cosa potrebbe evitarmi e qua chiudo di usare di fare questa scelta? Due cose fondamentalmente la regolarità, quindi occhio che queste due vanno bene se C2. Questa vi chiede un C3 e magari la regolarità C3 non ce l’ho. E l’altra cosa un pochino più difficile come\nNo, è una cosa più anche questa più da da praticoni, cioè supponete di avere di voler calcolare la derivata di f una collezione di punti. Ok? Quindi all’interno va bene tutto, ma se io devo calcolare la derivata prima in a cosa uso? Ho libertà di scelta. No,\nposso usare soltanto il delta più, giusto? Perché indietro non ho nessun altro e quindi qua non posso calcolare né delta meno né delta più, scusate, né delta e viceversa Quando sono qua in B devo necessariamente calcolare, utilizzare del - ok? Quindi ripeto, al momento e sono anche le uniche che vediamo, avete queste tre formule per approssimare la derivata prima di una funzione in un punto. Due schemi sono del primo ordine a fronte di una regolarità c2, uno schema di ordine 2 a fronte di una regolarità C3. Quindi l’idea è uso la se l’ultimo schema se posso, dove se posso vuol dire se ho tutta la regolarità che mi serve e più subentra anche, diciamo, una richiesta di o le informazioni che mi servono per costruire lo schema. Quindi, vuol dire che se io, per esempio, sono in un estremo di un intervallo e quindi la mia funzione prima non è definita e dopo non è definita, agli estremi ho un vincolo del preciso sullo schema che posso andare a utilizzare. Ok? In avanti sono in A, arrivo subito all’indietro ci sono in B. Vi dica tutto regolarità per scrivare l’errore, però\nSì, non per scriverla. Per scriverla serve soltanto che sia C1, direi, cioè che esista la deriv quello che stiamo approssimando nel punto\nSì, però poi alla fine si si fa, diciamo, caso anche alla regolarità. Comunque sì, poi insomma la disperazione guardo che sia almeno C1"},"6--full-note/temporaneo_2":{"slug":"6--full-note/temporaneo_2","filePath":"6- full note/temporaneo_2.md","title":"temporaneo_2","links":[],"tags":[],"content":"Appunti Lezione: Sistemi Sovradeterminati, Minimi Quadrati e Collegamento alle Equazioni Normali\n1. Introduzione ai Sistemi Sovradeterminati\nUn sistema lineare A x = y si dice sovradeterminato quando il numero di equazioni (righe) m è maggiore del numero di incognite (colonne) n, cioè m &gt; n.\nIn tali casi, il sistema in generale non ammette soluzione esatta e quindi si modifica la definizione di soluzione, cercando la soluzione nel senso dei minimi quadrati:\n\nTrovare x^* \\in \\mathbb{R}^n tale che minimizzi \\| A x - y \\|^2.\n\n2. Soluzione nei Minimi Quadrati\nLa soluzione nel senso dei minimi quadrati si può ottenere:\n\n\nVia equazioni normali: se A ha rango pieno, allora la soluzione x^* soddisfa il sistema:\nA^T A x^* = A^T y\n\n\nVia fattorizzazione QR: utile per evitare instabilità numerica.\n\n\n3. Sistemi Sovradeterminati a Rango Non Massimo\nSe A non ha rango massimo, il problema di minimi quadrati ha infinitamente molte soluzioni. In questo caso si cerca:\n\nLa soluzione che minimizza la norma della soluzione tra tutte quelle che minimizzano la norma del residuo:\n\\min_{x \\in \\mathbb{R}^n} \\| x \\| \\quad \\text{t.c.} \\quad \\| A x - y \\| = \\min\n\n4. Collegamento con la Regressione Polinomiale\n4.1 Polinomio dei Minimi Quadrati\nData una serie di dati (x_i, y_i), si vuole trovare un polinomio f_T(x) di grado m che minimizza la somma degli scarti quadratici:\n\\sum_{i=0}^n \\left( y_i - f_T(x_i) \\right)^2\ndove f_T(x) = a_0 + a_1 x + \\dots + a_m x^m.\n4.2 Problema di Minimizzazione Equivalente\nSi definisce un generico polinomio p_m(x) = b_0 + b_1 x + \\dots + b_m x^m, con \\vec{b} = [b_0, \\dots, b_m]^T, e si cerca:\n\\vec{a} = \\arg\\min_{\\vec{b} \\in \\mathbb{R}^{m+1}} \\sum_{i=0}^n \\left( y_i - (b_0 + b_1 x_i + \\dots + b_m x_i^m) \\right)^2\n\n4.3 Forma Vettoriale del Problema\nDefiniamo:\n\n\\vec{a} = [a_0, \\dots, a_m]^T\n\\vec{y} = [y_0, \\dots, y_n]^T\nA matrice di Vandermonde:\n\nA = \\begin{pmatrix}\n1 &amp; x_0 &amp; x_0^2 &amp; \\dots &amp; x_0^m \\\\\n1 &amp; x_1 &amp; x_1^2 &amp; \\dots &amp; x_1^m \\\\\n\\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n1 &amp; x_n &amp; x_n^2 &amp; \\dots &amp; x_n^m\n\\end{pmatrix}\nIl problema si riscrive come:\n\\vec{a} = \\arg\\min_{\\vec{b} \\in \\mathbb{R}^{m+1}} \\| A \\vec{b} - \\vec{y} \\|^2\nQuesta quantità rappresenta la norma al quadrato del residuo. La minimizzazione coincide con la risoluzione del sistema sovradeterminato nel senso dei minimi quadrati.\n4.4 Coincidenza con le Equazioni Normali\nOsservazione: questa formulazione è esattamente la stessa già incontrata nel caso della regressione lineare! Le equazioni normali sono:\nA^T A \\vec{a} = A^T \\vec{y}\nCalcolo esplicito dei termini:\n\n\nLa matrice A^T A ha componenti:\n(A^T A)_{jk} = \\sum_{i=0}^n x_i^{j+k} \\quad \\text{per} \\quad j,k = 0,\\dots,m\nQuindi:\n\\sum x_i^0 &amp; \\sum x_i^1 &amp; \\dots &amp; \\sum x_i^m \\\\\n\\sum x_i^1 &amp; \\sum x_i^2 &amp; \\dots &amp; \\sum x_i^{m+1} \\\\\n\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n\\sum x_i^m &amp; \\sum x_i^{m+1} &amp; \\dots &amp; \\sum x_i^{2m}\n\\end{pmatrix} $$\n\n\n\nIl vettore A^T \\vec{y} ha componenti:\n(A^T \\vec{y})_j = \\sum_{i=0}^n x_i^j y_i\nQuindi:\n\\sum y_i \\\\\n\\sum x_i y_i \\\\\n\\vdots \\\\\n\\sum x_i^m y_i\n\\end{pmatrix} $$\n\n\n\n\nConclusione: il sistema delle equazioni normali derivato da una visione algebrica (minimizzazione \\| A \\vec{b} - \\vec{y} \\|^2) coincide esattamente con il sistema derivato con l’approccio analitico via derivate parziali.\n\n5. Sistemi Sottodeterminati\n5.1 Definizione\nUn sistema lineare A x = y è sottodeterminato se A \\in \\mathbb{R}^{m \\times n} con m &lt; n, quindi meno equazioni che incognite. In questo caso:\n\nLe soluzioni sono infinitamente molte.\nSi cerca la soluzione con norma minima:\n\nx^* = \\arg\\min_{x \\in \\mathbb{R}^n} \\| x \\| \\quad \\text{t.c.} \\quad A x = y\n5.2 Ipotesi di rango massimo\nSi assume che \\operatorname{rank}(A) = m. In questo caso si può usare la fattorizzazione QR dell’A^T oppure la pseudoinversa.\n6. Conclusione: Collegamento dei Due Metodi\nLa lezione ha mostrato come:\n\nIl problema dell’approssimazione polinomiale (retta di regressione generalizzata) è un esempio di problema di minimi quadrati.\nLa sua formulazione coincide perfettamente con il problema di risolvere un sistema sovradeterminato a rango pieno nel senso dei minimi quadrati.\nI due approcci (analitico e algebrico) portano allo stesso sistema lineare: quello delle equazioni normali.\n\nQuesto chiude il cerchio tra la regressione, i sistemi lineari e i problemi di ottimizzazione quadratica lineare.\nAppunti Lezione: Sistemi Sovradeterminati, Minimi Quadrati e Derivate - Parte 2\n7. Sistemi Sottodeterminati\n7.1 Motivazione ed Esempio Introduttivo\nQuando un sistema lineare A x = y ha meno equazioni che incognite, ossia m &lt; n, il sistema si dice sottodeterminato.\nEsempio semplice: considerare l’insieme delle rette passanti per un punto: sono infinite. Serve una condizione aggiuntiva per selezionare una soluzione.\nNel contesto dei sistemi lineari, cerchiamo la soluzione classica che soddisfa A x = y ma che abbia norma minima:\n\nTroviamo x^* \\in \\mathbb{R}^n tale che A x^* = y e \\|x^*\\| minimo.\n\n7.2 Definizione della Soluzione a Norma Minima\nPoniamo:\nx^* = \\arg\\min_{x \\in \\mathbb{R}^n} \\| x \\| \\quad \\text{t.c.} \\quad A x = y\nLa soluzione x^* soddisfa due condizioni:\n\nA x^* = y (soluzione in senso classico)\nx^* ha norma minima tra tutte le soluzioni\n\nSi dimostra che questa soluzione ha forma chiusa:\nx^* = A^T (A A^T)^{-1} y\n7.3 Verifica delle Due Condizioni\nCondizione 1: A x^* = y\nSostituiamo l’espressione di x^*:\nA x^* = A A^T (A A^T)^{-1} y = y\nInfatti A A^T (A A^T)^{-1} = I, la matrice identità. Quindi x^* soddisfa il sistema.\nCondizione 2: \\|x^*\\| è minima\nSi dimostra che x^* ha norma minima con il seguente ragionamento:\nSia x una qualunque soluzione del sistema, cioè A x = y. Allora:\n\\|x\\|^2 = \\|x^* + (x - x^*)\\|^2 = \\|x^*\\|^2 + \\|x - x^*\\|^2 + 2 (x - x^*)^T x^*\nOsservazione: il termine misto è nullo. Per verificarlo usiamo il fatto che A x = A x^* = y e quindi:\nA(x - x^*) = 0 \\Rightarrow x - x^* \\in \\ker(A)\nInoltre x^* \\in \\operatorname{Im}(A^T), e quindi i due spazi sono ortogonali.\nQuindi il prodotto scalare (x - x^*)^T x^* = 0.\nSegue:\n\\|x\\|^2 = \\|x^*\\|^2 + \\|x - x^*\\|^2 \\geq \\|x^*\\|^2\n7.4 Problemi Numerici e QR\nAnche qui, come nei sovradeterminati, il calcolo esplicito è numericamente instabile. Si preferisce usare la fattorizzazione QR della matrice trasposta:\nA^T = \\widetilde{Q} \\widetilde{R}\nAllora:\nx^* = \\widetilde{Q} (\\widetilde{R}^T)^{-1} y\n\nQuesto sfrutta la struttura ortogonale di \\widetilde{Q} e la superiorità triangolare di \\widetilde{R}.\n\n8. Approssimazione delle Derivate\n8.1 Motivazione Fisica e Ingegneristica\nSpesso è più interessante monitorare la variazione di una funzione piuttosto che la funzione stessa:\n\nIngegneria civile: stress e deformazioni dipendono da f&#039; (derivata dello spostamento)\nFluidodinamica: il flusso (cioè derivata) di inquinanti è più importante della concentrazione istantanea\n\n8.2 Definizione Analitica\nLa derivata prima si definisce come:\nf&#039;(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}\n\nProblema: il limite non è computabile numericamente.\n\n8.3 Differenze Finite in Avanti (Forward)\nSchema:\n\\delta^+ f(x) = \\frac{f(x + h) - f(x)}{h}\nErrore stimato usando Taylor (con f \\in C^2):\nf&#039;(x) - \\delta^+ f(x) = -\\frac{h}{2} f&#039;&#039;(\\alpha), \\quad \\alpha \\in (x, x+h)\nConclusione: schema di ordine 1. L’errore è O(h).\n8.4 Differenze Finite all’Indietro (Backward)\nSchema:\n\\delta^- f(x) = \\frac{f(x) - f(x - h)}{h}\nErrore:\nf&#039;(x) - \\delta^- f(x) = \\frac{h}{2} f&#039;&#039;(\\beta), \\quad \\beta \\in (x-h, x)\nConclusione: anche questo è schema di ordine 1, errore O(h).\n8.5 Differenze Finite Centrate (Centered)\nSchema:\n\\delta f(x) = \\frac{f(x + h) - f(x - h)}{2h}\nSviluppi di Taylor fino al terzo ordine, con f \\in C^3, portano a:\nf&#039;(x) - \\delta f(x) = -\\frac{h^2}{6} f^{(3)}(\\xi), \\quad \\xi \\in (x - h, x + h)\nConclusione: schema di ordine 2, errore O(h^2).\n\nNota: questo schema richiede più regolarità (classe C^3) ma converge più rapidamente.\n\n8.6 Tabella Riepilogativa degli Schemi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSchemaFormulaOrdineRegolarità richiestaDifferenze in avanti\\delta^+ f(x) = \\frac{f(x+h) - f(x)}{h}1C^2Differenze all’indietro\\delta^- f(x) = \\frac{f(x) - f(x-h)}{h}1C^2Differenze finite centrate\\delta f(x) = \\frac{f(x+h) - f(x-h)}{2h}2C^3\n8.7 Considerazioni Pratiche\n\n\nAi bordi dell’intervallo, non è possibile usare il centrato:\n\nIn a: si usa \\delta^+\nIn b: si usa \\delta^-\n\n\n\nScelta dello schema:\n\nSe possibile, usare quello centrato: più preciso\nSe la funzione è solo C^2, usare schema in avanti o indietro\n\n\n\nL’errore in ciascun caso può essere stimato con il massimo della derivata coinvolta nel resto di Taylor\n\n\n\nEsercizio consigliato: mostrare che \\delta^+ f(x) corrisponde alla derivata della retta che interpola i punti (x, f(x)) e (x+h, f(x+h)).\n\n\nApprofondimento: costruire lo sviluppo di Taylor completo per ogni schema e verificarne l’errore.\n\n9. Conclusione\nCon questa lezione si chiude il capitolo sui sistemi lineari indeterminati. A seguire, il corso affronterà temi di approssimazione di derivate e integrali, proseguendo il percorso sull’interpolazione e l’analisi numerica.\n\nSe vuoi che espanda anche la parte degli esercizi o inserisca dei box di sintesi visuale, fammi sapere!"},"6--full-note/temporaneo_4":{"slug":"6--full-note/temporaneo_4","filePath":"6- full note/temporaneo_4.md","title":"temporaneo_4","links":[],"tags":[],"content":""},"6--full-note/tutorial-chiamate-telefoniche-STUDIO-2":{"slug":"6--full-note/tutorial-chiamate-telefoniche-STUDIO-2","filePath":"6- full note/tutorial chiamate telefoniche STUDIO 2.md","title":"tutorial chiamate telefoniche STUDIO 2","links":["tags/flashcard_zero","tags/riscritto_zero","tags/revisione_zero","3--tag/tutorial","3--tag/POLI.RADIO"],"tags":["flashcard_zero","riscritto_zero","revisione_zero"],"content":"2025-04-24 13:02\n_Status: flashcard_zero  riscritto_zero  revisione_zero\n_Tags: tutorial. POLI.RADIO\ntutorial chiamate telefoniche STUDIO 2\nTutorial per Effettuare Telefonate dallo Studio 2\nDifferenze Fondamentali con lo Studio 1\n\nAssenza del canale telefono pre-caricato: Nello studio 2, il canale telefono deve essere caricato manualmente.\nAssenza del tastierino fisico: Per effettuare chiamate, è necessario utilizzare un’app sul computer di regia 2.\n\nCaricare il Canale Telefono (Tel 2)\n\nScelta del canale: Selezionare un canale libero. (esempio “Studio 1”)\nSelezione del tipo di canale:\n\n\nCliccare nel punto indicato per aprire il menu .\n\n\n\nSelezionare “source” premendo il pomellino .\n\n\n\nScegliere:\n\n“tel 2” per la diretta\n(Non caricare “tel 1” perché è già in studio 1).\n“tel 2 rec” per la registrazione .\n\n\n\n\n\nConferma del caricamento: Dopo aver selezionato il canale, uscire dal menu . Dovrebbe comparire “tel 2 D” per indicare che è stato caricato correttamente . Per ulteriore verifica, dovrebbero comparire due tacchette nello schermino .\nApertura dell’app X screen 2: Una volta caricato “tel 2”, aprire l’app chiamata “X screen 2” . È importante essere su “producer” .\n\n\nUtilizzo delle Linee Telefoniche e degli Ibridi\n\nLinee disponibili: In studio 2 ci sono due linee telefoniche con i numeri 2475 e 2476 .\nIbridi: L’app mostra due ibridi  che corrispondono a “tel 1” (A) e “tel 2” (B) .\nSelezione dell’ibrido corretto: Essendo nello studio 2, è necessario utilizzare “tel 2” (B) . Assicurarsi che sia selezionato questo .\n\n\nRicevere una Telefonata\n\n\nSegnalazione di chiamata: Quando si riceve una chiamata (es. numero uno), si accenderà la luce led .\n\n\n\nRispondere: Cliccare sul tasto “B” per agganciare la chiamata .\n\n\nComunicare: Alzare il fader (non specificato quale) e parlare nel microfono in cuffia .\n\n\nTalkback: per parlare con la persona senza inviarla in diretta basterà premere il talkback (analogo in Studio 1) .\n\n\n\nPiù telefoni: Se ci sono più telefoni, talk to backfeed permette di parlare a tutte le persone al telefono.\n\n\n\nTerminare la chiamata: Cliccare su “Drop” sul tasto “B” .\n\n\n\nIndicatore di linea: A seconda della linea selezionata, compare “A” o “BB” cliccando sul rispettivo tasto . Deve essere su “BB” .\n\n\nChiamate in entrata su diverse linee: Se una chiamata arriva, ad esempio, al numero 2476, . È ancora fondamentale rispondere premendo il tasto “B” .\nSe si è su “A”, cliccare prima su “B” e poi rispondere.\n\n\nEffettuare una Chiamata\n\nSelezionare la linea: Scegliere la linea da cui si desidera effettuare la chiamata (se voglio far uscire la chiamata dal 75  userò la linea 1 se voglio usare la linea 2 il 7 6) .\nAvviare la chiamata: Una volta selezionata la linea, cliccare sul tasto “B” .\n\nDigitare il numero: Inserire il numero di telefono, ricordandosi di mettere lo zero davanti .\n\nPremere “Dial”: Premere il tasto “Dial”  .\n\nScaricare il Canale Telefono al Termine\n\nProcedura: Quando la telefonata è terminata, è necessario rimettere a posto il canale  (es. rimetti a il canale Studio 1 se hai usato quello)\n\nTelefonate in Registrata\n\nstessa roba ma in  rec mtk:\nSelezione del canale: Selezionare “tel2 rec” nel canale desiderato (nell’esempio, un canale selezionato genericamente) .\nAssegnazione al canale di registrazione: Ricordarsi di assegnare il telefono a un canale di registrazione (es. canale 4, se gli intervistatori sono sul canale 3) .\n\nUtilizzo del tasto B: Anche in registrazione, usare il tasto “b” che vuol dire tel 2 .\n"},"6--full-note/tutorial-template-video":{"slug":"6--full-note/tutorial-template-video","filePath":"6- full note/tutorial template video.md","title":"tutorial template video","links":["3--tag/POLI.RADIO","3--tag/tutorial"],"tags":[],"content":"2025-04-23 15:03\n_Tags: POLI.RADIO  tutorial\ntutorial template video\nAppunti per l’utilizzo del Template Video Grafiche su Premiere\n1. Preparazione Iniziale e Ricollegamento dei File\n\nPer iniziare, vai sulla cartella “condivisa”.\nAll’interno di “condivisa”, trova il percorso “condivisa/materiale comunicazione/nuovi template/grafica video”.\nCopia e incolla il progetto premiere sulla tua cartella (lavorerai sulla copia).\nRinomina e apri il file “template podcast” copincollato.\nInizialmente, i file non saranno collegati .\nPer ricollegare, fai individua ,ricerca la cartella “condivisa/materiale comunicazione/nuovi template/grafica video/file”\nDopo aver ricollegato la grana, Premiere farà tutto in automatico. Il file sarà ora ricollegato e utilizzabile.\n\n2.Preparazione della Grafica PSD per il Video\nAssicurati che il file PSD di Photoshop della grafica sia predisposta per l’utilizzo video. Questo significa che deve avere lo sfondo trasparente e contenere solo gli elementi essenziali: il titolo, l’icona del play, lo sfondo colorato e il logo del programma.\nPer ottenere questo risultato:\n\n\nFai una copia del file PSD del podcast, rinominandolo ad esempio grafica_video.psd.\n\n\nNella copia, nascondi tutti gli elementi grafici non necessari per il video, come la grana, la linea personalizzata e la linea bianca (sta nascosta nella cartella non modificare) e ogni immagine di fondo non indispensabile.\n  \n\n\nLascia visibili solo gli elementi fondamentali per il video: titolo, play, sfondo colorato e logo del programma.\n\n\n\nIn questo modo, quando trascini il file PSD nella sequenza “Grafica Video”, non sarà necessario fare ulteriori modifiche, e il risultato sarà immediatamente pronto per l’esportazione. Inoltre, ogni salvataggio del PSD sarà automaticamente aggiornato in Premiere.\n3. Modifiche del Template (Linea Colorata e Grafica PSD)\n\n\nCi sono due elementi da modificare nel template, che poi rimarranno impostati permanentemente: la linea colorata e la grafica video.\n\n\nModifica della Linea Colorata:\n\nClicca sulla finestra progetto la sequenza linea colorata che sta sulla cartella MODIFICARE.\nDoppio clicca sulla traccia video verde  “sostituisci colore”.\nSi aprirà la finestra controllo effetti .\nVai tutto giù e troverai l’opzione “sostituisci colore”.\nTrova la sotto-opzione “nuovo colore” e scegli di che colore vuoi che sia la linea (tramite hex copi incolli il colore secondario del programma).\nCambiare il “nuovo colore” dovrebbe cambiare il colore della linea personalizzata. Nell’esempio, viene lasciata nera.\n\n\n\n\nModifica della Grafica Video (PSD):\n\nLa grafica video è un file PSD (la grafica di photoshop del tuo programma).\nClicca sulla finestra progetto la sequenza Grafica Video che sta sulla cartella MODIFICARE.\nDevi semplicemente trascinare il file PSD sopra l’area dedicata nel template (vai a sostituire il png di prova “esempio grafica video.png” che è stato fatto).\nC’è da considerare che “Photoshop e Premiere non comunicano così bene come dovrebbero fare”, quindi potrebbe metterci un po’.\nIl vantaggio di usare un file PSD è che qualsiasi modifica farai nel PSD (e salverai), verrà automaticamente aggiornata anche in Premiere.\n\n4. Inserimento e Lavorazione del Video\n\n\n\nDopo aver modificato la linea colorata e la grafica PSD, devi andare in una delle due sequenze che stanno fuori da ogni cartella.\n\n\nNel template ci sono due sequenze: “15 secondi” e “30 secondi”.\n\n\nDevi decidere se vuoi fare un video da 15 o da 30 secondi.\n\n\nUna volta scelta la sequenza (ad esempio, quella da 15 secondi), devi inserire il video che vuoi mettere al suo interno.\n\n\nIl video di prova presente nel template va cancellato; serve solo per mostrare come funziona.\n\n\nMetti il tuo video. Trascina il video sopra la timeline.\n\n\nSe vuoi tagliare il video, fai un Ctrl+K.\n\n\nPuoi allungare o accorciare il video semplicemente trascinando l’estremità del video.\n\n\npuoi editare il tuo video come vuoi!\n\n\n5. Organizzazione dei File\n\nLa cartella “Non modificare” non viene toccata e “proprio neanche vista”.\nLe uniche cose da modificare sono la linea “Colorata” e la “durata del video” (scegliendo la sequenza da 15 o 30 secondi).\nÈ consigliato creare una cartella  (o un raccoglitore) “temporaneo”.\nIn questa cartella “temporaneo” metterai il video che ti serve. Ad esempio, il video della registrazione che userai per quella grafica.\nDopo aver usato il video, lo cancelli dalla cartella “temporaneo”.\nQuesto sistema serve per avere tutto ordinato e non avere “un casino”.\n\n6. Come Esportare il Video\nPer esportare il tuo video in Adobe Premiere, segui questi passaggi:\n\n\nPer avviare l’esportazione, dopo aver selezionato la sequenza (15/30 secondi) che vuoi esportare ,clicca sul tasto “esporta” che trovi in alto a sinistra su Adobe Premiere. Questo aprirà una nuova finestra.\n\n\nRinomina il file. consiglio il formato RR_ nome del programma_ # settimana per facilitare l’organizzazione e l’identificazione.\n\n\nRicordati di cambiare il percorso di destinazione del file.\n\n\nCome predefinito (preset), imposta “Instagram Reel 1080”. Questo dovrebbe selezionare le impostazioni ottimali per una buona qualità senza tempi di caricamento eccessivi.\n\n\nÈ utile fare un controllo nella finestra di esportazione. Clicca su “come sorgente” nella parte della finestra. Questo serve per assicurarsi che l’aspect ratio corretto (il 5/4 dell’immagine del podcast) venga selezionato.\n\n\nUna volta impostato tutto, clicca su “esporta”.\n\n\nA questo punto, avrai il tuo video pronto!\n\nguida redatta da Karyl Guerrero (Skaryllo)\n\n\nerrata corrige:\n\nla foto di esempio del psd deve essere senza linea\n"},"index":{"slug":"index","filePath":"index.md","title":"SIUM","links":[],"tags":[],"content":"Benvenuto!\nQui condividerò i miei appunti di ingegneria matematica 📚"}}